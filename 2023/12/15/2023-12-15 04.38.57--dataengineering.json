{"kind": "Listing", "data": {"after": "t3_18i1zoe", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nI am making a small group of people learning data engineering where we get on a call together every other week and talk about tools we're learning and other DE-related things. This will be good for everyone in the group to get better at DE and help each other out when needed. \n\nThanks, and happy learning to everyone!\n\nEdit: If more of you are interested consider making small groups with each other.\n\nEdit, again: If you are still interested please reach out to other people who want to make groups.", "author_fullname": "t2_3arqiq34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Group of Data Engineering Learners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i9w4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702601650.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702564301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;I am making a small group of people learning data engineering where we get on a call together every other week and talk about tools we&amp;#39;re learning and other DE-related things. This will be good for everyone in the group to get better at DE and help each other out when needed. &lt;/p&gt;\n\n&lt;p&gt;Thanks, and happy learning to everyone!&lt;/p&gt;\n\n&lt;p&gt;Edit: If more of you are interested consider making small groups with each other.&lt;/p&gt;\n\n&lt;p&gt;Edit, again: If you are still interested please reach out to other people who want to make groups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18i9w4x", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePen297", "discussion_type": null, "num_comments": 112, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i9w4x/small_group_of_data_engineering_learners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i9w4x/small_group_of_data_engineering_learners/", "subreddit_subscribers": 146008, "created_utc": 1702564301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was looking into Azure documentation for clustered columnstore indexes and I noticed the following:  \n\" Clustered columnstore indexes work on segments of 1,048,576 rows. As Azure Synapse Analytics has 60 nodes per distribution, the minimum recommended number of rows for a clustered columnstore index is 60,000,000. \"\n\nwhy is it that the don\u00b4t close it to just 1million? also, why is this the exact same limit of rows on excel?\n\nIs there someting I'm missing about this number?", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why 1,048,576 rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18id3ea", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702573133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking into Azure documentation for clustered columnstore indexes and I noticed the following:&lt;br/&gt;\n&amp;quot; Clustered columnstore indexes work on segments of 1,048,576 rows. As Azure Synapse Analytics has 60 nodes per distribution, the minimum recommended number of rows for a clustered columnstore index is 60,000,000. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;why is it that the don\u00b4t close it to just 1million? also, why is this the exact same limit of rows on excel?&lt;/p&gt;\n\n&lt;p&gt;Is there someting I&amp;#39;m missing about this number?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18id3ea", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18id3ea/why_1048576_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18id3ea/why_1048576_rows/", "subreddit_subscribers": 146008, "created_utc": 1702573133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "People who\u2019ve been in this game since when the hype was really getting started in the beginning of the last decade, what was it like working in the first companies that tried to build big data pipelines? What was the stack you worked on? I know that Hadoop and NoSQL were very trendy at the time, but can you share some more typical technologies that you ran into a lot? Are some of them supplanted by now or are they mostly still going strong?", "author_fullname": "t2_1xobc52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was data engineering like circa 2011-2013?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ilbto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702594923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People who\u2019ve been in this game since when the hype was really getting started in the beginning of the last decade, what was it like working in the first companies that tried to build big data pipelines? What was the stack you worked on? I know that Hadoop and NoSQL were very trendy at the time, but can you share some more typical technologies that you ran into a lot? Are some of them supplanted by now or are they mostly still going strong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ilbto", "is_robot_indexable": true, "report_reasons": null, "author": "pimmen89", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ilbto/what_was_data_engineering_like_circa_20112013/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ilbto/what_was_data_engineering_like_circa_20112013/", "subreddit_subscribers": 146008, "created_utc": 1702594923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Heres an architectural journey that I experienced on working with a data product on AWS Serverless architecture then  to migrate it back to servers using celery and Kubernetes and creating an entire orchestration workflow that would give  more control in architecture, feature developments, cost reductions and turn around time reductions. What we ended up was with creating our own AWS lambda and stepfunctions and avoid vendor lockins\n\n[https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2](https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2)\n\n  \nFeel free to share down your thoughts and opinions on this .  \n", "author_fullname": "t2_5fi8z4gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To Serverless or not to Serverless that is the question..?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18icwuf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702577435.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702572640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heres an architectural journey that I experienced on working with a data product on AWS Serverless architecture then  to migrate it back to servers using celery and Kubernetes and creating an entire orchestration workflow that would give  more control in architecture, feature developments, cost reductions and turn around time reductions. What we ended up was with creating our own AWS lambda and stepfunctions and avoid vendor lockins&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2\"&gt;https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feel free to share down your thoughts and opinions on this .  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?auto=webp&amp;s=67d661201a964c66dc3ea00e4111958c4811fe64", "width": 1012, "height": 969}, "resolutions": [{"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=961c02fbc890e97e99c12d9c30e2f3de2d710276", "width": 108, "height": 103}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb182e35d0e3cc78a4e456b2f3410fd275f7ade3", "width": 216, "height": 206}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c0cbb4a8db6a2a5468b4d2ef7efe2e5d3a21de4", "width": 320, "height": 306}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=83b51bc6a41e93746a01b5f547914ad8d1726684", "width": 640, "height": 612}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=58a3a85dd698d423e21144f798dbb70c58014e9e", "width": 960, "height": 919}], "variants": {}, "id": "mVLxJRsuAEGjFpeAi_DoJiW5UQVt-Y4U2Q6WWdTEZwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18icwuf", "is_robot_indexable": true, "report_reasons": null, "author": "Drphysics5", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18icwuf/to_serverless_or_not_to_serverless_that_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18icwuf/to_serverless_or_not_to_serverless_that_is_the/", "subreddit_subscribers": 146008, "created_utc": 1702572640.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a proprietary Excel .VBA that uses a highly complex mathematical function using 6 values to generate a number.  E.g.,:\n\n=PropietaryFormula(A1,B1,C1,D1,E1)*F1\n\nI don't have access to the VBA source code and a can't reverse engineer the math function.  I want to get away from using Excel and be able to fetch the value with an HTTP call (Azure function) by sending the 6 inputs in the HTTP request.   To generate all possible values using these inputs, the end result is around 600 billion unique combinations.\n\nI'm able to use Power Automate Desktop to open Excel, populate the inputs, and generate the needed value using the function.  I think I can do this for about 100,000 rows for each Excel file to stay within the memory limits on my desktop.  From there is where I'm wondering what would be the easiest way to get this into a data warehouse.  I'm thinking I could upload these 100s of thousands of Excel files to Azure ADL2 storage and use Synapse Analytics or Databricks to push them into a database, but I'm hoping someone out there may have a much better, faster, and cheaper idea.\n\nThanks!", "author_fullname": "t2_9lsmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you populate 600 billion rows in a structured database where the values are generated from Excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18il8i8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702594692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a proprietary Excel .VBA that uses a highly complex mathematical function using 6 values to generate a number.  E.g.,:&lt;/p&gt;\n\n&lt;p&gt;=PropietaryFormula(A1,B1,C1,D1,E1)*F1&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have access to the VBA source code and a can&amp;#39;t reverse engineer the math function.  I want to get away from using Excel and be able to fetch the value with an HTTP call (Azure function) by sending the 6 inputs in the HTTP request.   To generate all possible values using these inputs, the end result is around 600 billion unique combinations.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m able to use Power Automate Desktop to open Excel, populate the inputs, and generate the needed value using the function.  I think I can do this for about 100,000 rows for each Excel file to stay within the memory limits on my desktop.  From there is where I&amp;#39;m wondering what would be the easiest way to get this into a data warehouse.  I&amp;#39;m thinking I could upload these 100s of thousands of Excel files to Azure ADL2 storage and use Synapse Analytics or Databricks to push them into a database, but I&amp;#39;m hoping someone out there may have a much better, faster, and cheaper idea.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18il8i8", "is_robot_indexable": true, "report_reasons": null, "author": "dantasticdotorg", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18il8i8/how_would_you_populate_600_billion_rows_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18il8i8/how_would_you_populate_600_billion_rows_in_a/", "subreddit_subscribers": 146008, "created_utc": 1702594692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our org (~ 7000 employees) is looking to get into DataBricks. Management has expressed their belief that a dedicated application admin position should not be necessary since DataBricks handles all the infrastructure for you.\n\nI\u2019m of the belief a mission critical system should have an owner to handle troubleshooting, permissioning, policy rules, etc, and that making it an analyst\u2019s part time job is asking for trouble.\n\nThoughts? Data is probably in the 10 tb range but with a desire to grow into high volume streaming use cases.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks admin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18idt4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702575002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our org (~ 7000 employees) is looking to get into DataBricks. Management has expressed their belief that a dedicated application admin position should not be necessary since DataBricks handles all the infrastructure for you.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m of the belief a mission critical system should have an owner to handle troubleshooting, permissioning, policy rules, etc, and that making it an analyst\u2019s part time job is asking for trouble.&lt;/p&gt;\n\n&lt;p&gt;Thoughts? Data is probably in the 10 tb range but with a desire to grow into high volume streaming use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18idt4y", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18idt4y/databricks_admin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18idt4y/databricks_admin/", "subreddit_subscribers": 146008, "created_utc": 1702575002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started working with a small business. Until now, they have been using Microsoft SharePoint to keep their system-generated Excel files every day and then access them with other programs like Power BI. Still, now they are thinking about some more reliable solution to have a database to keep the data  they were thinking about Microsoft access. Still, I am thinking about what is the best thing these days for a small business to keep their data just a few different tables with a few relationships or even none of them.", "author_fullname": "t2_q9hhtqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with a database choice for small business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i43ue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702542541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working with a small business. Until now, they have been using Microsoft SharePoint to keep their system-generated Excel files every day and then access them with other programs like Power BI. Still, now they are thinking about some more reliable solution to have a database to keep the data  they were thinking about Microsoft access. Still, I am thinking about what is the best thing these days for a small business to keep their data just a few different tables with a few relationships or even none of them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18i43ue", "is_robot_indexable": true, "report_reasons": null, "author": "Mr-Nyan", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i43ue/help_with_a_database_choice_for_small_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i43ue/help_with_a_database_choice_for_small_business/", "subreddit_subscribers": 146008, "created_utc": 1702542541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pxof4neu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing LaunchFlow: The Developer Platform Built for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ie2zo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702575712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "launchflow.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.launchflow.com/blog/introducing-launchflow", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ie2zo", "is_robot_indexable": true, "report_reasons": null, "author": "josh_flow", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ie2zo/introducing_launchflow_the_developer_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.launchflow.com/blog/introducing-launchflow", "subreddit_subscribers": 146008, "created_utc": 1702575712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have always been wondering if luster based frameworks like Spark and Flink would make sense for stateless streaming application that also don't needny multi row aggregation (group by, avgs, sums, etc). I mean cases where all we need is to work record by record without needing to aggregate them nor to hold state.\n\nIf, for example, the deployment is done in a k8s cluster, we can write \"standard\" code and scale horizontally to handle more records (parallelism) also eventually opening threads for get more performance (concurrency).\n\nWould that be more perfomant and easy to deploy for such a case, since we avoid the cost of abstraction where we don't need it?\n\nI think that in other words I'm asking what is the purpose of Spark streaming and Flink when records/rows don't have to be aware of each other...\n\n  \nTwo use cases I'm think about is consuming from a Kafka topic and reading new files from S3 where the logic is row-by-row/file-by-file as stated. \n\nAppreciate opinions.\n\nThanks.", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any reason to use Spark or Flink for stateless non aggregative streaming application?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ihmuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702585389.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702585146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have always been wondering if luster based frameworks like Spark and Flink would make sense for stateless streaming application that also don&amp;#39;t needny multi row aggregation (group by, avgs, sums, etc). I mean cases where all we need is to work record by record without needing to aggregate them nor to hold state.&lt;/p&gt;\n\n&lt;p&gt;If, for example, the deployment is done in a k8s cluster, we can write &amp;quot;standard&amp;quot; code and scale horizontally to handle more records (parallelism) also eventually opening threads for get more performance (concurrency).&lt;/p&gt;\n\n&lt;p&gt;Would that be more perfomant and easy to deploy for such a case, since we avoid the cost of abstraction where we don&amp;#39;t need it?&lt;/p&gt;\n\n&lt;p&gt;I think that in other words I&amp;#39;m asking what is the purpose of Spark streaming and Flink when records/rows don&amp;#39;t have to be aware of each other...&lt;/p&gt;\n\n&lt;p&gt;Two use cases I&amp;#39;m think about is consuming from a Kafka topic and reading new files from S3 where the logic is row-by-row/file-by-file as stated. &lt;/p&gt;\n\n&lt;p&gt;Appreciate opinions.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ihmuo", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ihmuo/is_there_any_reason_to_use_spark_or_flink_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ihmuo/is_there_any_reason_to_use_spark_or_flink_for/", "subreddit_subscribers": 146008, "created_utc": 1702585146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fj8n8tp3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Database Engines use Functional Dependency Analysis to Improve Join Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18ih5ww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ROhIT7U9rbH6v9fxxr0BjA8yGwUvHK83afHPMnkHcMQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702583902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dolthub.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dolthub.com/blog/2023-12-13-functional-dependency-analysis/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?auto=webp&amp;s=399f65a130fe7e276dcf2f712ab6c84acaefd398", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ac95291e9bfb7eaa406f2ed4b8db927aa863b6e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3bdab7fa719123ca2fdd9b7bd5358504b0375cb9", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5abf32a74a7c9b106a3f8356c095900cceb64406", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e03f01c2a5f37cac07548ca5fc2c1003396eb99", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a289f58fc92cb2f6ca74962bef71ee39d1a7adb0", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=21bc571e2e3faa66af1e41315b3c9ebac4fb0473", "width": 1080, "height": 564}], "variants": {}, "id": "GVDVzKAiIGM2SDFASEWM2e-sTg22Qu_GDhOd_tP5EmU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ih5ww", "is_robot_indexable": true, "report_reasons": null, "author": "nick_at_dolt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ih5ww/how_database_engines_use_functional_dependency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dolthub.com/blog/2023-12-13-functional-dependency-analysis/", "subreddit_subscribers": 146008, "created_utc": 1702583902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm starting a new job soon in which I'll be migrating the current data set up to Databricks. The Databricks instance will be created when I join the company.\n\nWhat should I be thinking about/researching prior to this?\n\nE.g. Data modelling, s3 bucket naming conventions, etc.", "author_fullname": "t2_17e8p1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to plan before migrating to Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i84pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702558883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting a new job soon in which I&amp;#39;ll be migrating the current data set up to Databricks. The Databricks instance will be created when I join the company.&lt;/p&gt;\n\n&lt;p&gt;What should I be thinking about/researching prior to this?&lt;/p&gt;\n\n&lt;p&gt;E.g. Data modelling, s3 bucket naming conventions, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18i84pw", "is_robot_indexable": true, "report_reasons": null, "author": "RatBapple", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i84pw/what_to_plan_before_migrating_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i84pw/what_to_plan_before_migrating_to_databricks/", "subreddit_subscribers": 146008, "created_utc": 1702558883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here used Nessie's branching to trigger a data quality check? That is, whenever a merge is performed on a nessie branch, a GX/Soda/MC job is triggered on the branch for a Write-Audit-Publish workflow?\n\nIs it something to do with Nessie hooks? ([https://projectnessie.org/nessie\\_provider/](https://projectnessie.org/nessie_provider/)). I am also curious to know how people run their data quality checks on Iceberg tables.  \n", "author_fullname": "t2_abpkolp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality checks on Nessie branch merges", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i6617", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702551507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here used Nessie&amp;#39;s branching to trigger a data quality check? That is, whenever a merge is performed on a nessie branch, a GX/Soda/MC job is triggered on the branch for a Write-Audit-Publish workflow?&lt;/p&gt;\n\n&lt;p&gt;Is it something to do with Nessie hooks? (&lt;a href=\"https://projectnessie.org/nessie_provider/\"&gt;https://projectnessie.org/nessie_provider/&lt;/a&gt;). I am also curious to know how people run their data quality checks on Iceberg tables.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18i6617", "is_robot_indexable": true, "report_reasons": null, "author": "bytesapart", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i6617/data_quality_checks_on_nessie_branch_merges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i6617/data_quality_checks_on_nessie_branch_merges/", "subreddit_subscribers": 146008, "created_utc": 1702551507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was approached by a recruiter for a Data Engineer III contract remote (USA) position at a FAANG company, who informed me that the pay rate was $75/hr. I would have expected a higher rate from a FAANG company, or am I being unrealistic? I've seen many posts where individuals mention working on contract for FAANG, and I wanted to understand the actual figures before I negotiate.\n\nAdditionally, they're asking me to agree to and acknowledge the pay rate via email before any process begins. Can I still negotiate the rate later if I acknowledge do the interviews and end up receiving an offer?\n\nEdit: It's a shady contracting firm run from India that's employing me on their W2 ( No benefits, paid hourly) while I work for the end client.", "author_fullname": "t2_8b8jp1ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer III Pay Rate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i60w7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702574651.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702550905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was approached by a recruiter for a Data Engineer III contract remote (USA) position at a FAANG company, who informed me that the pay rate was $75/hr. I would have expected a higher rate from a FAANG company, or am I being unrealistic? I&amp;#39;ve seen many posts where individuals mention working on contract for FAANG, and I wanted to understand the actual figures before I negotiate.&lt;/p&gt;\n\n&lt;p&gt;Additionally, they&amp;#39;re asking me to agree to and acknowledge the pay rate via email before any process begins. Can I still negotiate the rate later if I acknowledge do the interviews and end up receiving an offer?&lt;/p&gt;\n\n&lt;p&gt;Edit: It&amp;#39;s a shady contracting firm run from India that&amp;#39;s employing me on their W2 ( No benefits, paid hourly) while I work for the end client.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18i60w7", "is_robot_indexable": true, "report_reasons": null, "author": "EstablishmentTop3908", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i60w7/data_engineer_iii_pay_rate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i60w7/data_engineer_iii_pay_rate/", "subreddit_subscribers": 146008, "created_utc": 1702550905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, post this here as well, because I spent some time gathering all the new releases of Snowflake (and competitors) in 2023 and mapping features against comparing platforms (and creating the pictures). Hopefully this usable for you as well\n\nhttps://preview.redd.it/h9uh1s2dj86c1.png?width=1219&amp;format=png&amp;auto=webp&amp;s=00efc02808eb614032adfb04a9e72df769d08cc1\n\n[https://www.recordlydata.com/blog/the-state-of-cloud-data-warehouses-2023-edition](https://www.recordlydata.com/blog/the-state-of-cloud-data-warehouses-2023-edition)", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The State of Cloud Data Warehouses - 2023 Edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"h9uh1s2dj86c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5302f49fa021390b5f4b94e6b5a00034a0806fa"}, {"y": 109, "x": 216, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=64fa7f821c9f94695adc2357243c1e72b8158f87"}, {"y": 161, "x": 320, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6648a02213aef0fe21833b9515edf452b4a8c9a8"}, {"y": 323, "x": 640, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fee02f395661e8a2c854e848b45df4378edae569"}, {"y": 485, "x": 960, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c1526461308512b4615a14d18b6375040c30395"}, {"y": 545, "x": 1080, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=614574dfd1538ff65c048b5650d468401f3f96be"}], "s": {"y": 616, "x": 1219, "u": "https://preview.redd.it/h9uh1s2dj86c1.png?width=1219&amp;format=png&amp;auto=webp&amp;s=00efc02808eb614032adfb04a9e72df769d08cc1"}, "id": "h9uh1s2dj86c1"}}, "name": "t3_18i5i5m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gEblvS_CjO-pSV2N3I12DjaRfrDFrrjQkAR0uOrbfpI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702548749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, post this here as well, because I spent some time gathering all the new releases of Snowflake (and competitors) in 2023 and mapping features against comparing platforms (and creating the pictures). Hopefully this usable for you as well&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/h9uh1s2dj86c1.png?width=1219&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=00efc02808eb614032adfb04a9e72df769d08cc1\"&gt;https://preview.redd.it/h9uh1s2dj86c1.png?width=1219&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=00efc02808eb614032adfb04a9e72df769d08cc1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/the-state-of-cloud-data-warehouses-2023-edition\"&gt;https://www.recordlydata.com/blog/the-state-of-cloud-data-warehouses-2023-edition&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18i5i5m", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i5i5m/the_state_of_cloud_data_warehouses_2023_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i5i5m/the_state_of_cloud_data_warehouses_2023_edition/", "subreddit_subscribers": 146008, "created_utc": 1702548749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI'm responsible for building out a financial reporting system at my company and I could use some advice on my approach.\n\n**A little background:** We offer coaching courses that will be split amongst various systems, but all purchased through deals with customers (companies), which are converted to credits and consumed through an atomic product model. We are in the process of transitioning to a credit system, so we will need to convert our existing deals into credits for the future system (deferred credits).\n\nEssentially I need to tie in various data sources to build a table to track at a deal level the amount of credits that have been assigned, unassigned and consumed. One of the challenges is that credit values can vary by deal and therefore need to be tracked at a deal level. Also, they need to burn down to 0 by oldest deal, first in first out. This might add a bit of annoyance dealing with remainders.\n\nHeres an example of roughly what im envisioning:\n\n|Company ID|deal id|trans dt|scheduled dt|completed dt|credit category|$ per credit|\\# of Credits|product|Product Cost|Credits Remaining|\n|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n|13|2|2/23/24|||unassigned|20|1000|A|300|1000|\n|13|2|2/23/24|3/01/24||assigned|20|1000|B|400|1000|\n|13|1|1/15/24|1/23/24|1/23/24|consumed|17.50|1500|B|400|1100|\n|13|1|1/15/24|||unassigned|17.50|1500|A|300|1100|\n|13|999|1/1/24|||deferred|23|3000|||0|\n\n&amp;#x200B;\n\nIts unclear to me what the best approach is for working through the many transformations involved here. I could build out a bunch of additional fields and apply calculations to the table at various stages of my pipeline with SQL, but im wondering if theres a more elegant solution through breaking it out into various tables and processes, using python or recursive functions etc.\n\nOne last caveat is that ideally this system will be able to track rate of spend of customers, which Id imagine would most simply be tracked through snapshot tables.\n\nSorry this was a lot, but any help is greatly appreciated!", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial Reporting Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ip1ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702612993.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702605806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m responsible for building out a financial reporting system at my company and I could use some advice on my approach.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A little background:&lt;/strong&gt; We offer coaching courses that will be split amongst various systems, but all purchased through deals with customers (companies), which are converted to credits and consumed through an atomic product model. We are in the process of transitioning to a credit system, so we will need to convert our existing deals into credits for the future system (deferred credits).&lt;/p&gt;\n\n&lt;p&gt;Essentially I need to tie in various data sources to build a table to track at a deal level the amount of credits that have been assigned, unassigned and consumed. One of the challenges is that credit values can vary by deal and therefore need to be tracked at a deal level. Also, they need to burn down to 0 by oldest deal, first in first out. This might add a bit of annoyance dealing with remainders.&lt;/p&gt;\n\n&lt;p&gt;Heres an example of roughly what im envisioning:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company ID&lt;/th&gt;\n&lt;th align=\"left\"&gt;deal id&lt;/th&gt;\n&lt;th align=\"left\"&gt;trans dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;scheduled dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;completed dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;credit category&lt;/th&gt;\n&lt;th align=\"left\"&gt;$ per credit&lt;/th&gt;\n&lt;th align=\"left\"&gt;# of Credits&lt;/th&gt;\n&lt;th align=\"left\"&gt;product&lt;/th&gt;\n&lt;th align=\"left\"&gt;Product Cost&lt;/th&gt;\n&lt;th align=\"left\"&gt;Credits Remaining&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;unassigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;300&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;3/01/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;assigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;400&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/15/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;consumed&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.50&lt;/td&gt;\n&lt;td align=\"left\"&gt;1500&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;400&lt;/td&gt;\n&lt;td align=\"left\"&gt;1100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/15/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;unassigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.50&lt;/td&gt;\n&lt;td align=\"left\"&gt;1500&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;300&lt;/td&gt;\n&lt;td align=\"left\"&gt;1100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;999&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/1/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;deferred&lt;/td&gt;\n&lt;td align=\"left\"&gt;23&lt;/td&gt;\n&lt;td align=\"left\"&gt;3000&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Its unclear to me what the best approach is for working through the many transformations involved here. I could build out a bunch of additional fields and apply calculations to the table at various stages of my pipeline with SQL, but im wondering if theres a more elegant solution through breaking it out into various tables and processes, using python or recursive functions etc.&lt;/p&gt;\n\n&lt;p&gt;One last caveat is that ideally this system will be able to track rate of spend of customers, which Id imagine would most simply be tracked through snapshot tables.&lt;/p&gt;\n\n&lt;p&gt;Sorry this was a lot, but any help is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ip1ya", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ip1ya/financial_reporting_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ip1ya/financial_reporting_problem/", "subreddit_subscribers": 146008, "created_utc": 1702605806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Experts,\n\nI'm currently exploring optimal solutions for our project, aiming to identify the most suitable framework or service for our data processing. We operate real-time dashboards that showcase alarms every two minutes, and our goal is to achieve reporting intervals closer to 10 seconds or less for new alarms.\n\nGiven the cost considerations highlighted by our product manager, we're seeking a solution that is efficient without being overly expensive. Our typical data size is approximately 50k records per job. I'd appreciate your recommendations and insights. If you're involved in a similar project, what framework or service are you utilizing? \n \nBTW- this is timeseries data\n\nThank you!", "author_fullname": "t2_6d76dzgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I use for real time job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ic0pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702570231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Experts,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring optimal solutions for our project, aiming to identify the most suitable framework or service for our data processing. We operate real-time dashboards that showcase alarms every two minutes, and our goal is to achieve reporting intervals closer to 10 seconds or less for new alarms.&lt;/p&gt;\n\n&lt;p&gt;Given the cost considerations highlighted by our product manager, we&amp;#39;re seeking a solution that is efficient without being overly expensive. Our typical data size is approximately 50k records per job. I&amp;#39;d appreciate your recommendations and insights. If you&amp;#39;re involved in a similar project, what framework or service are you utilizing? &lt;/p&gt;\n\n&lt;p&gt;BTW- this is timeseries data&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ic0pw", "is_robot_indexable": true, "report_reasons": null, "author": "Friendly-Radio-6312", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ic0pw/what_should_i_use_for_real_time_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ic0pw/what_should_i_use_for_real_time_job/", "subreddit_subscribers": 146008, "created_utc": 1702570231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019ve been trying to solve for this problem for a couple of years now. Trying to make a generic platform/product for data quality that would work for multiple data personas within the company. We knew this was going to be a hard one to solve.. and we\u2019re yet to hit that breakthrough. Curious to know what other data folks are doing and how they are solving for data quality.", "author_fullname": "t2_h5ll08of", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18iqbbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702609777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019ve been trying to solve for this problem for a couple of years now. Trying to make a generic platform/product for data quality that would work for multiple data personas within the company. We knew this was going to be a hard one to solve.. and we\u2019re yet to hit that breakthrough. Curious to know what other data folks are doing and how they are solving for data quality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18iqbbp", "is_robot_indexable": true, "report_reasons": null, "author": "Lucky-Front7675", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18iqbbp/data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18iqbbp/data_quality/", "subreddit_subscribers": 146008, "created_utc": 1702609777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, looking for some advice on my situation. \n\nI have been at my company for 1.5 yrs, having joined in a rotational program where there were 2 rotations, 6 months long each and this is my 3rd team now, doing data engineering(?) work for the first time. In one of my roles during the rotational program, I did primarily data analyst stuff but it was a bs role because I had only 1 project my entire time on the team and that was to create a basic tableau and power bi dashboard. That\u2019s literally it. \n\nI am not entirely sure if I am even a data engineer proper on this team now, because I am mostly doing analyst work and basic level sql queries. I haven\u2019t touched Python or done any ETL work. \n\nRecently, I was having a check in with my manager and he was expressing discontent about how I\u2019m not able to do my work independently yet and haven\u2019t been staying up to date with all updates coming through via email and teams chats. I completely get where he is coming from and I too am frustrated that I can\u2019t really work independently and he gave me some tips but they weren\u2019t really helpful, just the same old \u201clook at the documentation\u201d but the documentation isn\u2019t that much clearer either.\n\nHowever, on the other side, I feel like there wasn\u2019t really any chance to learn when I joined this team and was kind of thrown into this work without any relevant experience and structured trainings. His excuse for this is \u201ceveryone is learning\u201d and that this is new territory for everyone, but if that is the case, I feel like me not being at the same level as my colleagues in working independently should be okay because I\u2019ve never done this type of work before and it isn\u2019t like I\u2019m not trying, because I really am. \n\nIn addition, it can be hard to keep track of all the messages, emails, etc because there is so much back and forth and I get pulled into long meetings, leaving little time for me to do my work. I am still learning how to task switch especially because my previous teams were never this crazy busy. He also said in my check in that things will only get more busy from here onward into the new year. I am really feeling down on myself because I thought I was doing well despite the circumstances, but this was a ding on my confidence in myself. \n\nI am not sure if I can stay on this team long term if this is how things will be with the project ramping up in 2024. \n\nHas anyone else had this experience? Any advice? Should I just find a new role? I don\u2019t want to quit because things are getting hard but I also feel like this isn\u2019t an environment for learning and the longer I stay on this team doing lower level analyst work, the more I am putting myself behind in the data field and doing actual relevant work.", "author_fullname": "t2_tna1k085", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like I still don\u2019t know what I\u2019m doing 6 months into my role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ioz9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702605589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, looking for some advice on my situation. &lt;/p&gt;\n\n&lt;p&gt;I have been at my company for 1.5 yrs, having joined in a rotational program where there were 2 rotations, 6 months long each and this is my 3rd team now, doing data engineering(?) work for the first time. In one of my roles during the rotational program, I did primarily data analyst stuff but it was a bs role because I had only 1 project my entire time on the team and that was to create a basic tableau and power bi dashboard. That\u2019s literally it. &lt;/p&gt;\n\n&lt;p&gt;I am not entirely sure if I am even a data engineer proper on this team now, because I am mostly doing analyst work and basic level sql queries. I haven\u2019t touched Python or done any ETL work. &lt;/p&gt;\n\n&lt;p&gt;Recently, I was having a check in with my manager and he was expressing discontent about how I\u2019m not able to do my work independently yet and haven\u2019t been staying up to date with all updates coming through via email and teams chats. I completely get where he is coming from and I too am frustrated that I can\u2019t really work independently and he gave me some tips but they weren\u2019t really helpful, just the same old \u201clook at the documentation\u201d but the documentation isn\u2019t that much clearer either.&lt;/p&gt;\n\n&lt;p&gt;However, on the other side, I feel like there wasn\u2019t really any chance to learn when I joined this team and was kind of thrown into this work without any relevant experience and structured trainings. His excuse for this is \u201ceveryone is learning\u201d and that this is new territory for everyone, but if that is the case, I feel like me not being at the same level as my colleagues in working independently should be okay because I\u2019ve never done this type of work before and it isn\u2019t like I\u2019m not trying, because I really am. &lt;/p&gt;\n\n&lt;p&gt;In addition, it can be hard to keep track of all the messages, emails, etc because there is so much back and forth and I get pulled into long meetings, leaving little time for me to do my work. I am still learning how to task switch especially because my previous teams were never this crazy busy. He also said in my check in that things will only get more busy from here onward into the new year. I am really feeling down on myself because I thought I was doing well despite the circumstances, but this was a ding on my confidence in myself. &lt;/p&gt;\n\n&lt;p&gt;I am not sure if I can stay on this team long term if this is how things will be with the project ramping up in 2024. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else had this experience? Any advice? Should I just find a new role? I don\u2019t want to quit because things are getting hard but I also feel like this isn\u2019t an environment for learning and the longer I stay on this team doing lower level analyst work, the more I am putting myself behind in the data field and doing actual relevant work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ioz9p", "is_robot_indexable": true, "report_reasons": null, "author": "miserablywinning", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ioz9p/feel_like_i_still_dont_know_what_im_doing_6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ioz9p/feel_like_i_still_dont_know_what_im_doing_6/", "subreddit_subscribers": 146008, "created_utc": 1702605589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a1tanc569", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ask HN: Is there an open source database like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ilc2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702594940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atwong.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atwong.medium.com/ask-hn-is-there-an-open-source-database-like-this-39ba6ceaec1e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ilc2m", "is_robot_indexable": true, "report_reasons": null, "author": "albertstarrocks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ilc2m/ask_hn_is_there_an_open_source_database_like_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atwong.medium.com/ask-hn-is-there-an-open-source-database-like-this-39ba6ceaec1e", "subreddit_subscribers": 146008, "created_utc": 1702594940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was hoping to get some advice on the current methdology used for data warehousing in the public sector company I work for. I mention it's public sector to emphasise that both the people there and processes are quite old school. \n\nSo, currently the data warehouse is an on-premise SQL Server solution. The enterprise application we use, among a few other things, gets warehoused nightly via PowerShell scripts that dynamically generate stored procedures from the databases and tables identified from the various SQL servers from the applications and such. These stored procedures then run on a nightly basis via an SSIS package that loops through these and creates batches of tables to warehouse for each CPU thread.\n\nThe person who developed this workflow 10 years or so ago, which hasn't changed since, has now left. The data warehouse is primarily used for reporting in SSRS &amp; Power BI and archiving of data for auditing purposes. Myself and IT are wanting to potentially update our data warehouse methodology to hopefully improve and simplify it. My questions are: is the current workflow an effective data warehousing solution? Would using a cloud platform such as Azure SQL simplify things for reasons such as not needing to worry about scalability? What solutions can be recommended to transform and improve this workflow to warehouse our systems that mainly use on-premise SQL servers? I should also mention the company is very Microsoft orientated. Many thanks in advance for assistance!", "author_fullname": "t2_ppxsc3cy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehousing for public sectory company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i76gi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702555414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was hoping to get some advice on the current methdology used for data warehousing in the public sector company I work for. I mention it&amp;#39;s public sector to emphasise that both the people there and processes are quite old school. &lt;/p&gt;\n\n&lt;p&gt;So, currently the data warehouse is an on-premise SQL Server solution. The enterprise application we use, among a few other things, gets warehoused nightly via PowerShell scripts that dynamically generate stored procedures from the databases and tables identified from the various SQL servers from the applications and such. These stored procedures then run on a nightly basis via an SSIS package that loops through these and creates batches of tables to warehouse for each CPU thread.&lt;/p&gt;\n\n&lt;p&gt;The person who developed this workflow 10 years or so ago, which hasn&amp;#39;t changed since, has now left. The data warehouse is primarily used for reporting in SSRS &amp;amp; Power BI and archiving of data for auditing purposes. Myself and IT are wanting to potentially update our data warehouse methodology to hopefully improve and simplify it. My questions are: is the current workflow an effective data warehousing solution? Would using a cloud platform such as Azure SQL simplify things for reasons such as not needing to worry about scalability? What solutions can be recommended to transform and improve this workflow to warehouse our systems that mainly use on-premise SQL servers? I should also mention the company is very Microsoft orientated. Many thanks in advance for assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18i76gi", "is_robot_indexable": true, "report_reasons": null, "author": "strictlydatabusiness", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i76gi/data_warehousing_for_public_sectory_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i76gi/data_warehousing_for_public_sectory_company/", "subreddit_subscribers": 146008, "created_utc": 1702555414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \n\nI am currently working for a rather small consultancy company (5 FTEs + some working students). \n\nI am seeking some guidance/ feedback on some questions that are going through my mind and our current setup as a company. First, here's some information that should give you an overview about the situation.\n\n**Company background**\n\n* We're a consultancy that has developed a platform for our clients\n* Within this platform various tableau dashboard can be viewed, which we're embedding there.\n* Anything data engineering related we're doing involves some sort of ETL process and displaying the extracted data in a dashboard to our clients.\n\n**Team-Setup**\n\n* There are mostly non-IT people working here\n* There is one DevOps Guy that is mainly in charge for setting up infrastructure or, together with myself, fixing things if things go nuts. He's not working full time and is rather working on demand.\n* I am the only data engineer working here full time. When I started working here I mainly focused on building dashboards but as things are growing, I am focusing more on data engineering topics.\n* There is one other working student that has a data-background. He's mostly building dashboards or implementing some smaller ETL pipelines.\n* My Boss is thankfully supporting the topics I am working on, in case that matters for your feedback.\n\n**Tech-Stack**\n\n* On-Prem Postgres Cluster running on K8s as transactional database for our platform.\n* On-Prem Tableau Server for dashboards\n* Tableau Prep (UI-based ETL Tool)/Python for ETL processes\n* Prefect for Orchestration\n* Gitlab CI/CD\n\n**Current Challenges:**\n\n* Database / Data Warehouse: Currently everything is stored in the Postgres Database. So all the transactional data goes into the postgres (which is fine) but also the dashboard related data, which I know should not be stored there. As the number of projects we're doing, so is the database and everything starts to get more and more messy. I feel like I can still oversee everything but on the other hand this also feels like a ticking time bomb. Ideally I am thinking about setting up a data warehouse which we'll then use for all analytic related topics such as our dashboards. At the same time I feel like this is such a huge task that I am also underestimating. \n* We're not following any \"fixed\" guideline when it comes to how we're modeling/storing our dashboard related data in the postgres. I am currently making myself familiar with dimensional modeling (kimball) as I feel like we need a way to approach this, sometimes messy, situation on how we're storing our data.\n* Another thing on my list is DBT. We're currently using materialized views for some of our dashboards, mainly to shift aggregation away from tableau into the database. While this works fine, I feel like using DBT could improve our data quality and eg improve re usability among other things.\n\n**My questions to you:** \n\n* Has someone worked in a similar situation? How did you decide on \"what to do next\"? Quitting is not an option as I my pay is quite good for the YOE I have currently.\n* What topic would you start with? Is there any specific \"order\" that makes most sense and why?\n* Any other thoughts/feedback are of course appreciated.\n\n  \nTLDR; We're a small company and I am not sure what topic to tackle first to improve our data architecture.   \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_u88hoerb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance/ Feedback on data architecture and next steps planned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i5ovj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702549525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I am currently working for a rather small consultancy company (5 FTEs + some working students). &lt;/p&gt;\n\n&lt;p&gt;I am seeking some guidance/ feedback on some questions that are going through my mind and our current setup as a company. First, here&amp;#39;s some information that should give you an overview about the situation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Company background&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We&amp;#39;re a consultancy that has developed a platform for our clients&lt;/li&gt;\n&lt;li&gt;Within this platform various tableau dashboard can be viewed, which we&amp;#39;re embedding there.&lt;/li&gt;\n&lt;li&gt;Anything data engineering related we&amp;#39;re doing involves some sort of ETL process and displaying the extracted data in a dashboard to our clients.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Team-Setup&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There are mostly non-IT people working here&lt;/li&gt;\n&lt;li&gt;There is one DevOps Guy that is mainly in charge for setting up infrastructure or, together with myself, fixing things if things go nuts. He&amp;#39;s not working full time and is rather working on demand.&lt;/li&gt;\n&lt;li&gt;I am the only data engineer working here full time. When I started working here I mainly focused on building dashboards but as things are growing, I am focusing more on data engineering topics.&lt;/li&gt;\n&lt;li&gt;There is one other working student that has a data-background. He&amp;#39;s mostly building dashboards or implementing some smaller ETL pipelines.&lt;/li&gt;\n&lt;li&gt;My Boss is thankfully supporting the topics I am working on, in case that matters for your feedback.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tech-Stack&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;On-Prem Postgres Cluster running on K8s as transactional database for our platform.&lt;/li&gt;\n&lt;li&gt;On-Prem Tableau Server for dashboards&lt;/li&gt;\n&lt;li&gt;Tableau Prep (UI-based ETL Tool)/Python for ETL processes&lt;/li&gt;\n&lt;li&gt;Prefect for Orchestration&lt;/li&gt;\n&lt;li&gt;Gitlab CI/CD&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Challenges:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Database / Data Warehouse: Currently everything is stored in the Postgres Database. So all the transactional data goes into the postgres (which is fine) but also the dashboard related data, which I know should not be stored there. As the number of projects we&amp;#39;re doing, so is the database and everything starts to get more and more messy. I feel like I can still oversee everything but on the other hand this also feels like a ticking time bomb. Ideally I am thinking about setting up a data warehouse which we&amp;#39;ll then use for all analytic related topics such as our dashboards. At the same time I feel like this is such a huge task that I am also underestimating. &lt;/li&gt;\n&lt;li&gt;We&amp;#39;re not following any &amp;quot;fixed&amp;quot; guideline when it comes to how we&amp;#39;re modeling/storing our dashboard related data in the postgres. I am currently making myself familiar with dimensional modeling (kimball) as I feel like we need a way to approach this, sometimes messy, situation on how we&amp;#39;re storing our data.&lt;/li&gt;\n&lt;li&gt;Another thing on my list is DBT. We&amp;#39;re currently using materialized views for some of our dashboards, mainly to shift aggregation away from tableau into the database. While this works fine, I feel like using DBT could improve our data quality and eg improve re usability among other things.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;My questions to you:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Has someone worked in a similar situation? How did you decide on &amp;quot;what to do next&amp;quot;? Quitting is not an option as I my pay is quite good for the YOE I have currently.&lt;/li&gt;\n&lt;li&gt;What topic would you start with? Is there any specific &amp;quot;order&amp;quot; that makes most sense and why?&lt;/li&gt;\n&lt;li&gt;Any other thoughts/feedback are of course appreciated.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;TLDR; We&amp;#39;re a small company and I am not sure what topic to tackle first to improve our data architecture.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18i5ovj", "is_robot_indexable": true, "report_reasons": null, "author": "heggbert", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i5ovj/guidance_feedback_on_data_architecture_and_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i5ovj/guidance_feedback_on_data_architecture_and_next/", "subreddit_subscribers": 146008, "created_utc": 1702549525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.bytebase.com/changelog/bytebase-2-12-0/](https://www.bytebase.com/changelog/bytebase-2-12-0/)", "author_fullname": "t2_gxesw7ji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bytebase v2.12.0 released, Database DevOps &amp; CI/CD tool for engineering teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i5hdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702548661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.bytebase.com/changelog/bytebase-2-12-0/\"&gt;https://www.bytebase.com/changelog/bytebase-2-12-0/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?auto=webp&amp;s=5485407d9406aef94dbc618fc9bd92277d79553c", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c9538a4c1085c8724b674264582b7ee71129e2b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fa17aeed2d215a80b66b54b5df5e640d95141375", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0127f128a25d80af9f1433bdab92cae115c3c8c1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa7d61d00774d86ca0256598f6b54ccad18e04e1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0abdac1d7890e4a0f3902a6cb512c29d80241378", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/eRDIsmJXd2QMgaOjPsdH8_fTY86ICVixMhhsYkJftr8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9bbc8c5b2db4e4f1b58c0654325ef6f40993c3c7", "width": 1080, "height": 607}], "variants": {}, "id": "p7SDgKrdHb2CMLnOC8NrxjbTLNsmuMWWU9jl0_vAhaI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18i5hdu", "is_robot_indexable": true, "report_reasons": null, "author": "Adela_freedom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i5hdu/bytebase_v2120_released_database_devops_cicd_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i5hdu/bytebase_v2120_released_database_devops_cicd_tool/", "subreddit_subscribers": 146008, "created_utc": 1702548661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI wanted to read data from a dedicated sql pool table into a spark dataframe in synapse notebook. I am able to run this query directly in the query editor though.\n\nWhat permissions am I missing, I have contributor access to the synapse workspace, have control and connect permissions as well.\n\nPlease let me know,\nThanks!!", "author_fullname": "t2_9d4i4lxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unable to query data from dedicated sql pool using synapse notebook but able to query the same from query editor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i4cs2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702543686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I wanted to read data from a dedicated sql pool table into a spark dataframe in synapse notebook. I am able to run this query directly in the query editor though.&lt;/p&gt;\n\n&lt;p&gt;What permissions am I missing, I have contributor access to the synapse workspace, have control and connect permissions as well.&lt;/p&gt;\n\n&lt;p&gt;Please let me know,\nThanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18i4cs2", "is_robot_indexable": true, "report_reasons": null, "author": "New_Introduction_154", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i4cs2/unable_to_query_data_from_dedicated_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i4cs2/unable_to_query_data_from_dedicated_sql_pool/", "subreddit_subscribers": 146008, "created_utc": 1702543686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nCurrently employed in tech support, specializing in T-SQL, I've been contemplating a shift towards data engineering. I have a keen interest in working with data on a daily basis, and my previous experience includes a Java course and Selenium training, though my attempts at transitioning to QA automation were met with limited success.\n\nNow, I'm exploring opportunities in data engineering, as my primary goal is to code regularly in my job. I work extensively with T-SQL, handling various technical aspects, including XML files, and have exposure to JavaScript/jQuery and API endpoints.\n\nI'm curious to know if gaining 1 to 1.5 years of experience in my current role could enhance my prospects for a data engineering position. Any advice or insights on leveraging my skills for a successful transition into data engineering would be highly appreciated.\n\nThank you!", "author_fullname": "t2_hljgw2wbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "T-SQL Tech Support to Aspiring Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ifvuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702580453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Currently employed in tech support, specializing in T-SQL, I&amp;#39;ve been contemplating a shift towards data engineering. I have a keen interest in working with data on a daily basis, and my previous experience includes a Java course and Selenium training, though my attempts at transitioning to QA automation were met with limited success.&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m exploring opportunities in data engineering, as my primary goal is to code regularly in my job. I work extensively with T-SQL, handling various technical aspects, including XML files, and have exposure to JavaScript/jQuery and API endpoints.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to know if gaining 1 to 1.5 years of experience in my current role could enhance my prospects for a data engineering position. Any advice or insights on leveraging my skills for a successful transition into data engineering would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ifvuc", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Luck_763", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ifvuc/tsql_tech_support_to_aspiring_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ifvuc/tsql_tech_support_to_aspiring_data_engineer/", "subreddit_subscribers": 146008, "created_utc": 1702580453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit,\n\nQuick question, what is your average cloud bill for data traffic around your streaming use cases + which data format are you using?", "author_fullname": "t2_hhdac8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much do you pay for data traffic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i1zoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702533799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit,&lt;/p&gt;\n\n&lt;p&gt;Quick question, what is your average cloud bill for data traffic around your streaming use cases + which data format are you using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18i1zoe", "is_robot_indexable": true, "report_reasons": null, "author": "yanivbh1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i1zoe/how_much_do_you_pay_for_data_traffic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i1zoe/how_much_do_you_pay_for_data_traffic/", "subreddit_subscribers": 146008, "created_utc": 1702533799.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}