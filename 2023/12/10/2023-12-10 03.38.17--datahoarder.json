{"kind": "Listing", "data": {"after": "t3_18elqf2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It is a wd10tmw it has 12 pins on it. Can I connect it to anything to run it?", "author_fullname": "t2_6915x6u2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "How can I save it? Micro usb runs it but its disk only spins for 20 seconds and pc doesn\u2019t recognize it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"40qqg71e1b5c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d01b8e767fd8b8bd94400da2461e6f07cd9ff17b"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d13fa8ad9f283d0ee46cf0186df44d7b28ab73af"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b22fd78f7b3e12e2819ccf03da0216096b00cad6"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25a0830d2fd79b387844eb22bf0f69fed59587b5"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=19f5687ee1bd48ef156308db0c01e1836a7835a4"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06410a4d33c6d40d10ba0db0ccb2f7f78797e3db"}], "s": {"y": 4032, "x": 2268, "u": "https://preview.redd.it/40qqg71e1b5c1.jpg?width=2268&amp;format=pjpg&amp;auto=webp&amp;s=9e99b05e48e0dce890dfbae6cf1fe51f1ca4f4e9"}, "id": "40qqg71e1b5c1"}, "rafyp71e1b5c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=55d812605e23a06c610fcd20650984c6cd59b2cf"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d02d1f1f4743ec5f8bcd780efbbbd60c07799bbf"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40cd6087ab8c8439b9be76093def0e1b2197c600"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ce1c54c8f3f9b5d1cc52f231e11d9d10d0dc421"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cc15d96f5850341e505f34ad72d2896b172bf6ce"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=21a705bcb98232dc675907d3ad48d4d66f117605"}], "s": {"y": 8064, "x": 4536, "u": "https://preview.redd.it/rafyp71e1b5c1.jpg?width=4536&amp;format=pjpg&amp;auto=webp&amp;s=c21bc92b33ef5bb9683e719ce0b556bc621b5de5"}, "id": "rafyp71e1b5c1"}, "q2uck71e1b5c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6d79be608767e3b55f2a90aafdc7f88d09b5454"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06107dc68255e6c82ea4279eb36e5e59f40dcc1a"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb64c2ee88c435e5ba5d47296f0791b2abc29c91"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe83b94c901a1d3171f267d523692b2173724bf9"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c518c1917f17f0fe6d0f9f5ade786912405d925b"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c852bea0d34f6287201e94993142ef22d62208f7"}], "s": {"y": 4032, "x": 2268, "u": "https://preview.redd.it/q2uck71e1b5c1.jpg?width=2268&amp;format=pjpg&amp;auto=webp&amp;s=23d59ee7e5e7f13af6a902a9db03e5a6344763bc"}, "id": "q2uck71e1b5c1"}, "7rsfw61e1b5c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a51f833822599ed74865371c6bc8111e74289eb"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=835abd6196a808c263c103f7178f30477ee57407"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=370c278881b4c8ea638bbcc82a9519dcfb94bdd2"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a58ea29ddb74ffeea3155238f4e2a91a8ad8096a"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e954ed94dec28f0778e9d33631679ab325fa552"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fae59210993aa31176c5da2549f88478a57890e2"}], "s": {"y": 8064, "x": 4536, "u": "https://preview.redd.it/7rsfw61e1b5c1.jpg?width=4536&amp;format=pjpg&amp;auto=webp&amp;s=79598ddc1fc52486cd2ecc4ff1facdfaebcd92b5"}, "id": "7rsfw61e1b5c1"}}, "name": "t3_18eijcn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 61, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "40qqg71e1b5c1", "id": 371633095}, {"media_id": "7rsfw61e1b5c1", "id": 371633096}, {"media_id": "rafyp71e1b5c1", "id": 371633097}, {"media_id": "q2uck71e1b5c1", "id": 371633098}]}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/U6c9FT8_J0Dc2M9Aqudws4MgYkRPQbi4Cuwny46dZSg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702143136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is a wd10tmw it has 12 pins on it. Can I connect it to anything to run it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18eijcn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eijcn", "is_robot_indexable": true, "report_reasons": null, "author": "-lethifold-", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eijcn/how_can_i_save_it_micro_usb_runs_it_but_its_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18eijcn", "subreddit_subscribers": 717623, "created_utc": 1702143136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How does this work? Ie how can an HDD that was released about 6 months ago according to press releases already be readily available refurbs ? Also highest capacity drives today at 22TB so makes little sense that they would be replaced with something bigger. Anyone got more info on this? Currently running smart tests on the drives I got and started reading about refurbs but little info available.", "author_fullname": "t2_4qu7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the story of refurbs? Just got a couple of 22TB Ironwolves and release date for the product is just a few months ago..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ec9ll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702124177.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702123630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does this work? Ie how can an HDD that was released about 6 months ago according to press releases already be readily available refurbs ? Also highest capacity drives today at 22TB so makes little sense that they would be replaced with something bigger. Anyone got more info on this? Currently running smart tests on the drives I got and started reading about refurbs but little info available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ec9ll", "is_robot_indexable": true, "report_reasons": null, "author": "daveonreddit", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ec9ll/what_is_the_story_of_refurbs_just_got_a_couple_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ec9ll/what_is_the_story_of_refurbs_just_got_a_couple_of/", "subreddit_subscribers": 717623, "created_utc": 1702123630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hear me out. I know HDDs are cheaper TB per $.\n\nBUT. HDDs also fail a lot faster. And an SSD's lifespan for bulk storage would be longer than usual because you are not doing sustained writes over time. I find myself buying a new HDD (3x6TB + 1x16TB) every 2 years these days, on average.\n\nSo why is the adage in buildapc always saying HDDs for storage? The prices online for SSD storage is really getting quite good these days, too. 2 TB NVME drives I think can be found for what, $130?\n\nAt this point, I'd consider a NAS that houses only m.2 slots, instead of 3.5\".\n\nThoughts?", "author_fullname": "t2_4uv8kp1km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are HDDs REALLY better than SSDs for long term bulk storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18e40fh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702091205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hear me out. I know HDDs are cheaper TB per $.&lt;/p&gt;\n\n&lt;p&gt;BUT. HDDs also fail a lot faster. And an SSD&amp;#39;s lifespan for bulk storage would be longer than usual because you are not doing sustained writes over time. I find myself buying a new HDD (3x6TB + 1x16TB) every 2 years these days, on average.&lt;/p&gt;\n\n&lt;p&gt;So why is the adage in buildapc always saying HDDs for storage? The prices online for SSD storage is really getting quite good these days, too. 2 TB NVME drives I think can be found for what, $130?&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;d consider a NAS that houses only m.2 slots, instead of 3.5&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e40fh", "is_robot_indexable": true, "report_reasons": null, "author": "raging_pastafarian", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18e40fh/are_hdds_really_better_than_ssds_for_long_term/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e40fh/are_hdds_really_better_than_ssds_for_long_term/", "subreddit_subscribers": 717623, "created_utc": 1702091205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I check serverpartdeals but the shipping is to much for me :/ ", "author_fullname": "t2_k0h4m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you buy Disks in Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18e9cw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702111744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I check serverpartdeals but the shipping is to much for me :/ &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e9cw1", "is_robot_indexable": true, "report_reasons": null, "author": "surpyc", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18e9cw1/where_do_you_buy_disks_in_europe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e9cw1/where_do_you_buy_disks_in_europe/", "subreddit_subscribers": 717623, "created_utc": 1702111744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys. I've been collecting war footage since 2014. And perhaps a year a go  I have run out of memory, on my pc where   combat videos were kept.  than i bought 2 external hdds 2 and 1 tb each. But their longevity isn't so reliable. And finally i've posted most of them on [archive.org](https://archive.org). But today i found out that 1 item from the collection has been removed. So, it makes me worried, cause it something happens with those external drives, i won't be able to recover even 3 percent of my collection. Maybe could you recommend any reliable external or internal drives? + I've found out that yesterday not just my account has been slightly cleared. But someone's Else.  P.S. I thought, maybe my collection is too large for admins of archive to keep, so maybe i can manage it somehow and remove it. Since their memory storage isn't limitless too.   Cause the items were chosen randomly. Any way, i deeply appreciate archive's hospitality and their endless help.", "author_fullname": "t2_p0f47tbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ideas on where can i store 55000 combat footages?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eh26i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702139264.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702138999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I&amp;#39;ve been collecting war footage since 2014. And perhaps a year a go  I have run out of memory, on my pc where   combat videos were kept.  than i bought 2 external hdds 2 and 1 tb each. But their longevity isn&amp;#39;t so reliable. And finally i&amp;#39;ve posted most of them on &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;. But today i found out that 1 item from the collection has been removed. So, it makes me worried, cause it something happens with those external drives, i won&amp;#39;t be able to recover even 3 percent of my collection. Maybe could you recommend any reliable external or internal drives? + I&amp;#39;ve found out that yesterday not just my account has been slightly cleared. But someone&amp;#39;s Else.  P.S. I thought, maybe my collection is too large for admins of archive to keep, so maybe i can manage it somehow and remove it. Since their memory storage isn&amp;#39;t limitless too.   Cause the items were chosen randomly. Any way, i deeply appreciate archive&amp;#39;s hospitality and their endless help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eh26i", "is_robot_indexable": true, "report_reasons": null, "author": "Ablackshado", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eh26i/any_ideas_on_where_can_i_store_55000_combat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eh26i/any_ideas_on_where_can_i_store_55000_combat/", "subreddit_subscribers": 717623, "created_utc": 1702138999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "To whoever shucked a WD Black drive and sent the enclosure and packing back to Walmart, I hope you get your well deserved karma and you lose all your data after the drive fails spontaneously combusting in your rig.\n\nNow I get the joys of dealing with Walmart return lines in during Christmas and hoping they don't give me trouble for returning an obviously shucked drive.\n\nHappy Holidays everyone...", "author_fullname": "t2_kxop2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sealed WD-Black 8TB from Walmart, not so fast!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eneqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702157483.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702156886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To whoever shucked a WD Black drive and sent the enclosure and packing back to Walmart, I hope you get your well deserved karma and you lose all your data after the drive fails spontaneously combusting in your rig.&lt;/p&gt;\n\n&lt;p&gt;Now I get the joys of dealing with Walmart return lines in during Christmas and hoping they don&amp;#39;t give me trouble for returning an obviously shucked drive.&lt;/p&gt;\n\n&lt;p&gt;Happy Holidays everyone...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18eneqe", "is_robot_indexable": true, "report_reasons": null, "author": "adbeil", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eneqe/sealed_wdblack_8tb_from_walmart_not_so_fast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eneqe/sealed_wdblack_8tb_from_walmart_not_so_fast/", "subreddit_subscribers": 717623, "created_utc": 1702156886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there. I have about 60 TB of data w/o backup that I'm okay to lose and already 1.5 TB that I absolutely don't want to. I used 2x 2 TB external 2.5 drives: one stored cold in house, one always with me. Due to geopolitics or just 2.5 getting less popular due to SSDs in laptops, I could only find 5 TB 2.5 max, which design is 12 years old and 1.5 cm thick. \nHowever, there are no issues with 3.5 drives. I already used Seagate Exos for many-many years and bought another one 10 TB for backups. Yes, only one drive, as they are still stupid expensive here due to politics etc. I still want an extra copy, so I'll store one in my desktop (which has 16 TB of cold storage, too) instead of fully detached drive. At least I'm okay with that.\nI also bought 3.5 external case which comes with separate power supply and Type-B/Type-A cable.\n\nThe questions:\n1. As I plan to carry it with me in a backpack, how careful should I be when it's not in operation? I remember not giving a shit about 2.5 - I could just throw my backpack on the floor and be fine. \n2. Are they as resistant to cold when stored? Cause it gets pretty cold here (down to -30 C). Will they also survive that? Cause 2.5 did.\n3. Maybe there are better ways than external enclosures? I know DAS systems, but surely I won't carry one with me. I'm planning on syncing to that cold backup every quarter (3 mo), so no real issue with enclosure. But are there any better (more portable or reliable) solutions for using 3.5 on the go?\n4. Any other things I should know before it arrives?\n\nThank you very much!", "author_fullname": "t2_dleysue2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone experienced with 3.5\" to-go backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ebsq5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": "", "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702122243.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702121799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. I have about 60 TB of data w/o backup that I&amp;#39;m okay to lose and already 1.5 TB that I absolutely don&amp;#39;t want to. I used 2x 2 TB external 2.5 drives: one stored cold in house, one always with me. Due to geopolitics or just 2.5 getting less popular due to SSDs in laptops, I could only find 5 TB 2.5 max, which design is 12 years old and 1.5 cm thick. \nHowever, there are no issues with 3.5 drives. I already used Seagate Exos for many-many years and bought another one 10 TB for backups. Yes, only one drive, as they are still stupid expensive here due to politics etc. I still want an extra copy, so I&amp;#39;ll store one in my desktop (which has 16 TB of cold storage, too) instead of fully detached drive. At least I&amp;#39;m okay with that.\nI also bought 3.5 external case which comes with separate power supply and Type-B/Type-A cable.&lt;/p&gt;\n\n&lt;p&gt;The questions:\n1. As I plan to carry it with me in a backpack, how careful should I be when it&amp;#39;s not in operation? I remember not giving a shit about 2.5 - I could just throw my backpack on the floor and be fine. \n2. Are they as resistant to cold when stored? Cause it gets pretty cold here (down to -30 C). Will they also survive that? Cause 2.5 did.\n3. Maybe there are better ways than external enclosures? I know DAS systems, but surely I won&amp;#39;t carry one with me. I&amp;#39;m planning on syncing to that cold backup every quarter (3 mo), so no real issue with enclosure. But are there any better (more portable or reliable) solutions for using 3.5 on the go?\n4. Any other things I should know before it arrives?&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ebsq5", "is_robot_indexable": true, "report_reasons": null, "author": "cakee_ru", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18ebsq5/anyone_experienced_with_35_togo_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ebsq5/anyone_experienced_with_35_togo_backups/", "subreddit_subscribers": 717623, "created_utc": 1702121799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm worried that downloading and transferring so often from my SSD will make it die faster. It's also my boot drive and it stores my games. If an internal HDD is better, what should I be looking for? I want to temporarily store the videos and watch some of them before transferring to the external HDD. Maybe keep some permanently. I also want as little noise as possible.\n\nEdit: Sorry, I forgot to mention that my SSD might get more full than I'd like if I don't transfer regularly. Would downloading to an internal HDD to free up my SSD be good then? Or another internal SSD?\n\nThanks in advance!", "author_fullname": "t2_fgin1ofh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I plan to download 150GB of video a week to a SSD before transferring it to an external HDD. Would it be better to add an internal HDD to do this instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18e6k10", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702144622.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702100134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m worried that downloading and transferring so often from my SSD will make it die faster. It&amp;#39;s also my boot drive and it stores my games. If an internal HDD is better, what should I be looking for? I want to temporarily store the videos and watch some of them before transferring to the external HDD. Maybe keep some permanently. I also want as little noise as possible.&lt;/p&gt;\n\n&lt;p&gt;Edit: Sorry, I forgot to mention that my SSD might get more full than I&amp;#39;d like if I don&amp;#39;t transfer regularly. Would downloading to an internal HDD to free up my SSD be good then? Or another internal SSD?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e6k10", "is_robot_indexable": true, "report_reasons": null, "author": "MoldyWall030", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18e6k10/i_plan_to_download_150gb_of_video_a_week_to_a_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e6k10/i_plan_to_download_150gb_of_video_a_week_to_a_ssd/", "subreddit_subscribers": 717623, "created_utc": 1702100134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have read a bunch of posts talking about the 3-2-1 principle of backup.  It is pretty easy to do \"3-2\" part, while currently it seems that for \"1\" off-site backup most people simply use cloud storage.  I am wondering, unless you have an additional house/storage unit/someone you can trust not living with you/etc, are there really other options for \"off-site\" backup location?\n\n&amp;#x200B;", "author_fullname": "t2_lodqn3wz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is your \"off-site\" backup location?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18etat9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702174842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read a bunch of posts talking about the 3-2-1 principle of backup.  It is pretty easy to do &amp;quot;3-2&amp;quot; part, while currently it seems that for &amp;quot;1&amp;quot; off-site backup most people simply use cloud storage.  I am wondering, unless you have an additional house/storage unit/someone you can trust not living with you/etc, are there really other options for &amp;quot;off-site&amp;quot; backup location?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18etat9", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Pay-7516", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18etat9/what_is_your_offsite_backup_location/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18etat9/what_is_your_offsite_backup_location/", "subreddit_subscribers": 717623, "created_utc": 1702174842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI have two 4Tb hard drives (portable), one with my personal collection of files, photos, music and videos, the other movies and other linux ISOs.\n\nI kept a copy of the personal HDD in a spare 4tb drive, I used Free File Sync to mirror the main drive to the backup(copy). The spare drive is old now and starting to fail it made me realize that i have no way to check if data corruption is happening, so if my main drive fails, im toast. This led me to look for ways to prevent file corruption, the search led me computing the hases of files. Im purchasing a new 18tb drive to be used as an archive/Backup/Copy for my data. In the near future im gonna solve the remote location thats missing from my (not yet complete) 3-2-1 strategy.\n\nA) Is hashing really the solution for my needs?\n\nB) Is there a software with a GUI that creates hashes of a whole folder tree or do i need to create it one by one. (im on windows)\n\nC) If a file changes location because i moved it from folder A to folder B within the drive, will that impact the hash? Im assuming it wont and should only depend on the content of the file, so if it moved correctly the hash shouldnt change. \n\nD) If (C) is correct, do i need to do anything with the presumed output with all the hashes? Does i need to recalculate all the hashes again? Can maybe the software recalculate only for files that moved/changed?", "author_fullname": "t2_9qrgc2oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Integrity and checksums", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18edcw2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702127646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have two 4Tb hard drives (portable), one with my personal collection of files, photos, music and videos, the other movies and other linux ISOs.&lt;/p&gt;\n\n&lt;p&gt;I kept a copy of the personal HDD in a spare 4tb drive, I used Free File Sync to mirror the main drive to the backup(copy). The spare drive is old now and starting to fail it made me realize that i have no way to check if data corruption is happening, so if my main drive fails, im toast. This led me to look for ways to prevent file corruption, the search led me computing the hases of files. Im purchasing a new 18tb drive to be used as an archive/Backup/Copy for my data. In the near future im gonna solve the remote location thats missing from my (not yet complete) 3-2-1 strategy.&lt;/p&gt;\n\n&lt;p&gt;A) Is hashing really the solution for my needs?&lt;/p&gt;\n\n&lt;p&gt;B) Is there a software with a GUI that creates hashes of a whole folder tree or do i need to create it one by one. (im on windows)&lt;/p&gt;\n\n&lt;p&gt;C) If a file changes location because i moved it from folder A to folder B within the drive, will that impact the hash? Im assuming it wont and should only depend on the content of the file, so if it moved correctly the hash shouldnt change. &lt;/p&gt;\n\n&lt;p&gt;D) If (C) is correct, do i need to do anything with the presumed output with all the hashes? Does i need to recalculate all the hashes again? Can maybe the software recalculate only for files that moved/changed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18edcw2", "is_robot_indexable": true, "report_reasons": null, "author": "anasireto12", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18edcw2/file_integrity_and_checksums/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18edcw2/file_integrity_and_checksums/", "subreddit_subscribers": 717623, "created_utc": 1702127646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/082s59nli75c1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=ca07cb68e18f3bfd083c8988f6df305f5016fa2a\n\n  Running WHS2012 R2, the pool has nine 4TB drives, 3 in home server, 4 on a JBOD via eSata and 2 on separate USB docking stations.  At the moment I have 5TB available but I keep getting Duplication Inconsistent errors.  This started when I was running out of space and added a second external 4TB HDD to the pool so I thought it was a bad drive or a bad docking station but I checked both on another PC and the drive and docking station were working fine.\n\n&amp;#x200B;\n\nDoes anyone have any advice on how to fix this problem?", "author_fullname": "t2_egkhg7bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Drivepool, Keep getting Duplication inconsistent errors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"082s59nli75c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=392d73454c46c0510ebca3f9edceaa0fde350ee5"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eee27297ebaa0fd9c0b53faba4e839a010f1bdac"}, {"y": 173, "x": 320, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=09d33fac3b95a636149e1af88c775a73139c1c5d"}, {"y": 347, "x": 640, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6742c63b941202fac7029b34fdeff2f0c23d39e9"}, {"y": 520, "x": 960, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad08b65f1585530401d6ff98048af3edf13c9291"}, {"y": 585, "x": 1080, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=468bb2d775d8cc0e52616ad3e4b199fe2028f4fa"}], "s": {"y": 1041, "x": 1920, "u": "https://preview.redd.it/082s59nli75c1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=ca07cb68e18f3bfd083c8988f6df305f5016fa2a"}, "id": "082s59nli75c1"}}, "name": "t3_18e6rc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CvhWm2wu2ev3MLfbOtkxf7wF4IeTZZD9EWXkJGEVbTw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702100941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/082s59nli75c1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ca07cb68e18f3bfd083c8988f6df305f5016fa2a\"&gt;https://preview.redd.it/082s59nli75c1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ca07cb68e18f3bfd083c8988f6df305f5016fa2a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Running WHS2012 R2, the pool has nine 4TB drives, 3 in home server, 4 on a JBOD via eSata and 2 on separate USB docking stations.  At the moment I have 5TB available but I keep getting Duplication Inconsistent errors.  This started when I was running out of space and added a second external 4TB HDD to the pool so I thought it was a bad drive or a bad docking station but I checked both on another PC and the drive and docking station were working fine.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advice on how to fix this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e6rc9", "is_robot_indexable": true, "report_reasons": null, "author": "VladX0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18e6rc9/need_help_with_drivepool_keep_getting_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e6rc9/need_help_with_drivepool_keep_getting_duplication/", "subreddit_subscribers": 717623, "created_utc": 1702100941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I have a folder full of videos that have their audio separated in aac format. I was wondering if I can add all the videos and their audio almost into a queue to be automatically added instead of adding the audio to the video one by one, which of course is very time consuming. Is there a software or option to do that. Thanks in advance!", "author_fullname": "t2_12cmlj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Add Audio to multiple vidoes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18esy0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702173662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I have a folder full of videos that have their audio separated in aac format. I was wondering if I can add all the videos and their audio almost into a queue to be automatically added instead of adding the audio to the video one by one, which of course is very time consuming. Is there a software or option to do that. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18esy0e", "is_robot_indexable": true, "report_reasons": null, "author": "egyptianhunk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18esy0e/add_audio_to_multiple_vidoes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18esy0e/add_audio_to_multiple_vidoes/", "subreddit_subscribers": 717623, "created_utc": 1702173662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm dangerously close to becoming a datahoarder.  Currently I have a machine running Proxmox with Blue Iris, Home Assistant, Plex, and PiHole.  That machine is an I7 11700K with 64GB memory, 8X4TB HDD, a M.2 drive hosting the VMs and a couple of SSDs for boot.  New machine is a HP Z840 with 2X Xeon E5 2667 V3, 64GB memory 2x16TB Exos drives, a M.2 drive for VMs and a coupe of SSDs for boot.  I'm looking to split Plex and Blue Iris up, and replace the existing NAS (WD 2 bay).  The 2 machines will have to live in separate rooms due to space constraints.  Which machine would you run which program on if you had the choice?", "author_fullname": "t2_unox2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Goes Where-Proxmox and TrueNas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eqlvf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702166233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m dangerously close to becoming a datahoarder.  Currently I have a machine running Proxmox with Blue Iris, Home Assistant, Plex, and PiHole.  That machine is an I7 11700K with 64GB memory, 8X4TB HDD, a M.2 drive hosting the VMs and a couple of SSDs for boot.  New machine is a HP Z840 with 2X Xeon E5 2667 V3, 64GB memory 2x16TB Exos drives, a M.2 drive for VMs and a coupe of SSDs for boot.  I&amp;#39;m looking to split Plex and Blue Iris up, and replace the existing NAS (WD 2 bay).  The 2 machines will have to live in separate rooms due to space constraints.  Which machine would you run which program on if you had the choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eqlvf", "is_robot_indexable": true, "report_reasons": null, "author": "spandexnotleather", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eqlvf/what_goes_whereproxmox_and_truenas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eqlvf/what_goes_whereproxmox_and_truenas/", "subreddit_subscribers": 717623, "created_utc": 1702166233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently acquired an HPE MSL2024 Autoloader with LTO6 that I've connected to a Windows box using a SAS card.\n\nI've done a couple of test and all seems to be working fine, however I'm horrified at what Windows software that can use the Autoloader functionality costs.\n\nThe Windows box has mapped a couple of Synology box drives, my backup 'objectives' would be full backup every month, incrementals every night, 3 tape sets rotated, one 'live', most recent 2nd set in a fire safe onsite, 3rd set in a fire safe offsite this 3rd set being the max 2 months old if all else fails backup.  In total I'd be looking to backup about 40TB of assorted data with incrementals never more than 300-400Gb per night, although far more usually under 50Gb.\n\nWhat would others recommend as a suitable backup software tool that isn't going to cost either thousands or stupid annual licencing setups?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_172ebd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please recommend for me some Windows based backup software that isn't stupidly expensive.....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ekqcs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702149300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently acquired an HPE MSL2024 Autoloader with LTO6 that I&amp;#39;ve connected to a Windows box using a SAS card.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a couple of test and all seems to be working fine, however I&amp;#39;m horrified at what Windows software that can use the Autoloader functionality costs.&lt;/p&gt;\n\n&lt;p&gt;The Windows box has mapped a couple of Synology box drives, my backup &amp;#39;objectives&amp;#39; would be full backup every month, incrementals every night, 3 tape sets rotated, one &amp;#39;live&amp;#39;, most recent 2nd set in a fire safe onsite, 3rd set in a fire safe offsite this 3rd set being the max 2 months old if all else fails backup.  In total I&amp;#39;d be looking to backup about 40TB of assorted data with incrementals never more than 300-400Gb per night, although far more usually under 50Gb.&lt;/p&gt;\n\n&lt;p&gt;What would others recommend as a suitable backup software tool that isn&amp;#39;t going to cost either thousands or stupid annual licencing setups?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ekqcs", "is_robot_indexable": true, "report_reasons": null, "author": "Flubadubadubadub", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ekqcs/please_recommend_for_me_some_windows_based_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ekqcs/please_recommend_for_me_some_windows_based_backup/", "subreddit_subscribers": 717623, "created_utc": 1702149300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellow data hoarders!\n\nI am looking for a tool that could visualize the content of my NAS in a nice graphical dashboard, showing what takes up most of the space, by path, file types, etc. Something similar to WizTree under windows [https://diskanalyzer.com/](https://diskanalyzer.com/) or ncdu in linux, but better, running under docker and refreshing stats automatically in the background.\n\nIs there something like that available?", "author_fullname": "t2_gww3b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage analyzer/visualizer tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18e9sy9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702113663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data hoarders!&lt;/p&gt;\n\n&lt;p&gt;I am looking for a tool that could visualize the content of my NAS in a nice graphical dashboard, showing what takes up most of the space, by path, file types, etc. Something similar to WizTree under windows &lt;a href=\"https://diskanalyzer.com/\"&gt;https://diskanalyzer.com/&lt;/a&gt; or ncdu in linux, but better, running under docker and refreshing stats automatically in the background.&lt;/p&gt;\n\n&lt;p&gt;Is there something like that available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e9sy9", "is_robot_indexable": true, "report_reasons": null, "author": "rudeer_poke", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18e9sy9/storage_analyzervisualizer_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e9sy9/storage_analyzervisualizer_tool/", "subreddit_subscribers": 717623, "created_utc": 1702113663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know of a simple program I can use to backup my NAS in one go using multiple (2TB) drives?\n\nI want to point it at a mapped drive and say back that up onto these drives and have it just go.  I'm going to do this twice\n\nideally it would just copy the data, so that \n\n    &lt;Mapped drive&gt;\\dir1\n    .....\n    &lt;Mapped drive&gt;\\dirY\n\nis\n\n    &lt;bk1&gt;\\dir1\n    ....\n    &lt;BKX&gt;\\dirY\n\nI've got the stuff backed up in different ways (important stuff online backup plus own HD) video stuff across alphabetic drives - this would just make restore easier", "author_fullname": "t2_3xzg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using 2Tb drives for backup of NAS (spanned)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eqacw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702165259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a simple program I can use to backup my NAS in one go using multiple (2TB) drives?&lt;/p&gt;\n\n&lt;p&gt;I want to point it at a mapped drive and say back that up onto these drives and have it just go.  I&amp;#39;m going to do this twice&lt;/p&gt;\n\n&lt;p&gt;ideally it would just copy the data, so that &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;lt;Mapped drive&amp;gt;\\dir1\n.....\n&amp;lt;Mapped drive&amp;gt;\\dirY\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;is&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;lt;bk1&amp;gt;\\dir1\n....\n&amp;lt;BKX&amp;gt;\\dirY\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve got the stuff backed up in different ways (important stuff online backup plus own HD) video stuff across alphabetic drives - this would just make restore easier&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eqacw", "is_robot_indexable": true, "report_reasons": null, "author": "abz_eng", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eqacw/using_2tb_drives_for_backup_of_nas_spanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eqacw/using_2tb_drives_for_backup_of_nas_spanned/", "subreddit_subscribers": 717623, "created_utc": 1702165259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Synology started sending me emails about hitting 80% capacity, I do have it set so I can safely lose a drive, which eats a HDD... or is this array set for two?\n\n14TBx8 HDD and 16GB Intel Optane x2 RAID1 (cache)\n\nRegardless, I have at least 6 NAS, I moved a few months ago and I think I might actually have an ix2 at least SOMEWHERE, (a Synology DS1821+, a WD EX4 ( RAID5), WD MyCloud Mirror (4TBx2 RAID 1), Lacie something, 2 TrueNAS (8 3.5\"+4 2.5\" desktop style &amp; a 12 bay 8TB each (I think ZFS-Z2)). Plus countless flash drives, USB drives. \n\nOn a scale of 0 to I should seek help....\n\nI'm still running on 1 GbE because I'm on WiFi (Deco AX75 Pro- 1 2.5GbE port each) a decent amount and my FiOS is only 300Mbps (although it never hits that). I don't NEED 10GbE, so I can wait for it to get cheaper (Wifi 6E was more important). I VERY much prefer wired and use it whenever possible, but manufacturers seem hellbent on removing every ethernet port from EVERYTHING. I'm SO TIRED of needing a USB dongle to avoid wifi. Sorry, almost went on a tangent there.\n\nEverything is 100% for personal use and personal growth (disabled, brain tumor &amp; genetic disease affecting cartilage... apparently that stuff is everywhere, who knew/s), so I feel like it makes everything a little more silly. I need my own copy of my 2007 Visa statement, and my instance of home assistant (actually, I really do need that)...", "author_fullname": "t2_5a3zhit0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So, maybe I do have a problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18elcie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702151038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Synology started sending me emails about hitting 80% capacity, I do have it set so I can safely lose a drive, which eats a HDD... or is this array set for two?&lt;/p&gt;\n\n&lt;p&gt;14TBx8 HDD and 16GB Intel Optane x2 RAID1 (cache)&lt;/p&gt;\n\n&lt;p&gt;Regardless, I have at least 6 NAS, I moved a few months ago and I think I might actually have an ix2 at least SOMEWHERE, (a Synology DS1821+, a WD EX4 ( RAID5), WD MyCloud Mirror (4TBx2 RAID 1), Lacie something, 2 TrueNAS (8 3.5&amp;quot;+4 2.5&amp;quot; desktop style &amp;amp; a 12 bay 8TB each (I think ZFS-Z2)). Plus countless flash drives, USB drives. &lt;/p&gt;\n\n&lt;p&gt;On a scale of 0 to I should seek help....&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still running on 1 GbE because I&amp;#39;m on WiFi (Deco AX75 Pro- 1 2.5GbE port each) a decent amount and my FiOS is only 300Mbps (although it never hits that). I don&amp;#39;t NEED 10GbE, so I can wait for it to get cheaper (Wifi 6E was more important). I VERY much prefer wired and use it whenever possible, but manufacturers seem hellbent on removing every ethernet port from EVERYTHING. I&amp;#39;m SO TIRED of needing a USB dongle to avoid wifi. Sorry, almost went on a tangent there.&lt;/p&gt;\n\n&lt;p&gt;Everything is 100% for personal use and personal growth (disabled, brain tumor &amp;amp; genetic disease affecting cartilage... apparently that stuff is everywhere, who knew/s), so I feel like it makes everything a little more silly. I need my own copy of my 2007 Visa statement, and my instance of home assistant (actually, I really do need that)...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18elcie", "is_robot_indexable": true, "report_reasons": null, "author": "FalconSteve89", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18elcie/so_maybe_i_do_have_a_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18elcie/so_maybe_i_do_have_a_problem/", "subreddit_subscribers": 717623, "created_utc": 1702151038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Problem - I have a shared album that my wife, grandparents and myself regularly upload photos to of our daughter. We upload in full quality and its in a lovely timeline of her life.\n\nI would like an offline copy of this just for hoardings sake and the \"you never know google might goaway one day\" \n\nYes i could of kept a local copy but when you are a new parent your brain is pretty exhausted and you dont think about it. Now its getting large i would rather a copy of it.\n\n&amp;#x200B;\n\nIve tried rclone however it doesn't pull in full quality. I will accept it at the quality its at if its complete. Also im not convinced it pulls other peoples photos that are shared to it.\n\n&amp;#x200B;\n\nIve pulled a google takeout and where my storage is sitting around 2tb currently. It picks up content im not concerned with currently, is a structural mess and again 99% sure doesn't have other peoples photos shared in it.\n\n&amp;#x200B;\n\nIs there something other than Rclone i can leverage to do this\n\n&amp;#x200B;\n\nP.s comfortable with any solution cli or gui, windows or Linux or any other of flavour of solution", "author_fullname": "t2_unrbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to Clone Google Photos shared Albums?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eg7qd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702136609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Problem - I have a shared album that my wife, grandparents and myself regularly upload photos to of our daughter. We upload in full quality and its in a lovely timeline of her life.&lt;/p&gt;\n\n&lt;p&gt;I would like an offline copy of this just for hoardings sake and the &amp;quot;you never know google might goaway one day&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Yes i could of kept a local copy but when you are a new parent your brain is pretty exhausted and you dont think about it. Now its getting large i would rather a copy of it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ive tried rclone however it doesn&amp;#39;t pull in full quality. I will accept it at the quality its at if its complete. Also im not convinced it pulls other peoples photos that are shared to it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ive pulled a google takeout and where my storage is sitting around 2tb currently. It picks up content im not concerned with currently, is a structural mess and again 99% sure doesn&amp;#39;t have other peoples photos shared in it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there something other than Rclone i can leverage to do this&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;P.s comfortable with any solution cli or gui, windows or Linux or any other of flavour of solution&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "432TB Useable", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eg7qd", "is_robot_indexable": true, "report_reasons": null, "author": "kerbys", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18eg7qd/is_there_a_way_to_clone_google_photos_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eg7qd/is_there_a_way_to_clone_google_photos_shared/", "subreddit_subscribers": 717623, "created_utc": 1702136609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Question on bitrot- is its onset any different in terms of timeframe when it comes to SATA vs NVME ssds?\n\nAdditionally, will simply plugging the drive into an enclosure then connecting said enclosure to a functioning usbc/a port prevent bitrot onset for another year?", "author_fullname": "t2_e1qv9dge", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bitrot and SSDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18eemja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702131780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question on bitrot- is its onset any different in terms of timeframe when it comes to SATA vs NVME ssds?&lt;/p&gt;\n\n&lt;p&gt;Additionally, will simply plugging the drive into an enclosure then connecting said enclosure to a functioning usbc/a port prevent bitrot onset for another year?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18eemja", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed_Allele", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18eemja/bitrot_and_ssds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18eemja/bitrot_and_ssds/", "subreddit_subscribers": 717623, "created_utc": 1702131780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.glass-bead.org/audio-research/ Can anyone figure out how to download the mp3s off of this site? It used to work when you clicked the link in developer tools and played the audio file in it's own window, but that method no longer seems to work.", "author_fullname": "t2_shsin8fo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help downloading audio from site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ealys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702117085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.glass-bead.org/audio-research/\"&gt;https://www.glass-bead.org/audio-research/&lt;/a&gt; Can anyone figure out how to download the mp3s off of this site? It used to work when you clicked the link in developer tools and played the audio file in it&amp;#39;s own window, but that method no longer seems to work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?auto=webp&amp;s=9e79d9b29648d3767bb95ca3591fd1bd05890dc9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcc911e00e1e2b77a1578efeaff227ac8018c79c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac4fbc9a79352a580082f66b622aeb14f1b7ec34", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=71b091ef2804bd0a07274a2deffa503452287d4e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14352b75ccdf7eabc3f9b436a5bf6cbe13dc9c15", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d425ebf636f26e441447d48d549d3f62dd5ab031", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/8-8JUtdFJ3M_TW5bRDLYsKEcAbF0XBWnkN1tMnUFJAo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d417186d50f1c6786096e13c727e05fa78783e7", "width": 1080, "height": 1080}], "variants": {}, "id": "L0KPDLDHUpwyk1Za7sCp_QDDkbMZtnNp7SviIYbGx0w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ealys", "is_robot_indexable": true, "report_reasons": null, "author": "SystemElegant2703", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ealys/help_downloading_audio_from_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ealys/help_downloading_audio_from_site/", "subreddit_subscribers": 717623, "created_utc": 1702117085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay so basically I'm planning to use a 4TB drive formatted with btrfs on my server, which would perform a scrub every month or so. If the scrub shows no errors then that data gets copied to a backup drive on my PC probably formatted as just ext4, and if it does give me an error then I (manually) replace the problematic file with the one from the backup that was good. \n\nAre there any major issues with a setup like this for preventing bitrot / for backing up my data and if so how could it be improved? (besides not having an offsite backup)", "author_fullname": "t2_hbx5eze2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BTRFS no raid, 2 drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18e87nn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702106829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so basically I&amp;#39;m planning to use a 4TB drive formatted with btrfs on my server, which would perform a scrub every month or so. If the scrub shows no errors then that data gets copied to a backup drive on my PC probably formatted as just ext4, and if it does give me an error then I (manually) replace the problematic file with the one from the backup that was good. &lt;/p&gt;\n\n&lt;p&gt;Are there any major issues with a setup like this for preventing bitrot / for backing up my data and if so how could it be improved? (besides not having an offsite backup)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18e87nn", "is_robot_indexable": true, "report_reasons": null, "author": "emmaidontknow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18e87nn/btrfs_no_raid_2_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18e87nn/btrfs_no_raid_2_drives/", "subreddit_subscribers": 717623, "created_utc": 1702106829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Hello! I have multiple external 4 TB Backup HDDs with their own Micro-B and Power Supply cords, but they are not distinguishable from each other.\n\nHow can I tell which Micro-B and Power Supply cords are the ones that came packaged with the corresponding External Backup HDD?\n\nFor example, I have a 4TB WD My Book, and a 4TB Seagate Expansion drive, with very similar Micro-B and Power Supply cords that go with each other.", "author_fullname": "t2_w9e90nsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tell which cords go to which drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ettsr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702176679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I have multiple external 4 TB Backup HDDs with their own Micro-B and Power Supply cords, but they are not distinguishable from each other.&lt;/p&gt;\n\n&lt;p&gt;How can I tell which Micro-B and Power Supply cords are the ones that came packaged with the corresponding External Backup HDD?&lt;/p&gt;\n\n&lt;p&gt;For example, I have a 4TB WD My Book, and a 4TB Seagate Expansion drive, with very similar Micro-B and Power Supply cords that go with each other.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ettsr", "is_robot_indexable": true, "report_reasons": null, "author": "CuriousDivide2425", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ettsr/how_to_tell_which_cords_go_to_which_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ettsr/how_to_tell_which_cords_go_to_which_drives/", "subreddit_subscribers": 717623, "created_utc": 1702176679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nNewbie here but not new to data hoarding. I have to do a regular cross continental shipment of about 100x 3.5 inch HDDs every couple of months. This will be done as DHL express shipment as an air freight. Do you have any recommendation for a large enclosure that I can use to safely ship this? The ones I find are only 8x or 10x per box which makes for a lot of overhead weight. Any suggestions&gt;= 40 disks per box/enclosure would be very useful. TIA!", "author_fullname": "t2_dfven1zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shipping 100x 3.5 inch HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18epbgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702162429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;Newbie here but not new to data hoarding. I have to do a regular cross continental shipment of about 100x 3.5 inch HDDs every couple of months. This will be done as DHL express shipment as an air freight. Do you have any recommendation for a large enclosure that I can use to safely ship this? The ones I find are only 8x or 10x per box which makes for a lot of overhead weight. Any suggestions&amp;gt;= 40 disks per box/enclosure would be very useful. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18epbgh", "is_robot_indexable": true, "report_reasons": null, "author": "pulsar_timer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18epbgh/shipping_100x_35_inch_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18epbgh/shipping_100x_35_inch_hdds/", "subreddit_subscribers": 717623, "created_utc": 1702162429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a problem I've been wrestling with for years and I need help.\n\nMy photo library (that started on a Windows machine as jpg, tiff and CRW files stored in hierarchical folder structures) at some point reached into probably somewhere between 100k and 200k photos.  It became fragmented as I attempted to migrate it, then to make backups on external USB drives.  It seemed like every time I would try to move or consolidate the files my computer would choke at some point and stop midway through, leaving me in a panic because I didn't know what got copied/moved, and what remained, so there is now A TON of duplication.   I'm not sure of all of the details, but I've ended up with about four separate library versions - one on my Mac, and three external USB versions, none of which align perfectly.\n\nMy guess is that all four versions are about 75% common files, with each library having some folders and files not contained in the others, and also missing some that the others have.\n\nI'm now on a Mac (which is neither here nor there).  I am in the process of trying to move all four libraries onto a 2TB external SSD.  Once there, I am looking for advice on how to consolidate these libraries?  I'd obviously like to avoid as much duplication as possible, but I REALLY don't want to lose any photos - many are the only digital versions we have of our kids growing up.\n\nCan anyone advise me on the most thorough and reliable way to approach this?  I don't mind buying software so long as I KNOW it will do the job.\n\nThanks for any help folks can provide!\n\n&amp;#x200B;", "author_fullname": "t2_5rc38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merge three separate partial libraries from external USB drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18em6ay", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702153364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a problem I&amp;#39;ve been wrestling with for years and I need help.&lt;/p&gt;\n\n&lt;p&gt;My photo library (that started on a Windows machine as jpg, tiff and CRW files stored in hierarchical folder structures) at some point reached into probably somewhere between 100k and 200k photos.  It became fragmented as I attempted to migrate it, then to make backups on external USB drives.  It seemed like every time I would try to move or consolidate the files my computer would choke at some point and stop midway through, leaving me in a panic because I didn&amp;#39;t know what got copied/moved, and what remained, so there is now A TON of duplication.   I&amp;#39;m not sure of all of the details, but I&amp;#39;ve ended up with about four separate library versions - one on my Mac, and three external USB versions, none of which align perfectly.&lt;/p&gt;\n\n&lt;p&gt;My guess is that all four versions are about 75% common files, with each library having some folders and files not contained in the others, and also missing some that the others have.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now on a Mac (which is neither here nor there).  I am in the process of trying to move all four libraries onto a 2TB external SSD.  Once there, I am looking for advice on how to consolidate these libraries?  I&amp;#39;d obviously like to avoid as much duplication as possible, but I REALLY don&amp;#39;t want to lose any photos - many are the only digital versions we have of our kids growing up.&lt;/p&gt;\n\n&lt;p&gt;Can anyone advise me on the most thorough and reliable way to approach this?  I don&amp;#39;t mind buying software so long as I KNOW it will do the job.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help folks can provide!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18em6ay", "is_robot_indexable": true, "report_reasons": null, "author": "grendel2000", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18em6ay/merge_three_separate_partial_libraries_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18em6ay/merge_three_separate_partial_libraries_from/", "subreddit_subscribers": 717623, "created_utc": 1702153364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two different pcs running, one is a Windows 10 pc, has a drobo 5c with 3 12tb drives and 2 14 tb drives connected via usb c and this is backing up my truenas with pc with 5 14tb drives (main pc for all my data at home). \n\nI have two extra 8 tb as well on the side I just replaced.\n\nEach setup is basically a raid 5, would it be better to put all drives together in one pc and change it in truenas to a raid 6 or should I keep everything separate like it is now and just have one backup the other. I was planning to get a new case and using storage space or drive pool and put all the drives in my Windows pc as the backup system. \n\nOr\n\nSetup both as JBOD and one backup the other to maximize storage space, honestly any suggestions is fine with me just throwing out some ideas. Jbod seems like a bad idea because if one drive dies then that whole setup is going down, but I do have a backup at the same time, but bad because if both go then I'm screwed hahah.", "author_fullname": "t2_3hr19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updating setup, many drives and pcs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18elqf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702152127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two different pcs running, one is a Windows 10 pc, has a drobo 5c with 3 12tb drives and 2 14 tb drives connected via usb c and this is backing up my truenas with pc with 5 14tb drives (main pc for all my data at home). &lt;/p&gt;\n\n&lt;p&gt;I have two extra 8 tb as well on the side I just replaced.&lt;/p&gt;\n\n&lt;p&gt;Each setup is basically a raid 5, would it be better to put all drives together in one pc and change it in truenas to a raid 6 or should I keep everything separate like it is now and just have one backup the other. I was planning to get a new case and using storage space or drive pool and put all the drives in my Windows pc as the backup system. &lt;/p&gt;\n\n&lt;p&gt;Or&lt;/p&gt;\n\n&lt;p&gt;Setup both as JBOD and one backup the other to maximize storage space, honestly any suggestions is fine with me just throwing out some ideas. Jbod seems like a bad idea because if one drive dies then that whole setup is going down, but I do have a backup at the same time, but bad because if both go then I&amp;#39;m screwed hahah.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18elqf2", "is_robot_indexable": true, "report_reasons": null, "author": "xelu01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18elqf2/updating_setup_many_drives_and_pcs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18elqf2/updating_setup_many_drives_and_pcs/", "subreddit_subscribers": 717623, "created_utc": 1702152127.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}