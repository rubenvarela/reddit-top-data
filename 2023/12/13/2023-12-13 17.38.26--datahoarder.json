{"kind": "Listing", "data": {"after": "t3_18hjdb4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_830j5wb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VMware become subscription only", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18gzvjd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 310, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 310, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FYLRjRW0QoF4YgMFkT8QavkPeDzNpgnZ7qWCgumFrEg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702422329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.vmware.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.vmware.com/company/vmware-by-broadcom-business-transformation", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?auto=webp&amp;s=9a66c93b10f66e7b6fbf4ae6813cd1fcf4ecbc70", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1609c856453fe432a5ac14c314e5453d2a00838", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b3b74e4c05432a2c5428c307f1989dd0dcdd58d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f5b8e5a7e479aa5b72c884589f7bd35befaaa51", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7e4d3306b6f6bbb249d8903394724c0b98e3473", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f157489a956c38a1681fb2a06123db2ad8d4fe2", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Gz2FmeZcMNoxHQHKl7ki5rZrArwVA3R8AMQKYcX5VzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=57dc276aafa42256185f6ad1fccd874196cfc61f", "width": 1080, "height": 607}], "variants": {}, "id": "iYMv-ci8kxl9BjNABuq71vBpmyAXw4nY6hCl5hyTcuE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gzvjd", "is_robot_indexable": true, "report_reasons": null, "author": "hobbyhacker", "discussion_type": null, "num_comments": 140, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gzvjd/vmware_become_subscription_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.vmware.com/company/vmware-by-broadcom-business-transformation", "subreddit_subscribers": 717957, "created_utc": 1702422329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've backed numerous pieces of otherwise nonexistent software up to the Internet Archive, and it's saved me when I needed a specific thing numerous times.   \nBut given worst case it may be shut down and taken totally off the web, what's going to happen to the otherwise totally lost software? Does anyone have a way to manage this?   \nThe closest to a coherent full backup style plan I have that's not \\*totally\\* impossible is to spread hundreds of partial backups across dozens of the servers people in this community run, with a central hub to all of the server sites containing each chunk. This way at least even if fragmented between many sites, the entire software collection is present, and even if a chunk is lost, the entire thing doesn't go (the eggs aren't in one basket, so to speak). But I don't have the skills nor supplies and hardware to coordinate such a huge thing, and it's unlikely enough would help out and host such a huge amount of junk. It's really possible only on paper.  \nIs there any (good) plan B here or is the best realistic plan to grab what you want now and keep it safe and host anything especially rare on your own sites? Because if so, I've gotta get working on that. ", "author_fullname": "t2_718mpex4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens to software if the internet archive gets taken offline, and how can we prevent losing all of it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18harob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702449783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve backed numerous pieces of otherwise nonexistent software up to the Internet Archive, and it&amp;#39;s saved me when I needed a specific thing numerous times.&lt;br/&gt;\nBut given worst case it may be shut down and taken totally off the web, what&amp;#39;s going to happen to the otherwise totally lost software? Does anyone have a way to manage this?&lt;br/&gt;\nThe closest to a coherent full backup style plan I have that&amp;#39;s not *totally* impossible is to spread hundreds of partial backups across dozens of the servers people in this community run, with a central hub to all of the server sites containing each chunk. This way at least even if fragmented between many sites, the entire software collection is present, and even if a chunk is lost, the entire thing doesn&amp;#39;t go (the eggs aren&amp;#39;t in one basket, so to speak). But I don&amp;#39;t have the skills nor supplies and hardware to coordinate such a huge thing, and it&amp;#39;s unlikely enough would help out and host such a huge amount of junk. It&amp;#39;s really possible only on paper.&lt;br/&gt;\nIs there any (good) plan B here or is the best realistic plan to grab what you want now and keep it safe and host anything especially rare on your own sites? Because if so, I&amp;#39;ve gotta get working on that. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18harob", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_McGuggins", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18harob/what_happens_to_software_if_the_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18harob/what_happens_to_software_if_the_internet_archive/", "subreddit_subscribers": 717957, "created_utc": 1702449783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know there are some tools for .zip files, but are there any tools for 7zip archives?\n\nThanks!", "author_fullname": "t2_p79a3ceo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any tools that can help recovering files from corrupted non-solid 7zip archives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h2pc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702427559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are some tools for .zip files, but are there any tools for 7zip archives?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h2pc5", "is_robot_indexable": true, "report_reasons": null, "author": "No_Bid_4015", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h2pc5/are_there_any_tools_that_can_help_recovering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h2pc5/are_there_any_tools_that_can_help_recovering/", "subreddit_subscribers": 717957, "created_utc": 1702427559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have recently decided to start archiving my blu ray collection with MakeMKV, and I have run into a problem, namely don't have near enough space. I probably have at least 12 TB of media, and was looking into setting up a NAS so I can access it remotely later.  Are refurbished enterprise hard drives a good option, or is there a better option.  Sorry if it is a stupid question,  just getting started.", "author_fullname": "t2_8mirl3ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a good economical storage option?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h27b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702426634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently decided to start archiving my blu ray collection with MakeMKV, and I have run into a problem, namely don&amp;#39;t have near enough space. I probably have at least 12 TB of media, and was looking into setting up a NAS so I can access it remotely later.  Are refurbished enterprise hard drives a good option, or is there a better option.  Sorry if it is a stupid question,  just getting started.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h27b4", "is_robot_indexable": true, "report_reasons": null, "author": "Hot-Property1031", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h27b4/what_is_a_good_economical_storage_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h27b4/what_is_a_good_economical_storage_option/", "subreddit_subscribers": 717957, "created_utc": 1702426634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[(link to listing)](https://www.ebay.com/itm/304560559930?epid=27053479954&amp;hash=item46e939573a:g:trQAAOSwpZFi8pRk&amp;amdata=enc%3AAQAIAAABAIVf680bxJSVLwVIm4CzDXRlsNWGlAeznQvFndJV4r2dFrKD%2BeX7j74wu5SZIwd5h3UIgdFv%2F6Rh70rFABGGS0ne8gjCEhC4HSPES1MlSUv3uYHriWZ18cKZ0cax7X338JPFOIZHQMhAVrBImFRBRrJeuCuMxLhVhJi4jn%2BaGg33fV4JUBWsAMOnf8dAKHyBbeOxZ1mBrDYVqlc0guMipYJs%2BPbdTONRpdLFJEXoFIOqefHRh7nZbu%2BedqEpPWDL17C7zbTWqKVPZE8LjlPmqL%2BAYwXBHQ%2FFKjKXdnDc%2BxdZFCaquwigu%2Fa1gMsO1gE%2B3v%2B%2FHbb236URPAykc15loCg%3D%7Ctkp%3ABlBMUNKJtvmLYw)\n\nI know it's refurbished but only $209? Also is it a bad idea to buy a refurbished one?", "author_fullname": "t2_i0pdxpo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is the Seagate Exos X20 so cheap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gv0k6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702411583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.ebay.com/itm/304560559930?epid=27053479954&amp;amp;hash=item46e939573a:g:trQAAOSwpZFi8pRk&amp;amp;amdata=enc%3AAQAIAAABAIVf680bxJSVLwVIm4CzDXRlsNWGlAeznQvFndJV4r2dFrKD%2BeX7j74wu5SZIwd5h3UIgdFv%2F6Rh70rFABGGS0ne8gjCEhC4HSPES1MlSUv3uYHriWZ18cKZ0cax7X338JPFOIZHQMhAVrBImFRBRrJeuCuMxLhVhJi4jn%2BaGg33fV4JUBWsAMOnf8dAKHyBbeOxZ1mBrDYVqlc0guMipYJs%2BPbdTONRpdLFJEXoFIOqefHRh7nZbu%2BedqEpPWDL17C7zbTWqKVPZE8LjlPmqL%2BAYwXBHQ%2FFKjKXdnDc%2BxdZFCaquwigu%2Fa1gMsO1gE%2B3v%2B%2FHbb236URPAykc15loCg%3D%7Ctkp%3ABlBMUNKJtvmLYw\"&gt;(link to listing)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s refurbished but only $209? Also is it a bad idea to buy a refurbished one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OSFnCS6awf60YVzS_8XIHydR8x79LM92apwixWdvqz4.jpg?auto=webp&amp;s=d30df6ef672b5966e20fe74fa5ca24330120b81f", "width": 251, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/OSFnCS6awf60YVzS_8XIHydR8x79LM92apwixWdvqz4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=079883c99813fc1301e4037355699999474c4f12", "width": 108, "height": 172}, {"url": "https://external-preview.redd.it/OSFnCS6awf60YVzS_8XIHydR8x79LM92apwixWdvqz4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db172c33f7ed593776315f53329caa8851c73ec9", "width": 216, "height": 344}], "variants": {}, "id": "AkKT7YC5VN2e-qEsW3HGJMpLJYMkOeEi_To67MIYr74"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gv0k6", "is_robot_indexable": true, "report_reasons": null, "author": "diamitaye", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gv0k6/why_is_the_seagate_exos_x20_so_cheap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gv0k6/why_is_the_seagate_exos_x20_so_cheap/", "subreddit_subscribers": 717957, "created_utc": 1702411583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I picked up the 11 XL and it's fantastic, but I'm frustrated that my scans don't capture the entire document on the bed. It's only a millimetre or two, but knowing my scans aren't complete has been enough for me to pause this project. Is there any kind of software level fix for this, or do I just need to create a 90 degree wedge to offset every scan?\n\nI know I could place smaller documents away from the edge and level the image later, but I'd rather do a one time fix for this issue, than do tens of thousands of fixes.   \n\n\nThanks!", "author_fullname": "t2_ihs3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Epson Expression 11000XL scans cropped in from edges, how to scan full document?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hfz9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702471410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I picked up the 11 XL and it&amp;#39;s fantastic, but I&amp;#39;m frustrated that my scans don&amp;#39;t capture the entire document on the bed. It&amp;#39;s only a millimetre or two, but knowing my scans aren&amp;#39;t complete has been enough for me to pause this project. Is there any kind of software level fix for this, or do I just need to create a 90 degree wedge to offset every scan?&lt;/p&gt;\n\n&lt;p&gt;I know I could place smaller documents away from the edge and level the image later, but I&amp;#39;d rather do a one time fix for this issue, than do tens of thousands of fixes.   &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18hfz9w", "is_robot_indexable": true, "report_reasons": null, "author": "Plebsolute", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18hfz9w/epson_expression_11000xl_scans_cropped_in_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18hfz9w/epson_expression_11000xl_scans_cropped_in_from/", "subreddit_subscribers": 717957, "created_utc": 1702471410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I am an IT admin of a local videography company here in my area and I suggested that we should implement a NAS Server for their centralized storage so that they can increase their productivity. We settled on 4 IRONWOLF PRO 12TB drives that will run RAID 10 utilizing TrueNAS. However during the initial setup, I noticed that the connectors of the drives are different and they would not lock with a standard SATA connector for the motherboard and power supply.\n\nI read about NAS Drives being used in desktops but I suspect this requires a specific connector but I am not sure. Any suggestions?", "author_fullname": "t2_6mnjye6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate IRONWOLF PRO 12TB for Homemade NAS Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h6bfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702434785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am an IT admin of a local videography company here in my area and I suggested that we should implement a NAS Server for their centralized storage so that they can increase their productivity. We settled on 4 IRONWOLF PRO 12TB drives that will run RAID 10 utilizing TrueNAS. However during the initial setup, I noticed that the connectors of the drives are different and they would not lock with a standard SATA connector for the motherboard and power supply.&lt;/p&gt;\n\n&lt;p&gt;I read about NAS Drives being used in desktops but I suspect this requires a specific connector but I am not sure. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h6bfs", "is_robot_indexable": true, "report_reasons": null, "author": "Crafty-Total-6978", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h6bfs/seagate_ironwolf_pro_12tb_for_homemade_nas_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h6bfs/seagate_ironwolf_pro_12tb_for_homemade_nas_server/", "subreddit_subscribers": 717957, "created_utc": 1702434785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Used to use crystal disk info but I recently change my HBA cards and it no longer detects the disks. The HBA cards have their own webpage based solution but its enterprise grade and not exactly user friendly especially for just monitoring SMART stats. Needs to work on windows server. Any suggestions?", "author_fullname": "t2_zm7dz8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best program for SMART stat monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gujpy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702411618.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702410410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Used to use crystal disk info but I recently change my HBA cards and it no longer detects the disks. The HBA cards have their own webpage based solution but its enterprise grade and not exactly user friendly especially for just monitoring SMART stats. Needs to work on windows server. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gujpy", "is_robot_indexable": true, "report_reasons": null, "author": "smorgisborg1", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gujpy/best_program_for_smart_stat_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gujpy/best_program_for_smart_stat_monitoring/", "subreddit_subscribers": 717957, "created_utc": 1702410410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am making a fairly modest archive that is just a directory with a ton of pdfs and maybe some other files in it. I don't have the tech skills to implement any fancy solutions, so I want to keep it simple - throw the document in the pile, and to find it later search by filename (I use a specific format including key information like author) and keywords. The thing is, I don't want to add a ton of keywords to the end of a filename. Is there any way I can drop them into the file and have a software to quickly pull them without searching through the whole file? Again, I suck at technology so I can't do anything really fancy like all you professionals here.", "author_fullname": "t2_kda89q2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add keywords to files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18hldm7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702486770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am making a fairly modest archive that is just a directory with a ton of pdfs and maybe some other files in it. I don&amp;#39;t have the tech skills to implement any fancy solutions, so I want to keep it simple - throw the document in the pile, and to find it later search by filename (I use a specific format including key information like author) and keywords. The thing is, I don&amp;#39;t want to add a ton of keywords to the end of a filename. Is there any way I can drop them into the file and have a software to quickly pull them without searching through the whole file? Again, I suck at technology so I can&amp;#39;t do anything really fancy like all you professionals here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18hldm7", "is_robot_indexable": true, "report_reasons": null, "author": "dakkablakka", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18hldm7/how_to_add_keywords_to_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18hldm7/how_to_add_keywords_to_files/", "subreddit_subscribers": 717957, "created_utc": 1702486770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So here's the thing I need to batch download a bunch of images from [Zerochan.net](https://Zerochan.net) , I used wfdownloader to download them but every time I do it does not download all images because Zerochan disables the downloads until the downloader client is finished. Does anyone have anything that can help me with this problem?", "author_fullname": "t2_6bybo0w0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mass Download for Zerochan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h97v9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702443981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So here&amp;#39;s the thing I need to batch download a bunch of images from &lt;a href=\"https://Zerochan.net\"&gt;Zerochan.net&lt;/a&gt; , I used wfdownloader to download them but every time I do it does not download all images because Zerochan disables the downloads until the downloader client is finished. Does anyone have anything that can help me with this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h97v9", "is_robot_indexable": true, "report_reasons": null, "author": "Swiftmaker", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h97v9/mass_download_for_zerochan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h97v9/mass_download_for_zerochan/", "subreddit_subscribers": 717957, "created_utc": 1702443981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can you put HDDs/SSDs of different maximum capacity in a Synology, and have each one usable in the Synology?\n\n&amp;#x200B;\n\n*EX:*\n\n*Slot 1 = 4 TB,*\n\n*Slot 2 = 8 TB,*\n\n*Slot 3 = 16 TB*\n\n*Slot 4 = 4 TB*", "author_fullname": "t2_w9e90nsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synology HDD question.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h72t0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702437046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you put HDDs/SSDs of different maximum capacity in a Synology, and have each one usable in the Synology?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;EX:&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Slot 1 = 4 TB,&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Slot 2 = 8 TB,&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Slot 3 = 16 TB&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Slot 4 = 4 TB&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h72t0", "is_robot_indexable": true, "report_reasons": null, "author": "CuriousDivide2425", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h72t0/synology_hdd_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h72t0/synology_hdd_question/", "subreddit_subscribers": 717957, "created_utc": 1702437046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been collecting iOS games for a while, is there any way to archive them so I don't have to worry about developer unpublishing them or even App Store closing?", "author_fullname": "t2_x3s0wiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to archive iOS games?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h6pel", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702435924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been collecting iOS games for a while, is there any way to archive them so I don&amp;#39;t have to worry about developer unpublishing them or even App Store closing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h6pel", "is_robot_indexable": true, "report_reasons": null, "author": "slmjkdbtl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h6pel/is_there_any_way_to_archive_ios_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h6pel/is_there_any_way_to_archive_ios_games/", "subreddit_subscribers": 717957, "created_utc": 1702435924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am about to max out my 3.5\" HDD bays and PSU SATA connectors.  Besides buying an external drive or NAS (Synology or QNAP), what are my options to expand storage outside of my desktop tower case?", "author_fullname": "t2_o75sl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options to expand storage (outside of desktop tower)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h53ow", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702432187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am about to max out my 3.5&amp;quot; HDD bays and PSU SATA connectors.  Besides buying an external drive or NAS (Synology or QNAP), what are my options to expand storage outside of my desktop tower case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h53ow", "is_robot_indexable": true, "report_reasons": null, "author": "KB-ice-cream", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h53ow/options_to_expand_storage_outside_of_desktop_tower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h53ow/options_to_expand_storage_outside_of_desktop_tower/", "subreddit_subscribers": 717957, "created_utc": 1702432187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've spent quite a bunch of time searching around RAIDZ, RAID-5 unRAID solutions to a storage/cloud storage I am making for myself to store important Documents and or videos or anything I really want to archive and hoard as well as using it for other miscallenous purposes such as hosting game servers for small a small group of friends.\n\n&amp;#x200B;\n\nI recently received a computer from my friend with 2 socket 2 xeon E5620 and thought it was perfect to to turn it into a server.\n\nI was mainly looking into RAID 5/RAIDZ as a way to efficiently store said data whilst being able to recover it in case of a failure. At the moment I'm starting with a 240GB SSD simply for running the operating system, 2 2TB hard drives and 1 1TB hard drive. I am planning to expand this configuration as my need for storing more data increases \n\n&amp;#x200B;\n\nOne solution was to commit to using RAIDZ and only worry about the expansion aspect of it upon the OpenZFS 2.3 release where this feature will be officially released and I'm unlikely to end up using up my entire storage space up until that point either way. However, I do not know for sure if this will be the case.\n\n&amp;#x200B;\n\nAs such I wanted to inquire about any solutions to adding a drive on top of the current installation as I am aware that there are quite a few caveats in doing so and it seems quite difficult to do so under the current system. (i.e Adding another drive to the existing pool as time goes on)\n\n&amp;#x200B;\n\nI do not want to run unRAID due to A: The price of it (I need to save as much money as possible) and B: I highly dislike running an entire Operating System off of a usb stick even if it is reliable. I want the server to be as self contained as possible and due to the space limitations in my room which is where I'm storing the server it is likely I would destroy the usb stick by a freak accident.\n\n&amp;#x200B;\n\nI will be running the system under Debian due to wanting to use the server for other purposes than just data hoarding.\n\n&amp;#x200B;\n\nso my main questions are:  \n1: Is there a reliable way of adding a single drive on top of an existing pool in RAIDZ or RAID-5\n\n2: If not, is there another solution that could somewhat satisfy that need?\n\n3: if this is also not possible. Would creating another pool with the same size and amount of drives and then merging the pools together be the correct solution?\n\n&amp;#x200B;\n\nThank you for reading. I understand this might be a newbie question but I've been struggling to find an answer just from scouring reddit and google and the only thing I've managed to find is OpenZFS 2.3 release addressing this whenever it ends up coming out.  \n", "author_fullname": "t2_wb8d7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive pooling + striping + parity with eventual expansion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h3293", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702428240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve spent quite a bunch of time searching around RAIDZ, RAID-5 unRAID solutions to a storage/cloud storage I am making for myself to store important Documents and or videos or anything I really want to archive and hoard as well as using it for other miscallenous purposes such as hosting game servers for small a small group of friends.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I recently received a computer from my friend with 2 socket 2 xeon E5620 and thought it was perfect to to turn it into a server.&lt;/p&gt;\n\n&lt;p&gt;I was mainly looking into RAID 5/RAIDZ as a way to efficiently store said data whilst being able to recover it in case of a failure. At the moment I&amp;#39;m starting with a 240GB SSD simply for running the operating system, 2 2TB hard drives and 1 1TB hard drive. I am planning to expand this configuration as my need for storing more data increases &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;One solution was to commit to using RAIDZ and only worry about the expansion aspect of it upon the OpenZFS 2.3 release where this feature will be officially released and I&amp;#39;m unlikely to end up using up my entire storage space up until that point either way. However, I do not know for sure if this will be the case.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As such I wanted to inquire about any solutions to adding a drive on top of the current installation as I am aware that there are quite a few caveats in doing so and it seems quite difficult to do so under the current system. (i.e Adding another drive to the existing pool as time goes on)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I do not want to run unRAID due to A: The price of it (I need to save as much money as possible) and B: I highly dislike running an entire Operating System off of a usb stick even if it is reliable. I want the server to be as self contained as possible and due to the space limitations in my room which is where I&amp;#39;m storing the server it is likely I would destroy the usb stick by a freak accident.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I will be running the system under Debian due to wanting to use the server for other purposes than just data hoarding.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;so my main questions are:&lt;br/&gt;\n1: Is there a reliable way of adding a single drive on top of an existing pool in RAIDZ or RAID-5&lt;/p&gt;\n\n&lt;p&gt;2: If not, is there another solution that could somewhat satisfy that need?&lt;/p&gt;\n\n&lt;p&gt;3: if this is also not possible. Would creating another pool with the same size and amount of drives and then merging the pools together be the correct solution?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading. I understand this might be a newbie question but I&amp;#39;ve been struggling to find an answer just from scouring reddit and google and the only thing I&amp;#39;ve managed to find is OpenZFS 2.3 release addressing this whenever it ends up coming out.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h3293", "is_robot_indexable": true, "report_reasons": null, "author": "kuba6532", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h3293/drive_pooling_striping_parity_with_eventual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h3293/drive_pooling_striping_parity_with_eventual/", "subreddit_subscribers": 717957, "created_utc": 1702428240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a utility I can put in a recordable CD or DVD and it looks at all the files and tells me if it was able to locate those files on my hard drive?  Basically, is this clutter on my clutter piles of CD safely somewhere else.", "author_fullname": "t2_pczsrl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are cd or dvd files on my hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gvu21", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702413722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a utility I can put in a recordable CD or DVD and it looks at all the files and tells me if it was able to locate those files on my hard drive?  Basically, is this clutter on my clutter piles of CD safely somewhere else.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gvu21", "is_robot_indexable": true, "report_reasons": null, "author": "bsee_xflds", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gvu21/are_cd_or_dvd_files_on_my_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gvu21/are_cd_or_dvd_files_on_my_hard_drive/", "subreddit_subscribers": 717957, "created_utc": 1702413722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI am a bit stuck, could you please give me some ideas?\n\n2 years ago I got 2 x 18 TB HDDs on wich to store data ... As space is at a premium in my flat and I don't need the drives online at all times, I have them in my main gaming rig - a Meshify 2 case, under the shroud near the PSU - I connect them whenever I need them, copy data from / to them then disconnect them. Originally I had them in RAID 1 but found out that disconnecting them from Windows and connecting them back they were always rebuilding the raid, so I have gave up o that and I make sure to copy the data to both of them - a bit tedious but it's a 4 hours effort every 4-5 months.\n\nNow 2 years later, these drives are on the verge of getting full ... and have no idea how to proceed.\n\nI guess I would need to commit one way or another - either build up some kind of storage server or get at least a 4 bay NAS. In that case, how easy would it be to extend that in 2-3 years when the 4 drives will get full?\n\nWhat would you guys recommend?\n\nThanks", "author_fullname": "t2_155ml1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me - How to continue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18hjz0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702483094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I am a bit stuck, could you please give me some ideas?&lt;/p&gt;\n\n&lt;p&gt;2 years ago I got 2 x 18 TB HDDs on wich to store data ... As space is at a premium in my flat and I don&amp;#39;t need the drives online at all times, I have them in my main gaming rig - a Meshify 2 case, under the shroud near the PSU - I connect them whenever I need them, copy data from / to them then disconnect them. Originally I had them in RAID 1 but found out that disconnecting them from Windows and connecting them back they were always rebuilding the raid, so I have gave up o that and I make sure to copy the data to both of them - a bit tedious but it&amp;#39;s a 4 hours effort every 4-5 months.&lt;/p&gt;\n\n&lt;p&gt;Now 2 years later, these drives are on the verge of getting full ... and have no idea how to proceed.&lt;/p&gt;\n\n&lt;p&gt;I guess I would need to commit one way or another - either build up some kind of storage server or get at least a 4 bay NAS. In that case, how easy would it be to extend that in 2-3 years when the 4 drives will get full?&lt;/p&gt;\n\n&lt;p&gt;What would you guys recommend?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18hjz0b", "is_robot_indexable": true, "report_reasons": null, "author": "mariusmoga_2005", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18hjz0b/help_me_how_to_continue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18hjz0b/help_me_how_to_continue/", "subreddit_subscribers": 717957, "created_utc": 1702483094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you use cshatag with ext4? Is reliable in your experience? Is good as an alternative to built-in btrfs checksums?", "author_fullname": "t2_bft4zd1l6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ext4+cshatag", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hgilb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702473191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you use cshatag with ext4? Is reliable in your experience? Is good as an alternative to built-in btrfs checksums?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18hgilb", "is_robot_indexable": true, "report_reasons": null, "author": "z13131313", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18hgilb/ext4cshatag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18hgilb/ext4cshatag/", "subreddit_subscribers": 717957, "created_utc": 1702473191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using ACASIS 7port USB Hub with power supplied for a few months now.  \nrecently having issue of it getting disconnect and reconnecting quite frequently which is terribly affecting my daily use.  \nanyone else encountered this problem with solutions?  \ncant seem to find any link to a driver update or something...", "author_fullname": "t2_fva6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using ACASIS USB hub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h740b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702437143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using ACASIS 7port USB Hub with power supplied for a few months now.&lt;br/&gt;\nrecently having issue of it getting disconnect and reconnecting quite frequently which is terribly affecting my daily use.&lt;br/&gt;\nanyone else encountered this problem with solutions?&lt;br/&gt;\ncant seem to find any link to a driver update or something...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h740b", "is_robot_indexable": true, "report_reasons": null, "author": "roastedhead", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h740b/anyone_using_acasis_usb_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18h740b/anyone_using_acasis_usb_hub/", "subreddit_subscribers": 717957, "created_utc": 1702437143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, \n\nHoping someone can help me troubleshoot an issue with a brand new RAID setup. \n\nI just bought an OWC Elite Pro Quad enclosure and put 4x16TB Seagate EXOS drives (Recertified from goharddrive) in it with a RAID 5 setup. \n\nI know there is risk with recertified but have had good success from them before and before using them I ran some basic tests and was satisfied. The data going on the drive is not mission critical, so I'm ok with loss to a degree if it happens. \n\nFirst major symptom I observed with this setup is that during two large data transfers at some point, the enclosure (and seemingly part of my onboard USB hub) completely died. SoftRAID couldn't read the mounted RAID, Windows didn't see it, and rebooting the unit didn't bring it back. Windows reboot fixed this problem, and it happened a couple of times over the next few days. I am now on a week of it not happening with nothing major changing other than I decided to unplug a few other USB periphs just to see if it was overloading for some strange reason. Still unsure what happened and Windows logs are not helpful. \n\nNext issue is data-related. I downloaded a few large archives (.zip, .7z, etc.) to the drive, and when testing integrity on them, I am getting a ton of CRC/checksum errors. It's totally random, but can be reproduced. To make sure it wasn't the archives themselves, I downloaded one of the problem ones to a completely different drive outside of the enclosure and there are no checksum errors. I am able to transfer, load and launch a lot of other files to this RAID array without issue. SoftRAID detects no errors, crystaldisk looks good and generally speaking I can't see anything actually wrong here. So to recap, can use the drives like normal, but experiencing what appear to be random read/write issues like this. \n\nI am looking for help on what to check next. I am not the deepest on what tools to use to really detect bad sectors or other issues, but I'm starting to think this is a bad OWC enclosure or some other issues causing this? Does anyone have any suggestions to try before I completely rebuild or do something more extreme? SoftRAID has a verify drive function that I am running but it takes a while to finish, so I am in the process of doing that one by one. \n\nThank you!", "author_fullname": "t2_zvqah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OWC New RAID 5 Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gzuuz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702422296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;Hoping someone can help me troubleshoot an issue with a brand new RAID setup. &lt;/p&gt;\n\n&lt;p&gt;I just bought an OWC Elite Pro Quad enclosure and put 4x16TB Seagate EXOS drives (Recertified from goharddrive) in it with a RAID 5 setup. &lt;/p&gt;\n\n&lt;p&gt;I know there is risk with recertified but have had good success from them before and before using them I ran some basic tests and was satisfied. The data going on the drive is not mission critical, so I&amp;#39;m ok with loss to a degree if it happens. &lt;/p&gt;\n\n&lt;p&gt;First major symptom I observed with this setup is that during two large data transfers at some point, the enclosure (and seemingly part of my onboard USB hub) completely died. SoftRAID couldn&amp;#39;t read the mounted RAID, Windows didn&amp;#39;t see it, and rebooting the unit didn&amp;#39;t bring it back. Windows reboot fixed this problem, and it happened a couple of times over the next few days. I am now on a week of it not happening with nothing major changing other than I decided to unplug a few other USB periphs just to see if it was overloading for some strange reason. Still unsure what happened and Windows logs are not helpful. &lt;/p&gt;\n\n&lt;p&gt;Next issue is data-related. I downloaded a few large archives (.zip, .7z, etc.) to the drive, and when testing integrity on them, I am getting a ton of CRC/checksum errors. It&amp;#39;s totally random, but can be reproduced. To make sure it wasn&amp;#39;t the archives themselves, I downloaded one of the problem ones to a completely different drive outside of the enclosure and there are no checksum errors. I am able to transfer, load and launch a lot of other files to this RAID array without issue. SoftRAID detects no errors, crystaldisk looks good and generally speaking I can&amp;#39;t see anything actually wrong here. So to recap, can use the drives like normal, but experiencing what appear to be random read/write issues like this. &lt;/p&gt;\n\n&lt;p&gt;I am looking for help on what to check next. I am not the deepest on what tools to use to really detect bad sectors or other issues, but I&amp;#39;m starting to think this is a bad OWC enclosure or some other issues causing this? Does anyone have any suggestions to try before I completely rebuild or do something more extreme? SoftRAID has a verify drive function that I am running but it takes a while to finish, so I am in the process of doing that one by one. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gzuuz", "is_robot_indexable": true, "report_reasons": null, "author": "Spectre_N7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gzuuz/owc_new_raid_5_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gzuuz/owc_new_raid_5_help/", "subreddit_subscribers": 717957, "created_utc": 1702422296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any recommendations for a computer case that has room for at least 6 3.5\" drives and maybe a couple 2.5\" drives?\nI have about 85TB of storage on my main rig and hate having it all on there. I have an abundance of motherboards and processors and PSUs so all I really need is the case. Everything I'm finding is ridiculously overpriced.", "author_fullname": "t2_112euc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nas PC case recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gr3cr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702426495.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702401645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any recommendations for a computer case that has room for at least 6 3.5&amp;quot; drives and maybe a couple 2.5&amp;quot; drives?\nI have about 85TB of storage on my main rig and hate having it all on there. I have an abundance of motherboards and processors and PSUs so all I really need is the case. Everything I&amp;#39;m finding is ridiculously overpriced.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gr3cr", "is_robot_indexable": true, "report_reasons": null, "author": "jcurrin15205", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gr3cr/nas_pc_case_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gr3cr/nas_pc_case_recommendations/", "subreddit_subscribers": 717957, "created_utc": 1702401645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive Replace Won't Complete?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h129x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_g92gi", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "zfs", "selftext": "Okay so I recently rebuild my primary array with new drives. It's a 7 X 8TB array in a RAIDZ2.\n\nNow I did a slightly dumb thing and created the array with the /dev/sdX devices and then made changes to my configuration. Due to that, I had to do a zpool replace on one one drive that had moved around in /dev and export and re-import the pool to get everything back and kosher.\n\nTo fix it long-term, I exported and then reimported with:\n\n    zpool import -d /dev/disk/by-path/ Array\n\nBut I still had one drive that wasn't showing up so I did one more zpool replace.\n\nNow my pool is \\*working\\* fine but the \"old\" drive with the numeric identifier 9345874793597732565 is supposed to be replaced by pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:3, but it's still just hanging around in this state:\n\n      pool: Array\n     state: DEGRADED\n      scan: scrub canceled on Tue Dec 12 17:11:43 2023\n    config:\n    \n    \tNAME                                             STATE     READ WRITE CKSUM\n    \tArray                                            DEGRADED     0     0     0\n    \t  raidz2-0                                       DEGRADED     0     0     0\n    \t    pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:0    ONLINE       0     0     0\n    \t    pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:1    ONLINE       0     0     0\n    \t    pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:2    ONLINE       0     0     0\n    \t    replacing-3                                  DEGRADED     0     0     0\n    \t      pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:3  ONLINE       0     0     0\n    \t      9345874793597732565                        OFFLINE      0     0     0 was /dev/sdc1\n    \t    pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:0    ONLINE       0     0     0\n    \t    pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:1    ONLINE       0     0     0\n    \t    pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:2    ONLINE       0     0     0\n    \n    errors: No known data errors\n\nLike I said, the pool is fine, no data errors but I would really like to get back to the nice clean Array. It resilvered for 8 hours but now it's done and I'm still seeing that \"replacing-3\" drive.\n\nAny ZFS gurus have any ideas what I need to do to truly remove 9345874793597732565 and get the pool out of it's degraded state? Thanks!", "author_fullname": "t2_g92gi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive Replace Won't Complete?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/zfs", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h0t93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702424055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.zfs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so I recently rebuild my primary array with new drives. It&amp;#39;s a 7 X 8TB array in a RAIDZ2.&lt;/p&gt;\n\n&lt;p&gt;Now I did a slightly dumb thing and created the array with the /dev/sdX devices and then made changes to my configuration. Due to that, I had to do a zpool replace on one one drive that had moved around in /dev and export and re-import the pool to get everything back and kosher.&lt;/p&gt;\n\n&lt;p&gt;To fix it long-term, I exported and then reimported with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;zpool import -d /dev/disk/by-path/ Array\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But I still had one drive that wasn&amp;#39;t showing up so I did one more zpool replace.&lt;/p&gt;\n\n&lt;p&gt;Now my pool is *working* fine but the &amp;quot;old&amp;quot; drive with the numeric identifier 9345874793597732565 is supposed to be replaced by pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:3, but it&amp;#39;s still just hanging around in this state:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  pool: Array\n state: DEGRADED\n  scan: scrub canceled on Tue Dec 12 17:11:43 2023\nconfig:\n\n    NAME                                             STATE     READ WRITE CKSUM\n    Array                                            DEGRADED     0     0     0\n      raidz2-0                                       DEGRADED     0     0     0\n        pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:0    ONLINE       0     0     0\n        pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:1    ONLINE       0     0     0\n        pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:2    ONLINE       0     0     0\n        replacing-3                                  DEGRADED     0     0     0\n          pci-0000:00:14.0-usb-0:3:1.0-scsi-0:0:0:3  ONLINE       0     0     0\n          9345874793597732565                        OFFLINE      0     0     0 was /dev/sdc1\n        pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:0    ONLINE       0     0     0\n        pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:1    ONLINE       0     0     0\n        pci-0000:00:14.0-usb-0:4:1.0-scsi-0:0:0:2    ONLINE       0     0     0\n\nerrors: No known data errors\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Like I said, the pool is fine, no data errors but I would really like to get back to the nice clean Array. It resilvered for 8 hours but now it&amp;#39;s done and I&amp;#39;m still seeing that &amp;quot;replacing-3&amp;quot; drive.&lt;/p&gt;\n\n&lt;p&gt;Any ZFS gurus have any ideas what I need to do to truly remove 9345874793597732565 and get the pool out of it&amp;#39;s degraded state? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ruui", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18h0t93", "is_robot_indexable": true, "report_reasons": null, "author": "skydecklover", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/zfs/comments/18h0t93/drive_replace_wont_complete/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/zfs/comments/18h0t93/drive_replace_wont_complete/", "subreddit_subscribers": 28912, "created_utc": 1702424055.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1702424518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.zfs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/zfs/comments/18h0t93/drive_replace_wont_complete/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18h129x", "is_robot_indexable": true, "report_reasons": null, "author": "skydecklover", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_18h0t93", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18h129x/drive_replace_wont_complete/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/zfs/comments/18h0t93/drive_replace_wont_complete/", "subreddit_subscribers": 717957, "created_utc": 1702424518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been attempting this on and off for years, but never found anything that works long term. I have both Pc and Mac but was predominantly using Mac until recently. I was devoted to Downcast, but it started becoming unreliable for macOS Monterey operating system, I switched to Mimir, but that was saving in two places at once. \n\nI would like an app/program that I can put the address of the podcast in, tell it to go to a download location, and wait. I don\u2019t think it\u2019s that complicated, either save to a hard drive, or point it toward my NAS and be done with it. \n\nAny suggestions for a better reliable solution, would be very much appreciated.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to start properly archiving podcasts. Any suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqvcs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702401087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been attempting this on and off for years, but never found anything that works long term. I have both Pc and Mac but was predominantly using Mac until recently. I was devoted to Downcast, but it started becoming unreliable for macOS Monterey operating system, I switched to Mimir, but that was saving in two places at once. &lt;/p&gt;\n\n&lt;p&gt;I would like an app/program that I can put the address of the podcast in, tell it to go to a download location, and wait. I don\u2019t think it\u2019s that complicated, either save to a hard drive, or point it toward my NAS and be done with it. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions for a better reliable solution, would be very much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gqvcs", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gqvcs/want_to_start_properly_archiving_podcasts_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gqvcs/want_to_start_properly_archiving_podcasts_any/", "subreddit_subscribers": 717957, "created_utc": 1702401087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I think I already know the answer to this, but I wanted a sanity check just to be sure. I am running majaro with a 5 disk ZFS raid 5 configuration (5x4TB) for a total usable space of 16TB.  I'm getting pretty close to fulll (90%+ utilization) and picked up 3x18TB drives.  Looking to do another Raid 5 setup so 2+1 still gets me 36TB of usable space. \n\nMy question is: is there any way to slot in the 3 larger drives into the existing array, reconfigure (somehow) to only use the 3 disks, and then pull out the 2 extra 4TB drives?  Or is my best bet to backup, nuke, and start from scratch?", "author_fullname": "t2_16qws1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS Raid 5 Setup (5 Disks) upgrade to fewer disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18grag3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702402147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think I already know the answer to this, but I wanted a sanity check just to be sure. I am running majaro with a 5 disk ZFS raid 5 configuration (5x4TB) for a total usable space of 16TB.  I&amp;#39;m getting pretty close to fulll (90%+ utilization) and picked up 3x18TB drives.  Looking to do another Raid 5 setup so 2+1 still gets me 36TB of usable space. &lt;/p&gt;\n\n&lt;p&gt;My question is: is there any way to slot in the 3 larger drives into the existing array, reconfigure (somehow) to only use the 3 disks, and then pull out the 2 extra 4TB drives?  Or is my best bet to backup, nuke, and start from scratch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18grag3", "is_robot_indexable": true, "report_reasons": null, "author": "crono141", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18grag3/zfs_raid_5_setup_5_disks_upgrade_to_fewer_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18grag3/zfs_raid_5_setup_5_disks_upgrade_to_fewer_disks/", "subreddit_subscribers": 717957, "created_utc": 1702402147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm building a NAS and have opted to use Windows 11 out of sheer simplicity of setup(though I am open to suggestions that meet my requirements). I already have everything I need(arr's, qbit, PIA(everything running through PIA), remote desktop, etc) running perfectly fine on Windows 10, so upgrading will be little more than a formality. The only key I'm missing is drive pooling software. Right now I just have media libraries split across drives. Obviously not a good solution and something that has to change. So, what's the best drive pooling software for windows 11?\n\n&amp;#x200B;\n\nThanks, TC370", "author_fullname": "t2_542g2ndg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best Drive Pooling software on windows 11?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqt3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a NAS and have opted to use Windows 11 out of sheer simplicity of setup(though I am open to suggestions that meet my requirements). I already have everything I need(arr&amp;#39;s, qbit, PIA(everything running through PIA), remote desktop, etc) running perfectly fine on Windows 10, so upgrading will be little more than a formality. The only key I&amp;#39;m missing is drive pooling software. Right now I just have media libraries split across drives. Obviously not a good solution and something that has to change. So, what&amp;#39;s the best drive pooling software for windows 11?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks, TC370&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18gqt3c", "is_robot_indexable": true, "report_reasons": null, "author": "Thiscave3701365", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18gqt3c/whats_the_best_drive_pooling_software_on_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18gqt3c/whats_the_best_drive_pooling_software_on_windows/", "subreddit_subscribers": 717957, "created_utc": 1702400936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like, if you love seeing the files transfer in time, live. Love seeing the speed that it takes to transfer them and how cool it feels to have them in your HDD. Does the whole process of it feel good to you?  \n\n\nI am someone that finally switched from cloud storage and I can say that locally, it just feels much better.", "author_fullname": "t2_pzcs0b20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do y\u2019all get any type of satisfaction while transferring files to y\u2019all\u2019s HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hjdb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702481484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like, if you love seeing the files transfer in time, live. Love seeing the speed that it takes to transfer them and how cool it feels to have them in your HDD. Does the whole process of it feel good to you?  &lt;/p&gt;\n\n&lt;p&gt;I am someone that finally switched from cloud storage and I can say that locally, it just feels much better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18hjdb4", "is_robot_indexable": true, "report_reasons": null, "author": "ImHidingtheRealMe", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18hjdb4/do_yall_get_any_type_of_satisfaction_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18hjdb4/do_yall_get_any_type_of_satisfaction_while/", "subreddit_subscribers": 717957, "created_utc": 1702481484.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}