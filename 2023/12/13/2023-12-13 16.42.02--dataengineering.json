{"kind": "Listing", "data": {"after": "t3_18hgueg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Other than \"creating data pipelines over, and over again\" or \"practicing\", what are some things that have radically improved your data engineering skills?\n\ne.g.\n\n* Making each discrete phase of a given pipeline dumber (i.e. simpler, easier to deliver, easier to replace)\n* Starting with a dumb Python script almost every time, and making it more robust over time\n* Just getting started, and making things pretty later\n* Using a particular data pipeline orchestrator because &lt;x&gt;\n* Analyzing data a particular way before getting started\n* Creating documentation &lt;y&gt; before getting started\n* Sketching data composition and lineage out with pen and paper\n* Sketching out your data pipeline with pen and paper\n* Rendering your data pipeline using GraphViz and DOT markup, etc. so you can better visualize the structure of your data pipelines\n\nEDIT: if this is too vague, or a bad fit, I'll delete it, just let me know - AFAIK how you build things and the process by which you decide to build things is just as important as what tools you use to build those things - i.e., software architecture matters when developing software - but, I don't know - just, let me know.", "author_fullname": "t2_lwr1wvz8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some things that have radically improved your data engineering skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hgf31", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702484360.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702472862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Other than &amp;quot;creating data pipelines over, and over again&amp;quot; or &amp;quot;practicing&amp;quot;, what are some things that have radically improved your data engineering skills?&lt;/p&gt;\n\n&lt;p&gt;e.g.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Making each discrete phase of a given pipeline dumber (i.e. simpler, easier to deliver, easier to replace)&lt;/li&gt;\n&lt;li&gt;Starting with a dumb Python script almost every time, and making it more robust over time&lt;/li&gt;\n&lt;li&gt;Just getting started, and making things pretty later&lt;/li&gt;\n&lt;li&gt;Using a particular data pipeline orchestrator because &amp;lt;x&amp;gt;&lt;/li&gt;\n&lt;li&gt;Analyzing data a particular way before getting started&lt;/li&gt;\n&lt;li&gt;Creating documentation &amp;lt;y&amp;gt; before getting started&lt;/li&gt;\n&lt;li&gt;Sketching data composition and lineage out with pen and paper&lt;/li&gt;\n&lt;li&gt;Sketching out your data pipeline with pen and paper&lt;/li&gt;\n&lt;li&gt;Rendering your data pipeline using GraphViz and DOT markup, etc. so you can better visualize the structure of your data pipelines&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;EDIT: if this is too vague, or a bad fit, I&amp;#39;ll delete it, just let me know - AFAIK how you build things and the process by which you decide to build things is just as important as what tools you use to build those things - i.e., software architecture matters when developing software - but, I don&amp;#39;t know - just, let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hgf31", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Importance-1605", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18hgf31/what_are_some_things_that_have_radically_improved/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hgf31/what_are_some_things_that_have_radically_improved/", "subreddit_subscribers": 145660, "created_utc": 1702472862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been with my current company for about six months, and in that time, I've not only developed data pipelines but also found myself building the team-specific dashboards they feed into. Back at my old job, things were a bit different. I worked alongside an analyst who took care of the dashboards. They would give me the business needs, and I'd tailor the data pipelines to suit those requirements and the analysis being done. Personally, I don't think dashboard building is really part of a data engineer's job, but I'm curious to hear what others in this group think. Have you had similar experiences?", "author_fullname": "t2_103ndz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much dashboarding / viz do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h7vek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702439534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been with my current company for about six months, and in that time, I&amp;#39;ve not only developed data pipelines but also found myself building the team-specific dashboards they feed into. Back at my old job, things were a bit different. I worked alongside an analyst who took care of the dashboards. They would give me the business needs, and I&amp;#39;d tailor the data pipelines to suit those requirements and the analysis being done. Personally, I don&amp;#39;t think dashboard building is really part of a data engineer&amp;#39;s job, but I&amp;#39;m curious to hear what others in this group think. Have you had similar experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18h7vek", "is_robot_indexable": true, "report_reasons": null, "author": "natelifts", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h7vek/how_much_dashboarding_viz_do_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h7vek/how_much_dashboarding_viz_do_you_do/", "subreddit_subscribers": 145660, "created_utc": 1702439534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been modeling NBA data for a couple months, and this is one of my favorite insights so far!\n\n\\- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python  \n\\- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp; Snowflake (Production)  \n\\- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: [paradime.io](https://www.linkedin.com/company/paradimelabs/) (dbt)  \n\\- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - [Lightdash](https://www.linkedin.com/company/lightdash/)\n\nSo, why do the Jazz have the lowest avg. cost per win?  \n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&gt; Malone, Great home-court advantage, stable coaching.  \n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)  \n\ud83e\ude84 Salt Lake City doesn't attract top (expensive) NBA talent \ud83e\udd23  \n\ud83e\ude84 Consistent &amp; competent leadership  \nSeparate note - I'm still shocked by how terrible the Knicks have been historically. They're the biggest market, they're willing to spend (obviously) yet they can't pull it together... Ever\n\nYou can find, critique, and contribute to my NBA project here: [https://github.com/jpooksy/NBA\\_Data\\_Modeling](https://github.com/jpooksy/NBA_Data_Modeling)  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA data modeling wth dbt + Paradime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lrw4oybekw5c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 130, "x": 108, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49598bbed60ac1dfad30e730226a940d1617ac82"}, {"y": 261, "x": 216, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2633eed8b2e34880131642200e2dacb2083d1b71"}, {"y": 386, "x": 320, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1ad4371601d2889998d2164deba121e4f822f96"}], "s": {"y": 682, "x": 564, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960"}, "id": "lrw4oybekw5c1"}}, "name": "t3_18grxlj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_pUtcBckyyefRo0H27ezy2qeaxhbYnsrdXQXQjFIhAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702403763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been modeling NBA data for a couple months, and this is one of my favorite insights so far!&lt;/p&gt;\n\n&lt;p&gt;- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python&lt;br/&gt;\n- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp;amp; Snowflake (Production)&lt;br/&gt;\n- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: &lt;a href=\"https://www.linkedin.com/company/paradimelabs/\"&gt;paradime.io&lt;/a&gt; (dbt)&lt;br/&gt;\n- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - &lt;a href=\"https://www.linkedin.com/company/lightdash/\"&gt;Lightdash&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So, why do the Jazz have the lowest avg. cost per win?&lt;br/&gt;\n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&amp;gt; Malone, Great home-court advantage, stable coaching.&lt;br/&gt;\n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)&lt;br/&gt;\n\ud83e\ude84 Salt Lake City doesn&amp;#39;t attract top (expensive) NBA talent \ud83e\udd23&lt;br/&gt;\n\ud83e\ude84 Consistent &amp;amp; competent leadership&lt;br/&gt;\nSeparate note - I&amp;#39;m still shocked by how terrible the Knicks have been historically. They&amp;#39;re the biggest market, they&amp;#39;re willing to spend (obviously) yet they can&amp;#39;t pull it together... Ever&lt;/p&gt;\n\n&lt;p&gt;You can find, critique, and contribute to my NBA project here: &lt;a href=\"https://github.com/jpooksy/NBA_Data_Modeling\"&gt;https://github.com/jpooksy/NBA_Data_Modeling&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960\"&gt;https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18grxlj", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "subreddit_subscribers": 145660, "created_utc": 1702403763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, Dear Data Engineers!\n\nI wrote a [blog post](https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der) about solving the **User ID Stitching** problem with Recursive SQL. You can use this in DBT with data warehouses supporting recursive CTEs.\n\n&gt;The **User ID Stitching** problem concerns primarily **B2C companies** that want to measure marketing, product, and sales metrics correctly. It is about creating a **user\\_aliases** table that maps all possible user identifiers for every user across all datasets  to a single **merged\\_id**\n\n**Possible user identifiers:**\n\n* device\\_id\n* user\\_id\n* anonymous\\_user\\_id\n* email\n* contact\\_id (Hubspot)\n* customer\\_id (Stripe)\n* \u2026 etc\u2026\n\nYou can then use the **merge\\_id** to join across all datasets, count unique users correctly, create funnel queries across all datasets, etc.I hope it helps whoever it may help :)\n\nLink to the [blog post](https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der)", "author_fullname": "t2_gnytqihqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "User ID Stitching with Recursive SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hc4jz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702482416.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702455492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, Dear Data Engineers!&lt;/p&gt;\n\n&lt;p&gt;I wrote a &lt;a href=\"https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der\"&gt;blog post&lt;/a&gt; about solving the &lt;strong&gt;User ID Stitching&lt;/strong&gt; problem with Recursive SQL. You can use this in DBT with data warehouses supporting recursive CTEs.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The &lt;strong&gt;User ID Stitching&lt;/strong&gt; problem concerns primarily &lt;strong&gt;B2C companies&lt;/strong&gt; that want to measure marketing, product, and sales metrics correctly. It is about creating a &lt;strong&gt;user_aliases&lt;/strong&gt; table that maps all possible user identifiers for every user across all datasets  to a single &lt;strong&gt;merged_id&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Possible user identifiers:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;device_id&lt;/li&gt;\n&lt;li&gt;user_id&lt;/li&gt;\n&lt;li&gt;anonymous_user_id&lt;/li&gt;\n&lt;li&gt;email&lt;/li&gt;\n&lt;li&gt;contact_id (Hubspot)&lt;/li&gt;\n&lt;li&gt;customer_id (Stripe)&lt;/li&gt;\n&lt;li&gt;\u2026 etc\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can then use the &lt;strong&gt;merge_id&lt;/strong&gt; to join across all datasets, count unique users correctly, create funnel queries across all datasets, etc.I hope it helps whoever it may help :)&lt;/p&gt;\n\n&lt;p&gt;Link to the &lt;a href=\"https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der\"&gt;blog post&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?auto=webp&amp;s=0d093ce954e3041f48a37532a5dcaf93dc69e403", "width": 1776, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc79b8bbb10e9f68c1d1d6c86af1f3841dc4f10e", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c07e77a7075812c321c03396caabe8b0df20257", "width": 216, "height": 97}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3ef5435010e00eaf07797ddfcec9de3febd41ce", "width": 320, "height": 144}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b745bec61cacf775819bc9c0dee5dc03fbf29420", "width": 640, "height": 288}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49e6f8c7db99048714c1629660d5ca625c2c9ba6", "width": 960, "height": 432}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32c1b03ffdc645de4619500f6d9673e4f4fcb49a", "width": 1080, "height": 486}], "variants": {}, "id": "PNhHEjsZUew5p0U0EcK53-ZbVngG-Nb-Q0Qqg7c5UcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18hc4jz", "is_robot_indexable": true, "report_reasons": null, "author": "MitzuIstvan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hc4jz/user_id_stitching_with_recursive_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hc4jz/user_id_stitching_with_recursive_sql/", "subreddit_subscribers": 145660, "created_utc": 1702455492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into a discussion with a visualization engineer who insists that never in her career had they created materialized views or regular views specific to a dashboard element. \nI\u2019m not in visualization, so honestly don\u2019t even have context to decide if this person\u2019s perspective is reasonable. From my perspective, as a dashboard is designed for a larger audience, if dealing with data from multiple tables, of course it makes sense to do this work upstream. Am I crazy here?", "author_fullname": "t2_5s7getlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pattern: Table or View per Dashboard Element", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gv87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702412142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into a discussion with a visualization engineer who insists that never in her career had they created materialized views or regular views specific to a dashboard element. \nI\u2019m not in visualization, so honestly don\u2019t even have context to decide if this person\u2019s perspective is reasonable. From my perspective, as a dashboard is designed for a larger audience, if dealing with data from multiple tables, of course it makes sense to do this work upstream. Am I crazy here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gv87y", "is_robot_indexable": true, "report_reasons": null, "author": "pro__acct__", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gv87y/pattern_table_or_view_per_dashboard_element/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gv87y/pattern_table_or_view_per_dashboard_element/", "subreddit_subscribers": 145660, "created_utc": 1702412142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_artaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What it's like watching performance tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_18h8vaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p-ScxshpaIH0LpOXfbiGYg_scjII6-q45KRcSku5VHE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702442790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/abq9civ6sz5c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/abq9civ6sz5c1.png?auto=webp&amp;s=8b185af5c90f3b84ccb0159c6b0d7a19acfcb67d", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=19733133c2e33da130bb2cc44e3903397044da4c", "width": 108, "height": 61}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d298fc84454e747f4142361fe3c2395ed7f728d3", "width": 216, "height": 123}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf8a5a0fe428bd9b9d43ec2081f14ca243adc9ac", "width": 320, "height": 182}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=674624077c2d64c5762ac4a3c5325f44a0c530ab", "width": 640, "height": 365}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d272489210b302a0b7f32c8b5623768d4cd14da5", "width": 960, "height": 548}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b087a167c1eed7ae6ccd1098f3f95280496ee499", "width": 1080, "height": 617}], "variants": {}, "id": "A-qG__OJXA_ovT6p9YyJ08z42GO-MzxjPebbjk5kS6U"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "18h8vaw", "is_robot_indexable": true, "report_reasons": null, "author": "Toasty_toaster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h8vaw/what_its_like_watching_performance_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/abq9civ6sz5c1.png", "subreddit_subscribers": 145660, "created_utc": 1702442790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The article shows you all the important differences between DuckDB/MotherDuck and other databases, including results from the first iteration of performance tests.  \n\n\n[https://medium.com/gooddata-developers/is-motherduck-producktion-ready-a3a0347715c5](https://medium.com/gooddata-developers/is-motherduck-producktion-ready-a3a0347715c5)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is MotherDuck ProDUCKtion-Ready?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hdjry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702461903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The article shows you all the important differences between DuckDB/MotherDuck and other databases, including results from the first iteration of performance tests.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/gooddata-developers/is-motherduck-producktion-ready-a3a0347715c5\"&gt;https://medium.com/gooddata-developers/is-motherduck-producktion-ready-a3a0347715c5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?auto=webp&amp;s=464e982e8535936416c81b255d265e379a74453f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f22bd0b7a1eba0df9818d95987df2e90ff804a47", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8808f867b2bc9b7afc8ee262e583033c0002a3f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=770ea05dd5058890d39eea27d143849e95b9e0aa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b59f97e63fc83024129cf7a2e06b0c10401108aa", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9212e28c7f173a8df84f72500c4e1c5753b40e00", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/oYI3oqL44mavsShI5_lKc4btUA_xK8RPhIL_vdYdB1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d1558c54756703b248d71fde44619e7999fd4bd", "width": 1080, "height": 565}], "variants": {}, "id": "2XijoLGCZ5b01Blb6hT-fjIRZbscSJzrmSkZT1Q49_g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18hdjry", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hdjry/is_motherduck_producktionready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hdjry/is_motherduck_producktionready/", "subreddit_subscribers": 145660, "created_utc": 1702461903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading Jobs Code between Databricks Runtime Versions Made Easier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_18gq1fy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vHriYbg9RY72KUXRAAYKX7WkPAf_TJCsD36ioLiCkEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702399004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?auto=webp&amp;s=e6fff503363810a1a844243d4dc30e20374a7e61", "width": 1200, "height": 639}, "resolutions": [{"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b1bd7c5baa426d324568692cf26b63002b7b9ab", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=632346f8e065aae9f74ea8fe594679ac441da0d7", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a7c5312e6d82b74496104ca1ba5fd37d8edfc97", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d87a636f09f8ab2bf8a00a4eee4eae61323608f8", "width": 640, "height": 340}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9002d9c593d7a4124e0ce8d3e0cba46f56a69233", "width": 960, "height": 511}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a322c150c48715bdd366d61e7a96a10d7e03776c", "width": 1080, "height": 575}], "variants": {}, "id": "uhonE0yWOOsFkvPBPnnGD6Eg9m5tkICAwlDw0bCdu6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gq1fy", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gq1fy/upgrading_jobs_code_between_databricks_runtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "subreddit_subscribers": 145660, "created_utc": 1702399004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a cross-disciplinary Big Data (Engineering, Science) Master's degree, i have done an internship as a assistant DE then the company hired me as a junior DE. But i didn't really stuck to DE, of course i made a lot of pipelines from ingestion to exports...etc and all usual Data Engineer tasks. But i also did a lot (like really a lot) of Data Viz and some analysis (either descriptive or predictive). With great results for our company, and that's something i like doing.   \nNow the company is growing, we recently hired a huge data analysts team, that took over all the data analysis and data viz perimeter, and i kinda feel limited in my scope as i do really well in this hybrid role and i wanted to learn some ML (i have all the major certifications in the technologies we're already using like GCP professional DE)   \nAs i'm still \"new\" and young, i want to ask to the more experienced ones here what is a realistic career path for a \"DE\" that likes the business side of Data. Is it some like of utopia if i'm thinking to have some hybrid role that goes through all the Data lifecyle ? Especially in big companies", "author_fullname": "t2_7twd1xfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After 2 years as a DE, i don't know where my career path is going", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h1u2e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702425940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a cross-disciplinary Big Data (Engineering, Science) Master&amp;#39;s degree, i have done an internship as a assistant DE then the company hired me as a junior DE. But i didn&amp;#39;t really stuck to DE, of course i made a lot of pipelines from ingestion to exports...etc and all usual Data Engineer tasks. But i also did a lot (like really a lot) of Data Viz and some analysis (either descriptive or predictive). With great results for our company, and that&amp;#39;s something i like doing.&lt;br/&gt;\nNow the company is growing, we recently hired a huge data analysts team, that took over all the data analysis and data viz perimeter, and i kinda feel limited in my scope as i do really well in this hybrid role and i wanted to learn some ML (i have all the major certifications in the technologies we&amp;#39;re already using like GCP professional DE)&lt;br/&gt;\nAs i&amp;#39;m still &amp;quot;new&amp;quot; and young, i want to ask to the more experienced ones here what is a realistic career path for a &amp;quot;DE&amp;quot; that likes the business side of Data. Is it some like of utopia if i&amp;#39;m thinking to have some hybrid role that goes through all the Data lifecyle ? Especially in big companies&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18h1u2e", "is_robot_indexable": true, "report_reasons": null, "author": "BennyLauren", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h1u2e/after_2_years_as_a_de_i_dont_know_where_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h1u2e/after_2_years_as_a_de_i_dont_know_where_my_career/", "subreddit_subscribers": 145660, "created_utc": 1702425940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Data Processing with Ray Data and MinIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_18gskm2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uzAf_NxB0nLPzpd6yZHTuYbIip8pyxSiP67aPyuEhSU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702405394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?auto=webp&amp;s=60a9a5bb13ad52dc6f983d22a24a53b3b835a119", "width": 1200, "height": 359}, "resolutions": [{"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db2aa38b11de95fa42f9dbf716d73c3b2a64e4f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c18b4e8bc4062930b8490b5721bf20e5d91b96a", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e065467bf6807e1f7014eb05a7e8aef79c5b4e88", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74d1b5b114a455946e7c372fa0cc71907ebdd6dd", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d0ea6ae4d3f00a6c97c690b38471318183ee2c8", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=011a2c8ca8070e4782e8cf151170e64f2db7fd85", "width": 1080, "height": 323}], "variants": {}, "id": "ycJVbgf3bDDq06hpn_WuGtC2gZGgwo5DkVBTrJOe5j8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gskm2", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gskm2/distributed_data_processing_with_ray_data_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "subreddit_subscribers": 145660, "created_utc": 1702405394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, what are you interested to know about orchestrators? \n\nI am looking to do a deep dive on the more popular ones and write about it. \n\nWhat I am interested to understand is what use cases are each of them best at, and the kinds of criteria **you** use to make that choice.  \n\n\nSo my questions to you are:\n\n  \n**- what do you want to know about orchestrators?**\n\n**- what would you compare them on?**\n\n\\- **what killer features or orchestrators do you think I should check out and investigate?**  \n\n\nCurrently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we'll dig in :)  \n\n\nThanks in advance!\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want to know about orchestrators?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqg6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, what are you interested to know about orchestrators? &lt;/p&gt;\n\n&lt;p&gt;I am looking to do a deep dive on the more popular ones and write about it. &lt;/p&gt;\n\n&lt;p&gt;What I am interested to understand is what use cases are each of them best at, and the kinds of criteria &lt;strong&gt;you&lt;/strong&gt; use to make that choice.  &lt;/p&gt;\n\n&lt;p&gt;So my questions to you are:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what do you want to know about orchestrators?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what would you compare them on?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;what killer features or orchestrators do you think I should check out and investigate?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Currently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we&amp;#39;ll dig in :)  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gqg6q", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "subreddit_subscribers": 145660, "created_utc": 1702400055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, hope you are okay!\n\nSo, I work for a big company where we develop demands coming from other sectors.\n\nEach project has it's own particularities but in a nutshell it follows the \"Data ingestion, data trasnformation and data serving\" path\n\nIn many projects I face a situation where the project gets blocked because something is missing and this blocking could be avoided with a little bit more planning before we started it.\n\nI would like to know if you guys have a kind of \"check list\" of what you need to have before start a project?\n\n&amp;#x200B;", "author_fullname": "t2_84jw5rk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering project kickof checklist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hglcf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702473448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, hope you are okay!&lt;/p&gt;\n\n&lt;p&gt;So, I work for a big company where we develop demands coming from other sectors.&lt;/p&gt;\n\n&lt;p&gt;Each project has it&amp;#39;s own particularities but in a nutshell it follows the &amp;quot;Data ingestion, data trasnformation and data serving&amp;quot; path&lt;/p&gt;\n\n&lt;p&gt;In many projects I face a situation where the project gets blocked because something is missing and this blocking could be avoided with a little bit more planning before we started it.&lt;/p&gt;\n\n&lt;p&gt;I would like to know if you guys have a kind of &amp;quot;check list&amp;quot; of what you need to have before start a project?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hglcf", "is_robot_indexable": true, "report_reasons": null, "author": "El_Balde_K", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hglcf/data_engineering_project_kickof_checklist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hglcf/data_engineering_project_kickof_checklist/", "subreddit_subscribers": 145660, "created_utc": 1702473448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn the the discussions around bronze layers / staging areas it is always said that the raw data should be stored (and never changed). However one aspect that is barely discussed in my opinion is how to ensure data protection e.g. GDPR in that data. \n\nIn my case we are not allowed to have any non-pseudonymized personal data stored. Therefore we already do transformations to do that before storing in \"bronze\". \nAlso data deletion on specific rules needs to take place in bronze. Since we work with json data where important identifiers are nested in the data this is quite complex.\n\nWhat are your experiences and opinions on this?", "author_fullname": "t2_rydqu8m3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GDPR in Bronze / Staging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18haxma", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702450447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In the the discussions around bronze layers / staging areas it is always said that the raw data should be stored (and never changed). However one aspect that is barely discussed in my opinion is how to ensure data protection e.g. GDPR in that data. &lt;/p&gt;\n\n&lt;p&gt;In my case we are not allowed to have any non-pseudonymized personal data stored. Therefore we already do transformations to do that before storing in &amp;quot;bronze&amp;quot;. \nAlso data deletion on specific rules needs to take place in bronze. Since we work with json data where important identifiers are nested in the data this is quite complex.&lt;/p&gt;\n\n&lt;p&gt;What are your experiences and opinions on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18haxma", "is_robot_indexable": true, "report_reasons": null, "author": "DecisionAgile7326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18haxma/gdpr_in_bronze_staging/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18haxma/gdpr_in_bronze_staging/", "subreddit_subscribers": 145660, "created_utc": 1702450447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title basically. using azure devOps on prem for build.", "author_fullname": "t2_slq927f8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how are ms sql server DBs deployed on-prem using ci/cd?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h30tl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702428163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title basically. using azure devOps on prem for build.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18h30tl", "is_robot_indexable": true, "report_reasons": null, "author": "Senior-Release930", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h30tl/how_are_ms_sql_server_dbs_deployed_onprem_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h30tl/how_are_ms_sql_server_dbs_deployed_onprem_using/", "subreddit_subscribers": 145660, "created_utc": 1702428163.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization has an existing data engineering software stack but I have a large new project in the pipeline that will be supported by a dedicated team outside of our existing DE group.  I, as as solutions architect, am free to choose a new software stack for this project, although I do see value in using our existing toolsets and not creating duplicate solutions.  If funding wasn't a big issue, what solutions would you deploy today?  My only constraint is that it will be deployed in Azure.  Here's our current landscape:\n\nScheduling &amp; pipelines: Tidal\n\nETL for integrations: Talend\n\nData lake/warehouse: Snowflake\n\nAI/ML for DE: Databricks\n\nSQL-based transformations: dbt\n\nThanks!", "author_fullname": "t2_9lsmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What software stack would you choose if you were starting from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18hjcy6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702481458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization has an existing data engineering software stack but I have a large new project in the pipeline that will be supported by a dedicated team outside of our existing DE group.  I, as as solutions architect, am free to choose a new software stack for this project, although I do see value in using our existing toolsets and not creating duplicate solutions.  If funding wasn&amp;#39;t a big issue, what solutions would you deploy today?  My only constraint is that it will be deployed in Azure.  Here&amp;#39;s our current landscape:&lt;/p&gt;\n\n&lt;p&gt;Scheduling &amp;amp; pipelines: Tidal&lt;/p&gt;\n\n&lt;p&gt;ETL for integrations: Talend&lt;/p&gt;\n\n&lt;p&gt;Data lake/warehouse: Snowflake&lt;/p&gt;\n\n&lt;p&gt;AI/ML for DE: Databricks&lt;/p&gt;\n\n&lt;p&gt;SQL-based transformations: dbt&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hjcy6", "is_robot_indexable": true, "report_reasons": null, "author": "dantasticdotorg", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hjcy6/what_software_stack_would_you_choose_if_you_were/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hjcy6/what_software_stack_would_you_choose_if_you_were/", "subreddit_subscribers": 145660, "created_utc": 1702481458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Regarding the aggregation of heterogeneous data imported by different pipelines, what is your opinion on performing the aggregation as much upstream or further down as possible?\n\nI've recently seen people in conferences suggesting to transform data as much upstream as possible to generate a single core model used to populate different target tables. I understand the idea that all the subsequent join operations will be more efficient due to having all the transformations done upstream, but I'm not really convinced that this might be a good approach since it implies a sacrifice in modularity. For example, we would lose the ability to rerun a single target without aggregating all the data from different sources first.  \na) Example of aggregation upstream:  \n\n\nhttps://preview.redd.it/88vk8dy9o26c1.png?width=798&amp;format=png&amp;auto=webp&amp;s=f69201070358bd6451b433054f2ae318e0d6dbfb\n\n  \nb) Example of aggregation downstream:  \n\n\nhttps://preview.redd.it/u0d2dvwdo26c1.png?width=554&amp;format=png&amp;auto=webp&amp;s=1993397031a042752778561f7d5fde0a3e3fdc8c\n\nThe main disadvantage I see in option a) is that an issue in a single pipeline gets propagated to all other models as well, while with option b) we still preserve the ability to rerun each single pipeline independently.", "author_fullname": "t2_vo4giaww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices on heterogeneous pipeline imports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u0d2dvwdo26c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/u0d2dvwdo26c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f225d065722648dd3f0cd8b9ef6fe51c41f99818"}, {"y": 96, "x": 216, "u": "https://preview.redd.it/u0d2dvwdo26c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c25ed9d364b7dfca74d0914a0eef5073e4f7fd3"}, {"y": 143, "x": 320, "u": "https://preview.redd.it/u0d2dvwdo26c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f08949c5a1a2486b1c2cdcb129937268f0a8419c"}], "s": {"y": 248, "x": 554, "u": "https://preview.redd.it/u0d2dvwdo26c1.png?width=554&amp;format=png&amp;auto=webp&amp;s=1993397031a042752778561f7d5fde0a3e3fdc8c"}, "id": "u0d2dvwdo26c1"}, "88vk8dy9o26c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/88vk8dy9o26c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c3e9dce7679c3aed3dbc2a61e54c88c6c605496"}, {"y": 65, "x": 216, "u": "https://preview.redd.it/88vk8dy9o26c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e03b10b4636d893849298d4edb52f6186a0c822"}, {"y": 96, "x": 320, "u": "https://preview.redd.it/88vk8dy9o26c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=83cddbf66bf59cb424ecf0b12b25986c10ac1006"}, {"y": 193, "x": 640, "u": "https://preview.redd.it/88vk8dy9o26c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b4f18fa0c2152be9aadea07e6dc95014b837dcb"}], "s": {"y": 241, "x": 798, "u": "https://preview.redd.it/88vk8dy9o26c1.png?width=798&amp;format=png&amp;auto=webp&amp;s=f69201070358bd6451b433054f2ae318e0d6dbfb"}, "id": "88vk8dy9o26c1"}}, "name": "t3_18hi6zy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rGWvMoGtBzM-VbFy4OTj3OrFCDswU48h5proIGCxwkQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702478250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Regarding the aggregation of heterogeneous data imported by different pipelines, what is your opinion on performing the aggregation as much upstream or further down as possible?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently seen people in conferences suggesting to transform data as much upstream as possible to generate a single core model used to populate different target tables. I understand the idea that all the subsequent join operations will be more efficient due to having all the transformations done upstream, but I&amp;#39;m not really convinced that this might be a good approach since it implies a sacrifice in modularity. For example, we would lose the ability to rerun a single target without aggregating all the data from different sources first.&lt;br/&gt;\na) Example of aggregation upstream:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/88vk8dy9o26c1.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f69201070358bd6451b433054f2ae318e0d6dbfb\"&gt;https://preview.redd.it/88vk8dy9o26c1.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f69201070358bd6451b433054f2ae318e0d6dbfb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;b) Example of aggregation downstream:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/u0d2dvwdo26c1.png?width=554&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1993397031a042752778561f7d5fde0a3e3fdc8c\"&gt;https://preview.redd.it/u0d2dvwdo26c1.png?width=554&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1993397031a042752778561f7d5fde0a3e3fdc8c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The main disadvantage I see in option a) is that an issue in a single pipeline gets propagated to all other models as well, while with option b) we still preserve the ability to rerun each single pipeline independently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hi6zy", "is_robot_indexable": true, "report_reasons": null, "author": "LnYmte", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hi6zy/best_practices_on_heterogeneous_pipeline_imports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hi6zy/best_practices_on_heterogeneous_pipeline_imports/", "subreddit_subscribers": 145660, "created_utc": 1702478250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing the fundamentals of dbt course right now and came across the following:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/snw7lecr326c1.png?width=1838&amp;format=png&amp;auto=webp&amp;s=29cf9cafb2922f6bbe5c177381f90f9cea7d7400\n\n&amp;#x200B;\n\nThey specify a test in some documentation file (yaml).\n\nI wonder why is this done on this level and not on the level of sql constraints?\n\nI skimmed a thread a found a comment where [someone argued](https://www.reddit.com/r/dataengineering/comments/119s7yv/comment/j9ozeus/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button) that dbt is good for when one can live (has) dirty data and hence has not enforced the level of data completeness as done with sql constraints.\n\n&amp;#x200B;\n\nWhat is the philosophy there?\n\nWhy would I even consider living with dirty data? Is my goal as an engineer not to keep data records clean and sort the completeness out on the level where transactions (i.e. updates) are handled?", "author_fullname": "t2_1b2msvdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why testing in dbt? why live with dirty data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 47, "top_awarded_type": null, "hide_score": false, "media_metadata": {"snw7lecr326c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/snw7lecr326c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dcdfdcc4acf994e7dea6193fb88688aeaa8a0129"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/snw7lecr326c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac27c1ed016e48de40ac4fb89df5d0f51400e6a5"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/snw7lecr326c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=463eeaecda7aea123587ca48ce6aa9b67568bd79"}, {"y": 219, "x": 640, "u": "https://preview.redd.it/snw7lecr326c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ebcf00dce7fc5f281758d0ba1f223237238a4fb"}, {"y": 329, "x": 960, "u": "https://preview.redd.it/snw7lecr326c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8ad4f1c57916a9c19c40e918897dd1f82e39449d"}, {"y": 370, "x": 1080, "u": "https://preview.redd.it/snw7lecr326c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=769012686b0bfed9e39949fe00466e3971b66dad"}], "s": {"y": 630, "x": 1838, "u": "https://preview.redd.it/snw7lecr326c1.png?width=1838&amp;format=png&amp;auto=webp&amp;s=29cf9cafb2922f6bbe5c177381f90f9cea7d7400"}, "id": "snw7lecr326c1"}}, "name": "t3_18hfvkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TEifI7eBZWLbs2l77WkdatkskdQfmD-Qq6dGuIAzlio.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702471054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing the fundamentals of dbt course right now and came across the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/snw7lecr326c1.png?width=1838&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=29cf9cafb2922f6bbe5c177381f90f9cea7d7400\"&gt;https://preview.redd.it/snw7lecr326c1.png?width=1838&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=29cf9cafb2922f6bbe5c177381f90f9cea7d7400&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;They specify a test in some documentation file (yaml).&lt;/p&gt;\n\n&lt;p&gt;I wonder why is this done on this level and not on the level of sql constraints?&lt;/p&gt;\n\n&lt;p&gt;I skimmed a thread a found a comment where &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/119s7yv/comment/j9ozeus/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button\"&gt;someone argued&lt;/a&gt; that dbt is good for when one can live (has) dirty data and hence has not enforced the level of data completeness as done with sql constraints.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is the philosophy there?&lt;/p&gt;\n\n&lt;p&gt;Why would I even consider living with dirty data? Is my goal as an engineer not to keep data records clean and sort the completeness out on the level where transactions (i.e. updates) are handled?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hfvkl", "is_robot_indexable": true, "report_reasons": null, "author": "HillTheBilly", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hfvkl/why_testing_in_dbt_why_live_with_dirty_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hfvkl/why_testing_in_dbt_why_live_with_dirty_data/", "subreddit_subscribers": 145660, "created_utc": 1702471054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \n\n\n**Context:**\n\nI have a bit of a situation in my company due to the lack of skills of our data engineering team and BI team. I am in the DS team and honestly we are incredibly ahead from them in terms of DevOps practices, software design patterns, cloud architectural knowledge etc....\n\nI am trying to setup a common standard based on polars+delta lake+sql server (serving layer for power BI) to develop fast and cheap data pipelines.\n\nWe are trying to avoid using spark in our data processing workflows as we do not have the neither the data size not the in-house competence (I am the only one who knows spark in a company of around 2k employees). The DS team is willing to learn pyspark (as usual) but I think polars will have a very low learning curve for them instead of spark. Also, polars integrates nicely with duckDB so it seems a middle ground that can make everyone happy.\n\n**Current setup:**\n\nThe data engineers here are very old-fashioned and they use MSSQL as a data warehouse instead of using it only as OLTP. Some on-premise servers are very well modelled with Kimball and the loads are kind of okay in terms of performance but the central DW is a bit of a mess. The DE and BI team is mostly skillful with SQL and have very very very basic python knowledge (I think over the 10 members only one is able to write a class), so I thought of introducing polars + delta lake to them instead of going the spark way.\n\nAs a matter of comparison I have done a rewrite of one of their processes using polars and delta lake and I am able to make a full load in approx 4mins vs their 3h (they are not aware of this and I am not planning to share it as I dont want to take the refactoring on my shoulders). \n\nI am aware that due to their SQL knowledge probably DBT will be a better option but no one has the knowledge of DBT and they are very stuck with .DACPAC files deployment (a side note here, we had to build their CI CD pipelines for both .dacpac files and ADF workflows as they were deploying .dacpac files directly from the editor to production, without any integration test for ingesting new data or fake data with ADF). Also, DBT integration with SQL Server seems very poor in comparison with PostgreSQL systems. Finally we use azure and in ADF the easier way that I found to run dbt continously (outside the CI CD pipelines) is via an invocation of container instances (no one in these teams know how to use docker).\n\n**Problem I am trying to solve:**\n\nHowever I am afraid that I will face a lot of friction as they have a lot of data quality checks written in SQL. I am trying to find an equivalent to GE, Pandera or Dequee in Polars to make them their journey a bit easier.\n\nDoes someone knows about such tools? So far I can only think on using polars and switch to pandas for quality checks but seems to kill quite a lot of the performance gains that Im getting with polars.\n\nIs this a good idea at all? Honestly I think that putting dagster/airflow in AKS and then use the integration with DBT will be better for their setup but we are not skilfull with DBT in my team and if we are going to help them we would like to use technologies that we are a bit familiar with as currently they do not have the capabilities to go outside SQL Server.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_4aht7cg8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Equivalent of Great Expectations/Pandera/Dequee in Polars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hdotc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702462468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a bit of a situation in my company due to the lack of skills of our data engineering team and BI team. I am in the DS team and honestly we are incredibly ahead from them in terms of DevOps practices, software design patterns, cloud architectural knowledge etc....&lt;/p&gt;\n\n&lt;p&gt;I am trying to setup a common standard based on polars+delta lake+sql server (serving layer for power BI) to develop fast and cheap data pipelines.&lt;/p&gt;\n\n&lt;p&gt;We are trying to avoid using spark in our data processing workflows as we do not have the neither the data size not the in-house competence (I am the only one who knows spark in a company of around 2k employees). The DS team is willing to learn pyspark (as usual) but I think polars will have a very low learning curve for them instead of spark. Also, polars integrates nicely with duckDB so it seems a middle ground that can make everyone happy.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Current setup:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The data engineers here are very old-fashioned and they use MSSQL as a data warehouse instead of using it only as OLTP. Some on-premise servers are very well modelled with Kimball and the loads are kind of okay in terms of performance but the central DW is a bit of a mess. The DE and BI team is mostly skillful with SQL and have very very very basic python knowledge (I think over the 10 members only one is able to write a class), so I thought of introducing polars + delta lake to them instead of going the spark way.&lt;/p&gt;\n\n&lt;p&gt;As a matter of comparison I have done a rewrite of one of their processes using polars and delta lake and I am able to make a full load in approx 4mins vs their 3h (they are not aware of this and I am not planning to share it as I dont want to take the refactoring on my shoulders). &lt;/p&gt;\n\n&lt;p&gt;I am aware that due to their SQL knowledge probably DBT will be a better option but no one has the knowledge of DBT and they are very stuck with .DACPAC files deployment (a side note here, we had to build their CI CD pipelines for both .dacpac files and ADF workflows as they were deploying .dacpac files directly from the editor to production, without any integration test for ingesting new data or fake data with ADF). Also, DBT integration with SQL Server seems very poor in comparison with PostgreSQL systems. Finally we use azure and in ADF the easier way that I found to run dbt continously (outside the CI CD pipelines) is via an invocation of container instances (no one in these teams know how to use docker).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem I am trying to solve:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;However I am afraid that I will face a lot of friction as they have a lot of data quality checks written in SQL. I am trying to find an equivalent to GE, Pandera or Dequee in Polars to make them their journey a bit easier.&lt;/p&gt;\n\n&lt;p&gt;Does someone knows about such tools? So far I can only think on using polars and switch to pandas for quality checks but seems to kill quite a lot of the performance gains that Im getting with polars.&lt;/p&gt;\n\n&lt;p&gt;Is this a good idea at all? Honestly I think that putting dagster/airflow in AKS and then use the integration with DBT will be better for their setup but we are not skilfull with DBT in my team and if we are going to help them we would like to use technologies that we are a bit familiar with as currently they do not have the capabilities to go outside SQL Server.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18hdotc", "is_robot_indexable": true, "report_reasons": null, "author": "Lix021", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hdotc/equivalent_of_great_expectationspanderadequee_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hdotc/equivalent_of_great_expectationspanderadequee_in/", "subreddit_subscribers": 145660, "created_utc": 1702462468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to kafka. Want to understand its functionality and different use cases.", "author_fullname": "t2_q32966uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Eli5 Kafka learning resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h5f7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702432828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to kafka. Want to understand its functionality and different use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18h5f7b", "is_robot_indexable": true, "report_reasons": null, "author": "PrestigiousCup7026", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h5f7b/eli5_kafka_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h5f7b/eli5_kafka_learning_resources/", "subreddit_subscribers": 145660, "created_utc": 1702432828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fantastic post from Georg and Aleksandar", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster, dbt, duckdb as new local MDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_18hipz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "#46d160", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C8BThcaoCneGtqR55zryhvIDi2M_OoTkLPOgIn9tXAM.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702479709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "georgheiler.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fantastic post from Georg and Aleksandar&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://georgheiler.com/2023/12/11/dagster-dbt-duckdb-as-new-local-mds/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?auto=webp&amp;s=861e4f94dc91e2f5ba063c56da2f709e01437573", "width": 2048, "height": 2048}, "resolutions": [{"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cdb58b5a195232e633f8b91f78f9f24e22bcc1e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3605171ded8bd689c2b60aa4bf84ed0536c09c7f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f4cbba5cea1ebe44625c4f4069a6c78dcfa85061", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df803cd4ca1683749c35eada75315eb588ef67e1", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99501c4a7318bc43ffec2b0e60c50c810127a1a0", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/HfWaiitkxeMzkIOXSRWTtTrhkiuK3kT-le8bS_Cjk-U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6e815925fa8a0e77f571fed51d348e38b1b9ddae", "width": 1080, "height": 1080}], "variants": {}, "id": "fi_LHP4YaKAqYxd02lcILIegMmkY3lQeK3OCDUu36vQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18hipz6", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/18hipz6/dagster_dbt_duckdb_as_new_local_mds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://georgheiler.com/2023/12/11/dagster-dbt-duckdb-as-new-local-mds/", "subreddit_subscribers": 145660, "created_utc": 1702479709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "JSON is needed, and we have mixed JSON databases JSON as separate type. Why we keep the tables and not treating everything as JSON, like MongoDB does?\n\nDocument model is like a tree, it can be a table also, someone can model data in JSON as if it was a table, but the opposite is not natural and complicated.Having JSON columns makes things complicated, and queries even more complicated separating normal data from JSON data.\n\nI don't mean why MongoDB doesn't replace all, i mean why RDBMS don't become JSON databases.Its because its so hard to make the change, or because its bad idea to make this change?", "author_fullname": "t2_3t7x5s1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why all relational databases don't become document(JSON) databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18hjtnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702482682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;JSON is needed, and we have mixed JSON databases JSON as separate type. Why we keep the tables and not treating everything as JSON, like MongoDB does?&lt;/p&gt;\n\n&lt;p&gt;Document model is like a tree, it can be a table also, someone can model data in JSON as if it was a table, but the opposite is not natural and complicated.Having JSON columns makes things complicated, and queries even more complicated separating normal data from JSON data.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean why MongoDB doesn&amp;#39;t replace all, i mean why RDBMS don&amp;#39;t become JSON databases.Its because its so hard to make the change, or because its bad idea to make this change?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hjtnq", "is_robot_indexable": true, "report_reasons": null, "author": "takis__", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hjtnq/why_all_relational_databases_dont_become/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hjtnq/why_all_relational_databases_dont_become/", "subreddit_subscribers": 145660, "created_utc": 1702482682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI wanted to know if someone is familiar with an automation tool that generates ERD from tables relations (PKs and FKs) in the DB.\n\nI saw that there are some free/paid tools.\n\nMostly it looks like this ability is part of a bigger tool that contains more abilities like (dataedo, datagrip, Dbeaver).\n\nI would like to get some recommendations.\n\nThanks ", "author_fullname": "t2_puttmuzbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generate ERD automation tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hhyd2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702477577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I wanted to know if someone is familiar with an automation tool that generates ERD from tables relations (PKs and FKs) in the DB.&lt;/p&gt;\n\n&lt;p&gt;I saw that there are some free/paid tools.&lt;/p&gt;\n\n&lt;p&gt;Mostly it looks like this ability is part of a bigger tool that contains more abilities like (dataedo, datagrip, Dbeaver).&lt;/p&gt;\n\n&lt;p&gt;I would like to get some recommendations.&lt;/p&gt;\n\n&lt;p&gt;Thanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18hhyd2", "is_robot_indexable": true, "report_reasons": null, "author": "The-Angel-1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hhyd2/generate_erd_automation_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hhyd2/generate_erd_automation_tools/", "subreddit_subscribers": 145660, "created_utc": 1702477577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Junior data engineer with 1.5 yrs experience . I do have one doubt like which is better for us being a Data engineer ? Like, \nIs to provide Data to other team such as analysts so they can build an insight from the data and build a Dashboard which is actually possible for us too .\nOr \nTo build an end to end product (such as a dashboard) where we bring the transformed data and build the dashboard and give to the end users such as analyst.", "author_fullname": "t2_suskxfga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do we do ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hhk3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702476434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Junior data engineer with 1.5 yrs experience . I do have one doubt like which is better for us being a Data engineer ? Like, \nIs to provide Data to other team such as analysts so they can build an insight from the data and build a Dashboard which is actually possible for us too .\nOr \nTo build an end to end product (such as a dashboard) where we bring the transformed data and build the dashboard and give to the end users such as analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hhk3e", "is_robot_indexable": true, "report_reasons": null, "author": "PressureCandid1989", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hhk3e/what_do_we_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hhk3e/what_do_we_do/", "subreddit_subscribers": 145660, "created_utc": 1702476434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just noticed that AWS Datazone is now in GA and am considering using it as the Data Governance tool for my organisation. Any initial thoughts on whether it's a good product to consider? How does it compare to other tools like Privacera and Alation?", "author_fullname": "t2_15lzfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about AWS Datazone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hh8yd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702475532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just noticed that AWS Datazone is now in GA and am considering using it as the Data Governance tool for my organisation. Any initial thoughts on whether it&amp;#39;s a good product to consider? How does it compare to other tools like Privacera and Alation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hh8yd", "is_robot_indexable": true, "report_reasons": null, "author": "kaiusang", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hh8yd/thoughts_about_aws_datazone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hh8yd/thoughts_about_aws_datazone/", "subreddit_subscribers": 145660, "created_utc": 1702475532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit,\n\nWe (Memphis.dev) recently added [Functions](https://docs.memphis.dev/memphis/memphis-functions/overview). A serverless/FaaS framework for processing events in real time. What do you think about real-time data scrubbing as a use case? before the events are landed in the warehouse. Are you doing something like that today? If so, how did you implement it?\n\nTnx!", "author_fullname": "t2_hhdac8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time data scrubbing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hgueg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702474278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit,&lt;/p&gt;\n\n&lt;p&gt;We (Memphis.dev) recently added &lt;a href=\"https://docs.memphis.dev/memphis/memphis-functions/overview\"&gt;Functions&lt;/a&gt;. A serverless/FaaS framework for processing events in real time. What do you think about real-time data scrubbing as a use case? before the events are landed in the warehouse. Are you doing something like that today? If so, how did you implement it?&lt;/p&gt;\n\n&lt;p&gt;Tnx!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?auto=webp&amp;s=23356ab3e241fde6d44e0836a3d129d6ab03612b", "width": 2275, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f52c332031dc2ab7213a7e7873a10755a62647b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6eea1454a54db9fb7f3b7d3e29b373cc6b0153d5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e7b136a33d618f892f4082dffbfd503dd857ff0", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20650affd4ac6ecc261d6311d878fbcc1743aba5", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=456a0d353af6c4fffc708f3c50d455817b622849", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/M10CrGnHEt2dTun1b0vJD6NxCzDwMG7NllbXb--WD_s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d219936f800159b30d27d358ca1056243ab491f3", "width": 1080, "height": 607}], "variants": {}, "id": "0yIoWJPDI-yE98VdA0N5P_Mm3w7yzpJFL4HSBzidtdw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18hgueg", "is_robot_indexable": true, "report_reasons": null, "author": "yanivbh1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hgueg/realtime_data_scrubbing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hgueg/realtime_data_scrubbing/", "subreddit_subscribers": 145660, "created_utc": 1702474278.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}