{"kind": "Listing", "data": {"after": "t3_18gocy7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Although I work as a Machine Learning Engineer, sometimes I'm requested to build some queries, for instance for dashboarding purposes.\n\nHowever, I find it really tedious when working with SQL. My main reasons being:\n\n1. Most of the times we work with tables in the DataLake we don't own, hence it takes an awful lot of time to get an understanding of how that data is structured (and what kind of data problems it might have)\n2. I feel really unproductive having to wait for query results. It really slows down any kind of exploration one might want do with the data like one would with tools like Pandas or Polars (and loading data locally is not an option as we're talking of billions of records here, which we're handling with Spark)\n3. Sometimes queries grow to be extremely complex, which makes it harder for team mates to review\n4. Along the previous point, I really feel SQL is extremely unreadable as compared to a programming language", "author_fullname": "t2_21rg1aff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you make working with SQL enjoyable (or less tedious)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gn43u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702391339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Although I work as a Machine Learning Engineer, sometimes I&amp;#39;m requested to build some queries, for instance for dashboarding purposes.&lt;/p&gt;\n\n&lt;p&gt;However, I find it really tedious when working with SQL. My main reasons being:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Most of the times we work with tables in the DataLake we don&amp;#39;t own, hence it takes an awful lot of time to get an understanding of how that data is structured (and what kind of data problems it might have)&lt;/li&gt;\n&lt;li&gt;I feel really unproductive having to wait for query results. It really slows down any kind of exploration one might want do with the data like one would with tools like Pandas or Polars (and loading data locally is not an option as we&amp;#39;re talking of billions of records here, which we&amp;#39;re handling with Spark)&lt;/li&gt;\n&lt;li&gt;Sometimes queries grow to be extremely complex, which makes it harder for team mates to review&lt;/li&gt;\n&lt;li&gt;Along the previous point, I really feel SQL is extremely unreadable as compared to a programming language&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gn43u", "is_robot_indexable": true, "report_reasons": null, "author": "barberogaston", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gn43u/how_do_you_make_working_with_sql_enjoyable_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gn43u/how_do_you_make_working_with_sql_enjoyable_or/", "subreddit_subscribers": 145624, "created_utc": 1702391339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been modeling NBA data for a couple months, and this is one of my favorite insights so far!\n\n\\- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python  \n\\- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp; Snowflake (Production)  \n\\- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: [paradime.io](https://www.linkedin.com/company/paradimelabs/) (dbt)  \n\\- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - [Lightdash](https://www.linkedin.com/company/lightdash/)\n\nSo, why do the Jazz have the lowest avg. cost per win?  \n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&gt; Malone, Great home-court advantage, stable coaching.  \n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)  \n\ud83e\ude84 Salt Lake City doesn't attract top (expensive) NBA talent \ud83e\udd23  \n\ud83e\ude84 Consistent &amp; competent leadership  \nSeparate note - I'm still shocked by how terrible the Knicks have been historically. They're the biggest market, they're willing to spend (obviously) yet they can't pull it together... Ever\n\nYou can find, critique, and contribute to my NBA project here: [https://github.com/jpooksy/NBA\\_Data\\_Modeling](https://github.com/jpooksy/NBA_Data_Modeling)  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA data modeling wth dbt + Paradime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lrw4oybekw5c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 130, "x": 108, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49598bbed60ac1dfad30e730226a940d1617ac82"}, {"y": 261, "x": 216, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2633eed8b2e34880131642200e2dacb2083d1b71"}, {"y": 386, "x": 320, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1ad4371601d2889998d2164deba121e4f822f96"}], "s": {"y": 682, "x": 564, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960"}, "id": "lrw4oybekw5c1"}}, "name": "t3_18grxlj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_pUtcBckyyefRo0H27ezy2qeaxhbYnsrdXQXQjFIhAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702403763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been modeling NBA data for a couple months, and this is one of my favorite insights so far!&lt;/p&gt;\n\n&lt;p&gt;- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python&lt;br/&gt;\n- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp;amp; Snowflake (Production)&lt;br/&gt;\n- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: &lt;a href=\"https://www.linkedin.com/company/paradimelabs/\"&gt;paradime.io&lt;/a&gt; (dbt)&lt;br/&gt;\n- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - &lt;a href=\"https://www.linkedin.com/company/lightdash/\"&gt;Lightdash&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So, why do the Jazz have the lowest avg. cost per win?&lt;br/&gt;\n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&amp;gt; Malone, Great home-court advantage, stable coaching.&lt;br/&gt;\n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)&lt;br/&gt;\n\ud83e\ude84 Salt Lake City doesn&amp;#39;t attract top (expensive) NBA talent \ud83e\udd23&lt;br/&gt;\n\ud83e\ude84 Consistent &amp;amp; competent leadership&lt;br/&gt;\nSeparate note - I&amp;#39;m still shocked by how terrible the Knicks have been historically. They&amp;#39;re the biggest market, they&amp;#39;re willing to spend (obviously) yet they can&amp;#39;t pull it together... Ever&lt;/p&gt;\n\n&lt;p&gt;You can find, critique, and contribute to my NBA project here: &lt;a href=\"https://github.com/jpooksy/NBA_Data_Modeling\"&gt;https://github.com/jpooksy/NBA_Data_Modeling&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960\"&gt;https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18grxlj", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "subreddit_subscribers": 145624, "created_utc": 1702403763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into a discussion with a visualization engineer who insists that never in her career had they created materialized views or regular views specific to a dashboard element. \nI\u2019m not in visualization, so honestly don\u2019t even have context to decide if this person\u2019s perspective is reasonable. From my perspective, as a dashboard is designed for a larger audience, if dealing with data from multiple tables, of course it makes sense to do this work upstream. Am I crazy here?", "author_fullname": "t2_5s7getlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pattern: Table or View per Dashboard Element", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gv87y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702412142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into a discussion with a visualization engineer who insists that never in her career had they created materialized views or regular views specific to a dashboard element. \nI\u2019m not in visualization, so honestly don\u2019t even have context to decide if this person\u2019s perspective is reasonable. From my perspective, as a dashboard is designed for a larger audience, if dealing with data from multiple tables, of course it makes sense to do this work upstream. Am I crazy here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gv87y", "is_robot_indexable": true, "report_reasons": null, "author": "pro__acct__", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gv87y/pattern_table_or_view_per_dashboard_element/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gv87y/pattern_table_or_view_per_dashboard_element/", "subreddit_subscribers": 145624, "created_utc": 1702412142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been with my current company for about six months, and in that time, I've not only developed data pipelines but also found myself building the team-specific dashboards they feed into. Back at my old job, things were a bit different. I worked alongside an analyst who took care of the dashboards. They would give me the business needs, and I'd tailor the data pipelines to suit those requirements and the analysis being done. Personally, I don't think dashboard building is really part of a data engineer's job, but I'm curious to hear what others in this group think. Have you had similar experiences?", "author_fullname": "t2_103ndz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much dashboarding / viz do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h7vek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702439534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been with my current company for about six months, and in that time, I&amp;#39;ve not only developed data pipelines but also found myself building the team-specific dashboards they feed into. Back at my old job, things were a bit different. I worked alongside an analyst who took care of the dashboards. They would give me the business needs, and I&amp;#39;d tailor the data pipelines to suit those requirements and the analysis being done. Personally, I don&amp;#39;t think dashboard building is really part of a data engineer&amp;#39;s job, but I&amp;#39;m curious to hear what others in this group think. Have you had similar experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18h7vek", "is_robot_indexable": true, "report_reasons": null, "author": "natelifts", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h7vek/how_much_dashboarding_viz_do_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h7vek/how_much_dashboarding_viz_do_you_do/", "subreddit_subscribers": 145624, "created_utc": 1702439534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a cross-disciplinary Big Data (Engineering, Science) Master's degree, i have done an internship as a assistant DE then the company hired me as a junior DE. But i didn't really stuck to DE, of course i made a lot of pipelines from ingestion to exports...etc and all usual Data Engineer tasks. But i also did a lot (like really a lot) of Data Viz and some analysis (either descriptive or predictive). With great results for our company, and that's something i like doing.   \nNow the company is growing, we recently hired a huge data analysts team, that took over all the data analysis and data viz perimeter, and i kinda feel limited in my scope as i do really well in this hybrid role and i wanted to learn some ML (i have all the major certifications in the technologies we're already using like GCP professional DE)   \nAs i'm still \"new\" and young, i want to ask to the more experienced ones here what is a realistic career path for a \"DE\" that likes the business side of Data. Is it some like of utopia if i'm thinking to have some hybrid role that goes through all the Data lifecyle ? Especially in big companies", "author_fullname": "t2_7twd1xfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After 2 years as a DE, i don't know where my career path is going", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h1u2e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702425940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a cross-disciplinary Big Data (Engineering, Science) Master&amp;#39;s degree, i have done an internship as a assistant DE then the company hired me as a junior DE. But i didn&amp;#39;t really stuck to DE, of course i made a lot of pipelines from ingestion to exports...etc and all usual Data Engineer tasks. But i also did a lot (like really a lot) of Data Viz and some analysis (either descriptive or predictive). With great results for our company, and that&amp;#39;s something i like doing.&lt;br/&gt;\nNow the company is growing, we recently hired a huge data analysts team, that took over all the data analysis and data viz perimeter, and i kinda feel limited in my scope as i do really well in this hybrid role and i wanted to learn some ML (i have all the major certifications in the technologies we&amp;#39;re already using like GCP professional DE)&lt;br/&gt;\nAs i&amp;#39;m still &amp;quot;new&amp;quot; and young, i want to ask to the more experienced ones here what is a realistic career path for a &amp;quot;DE&amp;quot; that likes the business side of Data. Is it some like of utopia if i&amp;#39;m thinking to have some hybrid role that goes through all the Data lifecyle ? Especially in big companies&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18h1u2e", "is_robot_indexable": true, "report_reasons": null, "author": "BennyLauren", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h1u2e/after_2_years_as_a_de_i_dont_know_where_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h1u2e/after_2_years_as_a_de_i_dont_know_where_my_career/", "subreddit_subscribers": 145624, "created_utc": 1702425940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, Dear Data Engineers!\n\nI wrote a [blog post](https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der) about solving the **User ID Stitching** problem with Recursive SQL. You can use this in DBT with data warehouses supporting recursive CTEs.  \n\n\n&gt;The **User ID Stitching** problem concerns primarily **B2C companies** that want to measure marketing, product, and sales metrics correctly from the delta lake.  \nIt is about creating a **user\\_aliases** table that maps all possible user identifiers for every user across all datasets in a Delta Lake to a single **merged\\_id**\n\n**Possible user identifiers:**\n\n* device\\_id\n* user\\_id\n* anonymous\\_user\\_id\n* email\n* contact\\_id (Hubspot)\n* customer\\_id (Stripe)\n* \u2026 etc\u2026\n\nYou can then use the **merge\\_id** to join across all datasets, count unique users correctly, create funnel queries across all datasets, etc.  \nI hope it helps whoever it may help :)\n\nLink to the [blog post](https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der)", "author_fullname": "t2_gnytqihqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "User ID Stitching with Recursive SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hc4jz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702455492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, Dear Data Engineers!&lt;/p&gt;\n\n&lt;p&gt;I wrote a &lt;a href=\"https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der\"&gt;blog post&lt;/a&gt; about solving the &lt;strong&gt;User ID Stitching&lt;/strong&gt; problem with Recursive SQL. You can use this in DBT with data warehouses supporting recursive CTEs.  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The &lt;strong&gt;User ID Stitching&lt;/strong&gt; problem concerns primarily &lt;strong&gt;B2C companies&lt;/strong&gt; that want to measure marketing, product, and sales metrics correctly from the delta lake.&lt;br/&gt;\nIt is about creating a &lt;strong&gt;user_aliases&lt;/strong&gt; table that maps all possible user identifiers for every user across all datasets in a Delta Lake to a single &lt;strong&gt;merged_id&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Possible user identifiers:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;device_id&lt;/li&gt;\n&lt;li&gt;user_id&lt;/li&gt;\n&lt;li&gt;anonymous_user_id&lt;/li&gt;\n&lt;li&gt;email&lt;/li&gt;\n&lt;li&gt;contact_id (Hubspot)&lt;/li&gt;\n&lt;li&gt;customer_id (Stripe)&lt;/li&gt;\n&lt;li&gt;\u2026 etc\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can then use the &lt;strong&gt;merge_id&lt;/strong&gt; to join across all datasets, count unique users correctly, create funnel queries across all datasets, etc.&lt;br/&gt;\nI hope it helps whoever it may help :)&lt;/p&gt;\n\n&lt;p&gt;Link to the &lt;a href=\"https://www.mitzu.io/post/identifying-users-in-the-data-warehouse?source=der\"&gt;blog post&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?auto=webp&amp;s=0d093ce954e3041f48a37532a5dcaf93dc69e403", "width": 1776, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc79b8bbb10e9f68c1d1d6c86af1f3841dc4f10e", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c07e77a7075812c321c03396caabe8b0df20257", "width": 216, "height": 97}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3ef5435010e00eaf07797ddfcec9de3febd41ce", "width": 320, "height": 144}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b745bec61cacf775819bc9c0dee5dc03fbf29420", "width": 640, "height": 288}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49e6f8c7db99048714c1629660d5ca625c2c9ba6", "width": 960, "height": 432}, {"url": "https://external-preview.redd.it/6cDKS_NF0x-XxokIrxw9chJ_xZYQVp7HT_0BZyjKrNQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32c1b03ffdc645de4619500f6d9673e4f4fcb49a", "width": 1080, "height": 486}], "variants": {}, "id": "PNhHEjsZUew5p0U0EcK53-ZbVngG-Nb-Q0Qqg7c5UcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18hc4jz", "is_robot_indexable": true, "report_reasons": null, "author": "MitzuIstvan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hc4jz/user_id_stitching_with_recursive_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hc4jz/user_id_stitching_with_recursive_sql/", "subreddit_subscribers": 145624, "created_utc": 1702455492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_artaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What it's like watching performance tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_18h8vaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p-ScxshpaIH0LpOXfbiGYg_scjII6-q45KRcSku5VHE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702442790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/abq9civ6sz5c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/abq9civ6sz5c1.png?auto=webp&amp;s=8b185af5c90f3b84ccb0159c6b0d7a19acfcb67d", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=19733133c2e33da130bb2cc44e3903397044da4c", "width": 108, "height": 61}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d298fc84454e747f4142361fe3c2395ed7f728d3", "width": 216, "height": 123}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf8a5a0fe428bd9b9d43ec2081f14ca243adc9ac", "width": 320, "height": 182}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=674624077c2d64c5762ac4a3c5325f44a0c530ab", "width": 640, "height": 365}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d272489210b302a0b7f32c8b5623768d4cd14da5", "width": 960, "height": 548}, {"url": "https://preview.redd.it/abq9civ6sz5c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b087a167c1eed7ae6ccd1098f3f95280496ee499", "width": 1080, "height": 617}], "variants": {}, "id": "A-qG__OJXA_ovT6p9YyJ08z42GO-MzxjPebbjk5kS6U"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "18h8vaw", "is_robot_indexable": true, "report_reasons": null, "author": "Toasty_toaster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h8vaw/what_its_like_watching_performance_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/abq9civ6sz5c1.png", "subreddit_subscribers": 145624, "created_utc": 1702442790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading Jobs Code between Databricks Runtime Versions Made Easier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_18gq1fy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vHriYbg9RY72KUXRAAYKX7WkPAf_TJCsD36ioLiCkEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702399004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?auto=webp&amp;s=e6fff503363810a1a844243d4dc30e20374a7e61", "width": 1200, "height": 639}, "resolutions": [{"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b1bd7c5baa426d324568692cf26b63002b7b9ab", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=632346f8e065aae9f74ea8fe594679ac441da0d7", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a7c5312e6d82b74496104ca1ba5fd37d8edfc97", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d87a636f09f8ab2bf8a00a4eee4eae61323608f8", "width": 640, "height": 340}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9002d9c593d7a4124e0ce8d3e0cba46f56a69233", "width": 960, "height": 511}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a322c150c48715bdd366d61e7a96a10d7e03776c", "width": 1080, "height": 575}], "variants": {}, "id": "uhonE0yWOOsFkvPBPnnGD6Eg9m5tkICAwlDw0bCdu6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gq1fy", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gq1fy/upgrading_jobs_code_between_databricks_runtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "subreddit_subscribers": 145624, "created_utc": 1702399004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a new job and I wanted to make sure that I know the basic things moving forward.", "author_fullname": "t2_e8k9c3l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some basic requirements or skills that are least expected from a Data Engineer with one year of experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18hc0wr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702455054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a new job and I wanted to make sure that I know the basic things moving forward.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18hc0wr", "is_robot_indexable": true, "report_reasons": null, "author": "SignalCrew739", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hc0wr/what_are_some_basic_requirements_or_skills_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hc0wr/what_are_some_basic_requirements_or_skills_that/", "subreddit_subscribers": 145624, "created_utc": 1702455054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title basically. using azure devOps on prem for build.", "author_fullname": "t2_slq927f8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how are ms sql server DBs deployed on-prem using ci/cd?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h30tl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702428163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title basically. using azure devOps on prem for build.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18h30tl", "is_robot_indexable": true, "report_reasons": null, "author": "Senior-Release930", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h30tl/how_are_ms_sql_server_dbs_deployed_onprem_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h30tl/how_are_ms_sql_server_dbs_deployed_onprem_using/", "subreddit_subscribers": 145624, "created_utc": 1702428163.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Data Processing with Ray Data and MinIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_18gskm2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uzAf_NxB0nLPzpd6yZHTuYbIip8pyxSiP67aPyuEhSU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702405394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?auto=webp&amp;s=60a9a5bb13ad52dc6f983d22a24a53b3b835a119", "width": 1200, "height": 359}, "resolutions": [{"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db2aa38b11de95fa42f9dbf716d73c3b2a64e4f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c18b4e8bc4062930b8490b5721bf20e5d91b96a", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e065467bf6807e1f7014eb05a7e8aef79c5b4e88", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74d1b5b114a455946e7c372fa0cc71907ebdd6dd", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d0ea6ae4d3f00a6c97c690b38471318183ee2c8", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=011a2c8ca8070e4782e8cf151170e64f2db7fd85", "width": 1080, "height": 323}], "variants": {}, "id": "ycJVbgf3bDDq06hpn_WuGtC2gZGgwo5DkVBTrJOe5j8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gskm2", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gskm2/distributed_data_processing_with_ray_data_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "subreddit_subscribers": 145624, "created_utc": 1702405394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, what are you interested to know about orchestrators? \n\nI am looking to do a deep dive on the more popular ones and write about it. \n\nWhat I am interested to understand is what use cases are each of them best at, and the kinds of criteria **you** use to make that choice.  \n\n\nSo my questions to you are:\n\n  \n**- what do you want to know about orchestrators?**\n\n**- what would you compare them on?**\n\n\\- **what killer features or orchestrators do you think I should check out and investigate?**  \n\n\nCurrently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we'll dig in :)  \n\n\nThanks in advance!\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want to know about orchestrators?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqg6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, what are you interested to know about orchestrators? &lt;/p&gt;\n\n&lt;p&gt;I am looking to do a deep dive on the more popular ones and write about it. &lt;/p&gt;\n\n&lt;p&gt;What I am interested to understand is what use cases are each of them best at, and the kinds of criteria &lt;strong&gt;you&lt;/strong&gt; use to make that choice.  &lt;/p&gt;\n\n&lt;p&gt;So my questions to you are:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what do you want to know about orchestrators?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what would you compare them on?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;what killer features or orchestrators do you think I should check out and investigate?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Currently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we&amp;#39;ll dig in :)  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gqg6q", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "subreddit_subscribers": 145624, "created_utc": 1702400055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to kafka. Want to understand its functionality and different use cases.", "author_fullname": "t2_q32966uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Eli5 Kafka learning resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h5f7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702432828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to kafka. Want to understand its functionality and different use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18h5f7b", "is_robot_indexable": true, "report_reasons": null, "author": "PrestigiousCup7026", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h5f7b/eli5_kafka_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h5f7b/eli5_kafka_learning_resources/", "subreddit_subscribers": 145624, "created_utc": 1702432828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is not entirely dedicated to data engineering, but it has touch points.\n\n **Some context:**\n\nIn our small to medium-sized enterprise operating in a production environment with a myriad of applications, the majority of which have point-to-point interfaces with our ERP (a local SQL database), and a considerable amount of legacy systems, the IT team, consisting of just two members, manages all applications and integrations. It's noteworthy that we lack in-house developers. Many of our integrations rely on XML files for data exchange, employing SQL and mapping tools like Altova and sometimes even BizTalk.\n\nLooking ahead, by the end of 2024, we plan to implement a new ERP, likely Dynamics 365 F&amp;O. This transition necessitates the rebuilding of numerous integrations to align with the new ERP. Ideally, we aim to centralize these integrations for improved oversight, addressing issues proactively rather than reactively as is often the case currently.\n\nOur challenges are further compounded when dealing with modern web applications utilizing RESTAPI, especially with our legacy ERP. Typically, we resort to scripting PowerShell and requesting vendors to set up an SFTP server for XML file exchange, incurring additional costs for their extra efforts. To address these issues, we have explored integration platforms such as Mulesoft, Workato, and Boomi.\n\nBoomi was discarded after practical testing due to perceived shortcomings. \n\nMulesoft proved comprehensible, enabling successful use cases, yet its deployment and maintenance seemed burdensome. \n\nWorkato, while lacking robust debugging and offering basic logging, demonstrated ease of use in creating integrations, aligning well with the simplicity of our integration needs. Its variety of connectors reduces the need for custom wrappers or connectors, and it presents automation possibilities.\n\nSome of the use cases that I finalized in the 2 last tools are:  \n\\- I was able to build an extensive integration between ERP and Salesforce, \n\n\\- create an API based on openapi specs and send data between ERP and the web app\n\n\\- do data transformation into an XML file with iterations \n\n**The question at hand** is whether an Integration Platform as a Service (iPaaS) is a suitable solution for our scenario, given that we do not anticipate hiring an in-house developer. Additionally, are there other platforms or tools we might be overlooking? We are seeking insights from those with experience in the listed tools, with Workato emerging as our preferred choice due to its balance of simplicity and functionality, even though Mulesoft offers more robust features. The overarching question is whether the additional functionalities of Mulesoft are necessary for our specific requirements.\n\nTL;DR: We're a small-to-medium enterprise handling various applications with point-to-point interfaces and legacy systems. Two-person IT team, no in-house developers. Looking to rebuild integrations for a new ERP (probably Dynamics 365 F&amp;O) by 2024. Currently considering Workato, Mulesoft, and Boomi. Workato seems suitable due to simplicity and variety of connectors. Wondering if Integration Platform as a Service (iPaaS) is the right solution for us and seeking insights on other tools or experiences with the mentioned platforms. Open to suggestions given our context and the absence of in-house developers.", "author_fullname": "t2_8mnqz0ek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about IPAAS platforms (Mulesoft, Workato,...)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gm0jn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702388156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is not entirely dedicated to data engineering, but it has touch points.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In our small to medium-sized enterprise operating in a production environment with a myriad of applications, the majority of which have point-to-point interfaces with our ERP (a local SQL database), and a considerable amount of legacy systems, the IT team, consisting of just two members, manages all applications and integrations. It&amp;#39;s noteworthy that we lack in-house developers. Many of our integrations rely on XML files for data exchange, employing SQL and mapping tools like Altova and sometimes even BizTalk.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead, by the end of 2024, we plan to implement a new ERP, likely Dynamics 365 F&amp;amp;O. This transition necessitates the rebuilding of numerous integrations to align with the new ERP. Ideally, we aim to centralize these integrations for improved oversight, addressing issues proactively rather than reactively as is often the case currently.&lt;/p&gt;\n\n&lt;p&gt;Our challenges are further compounded when dealing with modern web applications utilizing RESTAPI, especially with our legacy ERP. Typically, we resort to scripting PowerShell and requesting vendors to set up an SFTP server for XML file exchange, incurring additional costs for their extra efforts. To address these issues, we have explored integration platforms such as Mulesoft, Workato, and Boomi.&lt;/p&gt;\n\n&lt;p&gt;Boomi was discarded after practical testing due to perceived shortcomings. &lt;/p&gt;\n\n&lt;p&gt;Mulesoft proved comprehensible, enabling successful use cases, yet its deployment and maintenance seemed burdensome. &lt;/p&gt;\n\n&lt;p&gt;Workato, while lacking robust debugging and offering basic logging, demonstrated ease of use in creating integrations, aligning well with the simplicity of our integration needs. Its variety of connectors reduces the need for custom wrappers or connectors, and it presents automation possibilities.&lt;/p&gt;\n\n&lt;p&gt;Some of the use cases that I finalized in the 2 last tools are:&lt;br/&gt;\n- I was able to build an extensive integration between ERP and Salesforce, &lt;/p&gt;\n\n&lt;p&gt;- create an API based on openapi specs and send data between ERP and the web app&lt;/p&gt;\n\n&lt;p&gt;- do data transformation into an XML file with iterations &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The question at hand&lt;/strong&gt; is whether an Integration Platform as a Service (iPaaS) is a suitable solution for our scenario, given that we do not anticipate hiring an in-house developer. Additionally, are there other platforms or tools we might be overlooking? We are seeking insights from those with experience in the listed tools, with Workato emerging as our preferred choice due to its balance of simplicity and functionality, even though Mulesoft offers more robust features. The overarching question is whether the additional functionalities of Mulesoft are necessary for our specific requirements.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: We&amp;#39;re a small-to-medium enterprise handling various applications with point-to-point interfaces and legacy systems. Two-person IT team, no in-house developers. Looking to rebuild integrations for a new ERP (probably Dynamics 365 F&amp;amp;O) by 2024. Currently considering Workato, Mulesoft, and Boomi. Workato seems suitable due to simplicity and variety of connectors. Wondering if Integration Platform as a Service (iPaaS) is the right solution for us and seeking insights on other tools or experiences with the mentioned platforms. Open to suggestions given our context and the absence of in-house developers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gm0jn", "is_robot_indexable": true, "report_reasons": null, "author": "LangeHamburger", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gm0jn/question_about_ipaas_platforms_mulesoft_workato/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gm0jn/question_about_ipaas_platforms_mulesoft_workato/", "subreddit_subscribers": 145624, "created_utc": 1702388156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn the the discussions around bronze layers / staging areas it is always said that the raw data should be stored (and never changed). However one aspect that is barely discussed in my opinion is how to ensure data protection e.g. GDPR in that data. \n\nIn my case we are not allowed to have any non-pseudonymized personal data stored. Therefore we already do transformations to do that before storing in \"bronze\". \nAlso data deletion on specific rules needs to take place in bronze. Since we work with json data where important identifiers are nested in the data this is quite complex.\n\nWhat are your experiences and opinions on this?", "author_fullname": "t2_rydqu8m3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GDPR in Bronze / Staging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18haxma", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702450447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In the the discussions around bronze layers / staging areas it is always said that the raw data should be stored (and never changed). However one aspect that is barely discussed in my opinion is how to ensure data protection e.g. GDPR in that data. &lt;/p&gt;\n\n&lt;p&gt;In my case we are not allowed to have any non-pseudonymized personal data stored. Therefore we already do transformations to do that before storing in &amp;quot;bronze&amp;quot;. \nAlso data deletion on specific rules needs to take place in bronze. Since we work with json data where important identifiers are nested in the data this is quite complex.&lt;/p&gt;\n\n&lt;p&gt;What are your experiences and opinions on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18haxma", "is_robot_indexable": true, "report_reasons": null, "author": "DecisionAgile7326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18haxma/gdpr_in_bronze_staging/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18haxma/gdpr_in_bronze_staging/", "subreddit_subscribers": 145624, "created_utc": 1702450447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm looking to test Airbyte OSS and have deployed the product locally on WSL using the instructions [here](https://docs.airbyte.com/deploying-airbyte/local-deployment). This has create a local repo with all the Airbyte files.\n\nI am looking to use these files to create a connector to ADLS, which is a standard connector on Airbyte, however, all of the documentation is about using Airbyte Cloud and the UI, which I don't want to do. I want to deploy an ADLS connector locally then use Docker to publish to Azure Container Registry, then self-host this container in a VM.\n\nI know how to use Docker and Azure, but am stumped with the first stage. Is there any documentation about how to create a connector using OSS rather than the Cloud version of the product?\n\nThanks, ", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create connectors for Self-Hosted Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gky16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702384695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to test Airbyte OSS and have deployed the product locally on WSL using the instructions &lt;a href=\"https://docs.airbyte.com/deploying-airbyte/local-deployment\"&gt;here&lt;/a&gt;. This has create a local repo with all the Airbyte files.&lt;/p&gt;\n\n&lt;p&gt;I am looking to use these files to create a connector to ADLS, which is a standard connector on Airbyte, however, all of the documentation is about using Airbyte Cloud and the UI, which I don&amp;#39;t want to do. I want to deploy an ADLS connector locally then use Docker to publish to Azure Container Registry, then self-host this container in a VM.&lt;/p&gt;\n\n&lt;p&gt;I know how to use Docker and Azure, but am stumped with the first stage. Is there any documentation about how to create a connector using OSS rather than the Cloud version of the product?&lt;/p&gt;\n\n&lt;p&gt;Thanks, &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gky16", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gky16/how_to_create_connectors_for_selfhosted_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gky16/how_to_create_connectors_for_selfhosted_airbyte/", "subreddit_subscribers": 145624, "created_utc": 1702384695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a project to normalise existing production tables and I would like a tool or method to verify the data matches in the old denormalised tables vs the new normalised tables. \n\nThe plan is to create the new normalised tables. Modify the web app to populate new normalised tables alongside the existing denormalised tables. Then we can compare the results in each table with the long term goal of moving the web app over to the new tables and decommissioning the legacy denormalised tables.\n\nLittle example to explain:\n\nThis would be a denormalised table\n\n    CREATE TABLE Sales (\n        customer_id INT PRIMARY KEY,\n        customer_name VARCHAR(50),\n        customer_email VARCHAR(50),\n        order_id INT,\n        order_date DATE,\n        product_id INT,\n        product_name VARCHAR(50),\n        product_price DECIMAL(10, 2),\n        quantity INT\n    );\n\nNext we normalise the table\n\n\n    CREATE TABLE Customers (\n        customer_id INT PRIMARY KEY,\n        customer_name VARCHAR(50),\n        customer_email VARCHAR(50)\n    );\n\n    CREATE TABLE Products (\n        product_id INT PRIMARY KEY,\n        product_name VARCHAR(50),\n        product_price DECIMAL(10, 2)\n    );\n\n    CREATE TABLE Orders (\n        order_id INT PRIMARY KEY,\n        customer_id INT,\n        order_date DATE,\n        FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n    );\n\n    CREATE TABLE OrderDetails (\n        order_id INT,\n        product_id INT,\n        quantity INT,\n        PRIMARY KEY (order_id, product_id),\n        FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n        FOREIGN KEY (product_id) REFERENCES Products(product_id)\n    );\n\nAll tables will exist in production and be populated, as part of validating the data I would need to check that Sales.customer_email is equal to Customers.customer_email that Sales.product_name is equal to Products.product_name and so on for every column.\n\nWriting a unique SQL for each check would explode in complexity as we have many tables to compare.\n\nTo be clear I'm not talking about migrating data from the denormalised tables to the normalised tables the web app will populated both sets I wish to verify the data to spot mistakes in population between old and new tables.\n\nAny help or guidance is appreciated.", "author_fullname": "t2_1hj7ckkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reconciling data in denormalised vs normalised tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18hdec0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702461267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a project to normalise existing production tables and I would like a tool or method to verify the data matches in the old denormalised tables vs the new normalised tables. &lt;/p&gt;\n\n&lt;p&gt;The plan is to create the new normalised tables. Modify the web app to populate new normalised tables alongside the existing denormalised tables. Then we can compare the results in each table with the long term goal of moving the web app over to the new tables and decommissioning the legacy denormalised tables.&lt;/p&gt;\n\n&lt;p&gt;Little example to explain:&lt;/p&gt;\n\n&lt;p&gt;This would be a denormalised table&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE TABLE Sales (\n    customer_id INT PRIMARY KEY,\n    customer_name VARCHAR(50),\n    customer_email VARCHAR(50),\n    order_id INT,\n    order_date DATE,\n    product_id INT,\n    product_name VARCHAR(50),\n    product_price DECIMAL(10, 2),\n    quantity INT\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Next we normalise the table&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE TABLE Customers (\n    customer_id INT PRIMARY KEY,\n    customer_name VARCHAR(50),\n    customer_email VARCHAR(50)\n);\n\nCREATE TABLE Products (\n    product_id INT PRIMARY KEY,\n    product_name VARCHAR(50),\n    product_price DECIMAL(10, 2)\n);\n\nCREATE TABLE Orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    order_date DATE,\n    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id)\n);\n\nCREATE TABLE OrderDetails (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id),\n    FOREIGN KEY (order_id) REFERENCES Orders(order_id),\n    FOREIGN KEY (product_id) REFERENCES Products(product_id)\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;All tables will exist in production and be populated, as part of validating the data I would need to check that Sales.customer_email is equal to Customers.customer_email that Sales.product_name is equal to Products.product_name and so on for every column.&lt;/p&gt;\n\n&lt;p&gt;Writing a unique SQL for each check would explode in complexity as we have many tables to compare.&lt;/p&gt;\n\n&lt;p&gt;To be clear I&amp;#39;m not talking about migrating data from the denormalised tables to the normalised tables the web app will populated both sets I wish to verify the data to spot mistakes in population between old and new tables.&lt;/p&gt;\n\n&lt;p&gt;Any help or guidance is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18hdec0", "is_robot_indexable": true, "report_reasons": null, "author": "OisinWard", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18hdec0/reconciling_data_in_denormalised_vs_normalised/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18hdec0/reconciling_data_in_denormalised_vs_normalised/", "subreddit_subscribers": 145624, "created_utc": 1702461267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,  \n\n\nI'm in the first step of building a end-to-end data analytics solution, including design &amp; build data warehouse,  then push data to BI tool &amp; Visualize. This project is for job hunting (There's not many DE jobs for junior level in my area.) \n\nBut my concern is that...I might want to expand the project into a bigger one at later stages (such as scraping raw data, building Datalake solution or ETL, or migrating to cloud, etc.), so I want to start off correctly.   \n\n\nCould you give me the advice such as - the topic? the industry? any experience you think that might be useful?  \nThanks for reading. ", "author_fullname": "t2_80m5fstj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal project: To build a datawarehouse &amp; push data to BI platform (Tableau) &amp; Visualize. Ideas!?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18h2zta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702428108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the first step of building a end-to-end data analytics solution, including design &amp;amp; build data warehouse,  then push data to BI tool &amp;amp; Visualize. This project is for job hunting (There&amp;#39;s not many DE jobs for junior level in my area.) &lt;/p&gt;\n\n&lt;p&gt;But my concern is that...I might want to expand the project into a bigger one at later stages (such as scraping raw data, building Datalake solution or ETL, or migrating to cloud, etc.), so I want to start off correctly.   &lt;/p&gt;\n\n&lt;p&gt;Could you give me the advice such as - the topic? the industry? any experience you think that might be useful?&lt;br/&gt;\nThanks for reading. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18h2zta", "is_robot_indexable": true, "report_reasons": null, "author": "Solid-Exchange-8447", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18h2zta/personal_project_to_build_a_datawarehouse_push/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18h2zta/personal_project_to_build_a_datawarehouse_push/", "subreddit_subscribers": 145624, "created_utc": 1702428108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted this in IndieDev at first until I realised in my last sentence that this is fundamentally, I think, a data engineering issue.\n\nI'm working alongside a dev team who have a game published in the appstore with a decent user base and organic traffic. Their need for analytics has outgrown what's available in the Google Play Console and I've volunteered to help out.\n\nThe problem is that I've no idea how to extract, or even access, more data than what's in the dashboard. How do I query all of the data google must keep about the game and its users? And if Google doesn't keep all that much data, how can I set up a data pipeline to start this?\n\nMy experience is in analytics rather than data engineering so any help is much appreciated.", "author_fullname": "t2_m27f9f79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I query data / setup a data pipeline for my Google Playstore App", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gzzxc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702422552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted this in IndieDev at first until I realised in my last sentence that this is fundamentally, I think, a data engineering issue.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working alongside a dev team who have a game published in the appstore with a decent user base and organic traffic. Their need for analytics has outgrown what&amp;#39;s available in the Google Play Console and I&amp;#39;ve volunteered to help out.&lt;/p&gt;\n\n&lt;p&gt;The problem is that I&amp;#39;ve no idea how to extract, or even access, more data than what&amp;#39;s in the dashboard. How do I query all of the data google must keep about the game and its users? And if Google doesn&amp;#39;t keep all that much data, how can I set up a data pipeline to start this?&lt;/p&gt;\n\n&lt;p&gt;My experience is in analytics rather than data engineering so any help is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gzzxc", "is_robot_indexable": true, "report_reasons": null, "author": "TommyGunQuartet", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gzzxc/how_can_i_query_data_setup_a_data_pipeline_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gzzxc/how_can_i_query_data_setup_a_data_pipeline_for_my/", "subreddit_subscribers": 145624, "created_utc": 1702422552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Yall,   \n\n\nI want to move off of azure synapse, and im trying to build a proof of concept for upper leadership to show them. As im getting into Databricks i feel like i really dove into the deep end here!  \n\n\nCouple of questions I have:  \nRegarding compute, what are some best practices here. How do you guys manage your compute clusters? E.g. right now as I'm building a PoC, i just have a personal compute. Is that going to be sufficient for having automated jobs etc setup in databricks? On that note, I have some python code i was running in azure batch i would like to port over. Essentially the code just queries some APIs and writes the JSON to the datalake. Is this something i can use databricks for instead?   \n\n\nSpeaking of compute, I obviously dont want a compute cluster running all the time, right? But it seems if i create a view from a dataframe in spark, that dataframe is temporary. What do you guys use to integrate everything youre doing in databricks into your BI tools (this case im looking at powerbi)? I'm looking at SQL warehouses, but thats even more DBUs and im afraid im going to incur quite a bit of costs. I want to optimize costs as much as possible I'm im worried that databricks is going to rob me in compute costs lol if i start spinning up all these fancy tools. Would love to hear some best practices here. \n\n  \nI hear a lot of marketing buzzwordyness on delta live tables, bronze silver gold yada yada. Do i need to buy into the delta live table stuff in databricks? or is this something i can manage with code on my own? I guess im just confused how this all fits together.   \n", "author_fullname": "t2_jrmn04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started with databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gxsdq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702418500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Yall,   &lt;/p&gt;\n\n&lt;p&gt;I want to move off of azure synapse, and im trying to build a proof of concept for upper leadership to show them. As im getting into Databricks i feel like i really dove into the deep end here!  &lt;/p&gt;\n\n&lt;p&gt;Couple of questions I have:&lt;br/&gt;\nRegarding compute, what are some best practices here. How do you guys manage your compute clusters? E.g. right now as I&amp;#39;m building a PoC, i just have a personal compute. Is that going to be sufficient for having automated jobs etc setup in databricks? On that note, I have some python code i was running in azure batch i would like to port over. Essentially the code just queries some APIs and writes the JSON to the datalake. Is this something i can use databricks for instead?   &lt;/p&gt;\n\n&lt;p&gt;Speaking of compute, I obviously dont want a compute cluster running all the time, right? But it seems if i create a view from a dataframe in spark, that dataframe is temporary. What do you guys use to integrate everything youre doing in databricks into your BI tools (this case im looking at powerbi)? I&amp;#39;m looking at SQL warehouses, but thats even more DBUs and im afraid im going to incur quite a bit of costs. I want to optimize costs as much as possible I&amp;#39;m im worried that databricks is going to rob me in compute costs lol if i start spinning up all these fancy tools. Would love to hear some best practices here. &lt;/p&gt;\n\n&lt;p&gt;I hear a lot of marketing buzzwordyness on delta live tables, bronze silver gold yada yada. Do i need to buy into the delta live table stuff in databricks? or is this something i can manage with code on my own? I guess im just confused how this all fits together.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gxsdq", "is_robot_indexable": true, "report_reasons": null, "author": "soricellia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gxsdq/getting_started_with_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gxsdq/getting_started_with_databricks/", "subreddit_subscribers": 145624, "created_utc": 1702418500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. So I was just recently accepted into a sponsored program to learn data engineering. This programs is going to run for the entire of next year with the last 3 months being an internship with the company that will be sponsoring me. \n\nThis is something that I find exciting. However, even though the sponsoring company does give us an allowance - this won\u2019t be enough to live off of. So I was wondering if I am unrealistic for thinking that I could maybe try to find a remote internship or part time job in data as I\u2019m learning?\n\nIt is said that the program will require 40-50 hours a week. That is why I would like to find something not entirely full time. I\u2019ve heard of some people being able to do this while working full time though. \n\nIf it is indeed possible and not unrealistic - how would I go about finding something like that (especially in South Africa)? \n\nAny advice would be greatly appreciated.", "author_fullname": "t2_d54pk8w0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common are data engineering internships/part time jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gx9yb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702417410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. So I was just recently accepted into a sponsored program to learn data engineering. This programs is going to run for the entire of next year with the last 3 months being an internship with the company that will be sponsoring me. &lt;/p&gt;\n\n&lt;p&gt;This is something that I find exciting. However, even though the sponsoring company does give us an allowance - this won\u2019t be enough to live off of. So I was wondering if I am unrealistic for thinking that I could maybe try to find a remote internship or part time job in data as I\u2019m learning?&lt;/p&gt;\n\n&lt;p&gt;It is said that the program will require 40-50 hours a week. That is why I would like to find something not entirely full time. I\u2019ve heard of some people being able to do this while working full time though. &lt;/p&gt;\n\n&lt;p&gt;If it is indeed possible and not unrealistic - how would I go about finding something like that (especially in South Africa)? &lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18gx9yb", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Jicama2909", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gx9yb/how_common_are_data_engineering_internshipspart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gx9yb/how_common_are_data_engineering_internshipspart/", "subreddit_subscribers": 145624, "created_utc": 1702417410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nDoes anyone have any recommendations for data dictionary software? I've used excel before, but really want something more interactive!\n\nThanks", "author_fullname": "t2_674ibeps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data dictionaries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gupwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702410846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any recommendations for data dictionary software? I&amp;#39;ve used excel before, but really want something more interactive!&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gupwv", "is_robot_indexable": true, "report_reasons": null, "author": "atrifleamused", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gupwv/data_dictionaries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gupwv/data_dictionaries/", "subreddit_subscribers": 145624, "created_utc": 1702410846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an Azure Synapse dedicated SQL pool with 400 DWU.  It is set to replicated distribution policy.\n\nWithin this, we have a table with 600,000 rows and approximately 80 columns.  This table is similar to a table in an on-prem SQL Server database.  We have created the same indexes in the SQL pool version of the table that are on the original SQL Server database version.  We have a problem with our query performance.\n\nAggregations are fast but SELECTs are slow (&gt; 5 minutes). Even the count is faster.  The same table in SQL Server runs SELECT in 1 min 30 seconds.\n\nWe have run out of ideas for why the SELECT statement \\[SELECT \\* FROM tablename\\] runs in about 1.5 minutes in the SQL Server version but over 5 minutes in the Azure version.  Has anyone come across a situation like this?  ", "author_fullname": "t2_5lfqidpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Dedicated SQL Pool Performance Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gtfzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702407615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an Azure Synapse dedicated SQL pool with 400 DWU.  It is set to replicated distribution policy.&lt;/p&gt;\n\n&lt;p&gt;Within this, we have a table with 600,000 rows and approximately 80 columns.  This table is similar to a table in an on-prem SQL Server database.  We have created the same indexes in the SQL pool version of the table that are on the original SQL Server database version.  We have a problem with our query performance.&lt;/p&gt;\n\n&lt;p&gt;Aggregations are fast but SELECTs are slow (&amp;gt; 5 minutes). Even the count is faster.  The same table in SQL Server runs SELECT in 1 min 30 seconds.&lt;/p&gt;\n\n&lt;p&gt;We have run out of ideas for why the SELECT statement [SELECT * FROM tablename] runs in about 1.5 minutes in the SQL Server version but over 5 minutes in the Azure version.  Has anyone come across a situation like this?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gtfzr", "is_robot_indexable": true, "report_reasons": null, "author": "imani_TqiynAZU", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gtfzr/azure_synapse_dedicated_sql_pool_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gtfzr/azure_synapse_dedicated_sql_pool_performance/", "subreddit_subscribers": 145624, "created_utc": 1702407615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone keen to help me do that?", "author_fullname": "t2_7xqqfkwm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for help to build Xero ETL process on Mage.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqkq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone keen to help me do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gqkq5", "is_robot_indexable": true, "report_reasons": null, "author": "DisastrousMagician16", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gqkq5/looking_for_help_to_build_xero_etl_process_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gqkq5/looking_for_help_to_build_xero_etl_process_on/", "subreddit_subscribers": 145624, "created_utc": 1702400376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Performance Airbyte Alternative (With marketplace &amp; rev-share option).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_18gocy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RXisw1vYyrryutL98IO-maYwVLytLI2DsmM2KmTLwJY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702394682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/cloudquery/cloudquery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?auto=webp&amp;s=dd143a7f9b6a9015459c3dc772da9e98db7b6f47", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=147893b3db6dd4cae150c8886e4e7626cfbbad73", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1a14790a267d49a600b795d0e69becaa0f880bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89f0f40761cef4a98448da8d705fc0f7ac8da098", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ea4fd467efb9e12fdf42002ceadf2610ce7bb27", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c47a44b980bda39bba79f42cced4432f1d67a1e7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9817a5e9a3d1d6e3e2cd0fb13006fde1cb8be7a", "width": 1080, "height": 540}], "variants": {}, "id": "PYdEfT0qlVl6WVtoPac0-CRAKGdhmLIlFgFnNSh3Qcw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18gocy7", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gocy7/high_performance_airbyte_alternative_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/cloudquery/cloudquery", "subreddit_subscribers": 145624, "created_utc": 1702394682.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}