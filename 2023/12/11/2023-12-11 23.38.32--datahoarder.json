{"kind": "Listing", "data": {"after": "t3_18g3977", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My server has two plastic space fillers and empty bays. What\u2019s the most Data-Hoarder-y thing to do with that space?", "author_fullname": "t2_11dcf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data hoarders with servers that have 5.25 inch bays. What do you put in those things?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fisxb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702257752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My server has two plastic space fillers and empty bays. What\u2019s the most Data-Hoarder-y thing to do with that space?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fisxb", "is_robot_indexable": true, "report_reasons": null, "author": "wonka88", "discussion_type": null, "num_comments": 109, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fisxb/data_hoarders_with_servers_that_have_525_inch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fisxb/data_hoarders_with_servers_that_have_525_inch/", "subreddit_subscribers": 717961, "created_utc": 1702257752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm finally getting around to backing up my data properly. 3-2-1 rule - or at least 3-1-1 rule because I can only afford hard drives.\n\nMy question is - when a hard drive fails, and no data is lost because I had duplications, what do I do with the drive? I used to send it to a data recovery center, but now that I have duplications there's no point. Do I try and repair it? Scrap it somehow? Simply bin it?\n\nFollow up question: How do data centers deal with this? I read plenty about the data arrangements they use so that when drives fail, they can just 'replace' them with no loss of data. But what happens to all those old drives that get 'replaced'?\n\nSeems a bit wasteful and inefficient to spend the hundreds of dollars on a drive then just bin it a few years later when it's done its job.", "author_fullname": "t2_mkv24q0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with failed hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fx69z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702308732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finally getting around to backing up my data properly. 3-2-1 rule - or at least 3-1-1 rule because I can only afford hard drives.&lt;/p&gt;\n\n&lt;p&gt;My question is - when a hard drive fails, and no data is lost because I had duplications, what do I do with the drive? I used to send it to a data recovery center, but now that I have duplications there&amp;#39;s no point. Do I try and repair it? Scrap it somehow? Simply bin it?&lt;/p&gt;\n\n&lt;p&gt;Follow up question: How do data centers deal with this? I read plenty about the data arrangements they use so that when drives fail, they can just &amp;#39;replace&amp;#39; them with no loss of data. But what happens to all those old drives that get &amp;#39;replaced&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;Seems a bit wasteful and inefficient to spend the hundreds of dollars on a drive then just bin it a few years later when it&amp;#39;s done its job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fx69z", "is_robot_indexable": true, "report_reasons": null, "author": "tinnitushaver_69421", "discussion_type": null, "num_comments": 106, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fx69z/what_do_you_do_with_failed_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fx69z/what_do_you_do_with_failed_hard_drives/", "subreddit_subscribers": 717961, "created_utc": 1702308732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to do this when I had limited data, downloaded at home so I\u2019ve always got something to listen to when I\u2019m out. \n\nData hasn\u2019t been a problem for a while, but habits die hard. \n\nI have almost 3 month\u2019s worth if I listened to them 12 hours a day. All curated. No batch downloads.", "author_fullname": "t2_q3sqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anybody else hoard podcasts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_18fkm1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/c9sLf2hDI8MXFG0zmMCvKpIbHG5yK16cQ6GBdzPmFq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702263475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to do this when I had limited data, downloaded at home so I\u2019ve always got something to listen to when I\u2019m out. &lt;/p&gt;\n\n&lt;p&gt;Data hasn\u2019t been a problem for a while, but habits die hard. &lt;/p&gt;\n\n&lt;p&gt;I have almost 3 month\u2019s worth if I listened to them 12 hours a day. All curated. No batch downloads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ae192t6azk5c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ae192t6azk5c1.jpg?auto=webp&amp;s=cf86641a93382be1c3335b8cd7dbd285d077b13b", "width": 841, "height": 386}, "resolutions": [{"url": "https://preview.redd.it/ae192t6azk5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c2acf33c979ade4bcd7c2ff14b11a4ce673e87a", "width": 108, "height": 49}, {"url": "https://preview.redd.it/ae192t6azk5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0aa815551556ed2f08ddbc48b18ebea3462a9578", "width": 216, "height": 99}, {"url": "https://preview.redd.it/ae192t6azk5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07a3641edb559c961237c986b510f6ce3cd85837", "width": 320, "height": 146}, {"url": "https://preview.redd.it/ae192t6azk5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd233f581333f3ec51f6b3f8438be367a3746cfc", "width": 640, "height": 293}], "variants": {}, "id": "Hkl9kwR_6CbIAsrQ45NAnVqhzk1HwjdlqjDErIlf_CE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18fkm1y", "is_robot_indexable": true, "report_reasons": null, "author": "glytxh", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fkm1y/does_anybody_else_hoard_podcasts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ae192t6azk5c1.jpg", "subreddit_subscribers": 717961, "created_utc": 1702263475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have like 30TB of data (+backups to that) of 2-8GB files. Those files are are non-compressible bricks, but are mostly similar to each other bit to bit like 20-80%. Looking for software that would \"compress\" them by comparison and removal of similar parts and storing the difference only. \nMost useful would be, if it created a virtual drive where other programs would see those files normally, and while reading it would make them whole from real parts stored. \nTried to Google it, without success, but I know something similar was out there/was reading about it a while ago. Any ideas? Ring any bells? \nEdit: files are iterations of diffusion models saved as .safetensors files. Mostly 8GB by size. Difference is about 20% in file to file inside a batch.", "author_fullname": "t2_7dyqbygn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there software to compress large but similar files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fuyb8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702322368.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702302562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have like 30TB of data (+backups to that) of 2-8GB files. Those files are are non-compressible bricks, but are mostly similar to each other bit to bit like 20-80%. Looking for software that would &amp;quot;compress&amp;quot; them by comparison and removal of similar parts and storing the difference only. \nMost useful would be, if it created a virtual drive where other programs would see those files normally, and while reading it would make them whole from real parts stored. \nTried to Google it, without success, but I know something similar was out there/was reading about it a while ago. Any ideas? Ring any bells? \nEdit: files are iterations of diffusion models saved as .safetensors files. Mostly 8GB by size. Difference is about 20% in file to file inside a batch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fuyb8", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Ebb-584", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fuyb8/is_there_software_to_compress_large_but_similar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fuyb8/is_there_software_to_compress_large_but_similar/", "subreddit_subscribers": 717961, "created_utc": 1702302562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there guys,I'm about getting a new,maybe, couple of Hdds, for my daily PC , there's a drawback using the Seagate exos lineup? Specifically this one's:\n\nSeagate Exos 7E8 ST8000NM004A 8TB 512e Enterprise SATA Hard Drive\n\nEnterprise C EXOS X18 14TB 3.5IN 7200RPM SATA Helium 512E\n\nI know the exos in general are a little bit more louder and as little bit more power consumption, but aside from that, there's any big drawback on using them on Daily PC?\n\nThanks", "author_fullname": "t2_q09rbmy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any drawback using Seagate exos on daily PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fojml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702277582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there guys,I&amp;#39;m about getting a new,maybe, couple of Hdds, for my daily PC , there&amp;#39;s a drawback using the Seagate exos lineup? Specifically this one&amp;#39;s:&lt;/p&gt;\n\n&lt;p&gt;Seagate Exos 7E8 ST8000NM004A 8TB 512e Enterprise SATA Hard Drive&lt;/p&gt;\n\n&lt;p&gt;Enterprise C EXOS X18 14TB 3.5IN 7200RPM SATA Helium 512E&lt;/p&gt;\n\n&lt;p&gt;I know the exos in general are a little bit more louder and as little bit more power consumption, but aside from that, there&amp;#39;s any big drawback on using them on Daily PC?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fojml", "is_robot_indexable": true, "report_reasons": null, "author": "SkyBk", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fojml/any_drawback_using_seagate_exos_on_daily_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fojml/any_drawback_using_seagate_exos_on_daily_pc/", "subreddit_subscribers": 717961, "created_utc": 1702277582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi community, I want to know if there's a way I could download an entire movie website. The site in question is [https://play.cine.ar/](https://play.cine.ar/)  , an Argentinian free streaming site that publishes local movies. We had elections this year and the new president is very much against anything that's funded by the government, I\u00b4m worried it could get taken down.\n\nI\u00b4d like to preserve this site in the case it gets defunded, it has a huge historic value as it hosts thousand of movies that you can\u00b4t find anywere else.\n\nIn my house we get together weekly with family to watch some cinear, I love it so much it would break my heart to see it go. \n\nAnyway I could do this? Help me please, thanks", "author_fullname": "t2_2qg59mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving a local movie site before it (let's hope not) disappears", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g1uar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702322974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community, I want to know if there&amp;#39;s a way I could download an entire movie website. The site in question is &lt;a href=\"https://play.cine.ar/\"&gt;https://play.cine.ar/&lt;/a&gt;  , an Argentinian free streaming site that publishes local movies. We had elections this year and the new president is very much against anything that&amp;#39;s funded by the government, I\u00b4m worried it could get taken down.&lt;/p&gt;\n\n&lt;p&gt;I\u00b4d like to preserve this site in the case it gets defunded, it has a huge historic value as it hosts thousand of movies that you can\u00b4t find anywere else.&lt;/p&gt;\n\n&lt;p&gt;In my house we get together weekly with family to watch some cinear, I love it so much it would break my heart to see it go. &lt;/p&gt;\n\n&lt;p&gt;Anyway I could do this? Help me please, thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g1uar", "is_robot_indexable": true, "report_reasons": null, "author": "frufruf", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18g1uar/archiving_a_local_movie_site_before_it_lets_hope/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18g1uar/archiving_a_local_movie_site_before_it_lets_hope/", "subreddit_subscribers": 717961, "created_utc": 1702322974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's not officially supported (I'd pay for it if that was an option), but I *can* individually open each photo in full quality and save to disk (they even provide a download button). So I'm just looking for a downloader tool or other way to automate that process to extract all photos. EXIF data is preserved so no other metadata is needed, just the JPEG files.\n\nAny help appreciated, especially if you have any experience with this particular site!", "author_fullname": "t2_4cmkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any suggestions for downloading years' worth of photos from Family Album (mitene.us)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fhju3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702253914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not officially supported (I&amp;#39;d pay for it if that was an option), but I &lt;em&gt;can&lt;/em&gt; individually open each photo in full quality and save to disk (they even provide a download button). So I&amp;#39;m just looking for a downloader tool or other way to automate that process to extract all photos. EXIF data is preserved so no other metadata is needed, just the JPEG files.&lt;/p&gt;\n\n&lt;p&gt;Any help appreciated, especially if you have any experience with this particular site!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "120MB SCSI", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fhju3", "is_robot_indexable": true, "report_reasons": null, "author": "yParticle", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18fhju3/any_suggestions_for_downloading_years_worth_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fhju3/any_suggestions_for_downloading_years_worth_of/", "subreddit_subscribers": 717961, "created_utc": 1702253914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need a DAS to connect to my Windows PC. After unsatisfactory experiences with USB DAS devices, I'm looking for something faster and more stable. QNAP has the TL-D400S, a four-bay DAS enclosure which connects to an included ASM1164-based PCI-E card via an SFF-8088 cable.\n\nThere are very few user reviews or discussions about this product to be found online, which makes me a little wary of it. I'm also not particularly excited about giving QNAP more of my money after my recent experience with the TR-002. That was an overpriced, underperforming product and QNAP's support wasn't great either. The TL-D400S even seems to use the same flimsy drive trays as the TR-002.\n\nIs anyone using the TL-D400S, especially with Windows? How has it been?\n\nAlso, are there any other non-USB DAS products similar to the TL-D400S that will work with Windows?\n\n&amp;#x200B;", "author_fullname": "t2_72fm42nb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using the QNAP TL-D400S SFF-8088 DAS? Any recommended alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ftn7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702298399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a DAS to connect to my Windows PC. After unsatisfactory experiences with USB DAS devices, I&amp;#39;m looking for something faster and more stable. QNAP has the TL-D400S, a four-bay DAS enclosure which connects to an included ASM1164-based PCI-E card via an SFF-8088 cable.&lt;/p&gt;\n\n&lt;p&gt;There are very few user reviews or discussions about this product to be found online, which makes me a little wary of it. I&amp;#39;m also not particularly excited about giving QNAP more of my money after my recent experience with the TR-002. That was an overpriced, underperforming product and QNAP&amp;#39;s support wasn&amp;#39;t great either. The TL-D400S even seems to use the same flimsy drive trays as the TR-002.&lt;/p&gt;\n\n&lt;p&gt;Is anyone using the TL-D400S, especially with Windows? How has it been?&lt;/p&gt;\n\n&lt;p&gt;Also, are there any other non-USB DAS products similar to the TL-D400S that will work with Windows?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ftn7r", "is_robot_indexable": true, "report_reasons": null, "author": "ScrioteMyRewquards", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ftn7r/anyone_using_the_qnap_tld400s_sff8088_das_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ftn7r/anyone_using_the_qnap_tld400s_sff8088_das_any/", "subreddit_subscribers": 717961, "created_utc": 1702298399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to get decent NAS setup for under $300? I've been looking at 1 and 2 bay setups and they always end up closer to $500+. Unless I go with a buffalo setup, I don't see a way to do this. Buffalo doesn't seem to be a \"good\" option though for long term use. At this point I've been looking all day but I feel I'm a bit out of my depth. Please help with any recommendations?\n\nThis is primarily for my wifes use. My wife is not tech savvy at all, and I'm not much better. We just want an accessible spot to backup family photos and some documents that doesn't take a subscription. My wife takes a lot of photos... Probably best to start with at least a couple TB.", "author_fullname": "t2_lb2ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I setup NAS for under $300?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fhcgt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702253309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to get decent NAS setup for under $300? I&amp;#39;ve been looking at 1 and 2 bay setups and they always end up closer to $500+. Unless I go with a buffalo setup, I don&amp;#39;t see a way to do this. Buffalo doesn&amp;#39;t seem to be a &amp;quot;good&amp;quot; option though for long term use. At this point I&amp;#39;ve been looking all day but I feel I&amp;#39;m a bit out of my depth. Please help with any recommendations?&lt;/p&gt;\n\n&lt;p&gt;This is primarily for my wifes use. My wife is not tech savvy at all, and I&amp;#39;m not much better. We just want an accessible spot to backup family photos and some documents that doesn&amp;#39;t take a subscription. My wife takes a lot of photos... Probably best to start with at least a couple TB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fhcgt", "is_robot_indexable": true, "report_reasons": null, "author": "MalkavTepes", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fhcgt/can_i_setup_nas_for_under_300/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fhcgt/can_i_setup_nas_for_under_300/", "subreddit_subscribers": 717961, "created_utc": 1702253309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello y all, I am trying to download a website. That has a index page containing all the pages of the websites. \nI do not understand if there is a way to download this page and then all the links would be converted to local links after the website has been downloaded. \nIs there a way to achieve this ? \nThanks for your help", "author_fullname": "t2_24wxjalc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recursive Website Archiver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fqr6a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702287239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello y all, I am trying to download a website. That has a index page containing all the pages of the websites. \nI do not understand if there is a way to download this page and then all the links would be converted to local links after the website has been downloaded. \nIs there a way to achieve this ? \nThanks for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fqr6a", "is_robot_indexable": true, "report_reasons": null, "author": "Heewllett", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fqr6a/recursive_website_archiver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fqr6a/recursive_website_archiver/", "subreddit_subscribers": 717961, "created_utc": 1702287239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm starting my home lab and I'm toying with the idea of getting some 4TB drives to start with my unraid box. Using [diskprices.com](https://diskprices.com) it looks like Seagate ST4000NM0033 are a good deal.. Being this is my first venture into storage for home use, do you recommend these drives? If not what is a good alternative?  \n\n\n I bought 10x 2tb drives on ebay for $70 then found out they are SAS.. between a GPU, 10GbE NIC, NVMe SSDs.. I'm worried I'll run out of PCI-e lanes and would like to keep things simplified..   \n\n\nI will be picking up a new 10TB+ drive as a parity drive along with some NVME Gen4 SSD cache (cheap used drives on ebay) to help speed up the array. \n\n# ", "author_fullname": "t2_9xc8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4TB Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18g5ys5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702333043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting my home lab and I&amp;#39;m toying with the idea of getting some 4TB drives to start with my unraid box. Using &lt;a href=\"https://diskprices.com\"&gt;diskprices.com&lt;/a&gt; it looks like Seagate ST4000NM0033 are a good deal.. Being this is my first venture into storage for home use, do you recommend these drives? If not what is a good alternative?  &lt;/p&gt;\n\n&lt;p&gt;I bought 10x 2tb drives on ebay for $70 then found out they are SAS.. between a GPU, 10GbE NIC, NVMe SSDs.. I&amp;#39;m worried I&amp;#39;ll run out of PCI-e lanes and would like to keep things simplified..   &lt;/p&gt;\n\n&lt;p&gt;I will be picking up a new 10TB+ drive as a parity drive along with some NVME Gen4 SSD cache (cheap used drives on ebay) to help speed up the array. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g5ys5", "is_robot_indexable": true, "report_reasons": null, "author": "DeviatedSpeed", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18g5ys5/4tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18g5ys5/4tb_drives/", "subreddit_subscribers": 717961, "created_utc": 1702333043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hypothetically speaking; if I were to permanently seal away my Mdisc full of photo/video memories, what would I do to ensure it stays preserved and safe?   \n\n\nI'm thinking the initial layer should be cotton fabric wrapping, then add some silica desiccant sachets before wrapping it in tinfoil (does it even need to be Faraday-caged?), then another layer of cloth, then place the bundle in a sturdy waterproof and fireproof metal safe. Should I add anything to that? Perhaps an outer bubble-wrap layer for shock absorption.   \n\n\nMy reasoning for using metal layers is to make sure it never degrades on a molecular level from centuries of solar radiation, but who knows", "author_fullname": "t2_t2aft6uj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the safest way to store an M-Disc (mdisc)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18g565b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702331103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hypothetically speaking; if I were to permanently seal away my Mdisc full of photo/video memories, what would I do to ensure it stays preserved and safe?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking the initial layer should be cotton fabric wrapping, then add some silica desiccant sachets before wrapping it in tinfoil (does it even need to be Faraday-caged?), then another layer of cloth, then place the bundle in a sturdy waterproof and fireproof metal safe. Should I add anything to that? Perhaps an outer bubble-wrap layer for shock absorption.   &lt;/p&gt;\n\n&lt;p&gt;My reasoning for using metal layers is to make sure it never degrades on a molecular level from centuries of solar radiation, but who knows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g565b", "is_robot_indexable": true, "report_reasons": null, "author": "TurboPoodle", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18g565b/whats_the_safest_way_to_store_an_mdisc_mdisc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18g565b/whats_the_safest_way_to_store_an_mdisc_mdisc/", "subreddit_subscribers": 717961, "created_utc": 1702331103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a large and constantly growing collection of audio CDs. For many years now, I have been securely ripping these CDs as soon as I open them for the first time, and the resulting files are all immaculately organized and tagged. I already maintain multiple copies of the directory where these rips live, but a recent disk failure got me interested in making an offline backup to BD to store off-site (along with a matching optical drive).\n\nEach release lives in its own subdirectory. In the case of releases with multiple discs, each disc has its own subdirectory inside the release's subdirectory. Since it's easier to understand visually, here's the naming convention:\n\n```Codec - Source/ArtistName - ReleaseYear - ReleaseTitle[ - EditionNotes] - Codec/## TrackName.ext```  \n```Codec - Source/ArtistName - ReleaseYear - ReleaseTitle[ - EditionNotes] - #xCD - Codec/Disc #[ - DiscTitle]/TrackNumber Trackname.ext```\n\n----\n\nWhat I'm looking for is a backup or disc authoring software that will automatically split the parent directory's contents across multiple discs\u2014preferably *without* further splitting the contents of the subdirectories, but that's an optional nitpicky requirement\u2014and produce a list (either in plain text, CSV, or something similar) with the contents of each disc that I can use to print inserts for their storage cases.\n\nI'm fine with either free or paid options\u2014though I would prefer an open-source solution\u2014for either macOS or Windows, so long as the contents of the resulting discs are not modified in any way (*i.e.*, no proprietary formats). So far I've mostly looked at using the classic disc authoring solutions\u2014ImgBurn, Nero, Roxio, etc.\u2014rather than something designed specifically for creating backups, so I'd like to know if there is backup software out there with support for writing to optical media that could streamline the process. It's surprisingly difficult to search for information on this that doesn't return results for \"backing up\" the contents of commercial discs.\n\nAnyway, I'm just curious what's out there and if anyone in this community has any experience they can share on this topic. I can always do the directory splitting and documentation manually if it comes to that. I also know optical backups are mostly a thing of the past at this point, but it seems like there are few (if any) other archival oriented offline backup solutions available to home/prosumer users these days.\n\n----\n\nImportant context:\n\n1. I know.\n2. Don't tell me not to do this.\n3. No, really.\n4. Please.\n5. I already have known-good and tested 3-2-1 backups in place for this data. I'm doing this for extra peace of mind.", "author_fullname": "t2_19kzaq74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing Up to Optical Media - Software Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fzvs2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702316240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large and constantly growing collection of audio CDs. For many years now, I have been securely ripping these CDs as soon as I open them for the first time, and the resulting files are all immaculately organized and tagged. I already maintain multiple copies of the directory where these rips live, but a recent disk failure got me interested in making an offline backup to BD to store off-site (along with a matching optical drive).&lt;/p&gt;\n\n&lt;p&gt;Each release lives in its own subdirectory. In the case of releases with multiple discs, each disc has its own subdirectory inside the release&amp;#39;s subdirectory. Since it&amp;#39;s easier to understand visually, here&amp;#39;s the naming convention:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Codec - Source/ArtistName - ReleaseYear - ReleaseTitle[ - EditionNotes] - Codec/## TrackName.ext&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;Codec - Source/ArtistName - ReleaseYear - ReleaseTitle[ - EditionNotes] - #xCD - Codec/Disc #[ - DiscTitle]/TrackNumber Trackname.ext&lt;/code&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is a backup or disc authoring software that will automatically split the parent directory&amp;#39;s contents across multiple discs\u2014preferably &lt;em&gt;without&lt;/em&gt; further splitting the contents of the subdirectories, but that&amp;#39;s an optional nitpicky requirement\u2014and produce a list (either in plain text, CSV, or something similar) with the contents of each disc that I can use to print inserts for their storage cases.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fine with either free or paid options\u2014though I would prefer an open-source solution\u2014for either macOS or Windows, so long as the contents of the resulting discs are not modified in any way (&lt;em&gt;i.e.&lt;/em&gt;, no proprietary formats). So far I&amp;#39;ve mostly looked at using the classic disc authoring solutions\u2014ImgBurn, Nero, Roxio, etc.\u2014rather than something designed specifically for creating backups, so I&amp;#39;d like to know if there is backup software out there with support for writing to optical media that could streamline the process. It&amp;#39;s surprisingly difficult to search for information on this that doesn&amp;#39;t return results for &amp;quot;backing up&amp;quot; the contents of commercial discs.&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m just curious what&amp;#39;s out there and if anyone in this community has any experience they can share on this topic. I can always do the directory splitting and documentation manually if it comes to that. I also know optical backups are mostly a thing of the past at this point, but it seems like there are few (if any) other archival oriented offline backup solutions available to home/prosumer users these days.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Important context:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I know.&lt;/li&gt;\n&lt;li&gt;Don&amp;#39;t tell me not to do this.&lt;/li&gt;\n&lt;li&gt;No, really.&lt;/li&gt;\n&lt;li&gt;Please.&lt;/li&gt;\n&lt;li&gt;I already have known-good and tested 3-2-1 backups in place for this data. I&amp;#39;m doing this for extra peace of mind.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fzvs2", "is_robot_indexable": true, "report_reasons": null, "author": "synthmage00", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fzvs2/backing_up_to_optical_media_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fzvs2/backing_up_to_optical_media_software/", "subreddit_subscribers": 717961, "created_utc": 1702316240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have several external drives that I've collected over the years, and I have a lot of duplicate data across them. I was wanting to kind of reset and start over with just one drive with one copy of all the data from all the drives before trying to figure out a more robust system of redundancy and whatnot. Are there any methods or applications or tools that would help automate this or at least make this more efficient/reliable/faster than just manually going through and doing `copy, paste, skip duplicates, delete/format` on each drive?\n\nHard criteria would be that it would have to be free, as I'd rather just spend the time to do it manually rather than pay \ud83d\ude05 I mainly use and prefer macOS, but I have access to Windows machines as well.", "author_fullname": "t2_9n8234m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consolidating data from multiple drives to one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fxipy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702309663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several external drives that I&amp;#39;ve collected over the years, and I have a lot of duplicate data across them. I was wanting to kind of reset and start over with just one drive with one copy of all the data from all the drives before trying to figure out a more robust system of redundancy and whatnot. Are there any methods or applications or tools that would help automate this or at least make this more efficient/reliable/faster than just manually going through and doing &lt;code&gt;copy, paste, skip duplicates, delete/format&lt;/code&gt; on each drive?&lt;/p&gt;\n\n&lt;p&gt;Hard criteria would be that it would have to be free, as I&amp;#39;d rather just spend the time to do it manually rather than pay \ud83d\ude05 I mainly use and prefer macOS, but I have access to Windows machines as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fxipy", "is_robot_indexable": true, "report_reasons": null, "author": "justwinata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fxipy/consolidating_data_from_multiple_drives_to_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fxipy/consolidating_data_from_multiple_drives_to_one/", "subreddit_subscribers": 717961, "created_utc": 1702309663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would consider myself relatively tech savvy (I built my own computer, and set up my home network, but never did any kind of training whatsoever) and I want to buy a NAS. I'm looking to do the following with it: \n\n- use it as a cloud storage instead is paying monthly for Google drive (Android and Windows house mostly with the exception of a MacBook)\n\n- use it as a media server to sail the high seas\n\nMy wife is a digital hoarder (to the point where her Google account is basically locked up with pictures and videos, with a total inability to send our receive emails. She can't even create a gdoc). She is also very tech illiterate so if I replace her Google drive with a home cloud storage, it needs to be extra easy to use for her. She likes the features that Google photos offers in terms of searching and how photos organizes her pictures by person. I thought about paying for a bigger cloud storage on Google, but I can't foresee a situation where she doesn't fill that up too and then I'm stuck paying monthly just so Google doesn't delete her stuff. \n\nMy question is, is hosting a home cloud server with a NAS a viable option for me? Is the interface easy to use on the phone? How does it communicate with my TV for things like Plex? Which model would be good for me? I would like to set up a raid to ensure that our family pictures don't get lost if one drive happens to fail. My budget is not unlimited, but I'm ok to spend a few hundred on something like this.", "author_fullname": "t2_ci2kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is getting a NAS the right solution for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ftqco", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702298685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would consider myself relatively tech savvy (I built my own computer, and set up my home network, but never did any kind of training whatsoever) and I want to buy a NAS. I&amp;#39;m looking to do the following with it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;use it as a cloud storage instead is paying monthly for Google drive (Android and Windows house mostly with the exception of a MacBook)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;use it as a media server to sail the high seas&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My wife is a digital hoarder (to the point where her Google account is basically locked up with pictures and videos, with a total inability to send our receive emails. She can&amp;#39;t even create a gdoc). She is also very tech illiterate so if I replace her Google drive with a home cloud storage, it needs to be extra easy to use for her. She likes the features that Google photos offers in terms of searching and how photos organizes her pictures by person. I thought about paying for a bigger cloud storage on Google, but I can&amp;#39;t foresee a situation where she doesn&amp;#39;t fill that up too and then I&amp;#39;m stuck paying monthly just so Google doesn&amp;#39;t delete her stuff. &lt;/p&gt;\n\n&lt;p&gt;My question is, is hosting a home cloud server with a NAS a viable option for me? Is the interface easy to use on the phone? How does it communicate with my TV for things like Plex? Which model would be good for me? I would like to set up a raid to ensure that our family pictures don&amp;#39;t get lost if one drive happens to fail. My budget is not unlimited, but I&amp;#39;m ok to spend a few hundred on something like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ftqco", "is_robot_indexable": true, "report_reasons": null, "author": "fornoggg", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ftqco/is_getting_a_nas_the_right_solution_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ftqco/is_getting_a_nas_the_right_solution_for_me/", "subreddit_subscribers": 717961, "created_utc": 1702298685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5hleg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CaptureGem: a multi-threaded app for saving recordings from a variety of adult cam sites including VR recordings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 115, "top_awarded_type": null, "hide_score": false, "name": "t3_18fksgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702264036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "capturegem.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.capturegem.com/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?auto=webp&amp;s=7f01090d5ba915f52bcac63bab3a0cf2e7ff92fb", "width": 1632, "height": 1350}, "resolutions": [{"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d481d9d8c7c8749d34807ca8bf67ac600b273dc2", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=24804cde631ca9ed128cbb7d799c2d66f8f29bed", "width": 216, "height": 178}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a897777650ad729c866b6cdaec14cff274c4699e", "width": 320, "height": 264}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35997cec4985405a5fc2ae1343ac54bb2ef661d8", "width": 640, "height": 529}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3161916dca47bf02b6bc252cf47f2774be9aa7b", "width": 960, "height": 794}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da02f44d9eae8ff1aee5652b922fc3e57bb06ad4", "width": 1080, "height": 893}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2d608208d9025bfb26c00bc3c51855fbd764c665", "width": 1632, "height": 1350}, "resolutions": [{"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=0996c2c10b4b54fd6a79356216c660632d87062b", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=b5b8d5c44ebe159ac017d4735ef819c6a8588c1b", "width": 216, "height": 178}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=49116012f94430606e0cac3541af656dbbdf0a3d", "width": 320, "height": 264}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2e4e1ab6b8841f750fba9fea015ca27e5a718245", "width": 640, "height": 529}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=bf65b432151942087b700aa6a5bcb092c5ebaa12", "width": 960, "height": 794}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f61d4c92201b15af49e310d11ed54063e3982a9f", "width": 1080, "height": 893}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2d608208d9025bfb26c00bc3c51855fbd764c665", "width": 1632, "height": 1350}, "resolutions": [{"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=0996c2c10b4b54fd6a79356216c660632d87062b", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=b5b8d5c44ebe159ac017d4735ef819c6a8588c1b", "width": 216, "height": 178}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=49116012f94430606e0cac3541af656dbbdf0a3d", "width": 320, "height": 264}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2e4e1ab6b8841f750fba9fea015ca27e5a718245", "width": 640, "height": 529}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=bf65b432151942087b700aa6a5bcb092c5ebaa12", "width": 960, "height": 794}, {"url": "https://external-preview.redd.it/vAr_4cgB4zwncW4onNc5hcBz6l4ft_xiFtc2t5DqQnU.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f61d4c92201b15af49e310d11ed54063e3982a9f", "width": 1080, "height": 893}]}}, "id": "GuVxVKhxVeaoc19kPZfUDv8DNLEiDZPuP2XmGNsxcA8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fksgp", "is_robot_indexable": true, "report_reasons": null, "author": "lordofindia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fksgp/capturegem_a_multithreaded_app_for_saving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.capturegem.com/", "subreddit_subscribers": 717961, "created_utc": 1702264036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've researched and found about pigz/parallelLZMA which is good for Multi-CPU servers, is it possible to combine, instead of CPUs, multiple servers to compress files?\n\nI'm using Ceph and I need to compress heavy files (&gt;50GB), as I need speed + good compression to hoard the most possible, using a single CPU takes a few hours, it's too slow and each server got a powerful CPU that's being 'wasted'. does a software exist for multi-server compression?", "author_fullname": "t2_3gdxkeob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compress files with multiple servers? Is this possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fhi0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702254127.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702253763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve researched and found about pigz/parallelLZMA which is good for Multi-CPU servers, is it possible to combine, instead of CPUs, multiple servers to compress files?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Ceph and I need to compress heavy files (&amp;gt;50GB), as I need speed + good compression to hoard the most possible, using a single CPU takes a few hours, it&amp;#39;s too slow and each server got a powerful CPU that&amp;#39;s being &amp;#39;wasted&amp;#39;. does a software exist for multi-server compression?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "42TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fhi0g", "is_robot_indexable": true, "report_reasons": null, "author": "JoaGamo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18fhi0g/compress_files_with_multiple_servers_is_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fhi0g/compress_files_with_multiple_servers_is_this/", "subreddit_subscribers": 717961, "created_utc": 1702253763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys and gals, long time lurker first time poster. I am going to try to include as much information as possible and be as clear as I can. If something doesn\u2019t make sense I apologize, let me know and I\u2019ll try to clarify. \n\nI\u2019m a photographer who also makes YouTube videos, I use a MacBook Pro M3 with a 1TB SSD onboard. I purchased an OWC Thunderbay Mini to use as primary storage when I\u2019m docked, it is setup with 4, 4TB SSD\u2019s and each mount as a separate storage volume. One is setup for RAW image intake and the second is setup for finished edits and their original RAW file counterparts. The other two are setup the same way for video. I didn\u2019t want to setup RAID on it, I wanted to use each drive separately to keep the data separated.\n\nThe OWC backs up to Backblaze, it is backed up to the cloud as I work. When I\u2019m finished with an edit I keep a copy of the edit and original RAW files together in a folder on the OWC and then copy the same folder to an offsite Synology DS220+ that also backs up to Backblaze. The images that were not selected to be edited also stay on the primary OWC on a separate drive. I basically want to take a second OWC Mini with 4, 2TB SSD\u2019s setup as 2 - 4TB pools daisychained to the primary one and use it to backup the drive holding the final photo edits, and the other drive holding the original photos. The intended purpose of the second OWC is to have a secondary physical backup onsite. \n\nMy question is this: can I setup the second Mini to backup the first using my Mac, or do I need to use a special software for that? And those of you who have more experience with this, is this a viable backup solution? Any recommendations? \n\nThanks in advance!", "author_fullname": "t2_jl7hvcb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OWC Thunderbay Mini Daisychain Backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fh4xy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702252722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys and gals, long time lurker first time poster. I am going to try to include as much information as possible and be as clear as I can. If something doesn\u2019t make sense I apologize, let me know and I\u2019ll try to clarify. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m a photographer who also makes YouTube videos, I use a MacBook Pro M3 with a 1TB SSD onboard. I purchased an OWC Thunderbay Mini to use as primary storage when I\u2019m docked, it is setup with 4, 4TB SSD\u2019s and each mount as a separate storage volume. One is setup for RAW image intake and the second is setup for finished edits and their original RAW file counterparts. The other two are setup the same way for video. I didn\u2019t want to setup RAID on it, I wanted to use each drive separately to keep the data separated.&lt;/p&gt;\n\n&lt;p&gt;The OWC backs up to Backblaze, it is backed up to the cloud as I work. When I\u2019m finished with an edit I keep a copy of the edit and original RAW files together in a folder on the OWC and then copy the same folder to an offsite Synology DS220+ that also backs up to Backblaze. The images that were not selected to be edited also stay on the primary OWC on a separate drive. I basically want to take a second OWC Mini with 4, 2TB SSD\u2019s setup as 2 - 4TB pools daisychained to the primary one and use it to backup the drive holding the final photo edits, and the other drive holding the original photos. The intended purpose of the second OWC is to have a secondary physical backup onsite. &lt;/p&gt;\n\n&lt;p&gt;My question is this: can I setup the second Mini to backup the first using my Mac, or do I need to use a special software for that? And those of you who have more experience with this, is this a viable backup solution? Any recommendations? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fh4xy", "is_robot_indexable": true, "report_reasons": null, "author": "Nicholas-Albert", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fh4xy/owc_thunderbay_mini_daisychain_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fh4xy/owc_thunderbay_mini_daisychain_backup/", "subreddit_subscribers": 717961, "created_utc": 1702252722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a request for the Media and artwork NOT roms. I did have the data but I migrated all my collection to a larger hard drive and lost some wheels. \n\n&amp;#x200B;\n\nHoping someone can help!\n\n&amp;#x200B;\n\nThanks In advance :)", "author_fullname": "t2_1fyfkj83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Calling Hyperspin Retro Hoarders - Trying to locate a Java Games Wheel (J2ME)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18g68v5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702333747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a request for the Media and artwork NOT roms. I did have the data but I migrated all my collection to a larger hard drive and lost some wheels. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hoping someone can help!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks In advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g68v5", "is_robot_indexable": true, "report_reasons": null, "author": "TheMaddis", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18g68v5/calling_hyperspin_retro_hoarders_trying_to_locate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18g68v5/calling_hyperspin_retro_hoarders_trying_to_locate/", "subreddit_subscribers": 717961, "created_utc": 1702333747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone know of any good itx mobos for Lga 1151 that have several sata ports? Looking to build a mini nas but want to do it in an itx case so looking for some recommendations. Thanks!", "author_fullname": "t2_hllb7n19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lga 1151 itx mobo w 5-8 sata ports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3yai", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702328123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know of any good itx mobos for Lga 1151 that have several sata ports? Looking to build a mini nas but want to do it in an itx case so looking for some recommendations. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g3yai", "is_robot_indexable": true, "report_reasons": null, "author": "SpLTitanRuler", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18g3yai/lga_1151_itx_mobo_w_58_sata_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18g3yai/lga_1151_itx_mobo_w_58_sata_ports/", "subreddit_subscribers": 717961, "created_utc": 1702328123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone,\n\nI find myself facing a challenge in my approach to data storage and could really benefit from the insights of experienced individuals here.\n\nI've been using rClone to upload content to my Google Drive, employing standard encryption for the files via the crypt remote.\n\nHere's the catch: while the files themselves are encrypted; I've left the folder names in plaintext. My rationale was to retain a sense of organization and easily identify content, with the idea of selectively downloading specific parts through rClone without fetching the entire shebang, assuming the folder names were unencrypted.\n\nHowever, I've been considering the potential security implications of having plaintext folder names, particularly concerning the confidentiality of the content. Could leaving the folder names unencrypted pose a security risk or attract unwanted attention? Should I backtrack and encrypt the folder names, sacrificing some navigational ease for enhanced security?\n\nAny help would be much appreciated! :)", "author_fullname": "t2_97n64mzf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Encryption Quandary while Uploading to Google Drive via rClone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fr4ru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702323906.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702288816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I find myself facing a challenge in my approach to data storage and could really benefit from the insights of experienced individuals here.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using rClone to upload content to my Google Drive, employing standard encryption for the files via the crypt remote.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the catch: while the files themselves are encrypted; I&amp;#39;ve left the folder names in plaintext. My rationale was to retain a sense of organization and easily identify content, with the idea of selectively downloading specific parts through rClone without fetching the entire shebang, assuming the folder names were unencrypted.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve been considering the potential security implications of having plaintext folder names, particularly concerning the confidentiality of the content. Could leaving the folder names unencrypted pose a security risk or attract unwanted attention? Should I backtrack and encrypt the folder names, sacrificing some navigational ease for enhanced security?&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fr4ru", "is_robot_indexable": true, "report_reasons": null, "author": "Slow-Journalist-8250", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fr4ru/seeking_advice_encryption_quandary_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fr4ru/seeking_advice_encryption_quandary_while/", "subreddit_subscribers": 717961, "created_utc": 1702288816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.amazon.com/gp/product/B06ZY6DK8N\n\nhttps://www.amazon.com/gp/product/B07Y4F5SCK/\n\nI'm just one dude and have no short term plans to be sharing my media across the internet to friends or whatnot. Some day I may, but not soon. \n\nThat being said - what's the key differences between these DAS setups? I 'trust' Sabrent a little more, but the Terramaster is like 40% cheaper - is there anything about it that it's lacking (besides some no-name Chinese brand implications) that should give me pause?", "author_fullname": "t2_ltxqqttey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DAS to buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fobc6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702276651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B06ZY6DK8N\"&gt;https://www.amazon.com/gp/product/B06ZY6DK8N&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B07Y4F5SCK/\"&gt;https://www.amazon.com/gp/product/B07Y4F5SCK/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just one dude and have no short term plans to be sharing my media across the internet to friends or whatnot. Some day I may, but not soon. &lt;/p&gt;\n\n&lt;p&gt;That being said - what&amp;#39;s the key differences between these DAS setups? I &amp;#39;trust&amp;#39; Sabrent a little more, but the Terramaster is like 40% cheaper - is there anything about it that it&amp;#39;s lacking (besides some no-name Chinese brand implications) that should give me pause?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fobc6", "is_robot_indexable": true, "report_reasons": null, "author": "I-Should-Travel", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fobc6/which_das_to_buy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fobc6/which_das_to_buy/", "subreddit_subscribers": 717961, "created_utc": 1702276651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In the need of more storage but M.2 ssds arent an option due to higher price\n\nI found a Patriot P220 sata ssd for 59\u20ac and a 10\u20ac usb adapter for it\n\nThe P220 should have dram\n\nThe other option is to get an Adata SE880 external ssd which is 69\u20ac. That ssd is fast but lacks dram\n\nShould i rather go with the P220 or the SE880\n\nThe SE880 does have a 5 year warranty over the P220s 3 year warranty but wouldnt dram be better reliability wise?", "author_fullname": "t2_k7tqpvpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would a Patriot P220 be decent with an usb adapter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fwq1z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702307530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the need of more storage but M.2 ssds arent an option due to higher price&lt;/p&gt;\n\n&lt;p&gt;I found a Patriot P220 sata ssd for 59\u20ac and a 10\u20ac usb adapter for it&lt;/p&gt;\n\n&lt;p&gt;The P220 should have dram&lt;/p&gt;\n\n&lt;p&gt;The other option is to get an Adata SE880 external ssd which is 69\u20ac. That ssd is fast but lacks dram&lt;/p&gt;\n\n&lt;p&gt;Should i rather go with the P220 or the SE880&lt;/p&gt;\n\n&lt;p&gt;The SE880 does have a 5 year warranty over the P220s 3 year warranty but wouldnt dram be better reliability wise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18fwq1z", "is_robot_indexable": true, "report_reasons": null, "author": "kairukar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18fwq1z/would_a_patriot_p220_be_decent_with_an_usb_adapter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18fwq1z/would_a_patriot_p220_be_decent_with_an_usb_adapter/", "subreddit_subscribers": 717961, "created_utc": 1702307530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi friends,\n\nA couple of questions for any Linux users in the crowd who are into using LTO for archival:\n\n1) Are there any drives that have guaranteed out of the box compatibility with Ubuntu Linux as a desktop OS?\n\n2) For writing onto LTO in Ubuntu ... what GUIs are out there? I currently archive using M-Disc so K3B and a USB drive is my go-to but I don't believe it supports attached tape drives.\n\nTIA!", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know of any LTO drives that are compatible with Ubuntu Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ftbdb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702297261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends,&lt;/p&gt;\n\n&lt;p&gt;A couple of questions for any Linux users in the crowd who are into using LTO for archival:&lt;/p&gt;\n\n&lt;p&gt;1) Are there any drives that have guaranteed out of the box compatibility with Ubuntu Linux as a desktop OS?&lt;/p&gt;\n\n&lt;p&gt;2) For writing onto LTO in Ubuntu ... what GUIs are out there? I currently archive using M-Disc so K3B and a USB drive is my go-to but I don&amp;#39;t believe it supports attached tape drives.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ftbdb", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ftbdb/anyone_know_of_any_lto_drives_that_are_compatible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ftbdb/anyone_know_of_any_lto_drives_that_are_compatible/", "subreddit_subscribers": 717961, "created_utc": 1702297261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Transferring video from Sony digital8 but the FireWire port on the camera is broken so I will have to do it this way. Does anyone have links to the specific cords I will need? And does anyone have experience transferring this way? Will quality be compromised much?", "author_fullname": "t2_w5fti6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have experience with this way of video transfer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3977", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/E7oxhUPNoOXPsrNQ0x5S6jWXoxQyPvY69jCsePuhGm0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702326390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Transferring video from Sony digital8 but the FireWire port on the camera is broken so I will have to do it this way. Does anyone have links to the specific cords I will need? And does anyone have experience transferring this way? Will quality be compromised much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dwh94z0d6q5c1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dwh94z0d6q5c1.jpg?auto=webp&amp;s=816c6a1b96e0fa9249190f38f7c4b1ef9404b0d8", "width": 828, "height": 1321}, "resolutions": [{"url": "https://preview.redd.it/dwh94z0d6q5c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8011ab10870a87e5e3e2b6032dcdbcd501f2261f", "width": 108, "height": 172}, {"url": "https://preview.redd.it/dwh94z0d6q5c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d639666fc0dee9121a34b546d8adeeeb9a295d2", "width": 216, "height": 344}, {"url": "https://preview.redd.it/dwh94z0d6q5c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=095d071b48056e1145698a7473bcb06161584842", "width": 320, "height": 510}, {"url": "https://preview.redd.it/dwh94z0d6q5c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b247aef68cbc12eef3766693b30f2d2bcb38bd11", "width": 640, "height": 1021}], "variants": {}, "id": "hWJlxh1_Rai2OWj1e7ZaEV-QR_x2-vkmJjtfNM0ulgw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18g3977", "is_robot_indexable": true, "report_reasons": null, "author": "sesamechicken4evr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18g3977/anyone_have_experience_with_this_way_of_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dwh94z0d6q5c1.jpg", "subreddit_subscribers": 717961, "created_utc": 1702326390.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}