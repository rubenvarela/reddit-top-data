{"kind": "Listing", "data": {"after": "t3_18jvvkr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cymqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tech-America has 61.44 TB Solidigm SSDs in stock for anyone who would like to pick up one (or more)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18jr7bi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 114, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 114, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JRDbdU5p-ih-TLRUkK1T_TfJH-PB6IdvyomTaYlbfCc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702733258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tech-america.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.tech-america.com/item/solidigm-ssd-sbfpf2bv614t001-d5-p5336-61-44tb-2-5-pcie4-0x4-3d5-qlc-retail/sbfpf2bv614t001", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/S1JCBVuI14muOgLT5HGiENcuI9RdQ6PKFRra5I3Tmec.jpg?auto=webp&amp;s=ddab834e87c77f2a20110b14192274d36fa3f585", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/S1JCBVuI14muOgLT5HGiENcuI9RdQ6PKFRra5I3Tmec.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db4eed6a6ce54fd45798353a908a24e6b13f9c60", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/S1JCBVuI14muOgLT5HGiENcuI9RdQ6PKFRra5I3Tmec.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc6e307375e63311a623141b2a9b19e3108d1a77", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/S1JCBVuI14muOgLT5HGiENcuI9RdQ6PKFRra5I3Tmec.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24413b113bcef8db88734888ee9a6f0bf1b85ec8", "width": 320, "height": 320}], "variants": {}, "id": "DonADQrU4gV7WaMEXYTEwb2zitE-NnkvTPiB8yncAH4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jr7bi", "is_robot_indexable": true, "report_reasons": null, "author": "Torley_", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jr7bi/techamerica_has_6144_tb_solidigm_ssds_in_stock/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.tech-america.com/item/solidigm-ssd-sbfpf2bv614t001-d5-p5336-61-44tb-2-5-pcie4-0x4-3d5-qlc-retail/sbfpf2bv614t001", "subreddit_subscribers": 718597, "created_utc": 1702733258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently had to recover data from my barely used 12tb Seagate Ironwolf NAS drive. \n\nThe recovery found random documents, pictures and videos that are not mine.\n\nThis drive was bought brand new from a reputable source. Is this normal practice from Seagate or should I request a refund from?", "author_fullname": "t2_bm4rjnyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal practice for new HDD to be recycled? (Contain old files)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kbkhb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702797485.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702796448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had to recover data from my barely used 12tb Seagate Ironwolf NAS drive. &lt;/p&gt;\n\n&lt;p&gt;The recovery found random documents, pictures and videos that are not mine.&lt;/p&gt;\n\n&lt;p&gt;This drive was bought brand new from a reputable source. Is this normal practice from Seagate or should I request a refund from?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18kbkhb", "is_robot_indexable": true, "report_reasons": null, "author": "solaris1101", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18kbkhb/is_it_normal_practice_for_new_hdd_to_be_recycled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18kbkhb/is_it_normal_practice_for_new_hdd_to_be_recycled/", "subreddit_subscribers": 718597, "created_utc": 1702796448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I dont know a lot about servers Just had a few websites before. But can i rent a webserver without really a website on it. And just use it for me own little cloud storage i can access anywhere. Is this  valid use case or are there better ways? I dont really know the difference between servers like what a vps is etc. And it seems you always have to get a domein name with it even tho i dont use the website function just sftp.", "author_fullname": "t2_3c7nq2fk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can i use a webserver sftp as cloud storage or is that weird, dumb?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jny5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702720146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I dont know a lot about servers Just had a few websites before. But can i rent a webserver without really a website on it. And just use it for me own little cloud storage i can access anywhere. Is this  valid use case or are there better ways? I dont really know the difference between servers like what a vps is etc. And it seems you always have to get a domein name with it even tho i dont use the website function just sftp.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jny5f", "is_robot_indexable": true, "report_reasons": null, "author": "Anakhsunamon", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jny5f/can_i_use_a_webserver_sftp_as_cloud_storage_or_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jny5f/can_i_use_a_webserver_sftp_as_cloud_storage_or_is/", "subreddit_subscribers": 718597, "created_utc": 1702720146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All!\n\nIs there a (safe) way to mirror my Linux boot drive to another disk? I recently had a scare where I thought my boot drive died, so now I want to have an automatic backup of my data\n\nTo clarify, I'm not looking for the mirror to be bootable (and would prefer it's not, to avoid the issues that could lead to) - I just want to have a second place the same data exists in case my drive dies. My first intuition is to do this with a ZFS mirror, but I'm not sure that's safe to do on the same drive ZFS is running from, or if it can be done after-the-fact when I didn't install Ubuntu on ZFS, as I know it now supports\n\nThanks!", "author_fullname": "t2_4id0x6ry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirroring Boot Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jydso", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702754240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All!&lt;/p&gt;\n\n&lt;p&gt;Is there a (safe) way to mirror my Linux boot drive to another disk? I recently had a scare where I thought my boot drive died, so now I want to have an automatic backup of my data&lt;/p&gt;\n\n&lt;p&gt;To clarify, I&amp;#39;m not looking for the mirror to be bootable (and would prefer it&amp;#39;s not, to avoid the issues that could lead to) - I just want to have a second place the same data exists in case my drive dies. My first intuition is to do this with a ZFS mirror, but I&amp;#39;m not sure that&amp;#39;s safe to do on the same drive ZFS is running from, or if it can be done after-the-fact when I didn&amp;#39;t install Ubuntu on ZFS, as I know it now supports&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jydso", "is_robot_indexable": true, "report_reasons": null, "author": "ThatFireGuy0", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jydso/mirroring_boot_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jydso/mirroring_boot_drive/", "subreddit_subscribers": 718597, "created_utc": 1702754240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello dear colleagues,  \nSince there were similar questions in the past with relatively unclear conditions, I have tried to make the subject line as clear as possible. I tried some of the previously suggested methods in older threads like Firefox add-on titled \"Reddit All Comments Viewer by Draxxx\", but it appears that one is not operational anymore - I have tried several experiments but I am not getting browser option \"Load All Comments\" with that add-on.   \n\n\nSo basically my conditions are the following:  \n\n\n\\- Tool that would allow the saving/exporting the entire Reddit thread/post - especially targeted for large threads containing over 500 comments.  \n\\- Manual options are not practical since for proper archiving the user has to manually open/expand hundreds of comments and replies to save the entire thread properly. (similar questions in the past by other users haven't explained that part well which lead to many redundant replies).  \n\\- So the tool should load all comments/replies automatically and then the entire thread could be saved properly to capture all for historical reference/offline browsing.\n\nDoes anyone know is there a working option for that currently in 2023/2024.   \n\n\nBest wishes.   \n\n\n  \n", "author_fullname": "t2_p695jcz7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best method in 2023/2024 to save/extract large Reddit threads with all comments expanded/opened for offline browsing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jo6e8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702721143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello dear colleagues,&lt;br/&gt;\nSince there were similar questions in the past with relatively unclear conditions, I have tried to make the subject line as clear as possible. I tried some of the previously suggested methods in older threads like Firefox add-on titled &amp;quot;Reddit All Comments Viewer by Draxxx&amp;quot;, but it appears that one is not operational anymore - I have tried several experiments but I am not getting browser option &amp;quot;Load All Comments&amp;quot; with that add-on.   &lt;/p&gt;\n\n&lt;p&gt;So basically my conditions are the following:  &lt;/p&gt;\n\n&lt;p&gt;- Tool that would allow the saving/exporting the entire Reddit thread/post - especially targeted for large threads containing over 500 comments.&lt;br/&gt;\n- Manual options are not practical since for proper archiving the user has to manually open/expand hundreds of comments and replies to save the entire thread properly. (similar questions in the past by other users haven&amp;#39;t explained that part well which lead to many redundant replies).&lt;br/&gt;\n- So the tool should load all comments/replies automatically and then the entire thread could be saved properly to capture all for historical reference/offline browsing.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know is there a working option for that currently in 2023/2024.   &lt;/p&gt;\n\n&lt;p&gt;Best wishes.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jo6e8", "is_robot_indexable": true, "report_reasons": null, "author": "ObservationDeck2001", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jo6e8/what_is_the_best_method_in_20232024_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jo6e8/what_is_the_best_method_in_20232024_to/", "subreddit_subscribers": 718597, "created_utc": 1702721143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does Synology DS1821+ lock out  (blacklist) third party NICs (or whitelist only theirs), or is that very short compatibility list just the devices that they guarantee will work with the DS1821+ NAS?\n\n&amp;#x200B;\n\nI was considering the TP-Link TX201", "author_fullname": "t2_5a3zhit0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synology DS1821+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k69b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702777465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does Synology DS1821+ lock out  (blacklist) third party NICs (or whitelist only theirs), or is that very short compatibility list just the devices that they guarantee will work with the DS1821+ NAS?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was considering the TP-Link TX201&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k69b0", "is_robot_indexable": true, "report_reasons": null, "author": "FalconSteve89", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k69b0/synology_ds1821/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k69b0/synology_ds1821/", "subreddit_subscribers": 718597, "created_utc": 1702777465.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm having a weird problem with idrive. I upload a file, and then try to share it with someone. I copy the link, share it, and the person tries to access. However, he can't. It's just the loading logo, and that's it.\n\nI tried with a different computer and ISP and no problem, but in my friends house, when I try with a different computer, but same ISP, same problem.\n\nDo you know whats the problem? I googled it, and nothing.\n\nThanks", "author_fullname": "t2_mp9c6lcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IDrive problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k66zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702777255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having a weird problem with idrive. I upload a file, and then try to share it with someone. I copy the link, share it, and the person tries to access. However, he can&amp;#39;t. It&amp;#39;s just the loading logo, and that&amp;#39;s it.&lt;/p&gt;\n\n&lt;p&gt;I tried with a different computer and ISP and no problem, but in my friends house, when I try with a different computer, but same ISP, same problem.&lt;/p&gt;\n\n&lt;p&gt;Do you know whats the problem? I googled it, and nothing.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k66zw", "is_robot_indexable": true, "report_reasons": null, "author": "JackL_88", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k66zw/idrive_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k66zw/idrive_problem/", "subreddit_subscribers": 718597, "created_utc": 1702777255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using a ScanPro 3000 to scan a microfiche. I can see that the document is in color but all my scans are saved in black and white. I've tried to Google this and I can't find anything that verifies that scanning in color is even an option. I'm hoping someone on this forum works in a library or has experience with these scanners and can let me know.\n\nThanks!", "author_fullname": "t2_b35w3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scanning Microfiche in color", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k3azt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702768505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using a ScanPro 3000 to scan a microfiche. I can see that the document is in color but all my scans are saved in black and white. I&amp;#39;ve tried to Google this and I can&amp;#39;t find anything that verifies that scanning in color is even an option. I&amp;#39;m hoping someone on this forum works in a library or has experience with these scanners and can let me know.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k3azt", "is_robot_indexable": true, "report_reasons": null, "author": "kyjb70", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18k3azt/scanning_microfiche_in_color/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k3azt/scanning_microfiche_in_color/", "subreddit_subscribers": 718597, "created_utc": 1702768505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nJust curious what the consensus is on saving archives of email accounts, best formats for viewing them that is somewhat 'future proof'.  What do you think about importing them into Thunderbird?  I believe Thunderbird is multi-platform.\n\nI made the mistake of using Microsoft Entourage (Mac-only) back from about 1999-2005 or so.  If I have those drives, it will be an adventure getting that database converted.", "author_fullname": "t2_6pky9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving (and future-proofing) email accounts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jua51", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702742691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Just curious what the consensus is on saving archives of email accounts, best formats for viewing them that is somewhat &amp;#39;future proof&amp;#39;.  What do you think about importing them into Thunderbird?  I believe Thunderbird is multi-platform.&lt;/p&gt;\n\n&lt;p&gt;I made the mistake of using Microsoft Entourage (Mac-only) back from about 1999-2005 or so.  If I have those drives, it will be an adventure getting that database converted.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jua51", "is_robot_indexable": true, "report_reasons": null, "author": "drycounty", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jua51/archiving_and_futureproofing_email_accounts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jua51/archiving_and_futureproofing_email_accounts/", "subreddit_subscribers": 718597, "created_utc": 1702742691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use Epson V600 Photo and \"Restore colors\" (Epson ScanSmart). I get better results than in VueScan.\n\nIs it possible to reduce scanning passes for multiple crop areas in v600 (or any another scanner)?\n\nI want to scan multiple images (e.g. 3) at once (see picture).  \nI open Epson ScanSmart:\n\n* I can scan maximum area with all photos (without auto or manual cropping). It's 1 pass for scanner.\n* Or I can crop my 3 images and scanner will do 3 passes.\n\nOf course it's waste of time and scanner resources but this is not big deals for me.  \nMain difference for me is restored colors. Restored colors are different. Because of when I scan all photos at once scanner takes into account empty space (white cushioning bit or black sheet of paper).\n\nQuestion: Can I make 3 crops and make only 1 pass (not 3) with restoring colors?\n\nIf not I will need to make 1 pass without restoring, then crop images and restore colors in Photoshop or Lightroom.\n\nWith VueSmart I also make 3\\*1 passes.\n\n[process](https://preview.redd.it/v7e44naf5o6c1.jpg?width=840&amp;format=pjpg&amp;auto=webp&amp;s=7abb27d2193e0cfe559f6ba9769847bc04bdfb0f)", "author_fullname": "t2_7i0wwc92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Epson Perfection V600 Photo Scanner] Reduce scanning passes for multiple crop areas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v7e44naf5o6c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 110, "x": 108, "u": "https://preview.redd.it/v7e44naf5o6c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df0278a96552236d13de1a04ae8a59ebfdac27f7"}, {"y": 221, "x": 216, "u": "https://preview.redd.it/v7e44naf5o6c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=124de0050e21f4c427f11ff7262088dd9722194e"}, {"y": 327, "x": 320, "u": "https://preview.redd.it/v7e44naf5o6c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=96758b2a9505948fdcbc73c1bb51811293999142"}, {"y": 655, "x": 640, "u": "https://preview.redd.it/v7e44naf5o6c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1a457d9d7535823920cc8eec3d3da05afbb9fd34"}], "s": {"y": 860, "x": 840, "u": "https://preview.redd.it/v7e44naf5o6c1.jpg?width=840&amp;format=pjpg&amp;auto=webp&amp;s=7abb27d2193e0cfe559f6ba9769847bc04bdfb0f"}, "id": "v7e44naf5o6c1"}}, "name": "t3_18jsna1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5FPSCWV7s3UcY5c2vPQxs3_0P2CEycKhlXoYNWdERig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702737811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use Epson V600 Photo and &amp;quot;Restore colors&amp;quot; (Epson ScanSmart). I get better results than in VueScan.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to reduce scanning passes for multiple crop areas in v600 (or any another scanner)?&lt;/p&gt;\n\n&lt;p&gt;I want to scan multiple images (e.g. 3) at once (see picture).&lt;br/&gt;\nI open Epson ScanSmart:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I can scan maximum area with all photos (without auto or manual cropping). It&amp;#39;s 1 pass for scanner.&lt;/li&gt;\n&lt;li&gt;Or I can crop my 3 images and scanner will do 3 passes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Of course it&amp;#39;s waste of time and scanner resources but this is not big deals for me.&lt;br/&gt;\nMain difference for me is restored colors. Restored colors are different. Because of when I scan all photos at once scanner takes into account empty space (white cushioning bit or black sheet of paper).&lt;/p&gt;\n\n&lt;p&gt;Question: Can I make 3 crops and make only 1 pass (not 3) with restoring colors?&lt;/p&gt;\n\n&lt;p&gt;If not I will need to make 1 pass without restoring, then crop images and restore colors in Photoshop or Lightroom.&lt;/p&gt;\n\n&lt;p&gt;With VueSmart I also make 3*1 passes.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v7e44naf5o6c1.jpg?width=840&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7abb27d2193e0cfe559f6ba9769847bc04bdfb0f\"&gt;process&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jsna1", "is_robot_indexable": true, "report_reasons": null, "author": "michl-pfeiff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jsna1/epson_perfection_v600_photo_scanner_reduce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jsna1/epson_perfection_v600_photo_scanner_reduce/", "subreddit_subscribers": 718597, "created_utc": 1702737811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I feel like I'm not asking for much.\n\n1. On the PC side: just some proper syncing technologies that sync from my PC to Cloud (i.e. for my past academic work, I just want to have it properly stored and stuff); for my current work, I want to be able to just have a proper 1 to 1 sync, i.e. if I delete something, cloud side should delete as well.\n2. On my phone side (android): same old proper syncing, maybe with an option for me to keep some stuff in the cloud that I don't need on my phone (i.e. certain older albums)\n\nI have been trying to drag and drop stuff to onedrive but when folder size is too big it just freeze entirely.\n\nOneDrive sync is total crap and it just doesn't work...\n\nAre there better cloud service provider out there? I am considering stuff like pCloud but am worried if they would be around few years from now.\n\nReally really appreciate any advice!!!", "author_fullname": "t2_frutaosj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honestly, what is the best cloud storage provider that has proper syncing capabilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jo5if", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702721039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like I&amp;#39;m not asking for much.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;On the PC side: just some proper syncing technologies that sync from my PC to Cloud (i.e. for my past academic work, I just want to have it properly stored and stuff); for my current work, I want to be able to just have a proper 1 to 1 sync, i.e. if I delete something, cloud side should delete as well.&lt;/li&gt;\n&lt;li&gt;On my phone side (android): same old proper syncing, maybe with an option for me to keep some stuff in the cloud that I don&amp;#39;t need on my phone (i.e. certain older albums)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I have been trying to drag and drop stuff to onedrive but when folder size is too big it just freeze entirely.&lt;/p&gt;\n\n&lt;p&gt;OneDrive sync is total crap and it just doesn&amp;#39;t work...&lt;/p&gt;\n\n&lt;p&gt;Are there better cloud service provider out there? I am considering stuff like pCloud but am worried if they would be around few years from now.&lt;/p&gt;\n\n&lt;p&gt;Really really appreciate any advice!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jo5if", "is_robot_indexable": true, "report_reasons": null, "author": "warrior123456781", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jo5if/honestly_what_is_the_best_cloud_storage_provider/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jo5if/honestly_what_is_the_best_cloud_storage_provider/", "subreddit_subscribers": 718597, "created_utc": 1702721039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nLong story short - I've spent recent days to recover and move files from multiple HDDs from the past 10 years. Overall about 3 TB of data.\n\n- Now I have about 5 different partitions\n- Some of the files are duplicates\n- Some of the files are sadly corrupted\n-I'm dealing with many different files from images, office files, Time Machine backups and so on\n\nNow as a next step I would like to organise everything, separate them by file types, ideally remove duplicates and corrupted files and move them to a single location. \n\nIs there any (maybe even free) software that you would recommend to do such thing?", "author_fullname": "t2_6cmljsoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any decent software to categorise and move files based on file type?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jnj91", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702718328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Long story short - I&amp;#39;ve spent recent days to recover and move files from multiple HDDs from the past 10 years. Overall about 3 TB of data.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Now I have about 5 different partitions&lt;/li&gt;\n&lt;li&gt;Some of the files are duplicates&lt;/li&gt;\n&lt;li&gt;Some of the files are sadly corrupted\n-I&amp;#39;m dealing with many different files from images, office files, Time Machine backups and so on&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now as a next step I would like to organise everything, separate them by file types, ideally remove duplicates and corrupted files and move them to a single location. &lt;/p&gt;\n\n&lt;p&gt;Is there any (maybe even free) software that you would recommend to do such thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jnj91", "is_robot_indexable": true, "report_reasons": null, "author": "Tuttle489", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jnj91/any_decent_software_to_categorise_and_move_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jnj91/any_decent_software_to_categorise_and_move_files/", "subreddit_subscribers": 718597, "created_utc": 1702718328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im trying to find external storage for my Xbox Series X  to store my older games. Obviously an SSD os what I want and I want a really good product like Samsung,Seagate etc. Im tryingmro spend as close to $100 or less as possible and siince I used a Samsung Sata III SSD with a USB adapter on my PS5, I figured fo that route. Well, as was the case with external SSD's I haven't found much in my price range. So I read about some people using an M.2 NVME with an Enclosure to use Externally. I'd like to know if the following items will work together because I haven't dealt with this stuff before. Thanks for taking a look.\n\nThe M.2 NVME I'm looking at is a 2 TB Barracuda Q5\n\nhttps://www.bhphotovideo.com/c/product/1602504-REG/seagate_zp2000cv3a001_2tb_barracuda_q5_pcie.html/?ap=y&amp;ap=y&amp;smp=y&amp;smp=y&amp;lsft=BI%3A5451&amp;gad_source=5\n\n\nAnd here is the enclosure/adapter to use Externally with my Series X's  USB 3.0\n\nhttps://www.amazon.com/SSK-Aluminum-Enclosure-Adapter-External/dp/B07MNFH1PX/ref=sr_1_3?crid=2JOXE2SUKFZZK&amp;keywords=m.2+nvme+to+usb&amp;qid=1702777471&amp;s=electronics&amp;sprefix=m.2+nvme+to%2Celectronics%2C1583&amp;sr=1-3#customerReviews", "author_fullname": "t2_13ymei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will this adapter work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k9ke7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702788901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im trying to find external storage for my Xbox Series X  to store my older games. Obviously an SSD os what I want and I want a really good product like Samsung,Seagate etc. Im tryingmro spend as close to $100 or less as possible and siince I used a Samsung Sata III SSD with a USB adapter on my PS5, I figured fo that route. Well, as was the case with external SSD&amp;#39;s I haven&amp;#39;t found much in my price range. So I read about some people using an M.2 NVME with an Enclosure to use Externally. I&amp;#39;d like to know if the following items will work together because I haven&amp;#39;t dealt with this stuff before. Thanks for taking a look.&lt;/p&gt;\n\n&lt;p&gt;The M.2 NVME I&amp;#39;m looking at is a 2 TB Barracuda Q5&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.bhphotovideo.com/c/product/1602504-REG/seagate_zp2000cv3a001_2tb_barracuda_q5_pcie.html/?ap=y&amp;amp;ap=y&amp;amp;smp=y&amp;amp;smp=y&amp;amp;lsft=BI%3A5451&amp;amp;gad_source=5\"&gt;https://www.bhphotovideo.com/c/product/1602504-REG/seagate_zp2000cv3a001_2tb_barracuda_q5_pcie.html/?ap=y&amp;amp;ap=y&amp;amp;smp=y&amp;amp;smp=y&amp;amp;lsft=BI%3A5451&amp;amp;gad_source=5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here is the enclosure/adapter to use Externally with my Series X&amp;#39;s  USB 3.0&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/SSK-Aluminum-Enclosure-Adapter-External/dp/B07MNFH1PX/ref=sr_1_3?crid=2JOXE2SUKFZZK&amp;amp;keywords=m.2+nvme+to+usb&amp;amp;qid=1702777471&amp;amp;s=electronics&amp;amp;sprefix=m.2+nvme+to%2Celectronics%2C1583&amp;amp;sr=1-3#customerReviews\"&gt;https://www.amazon.com/SSK-Aluminum-Enclosure-Adapter-External/dp/B07MNFH1PX/ref=sr_1_3?crid=2JOXE2SUKFZZK&amp;amp;keywords=m.2+nvme+to+usb&amp;amp;qid=1702777471&amp;amp;s=electronics&amp;amp;sprefix=m.2+nvme+to%2Celectronics%2C1583&amp;amp;sr=1-3#customerReviews&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k9ke7", "is_robot_indexable": true, "report_reasons": null, "author": "Cmdm828", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k9ke7/will_this_adapter_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k9ke7/will_this_adapter_work/", "subreddit_subscribers": 718597, "created_utc": 1702788901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks, I've searched and there are several threads about UltraDMA CRC Error Count - I took the advice in those threads and swapped cables, but the error persists, and I think my value (91) seems higher than most people have.\n\nDrive is WD RED 6TB WD60EFAX (most of the other people I've seen with the issue were also using WD RED). It's out of warranty so I'm wondering if there's any other things worth trying before I have to replace it.\n\nHere's smartctl output:\n    \n    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       0\n      3 Spin_Up_Time            0x0027   224   224   021    Pre-fail  Always       -       3775\n      4 Start_Stop_Count        0x0032   096   096   000    Old_age   Always       -       4889\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   088   088   000    Old_age   Always       -       9323\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       107\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       48\n    193 Load_Cycle_Count        0x0032   199   199   000    Old_age   Always       -       4869\n    194 Temperature_Celsius     0x0022   120   102   000    Old_age   Always       -       30\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   100   253   000    Old_age   Offline      -       0\n    **199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       91**\n    200 Multi_Zone_Error_Rate   0x0008   100   253   000    Old_age   Offline      -       0\n    \nDoesn't seem like much of an issue in smartctl but scrutiny calls it a fail. It also runs a lot colder than my Ironwolf. Obviously I'm not that experienced with this hardware so this is a little open ended. Thanks in advance for any ideas.", "author_fullname": "t2_qb9m0ag7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UDMA_CRC_Error_Count persists after changing cables - anything else to try?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jxjo8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702751895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I&amp;#39;ve searched and there are several threads about UltraDMA CRC Error Count - I took the advice in those threads and swapped cables, but the error persists, and I think my value (91) seems higher than most people have.&lt;/p&gt;\n\n&lt;p&gt;Drive is WD RED 6TB WD60EFAX (most of the other people I&amp;#39;ve seen with the issue were also using WD RED). It&amp;#39;s out of warranty so I&amp;#39;m wondering if there&amp;#39;s any other things worth trying before I have to replace it.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s smartctl output:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART Attributes Data Structure revision number: 16\nVendor Specific SMART Attributes with Thresholds:\nID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       0\n  3 Spin_Up_Time            0x0027   224   224   021    Pre-fail  Always       -       3775\n  4 Start_Stop_Count        0x0032   096   096   000    Old_age   Always       -       4889\n  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n  9 Power_On_Hours          0x0032   088   088   000    Old_age   Always       -       9323\n 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       107\n192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       48\n193 Load_Cycle_Count        0x0032   199   199   000    Old_age   Always       -       4869\n194 Temperature_Celsius     0x0022   120   102   000    Old_age   Always       -       30\n196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n198 Offline_Uncorrectable   0x0030   100   253   000    Old_age   Offline      -       0\n**199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       91**\n200 Multi_Zone_Error_Rate   0x0008   100   253   000    Old_age   Offline      -       0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Doesn&amp;#39;t seem like much of an issue in smartctl but scrutiny calls it a fail. It also runs a lot colder than my Ironwolf. Obviously I&amp;#39;m not that experienced with this hardware so this is a little open ended. Thanks in advance for any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jxjo8", "is_robot_indexable": true, "report_reasons": null, "author": "ambiance6462", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jxjo8/udma_crc_error_count_persists_after_changing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jxjo8/udma_crc_error_count_persists_after_changing/", "subreddit_subscribers": 718597, "created_utc": 1702751895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nI'm not exactly a data hoarder... compared to others here at least, so I really hope this is the appropriate sub for this question. I have a fair amount of archival stuff for old computers such as software and HDD images, so not small quantities of data, plus several TB of personal data, mainly documents and build outputs (software dev).\n\nGot myself an LTO-5 drive (HP EH958A external SAS drive) and a box of 25 tapes, tapes are yet to arrive but drive is here. Was pretty dusty when it arrived both in and outside so I cracked the external enclosure case and cleaned it out thouroughly. Daren't open the actual drive itself for fear of destroying it.\n\nLooking through the front flap, I see a fair amount of dust. Using an electronics wipe, I gently reached in and got rid of most of the dust on the surface taking care not to touch anything past the front cavity, and not wipe away any lubricating greases.\n\nI can see the takeup reel at the back of the unit which appears to have a transparent plastic tape attached to it, which I guess is normal.\n\nThe reel itself looks pretty dusty, and knowing that's where the tape media will eventually be spooled has me concerned that its just going to rub all of that dust off, onto the side edge of the tape.\n\nAnything I can/should do about this dust?\n\nAny other first timer advice would be greatly appreciated too, as I am still seeking some open source software for forever-incremental backups to tapes for both personal and archival offsite backups (append changes to dataset to existing tape rather than rewrite entire tape every time, until tape gets full, then rewrite entire tape)\n\nThanks!", "author_fullname": "t2_1pmvzm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO-5 Drive takeup reel dusty, cause for concern? + Forever-incremental software recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jxah2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702751158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not exactly a data hoarder... compared to others here at least, so I really hope this is the appropriate sub for this question. I have a fair amount of archival stuff for old computers such as software and HDD images, so not small quantities of data, plus several TB of personal data, mainly documents and build outputs (software dev).&lt;/p&gt;\n\n&lt;p&gt;Got myself an LTO-5 drive (HP EH958A external SAS drive) and a box of 25 tapes, tapes are yet to arrive but drive is here. Was pretty dusty when it arrived both in and outside so I cracked the external enclosure case and cleaned it out thouroughly. Daren&amp;#39;t open the actual drive itself for fear of destroying it.&lt;/p&gt;\n\n&lt;p&gt;Looking through the front flap, I see a fair amount of dust. Using an electronics wipe, I gently reached in and got rid of most of the dust on the surface taking care not to touch anything past the front cavity, and not wipe away any lubricating greases.&lt;/p&gt;\n\n&lt;p&gt;I can see the takeup reel at the back of the unit which appears to have a transparent plastic tape attached to it, which I guess is normal.&lt;/p&gt;\n\n&lt;p&gt;The reel itself looks pretty dusty, and knowing that&amp;#39;s where the tape media will eventually be spooled has me concerned that its just going to rub all of that dust off, onto the side edge of the tape.&lt;/p&gt;\n\n&lt;p&gt;Anything I can/should do about this dust?&lt;/p&gt;\n\n&lt;p&gt;Any other first timer advice would be greatly appreciated too, as I am still seeking some open source software for forever-incremental backups to tapes for both personal and archival offsite backups (append changes to dataset to existing tape rather than rewrite entire tape every time, until tape gets full, then rewrite entire tape)&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jxah2", "is_robot_indexable": true, "report_reasons": null, "author": "DevelopedLogic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jxah2/lto5_drive_takeup_reel_dusty_cause_for_concern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jxah2/lto5_drive_takeup_reel_dusty_cause_for_concern/", "subreddit_subscribers": 718597, "created_utc": 1702751158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My accountant was asking me for help in backing up her data (I'm an IT guy).    She uses a cloud-based system called Tax Dome where she stores all of her files and she is worried she is putting all of her eggs in one basket with them.   It's only about 300GB of data but it would be a big deal if she lost it all.\n\nTax Dome mounts as a drive in Windows requiring occasional authentication.   Was thinking some sort of continuous cloud backup service (backing up the Tax Dome drive) would work for her as the machine is likely not running 24/7 and she is typically authenticated into Tax Dome during the work day, at least.\n\nAny recommendations for her that are simple to use, very reliable, has good support, and do a good job alerting if the backup is failing for any reason?   Was initially thinking IDrive or pCloud but the reviews seem quite mixed.", "author_fullname": "t2_ewor6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple and Reliable Continuous Backup Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jrixz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702734318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My accountant was asking me for help in backing up her data (I&amp;#39;m an IT guy).    She uses a cloud-based system called Tax Dome where she stores all of her files and she is worried she is putting all of her eggs in one basket with them.   It&amp;#39;s only about 300GB of data but it would be a big deal if she lost it all.&lt;/p&gt;\n\n&lt;p&gt;Tax Dome mounts as a drive in Windows requiring occasional authentication.   Was thinking some sort of continuous cloud backup service (backing up the Tax Dome drive) would work for her as the machine is likely not running 24/7 and she is typically authenticated into Tax Dome during the work day, at least.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations for her that are simple to use, very reliable, has good support, and do a good job alerting if the backup is failing for any reason?   Was initially thinking IDrive or pCloud but the reviews seem quite mixed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jrixz", "is_robot_indexable": true, "report_reasons": null, "author": "christoman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jrixz/simple_and_reliable_continuous_backup_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jrixz/simple_and_reliable_continuous_backup_options/", "subreddit_subscribers": 718597, "created_utc": 1702734318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Should one download audio files from youtube into Flac? It seems like youtube supports decently high bitrates (a file I just downloaded has a 20khz cutoff). I don't know if there is a way to download their version without converting it into another lossy transcoded file format. It seems like a waste of space to download non lossless audio into lossless but I'm a little worried about file degradation. Let me know what you think!", "author_fullname": "t2_ld10r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice when converting youtube audio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jp8qx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702725730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should one download audio files from youtube into Flac? It seems like youtube supports decently high bitrates (a file I just downloaded has a 20khz cutoff). I don&amp;#39;t know if there is a way to download their version without converting it into another lossy transcoded file format. It seems like a waste of space to download non lossless audio into lossless but I&amp;#39;m a little worried about file degradation. Let me know what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jp8qx", "is_robot_indexable": true, "report_reasons": null, "author": "MadMax2230", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jp8qx/best_practice_when_converting_youtube_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jp8qx/best_practice_when_converting_youtube_audio/", "subreddit_subscribers": 718597, "created_utc": 1702725730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a very humble script that calls one json endpoint a day, I can get to it from my laptop, but it stopped working from github actions.\n\nAnyone in the same boat?", "author_fullname": "t2_4uxoi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone accessing reddit .json endpoints noticed getting blocked recently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k1qw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702763993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very humble script that calls one json endpoint a day, I can get to it from my laptop, but it stopped working from github actions.&lt;/p&gt;\n\n&lt;p&gt;Anyone in the same boat?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k1qw3", "is_robot_indexable": true, "report_reasons": null, "author": "Madd0g", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k1qw3/anyone_accessing_reddit_json_endpoints_noticed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k1qw3/anyone_accessing_reddit_json_endpoints_noticed/", "subreddit_subscribers": 718597, "created_utc": 1702763993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there any script or way to download all TikTok URLs from your downloaded data like videos and text files? I realize the URLs have to be clicked on first. And then you can get the actual URL for downloading those videos. Tiktok downloaders cannot download links from the text file provided by the downloaded Tiktok data. Is there a workaround to this? ", "author_fullname": "t2_2vmpw7em", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "tiktok mass download from downloaded data liked videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k1fdf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702763038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any script or way to download all TikTok URLs from your downloaded data like videos and text files? I realize the URLs have to be clicked on first. And then you can get the actual URL for downloading those videos. Tiktok downloaders cannot download links from the text file provided by the downloaded Tiktok data. Is there a workaround to this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k1fdf", "is_robot_indexable": true, "report_reasons": null, "author": "UltraElixir", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k1fdf/tiktok_mass_download_from_downloaded_data_liked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k1fdf/tiktok_mass_download_from_downloaded_data_liked/", "subreddit_subscribers": 718597, "created_utc": 1702763038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there,\n\nI know there are a bunch of posts about this topic, but I'm in the process of doing a NAS upgrade, and I'm likely going from 5 drives to 3. I currently have 4 red plus drives and 1 schucked drive. These are likely quieter than the Exos drives, but I'm going from 5 to 3. Would 3 Exos drives be a lot noisier than 5 of the drives I currently have?\n\nAlso, I do have a dedicated server closet, and I've put extra sound protection on the door. When I walk by, I still hear some fans, though, so I'm overall looking to reduce heat / noise in the closet. Curious to get your thoughts here. Thanks!", "author_fullname": "t2_bra1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exos drive noise considerations... a few questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jy8ci", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702753817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I know there are a bunch of posts about this topic, but I&amp;#39;m in the process of doing a NAS upgrade, and I&amp;#39;m likely going from 5 drives to 3. I currently have 4 red plus drives and 1 schucked drive. These are likely quieter than the Exos drives, but I&amp;#39;m going from 5 to 3. Would 3 Exos drives be a lot noisier than 5 of the drives I currently have?&lt;/p&gt;\n\n&lt;p&gt;Also, I do have a dedicated server closet, and I&amp;#39;ve put extra sound protection on the door. When I walk by, I still hear some fans, though, so I&amp;#39;m overall looking to reduce heat / noise in the closet. Curious to get your thoughts here. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18jy8ci", "is_robot_indexable": true, "report_reasons": null, "author": "hungarianhc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jy8ci/exos_drive_noise_considerations_a_few_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jy8ci/exos_drive_noise_considerations_a_few_questions/", "subreddit_subscribers": 718597, "created_utc": 1702753817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My qestion is would siply burning that MKV file let BRplayers read the disc? or do i need to convert it into something different?\n\nWhat i did was use MakeMKV to rip the Blu-ray into a folder and now im gonna use imgburn to copy the show onto another Blu-ray. dont worry im not selling them, I want to give them as a gift to my friend who also likes the show ( The Magicians)", "author_fullname": "t2_rdanw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to burn a blank Blu-ray disk with the file I ripped with Makemkv.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18josdq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702723830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My qestion is would siply burning that MKV file let BRplayers read the disc? or do i need to convert it into something different?&lt;/p&gt;\n\n&lt;p&gt;What i did was use MakeMKV to rip the Blu-ray into a folder and now im gonna use imgburn to copy the show onto another Blu-ray. dont worry im not selling them, I want to give them as a gift to my friend who also likes the show ( The Magicians)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18josdq", "is_robot_indexable": true, "report_reasons": null, "author": "Tron_Livesx", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18josdq/i_want_to_burn_a_blank_bluray_disk_with_the_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18josdq/i_want_to_burn_a_blank_bluray_disk_with_the_file/", "subreddit_subscribers": 718597, "created_utc": 1702723830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hope this doesn't violate the subs rules.\n\nI finally want to do real backups for my data, not just relying on my NAS with Raid 5 and hoping that no major thing breaks.\n\nMy data mostly consist of personal pictures, documents and a movie/music library. All's in all not more than 5TB. It's not super important stuff, but I still would like to keep it. Archive storage won't allow me to regularly update the backup, but for old pictures this wouldn't really matter.\n\nI was thinking about cloud archive storage. Something like Azure blob storage. Price per GB is only 0,0009 \u20ac per month, so pretty cheap. But what I still haven't fully understood are the extra costs to access the data and how to actually accomplish that.\n\nI'm aware that it's not a simple cloud with a pretty web interface, but even with some searching I could figure out how to setup the storage.\n\nMy question now is: Is this the best/cheapest way to backup my stuff? Is there a cheaper provider or a better alternative solution? Does this even work at all? And how would I do it?", "author_fullname": "t2_2twg4boe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best/cheapest data archive storage for personal stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k8cat", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702784522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this doesn&amp;#39;t violate the subs rules.&lt;/p&gt;\n\n&lt;p&gt;I finally want to do real backups for my data, not just relying on my NAS with Raid 5 and hoping that no major thing breaks.&lt;/p&gt;\n\n&lt;p&gt;My data mostly consist of personal pictures, documents and a movie/music library. All&amp;#39;s in all not more than 5TB. It&amp;#39;s not super important stuff, but I still would like to keep it. Archive storage won&amp;#39;t allow me to regularly update the backup, but for old pictures this wouldn&amp;#39;t really matter.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about cloud archive storage. Something like Azure blob storage. Price per GB is only 0,0009 \u20ac per month, so pretty cheap. But what I still haven&amp;#39;t fully understood are the extra costs to access the data and how to actually accomplish that.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that it&amp;#39;s not a simple cloud with a pretty web interface, but even with some searching I could figure out how to setup the storage.&lt;/p&gt;\n\n&lt;p&gt;My question now is: Is this the best/cheapest way to backup my stuff? Is there a cheaper provider or a better alternative solution? Does this even work at all? And how would I do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k8cat", "is_robot_indexable": true, "report_reasons": null, "author": "ichfrissdich", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k8cat/bestcheapest_data_archive_storage_for_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k8cat/bestcheapest_data_archive_storage_for_personal/", "subreddit_subscribers": 718597, "created_utc": 1702784522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI'm stuck choosing between two RAID enclosures for my gaming PC running a Plex server. They are listed below.\n\nTerraMaster D5-300C ($248 in UK): \n5-bay, 2+3 RAID storage (RAID 0, 1 for first two drives), USB 3.0 Type-C.\n\nIcyBox IB-3640SU3 ($191 in Norway): \n4-bay, supports RAID 0, 1, 3, 5, 10, and Single, USB 3.0 Type-A and eSATA, toolless installation.\n\n\nI'm thinking of grabbing the TerraMaster while I'm in the UK for studies and taking it back to Norway. Or I can get the IcyBox now in Norway. \n\nIs the TerraMaster worth the extra cost and the wait? Which would you say is the best value? Any advice or personal experiences with these? I would love to hear your thoughts!\n\nThanks :)", "author_fullname": "t2_157d5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD enclosure for Plex PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k2p38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702766717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m stuck choosing between two RAID enclosures for my gaming PC running a Plex server. They are listed below.&lt;/p&gt;\n\n&lt;p&gt;TerraMaster D5-300C ($248 in UK): \n5-bay, 2+3 RAID storage (RAID 0, 1 for first two drives), USB 3.0 Type-C.&lt;/p&gt;\n\n&lt;p&gt;IcyBox IB-3640SU3 ($191 in Norway): \n4-bay, supports RAID 0, 1, 3, 5, 10, and Single, USB 3.0 Type-A and eSATA, toolless installation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of grabbing the TerraMaster while I&amp;#39;m in the UK for studies and taking it back to Norway. Or I can get the IcyBox now in Norway. &lt;/p&gt;\n\n&lt;p&gt;Is the TerraMaster worth the extra cost and the wait? Which would you say is the best value? Any advice or personal experiences with these? I would love to hear your thoughts!&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k2p38", "is_robot_indexable": true, "report_reasons": null, "author": "AnalShower", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k2p38/hdd_enclosure_for_plex_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k2p38/hdd_enclosure_for_plex_pc/", "subreddit_subscribers": 718597, "created_utc": 1702766717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, building this NAS:\n\n* https://pcpartpicker.com/list/gdyyHG\n\nand the PSU's molex don't quite reach both connectors on the backplane.  \nI need like another inch or two.\n\nWould something like [this](https://www.amazon.ca/CableMod-ModFlex-Molex-Extension-Black/dp/B077QX91B6/ref=pd_vtp_h_pd_vtp_h_d_sccl_3/142-7015331-4579812?pd_rd_w=0Dzbo&amp;content-id=amzn1.sym.54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;pf_rd_p=54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;pf_rd_r=HPX0WBEKN1WYDDCJWDW4&amp;pd_rd_wg=SVm4q&amp;pd_rd_r=b6054eb9-eeec-4834-9d5c-130dcf07901e&amp;pd_rd_i=B077QX91B6&amp;th=1) or even [this](https://www.amazon.ca/StarTech-com-PYO2L-Power-Splitter-Cable/dp/B000067SLY/ref=pd_vtp_h_pd_vtp_h_d_sccl_2/142-7015331-4579812?pd_rd_w=0Dzbo&amp;content-id=amzn1.sym.54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;pf_rd_p=54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;pf_rd_r=HPX0WBEKN1WYDDCJWDW4&amp;pd_rd_wg=SVm4q&amp;pd_rd_r=b6054eb9-eeec-4834-9d5c-130dcf07901e&amp;pd_rd_i=B000067SLY&amp;psc=1) be safe?\n\nIt'll be on 24/7 of course... I can see in the near future 4x 20TB drives and two 2.5 SATA drives (with 3D printed brackets) connected to the backplane.\n\nThank you for any info!", "author_fullname": "t2_dc8ji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Unraid NAS in Jonsbo N3 - Molex extender OK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k2bsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702765643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, building this NAS:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://pcpartpicker.com/list/gdyyHG\"&gt;https://pcpartpicker.com/list/gdyyHG&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;and the PSU&amp;#39;s molex don&amp;#39;t quite reach both connectors on the backplane.&lt;br/&gt;\nI need like another inch or two.&lt;/p&gt;\n\n&lt;p&gt;Would something like &lt;a href=\"https://www.amazon.ca/CableMod-ModFlex-Molex-Extension-Black/dp/B077QX91B6/ref=pd_vtp_h_pd_vtp_h_d_sccl_3/142-7015331-4579812?pd_rd_w=0Dzbo&amp;amp;content-id=amzn1.sym.54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;amp;pf_rd_p=54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;amp;pf_rd_r=HPX0WBEKN1WYDDCJWDW4&amp;amp;pd_rd_wg=SVm4q&amp;amp;pd_rd_r=b6054eb9-eeec-4834-9d5c-130dcf07901e&amp;amp;pd_rd_i=B077QX91B6&amp;amp;th=1\"&gt;this&lt;/a&gt; or even &lt;a href=\"https://www.amazon.ca/StarTech-com-PYO2L-Power-Splitter-Cable/dp/B000067SLY/ref=pd_vtp_h_pd_vtp_h_d_sccl_2/142-7015331-4579812?pd_rd_w=0Dzbo&amp;amp;content-id=amzn1.sym.54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;amp;pf_rd_p=54a077ab-41be-4d2b-b691-c4848b60dd3b&amp;amp;pf_rd_r=HPX0WBEKN1WYDDCJWDW4&amp;amp;pd_rd_wg=SVm4q&amp;amp;pd_rd_r=b6054eb9-eeec-4834-9d5c-130dcf07901e&amp;amp;pd_rd_i=B000067SLY&amp;amp;psc=1\"&gt;this&lt;/a&gt; be safe?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;ll be on 24/7 of course... I can see in the near future 4x 20TB drives and two 2.5 SATA drives (with 3D printed brackets) connected to the backplane.&lt;/p&gt;\n\n&lt;p&gt;Thank you for any info!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18k2bsj", "is_robot_indexable": true, "report_reasons": null, "author": "DevanteWeary", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18k2bsj/building_unraid_nas_in_jonsbo_n3_molex_extender_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18k2bsj/building_unraid_nas_in_jonsbo_n3_molex_extender_ok/", "subreddit_subscribers": 718597, "created_utc": 1702765643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just have to warn that I'm a little obsessive with my data. I have thousands of PDFs stored and I always intent to keep them safe and intact, like a large portable library. In addition to having external hard drives I use three cloud services.\n\n1) Two days ago I tried to enter Google Drive and it \u00ab\u00a0freezed\u00a0\u00bb: the page remained blank. I tried again and finally it worked. However, I had a bad feeling, I thought it may have disrupted or corrupted my PDF files. I decided to count them one by one, in each folder, to make sure that none are missing because in Google drive nothing indicates the number of files stored. Finally, nothing was missing. But who knows if some files have not been corrupted and can no longer be opened? \n\n2) Yesterday another problem happened to me on my other cloud: while I was consulting my files my internet connection was interrupted and the file lists became gray, indicating that it was no longer possible to access it. Fortunately the connection was reestablished as well as the access to the files. But maybe this internet interruption also corrupted the files? \n\n3) I know this sounds weird but I am obsessed with the integrity of my files. I know that nothing lasts forever, but do you think I'm worrying unnecessarily? Besides, what can really corrupt a pdf file in the cloud? Even external hard drives worry me because I've read that SSDs, if not plugged in regularly, can lose data. So what to do?", "author_fullname": "t2_870lxxpo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could my data in the cloud be corrupted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jvvkr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702747223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just have to warn that I&amp;#39;m a little obsessive with my data. I have thousands of PDFs stored and I always intent to keep them safe and intact, like a large portable library. In addition to having external hard drives I use three cloud services.&lt;/p&gt;\n\n&lt;p&gt;1) Two days ago I tried to enter Google Drive and it \u00ab\u00a0freezed\u00a0\u00bb: the page remained blank. I tried again and finally it worked. However, I had a bad feeling, I thought it may have disrupted or corrupted my PDF files. I decided to count them one by one, in each folder, to make sure that none are missing because in Google drive nothing indicates the number of files stored. Finally, nothing was missing. But who knows if some files have not been corrupted and can no longer be opened? &lt;/p&gt;\n\n&lt;p&gt;2) Yesterday another problem happened to me on my other cloud: while I was consulting my files my internet connection was interrupted and the file lists became gray, indicating that it was no longer possible to access it. Fortunately the connection was reestablished as well as the access to the files. But maybe this internet interruption also corrupted the files? &lt;/p&gt;\n\n&lt;p&gt;3) I know this sounds weird but I am obsessed with the integrity of my files. I know that nothing lasts forever, but do you think I&amp;#39;m worrying unnecessarily? Besides, what can really corrupt a pdf file in the cloud? Even external hard drives worry me because I&amp;#39;ve read that SSDs, if not plugged in regularly, can lose data. So what to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18jvvkr", "is_robot_indexable": true, "report_reasons": null, "author": "Caranthir-Hondero", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18jvvkr/could_my_data_in_the_cloud_be_corrupted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18jvvkr/could_my_data_in_the_cloud_be_corrupted/", "subreddit_subscribers": 718597, "created_utc": 1702747223.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}