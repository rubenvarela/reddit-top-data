{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I'm fresh out of college with an MSIT degree. I've been applying for DA/DE jobs in vain. If you have experience as a recruiter or have supported someone in recruiting a junior Data Analyst/Data Engineer/Analytics Engineer, what are a few must haves?  (I'm aware that they are intrinsically different, but I'm confident that I can do a great job at either of them.)  \nI've had experience with ETL (mostly OLAP data), SQL &amp; Python, Databricks and AWS amongst few other things, but with each recruiter having their own infrastructure, I'm finding it hard to make focus on one specific skill. A post from the other day ([How I Interview Data Engineers - by Yordan Ivanov (substack.com)](https://datagibberish.substack.com/p/how-i-interview-data-engineers?r=odlo3&amp;utm_campaign=post&amp;utm_medium=web)) gave me one person's view on how to give an interview. I'm trying get to the interview, which is proving to be difficult. How do I land an interview? Any pointers will be helpful. Thanks in advance.", "author_fullname": "t2_hqiwxblm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you look for on a resume when hiring for a Data Engineer (Junior/fresh out of college) role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k208t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702764707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I&amp;#39;m fresh out of college with an MSIT degree. I&amp;#39;ve been applying for DA/DE jobs in vain. If you have experience as a recruiter or have supported someone in recruiting a junior Data Analyst/Data Engineer/Analytics Engineer, what are a few must haves?  (I&amp;#39;m aware that they are intrinsically different, but I&amp;#39;m confident that I can do a great job at either of them.)&lt;br/&gt;\nI&amp;#39;ve had experience with ETL (mostly OLAP data), SQL &amp;amp; Python, Databricks and AWS amongst few other things, but with each recruiter having their own infrastructure, I&amp;#39;m finding it hard to make focus on one specific skill. A post from the other day (&lt;a href=\"https://datagibberish.substack.com/p/how-i-interview-data-engineers?r=odlo3&amp;amp;utm_campaign=post&amp;amp;utm_medium=web\"&gt;How I Interview Data Engineers - by Yordan Ivanov (substack.com)&lt;/a&gt;) gave me one person&amp;#39;s view on how to give an interview. I&amp;#39;m trying get to the interview, which is proving to be difficult. How do I land an interview? Any pointers will be helpful. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?auto=webp&amp;s=d62d1df611eb5fd3b6c201a2ca1198764c34576e", "width": 1080, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d233877d035936e4cdd051c8308d2ed8687ea4b4", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=658a8bd49e51df3ec03cb2ee2e11353625e67188", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6fa1c75aa9279837a1bc754209d43a4ecc494bf", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e81e57fe8694136946f0e0b90cd174e447289020", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c2d765d29649bb8542956c04e415c72a8794e9e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/6iVs_YuK7Bti4JZ6J7Q-nFZPVA4rg-HVAQNazDj9V3E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b00fa2cb6c57cffff61869c14eb6b4e6cbb86d4", "width": 1080, "height": 720}], "variants": {}, "id": "5zTWOZ4g6_ZEJv5W5FoiMbIfg0hblAMLhiLqgJKuoFg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18k208t", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Reason59", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18k208t/what_do_you_look_for_on_a_resume_when_hiring_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18k208t/what_do_you_look_for_on_a_resume_when_hiring_for/", "subreddit_subscribers": 146558, "created_utc": 1702764707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is Databricks fundamentally/architecturally different from other hyper scalers when all them have launched their own Lakehouse replicas? For e.g. BigLake under GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kfn28", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702813427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18kfn28", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kfn28/how_is_databricks_fundamentallyarchitecturally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kfn28/how_is_databricks_fundamentallyarchitecturally/", "subreddit_subscribers": 146558, "created_utc": 1702813427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Goals:**\n\nGain cloud experience so that I am more marketable to employers. My secondary goal is to create a more usable [NPI dataset](https://npiregistry.cms.hhs.gov/search). Everything I do for work currently is on premises Oracle orchestrated by airflow.\n\n**Project description:**\n\nThe project is to pull in a \\~9GB .csv healthcare provider file from NPPES (CMS) monthly. I want python [to download the .csv](https://download.cms.gov/nppes/NPI_Files.html) and full replace the existing table as my starting point. I have other analytic, data cleaning goals, and reach API development goals down the road.\n\nI have a linux VM setup with an airflow install via docker set up and have begun to set up the SQL db.\n\n**.CSV landing spot problems:**\n\nI am stuck on what is the 'best' way to process this .csv. I first downloaded it to my local machine and tried to bulk insert via SSMS for a proof of concept but I had file permissions issues. Abandoning that form of insert, I tried to upload it to Azure storage container but it took forever to upload and I don't think I want to go that route when it is automated. Should I try downloading to the linux vm and bulk inserting from there?  Where should this .csv go before it is bulk inserted?\n\n**Bulk Insert and/or .CSV processing:**\n\nI would like to drop many of the columns from the .csv before uploading. I haven't figured out if a format file could drop columns for me during bulk insert. Is column mapping during bulk insert possible if the table has less columns than the .csv? I have read suggestions about doing a full bulk insert and then creating a view, or bulk inserting to a temp table and then inserting from there but I thought it would maybe be easier to pre-process the .csv first? I am not as sharp on T-SQL. Any thoughts would be appreciated.\n\nMy efficiency questions are wondering if any pre-processing of the .csv is possible. I would love to drop a bunch of the columns and even partition the .csv's into many smaller .csv's by state. My hunch is that the file will be too large to do this using pandas which is what I am most familiar with. Any thoughts or suggestions on pre-processing .csvs in comparison to being savvier with the bulk insert?", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal Cloud Project Help - NPI Healthcare Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k750l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702780351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Goals:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Gain cloud experience so that I am more marketable to employers. My secondary goal is to create a more usable &lt;a href=\"https://npiregistry.cms.hhs.gov/search\"&gt;NPI dataset&lt;/a&gt;. Everything I do for work currently is on premises Oracle orchestrated by airflow.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Project description:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The project is to pull in a ~9GB .csv healthcare provider file from NPPES (CMS) monthly. I want python &lt;a href=\"https://download.cms.gov/nppes/NPI_Files.html\"&gt;to download the .csv&lt;/a&gt; and full replace the existing table as my starting point. I have other analytic, data cleaning goals, and reach API development goals down the road.&lt;/p&gt;\n\n&lt;p&gt;I have a linux VM setup with an airflow install via docker set up and have begun to set up the SQL db.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;.CSV landing spot problems:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am stuck on what is the &amp;#39;best&amp;#39; way to process this .csv. I first downloaded it to my local machine and tried to bulk insert via SSMS for a proof of concept but I had file permissions issues. Abandoning that form of insert, I tried to upload it to Azure storage container but it took forever to upload and I don&amp;#39;t think I want to go that route when it is automated. Should I try downloading to the linux vm and bulk inserting from there?  Where should this .csv go before it is bulk inserted?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bulk Insert and/or .CSV processing:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I would like to drop many of the columns from the .csv before uploading. I haven&amp;#39;t figured out if a format file could drop columns for me during bulk insert. Is column mapping during bulk insert possible if the table has less columns than the .csv? I have read suggestions about doing a full bulk insert and then creating a view, or bulk inserting to a temp table and then inserting from there but I thought it would maybe be easier to pre-process the .csv first? I am not as sharp on T-SQL. Any thoughts would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;My efficiency questions are wondering if any pre-processing of the .csv is possible. I would love to drop a bunch of the columns and even partition the .csv&amp;#39;s into many smaller .csv&amp;#39;s by state. My hunch is that the file will be too large to do this using pandas which is what I am most familiar with. Any thoughts or suggestions on pre-processing .csvs in comparison to being savvier with the bulk insert?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18k750l", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18k750l/personal_cloud_project_help_npi_healthcare_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18k750l/personal_cloud_project_help_npi_healthcare_data/", "subreddit_subscribers": 146558, "created_utc": 1702780351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "HI,\n\nIM new in Dagster and i come more from DevOps than from DataEngineering. My job will be basically to setup dagster to be able to run ETLs on dev/test/production.\n\nMy data team is creating a PoC. All data projects should be part of our SDLC, and im looking into how to deploy Dagster to different stages. I will deploy Dagster on K8s, that, i guess it will be the source of truth of running jobs on production. And again, i guess, an instance per environment.\n\nI went to the documentation, building some pipes on local computer. But,\n\ncan we use git to host all the source code?\n\ncan i connect Dagster (the instace deployed on k8s) to a git repo? (the concept repositories on dagster is not clear to me).\n\nis it Dagster deployment GitOps oriented (a prod instance check the master code and setup the assets, jobs, etc)?\n\ndoes it Dagsters has the concept \"environment\", where i use different variables, secrets per environment?\n\nThanks\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_7uozpvtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster DevOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jx1cw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702750445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI,&lt;/p&gt;\n\n&lt;p&gt;IM new in Dagster and i come more from DevOps than from DataEngineering. My job will be basically to setup dagster to be able to run ETLs on dev/test/production.&lt;/p&gt;\n\n&lt;p&gt;My data team is creating a PoC. All data projects should be part of our SDLC, and im looking into how to deploy Dagster to different stages. I will deploy Dagster on K8s, that, i guess it will be the source of truth of running jobs on production. And again, i guess, an instance per environment.&lt;/p&gt;\n\n&lt;p&gt;I went to the documentation, building some pipes on local computer. But,&lt;/p&gt;\n\n&lt;p&gt;can we use git to host all the source code?&lt;/p&gt;\n\n&lt;p&gt;can i connect Dagster (the instace deployed on k8s) to a git repo? (the concept repositories on dagster is not clear to me).&lt;/p&gt;\n\n&lt;p&gt;is it Dagster deployment GitOps oriented (a prod instance check the master code and setup the assets, jobs, etc)?&lt;/p&gt;\n\n&lt;p&gt;does it Dagsters has the concept &amp;quot;environment&amp;quot;, where i use different variables, secrets per environment?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18jx1cw", "is_robot_indexable": true, "report_reasons": null, "author": "Ancient_Canary1148", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18jx1cw/dagster_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18jx1cw/dagster_devops/", "subreddit_subscribers": 146558, "created_utc": 1702750445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nGreetings fellow data enthusiasts! I'm a Data Analyst with 2 years of experience, specializing in ETL tools such as Abinitio and Informatica. Currently, I'm diving into the exciting realm of the modern data stack and seeking advice on the skills I should acquire in the next six months.\n\n**Current Skillset:**\n\n* ETL tools: Abinitio, Informatica\n* Languages: SQL, Java, UNIX\n* Basic understanding of cloud and data warehousing\n\n**Career Transition Plan:** In the upcoming six months, I plan to make a switch in the modern data stack. Given my quick learning ability, I'm eager to know:\n\n**Python vs. Scala:**  \n\n\n* Is Scala still relevant, or is it considered outdated? (Referencing a post by Zach Wilson)\n* Recommendations on whether to focus on Python or Scala for the modern data stack.\n\n**SQL Proficiency:**  \n\n\n* What level of SQL knowledge is typically expected for someone transitioning into the modern data stack?\n\n**Software Engineering Knowledge:**  \n\n\n* Essential software engineering concepts and practices relevant to a data engineer.\n\n**Data Structures and Algorithms (DSA):**  \n\n\n* The importance of DSA in data engineering roles.\n* A list of DSA topics commonly asked during interviews.\n\n**Additional Tech Stack:**  \n\n\n* Other technologies or tools that complement a data engineer's skill set.\n\n**Cloud Knowledge:**  \n\n\n* The level of proficiency in cloud technologies (e.g., AWS, Azure, GCP) required for a data engineer in the current job market.\n\nIndian Data engineer folks need your help also here for salary expectation (\ud83d\ude05).\n\n**Salary Expectations:** Currently earning 7 LPA, I'm curious about the salary expectations in the market for someone with +2 years of experience in data engineering. Is aiming for 15 LPA too ambitious?\n\n**Closing Thoughts:** If you have additional insights or points to consider in my career transition journey, please share your suggestions. Your help is greatly appreciated!\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ijlf61xv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Guidance on Career Transition and Salary Expectations for Indian Data Engineers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jusv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702744217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings fellow data enthusiasts! I&amp;#39;m a Data Analyst with 2 years of experience, specializing in ETL tools such as Abinitio and Informatica. Currently, I&amp;#39;m diving into the exciting realm of the modern data stack and seeking advice on the skills I should acquire in the next six months.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Skillset:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ETL tools: Abinitio, Informatica&lt;/li&gt;\n&lt;li&gt;Languages: SQL, Java, UNIX&lt;/li&gt;\n&lt;li&gt;Basic understanding of cloud and data warehousing&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Career Transition Plan:&lt;/strong&gt; In the upcoming six months, I plan to make a switch in the modern data stack. Given my quick learning ability, I&amp;#39;m eager to know:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Python vs. Scala:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is Scala still relevant, or is it considered outdated? (Referencing a post by Zach Wilson)&lt;/li&gt;\n&lt;li&gt;Recommendations on whether to focus on Python or Scala for the modern data stack.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;SQL Proficiency:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What level of SQL knowledge is typically expected for someone transitioning into the modern data stack?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Software Engineering Knowledge:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Essential software engineering concepts and practices relevant to a data engineer.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Structures and Algorithms (DSA):&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The importance of DSA in data engineering roles.&lt;/li&gt;\n&lt;li&gt;A list of DSA topics commonly asked during interviews.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Additional Tech Stack:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Other technologies or tools that complement a data engineer&amp;#39;s skill set.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Cloud Knowledge:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The level of proficiency in cloud technologies (e.g., AWS, Azure, GCP) required for a data engineer in the current job market.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Indian Data engineer folks need your help also here for salary expectation (\ud83d\ude05).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Salary Expectations:&lt;/strong&gt; Currently earning 7 LPA, I&amp;#39;m curious about the salary expectations in the market for someone with +2 years of experience in data engineering. Is aiming for 15 LPA too ambitious?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Closing Thoughts:&lt;/strong&gt; If you have additional insights or points to consider in my career transition journey, please share your suggestions. Your help is greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18jusv1", "is_robot_indexable": true, "report_reasons": null, "author": "solouchiha64", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18jusv1/seeking_guidance_on_career_transition_and_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18jusv1/seeking_guidance_on_career_transition_and_salary/", "subreddit_subscribers": 146558, "created_utc": 1702744217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A little bit of my career background. I am a MS in CS, batch 2015. For 5 years I was a software engineer II. Lost job due to Covid then restarted my career as a Data Engineer but at level 1. It hurts me a lot that I am a DE I at my current job even when my job responsibilities/work is closely matching a senior data engineer job role. Well, I also cannot switch jobs currently due to work visa restrictions but looks like in about 2025-26 time range, I can make a job switch safely without hurting my visa formalities.\n\nIn my current job I am working heavily with Pyspark, Python, Airflow, Datadog, K8s, mentoring juniors (my company is hiring recent grads on level II where as I am at level I and I mentor them but still call them juniors fml), AWS, Databases (RDBMS or NoSQL), Snowflake, MSK and Confluent Kafka, Gitlab, CICD, SQL, Bash, Grafana, Opensearch, Loki etc. I have created highly scalable and robust data software applications to fulfill data requests from other teams in my company. I also do data solution architecture-ing to discuss how to make data reach from point A to point B, I join meetings with other teams and negotiate the contracts with them to fulfill their data requirements and what our infra can offer.\n\nOf course, I am not happy being titled as a Data Engineer I. But I have to deal with it till at least 2025-2026. So I have about 1.5 years to prepare for interviews, read books, be a better candidate for my next job. I need guidance on how to do a proper planning to be successful in cracking interviews.\n\nI have following books on my radar to prep for the interviews:\n\n1. Designing Data Intensive Applications\n2. The Data Warehouse Toolkit\n3. Elements of Programming Interviews\n4. Beginning Database Design Solutions\n\nOther than that, I am going to go heavy on Leetcode for Python, SQL, system design questions.\n\nI need guidance to know what am I missing in my preparations and what technologies am I missing to have hands-on in my current job. The more I know current trends of the market, the more I would be able to prep for my next interviews in upcoming years.\n\nYour guidance and suggestions are welcome. Its my time to hustle and solve the problem when its hurting me the most. Thank you!", "author_fullname": "t2_1dlki6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mid Senior Data Engineer looking for guidance in interview preparation plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k4oox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702772556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A little bit of my career background. I am a MS in CS, batch 2015. For 5 years I was a software engineer II. Lost job due to Covid then restarted my career as a Data Engineer but at level 1. It hurts me a lot that I am a DE I at my current job even when my job responsibilities/work is closely matching a senior data engineer job role. Well, I also cannot switch jobs currently due to work visa restrictions but looks like in about 2025-26 time range, I can make a job switch safely without hurting my visa formalities.&lt;/p&gt;\n\n&lt;p&gt;In my current job I am working heavily with Pyspark, Python, Airflow, Datadog, K8s, mentoring juniors (my company is hiring recent grads on level II where as I am at level I and I mentor them but still call them juniors fml), AWS, Databases (RDBMS or NoSQL), Snowflake, MSK and Confluent Kafka, Gitlab, CICD, SQL, Bash, Grafana, Opensearch, Loki etc. I have created highly scalable and robust data software applications to fulfill data requests from other teams in my company. I also do data solution architecture-ing to discuss how to make data reach from point A to point B, I join meetings with other teams and negotiate the contracts with them to fulfill their data requirements and what our infra can offer.&lt;/p&gt;\n\n&lt;p&gt;Of course, I am not happy being titled as a Data Engineer I. But I have to deal with it till at least 2025-2026. So I have about 1.5 years to prepare for interviews, read books, be a better candidate for my next job. I need guidance on how to do a proper planning to be successful in cracking interviews.&lt;/p&gt;\n\n&lt;p&gt;I have following books on my radar to prep for the interviews:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Designing Data Intensive Applications&lt;/li&gt;\n&lt;li&gt;The Data Warehouse Toolkit&lt;/li&gt;\n&lt;li&gt;Elements of Programming Interviews&lt;/li&gt;\n&lt;li&gt;Beginning Database Design Solutions&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other than that, I am going to go heavy on Leetcode for Python, SQL, system design questions.&lt;/p&gt;\n\n&lt;p&gt;I need guidance to know what am I missing in my preparations and what technologies am I missing to have hands-on in my current job. The more I know current trends of the market, the more I would be able to prep for my next interviews in upcoming years.&lt;/p&gt;\n\n&lt;p&gt;Your guidance and suggestions are welcome. Its my time to hustle and solve the problem when its hurting me the most. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18k4oox", "is_robot_indexable": true, "report_reasons": null, "author": "musicplay313", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18k4oox/mid_senior_data_engineer_looking_for_guidance_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18k4oox/mid_senior_data_engineer_looking_for_guidance_in/", "subreddit_subscribers": 146558, "created_utc": 1702772556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer using python, AWS and gitlab in my current project. I have been working for the past 1.7 years in my current role.\n\nI earn \u00a331k per year. \n\nI have a portfolio. I am looking to focus on a new portfolio project now. I have a professional profile picture. I have AWS certifications related to my work as well Python certs.\n\nHow do you choose viable roles to apply for. I am quite gun shy about applying. I have built myself up a lot in preparation for applications next year. I am trying to understand as much as I can. So I can develop more.", "author_fullname": "t2_bkou9use8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on natural career progression. Ask from a \u00a331k UK data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k8ncd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702785645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer using python, AWS and gitlab in my current project. I have been working for the past 1.7 years in my current role.&lt;/p&gt;\n\n&lt;p&gt;I earn \u00a331k per year. &lt;/p&gt;\n\n&lt;p&gt;I have a portfolio. I am looking to focus on a new portfolio project now. I have a professional profile picture. I have AWS certifications related to my work as well Python certs.&lt;/p&gt;\n\n&lt;p&gt;How do you choose viable roles to apply for. I am quite gun shy about applying. I have built myself up a lot in preparation for applications next year. I am trying to understand as much as I can. So I can develop more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18k8ncd", "is_robot_indexable": true, "report_reasons": null, "author": "RagingCharlotte", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18k8ncd/advice_on_natural_career_progression_ask_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18k8ncd/advice_on_natural_career_progression_ask_from_a/", "subreddit_subscribers": 146558, "created_utc": 1702785645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\nI'm planning to launch an OpenSource project on interoperability modules between different data collection and storage sources (KoboToolBox, ODK, Monkey, DHIS2, etc.).\nToday, when you work on this different project, you have to create your own data extraction code.\nCould we work together on this project?\nThe languages to be used are R and Python.", "author_fullname": "t2_gnhzyiiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Library for interoperability datasources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_18kg22e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-HgeX6Gn5tgepqRvzYfUYxKNoXyMi7zvKjMP4OXoREM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702815041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI&amp;#39;m planning to launch an OpenSource project on interoperability modules between different data collection and storage sources (KoboToolBox, ODK, Monkey, DHIS2, etc.).\nToday, when you work on this different project, you have to create your own data extraction code.\nCould we work together on this project?\nThe languages to be used are R and Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/frdblj8dju6c1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/frdblj8dju6c1.jpeg?auto=webp&amp;s=a9726b7fc3a6a933fc2948f9a2dc9ce040d0c80d", "width": 784, "height": 391}, "resolutions": [{"url": "https://preview.redd.it/frdblj8dju6c1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c65a96d42aa22cbd9e749eb01cf77be3df258fae", "width": 108, "height": 53}, {"url": "https://preview.redd.it/frdblj8dju6c1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad480beed7fb891aa1e310f5bf88ec471fa6d680", "width": 216, "height": 107}, {"url": "https://preview.redd.it/frdblj8dju6c1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c7d9156a2a5f220628386bea858918713c9005f", "width": 320, "height": 159}, {"url": "https://preview.redd.it/frdblj8dju6c1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c97bbc7692690e699b23f2c0b2510277676998cf", "width": 640, "height": 319}], "variants": {}, "id": "OOIGtN6jtekJhRzY3_ykgoXStsBRU36dxSvM21Xy0ho"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18kg22e", "is_robot_indexable": true, "report_reasons": null, "author": "hlama26", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kg22e/library_for_interoperability_datasources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/frdblj8dju6c1.jpeg", "subreddit_subscribers": 146558, "created_utc": 1702815041.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey!\n\nI\u2019m a second year computer science student and I managed to secure a data analytics/dev role at a big bank. This will be my first internship and just want to prepare. Just want some insight.\n\nWhat technologies should I learn beforehand? I\u2019ll be be primarily working with Python, SQL and R. I have lots of experience with python and some with R (took statistics), should I be putting a lot of focus into SQL? \n\nLet me know!", "author_fullname": "t2_slvidrds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips prior to first data/dev internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18k35b1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702768041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a second year computer science student and I managed to secure a data analytics/dev role at a big bank. This will be my first internship and just want to prepare. Just want some insight.&lt;/p&gt;\n\n&lt;p&gt;What technologies should I learn beforehand? I\u2019ll be be primarily working with Python, SQL and R. I have lots of experience with python and some with R (took statistics), should I be putting a lot of focus into SQL? &lt;/p&gt;\n\n&lt;p&gt;Let me know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18k35b1", "is_robot_indexable": true, "report_reasons": null, "author": "svahsvst", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18k35b1/tips_prior_to_first_datadev_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18k35b1/tips_prior_to_first_datadev_internship/", "subreddit_subscribers": 146558, "created_utc": 1702768041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I inherited a DE team when I joined my new job as a team lead. For some reason (performance, on-premise datacenter) they are using MySql for everything, including multi-terabyte datawarehouses. This led to literally 50+ database servers with hundreds of user accounts. While I prepare a migration to a more appropriate toolchain, I still need to manage access to all of these servers. Any pointers to decent, ideally open source, solutions to manage users, roles and permissions across servers. My Google-fu is failing me.", "author_fullname": "t2_dxt8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross Database user management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18kj9gp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702825600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I inherited a DE team when I joined my new job as a team lead. For some reason (performance, on-premise datacenter) they are using MySql for everything, including multi-terabyte datawarehouses. This led to literally 50+ database servers with hundreds of user accounts. While I prepare a migration to a more appropriate toolchain, I still need to manage access to all of these servers. Any pointers to decent, ideally open source, solutions to manage users, roles and permissions across servers. My Google-fu is failing me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18kj9gp", "is_robot_indexable": true, "report_reasons": null, "author": "pokepip", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kj9gp/cross_database_user_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kj9gp/cross_database_user_management/", "subreddit_subscribers": 146558, "created_utc": 1702825600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have tried reading through the DBT docs but finding it hard to understand how to change the target database for DBT production runs when developing in DBT cloud. I am using Redshift, and want my prod runs to output to its own 'analytics' database, and all dev runs to go to a dbt\\_dev database.  \nTIA ", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Changing DBT Cloud Target Database (Redshift)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kazlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702794141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tried reading through the DBT docs but finding it hard to understand how to change the target database for DBT production runs when developing in DBT cloud. I am using Redshift, and want my prod runs to output to its own &amp;#39;analytics&amp;#39; database, and all dev runs to go to a dbt_dev database.&lt;br/&gt;\nTIA &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18kazlm", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kazlm/changing_dbt_cloud_target_database_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kazlm/changing_dbt_cloud_target_database_redshift/", "subreddit_subscribers": 146558, "created_utc": 1702794141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi l , I want to build a feature pipeline for real time approximation (over 90 min) and use this feature in real time inference (90 min back). The data for the feature and the inference derived from the same events. \n\nHow would you suggest to solve those kind of problems and what technology stack do you use? Do you have some examples ? \n\nThanks", "author_fullname": "t2_j15inhpup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature pipeline in stream for approximation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kiirt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702823459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi l , I want to build a feature pipeline for real time approximation (over 90 min) and use this feature in real time inference (90 min back). The data for the feature and the inference derived from the same events. &lt;/p&gt;\n\n&lt;p&gt;How would you suggest to solve those kind of problems and what technology stack do you use? Do you have some examples ? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18kiirt", "is_robot_indexable": true, "report_reasons": null, "author": "springRock88", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kiirt/feature_pipeline_in_stream_for_approximation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kiirt/feature_pipeline_in_stream_for_approximation/", "subreddit_subscribers": 146558, "created_utc": 1702823459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://www.instagram.com/reel/C0UMsuNrwX5/?igshid=MzRlODBiNWFlZA==\n\nI've seen it suggested on this sub a few times. Surely it's a waste of time and won't ever be directly applicable to your actual career skills beyond some network basics that you'd get tinkering with AWS anyway?\n\nOr am I missing something?", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would someone want to be building RPI clusters which have so few transferable skills when you could just be doing projects in AWS/cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18khf1r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702819930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.instagram.com/reel/C0UMsuNrwX5/?igshid=MzRlODBiNWFlZA==\"&gt;https://www.instagram.com/reel/C0UMsuNrwX5/?igshid=MzRlODBiNWFlZA==&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen it suggested on this sub a few times. Surely it&amp;#39;s a waste of time and won&amp;#39;t ever be directly applicable to your actual career skills beyond some network basics that you&amp;#39;d get tinkering with AWS anyway?&lt;/p&gt;\n\n&lt;p&gt;Or am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-th6YlprDrdAa9jQoqT_f7yvdg8EEAfT44tHbx2vI1w.jpg?auto=webp&amp;s=870722f67c3bc0e2671bdff2eb5e54768215f381", "width": 540, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/-th6YlprDrdAa9jQoqT_f7yvdg8EEAfT44tHbx2vI1w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a56880ad097e4106d1bd35563580d925591b958", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-th6YlprDrdAa9jQoqT_f7yvdg8EEAfT44tHbx2vI1w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4acc9953c0bd0089ad7e45894f33886def0be756", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-th6YlprDrdAa9jQoqT_f7yvdg8EEAfT44tHbx2vI1w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8316399932d8a190da49675ca5749033abbadea0", "width": 320, "height": 320}], "variants": {}, "id": "AprF7A7Vjv6kqmuhxUJ-C9dMsGDdNHfawA9lPfuzvBE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18khf1r", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18khf1r/why_would_someone_want_to_be_building_rpi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18khf1r/why_would_someone_want_to_be_building_rpi/", "subreddit_subscribers": 146558, "created_utc": 1702819930.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}