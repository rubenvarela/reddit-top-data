{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zendesk Moves from DynamoDB to MySQL and S3 to Save over 80% in Costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18tjgp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MTka0EXAzqPNnMEHfn9nAO8RwoLOYivouYWdxwOALLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703843034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/12/zendesk-dynamodb-mysql-s3-cost/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?auto=webp&amp;s=611d84ebb2bb3a9ad062890da1b4f47ab4298102", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01c327d65beccee01d820dd00f255c7f7bf1935c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9666d9ea0e68b65667b668c34fc9ec760b425f0d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f8f1538db45c07dca09b843c450983ec84a7eb0", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02413dedb861ac5101df9446c09bb064fec135ca", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3d2a57cf7a5999ddb10ea6b5f0736ae4eafb4e6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/X9yCopKqzGwuPDo1OW5TNnyyXPox61ZP-cbkmbc5n0s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb48b64a8d45b4d554080505920bc38b75431b32", "width": 1080, "height": 567}], "variants": {}, "id": "7yyKoKkfxVkqP3uSULJ_K5wy-_bRYEEmjcZkyfNDPxY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18tjgp8", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tjgp8/zendesk_moves_from_dynamodb_to_mysql_and_s3_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/12/zendesk-dynamodb-mysql-s3-cost/", "subreddit_subscribers": 149302, "created_utc": 1703843034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there resources for best ways to go about *documenting* database designs? \n\nI realize that one can export a database schema, add some comments to it, and use diagrams to represent it visually. But, these seem deficient in that they do not capture the semantics or rationale for the underlying fields/tables. I\u2019m especially curious about established resources that lay this out in detail, especially ones that I can show to others in support of best practices (a textbook would be ideal, but I realize that\u2019s a tall order for what I\u2019m looking for).", "author_fullname": "t2_i90lr7q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for documenting database design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tgg69", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703831292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there resources for best ways to go about &lt;em&gt;documenting&lt;/em&gt; database designs? &lt;/p&gt;\n\n&lt;p&gt;I realize that one can export a database schema, add some comments to it, and use diagrams to represent it visually. But, these seem deficient in that they do not capture the semantics or rationale for the underlying fields/tables. I\u2019m especially curious about established resources that lay this out in detail, especially ones that I can show to others in support of best practices (a textbook would be ideal, but I realize that\u2019s a tall order for what I\u2019m looking for).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18tgg69", "is_robot_indexable": true, "report_reasons": null, "author": "rubikol", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tgg69/best_practices_for_documenting_database_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tgg69/best_practices_for_documenting_database_design/", "subreddit_subscribers": 149302, "created_utc": 1703831292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone\n\nI really would appreciate some guidance. From what I've read tools like Fivetran, Airflow, and Airbyte and on paper they sound interesting because you can code and more flexibility customize your pipeline. btw I've experience with Talend, Informatica PowerCenter, and SSIS .\n\nBut i be honest the prospect of coding in Python within an ETL context really piques my interest but i have concerns Do these modern ETL tools (or as what they call it the new wave) support CDC and Incremental load ?\n\nOur DWH is SingleStoreDB On-Premises. which ETL tool would you recommend for me to push my skills and keep up with those new tools\n\nEdit: we have very large data like like one table has 25M records so are the modern tool can handle those large records faster then the traditional ETL tools like power center.. etc", "author_fullname": "t2_h7fs687a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next-Gen ETL Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tho6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703838530.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703835856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone&lt;/p&gt;\n\n&lt;p&gt;I really would appreciate some guidance. From what I&amp;#39;ve read tools like Fivetran, Airflow, and Airbyte and on paper they sound interesting because you can code and more flexibility customize your pipeline. btw I&amp;#39;ve experience with Talend, Informatica PowerCenter, and SSIS .&lt;/p&gt;\n\n&lt;p&gt;But i be honest the prospect of coding in Python within an ETL context really piques my interest but i have concerns Do these modern ETL tools (or as what they call it the new wave) support CDC and Incremental load ?&lt;/p&gt;\n\n&lt;p&gt;Our DWH is SingleStoreDB On-Premises. which ETL tool would you recommend for me to push my skills and keep up with those new tools&lt;/p&gt;\n\n&lt;p&gt;Edit: we have very large data like like one table has 25M records so are the modern tool can handle those large records faster then the traditional ETL tools like power center.. etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18tho6r", "is_robot_indexable": true, "report_reasons": null, "author": "thebatman7727", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tho6r/nextgen_etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tho6r/nextgen_etl_tools/", "subreddit_subscribers": 149302, "created_utc": 1703835856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got hired as a data engineer and will likely start in 2 weeks. I have my theory ok, some personal projects and a certification, but I want to know how can I prepare for the day to day work. Bootcamps and solo projects don't fill much on what skills you will need in a real job I think. For some context, I have 4 yoe as a scientist (geologist).\n\nThanks!", "author_fullname": "t2_d9cmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to know before my first job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tr905", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703867945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got hired as a data engineer and will likely start in 2 weeks. I have my theory ok, some personal projects and a certification, but I want to know how can I prepare for the day to day work. Bootcamps and solo projects don&amp;#39;t fill much on what skills you will need in a real job I think. For some context, I have 4 yoe as a scientist (geologist).&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18tr905", "is_robot_indexable": true, "report_reasons": null, "author": "sebakjal", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tr905/what_to_know_before_my_first_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tr905/what_to_know_before_my_first_job/", "subreddit_subscribers": 149302, "created_utc": 1703867945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics Engineering in 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_18tx3o5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/22nzC8xnBVRjAAa7thEvjl58YK5o_9vYxuP3cUWv4VY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703883052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dbtips.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dbtips.substack.com/p/analytics-engineering-in-2024", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?auto=webp&amp;s=176e2eae0c06801e0d7b63fa2e5cb61460ce926d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3798aca9bc952393e73fd5f3721746f3c9e571c3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=550e2cac2b33f2041e07dd4f62b4b35fb3d1f3ac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6cfdbe87d36376418bcd53db58cb7da2c010d5fa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=66a57018b29a3358777a7820c87c020570d16393", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cf0e2cf6ed7b0f4f8bc3eb8d3c2db3a60b1a1255", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/erl_4gEdthd9n7HD_Y_p5rlgMIHb3BrY1Dww88yPa70.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88d9e7dcfeeb9345e7bd7e219c48d89d2dd7fb2e", "width": 1080, "height": 540}], "variants": {}, "id": "M4nZBZRGvhIsj5GZBPBKoPFNm33gxX-hbat5fXXkssA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18tx3o5", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tx3o5/analytics_engineering_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dbtips.substack.com/p/analytics-engineering-in-2024", "subreddit_subscribers": 149302, "created_utc": 1703883052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to let people upload excel files into Sharepoint that will be put into s3 and later into redshift. However having some difficulty. A few questions. \n\n&amp;#x200B;\n\nDo I want to use Lists or Libraries? \n\nHow do I handle the creation, updates, and deletes? \n\nWhat happens if someone renames a file? Does a new file get created in s3 alongside the old one or does it actually replace it (seems unlikely?)\n\n&amp;#x200B;\n\nIm basically thinking of creating 3 separate flows one for creates, one fore modifies, one for deletes. But Im not even sure if all 3 of those cases are supported. Any advice from someone who has done a similar thing would be very appreciated!", "author_fullname": "t2_b3n9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to best sync files between Sharepoint and s3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tw6um", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703880691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to let people upload excel files into Sharepoint that will be put into s3 and later into redshift. However having some difficulty. A few questions. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do I want to use Lists or Libraries? &lt;/p&gt;\n\n&lt;p&gt;How do I handle the creation, updates, and deletes? &lt;/p&gt;\n\n&lt;p&gt;What happens if someone renames a file? Does a new file get created in s3 alongside the old one or does it actually replace it (seems unlikely?)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Im basically thinking of creating 3 separate flows one for creates, one fore modifies, one for deletes. But Im not even sure if all 3 of those cases are supported. Any advice from someone who has done a similar thing would be very appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18tw6um", "is_robot_indexable": true, "report_reasons": null, "author": "third_dude", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tw6um/how_to_best_sync_files_between_sharepoint_and_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tw6um/how_to_best_sync_files_between_sharepoint_and_s3/", "subreddit_subscribers": 149302, "created_utc": 1703880691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI\u2019m trying to figure out a good system for securely using and managing secrets. I\u2019d like to hear about what everyone else does. I\u2019ll also share my early idea for a system I think may some merit to it.\n\nThis approach leverages AWS Secrets Manager, Gitea, Age encryption protocol, and Mozilla SOPS. It attempts to provide robust and secure secrets management while minimizing cost,\n\n**Key Components:**\n1. **Infrastructure:**\n   - Gitea hosted on a private cloud subnet, accessed via a bastion server.\n   - AWS Secrets Manager for secure storage of encryption keys.\n\n2. **Secrets Encryption:**\n   - Age encryption protocol for encryption keys.\n   - Mozilla SOPS to locally encrypt secrets in a `secrets.json` file.\n\n3. **Remote Machine Usage**\n     - Cloud machines perform `git pull` every time secrets are needed to retrieve updated secrets.\n     - Fetch the new decryption key from AWS Secrets.\n     - Decrypt secrets in memory using Mozilla SOPS.\n     - Discard old decryption key and decrypted secrets from memory.\n     - Discard decrypted secrets from memory after use\n\n4. **Key Rotation Process:**\n   - **Generate New Key**\n     - Utilize Age encryption protocol to create a fresh encryption key.\n     - Upload the encryption key to AWS secrets for later use\n\n   - **Rotate Secrets**\n     - Use AWS Secrets API to collect the old encryption key.\n     - `git pull` all repositories that use the encryption key for their secrets\n     - Decrypt all secrets with the old encryption key\n     - Encrypt all secrets with Mozilla SOPS using the new key.\n     - Embed AWS Secrets ID in the git push for future reference.\n     - `git push` the updated `secrets.json` files to Secrets-Gitea.\n     - Update AWS Secrets to include the new decryption key.\n\n**Capabilities:**\n- **Traceability:**\n  - Each `secrets.json` file is associated with its encryption key through AWS Secrets ID.\n\n- **Key Rotation:**\n  - Enables regular updates for enhanced security.\n\n- **Cost Savings:**\n  - Effective use of cloud resources. Secrets management is expensive.\n\n- **Version Control:**\n  - Leverages Gitea for versioning of secrets, aiding in auditing and rollbacks.\n\n**Considerations:**\n- **Centralization Drawbacks:**\n  - Potential single point of attack\n\nEdit: perhaps with git-remote-gcrypt", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you securely manage remotely available secrets at scale in a cost effective way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tdkfv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703823878.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703822035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to figure out a good system for securely using and managing secrets. I\u2019d like to hear about what everyone else does. I\u2019ll also share my early idea for a system I think may some merit to it.&lt;/p&gt;\n\n&lt;p&gt;This approach leverages AWS Secrets Manager, Gitea, Age encryption protocol, and Mozilla SOPS. It attempts to provide robust and secure secrets management while minimizing cost,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;\n1. &lt;strong&gt;Infrastructure:&lt;/strong&gt;\n   - Gitea hosted on a private cloud subnet, accessed via a bastion server.\n   - AWS Secrets Manager for secure storage of encryption keys.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Secrets Encryption:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Age encryption protocol for encryption keys.&lt;/li&gt;\n&lt;li&gt;Mozilla SOPS to locally encrypt secrets in a &lt;code&gt;secrets.json&lt;/code&gt; file.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Remote Machine Usage&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cloud machines perform &lt;code&gt;git pull&lt;/code&gt; every time secrets are needed to retrieve updated secrets.&lt;/li&gt;\n&lt;li&gt;Fetch the new decryption key from AWS Secrets.&lt;/li&gt;\n&lt;li&gt;Decrypt secrets in memory using Mozilla SOPS.&lt;/li&gt;\n&lt;li&gt;Discard old decryption key and decrypted secrets from memory.&lt;/li&gt;\n&lt;li&gt;Discard decrypted secrets from memory after use&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Key Rotation Process:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Generate New Key&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Utilize Age encryption protocol to create a fresh encryption key.&lt;/li&gt;\n&lt;li&gt;Upload the encryption key to AWS secrets for later use&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Rotate Secrets&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Use AWS Secrets API to collect the old encryption key.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;git pull&lt;/code&gt; all repositories that use the encryption key for their secrets&lt;/li&gt;\n&lt;li&gt;Decrypt all secrets with the old encryption key&lt;/li&gt;\n&lt;li&gt;Encrypt all secrets with Mozilla SOPS using the new key.&lt;/li&gt;\n&lt;li&gt;Embed AWS Secrets ID in the git push for future reference.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;git push&lt;/code&gt; the updated &lt;code&gt;secrets.json&lt;/code&gt; files to Secrets-Gitea.&lt;/li&gt;\n&lt;li&gt;Update AWS Secrets to include the new decryption key.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Capabilities:&lt;/strong&gt;\n- &lt;strong&gt;Traceability:&lt;/strong&gt;\n  - Each &lt;code&gt;secrets.json&lt;/code&gt; file is associated with its encryption key through AWS Secrets ID.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Key Rotation:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Enables regular updates for enhanced security.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Cost Savings:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Effective use of cloud resources. Secrets management is expensive.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Version Control:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Leverages Gitea for versioning of secrets, aiding in auditing and rollbacks.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Considerations:&lt;/strong&gt;\n- &lt;strong&gt;Centralization Drawbacks:&lt;/strong&gt;\n  - Potential single point of attack&lt;/p&gt;\n\n&lt;p&gt;Edit: perhaps with git-remote-gcrypt&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18tdkfv", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tdkfv/how_do_you_securely_manage_remotely_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tdkfv/how_do_you_securely_manage_remotely_available/", "subreddit_subscribers": 149302, "created_utc": 1703822035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need to SFTP files generated every 15 minutes up to an external SAAS product.\n\nProblem is the app generating these files has a hard lock on them.  It monitors realtime and keeps appending.  The target system doesn't actually need those files.  But it does need all the other files in the folder.\n\nThe files don't have an extension so I can't pattern match the ones to copy up.\n\nIs there anyway to do this in ADF natively?\n\nOr if it can't do that can I run a python script or powershell and pass the file list I want it to send back to ADF?\n\nThe files have RTA in the name so I'm sure I can regex that string in python.  Its the passing that list back to ADF for the pipeline job is the bit I have no clue.", "author_fullname": "t2_21umeu7n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I exclude files in ADF?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tbxq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703817432.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703817247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to SFTP files generated every 15 minutes up to an external SAAS product.&lt;/p&gt;\n\n&lt;p&gt;Problem is the app generating these files has a hard lock on them.  It monitors realtime and keeps appending.  The target system doesn&amp;#39;t actually need those files.  But it does need all the other files in the folder.&lt;/p&gt;\n\n&lt;p&gt;The files don&amp;#39;t have an extension so I can&amp;#39;t pattern match the ones to copy up.&lt;/p&gt;\n\n&lt;p&gt;Is there anyway to do this in ADF natively?&lt;/p&gt;\n\n&lt;p&gt;Or if it can&amp;#39;t do that can I run a python script or powershell and pass the file list I want it to send back to ADF?&lt;/p&gt;\n\n&lt;p&gt;The files have RTA in the name so I&amp;#39;m sure I can regex that string in python.  Its the passing that list back to ADF for the pipeline job is the bit I have no clue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18tbxq3", "is_robot_indexable": true, "report_reasons": null, "author": "ComfortAndSpeed", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tbxq3/how_do_i_exclude_files_in_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tbxq3/how_do_i_exclude_files_in_adf/", "subreddit_subscribers": 149302, "created_utc": 1703817247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started reading designing data intensive applications and found it complex for someone just starting out with DE. Looking for a lightweight recommendation please.  \n\nI have 20 years of IT experience on infrastructure management and devops.", "author_fullname": "t2_93n793j1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best book for data engineering fundamentals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18u2l6b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703897590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started reading designing data intensive applications and found it complex for someone just starting out with DE. Looking for a lightweight recommendation please.  &lt;/p&gt;\n\n&lt;p&gt;I have 20 years of IT experience on infrastructure management and devops.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18u2l6b", "is_robot_indexable": true, "report_reasons": null, "author": "Total_Definition_401", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18u2l6b/best_book_for_data_engineering_fundamentals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18u2l6b/best_book_for_data_engineering_fundamentals/", "subreddit_subscribers": 149302, "created_utc": 1703897590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nThis is a bit of a weird question, but I've been a \"data engineer\" for the past 6 months in a company that has been going through a lot of turmoil. Job security isn't great because of its financial position, we're not actually doing any development due to change freezes (so my skills aren't improving) and I may need to look elsewhere if things continue to go badly, but I feel like I don't have the actual skills or experience a data engineer should have and am worried about getting another job.\n\nI was hoping people here might be able to point at holes I need to fill to very generally improve my skillset. I know that data engineering roles and the technologies they use can vary massively, so I understand this will need to be broad.\n\n\nSkills I have at the moment:\n\n1. Good understanding of SQL in terms of writing and performance-tuning queries (I was a SQL dev / did Application Support for MSSQL and Interbase-based processes before this). Not much on the DBA side of things.\n\n2. Have been working with Snowflake for the past 6 months, though my \"Engineering\" experience with it extends as far as Snowpipes and making stages.\n\n3. Some Azure Data Factory pipeline use though these have been REALLY basic (picking up a list of select statements from a txt file, executing it on a target database and then shifting the data to Snowflake).\n\nI've picked up Python Crash Course to work through as I know I should have familiarity with Python at the moment, though I don't actually really know why I need Python; that's how sheltered I am from broad data engineering concepts! Other than that what should I be working on?\n\nThank you in advance.", "author_fullname": "t2_7ahm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filling Gaps in my Data Engineering Skillset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18u1isg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703894653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;This is a bit of a weird question, but I&amp;#39;ve been a &amp;quot;data engineer&amp;quot; for the past 6 months in a company that has been going through a lot of turmoil. Job security isn&amp;#39;t great because of its financial position, we&amp;#39;re not actually doing any development due to change freezes (so my skills aren&amp;#39;t improving) and I may need to look elsewhere if things continue to go badly, but I feel like I don&amp;#39;t have the actual skills or experience a data engineer should have and am worried about getting another job.&lt;/p&gt;\n\n&lt;p&gt;I was hoping people here might be able to point at holes I need to fill to very generally improve my skillset. I know that data engineering roles and the technologies they use can vary massively, so I understand this will need to be broad.&lt;/p&gt;\n\n&lt;p&gt;Skills I have at the moment:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Good understanding of SQL in terms of writing and performance-tuning queries (I was a SQL dev / did Application Support for MSSQL and Interbase-based processes before this). Not much on the DBA side of things.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have been working with Snowflake for the past 6 months, though my &amp;quot;Engineering&amp;quot; experience with it extends as far as Snowpipes and making stages.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Some Azure Data Factory pipeline use though these have been REALLY basic (picking up a list of select statements from a txt file, executing it on a target database and then shifting the data to Snowflake).&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve picked up Python Crash Course to work through as I know I should have familiarity with Python at the moment, though I don&amp;#39;t actually really know why I need Python; that&amp;#39;s how sheltered I am from broad data engineering concepts! Other than that what should I be working on?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18u1isg", "is_robot_indexable": true, "report_reasons": null, "author": "Devilb0y", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18u1isg/filling_gaps_in_my_data_engineering_skillset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18u1isg/filling_gaps_in_my_data_engineering_skillset/", "subreddit_subscribers": 149302, "created_utc": 1703894653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working in data within a manufacturing role and want a better understanding of how everything is typically linked together. For example shop floor production data, does each record have shift, PO#, WO#, etc. If not, how is that information linked together. How do assets (machines) and resources (cells) link to production goals and routings. \n\nThere are so many moving pieces and I want to better understand it. ", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MES/ERP Database Design Diagram Sample?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18u0o43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703892395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working in data within a manufacturing role and want a better understanding of how everything is typically linked together. For example shop floor production data, does each record have shift, PO#, WO#, etc. If not, how is that information linked together. How do assets (machines) and resources (cells) link to production goals and routings. &lt;/p&gt;\n\n&lt;p&gt;There are so many moving pieces and I want to better understand it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18u0o43", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18u0o43/meserp_database_design_diagram_sample/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18u0o43/meserp_database_design_diagram_sample/", "subreddit_subscribers": 149302, "created_utc": 1703892395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the best way to clean up messy customer address data and names? Right now, the data is landing into snowflake from Fivetran.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Messy Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tf85z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703827217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to clean up messy customer address data and names? Right now, the data is landing into snowflake from Fivetran.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18tf85z", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tf85z/messy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tf85z/messy_data/", "subreddit_subscribers": 149302, "created_utc": 1703827217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a project that will include some Linux boxes for servers and want to have essentially a basic S3-esque layer on top of them. Is Minio my best choice? Most objects will be 50-250MB in size and I don\u2019t need a data lake/advanced partitioning of any sort", "author_fullname": "t2_4ffbvgzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mimic Blob Storage on Linux Box(es)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tcx87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703820110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a project that will include some Linux boxes for servers and want to have essentially a basic S3-esque layer on top of them. Is Minio my best choice? Most objects will be 50-250MB in size and I don\u2019t need a data lake/advanced partitioning of any sort&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18tcx87", "is_robot_indexable": true, "report_reasons": null, "author": "ReporterNervous6822", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18tcx87/mimic_blob_storage_on_linux_boxes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18tcx87/mimic_blob_storage_on_linux_boxes/", "subreddit_subscribers": 149302, "created_utc": 1703820110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You are given a pair of datasets each api call and you're asked to link each record from file 1 to similar record from file 2 in real time without any metadata about the columns. How would you approach this problem?", "author_fullname": "t2_7zvlhn0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Record Linkage problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18torlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703861333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You are given a pair of datasets each api call and you&amp;#39;re asked to link each record from file 1 to similar record from file 2 in real time without any metadata about the columns. How would you approach this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18torlm", "is_robot_indexable": true, "report_reasons": null, "author": "Omart__", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18torlm/record_linkage_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18torlm/record_linkage_problem/", "subreddit_subscribers": 149302, "created_utc": 1703861333.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}