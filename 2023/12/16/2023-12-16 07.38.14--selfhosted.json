{"kind": "Listing", "data": {"after": "t3_18iwpqp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_93gqtkw25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Immich v1.91.0 is out, note the breaking changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "phototools", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_18j3sbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 169, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Photo Tools", "can_mod_post": false, "score": 169, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/chp8qYPiE1jVWUnjVobF0KMLl_L3l7VZS9JVILOh-F8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702657177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/immich-app/immich/releases/tag/v1.91.0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?auto=webp&amp;s=19e920b681104bf65d81f258967c805c11fc6ee5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73915eb7d3750dcc8b0884ccc0d2bacf7c51a7c5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe8ea0af0958a7739073e28bd9f2853d750f5c14", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36cdb321eeb238dbecc3df9a8415de6694dd15a7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec5b06214a822f69e5704f66d16cf9c6fca4186", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=317e9e6c1690940f903303bd90c8bdc1da88b27e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96105b20b09213d35c2347616a08138fd3228457", "width": 1080, "height": 540}], "variants": {}, "id": "7HLMCeoqPom_GRceRbz3kNxxbobDFNdWRAAnOC0zL5w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4474b0e2-7e68-11e9-96f8-0e01fac4c7aa", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j3sbt", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable-Jump-8332", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j3sbt/immich_v1910_is_out_note_the_breaking_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/immich-app/immich/releases/tag/v1.91.0", "subreddit_subscribers": 300140, "created_utc": 1702657177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I want to use wireguard only to \"phone home\" i.e. to be in \"LAN with what I selfhost\".\n\nDoes anyone do this? Any best practices?\n\nWhat bothers me is that default usage for VPN is to mask browsing and this does not interest me. Especially due to my home internet upload speed bottleneck.\n\nSo I would like to be able to start the VPN connection only when I want to access directly my services.\n\nOn Android Wireguard starts automatically and did not found a way to steer conviniently...\n\nOn my Linux machines I can stop it, but there I need to research a bit more how I can do it in the most comfortable way.\n\nAny thoughts / best practices by you?", "author_fullname": "t2_2zrf96nd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wireguard used only \"to phone home\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "vpn", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j12dk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "VPN", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702649757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use wireguard only to &amp;quot;phone home&amp;quot; i.e. to be in &amp;quot;LAN with what I selfhost&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Does anyone do this? Any best practices?&lt;/p&gt;\n\n&lt;p&gt;What bothers me is that default usage for VPN is to mask browsing and this does not interest me. Especially due to my home internet upload speed bottleneck.&lt;/p&gt;\n\n&lt;p&gt;So I would like to be able to start the VPN connection only when I want to access directly my services.&lt;/p&gt;\n\n&lt;p&gt;On Android Wireguard starts automatically and did not found a way to steer conviniently...&lt;/p&gt;\n\n&lt;p&gt;On my Linux machines I can stop it, but there I need to research a bit more how I can do it in the most comfortable way.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts / best practices by you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7e5c2d58-7e68-11e9-9418-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j12dk", "is_robot_indexable": true, "report_reasons": null, "author": "beje_ro", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j12dk/wireguard_used_only_to_phone_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j12dk/wireguard_used_only_to_phone_home/", "subreddit_subscribers": 300140, "created_utc": 1702649757.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello esteemed members of r/selfhosted,\n\n&amp;#x200B;\n\nI'm reaching out to tap into the collective wisdom of this knowledgeable community. I'm in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.\n\nThis tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I'm looking to gather evidence in a sophisticated, yet lighthearted, \"I-told-you-so\" package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca\n\nI would greatly appreciate your recommendations for a free software that combines functionality with ease of use.\n\nIf possible, I have a particular fondness for Docker solutions.\n\n&amp;#x200B;\n\nThank you all :)", "author_fullname": "t2_a0vsc0f4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet speed monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "personaldashboard", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixbks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Dashboard", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702636917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello esteemed members of &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to tap into the collective wisdom of this knowledgeable community. I&amp;#39;m in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.&lt;/p&gt;\n\n&lt;p&gt;This tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I&amp;#39;m looking to gather evidence in a sophisticated, yet lighthearted, &amp;quot;I-told-you-so&amp;quot; package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your recommendations for a free software that combines functionality with ease of use.&lt;/p&gt;\n\n&lt;p&gt;If possible, I have a particular fondness for Docker solutions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "587d404a-7e68-11e9-bd12-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixbks", "is_robot_indexable": true, "report_reasons": null, "author": "TPK-trade", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "subreddit_subscribers": 300140, "created_utc": 1702636917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Happy Friday, r/selfhosted! Below is a link to *This Week in Self-Hosted*, a weekly newsletter recap of the latest activity in self-hosted software.\n\nThis week's features include:\n\n* The latest news in self-hosted software\n* Noteworthy software updates, launches, and events\n* Featured content generated by the self-hosted community\n* A spotlight on [Dockge](https://github.com/louislam/dockge?ref=selfh.st), a web-based docker compose stack manager\n\nAs usual, feel free to reach out with questions or comments about the newsletter. Thanks!\n\n---\n\n[This Week in Self-Hosted (15 December 2023)](https://selfh.st/newsletter/2023-12-15/)", "author_fullname": "t2_vvcklg6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This Week in Self-Hosted (15 December 2023)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iz5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702643917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy Friday, &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;! Below is a link to &lt;em&gt;This Week in Self-Hosted&lt;/em&gt;, a weekly newsletter recap of the latest activity in self-hosted software.&lt;/p&gt;\n\n&lt;p&gt;This week&amp;#39;s features include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The latest news in self-hosted software&lt;/li&gt;\n&lt;li&gt;Noteworthy software updates, launches, and events&lt;/li&gt;\n&lt;li&gt;Featured content generated by the self-hosted community&lt;/li&gt;\n&lt;li&gt;A spotlight on &lt;a href=\"https://github.com/louislam/dockge?ref=selfh.st\"&gt;Dockge&lt;/a&gt;, a web-based docker compose stack manager&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As usual, feel free to reach out with questions or comments about the newsletter. Thanks!&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;a href=\"https://selfh.st/newsletter/2023-12-15/\"&gt;This Week in Self-Hosted (15 December 2023)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?auto=webp&amp;s=edfc1e87b204020d848795a64b8ddd109f886270", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c09d9bcd169fce6fdd6ec7fe2b47833eb6296217", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a96911c301ea2dc8736504b014f3a27df1e244e7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a033b33b71d55259659ff2a51b42fcacac339838", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d2f988460654901b3d6b889110ca2a147372098", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ba692125aee2344994701d6c49e2c97855e8965", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e4378b1466adcd48a4bf01cd798b53307a12061e", "width": 1080, "height": 540}], "variants": {}, "id": "Gf1_-kT8szx_yWNO2zBdA-iQjknAjjAqkcYTWsAw_zE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iz5mc", "is_robot_indexable": true, "report_reasons": null, "author": "selfh-sted", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "subreddit_subscribers": 300140, "created_utc": 1702643917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": " \n\nHey\n\nI'm diving into the exciting world of honeypots and cybersecurity at home, and I'd love some guidance on creating a live attack map using Grafana. Specifically, I'm using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here's where I could use some help.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\n\nI've been inspired by those awesome live attack maps from TPOTCE, and I'm eager to replicate something similar for my own setup. As a newbie in homelabs, I'm wondering if anyone has experience or advice on achieving this. I'd appreciate insights on how to Configure Grafana to visualize the attacks in real-time.\n\nIf you've tackled a similar project or have tips for a homelab newbie, I'd love to hear about your experiences and any resources you found helpful.", "author_fullname": "t2_7dixsldo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Live Attack Map with Grafana, Cowrie, and Prometheus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 126, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3yu1gngy6g6c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 97, "x": 108, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8eec587d6c24a02fac84f9548944912c281d97d2"}, {"y": 195, "x": 216, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccf1ecd4a718dc91fafbbdecce962f5882ab478d"}, {"y": 289, "x": 320, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=571b35d86b53068d98c3621eecc169a2cccb5a95"}, {"y": 578, "x": 640, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=141473d0b9e21d6cecbc41b47cccbdfa25327e37"}, {"y": 867, "x": 960, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=39c78b816374d4d7939511a4ff110b2abc1b43db"}, {"y": 975, "x": 1080, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe1964b3a71a6a02f3864b791570b95d6a0f0a2e"}], "s": {"y": 1779, "x": 1969, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b"}, "id": "3yu1gngy6g6c1"}}, "name": "t3_18iyggv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/h0uIxx4KbylDGGBKiqlSjEh74Qh1inkEkmdCMtq0YaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702641392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m diving into the exciting world of honeypots and cybersecurity at home, and I&amp;#39;d love some guidance on creating a live attack map using Grafana. Specifically, I&amp;#39;m using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here&amp;#39;s where I could use some help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\"&gt;https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been inspired by those awesome live attack maps from TPOTCE, and I&amp;#39;m eager to replicate something similar for my own setup. As a newbie in homelabs, I&amp;#39;m wondering if anyone has experience or advice on achieving this. I&amp;#39;d appreciate insights on how to Configure Grafana to visualize the attacks in real-time.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve tackled a similar project or have tips for a homelab newbie, I&amp;#39;d love to hear about your experiences and any resources you found helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iyggv", "is_robot_indexable": true, "report_reasons": null, "author": "TheKing464", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "subreddit_subscribers": 300140, "created_utc": 1702641392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_1fsoypwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lemmy v0.19.0 Release - Instance blocking, Scaled sort, and Federation Queue.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "blogging", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j10rm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blogging Platform", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702649630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "join-lemmy.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://join-lemmy.org/news/2023-12-15_-_Lemmy_Release_v0.19.0_-_Instance_blocking,_Scaled_sort,_and_Federation_Queue", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "fd71269e-7e67-11e9-8d1a-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j10rm", "is_robot_indexable": true, "report_reasons": null, "author": "parentis_shotgun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j10rm/lemmy_v0190_release_instance_blocking_scaled_sort/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://join-lemmy.org/news/2023-12-15_-_Lemmy_Release_v0.19.0_-_Instance_blocking,_Scaled_sort,_and_Federation_Queue", "subreddit_subscribers": 300140, "created_utc": 1702649630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So, i keep moving forward on my journey choosing an IDP for my services.\n\nI have tested Authentik and it works kinda OK, i have some issues with Azure AD authentication. It seems that there is a confirmed bug, but it looks like Authentik has kinda only one person developing it and that can be a problem when we face problems or bugs. Thats the biggest negative of Authentik for me.\n\nNow i'm testing Keycloak, i was able to set it up and it seams that is running just fine. The problem is that most of the services that i want to protect does note use any kind of authentication that is suported by Keycloak (\\*rr apps, Overseerr, Homarr and etc), like Oauth2, SAML and etc.\n\nAuthentik supports the \"proxy\" auth, meaning that you put an forward auth middleware on traefik and it will intercept the trafic and authenticate you before you enter the page. On Authentik that works great, but i did not found any way to do that on Keycloak without using an external middleware on traefik that goes thought anoter container and not drirectly to keycloak like authentik can do.\n\nI have in the past used that forward auth container but i always had problems with it, lots of problems, so i dont want to get back to it.\n\nDo you know if is there any way to configure Keycloak to act as the forward auth middleware for Traefik like Authentik does so i dont need to use a third container to this usecase?\n\nThanks", "author_fullname": "t2_dlsxpsz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keycloak + Traefik and Forward Auth (Proxy Auth)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "proxy", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jdyik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Proxy", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702684437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i keep moving forward on my journey choosing an IDP for my services.&lt;/p&gt;\n\n&lt;p&gt;I have tested Authentik and it works kinda OK, i have some issues with Azure AD authentication. It seems that there is a confirmed bug, but it looks like Authentik has kinda only one person developing it and that can be a problem when we face problems or bugs. Thats the biggest negative of Authentik for me.&lt;/p&gt;\n\n&lt;p&gt;Now i&amp;#39;m testing Keycloak, i was able to set it up and it seams that is running just fine. The problem is that most of the services that i want to protect does note use any kind of authentication that is suported by Keycloak (*rr apps, Overseerr, Homarr and etc), like Oauth2, SAML and etc.&lt;/p&gt;\n\n&lt;p&gt;Authentik supports the &amp;quot;proxy&amp;quot; auth, meaning that you put an forward auth middleware on traefik and it will intercept the trafic and authenticate you before you enter the page. On Authentik that works great, but i did not found any way to do that on Keycloak without using an external middleware on traefik that goes thought anoter container and not drirectly to keycloak like authentik can do.&lt;/p&gt;\n\n&lt;p&gt;I have in the past used that forward auth container but i always had problems with it, lots of problems, so i dont want to get back to it.&lt;/p&gt;\n\n&lt;p&gt;Do you know if is there any way to configure Keycloak to act as the forward auth middleware for Traefik like Authentik does so i dont need to use a third container to this usecase?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5e46c26c-7e68-11e9-8d4e-0e3bbb559e74", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jdyik", "is_robot_indexable": true, "report_reasons": null, "author": "fabio_teixei", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jdyik/keycloak_traefik_and_forward_auth_proxy_auth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jdyik/keycloak_traefik_and_forward_auth_proxy_auth/", "subreddit_subscribers": 300140, "created_utc": 1702684437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Howdy, I am looking to update our CCTV setup and hoping all you lovely folks can help point me in the right direction without spending days evaluating options :)\n\nI run an escape room business and we use CCTV to monitor guest progress as they \"escape\" the rooms.\n\nOur current setup:\n\n* we have 16 cameras (Amcrest IP2M-841EB)\n* we use **Amcrest Surveillance Pro** installed on each workstation (4 Windows PCs)\n* the cameras are grouped per room (e.g. \"Detective Room\", \"Space Room\", etc)\n* employees use the workstation PCs to monitor guests on up to 4 cameras (3-4 cameras per escape room)\n* employees use PTZ to view different angles from the cameras\n\nI'm looking to get everything onto a self-hosted server rather than installed directly on the workstations. I have a Dell PoweEdge R230 with Proxmox and a few docker instances running. NVR would be nice, but is a secondary priority. I also DO NOT need AI, motion / object detection, zones, triggers, \"tours\", auto-tracking, or anything fancy like that.\n\nI want to get all the cameras centrally hosted and then use a web UI (or desktop client) to view a given room's cameras. Being able to save a camera layout / view / group is a requirement (e.g. all cameras in a room). Also being able to use PTZ easily is a requirement (ideally, can control PTZ for any given camera without having to leave the 4 camera view).\n\nBlue Iris probably seems like the most obvious answer (especially since our whole setup is Amcrest at this point), but I'm not huge on spinning up a Windows VM just for BI, and I've never loved Amcrest Surveillance Pro, so part of me wants to try another vendor, but I'm not terribly biased.\n\nNormally I would just spin up each of them and evaluate all the options, but life has other plans, so I'm looking for some outside (\"expert\") advice.\n\nThanks a bunch for any suggestions / insight!", "author_fullname": "t2_ikuhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for CCTV/NVR recommendation (Frigate, Shinobi, iSpy, BlueIris, Zoneminder, etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jb3tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702676582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy, I am looking to update our CCTV setup and hoping all you lovely folks can help point me in the right direction without spending days evaluating options :)&lt;/p&gt;\n\n&lt;p&gt;I run an escape room business and we use CCTV to monitor guest progress as they &amp;quot;escape&amp;quot; the rooms.&lt;/p&gt;\n\n&lt;p&gt;Our current setup:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;we have 16 cameras (Amcrest IP2M-841EB)&lt;/li&gt;\n&lt;li&gt;we use &lt;strong&gt;Amcrest Surveillance Pro&lt;/strong&gt; installed on each workstation (4 Windows PCs)&lt;/li&gt;\n&lt;li&gt;the cameras are grouped per room (e.g. &amp;quot;Detective Room&amp;quot;, &amp;quot;Space Room&amp;quot;, etc)&lt;/li&gt;\n&lt;li&gt;employees use the workstation PCs to monitor guests on up to 4 cameras (3-4 cameras per escape room)&lt;/li&gt;\n&lt;li&gt;employees use PTZ to view different angles from the cameras&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m looking to get everything onto a self-hosted server rather than installed directly on the workstations. I have a Dell PoweEdge R230 with Proxmox and a few docker instances running. NVR would be nice, but is a secondary priority. I also DO NOT need AI, motion / object detection, zones, triggers, &amp;quot;tours&amp;quot;, auto-tracking, or anything fancy like that.&lt;/p&gt;\n\n&lt;p&gt;I want to get all the cameras centrally hosted and then use a web UI (or desktop client) to view a given room&amp;#39;s cameras. Being able to save a camera layout / view / group is a requirement (e.g. all cameras in a room). Also being able to use PTZ easily is a requirement (ideally, can control PTZ for any given camera without having to leave the 4 camera view).&lt;/p&gt;\n\n&lt;p&gt;Blue Iris probably seems like the most obvious answer (especially since our whole setup is Amcrest at this point), but I&amp;#39;m not huge on spinning up a Windows VM just for BI, and I&amp;#39;ve never loved Amcrest Surveillance Pro, so part of me wants to try another vendor, but I&amp;#39;m not terribly biased.&lt;/p&gt;\n\n&lt;p&gt;Normally I would just spin up each of them and evaluate all the options, but life has other plans, so I&amp;#39;m looking for some outside (&amp;quot;expert&amp;quot;) advice.&lt;/p&gt;\n\n&lt;p&gt;Thanks a bunch for any suggestions / insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jb3tr", "is_robot_indexable": true, "report_reasons": null, "author": "largenostril", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jb3tr/looking_for_cctvnvr_recommendation_frigate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jb3tr/looking_for_cctvnvr_recommendation_frigate/", "subreddit_subscribers": 300140, "created_utc": 1702676582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My first post here. Do any of you guys know an open source self hosted option for a ticketing system similar to eventbrite, ticketmaster etc ..?", "author_fullname": "t2_8onhnk6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted opensource app for ticketing system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jjgpz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702702319.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702702020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My first post here. Do any of you guys know an open source self hosted option for a ticketing system similar to eventbrite, ticketmaster etc ..?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jjgpz", "is_robot_indexable": true, "report_reasons": null, "author": "MoneyBag4705", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jjgpz/selfhosted_opensource_app_for_ticketing_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jjgpz/selfhosted_opensource_app_for_ticketing_system/", "subreddit_subscribers": 300140, "created_utc": 1702702020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Been looking for something that can achieve the need but never found anything. So time to ask.\n\n&amp;#x200B;\n\nAs indie dev I always need to get users logs from my apps for support and I'm doing most of the support publicly on a discourse server.\n\nUsers uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.\n\nSo I'm looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)\n\nIdeally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).\n\nBonus would be automated deletion of the files after a configurable delay.\n\nAnything that requires users to create an account does not really work.\n\nIf they no more have access to the file after upload and closing the page this can be OK.", "author_fullname": "t2_9oh0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting securely temporary logs between anonymous persons and me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iuysh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702626674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been looking for something that can achieve the need but never found anything. So time to ask.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As indie dev I always need to get users logs from my apps for support and I&amp;#39;m doing most of the support publicly on a discourse server.&lt;/p&gt;\n\n&lt;p&gt;Users uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)&lt;/p&gt;\n\n&lt;p&gt;Ideally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).&lt;/p&gt;\n\n&lt;p&gt;Bonus would be automated deletion of the files after a configurable delay.&lt;/p&gt;\n\n&lt;p&gt;Anything that requires users to create an account does not really work.&lt;/p&gt;\n\n&lt;p&gt;If they no more have access to the file after upload and closing the page this can be OK.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iuysh", "is_robot_indexable": true, "report_reasons": null, "author": "Tolriq", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "subreddit_subscribers": 300140, "created_utc": 1702626674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\nI bought a domain on cloudflare in order to expose my selfhosted apps. I am using authelia with 2fa for security an have my cloudflare challenges to high. I have got 2.5k requests in the last 24 hours. The domain only started working 48 hours ago but I have got seemingly a lot of requests. Most of the requests (1.7k) are from my country so I am not sure if they are all me but that leaves 800 requests from 144 unique visitors that are not me. A few cloudflare challenges were completed from people in other countries and I have locked all traffic not from my country for now. Is this normal for a new domain and should I be worried?  \n\n\nThank you!", "author_fullname": "t2_5gthmgz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudflare lots of requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j8o6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702670016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I bought a domain on cloudflare in order to expose my selfhosted apps. I am using authelia with 2fa for security an have my cloudflare challenges to high. I have got 2.5k requests in the last 24 hours. The domain only started working 48 hours ago but I have got seemingly a lot of requests. Most of the requests (1.7k) are from my country so I am not sure if they are all me but that leaves 800 requests from 144 unique visitors that are not me. A few cloudflare challenges were completed from people in other countries and I have locked all traffic not from my country for now. Is this normal for a new domain and should I be worried?  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j8o6p", "is_robot_indexable": true, "report_reasons": null, "author": "Only-Pin-490", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j8o6p/cloudflare_lots_of_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j8o6p/cloudflare_lots_of_requests/", "subreddit_subscribers": 300140, "created_utc": 1702670016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So i've been trying to get Archivebox running for the past few hours and i'm at a loss\n\nThe logs make it seem everything is working properly but when I go to [192.168.1.32:31200](https://192.168.1.32:31200) it just times out. \n\nI've tried using Portainer and running the docker compose setup guide through the shell with no luck.\n\nHere are the Portainer logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n       &gt; /data\n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    [+] Building archive folder structure...\n       + ./archive, ./sources, ./logs...\n       + ./ArchiveBox.conf...\n    [+] Building main SQL index and running initial migrations...\n       Operations to perform:\n       Apply all migrations: admin, auth, contenttypes, core, sessions\n       Running migrations:\n       Applying contenttypes.0001_initial... OK\n       Applying auth.0001_initial... OK\n       Applying admin.0001_initial... OK\n       Applying admin.0002_logentry_remove_auto_add... OK\n       Applying admin.0003_logentry_add_action_flag_choices... OK\n       Applying contenttypes.0002_remove_content_type_name... OK\n       Applying auth.0002_alter_permission_name_max_length... OK\n       Applying auth.0003_alter_user_email_max_length... OK\n       Applying auth.0004_alter_user_username_opts... OK\n       Applying auth.0005_alter_user_last_login_null... OK\n       Applying auth.0006_require_contenttypes_0002... OK\n       Applying auth.0007_alter_validators_add_error_messages... OK\n       Applying auth.0008_alter_user_username_max_length... OK\n       Applying auth.0009_alter_user_last_name_max_length... OK\n       Applying auth.0010_alter_group_name_max_length... OK\n       Applying auth.0011_update_proxy_permissions... OK\n       Applying auth.0012_alter_user_first_name_max_length... OK\n       Applying core.0001_initial... OK\n       Applying core.0002_auto_20200625_1521... OK\n       Applying core.0003_auto_20200630_1034... OK\n       Applying core.0004_auto_20200713_1552... OK\n       Applying core.0005_auto_20200728_0326... OK\n       Applying core.0006_auto_20201012_1520... OK\n       Applying core.0007_archiveresult... OK\n       Applying core.0008_auto_20210105_1421... OK\n       Applying core.0009_auto_20210216_1038... OK\n       Applying core.0010_auto_20210216_1055... OK\n       Applying core.0011_auto_20210216_1331... OK\n       Applying core.0012_auto_20210216_1425... OK\n       Applying core.0013_auto_20210218_0729... OK\n       Applying core.0014_auto_20210218_0729... OK\n       Applying core.0015_auto_20210218_0730... OK\n       Applying core.0016_auto_20210218_1204... OK\n       Applying core.0017_auto_20210219_0211... OK\n       Applying core.0018_auto_20210327_0952... OK\n       Applying core.0019_auto_20210401_0654... OK\n       Applying core.0020_auto_20210410_1031... OK\n       Applying core.0021_auto_20220914_0934... OK\n       Applying core.0022_auto_20231023_2008... OK\n       Applying sessions.0001_initial... OK\n       \u221a ./index.sqlite3\n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n       &gt; Skipping full snapshot directory check (quick mode)\n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n       Hint: To view your archive index, run:\n           archivebox server  # then visit http://127.0.0.1:8000\n       To add new links, you can run:\n           archivebox add &lt; ~/some/path/to/list_of_links.txt\n       For more usage and examples, run:\n           archivebox help\n    [+] Starting ArchiveBox webserver...\n       &gt; Logging errors to ./logs/errors.log\n    [!] No admin users exist yet, you will not be able to edit links in the UI.\n       To create an admin user, run:\n           archivebox manage createsuperuser\n    Performing system checks...\n    System check identified no issues (0 silenced).\n    December 15, 2023 - 10:29:59\n    Django version 3.1.14, using settings 'core.settings'\n    Starting development server at http://0.0.0.0:31200/\n    Quit the server with CONTROL-C.\n\nAnd here are the Proxmox shell logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n        &gt; /data\n    \n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    \n    [+] Building archive folder structure...\n        + ./archive, ./sources, ./logs...\n        + ./ArchiveBox.conf...\n    \n    [+] Building main SQL index and running initial migrations...\n        Operations to perform:\n          Apply all migrations: admin, auth, contenttypes, core, sessions\n        Running migrations:\n        Applying contenttypes.0001_initial... OK\n        Applying auth.0001_initial... OK\n        Applying admin.0001_initial... OK\n        Applying admin.0002_logentry_remove_auto_add... OK\n        Applying admin.0003_logentry_add_action_flag_choices... OK\n        Applying contenttypes.0002_remove_content_type_name... OK\n        Applying auth.0002_alter_permission_name_max_length... OK\n        Applying auth.0003_alter_user_email_max_length... OK\n        Applying auth.0004_alter_user_username_opts... OK\n        Applying auth.0005_alter_user_last_login_null... OK\n        Applying auth.0006_require_contenttypes_0002... OK\n        Applying auth.0007_alter_validators_add_error_messages... OK\n        Applying auth.0008_alter_user_username_max_length... OK\n        Applying auth.0009_alter_user_last_name_max_length... OK\n        Applying auth.0010_alter_group_name_max_length... OK\n        Applying auth.0011_update_proxy_permissions... OK\n        Applying auth.0012_alter_user_first_name_max_length... OK\n        Applying core.0001_initial... OK\n        Applying core.0002_auto_20200625_1521... OK\n        Applying core.0003_auto_20200630_1034... OK\n        Applying core.0004_auto_20200713_1552... OK\n        Applying core.0005_auto_20200728_0326... OK\n        Applying core.0006_auto_20201012_1520... OK\n        Applying core.0007_archiveresult... OK\n        Applying core.0008_auto_20210105_1421... OK\n        Applying core.0009_auto_20210216_1038... OK\n        Applying core.0010_auto_20210216_1055... OK\n        Applying core.0011_auto_20210216_1331... OK\n        Applying core.0012_auto_20210216_1425... OK\n        Applying core.0013_auto_20210218_0729... OK\n        Applying core.0014_auto_20210218_0729... OK\n        Applying core.0015_auto_20210218_0730... OK\n        Applying core.0016_auto_20210218_1204... OK\n        Applying core.0017_auto_20210219_0211... OK\n        Applying core.0018_auto_20210327_0952... OK\n        Applying core.0019_auto_20210401_0654... OK\n        Applying core.0020_auto_20210410_1031... OK\n        Applying core.0021_auto_20220914_0934... OK\n        Applying core.0022_auto_20231023_2008... OK\n        Applying sessions.0001_initial... OK\n    \n        \u221a ./index.sqlite3\n    \n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n    \n    [*] [2023-12-15 09:20:19] Writing 0 links to main index...\n        \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n    \n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n    \n    [+] Creating new admin user for the Web UI...\n    Username (leave blank to use 'archivebox'): admin\n    Email address: **********\n    Password: \n    Password (again): \n    The password is too similar to the username.\n    This password is too short. It must contain at least 8 characters.\n    This password is too common.\n    Bypass password validation and create user anyway? [y/N]: y\n    Superuser created successfully.\n    \n    [+] Installing enabled ArchiveBox dependencies automatically...\n    \n        Installing YOUTUBEDL_BINARY automatically using pip...\n    2023.10.13 is already installed yt-dlp\n    \n        Installing CHROME_BINARY automatically using playwright...\n    Chromium 119.0.6045.9 is already installed chromium-browser\n    \n        Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\n    SINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n    \n    [\u221a] Set up ArchiveBox and its dependencies successfully.\n    0.7.1+editable\n    ArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\n    DEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n    \n    [i] Dependency versions:\n     \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n     \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n     \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n     \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n    \n     \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n     \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n     \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n     \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n     \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n     \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n     \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n     \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n     \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n     \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n    \n    [i] Source-code locations:\n     \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n     \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n     -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n    \n    [i] Secrets locations:\n     -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n     -  COOKIES_FILE          -               disabled  None                                                                        \n    \n    [i] Data locations:\n     \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n     \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n     \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n     \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n     \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n     \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n    \n    \n        Hint: To view your archive index, run:\n            archivebox server  # then visit http://127.0.0.1:8000\n    \n        To add new links, you can run:\n            archivebox add &lt; ~/some/path/to/list_of_links.txt\n    \n        For more usage and examples, run:\n            archivebox help", "author_fullname": "t2_py1z2u36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archivebox timing out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixfjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702637384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;ve been trying to get Archivebox running for the past few hours and i&amp;#39;m at a loss&lt;/p&gt;\n\n&lt;p&gt;The logs make it seem everything is working properly but when I go to &lt;a href=\"https://192.168.1.32:31200\"&gt;192.168.1.32:31200&lt;/a&gt; it just times out. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried using Portainer and running the docker compose setup guide through the shell with no luck.&lt;/p&gt;\n\n&lt;p&gt;Here are the Portainer logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n   &amp;gt; /data\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n[+] Building archive folder structure...\n   + ./archive, ./sources, ./logs...\n   + ./ArchiveBox.conf...\n[+] Building main SQL index and running initial migrations...\n   Operations to perform:\n   Apply all migrations: admin, auth, contenttypes, core, sessions\n   Running migrations:\n   Applying contenttypes.0001_initial... OK\n   Applying auth.0001_initial... OK\n   Applying admin.0001_initial... OK\n   Applying admin.0002_logentry_remove_auto_add... OK\n   Applying admin.0003_logentry_add_action_flag_choices... OK\n   Applying contenttypes.0002_remove_content_type_name... OK\n   Applying auth.0002_alter_permission_name_max_length... OK\n   Applying auth.0003_alter_user_email_max_length... OK\n   Applying auth.0004_alter_user_username_opts... OK\n   Applying auth.0005_alter_user_last_login_null... OK\n   Applying auth.0006_require_contenttypes_0002... OK\n   Applying auth.0007_alter_validators_add_error_messages... OK\n   Applying auth.0008_alter_user_username_max_length... OK\n   Applying auth.0009_alter_user_last_name_max_length... OK\n   Applying auth.0010_alter_group_name_max_length... OK\n   Applying auth.0011_update_proxy_permissions... OK\n   Applying auth.0012_alter_user_first_name_max_length... OK\n   Applying core.0001_initial... OK\n   Applying core.0002_auto_20200625_1521... OK\n   Applying core.0003_auto_20200630_1034... OK\n   Applying core.0004_auto_20200713_1552... OK\n   Applying core.0005_auto_20200728_0326... OK\n   Applying core.0006_auto_20201012_1520... OK\n   Applying core.0007_archiveresult... OK\n   Applying core.0008_auto_20210105_1421... OK\n   Applying core.0009_auto_20210216_1038... OK\n   Applying core.0010_auto_20210216_1055... OK\n   Applying core.0011_auto_20210216_1331... OK\n   Applying core.0012_auto_20210216_1425... OK\n   Applying core.0013_auto_20210218_0729... OK\n   Applying core.0014_auto_20210218_0729... OK\n   Applying core.0015_auto_20210218_0730... OK\n   Applying core.0016_auto_20210218_1204... OK\n   Applying core.0017_auto_20210219_0211... OK\n   Applying core.0018_auto_20210327_0952... OK\n   Applying core.0019_auto_20210401_0654... OK\n   Applying core.0020_auto_20210410_1031... OK\n   Applying core.0021_auto_20220914_0934... OK\n   Applying core.0022_auto_20231023_2008... OK\n   Applying sessions.0001_initial... OK\n   \u221a ./index.sqlite3\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n   &amp;gt; Skipping full snapshot directory check (quick mode)\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n   Hint: To view your archive index, run:\n       archivebox server  # then visit http://127.0.0.1:8000\n   To add new links, you can run:\n       archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n   For more usage and examples, run:\n       archivebox help\n[+] Starting ArchiveBox webserver...\n   &amp;gt; Logging errors to ./logs/errors.log\n[!] No admin users exist yet, you will not be able to edit links in the UI.\n   To create an admin user, run:\n       archivebox manage createsuperuser\nPerforming system checks...\nSystem check identified no issues (0 silenced).\nDecember 15, 2023 - 10:29:59\nDjango version 3.1.14, using settings &amp;#39;core.settings&amp;#39;\nStarting development server at http://0.0.0.0:31200/\nQuit the server with CONTROL-C.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And here are the Proxmox shell logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n    &amp;gt; /data\n\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n\n[+] Building archive folder structure...\n    + ./archive, ./sources, ./logs...\n    + ./ArchiveBox.conf...\n\n[+] Building main SQL index and running initial migrations...\n    Operations to perform:\n      Apply all migrations: admin, auth, contenttypes, core, sessions\n    Running migrations:\n    Applying contenttypes.0001_initial... OK\n    Applying auth.0001_initial... OK\n    Applying admin.0001_initial... OK\n    Applying admin.0002_logentry_remove_auto_add... OK\n    Applying admin.0003_logentry_add_action_flag_choices... OK\n    Applying contenttypes.0002_remove_content_type_name... OK\n    Applying auth.0002_alter_permission_name_max_length... OK\n    Applying auth.0003_alter_user_email_max_length... OK\n    Applying auth.0004_alter_user_username_opts... OK\n    Applying auth.0005_alter_user_last_login_null... OK\n    Applying auth.0006_require_contenttypes_0002... OK\n    Applying auth.0007_alter_validators_add_error_messages... OK\n    Applying auth.0008_alter_user_username_max_length... OK\n    Applying auth.0009_alter_user_last_name_max_length... OK\n    Applying auth.0010_alter_group_name_max_length... OK\n    Applying auth.0011_update_proxy_permissions... OK\n    Applying auth.0012_alter_user_first_name_max_length... OK\n    Applying core.0001_initial... OK\n    Applying core.0002_auto_20200625_1521... OK\n    Applying core.0003_auto_20200630_1034... OK\n    Applying core.0004_auto_20200713_1552... OK\n    Applying core.0005_auto_20200728_0326... OK\n    Applying core.0006_auto_20201012_1520... OK\n    Applying core.0007_archiveresult... OK\n    Applying core.0008_auto_20210105_1421... OK\n    Applying core.0009_auto_20210216_1038... OK\n    Applying core.0010_auto_20210216_1055... OK\n    Applying core.0011_auto_20210216_1331... OK\n    Applying core.0012_auto_20210216_1425... OK\n    Applying core.0013_auto_20210218_0729... OK\n    Applying core.0014_auto_20210218_0729... OK\n    Applying core.0015_auto_20210218_0730... OK\n    Applying core.0016_auto_20210218_1204... OK\n    Applying core.0017_auto_20210219_0211... OK\n    Applying core.0018_auto_20210327_0952... OK\n    Applying core.0019_auto_20210401_0654... OK\n    Applying core.0020_auto_20210410_1031... OK\n    Applying core.0021_auto_20220914_0934... OK\n    Applying core.0022_auto_20231023_2008... OK\n    Applying sessions.0001_initial... OK\n\n    \u221a ./index.sqlite3\n\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n\n[*] [2023-12-15 09:20:19] Writing 0 links to main index...\n    \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n\n[+] Creating new admin user for the Web UI...\nUsername (leave blank to use &amp;#39;archivebox&amp;#39;): admin\nEmail address: **********\nPassword: \nPassword (again): \nThe password is too similar to the username.\nThis password is too short. It must contain at least 8 characters.\nThis password is too common.\nBypass password validation and create user anyway? [y/N]: y\nSuperuser created successfully.\n\n[+] Installing enabled ArchiveBox dependencies automatically...\n\n    Installing YOUTUBEDL_BINARY automatically using pip...\n2023.10.13 is already installed yt-dlp\n\n    Installing CHROME_BINARY automatically using playwright...\nChromium 119.0.6045.9 is already installed chromium-browser\n\n    Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\nSINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n\n[\u221a] Set up ArchiveBox and its dependencies successfully.\n0.7.1+editable\nArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\nDEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n\n[i] Dependency versions:\n \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n\n \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n\n[i] Source-code locations:\n \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n\n[i] Secrets locations:\n -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n -  COOKIES_FILE          -               disabled  None                                                                        \n\n[i] Data locations:\n \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n\n\n    Hint: To view your archive index, run:\n        archivebox server  # then visit http://127.0.0.1:8000\n\n    To add new links, you can run:\n        archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n\n    For more usage and examples, run:\n        archivebox help\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixfjh", "is_robot_indexable": true, "report_reasons": null, "author": "DisasterousLamps", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "subreddit_subscribers": 300140, "created_utc": 1702637384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "When I searched for help on this I had a terrible time but I eventually figured it out. Here is what I used with hopes it will help someone in the future.\n\nCaddyfile:\n    \n    mydomain.duckdns.org {\n            @title {\n                    not file {\n                            try_files {path} {path}/\n                            split_path .php\n                    }\n                    path_regexp title ^/(.*)$\n            }\n            rewrite @title /index.php?title={re.title.1}&amp;{query}\n            root * /var/www/html/w #this might be /mediawiki for you\n            php_fastcgi unix//var/run/php/php7.4-fpm.sock #check your version\n            encode gzip #I honestly don't know if this is required\n            file_server\n\nLocalSettings.php:\n\n    ## The URL base path to the directory containing the wiki;\n    ## defaults for all runtime URL paths are based off of this.\n    ## For more information on customizing the URLs\n    ## (like /w/index.php/Page_title to /wiki/Page_title) please see:\n    ## https://www.mediawiki.org/wiki/Manual:Short_URL\n    $wgScriptPath = \"\"; // note I didn't use /w/ here because my redirect goes straight there\n    # &lt;snip&gt;\n    # short url\n    $wgArticlePath = \"/wiki/$1\";\n    $wgUsePathInfo = true;", "author_fullname": "t2_rgq94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MediaWiki and Caddy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "wikis", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jgreo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Wiki's", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702693364.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702692986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I searched for help on this I had a terrible time but I eventually figured it out. Here is what I used with hopes it will help someone in the future.&lt;/p&gt;\n\n&lt;p&gt;Caddyfile:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;mydomain.duckdns.org {\n        @title {\n                not file {\n                        try_files {path} {path}/\n                        split_path .php\n                }\n                path_regexp title ^/(.*)$\n        }\n        rewrite @title /index.php?title={re.title.1}&amp;amp;{query}\n        root * /var/www/html/w #this might be /mediawiki for you\n        php_fastcgi unix//var/run/php/php7.4-fpm.sock #check your version\n        encode gzip #I honestly don&amp;#39;t know if this is required\n        file_server\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;LocalSettings.php:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;## The URL base path to the directory containing the wiki;\n## defaults for all runtime URL paths are based off of this.\n## For more information on customizing the URLs\n## (like /w/index.php/Page_title to /wiki/Page_title) please see:\n## https://www.mediawiki.org/wiki/Manual:Short_URL\n$wgScriptPath = &amp;quot;&amp;quot;; // note I didn&amp;#39;t use /w/ here because my redirect goes straight there\n# &amp;lt;snip&amp;gt;\n# short url\n$wgArticlePath = &amp;quot;/wiki/$1&amp;quot;;\n$wgUsePathInfo = true;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "78dcb492-7e68-11e9-b4e7-0e296f55dc70", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jgreo", "is_robot_indexable": true, "report_reasons": null, "author": "tznkai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jgreo/mediawiki_and_caddy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jgreo/mediawiki_and_caddy/", "subreddit_subscribers": 300140, "created_utc": 1702692986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_140qn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zulip 8.0: Threaded open-source team chat", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18jgf1g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qN_9K08BA3qocUNzM1jOtBnKYRDxBhwtx0igCp8yNI0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1702691880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.zulip.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.zulip.com/2023/12/15/zulip-8-0-released/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?auto=webp&amp;s=ce604e70be104cc2b7c7585f5789e9fc3fae713d", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce27d6b542e018f5f86158709eb286dd0028bc5e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=867d53d34646badc8549f5edf080c058c5d16e4a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=700e628c8b084173f465e243bc0d4c35b56ab5d0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=187114b73340e9569492b7d07219b97edff16900", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4485e8eee8860e9f67e84449c5b996255daf7b6e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=75e1581e7b369d0368c1eb3ed3cb68cd62982daf", "width": 1080, "height": 565}], "variants": {}, "id": "didV0pbr0i0drK8zT1Y86j81F72zF3BTZoN5kDm_WIw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jgf1g", "is_robot_indexable": true, "report_reasons": null, "author": "Neustradamus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jgf1g/zulip_80_threaded_opensource_team_chat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.zulip.com/2023/12/15/zulip-8-0-released/", "subreddit_subscribers": 300140, "created_utc": 1702691880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am running a self hosted server using docker containers and NPM as a reverse proxy. I have some web servers that I want exposed to the internet and I want of course my Portainer, Dashboard, etc. only accessible from the internal network. \n\nMy setup right now includes Cloudflare as a DNS service where I have\n\n* An A and AAAA record pointing at my static home ip proxied through cloudflare\n* Multiple CNAME records on 3rd level domains for my web servers pointing at my domain name (e.g. [website1.mydomain.com](https://website1.mydomain.com)) proxied through cloudflare\n* Multiple A records pointing at the local ip of my server on my home network for different services (e.g. [dashboard.mydomain.com](https://dashboard.mydomain.com) points to 192.168.1.69)\n\nNPM functions as a reverse proxy, routing traffic to each service. I am forwarding ports 80 and 443 on my router.\n\nWith this setup I only have access to my services from inside my network where the domain points to a local IP. Outside my network the same local IP is not reachable. My question is: Is this safe? \n\nA possible solution I was thinking about would be to route traffic from my web servers to a different port, e.g. 8080 which would be forwarded to 80 on WAN through my router. Port 80 would be kept closed internally and used only for local services. But I do not know how to do this using NPM.", "author_fullname": "t2_2ksf1vz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exposing some services and keeping others private", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jgdx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702691771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running a self hosted server using docker containers and NPM as a reverse proxy. I have some web servers that I want exposed to the internet and I want of course my Portainer, Dashboard, etc. only accessible from the internal network. &lt;/p&gt;\n\n&lt;p&gt;My setup right now includes Cloudflare as a DNS service where I have&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An A and AAAA record pointing at my static home ip proxied through cloudflare&lt;/li&gt;\n&lt;li&gt;Multiple CNAME records on 3rd level domains for my web servers pointing at my domain name (e.g. &lt;a href=\"https://website1.mydomain.com\"&gt;website1.mydomain.com&lt;/a&gt;) proxied through cloudflare&lt;/li&gt;\n&lt;li&gt;Multiple A records pointing at the local ip of my server on my home network for different services (e.g. &lt;a href=\"https://dashboard.mydomain.com\"&gt;dashboard.mydomain.com&lt;/a&gt; points to 192.168.1.69)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;NPM functions as a reverse proxy, routing traffic to each service. I am forwarding ports 80 and 443 on my router.&lt;/p&gt;\n\n&lt;p&gt;With this setup I only have access to my services from inside my network where the domain points to a local IP. Outside my network the same local IP is not reachable. My question is: Is this safe? &lt;/p&gt;\n\n&lt;p&gt;A possible solution I was thinking about would be to route traffic from my web servers to a different port, e.g. 8080 which would be forwarded to 80 on WAN through my router. Port 80 would be kept closed internally and used only for local services. But I do not know how to do this using NPM.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jgdx8", "is_robot_indexable": true, "report_reasons": null, "author": "frank20a", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jgdx8/exposing_some_services_and_keeping_others_private/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jgdx8/exposing_some_services_and_keeping_others_private/", "subreddit_subscribers": 300140, "created_utc": 1702691771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello Selfhosters,\n\nI have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm's running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I've tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn't work for me. I also like the idea of isolation/serperating certain tasks. So i've tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. \n\nAny advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!", "author_fullname": "t2_7g226", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pihole + VPN on proxmox", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ivsgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702630263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Selfhosters,&lt;/p&gt;\n\n&lt;p&gt;I have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm&amp;#39;s running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I&amp;#39;ve tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn&amp;#39;t work for me. I also like the idea of isolation/serperating certain tasks. So i&amp;#39;ve tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. &lt;/p&gt;\n\n&lt;p&gt;Any advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ivsgl", "is_robot_indexable": true, "report_reasons": null, "author": "vivachris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "subreddit_subscribers": 300140, "created_utc": 1702630263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello,  \nMy question is simple: Where do you guys store your data? Volumes? Bind Mounts?\n\nIn my case, I store my data in bind mounts, all to a folder called \"dockerDATA,\" but I can't help but notice that a folder called \"data\" exists at the root of my filesystem as well (ubuntu 22.04). Sometimes, when I create containers, I also notice that their default volume creation location is \".data/\". Where is this, though? There is no hidden data folder in my root directory. Just a regular data folder, which I believe is managed by Portainer. Is this the other data folder? I mean, I have Portainer in use as well, so I think that may affect this.\n\nBeyond this, though, what do you think is better? Bind mounts or Docker-managed volumes, which I still don't actually understand how to create even after reading the documentation on volumes, How can I migrate my data to volumes? I know NextCloudAIO uses Docker volumes; do I just not put a \"/\" in front of the volume path to make it available in \"/var/lib/docker/volumes...\"?\n\nAlso, a last consideration is that I use Kopia for backups. I run it in Docker, and I have it bind mount to my repository location. Would backing up everything in the Docker volumes path be better than what I currently do, which is backup \"/dockerDATA\" and the \"/var/lib...volumes\" path?\n\nHelp is appreciated, and I would like to learn how to best do this.", "author_fullname": "t2_q1rfumi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker | How do you store your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jcxg8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702681502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nMy question is simple: Where do you guys store your data? Volumes? Bind Mounts?&lt;/p&gt;\n\n&lt;p&gt;In my case, I store my data in bind mounts, all to a folder called &amp;quot;dockerDATA,&amp;quot; but I can&amp;#39;t help but notice that a folder called &amp;quot;data&amp;quot; exists at the root of my filesystem as well (ubuntu 22.04). Sometimes, when I create containers, I also notice that their default volume creation location is &amp;quot;.data/&amp;quot;. Where is this, though? There is no hidden data folder in my root directory. Just a regular data folder, which I believe is managed by Portainer. Is this the other data folder? I mean, I have Portainer in use as well, so I think that may affect this.&lt;/p&gt;\n\n&lt;p&gt;Beyond this, though, what do you think is better? Bind mounts or Docker-managed volumes, which I still don&amp;#39;t actually understand how to create even after reading the documentation on volumes, How can I migrate my data to volumes? I know NextCloudAIO uses Docker volumes; do I just not put a &amp;quot;/&amp;quot; in front of the volume path to make it available in &amp;quot;/var/lib/docker/volumes...&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Also, a last consideration is that I use Kopia for backups. I run it in Docker, and I have it bind mount to my repository location. Would backing up everything in the Docker volumes path be better than what I currently do, which is backup &amp;quot;/dockerDATA&amp;quot; and the &amp;quot;/var/lib...volumes&amp;quot; path?&lt;/p&gt;\n\n&lt;p&gt;Help is appreciated, and I would like to learn how to best do this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jcxg8", "is_robot_indexable": true, "report_reasons": null, "author": "Ejz9", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jcxg8/docker_how_do_you_store_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jcxg8/docker_how_do_you_store_your_data/", "subreddit_subscribers": 300140, "created_utc": 1702681502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi everyone i am trying to run my own mail server but this hiccup i cant find any fix for.i tried connecting to port 25 using telnet on my machine where i run the server and it works fine with localhost and [mail.domain.com](https://mail.domain.com) but when  try this from my personal computer i get a connection timeout. Cant find any postfix error logs or some other error logs. The port does react to pings.\n\nthings i tried:disabling firewall,disabling helo configuration\n\nfurther i dont know what maybe can fix it:\n\npostfix configuration:\n\n    alias_database = hash:/etc/aliases\n    alias_maps = hash:/etc/aliases\n    append_dot_mydomain = no\n    biff = no\n    broken_sasl_auth_clients = yes\n    compatibility_level = 2\n    home_mailbox = Maildir/\n    inet_interfaces = all\n    inet_protocols = all\n    mailbox_command =\n    mailbox_size_limit = 0\n    mydestination = $myhostname, mail.domain.com, domain.com, smtp.domain.coml, debian, localhost.localdomain, localhost\n    mydomain = domain.com\n    myhostname = mail.domain.com\n    mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128\n    myorigin = /etc/mailname\n    readme_directory = no\n    recipient_delimiter = +\n    relayhost =\n    smtp_tls_CApath = /etc/ssl/certs\n    smtp_tls_note_starttls_offer = yes\n    smtp_tls_security_level = may\n    smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\n    smtp_use_tls = yes\n    smtpd_banner = $myhostname ESMTP $mail_name (Debian/GNU)\n    smtpd_helo_required = yes\n    smtpd_helo_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_helo_hostname, check_helo_access hash:/etc/postfix/helo_access\n    smtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\n    smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\n    smtpd_sasl_auth_enable = yes\n    smtpd_sasl_local_domain =\n    smtpd_sasl_path = private/auth\n    smtpd_sasl_security_options = noanonymous\n    smtpd_sasl_type = dovecot\n    smtpd_tls_cert_file = /etc/letsencrypt/live/mail.domain.com/fullchain.pem\n    smtpd_tls_key_file = /etc/letsencrypt/live/mail.domain.com/privkey.pem\n    smtpd_tls_loglevel = 1\n    smtpd_tls_received_header = yes\n    smtpd_tls_security_level = may\n    smtpd_use_tls = yes\n\n&amp;#x200B;", "author_fullname": "t2_7vhbqmi4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "smtp not accepting connections on port 25", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jc2qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702679196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone i am trying to run my own mail server but this hiccup i cant find any fix for.i tried connecting to port 25 using telnet on my machine where i run the server and it works fine with localhost and &lt;a href=\"https://mail.domain.com\"&gt;mail.domain.com&lt;/a&gt; but when  try this from my personal computer i get a connection timeout. Cant find any postfix error logs or some other error logs. The port does react to pings.&lt;/p&gt;\n\n&lt;p&gt;things i tried:disabling firewall,disabling helo configuration&lt;/p&gt;\n\n&lt;p&gt;further i dont know what maybe can fix it:&lt;/p&gt;\n\n&lt;p&gt;postfix configuration:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;alias_database = hash:/etc/aliases\nalias_maps = hash:/etc/aliases\nappend_dot_mydomain = no\nbiff = no\nbroken_sasl_auth_clients = yes\ncompatibility_level = 2\nhome_mailbox = Maildir/\ninet_interfaces = all\ninet_protocols = all\nmailbox_command =\nmailbox_size_limit = 0\nmydestination = $myhostname, mail.domain.com, domain.com, smtp.domain.coml, debian, localhost.localdomain, localhost\nmydomain = domain.com\nmyhostname = mail.domain.com\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128\nmyorigin = /etc/mailname\nreadme_directory = no\nrecipient_delimiter = +\nrelayhost =\nsmtp_tls_CApath = /etc/ssl/certs\nsmtp_tls_note_starttls_offer = yes\nsmtp_tls_security_level = may\nsmtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\nsmtp_use_tls = yes\nsmtpd_banner = $myhostname ESMTP $mail_name (Debian/GNU)\nsmtpd_helo_required = yes\nsmtpd_helo_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_helo_hostname, check_helo_access hash:/etc/postfix/helo_access\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\nsmtpd_sasl_auth_enable = yes\nsmtpd_sasl_local_domain =\nsmtpd_sasl_path = private/auth\nsmtpd_sasl_security_options = noanonymous\nsmtpd_sasl_type = dovecot\nsmtpd_tls_cert_file = /etc/letsencrypt/live/mail.domain.com/fullchain.pem\nsmtpd_tls_key_file = /etc/letsencrypt/live/mail.domain.com/privkey.pem\nsmtpd_tls_loglevel = 1\nsmtpd_tls_received_header = yes\nsmtpd_tls_security_level = may\nsmtpd_use_tls = yes\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jc2qo", "is_robot_indexable": true, "report_reasons": null, "author": "kajvans", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jc2qo/smtp_not_accepting_connections_on_port_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jc2qo/smtp_not_accepting_connections_on_port_25/", "subreddit_subscribers": 300140, "created_utc": 1702679196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm pretty new to self hosting things, and really just Jellyfin so far. I want to use Tailscale to allow my brother access to my Jellyfin server, but I have some questions about that and the security behind it. I was able to get a subnet set up and active with what is maybe too large of an IP range. I'll be honest I don't understand that part of it very well. I would really only like to expose my particular Jellyfin address to Tailscale, 192.168.*.*: Port, so how do I go about doing that in Windows? Is it possible? I'm just using Windows right now because I'm lazy, and I'm planning a new build that will use Linux/Unraid/whatever later. Also, just so I understand, opening up the subnet this way still only gives Tailscale access to my network, correct? Only approved devices will be able to access my network? I just want to make sure I didn't make any mistakes.", "author_fullname": "t2_t6qqg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tailscale questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j7hwx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702666862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m pretty new to self hosting things, and really just Jellyfin so far. I want to use Tailscale to allow my brother access to my Jellyfin server, but I have some questions about that and the security behind it. I was able to get a subnet set up and active with what is maybe too large of an IP range. I&amp;#39;ll be honest I don&amp;#39;t understand that part of it very well. I would really only like to expose my particular Jellyfin address to Tailscale, 192.168.&lt;em&gt;.&lt;/em&gt;: Port, so how do I go about doing that in Windows? Is it possible? I&amp;#39;m just using Windows right now because I&amp;#39;m lazy, and I&amp;#39;m planning a new build that will use Linux/Unraid/whatever later. Also, just so I understand, opening up the subnet this way still only gives Tailscale access to my network, correct? Only approved devices will be able to access my network? I just want to make sure I didn&amp;#39;t make any mistakes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j7hwx", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyRingo84", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j7hwx/tailscale_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j7hwx/tailscale_questions/", "subreddit_subscribers": 300140, "created_utc": 1702666862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have started to look into logging and performance monitoring, and have been between the Grafana stack (the online one as well as a local one), zabbix and checkmk. Right now I am leaning towards Grafana, but the documentation is very lacking on a proper expenation.\n\nI am running the grafana-agent in flow mode (as suggested in their docs over promtail), and that is alright.\n\nBut my main issue is that way too much data is sent and it is just unuseable. Also I am a bit unsure how to seperate the logs and data if for example I run the agent on two computers. Say I run it on a server, it got its syslogs, for example /var/log/syslog, and then I run it on a raspberry pi (that is handling UPS and such), that also got a /var/log/syslog. \n\nWhen logging into the explore mode on grafana, its just a filename label with the filename, but I have no idea which one belongs to what computer. Is it any best practise flows for this?\n\nAlso any suggestion to filter the logs so it reduce the amount of data sent? I filled up the 10K limit in days.\n\nHere is the example of the config this far:\n\n&amp;#x200B;\n\n    logging {\n      level  = \"error\"\n      format = \"logfmt\"\n    }\n    \n    local.file_match \"unraid\" {\n      path_targets = [{\n        __address__ = \"localhost\",\n        __path__    = \"/var/log/**\",\n        __path_exclude__    = \"/var/log/file.activity.log\",\n      }]\n    }\n    \n    loki.source.file \"files\" {\n    \ttargets    = local.file_match.unraid.targets\n    \tforward_to = [loki.write.default.receiver]\n    }\n    \n    \n    discovery.docker \"flog_scrape\" {\n    \thost             = \"unix:///var/run/docker.sock\"\n    \trefresh_interval = \"5s\"\n    \n    \tfilter {\n    \t\tname   = \"label\"\n    \t\tvalues = [\"logging=promtail\"]\n    \t}\n    }\n    \n    discovery.relabel \"flog_scrape\" {\n    \ttargets = discovery.docker.flog_scrape.targets\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_name\"]\n    \t\tregex         = \"/(.*)\"\n    \t\ttarget_label  = \"container\"\n    \t}\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_log_stream\"]\n    \t\ttarget_label  = \"logstream\"\n    \t}\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_label_logging_jobname\"]\n    \t\ttarget_label  = \"job\"\n    \t}\n    }\n    \n    \n    local.file_match \"flog_scrape\" {\n    \tpath_targets = discovery.relabel.flog_scrape.output\n    }\n    \n    loki.source.file \"flog_scrape\" {\n    \ttargets    = local.file_match.flog_scrape.targets\n    \tforward_to = [loki.write.default.receiver]\n    }\n    \n    loki.write \"default\" {\n        endpoint {\n            url = \"https://logs-prod-025.grafana.net/loki/api/v1/push\"\n            basic_auth {\n                username = user\n                password = \"password\"\n            }\n        }\n    }\n    \n\n&amp;#x200B;", "author_fullname": "t2_kvhks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with some best practises in logging and metrics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j6y1z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702665447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started to look into logging and performance monitoring, and have been between the Grafana stack (the online one as well as a local one), zabbix and checkmk. Right now I am leaning towards Grafana, but the documentation is very lacking on a proper expenation.&lt;/p&gt;\n\n&lt;p&gt;I am running the grafana-agent in flow mode (as suggested in their docs over promtail), and that is alright.&lt;/p&gt;\n\n&lt;p&gt;But my main issue is that way too much data is sent and it is just unuseable. Also I am a bit unsure how to seperate the logs and data if for example I run the agent on two computers. Say I run it on a server, it got its syslogs, for example /var/log/syslog, and then I run it on a raspberry pi (that is handling UPS and such), that also got a /var/log/syslog. &lt;/p&gt;\n\n&lt;p&gt;When logging into the explore mode on grafana, its just a filename label with the filename, but I have no idea which one belongs to what computer. Is it any best practise flows for this?&lt;/p&gt;\n\n&lt;p&gt;Also any suggestion to filter the logs so it reduce the amount of data sent? I filled up the 10K limit in days.&lt;/p&gt;\n\n&lt;p&gt;Here is the example of the config this far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;logging {\n  level  = &amp;quot;error&amp;quot;\n  format = &amp;quot;logfmt&amp;quot;\n}\n\nlocal.file_match &amp;quot;unraid&amp;quot; {\n  path_targets = [{\n    __address__ = &amp;quot;localhost&amp;quot;,\n    __path__    = &amp;quot;/var/log/**&amp;quot;,\n    __path_exclude__    = &amp;quot;/var/log/file.activity.log&amp;quot;,\n  }]\n}\n\nloki.source.file &amp;quot;files&amp;quot; {\n    targets    = local.file_match.unraid.targets\n    forward_to = [loki.write.default.receiver]\n}\n\n\ndiscovery.docker &amp;quot;flog_scrape&amp;quot; {\n    host             = &amp;quot;unix:///var/run/docker.sock&amp;quot;\n    refresh_interval = &amp;quot;5s&amp;quot;\n\n    filter {\n        name   = &amp;quot;label&amp;quot;\n        values = [&amp;quot;logging=promtail&amp;quot;]\n    }\n}\n\ndiscovery.relabel &amp;quot;flog_scrape&amp;quot; {\n    targets = discovery.docker.flog_scrape.targets\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_name&amp;quot;]\n        regex         = &amp;quot;/(.*)&amp;quot;\n        target_label  = &amp;quot;container&amp;quot;\n    }\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_log_stream&amp;quot;]\n        target_label  = &amp;quot;logstream&amp;quot;\n    }\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_label_logging_jobname&amp;quot;]\n        target_label  = &amp;quot;job&amp;quot;\n    }\n}\n\n\nlocal.file_match &amp;quot;flog_scrape&amp;quot; {\n    path_targets = discovery.relabel.flog_scrape.output\n}\n\nloki.source.file &amp;quot;flog_scrape&amp;quot; {\n    targets    = local.file_match.flog_scrape.targets\n    forward_to = [loki.write.default.receiver]\n}\n\nloki.write &amp;quot;default&amp;quot; {\n    endpoint {\n        url = &amp;quot;https://logs-prod-025.grafana.net/loki/api/v1/push&amp;quot;\n        basic_auth {\n            username = user\n            password = &amp;quot;password&amp;quot;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j6y1z", "is_robot_indexable": true, "report_reasons": null, "author": "alekslyse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j6y1z/help_with_some_best_practises_in_logging_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j6y1z/help_with_some_best_practises_in_logging_and/", "subreddit_subscribers": 300140, "created_utc": 1702665447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My local network contains a brand new media server in a Proxmox container and I don't want to go to it using [http://ip.address:9000/material](http://ip.address:9000/material) anymore. What would it take for me to set up a local DNS resolver that turns [http://music](http://music) into the above lookup?\n\nI had a pi-hole setup for a brief while as the DNS server of choice. That has this feature. Unfortunately, it wasn't blocking too many ads and it was causing a lot of other problems (I forget) so I shut it off. I still have the container for it. I can probably give it another try if all else fails. Or I can try adguard.\n\nI was hoping my tp-link archer router will have a way for doing this but it doesn't.\n\nFWIW I also have nginx running for a reverse proxy in the same Ubuntu LXC where the media server is installed. But it is for the incoming traffic and it helps me expose a couple of services on my personal domain. This is for internal only.\n\nThanks in advance.", "author_fullname": "t2_11an59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local DNS names", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dnstools", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j6sbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "DNS Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702665036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My local network contains a brand new media server in a Proxmox container and I don&amp;#39;t want to go to it using &lt;a href=\"http://ip.address:9000/material\"&gt;http://ip.address:9000/material&lt;/a&gt; anymore. What would it take for me to set up a local DNS resolver that turns &lt;a href=\"http://music\"&gt;http://music&lt;/a&gt; into the above lookup?&lt;/p&gt;\n\n&lt;p&gt;I had a pi-hole setup for a brief while as the DNS server of choice. That has this feature. Unfortunately, it wasn&amp;#39;t blocking too many ads and it was causing a lot of other problems (I forget) so I shut it off. I still have the container for it. I can probably give it another try if all else fails. Or I can try adguard.&lt;/p&gt;\n\n&lt;p&gt;I was hoping my tp-link archer router will have a way for doing this but it doesn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;FWIW I also have nginx running for a reverse proxy in the same Ubuntu LXC where the media server is installed. But it is for the incoming traffic and it helps me expose a couple of services on my personal domain. This is for internal only.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f0c1d430-7e6b-11e9-9779-0e688895811a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j6sbc", "is_robot_indexable": true, "report_reasons": null, "author": "yelloguy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j6sbc/local_dns_names/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j6sbc/local_dns_names/", "subreddit_subscribers": 300140, "created_utc": 1702665036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey guys,\n\nSo im a bit of a noob here but me and my brother got proxmox installed on one of my old windows systems along with an alpine linux vm for docker. I have 3 drives in that system and i am using 1 for installs and another for storage for my jellyfin server. I have a 3rd 2tb drive that has game installs and a few other random items that i want to either take off or use that drive on my windows machine for storage. I heard about smb but i am unsure how all that works.\n\nIf anyone could point me in the right direction to a video of sorts or a writeup that would be great! Im also trying to gain knowlege on this since my brother wont be around long (school) to help me all the time", "author_fullname": "t2_q35kv8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proxmox network drive to windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j5j9d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702661806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;So im a bit of a noob here but me and my brother got proxmox installed on one of my old windows systems along with an alpine linux vm for docker. I have 3 drives in that system and i am using 1 for installs and another for storage for my jellyfin server. I have a 3rd 2tb drive that has game installs and a few other random items that i want to either take off or use that drive on my windows machine for storage. I heard about smb but i am unsure how all that works.&lt;/p&gt;\n\n&lt;p&gt;If anyone could point me in the right direction to a video of sorts or a writeup that would be great! Im also trying to gain knowlege on this since my brother wont be around long (school) to help me all the time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j5j9d", "is_robot_indexable": true, "report_reasons": null, "author": "turbocharged5652", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j5j9d/proxmox_network_drive_to_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j5j9d/proxmox_network_drive_to_windows/", "subreddit_subscribers": 300140, "created_utc": 1702661806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "If I configure my onlyoffice with my public address and stop there it works fine. However if I go and configure the addresses that the onlyoffice and nextcloud servers should use to talk to each other I get this error:\n\n    Error: DNS lookup 172.19.0.5(family:4, host:app) is not allowed. Because, It is private IP address.\n\nOnlyoffice and nextcloud are running in the same docker stack and I would prefer onlyoffice be able to fetch documents directly from nextcloud instead of doing some sort of roundabout trip all the way to the WAN and back. Why is it that it's not allowed to connect through a private IP address? Does anyone know either a way to disable this restriction or else permit a specific address?", "author_fullname": "t2_8jddbaxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onlyoffice on nextcloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j2qvr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702654402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I configure my onlyoffice with my public address and stop there it works fine. However if I go and configure the addresses that the onlyoffice and nextcloud servers should use to talk to each other I get this error:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Error: DNS lookup 172.19.0.5(family:4, host:app) is not allowed. Because, It is private IP address.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Onlyoffice and nextcloud are running in the same docker stack and I would prefer onlyoffice be able to fetch documents directly from nextcloud instead of doing some sort of roundabout trip all the way to the WAN and back. Why is it that it&amp;#39;s not allowed to connect through a private IP address? Does anyone know either a way to disable this restriction or else permit a specific address?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j2qvr", "is_robot_indexable": true, "report_reasons": null, "author": "xervir-445", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j2qvr/onlyoffice_on_nextcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j2qvr/onlyoffice_on_nextcloud/", "subreddit_subscribers": 300140, "created_utc": 1702654402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi!\n\nI purchased a Unifi Express to replace my aging setup. I finally got it installed, and I have a few devices that can't seem to access my reverse proxy that's hosted on he same network, while some can. All devices are on the same default network, except for the last example.\n\nExample 1: Computer is hardwired. When loading my reverse proxy websites, I get connection has timed out. When I disable eth and connect via WiFi, it works. Same network.\n\nExample 2: Wife's phone can't access locally hosted streaming app. Connected to the same default network as the server. When I swap her to the Guest network, she's able to connect just fine.\n\nI searched the past couple of nights through google, and I can't seem to find whats causing my issue. What am I doing wrong here?\n\nI should note that I do have Pi-hole running and I don't believe that is causing the issue. I tested my network to run whatever is default with Unifi.", "author_fullname": "t2_76y4yxsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgraded my network setup. Now having issues with certain devices accessing a reverse proxy hosted on the same network.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j2qcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702654362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I purchased a Unifi Express to replace my aging setup. I finally got it installed, and I have a few devices that can&amp;#39;t seem to access my reverse proxy that&amp;#39;s hosted on he same network, while some can. All devices are on the same default network, except for the last example.&lt;/p&gt;\n\n&lt;p&gt;Example 1: Computer is hardwired. When loading my reverse proxy websites, I get connection has timed out. When I disable eth and connect via WiFi, it works. Same network.&lt;/p&gt;\n\n&lt;p&gt;Example 2: Wife&amp;#39;s phone can&amp;#39;t access locally hosted streaming app. Connected to the same default network as the server. When I swap her to the Guest network, she&amp;#39;s able to connect just fine.&lt;/p&gt;\n\n&lt;p&gt;I searched the past couple of nights through google, and I can&amp;#39;t seem to find whats causing my issue. What am I doing wrong here?&lt;/p&gt;\n\n&lt;p&gt;I should note that I do have Pi-hole running and I don&amp;#39;t believe that is causing the issue. I tested my network to run whatever is default with Unifi.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j2qcr", "is_robot_indexable": true, "report_reasons": null, "author": "NoFeedback4007", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j2qcr/upgraded_my_network_setup_now_having_issues_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j2qcr/upgraded_my_network_setup_now_having_issues_with/", "subreddit_subscribers": 300140, "created_utc": 1702654362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\ni've got a general question about SSO and IDP/IAM, especially for the use with Seafile.\n\nI installed Authentik a while ago and got it running with my (puclicly reachable) NPM instance. I have some services that are protected by forward auth (e.g. Mealie) and some that have SSO with OAuth bzw. OID (e.g.) Seafile. This far everything works great.\n\nI'm happy with the forward auth part, since every viewer for the site is now forced to login to authentik (with his account, 2FA, it's quite secure I guess).\n\nI'm not sure about the SSO part though. Right now if users visit my seafile instance, they have the option to login by SSO, or use their (seafile) login credentials. At no point they're forced to actually authenticate against Authentik. With some system against brute force attacks (like fail2ban or crowdsec) this seems fine, but I'd like to knwo, if there's some concept I'm missing that allows me to check for a valid Authentik session, including my services that offer SSO. In other words, is IDP (OAuth) and IAM (forward auth) exclusive, or can I have both?\n\nI tried adding the forward auth part to NPM for Seafile, so I would first have to authenticate, and then I can login with SSO (or username/password), but that doesn't work for some reason. That way seems quite hacky to me anyways.\n\nIs there something I'm missing or missunderstanding?", "author_fullname": "t2_i9nrc4obl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to always force authentication with Authentik (for Seafile)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iwpqp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702634432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;ve got a general question about SSO and IDP/IAM, especially for the use with Seafile.&lt;/p&gt;\n\n&lt;p&gt;I installed Authentik a while ago and got it running with my (puclicly reachable) NPM instance. I have some services that are protected by forward auth (e.g. Mealie) and some that have SSO with OAuth bzw. OID (e.g.) Seafile. This far everything works great.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m happy with the forward auth part, since every viewer for the site is now forced to login to authentik (with his account, 2FA, it&amp;#39;s quite secure I guess).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure about the SSO part though. Right now if users visit my seafile instance, they have the option to login by SSO, or use their (seafile) login credentials. At no point they&amp;#39;re forced to actually authenticate against Authentik. With some system against brute force attacks (like fail2ban or crowdsec) this seems fine, but I&amp;#39;d like to knwo, if there&amp;#39;s some concept I&amp;#39;m missing that allows me to check for a valid Authentik session, including my services that offer SSO. In other words, is IDP (OAuth) and IAM (forward auth) exclusive, or can I have both?&lt;/p&gt;\n\n&lt;p&gt;I tried adding the forward auth part to NPM for Seafile, so I would first have to authenticate, and then I can login with SSO (or username/password), but that doesn&amp;#39;t work for some reason. That way seems quite hacky to me anyways.&lt;/p&gt;\n\n&lt;p&gt;Is there something I&amp;#39;m missing or missunderstanding?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iwpqp", "is_robot_indexable": true, "report_reasons": null, "author": "xBeo_x", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iwpqp/how_to_always_force_authentication_with_authentik/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iwpqp/how_to_always_force_authentication_with_authentik/", "subreddit_subscribers": 300140, "created_utc": 1702634432.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}