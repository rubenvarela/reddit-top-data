{"kind": "Listing", "data": {"after": "t3_18j6sbc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "As 2023 comes to an end I want to understand how you went about self hosting this year. While this is an open ended question, I came up with 5 categories. Obviously there will be some overlap but you can of course mention as many apps and services as you like how you like.\n\nMost used\n\nMost critical \n\nMost recommended \n\nMost fun\n\nMost looking forward to", "author_fullname": "t2_5o6owomn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What we're you hosting in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqlve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 235, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 235, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702610994.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702610702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As 2023 comes to an end I want to understand how you went about self hosting this year. While this is an open ended question, I came up with 5 categories. Obviously there will be some overlap but you can of course mention as many apps and services as you like how you like.&lt;/p&gt;\n\n&lt;p&gt;Most used&lt;/p&gt;\n\n&lt;p&gt;Most critical &lt;/p&gt;\n\n&lt;p&gt;Most recommended &lt;/p&gt;\n\n&lt;p&gt;Most fun&lt;/p&gt;\n\n&lt;p&gt;Most looking forward to&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iqlve", "is_robot_indexable": true, "report_reasons": null, "author": "Alt_Lightning", "discussion_type": null, "num_comments": 161, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iqlve/what_were_you_hosting_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iqlve/what_were_you_hosting_in_2023/", "subreddit_subscribers": 300092, "created_utc": 1702610702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_93gqtkw25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Immich v1.91.0 is out, note the breaking changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "phototools", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_18j3sbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 125, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Photo Tools", "can_mod_post": false, "score": 125, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/chp8qYPiE1jVWUnjVobF0KMLl_L3l7VZS9JVILOh-F8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702657177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/immich-app/immich/releases/tag/v1.91.0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?auto=webp&amp;s=19e920b681104bf65d81f258967c805c11fc6ee5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73915eb7d3750dcc8b0884ccc0d2bacf7c51a7c5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe8ea0af0958a7739073e28bd9f2853d750f5c14", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36cdb321eeb238dbecc3df9a8415de6694dd15a7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec5b06214a822f69e5704f66d16cf9c6fca4186", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=317e9e6c1690940f903303bd90c8bdc1da88b27e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9EjcnSTbZLIfb43jhWdj-VxdhpgfCSqhdreGwzDXxFk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96105b20b09213d35c2347616a08138fd3228457", "width": 1080, "height": 540}], "variants": {}, "id": "7HLMCeoqPom_GRceRbz3kNxxbobDFNdWRAAnOC0zL5w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4474b0e2-7e68-11e9-96f8-0e01fac4c7aa", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j3sbt", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable-Jump-8332", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j3sbt/immich_v1910_is_out_note_the_breaking_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/immich-app/immich/releases/tag/v1.91.0", "subreddit_subscribers": 300092, "created_utc": 1702657177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I want to use wireguard only to \"phone home\" i.e. to be in \"LAN with what I selfhost\".\n\nDoes anyone do this? Any best practices?\n\nWhat bothers me is that default usage for VPN is to mask browsing and this does not interest me. Especially due to my home internet upload speed bottleneck.\n\nSo I would like to be able to start the VPN connection only when I want to access directly my services.\n\nOn Android Wireguard starts automatically and did not found a way to steer conviniently...\n\nOn my Linux machines I can stop it, but there I need to research a bit more how I can do it in the most comfortable way.\n\nAny thoughts / best practices by you?", "author_fullname": "t2_2zrf96nd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wireguard used only \"to phone home\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "vpn", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j12dk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "VPN", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702649757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use wireguard only to &amp;quot;phone home&amp;quot; i.e. to be in &amp;quot;LAN with what I selfhost&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Does anyone do this? Any best practices?&lt;/p&gt;\n\n&lt;p&gt;What bothers me is that default usage for VPN is to mask browsing and this does not interest me. Especially due to my home internet upload speed bottleneck.&lt;/p&gt;\n\n&lt;p&gt;So I would like to be able to start the VPN connection only when I want to access directly my services.&lt;/p&gt;\n\n&lt;p&gt;On Android Wireguard starts automatically and did not found a way to steer conviniently...&lt;/p&gt;\n\n&lt;p&gt;On my Linux machines I can stop it, but there I need to research a bit more how I can do it in the most comfortable way.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts / best practices by you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7e5c2d58-7e68-11e9-9418-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j12dk", "is_robot_indexable": true, "report_reasons": null, "author": "beje_ro", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j12dk/wireguard_used_only_to_phone_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j12dk/wireguard_used_only_to_phone_home/", "subreddit_subscribers": 300092, "created_utc": 1702649757.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello esteemed members of r/selfhosted,\n\n&amp;#x200B;\n\nI'm reaching out to tap into the collective wisdom of this knowledgeable community. I'm in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.\n\nThis tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I'm looking to gather evidence in a sophisticated, yet lighthearted, \"I-told-you-so\" package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca\n\nI would greatly appreciate your recommendations for a free software that combines functionality with ease of use.\n\nIf possible, I have a particular fondness for Docker solutions.\n\n&amp;#x200B;\n\nThank you all :)", "author_fullname": "t2_a0vsc0f4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet speed monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "personaldashboard", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixbks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Dashboard", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702636917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello esteemed members of &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to tap into the collective wisdom of this knowledgeable community. I&amp;#39;m in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.&lt;/p&gt;\n\n&lt;p&gt;This tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I&amp;#39;m looking to gather evidence in a sophisticated, yet lighthearted, &amp;quot;I-told-you-so&amp;quot; package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your recommendations for a free software that combines functionality with ease of use.&lt;/p&gt;\n\n&lt;p&gt;If possible, I have a particular fondness for Docker solutions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "587d404a-7e68-11e9-bd12-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixbks", "is_robot_indexable": true, "report_reasons": null, "author": "TPK-trade", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "subreddit_subscribers": 300092, "created_utc": 1702636917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Happy Friday, r/selfhosted! Below is a link to *This Week in Self-Hosted*, a weekly newsletter recap of the latest activity in self-hosted software.\n\nThis week's features include:\n\n* The latest news in self-hosted software\n* Noteworthy software updates, launches, and events\n* Featured content generated by the self-hosted community\n* A spotlight on [Dockge](https://github.com/louislam/dockge?ref=selfh.st), a web-based docker compose stack manager\n\nAs usual, feel free to reach out with questions or comments about the newsletter. Thanks!\n\n---\n\n[This Week in Self-Hosted (15 December 2023)](https://selfh.st/newsletter/2023-12-15/)", "author_fullname": "t2_vvcklg6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This Week in Self-Hosted (15 December 2023)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iz5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702643917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy Friday, &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;! Below is a link to &lt;em&gt;This Week in Self-Hosted&lt;/em&gt;, a weekly newsletter recap of the latest activity in self-hosted software.&lt;/p&gt;\n\n&lt;p&gt;This week&amp;#39;s features include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The latest news in self-hosted software&lt;/li&gt;\n&lt;li&gt;Noteworthy software updates, launches, and events&lt;/li&gt;\n&lt;li&gt;Featured content generated by the self-hosted community&lt;/li&gt;\n&lt;li&gt;A spotlight on &lt;a href=\"https://github.com/louislam/dockge?ref=selfh.st\"&gt;Dockge&lt;/a&gt;, a web-based docker compose stack manager&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As usual, feel free to reach out with questions or comments about the newsletter. Thanks!&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;a href=\"https://selfh.st/newsletter/2023-12-15/\"&gt;This Week in Self-Hosted (15 December 2023)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?auto=webp&amp;s=edfc1e87b204020d848795a64b8ddd109f886270", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c09d9bcd169fce6fdd6ec7fe2b47833eb6296217", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a96911c301ea2dc8736504b014f3a27df1e244e7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a033b33b71d55259659ff2a51b42fcacac339838", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d2f988460654901b3d6b889110ca2a147372098", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ba692125aee2344994701d6c49e2c97855e8965", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e4378b1466adcd48a4bf01cd798b53307a12061e", "width": 1080, "height": 540}], "variants": {}, "id": "Gf1_-kT8szx_yWNO2zBdA-iQjknAjjAqkcYTWsAw_zE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iz5mc", "is_robot_indexable": true, "report_reasons": null, "author": "selfh-sted", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "subreddit_subscribers": 300092, "created_utc": 1702643917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": " \n\nHey\n\nI'm diving into the exciting world of honeypots and cybersecurity at home, and I'd love some guidance on creating a live attack map using Grafana. Specifically, I'm using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here's where I could use some help.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\n\nI've been inspired by those awesome live attack maps from TPOTCE, and I'm eager to replicate something similar for my own setup. As a newbie in homelabs, I'm wondering if anyone has experience or advice on achieving this. I'd appreciate insights on how to Configure Grafana to visualize the attacks in real-time.\n\nIf you've tackled a similar project or have tips for a homelab newbie, I'd love to hear about your experiences and any resources you found helpful.", "author_fullname": "t2_7dixsldo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Live Attack Map with Grafana, Cowrie, and Prometheus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 126, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3yu1gngy6g6c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 97, "x": 108, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8eec587d6c24a02fac84f9548944912c281d97d2"}, {"y": 195, "x": 216, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccf1ecd4a718dc91fafbbdecce962f5882ab478d"}, {"y": 289, "x": 320, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=571b35d86b53068d98c3621eecc169a2cccb5a95"}, {"y": 578, "x": 640, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=141473d0b9e21d6cecbc41b47cccbdfa25327e37"}, {"y": 867, "x": 960, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=39c78b816374d4d7939511a4ff110b2abc1b43db"}, {"y": 975, "x": 1080, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe1964b3a71a6a02f3864b791570b95d6a0f0a2e"}], "s": {"y": 1779, "x": 1969, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b"}, "id": "3yu1gngy6g6c1"}}, "name": "t3_18iyggv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/h0uIxx4KbylDGGBKiqlSjEh74Qh1inkEkmdCMtq0YaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702641392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m diving into the exciting world of honeypots and cybersecurity at home, and I&amp;#39;d love some guidance on creating a live attack map using Grafana. Specifically, I&amp;#39;m using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here&amp;#39;s where I could use some help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\"&gt;https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been inspired by those awesome live attack maps from TPOTCE, and I&amp;#39;m eager to replicate something similar for my own setup. As a newbie in homelabs, I&amp;#39;m wondering if anyone has experience or advice on achieving this. I&amp;#39;d appreciate insights on how to Configure Grafana to visualize the attacks in real-time.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve tackled a similar project or have tips for a homelab newbie, I&amp;#39;d love to hear about your experiences and any resources you found helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iyggv", "is_robot_indexable": true, "report_reasons": null, "author": "TheKing464", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "subreddit_subscribers": 300092, "created_utc": 1702641392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_1fsoypwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lemmy v0.19.0 Release - Instance blocking, Scaled sort, and Federation Queue.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "blogging", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j10rm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blogging Platform", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702649630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "join-lemmy.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://join-lemmy.org/news/2023-12-15_-_Lemmy_Release_v0.19.0_-_Instance_blocking,_Scaled_sort,_and_Federation_Queue", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "fd71269e-7e67-11e9-8d1a-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j10rm", "is_robot_indexable": true, "report_reasons": null, "author": "parentis_shotgun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j10rm/lemmy_v0190_release_instance_blocking_scaled_sort/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://join-lemmy.org/news/2023-12-15_-_Lemmy_Release_v0.19.0_-_Instance_blocking,_Scaled_sort,_and_Federation_Queue", "subreddit_subscribers": 300092, "created_utc": 1702649630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I\u2019m a bit skeptical of things like cloud flare tunnels and want to set up a Linode instance running a reverse proxy in the cloud. The idea is that I could host things on my local servers, and access them publicly without revealing my public IP. \n\nI\u2019d run something like Traefik on the public cloud node and then poke a hole in my home firewall for that IP only. I don\u2019t want to expose and forward a bunch of ports on my local network even if they\u2019re IP restricted, so I\u2019m thinking I could run another reverse proxy locally and forward 443? Is double hopping through proxies going to lead to headaches?\n\nAlso if everything is always TLS encrypted, would just using a cloudflare tunnel be any less secure?", "author_fullname": "t2_ehz9mae5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse proxy in the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ir0el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702611993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a bit skeptical of things like cloud flare tunnels and want to set up a Linode instance running a reverse proxy in the cloud. The idea is that I could host things on my local servers, and access them publicly without revealing my public IP. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d run something like Traefik on the public cloud node and then poke a hole in my home firewall for that IP only. I don\u2019t want to expose and forward a bunch of ports on my local network even if they\u2019re IP restricted, so I\u2019m thinking I could run another reverse proxy locally and forward 443? Is double hopping through proxies going to lead to headaches?&lt;/p&gt;\n\n&lt;p&gt;Also if everything is always TLS encrypted, would just using a cloudflare tunnel be any less secure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ir0el", "is_robot_indexable": true, "report_reasons": null, "author": "BinaryPatrickDev", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ir0el/reverse_proxy_in_the_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ir0el/reverse_proxy_in_the_cloud/", "subreddit_subscribers": 300092, "created_utc": 1702611993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Howdy, I am looking to update our CCTV setup and hoping all you lovely folks can help point me in the right direction without spending days evaluating options :)\n\nI run an escape room business and we use CCTV to monitor guest progress as they \"escape\" the rooms.\n\nOur current setup:\n\n* we have 16 cameras (Amcrest IP2M-841EB)\n* we use **Amcrest Surveillance Pro** installed on each workstation (4 Windows PCs)\n* the cameras are grouped per room (e.g. \"Detective Room\", \"Space Room\", etc)\n* employees use the workstation PCs to monitor guests on up to 4 cameras (3-4 cameras per escape room)\n* employees use PTZ to view different angles from the cameras\n\nI'm looking to get everything onto a self-hosted server rather than installed directly on the workstations. I have a Dell PoweEdge R230 with Proxmox and a few docker instances running. NVR would be nice, but is a secondary priority. I also DO NOT need AI, motion / object detection, zones, triggers, \"tours\", auto-tracking, or anything fancy like that.\n\nI want to get all the cameras centrally hosted and then use a web UI (or desktop client) to view a given room's cameras. Being able to save a camera layout / view / group is a requirement (e.g. all cameras in a room). Also being able to use PTZ easily is a requirement (ideally, can control PTZ for any given camera without having to leave the 4 camera view).\n\nBlue Iris probably seems like the most obvious answer (especially since our whole setup is Amcrest at this point), but I'm not huge on spinning up a Windows VM just for BI, and I've never loved Amcrest Surveillance Pro, so part of me wants to try another vendor, but I'm not terribly biased.\n\nNormally I would just spin up each of them and evaluate all the options, but life has other plans, so I'm looking for some outside (\"expert\") advice.\n\nThanks a bunch for any suggestions / insight!", "author_fullname": "t2_ikuhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for CCTV/NVR recommendation (Frigate, Shinobi, iSpy, BlueIris, Zoneminder, etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jb3tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702676582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy, I am looking to update our CCTV setup and hoping all you lovely folks can help point me in the right direction without spending days evaluating options :)&lt;/p&gt;\n\n&lt;p&gt;I run an escape room business and we use CCTV to monitor guest progress as they &amp;quot;escape&amp;quot; the rooms.&lt;/p&gt;\n\n&lt;p&gt;Our current setup:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;we have 16 cameras (Amcrest IP2M-841EB)&lt;/li&gt;\n&lt;li&gt;we use &lt;strong&gt;Amcrest Surveillance Pro&lt;/strong&gt; installed on each workstation (4 Windows PCs)&lt;/li&gt;\n&lt;li&gt;the cameras are grouped per room (e.g. &amp;quot;Detective Room&amp;quot;, &amp;quot;Space Room&amp;quot;, etc)&lt;/li&gt;\n&lt;li&gt;employees use the workstation PCs to monitor guests on up to 4 cameras (3-4 cameras per escape room)&lt;/li&gt;\n&lt;li&gt;employees use PTZ to view different angles from the cameras&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m looking to get everything onto a self-hosted server rather than installed directly on the workstations. I have a Dell PoweEdge R230 with Proxmox and a few docker instances running. NVR would be nice, but is a secondary priority. I also DO NOT need AI, motion / object detection, zones, triggers, &amp;quot;tours&amp;quot;, auto-tracking, or anything fancy like that.&lt;/p&gt;\n\n&lt;p&gt;I want to get all the cameras centrally hosted and then use a web UI (or desktop client) to view a given room&amp;#39;s cameras. Being able to save a camera layout / view / group is a requirement (e.g. all cameras in a room). Also being able to use PTZ easily is a requirement (ideally, can control PTZ for any given camera without having to leave the 4 camera view).&lt;/p&gt;\n\n&lt;p&gt;Blue Iris probably seems like the most obvious answer (especially since our whole setup is Amcrest at this point), but I&amp;#39;m not huge on spinning up a Windows VM just for BI, and I&amp;#39;ve never loved Amcrest Surveillance Pro, so part of me wants to try another vendor, but I&amp;#39;m not terribly biased.&lt;/p&gt;\n\n&lt;p&gt;Normally I would just spin up each of them and evaluate all the options, but life has other plans, so I&amp;#39;m looking for some outside (&amp;quot;expert&amp;quot;) advice.&lt;/p&gt;\n\n&lt;p&gt;Thanks a bunch for any suggestions / insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jb3tr", "is_robot_indexable": true, "report_reasons": null, "author": "largenostril", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jb3tr/looking_for_cctvnvr_recommendation_frigate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jb3tr/looking_for_cctvnvr_recommendation_frigate/", "subreddit_subscribers": 300092, "created_utc": 1702676582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So i've been trying to get Archivebox running for the past few hours and i'm at a loss\n\nThe logs make it seem everything is working properly but when I go to [192.168.1.32:31200](https://192.168.1.32:31200) it just times out. \n\nI've tried using Portainer and running the docker compose setup guide through the shell with no luck.\n\nHere are the Portainer logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n       &gt; /data\n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    [+] Building archive folder structure...\n       + ./archive, ./sources, ./logs...\n       + ./ArchiveBox.conf...\n    [+] Building main SQL index and running initial migrations...\n       Operations to perform:\n       Apply all migrations: admin, auth, contenttypes, core, sessions\n       Running migrations:\n       Applying contenttypes.0001_initial... OK\n       Applying auth.0001_initial... OK\n       Applying admin.0001_initial... OK\n       Applying admin.0002_logentry_remove_auto_add... OK\n       Applying admin.0003_logentry_add_action_flag_choices... OK\n       Applying contenttypes.0002_remove_content_type_name... OK\n       Applying auth.0002_alter_permission_name_max_length... OK\n       Applying auth.0003_alter_user_email_max_length... OK\n       Applying auth.0004_alter_user_username_opts... OK\n       Applying auth.0005_alter_user_last_login_null... OK\n       Applying auth.0006_require_contenttypes_0002... OK\n       Applying auth.0007_alter_validators_add_error_messages... OK\n       Applying auth.0008_alter_user_username_max_length... OK\n       Applying auth.0009_alter_user_last_name_max_length... OK\n       Applying auth.0010_alter_group_name_max_length... OK\n       Applying auth.0011_update_proxy_permissions... OK\n       Applying auth.0012_alter_user_first_name_max_length... OK\n       Applying core.0001_initial... OK\n       Applying core.0002_auto_20200625_1521... OK\n       Applying core.0003_auto_20200630_1034... OK\n       Applying core.0004_auto_20200713_1552... OK\n       Applying core.0005_auto_20200728_0326... OK\n       Applying core.0006_auto_20201012_1520... OK\n       Applying core.0007_archiveresult... OK\n       Applying core.0008_auto_20210105_1421... OK\n       Applying core.0009_auto_20210216_1038... OK\n       Applying core.0010_auto_20210216_1055... OK\n       Applying core.0011_auto_20210216_1331... OK\n       Applying core.0012_auto_20210216_1425... OK\n       Applying core.0013_auto_20210218_0729... OK\n       Applying core.0014_auto_20210218_0729... OK\n       Applying core.0015_auto_20210218_0730... OK\n       Applying core.0016_auto_20210218_1204... OK\n       Applying core.0017_auto_20210219_0211... OK\n       Applying core.0018_auto_20210327_0952... OK\n       Applying core.0019_auto_20210401_0654... OK\n       Applying core.0020_auto_20210410_1031... OK\n       Applying core.0021_auto_20220914_0934... OK\n       Applying core.0022_auto_20231023_2008... OK\n       Applying sessions.0001_initial... OK\n       \u221a ./index.sqlite3\n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n       &gt; Skipping full snapshot directory check (quick mode)\n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n       Hint: To view your archive index, run:\n           archivebox server  # then visit http://127.0.0.1:8000\n       To add new links, you can run:\n           archivebox add &lt; ~/some/path/to/list_of_links.txt\n       For more usage and examples, run:\n           archivebox help\n    [+] Starting ArchiveBox webserver...\n       &gt; Logging errors to ./logs/errors.log\n    [!] No admin users exist yet, you will not be able to edit links in the UI.\n       To create an admin user, run:\n           archivebox manage createsuperuser\n    Performing system checks...\n    System check identified no issues (0 silenced).\n    December 15, 2023 - 10:29:59\n    Django version 3.1.14, using settings 'core.settings'\n    Starting development server at http://0.0.0.0:31200/\n    Quit the server with CONTROL-C.\n\nAnd here are the Proxmox shell logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n        &gt; /data\n    \n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    \n    [+] Building archive folder structure...\n        + ./archive, ./sources, ./logs...\n        + ./ArchiveBox.conf...\n    \n    [+] Building main SQL index and running initial migrations...\n        Operations to perform:\n          Apply all migrations: admin, auth, contenttypes, core, sessions\n        Running migrations:\n        Applying contenttypes.0001_initial... OK\n        Applying auth.0001_initial... OK\n        Applying admin.0001_initial... OK\n        Applying admin.0002_logentry_remove_auto_add... OK\n        Applying admin.0003_logentry_add_action_flag_choices... OK\n        Applying contenttypes.0002_remove_content_type_name... OK\n        Applying auth.0002_alter_permission_name_max_length... OK\n        Applying auth.0003_alter_user_email_max_length... OK\n        Applying auth.0004_alter_user_username_opts... OK\n        Applying auth.0005_alter_user_last_login_null... OK\n        Applying auth.0006_require_contenttypes_0002... OK\n        Applying auth.0007_alter_validators_add_error_messages... OK\n        Applying auth.0008_alter_user_username_max_length... OK\n        Applying auth.0009_alter_user_last_name_max_length... OK\n        Applying auth.0010_alter_group_name_max_length... OK\n        Applying auth.0011_update_proxy_permissions... OK\n        Applying auth.0012_alter_user_first_name_max_length... OK\n        Applying core.0001_initial... OK\n        Applying core.0002_auto_20200625_1521... OK\n        Applying core.0003_auto_20200630_1034... OK\n        Applying core.0004_auto_20200713_1552... OK\n        Applying core.0005_auto_20200728_0326... OK\n        Applying core.0006_auto_20201012_1520... OK\n        Applying core.0007_archiveresult... OK\n        Applying core.0008_auto_20210105_1421... OK\n        Applying core.0009_auto_20210216_1038... OK\n        Applying core.0010_auto_20210216_1055... OK\n        Applying core.0011_auto_20210216_1331... OK\n        Applying core.0012_auto_20210216_1425... OK\n        Applying core.0013_auto_20210218_0729... OK\n        Applying core.0014_auto_20210218_0729... OK\n        Applying core.0015_auto_20210218_0730... OK\n        Applying core.0016_auto_20210218_1204... OK\n        Applying core.0017_auto_20210219_0211... OK\n        Applying core.0018_auto_20210327_0952... OK\n        Applying core.0019_auto_20210401_0654... OK\n        Applying core.0020_auto_20210410_1031... OK\n        Applying core.0021_auto_20220914_0934... OK\n        Applying core.0022_auto_20231023_2008... OK\n        Applying sessions.0001_initial... OK\n    \n        \u221a ./index.sqlite3\n    \n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n    \n    [*] [2023-12-15 09:20:19] Writing 0 links to main index...\n        \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n    \n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n    \n    [+] Creating new admin user for the Web UI...\n    Username (leave blank to use 'archivebox'): admin\n    Email address: **********\n    Password: \n    Password (again): \n    The password is too similar to the username.\n    This password is too short. It must contain at least 8 characters.\n    This password is too common.\n    Bypass password validation and create user anyway? [y/N]: y\n    Superuser created successfully.\n    \n    [+] Installing enabled ArchiveBox dependencies automatically...\n    \n        Installing YOUTUBEDL_BINARY automatically using pip...\n    2023.10.13 is already installed yt-dlp\n    \n        Installing CHROME_BINARY automatically using playwright...\n    Chromium 119.0.6045.9 is already installed chromium-browser\n    \n        Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\n    SINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n    \n    [\u221a] Set up ArchiveBox and its dependencies successfully.\n    0.7.1+editable\n    ArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\n    DEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n    \n    [i] Dependency versions:\n     \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n     \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n     \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n     \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n    \n     \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n     \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n     \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n     \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n     \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n     \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n     \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n     \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n     \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n     \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n    \n    [i] Source-code locations:\n     \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n     \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n     -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n    \n    [i] Secrets locations:\n     -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n     -  COOKIES_FILE          -               disabled  None                                                                        \n    \n    [i] Data locations:\n     \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n     \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n     \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n     \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n     \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n     \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n    \n    \n        Hint: To view your archive index, run:\n            archivebox server  # then visit http://127.0.0.1:8000\n    \n        To add new links, you can run:\n            archivebox add &lt; ~/some/path/to/list_of_links.txt\n    \n        For more usage and examples, run:\n            archivebox help", "author_fullname": "t2_py1z2u36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archivebox timing out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixfjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702637384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;ve been trying to get Archivebox running for the past few hours and i&amp;#39;m at a loss&lt;/p&gt;\n\n&lt;p&gt;The logs make it seem everything is working properly but when I go to &lt;a href=\"https://192.168.1.32:31200\"&gt;192.168.1.32:31200&lt;/a&gt; it just times out. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried using Portainer and running the docker compose setup guide through the shell with no luck.&lt;/p&gt;\n\n&lt;p&gt;Here are the Portainer logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n   &amp;gt; /data\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n[+] Building archive folder structure...\n   + ./archive, ./sources, ./logs...\n   + ./ArchiveBox.conf...\n[+] Building main SQL index and running initial migrations...\n   Operations to perform:\n   Apply all migrations: admin, auth, contenttypes, core, sessions\n   Running migrations:\n   Applying contenttypes.0001_initial... OK\n   Applying auth.0001_initial... OK\n   Applying admin.0001_initial... OK\n   Applying admin.0002_logentry_remove_auto_add... OK\n   Applying admin.0003_logentry_add_action_flag_choices... OK\n   Applying contenttypes.0002_remove_content_type_name... OK\n   Applying auth.0002_alter_permission_name_max_length... OK\n   Applying auth.0003_alter_user_email_max_length... OK\n   Applying auth.0004_alter_user_username_opts... OK\n   Applying auth.0005_alter_user_last_login_null... OK\n   Applying auth.0006_require_contenttypes_0002... OK\n   Applying auth.0007_alter_validators_add_error_messages... OK\n   Applying auth.0008_alter_user_username_max_length... OK\n   Applying auth.0009_alter_user_last_name_max_length... OK\n   Applying auth.0010_alter_group_name_max_length... OK\n   Applying auth.0011_update_proxy_permissions... OK\n   Applying auth.0012_alter_user_first_name_max_length... OK\n   Applying core.0001_initial... OK\n   Applying core.0002_auto_20200625_1521... OK\n   Applying core.0003_auto_20200630_1034... OK\n   Applying core.0004_auto_20200713_1552... OK\n   Applying core.0005_auto_20200728_0326... OK\n   Applying core.0006_auto_20201012_1520... OK\n   Applying core.0007_archiveresult... OK\n   Applying core.0008_auto_20210105_1421... OK\n   Applying core.0009_auto_20210216_1038... OK\n   Applying core.0010_auto_20210216_1055... OK\n   Applying core.0011_auto_20210216_1331... OK\n   Applying core.0012_auto_20210216_1425... OK\n   Applying core.0013_auto_20210218_0729... OK\n   Applying core.0014_auto_20210218_0729... OK\n   Applying core.0015_auto_20210218_0730... OK\n   Applying core.0016_auto_20210218_1204... OK\n   Applying core.0017_auto_20210219_0211... OK\n   Applying core.0018_auto_20210327_0952... OK\n   Applying core.0019_auto_20210401_0654... OK\n   Applying core.0020_auto_20210410_1031... OK\n   Applying core.0021_auto_20220914_0934... OK\n   Applying core.0022_auto_20231023_2008... OK\n   Applying sessions.0001_initial... OK\n   \u221a ./index.sqlite3\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n   &amp;gt; Skipping full snapshot directory check (quick mode)\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n   Hint: To view your archive index, run:\n       archivebox server  # then visit http://127.0.0.1:8000\n   To add new links, you can run:\n       archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n   For more usage and examples, run:\n       archivebox help\n[+] Starting ArchiveBox webserver...\n   &amp;gt; Logging errors to ./logs/errors.log\n[!] No admin users exist yet, you will not be able to edit links in the UI.\n   To create an admin user, run:\n       archivebox manage createsuperuser\nPerforming system checks...\nSystem check identified no issues (0 silenced).\nDecember 15, 2023 - 10:29:59\nDjango version 3.1.14, using settings &amp;#39;core.settings&amp;#39;\nStarting development server at http://0.0.0.0:31200/\nQuit the server with CONTROL-C.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And here are the Proxmox shell logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n    &amp;gt; /data\n\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n\n[+] Building archive folder structure...\n    + ./archive, ./sources, ./logs...\n    + ./ArchiveBox.conf...\n\n[+] Building main SQL index and running initial migrations...\n    Operations to perform:\n      Apply all migrations: admin, auth, contenttypes, core, sessions\n    Running migrations:\n    Applying contenttypes.0001_initial... OK\n    Applying auth.0001_initial... OK\n    Applying admin.0001_initial... OK\n    Applying admin.0002_logentry_remove_auto_add... OK\n    Applying admin.0003_logentry_add_action_flag_choices... OK\n    Applying contenttypes.0002_remove_content_type_name... OK\n    Applying auth.0002_alter_permission_name_max_length... OK\n    Applying auth.0003_alter_user_email_max_length... OK\n    Applying auth.0004_alter_user_username_opts... OK\n    Applying auth.0005_alter_user_last_login_null... OK\n    Applying auth.0006_require_contenttypes_0002... OK\n    Applying auth.0007_alter_validators_add_error_messages... OK\n    Applying auth.0008_alter_user_username_max_length... OK\n    Applying auth.0009_alter_user_last_name_max_length... OK\n    Applying auth.0010_alter_group_name_max_length... OK\n    Applying auth.0011_update_proxy_permissions... OK\n    Applying auth.0012_alter_user_first_name_max_length... OK\n    Applying core.0001_initial... OK\n    Applying core.0002_auto_20200625_1521... OK\n    Applying core.0003_auto_20200630_1034... OK\n    Applying core.0004_auto_20200713_1552... OK\n    Applying core.0005_auto_20200728_0326... OK\n    Applying core.0006_auto_20201012_1520... OK\n    Applying core.0007_archiveresult... OK\n    Applying core.0008_auto_20210105_1421... OK\n    Applying core.0009_auto_20210216_1038... OK\n    Applying core.0010_auto_20210216_1055... OK\n    Applying core.0011_auto_20210216_1331... OK\n    Applying core.0012_auto_20210216_1425... OK\n    Applying core.0013_auto_20210218_0729... OK\n    Applying core.0014_auto_20210218_0729... OK\n    Applying core.0015_auto_20210218_0730... OK\n    Applying core.0016_auto_20210218_1204... OK\n    Applying core.0017_auto_20210219_0211... OK\n    Applying core.0018_auto_20210327_0952... OK\n    Applying core.0019_auto_20210401_0654... OK\n    Applying core.0020_auto_20210410_1031... OK\n    Applying core.0021_auto_20220914_0934... OK\n    Applying core.0022_auto_20231023_2008... OK\n    Applying sessions.0001_initial... OK\n\n    \u221a ./index.sqlite3\n\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n\n[*] [2023-12-15 09:20:19] Writing 0 links to main index...\n    \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n\n[+] Creating new admin user for the Web UI...\nUsername (leave blank to use &amp;#39;archivebox&amp;#39;): admin\nEmail address: **********\nPassword: \nPassword (again): \nThe password is too similar to the username.\nThis password is too short. It must contain at least 8 characters.\nThis password is too common.\nBypass password validation and create user anyway? [y/N]: y\nSuperuser created successfully.\n\n[+] Installing enabled ArchiveBox dependencies automatically...\n\n    Installing YOUTUBEDL_BINARY automatically using pip...\n2023.10.13 is already installed yt-dlp\n\n    Installing CHROME_BINARY automatically using playwright...\nChromium 119.0.6045.9 is already installed chromium-browser\n\n    Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\nSINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n\n[\u221a] Set up ArchiveBox and its dependencies successfully.\n0.7.1+editable\nArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\nDEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n\n[i] Dependency versions:\n \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n\n \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n\n[i] Source-code locations:\n \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n\n[i] Secrets locations:\n -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n -  COOKIES_FILE          -               disabled  None                                                                        \n\n[i] Data locations:\n \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n\n\n    Hint: To view your archive index, run:\n        archivebox server  # then visit http://127.0.0.1:8000\n\n    To add new links, you can run:\n        archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n\n    For more usage and examples, run:\n        archivebox help\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixfjh", "is_robot_indexable": true, "report_reasons": null, "author": "DisasterousLamps", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "subreddit_subscribers": 300092, "created_utc": 1702637384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Been looking for something that can achieve the need but never found anything. So time to ask.\n\n&amp;#x200B;\n\nAs indie dev I always need to get users logs from my apps for support and I'm doing most of the support publicly on a discourse server.\n\nUsers uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.\n\nSo I'm looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)\n\nIdeally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).\n\nBonus would be automated deletion of the files after a configurable delay.\n\nAnything that requires users to create an account does not really work.\n\nIf they no more have access to the file after upload and closing the page this can be OK.", "author_fullname": "t2_9oh0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting securely temporary logs between anonymous persons and me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iuysh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702626674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been looking for something that can achieve the need but never found anything. So time to ask.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As indie dev I always need to get users logs from my apps for support and I&amp;#39;m doing most of the support publicly on a discourse server.&lt;/p&gt;\n\n&lt;p&gt;Users uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)&lt;/p&gt;\n\n&lt;p&gt;Ideally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).&lt;/p&gt;\n\n&lt;p&gt;Bonus would be automated deletion of the files after a configurable delay.&lt;/p&gt;\n\n&lt;p&gt;Anything that requires users to create an account does not really work.&lt;/p&gt;\n\n&lt;p&gt;If they no more have access to the file after upload and closing the page this can be OK.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iuysh", "is_robot_indexable": true, "report_reasons": null, "author": "Tolriq", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "subreddit_subscribers": 300092, "created_utc": 1702626674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So, i keep moving forward on my journey choosing an IDP for my services.\n\nI have tested Authentik and it works kinda OK, i have some issues with Azure AD authentication. It seems that there is a confirmed bug, but it looks like Authentik has kinda only one person developing it and that can be a problem when we face problems or bugs. Thats the biggest negative of Authentik for me.\n\nNow i'm testing Keycloak, i was able to set it up and it seams that is running just fine. The problem is that most of the services that i want to protect does note use any kind of authentication that is suported by Keycloak (\\*rr apps, Overseerr, Homarr and etc), like Oauth2, SAML and etc.\n\nAuthentik supports the \"proxy\" auth, meaning that you put an forward auth middleware on traefik and it will intercept the trafic and authenticate you before you enter the page. On Authentik that works great, but i did not found any way to do that on Keycloak without using an external middleware on traefik that goes thought anoter container and not drirectly to keycloak like authentik can do.\n\nI have in the past used that forward auth container but i always had problems with it, lots of problems, so i dont want to get back to it.\n\nDo you know if is there any way to configure Keycloak to act as the forward auth middleware for Traefik like Authentik does so i dont need to use a third container to this usecase?\n\nThanks", "author_fullname": "t2_dlsxpsz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keycloak + Traefik and Forward Auth (Proxy Auth)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "proxy", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jdyik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Proxy", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702684437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i keep moving forward on my journey choosing an IDP for my services.&lt;/p&gt;\n\n&lt;p&gt;I have tested Authentik and it works kinda OK, i have some issues with Azure AD authentication. It seems that there is a confirmed bug, but it looks like Authentik has kinda only one person developing it and that can be a problem when we face problems or bugs. Thats the biggest negative of Authentik for me.&lt;/p&gt;\n\n&lt;p&gt;Now i&amp;#39;m testing Keycloak, i was able to set it up and it seams that is running just fine. The problem is that most of the services that i want to protect does note use any kind of authentication that is suported by Keycloak (*rr apps, Overseerr, Homarr and etc), like Oauth2, SAML and etc.&lt;/p&gt;\n\n&lt;p&gt;Authentik supports the &amp;quot;proxy&amp;quot; auth, meaning that you put an forward auth middleware on traefik and it will intercept the trafic and authenticate you before you enter the page. On Authentik that works great, but i did not found any way to do that on Keycloak without using an external middleware on traefik that goes thought anoter container and not drirectly to keycloak like authentik can do.&lt;/p&gt;\n\n&lt;p&gt;I have in the past used that forward auth container but i always had problems with it, lots of problems, so i dont want to get back to it.&lt;/p&gt;\n\n&lt;p&gt;Do you know if is there any way to configure Keycloak to act as the forward auth middleware for Traefik like Authentik does so i dont need to use a third container to this usecase?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5e46c26c-7e68-11e9-8d4e-0e3bbb559e74", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jdyik", "is_robot_indexable": true, "report_reasons": null, "author": "fabio_teixei", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jdyik/keycloak_traefik_and_forward_auth_proxy_auth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jdyik/keycloak_traefik_and_forward_auth_proxy_auth/", "subreddit_subscribers": 300092, "created_utc": 1702684437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\nI bought a domain on cloudflare in order to expose my selfhosted apps. I am using authelia with 2fa for security an have my cloudflare challenges to high. I have got 2.5k requests in the last 24 hours. The domain only started working 48 hours ago but I have got seemingly a lot of requests. Most of the requests (1.7k) are from my country so I am not sure if they are all me but that leaves 800 requests from 144 unique visitors that are not me. A few cloudflare challenges were completed from people in other countries and I have locked all traffic not from my country for now. Is this normal for a new domain and should I be worried?  \n\n\nThank you!", "author_fullname": "t2_5gthmgz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudflare lots of requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j8o6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702670016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I bought a domain on cloudflare in order to expose my selfhosted apps. I am using authelia with 2fa for security an have my cloudflare challenges to high. I have got 2.5k requests in the last 24 hours. The domain only started working 48 hours ago but I have got seemingly a lot of requests. Most of the requests (1.7k) are from my country so I am not sure if they are all me but that leaves 800 requests from 144 unique visitors that are not me. A few cloudflare challenges were completed from people in other countries and I have locked all traffic not from my country for now. Is this normal for a new domain and should I be worried?  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j8o6p", "is_robot_indexable": true, "report_reasons": null, "author": "Only-Pin-490", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j8o6p/cloudflare_lots_of_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j8o6p/cloudflare_lots_of_requests/", "subreddit_subscribers": 300092, "created_utc": 1702670016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm looking for some project / task management software that allows me to view tasks across multiple \"project\" (or whatever term the app uses). Basically the idea is that we have a household \"project\" (currently in Trello) that my wife and I both work on but I also have many side projects that I work on I need to keep separate. However, I want one unified view across all projects where I can see what should be worked on next, what's overdue, what she's working on, etc.\n\n**Requirements:**\n\n* **Cross-project views** (must have)\n* **Mobile support**  (my wife work mostly on mobile for her tasks)\n* **Kanban support** (might be flexible on this but would really like it)\n\nSo far I've tried the following and either they are overloaded with features I don't need, ugly, or in most cases don't have the cross-project view I need.\n\n* **Openproject** (overkill and ugly / unintuitive interface)\n* **Focalboard** (simple, decent, mobile is in beta and janky, no cross-project views)\n* **leantime** (no cross-project view)  \nEdit: Actually there basically is with the Home view which lists your tasks from all projects and you can group them by due date, project, etc. Not bad. I might give this more of a try.\n* **taiga** (no cross-project view)\n* **WeKan** (no cross-project view)\n* **Planka** (no cross-project view)\n* **ZenTao** (cross-project view but clunky mobile experience and a lot of features I don't need)\n* **TaskCafe** (cross-project list view but mobile pretty broken and project semi-abandoned)\n* **NextCloud Deck** (no cross-project view? can't tell)\n* **Plane** (closest so far but only has \"spreadsheet view\" for cross-project view). The [Docker install](https://github.com/makeplane/plane/blob/preview/docker-compose.yml) also requires like 9? images / containers which seems pretty heavy", "author_fullname": "t2_atxoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project management software that has cross-project dashboard / views?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqw6d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702621293.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702611615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some project / task management software that allows me to view tasks across multiple &amp;quot;project&amp;quot; (or whatever term the app uses). Basically the idea is that we have a household &amp;quot;project&amp;quot; (currently in Trello) that my wife and I both work on but I also have many side projects that I work on I need to keep separate. However, I want one unified view across all projects where I can see what should be worked on next, what&amp;#39;s overdue, what she&amp;#39;s working on, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Cross-project views&lt;/strong&gt; (must have)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Mobile support&lt;/strong&gt;  (my wife work mostly on mobile for her tasks)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Kanban support&lt;/strong&gt; (might be flexible on this but would really like it)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So far I&amp;#39;ve tried the following and either they are overloaded with features I don&amp;#39;t need, ugly, or in most cases don&amp;#39;t have the cross-project view I need.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Openproject&lt;/strong&gt; (overkill and ugly / unintuitive interface)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Focalboard&lt;/strong&gt; (simple, decent, mobile is in beta and janky, no cross-project views)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;leantime&lt;/strong&gt; (no cross-project view)&lt;br/&gt;\nEdit: Actually there basically is with the Home view which lists your tasks from all projects and you can group them by due date, project, etc. Not bad. I might give this more of a try.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;taiga&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;WeKan&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Planka&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ZenTao&lt;/strong&gt; (cross-project view but clunky mobile experience and a lot of features I don&amp;#39;t need)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;TaskCafe&lt;/strong&gt; (cross-project list view but mobile pretty broken and project semi-abandoned)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;NextCloud Deck&lt;/strong&gt; (no cross-project view? can&amp;#39;t tell)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Plane&lt;/strong&gt; (closest so far but only has &amp;quot;spreadsheet view&amp;quot; for cross-project view). The &lt;a href=\"https://github.com/makeplane/plane/blob/preview/docker-compose.yml\"&gt;Docker install&lt;/a&gt; also requires like 9? images / containers which seems pretty heavy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?auto=webp&amp;s=22698fb6aedf8db0dd8b1096be2170230f52d329", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba7d8cf685e70b5d69626b4cf6136f9e2991fb14", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19c5ab8605ccee5dab644b663a6cf31d64156530", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11ede2b49a6d6af8f1f7ac8a2fdc708382287a96", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28bd12319e14374ebe3c2b42bf09d82377a9f86e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b1aca5578f2df9dcf49df70d147f11b327c3c02", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1ea58a04873f4087fc73eae47035995fdefb8c4", "width": 1080, "height": 540}], "variants": {}, "id": "KscnINYRQTsVomj6pESVRD9AbGWpMuqgnjOqrecfQ1A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iqw6d", "is_robot_indexable": true, "report_reasons": null, "author": "guesswhochickenpoo", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iqw6d/project_management_software_that_has_crossproject/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iqw6d/project_management_software_that_has_crossproject/", "subreddit_subscribers": 300092, "created_utc": 1702611615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello Selfhosters,\n\nI have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm's running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I've tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn't work for me. I also like the idea of isolation/serperating certain tasks. So i've tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. \n\nAny advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!", "author_fullname": "t2_7g226", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pihole + VPN on proxmox", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ivsgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702630263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Selfhosters,&lt;/p&gt;\n\n&lt;p&gt;I have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm&amp;#39;s running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I&amp;#39;ve tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn&amp;#39;t work for me. I also like the idea of isolation/serperating certain tasks. So i&amp;#39;ve tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. &lt;/p&gt;\n\n&lt;p&gt;Any advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ivsgl", "is_robot_indexable": true, "report_reasons": null, "author": "vivachris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "subreddit_subscribers": 300092, "created_utc": 1702630263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am finally at a point where I am hosting a few services that I would like to be accessible from outside of my home network. And potentially even have a couple of family members have access to it. In addition, I would like to move away from using Duckdns for having https access for my Home Assistant install (so that I can leverage Google Assistant)\n\nWith that said, time to buy a domain. But I have very little background in how this is supposed to work. Most domains I looked at would cost almost nothing for the 1st year and then crazy renewal fees from year 2 onwards. What are some of my options that won't break the bank and give me a domain that I can host a few of my services on (using subdomains - am I understanding that right?)", "author_fullname": "t2_k3srjshd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on buying a domain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqgrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702610257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am finally at a point where I am hosting a few services that I would like to be accessible from outside of my home network. And potentially even have a couple of family members have access to it. In addition, I would like to move away from using Duckdns for having https access for my Home Assistant install (so that I can leverage Google Assistant)&lt;/p&gt;\n\n&lt;p&gt;With that said, time to buy a domain. But I have very little background in how this is supposed to work. Most domains I looked at would cost almost nothing for the 1st year and then crazy renewal fees from year 2 onwards. What are some of my options that won&amp;#39;t break the bank and give me a domain that I can host a few of my services on (using subdomains - am I understanding that right?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iqgrd", "is_robot_indexable": true, "report_reasons": null, "author": "fredflintstone88", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iqgrd/advice_on_buying_a_domain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iqgrd/advice_on_buying_a_domain/", "subreddit_subscribers": 300092, "created_utc": 1702610257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_140qn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zulip 8.0: Threaded open-source team chat", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_18jgf1g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qN_9K08BA3qocUNzM1jOtBnKYRDxBhwtx0igCp8yNI0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1702691880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.zulip.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.zulip.com/2023/12/15/zulip-8-0-released/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?auto=webp&amp;s=ce604e70be104cc2b7c7585f5789e9fc3fae713d", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce27d6b542e018f5f86158709eb286dd0028bc5e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=867d53d34646badc8549f5edf080c058c5d16e4a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=700e628c8b084173f465e243bc0d4c35b56ab5d0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=187114b73340e9569492b7d07219b97edff16900", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4485e8eee8860e9f67e84449c5b996255daf7b6e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/18YgJVT5qwet1aLR75TWPqMbqKybOsbpeZb83i6AjbU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=75e1581e7b369d0368c1eb3ed3cb68cd62982daf", "width": 1080, "height": 565}], "variants": {}, "id": "didV0pbr0i0drK8zT1Y86j81F72zF3BTZoN5kDm_WIw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jgf1g", "is_robot_indexable": true, "report_reasons": null, "author": "Neustradamus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jgf1g/zulip_80_threaded_opensource_team_chat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.zulip.com/2023/12/15/zulip-8-0-released/", "subreddit_subscribers": 300092, "created_utc": 1702691880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am running a self hosted server using docker containers and NPM as a reverse proxy. I have some web servers that I want exposed to the internet and I want of course my Portainer, Dashboard, etc. only accessible from the internal network. \n\nMy setup right now includes Cloudflare as a DNS service where I have\n\n* An A and AAAA record pointing at my static home ip proxied through cloudflare\n* Multiple CNAME records on 3rd level domains for my web servers pointing at my domain name (e.g. [website1.mydomain.com](https://website1.mydomain.com)) proxied through cloudflare\n* Multiple A records pointing at the local ip of my server on my home network for different services (e.g. [dashboard.mydomain.com](https://dashboard.mydomain.com) points to 192.168.1.69)\n\nNPM functions as a reverse proxy, routing traffic to each service. I am forwarding ports 80 and 443 on my router.\n\nWith this setup I only have access to my services from inside my network where the domain points to a local IP. Outside my network the same local IP is not reachable. My question is: Is this safe? \n\nA possible solution I was thinking about would be to route traffic from my web servers to a different port, e.g. 8080 which would be forwarded to 80 on WAN through my router. Port 80 would be kept closed internally and used only for local services. But I do not know how to do this using NPM.", "author_fullname": "t2_2ksf1vz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exposing some services and keeping others private", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18jgdx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702691771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running a self hosted server using docker containers and NPM as a reverse proxy. I have some web servers that I want exposed to the internet and I want of course my Portainer, Dashboard, etc. only accessible from the internal network. &lt;/p&gt;\n\n&lt;p&gt;My setup right now includes Cloudflare as a DNS service where I have&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An A and AAAA record pointing at my static home ip proxied through cloudflare&lt;/li&gt;\n&lt;li&gt;Multiple CNAME records on 3rd level domains for my web servers pointing at my domain name (e.g. &lt;a href=\"https://website1.mydomain.com\"&gt;website1.mydomain.com&lt;/a&gt;) proxied through cloudflare&lt;/li&gt;\n&lt;li&gt;Multiple A records pointing at the local ip of my server on my home network for different services (e.g. &lt;a href=\"https://dashboard.mydomain.com\"&gt;dashboard.mydomain.com&lt;/a&gt; points to 192.168.1.69)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;NPM functions as a reverse proxy, routing traffic to each service. I am forwarding ports 80 and 443 on my router.&lt;/p&gt;\n\n&lt;p&gt;With this setup I only have access to my services from inside my network where the domain points to a local IP. Outside my network the same local IP is not reachable. My question is: Is this safe? &lt;/p&gt;\n\n&lt;p&gt;A possible solution I was thinking about would be to route traffic from my web servers to a different port, e.g. 8080 which would be forwarded to 80 on WAN through my router. Port 80 would be kept closed internally and used only for local services. But I do not know how to do this using NPM.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jgdx8", "is_robot_indexable": true, "report_reasons": null, "author": "frank20a", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jgdx8/exposing_some_services_and_keeping_others_private/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jgdx8/exposing_some_services_and_keeping_others_private/", "subreddit_subscribers": 300092, "created_utc": 1702691771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello,  \nMy question is simple: Where do you guys store your data? Volumes? Bind Mounts?\n\nIn my case, I store my data in bind mounts, all to a folder called \"dockerDATA,\" but I can't help but notice that a folder called \"data\" exists at the root of my filesystem as well (ubuntu 22.04). Sometimes, when I create containers, I also notice that their default volume creation location is \".data/\". Where is this, though? There is no hidden data folder in my root directory. Just a regular data folder, which I believe is managed by Portainer. Is this the other data folder? I mean, I have Portainer in use as well, so I think that may affect this.\n\nBeyond this, though, what do you think is better? Bind mounts or Docker-managed volumes, which I still don't actually understand how to create even after reading the documentation on volumes, How can I migrate my data to volumes? I know NextCloudAIO uses Docker volumes; do I just not put a \"/\" in front of the volume path to make it available in \"/var/lib/docker/volumes...\"?\n\nAlso, a last consideration is that I use Kopia for backups. I run it in Docker, and I have it bind mount to my repository location. Would backing up everything in the Docker volumes path be better than what I currently do, which is backup \"/dockerDATA\" and the \"/var/lib...volumes\" path?\n\nHelp is appreciated, and I would like to learn how to best do this.", "author_fullname": "t2_q1rfumi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker | How do you store your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jcxg8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702681502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nMy question is simple: Where do you guys store your data? Volumes? Bind Mounts?&lt;/p&gt;\n\n&lt;p&gt;In my case, I store my data in bind mounts, all to a folder called &amp;quot;dockerDATA,&amp;quot; but I can&amp;#39;t help but notice that a folder called &amp;quot;data&amp;quot; exists at the root of my filesystem as well (ubuntu 22.04). Sometimes, when I create containers, I also notice that their default volume creation location is &amp;quot;.data/&amp;quot;. Where is this, though? There is no hidden data folder in my root directory. Just a regular data folder, which I believe is managed by Portainer. Is this the other data folder? I mean, I have Portainer in use as well, so I think that may affect this.&lt;/p&gt;\n\n&lt;p&gt;Beyond this, though, what do you think is better? Bind mounts or Docker-managed volumes, which I still don&amp;#39;t actually understand how to create even after reading the documentation on volumes, How can I migrate my data to volumes? I know NextCloudAIO uses Docker volumes; do I just not put a &amp;quot;/&amp;quot; in front of the volume path to make it available in &amp;quot;/var/lib/docker/volumes...&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Also, a last consideration is that I use Kopia for backups. I run it in Docker, and I have it bind mount to my repository location. Would backing up everything in the Docker volumes path be better than what I currently do, which is backup &amp;quot;/dockerDATA&amp;quot; and the &amp;quot;/var/lib...volumes&amp;quot; path?&lt;/p&gt;\n\n&lt;p&gt;Help is appreciated, and I would like to learn how to best do this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jcxg8", "is_robot_indexable": true, "report_reasons": null, "author": "Ejz9", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jcxg8/docker_how_do_you_store_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jcxg8/docker_how_do_you_store_your_data/", "subreddit_subscribers": 300092, "created_utc": 1702681502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_74cls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better way to manage secrets with `docker compose`", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jctd3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702681212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "igor.moomers.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://igor.moomers.org/posts/secrets-in-docker-compose", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jctd3", "is_robot_indexable": true, "report_reasons": null, "author": "igor_47", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jctd3/better_way_to_manage_secrets_with_docker_compose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://igor.moomers.org/posts/secrets-in-docker-compose", "subreddit_subscribers": 300092, "created_utc": 1702681212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi everyone i am trying to run my own mail server but this hiccup i cant find any fix for.i tried connecting to port 25 using telnet on my machine where i run the server and it works fine with localhost and [mail.domain.com](https://mail.domain.com) but when  try this from my personal computer i get a connection timeout. Cant find any postfix error logs or some other error logs. The port does react to pings.\n\nthings i tried:disabling firewall,disabling helo configuration\n\nfurther i dont know what maybe can fix it:\n\npostfix configuration:\n\n    alias_database = hash:/etc/aliases\n    alias_maps = hash:/etc/aliases\n    append_dot_mydomain = no\n    biff = no\n    broken_sasl_auth_clients = yes\n    compatibility_level = 2\n    home_mailbox = Maildir/\n    inet_interfaces = all\n    inet_protocols = all\n    mailbox_command =\n    mailbox_size_limit = 0\n    mydestination = $myhostname, mail.domain.com, domain.com, smtp.domain.coml, debian, localhost.localdomain, localhost\n    mydomain = domain.com\n    myhostname = mail.domain.com\n    mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128\n    myorigin = /etc/mailname\n    readme_directory = no\n    recipient_delimiter = +\n    relayhost =\n    smtp_tls_CApath = /etc/ssl/certs\n    smtp_tls_note_starttls_offer = yes\n    smtp_tls_security_level = may\n    smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\n    smtp_use_tls = yes\n    smtpd_banner = $myhostname ESMTP $mail_name (Debian/GNU)\n    smtpd_helo_required = yes\n    smtpd_helo_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_helo_hostname, check_helo_access hash:/etc/postfix/helo_access\n    smtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\n    smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\n    smtpd_sasl_auth_enable = yes\n    smtpd_sasl_local_domain =\n    smtpd_sasl_path = private/auth\n    smtpd_sasl_security_options = noanonymous\n    smtpd_sasl_type = dovecot\n    smtpd_tls_cert_file = /etc/letsencrypt/live/mail.domain.com/fullchain.pem\n    smtpd_tls_key_file = /etc/letsencrypt/live/mail.domain.com/privkey.pem\n    smtpd_tls_loglevel = 1\n    smtpd_tls_received_header = yes\n    smtpd_tls_security_level = may\n    smtpd_use_tls = yes\n\n&amp;#x200B;", "author_fullname": "t2_7vhbqmi4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "smtp not accepting connections on port 25", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18jc2qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702679196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone i am trying to run my own mail server but this hiccup i cant find any fix for.i tried connecting to port 25 using telnet on my machine where i run the server and it works fine with localhost and &lt;a href=\"https://mail.domain.com\"&gt;mail.domain.com&lt;/a&gt; but when  try this from my personal computer i get a connection timeout. Cant find any postfix error logs or some other error logs. The port does react to pings.&lt;/p&gt;\n\n&lt;p&gt;things i tried:disabling firewall,disabling helo configuration&lt;/p&gt;\n\n&lt;p&gt;further i dont know what maybe can fix it:&lt;/p&gt;\n\n&lt;p&gt;postfix configuration:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;alias_database = hash:/etc/aliases\nalias_maps = hash:/etc/aliases\nappend_dot_mydomain = no\nbiff = no\nbroken_sasl_auth_clients = yes\ncompatibility_level = 2\nhome_mailbox = Maildir/\ninet_interfaces = all\ninet_protocols = all\nmailbox_command =\nmailbox_size_limit = 0\nmydestination = $myhostname, mail.domain.com, domain.com, smtp.domain.coml, debian, localhost.localdomain, localhost\nmydomain = domain.com\nmyhostname = mail.domain.com\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128\nmyorigin = /etc/mailname\nreadme_directory = no\nrecipient_delimiter = +\nrelayhost =\nsmtp_tls_CApath = /etc/ssl/certs\nsmtp_tls_note_starttls_offer = yes\nsmtp_tls_security_level = may\nsmtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\nsmtp_use_tls = yes\nsmtpd_banner = $myhostname ESMTP $mail_name (Debian/GNU)\nsmtpd_helo_required = yes\nsmtpd_helo_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_helo_hostname, check_helo_access hash:/etc/postfix/helo_access\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\nsmtpd_sasl_auth_enable = yes\nsmtpd_sasl_local_domain =\nsmtpd_sasl_path = private/auth\nsmtpd_sasl_security_options = noanonymous\nsmtpd_sasl_type = dovecot\nsmtpd_tls_cert_file = /etc/letsencrypt/live/mail.domain.com/fullchain.pem\nsmtpd_tls_key_file = /etc/letsencrypt/live/mail.domain.com/privkey.pem\nsmtpd_tls_loglevel = 1\nsmtpd_tls_received_header = yes\nsmtpd_tls_security_level = may\nsmtpd_use_tls = yes\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jc2qo", "is_robot_indexable": true, "report_reasons": null, "author": "kajvans", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jc2qo/smtp_not_accepting_connections_on_port_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jc2qo/smtp_not_accepting_connections_on_port_25/", "subreddit_subscribers": 300092, "created_utc": 1702679196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I lost power for about 8 hours last night. After turning my server back on, I noticed I couldn't access any of my cocker containers (on my ubuntu server vm). I checked the procmoc console and noticed that instead of the usual \"welcome to ubuntu server, access via we on `MY IP ADDRESS` instead it says to access via the name of my server: `https:my-server:9090` which I know is the cockpit socket.\n\n`https:my-server:9090` doesn't work and neigher does `MY IP ADDRESS:9090` Trying to ssh into `MY IP ADDRESS` doesn't work either.\n\nI removed cockpit to see if it would revert back to showing me the ip address but it doesn't. I see the welcome screen but no mention of the vm's ip. \n\nI tried `ip a` and `ip addr`and I get 17 lines of output a bunch of random addresses starting with 172 named global br-... I don't know what these are and I can only see the output from lines 9 through 17 because they don't all fit in one screen but this is the proxmox shitty console and I'm not able to scroll up or down. I stopped all my docker containers to nesure the output isn't clogged. \n\nI redirected the output to a a file: so I could open it with nano and checked the content but it's still a bunch of those 172 addresses.\n\nline one has my [127.0.0.1](https://127.0.0.1) local address but everything else is 172. No 192 address anywhere which should be my vm's address.\n\nFinally I checked the vm's netplan config.yaml file and everything looks the way I set it up using Google and Cloudflare DNS:\n\nhttps://preview.redd.it/x639as4j0j6c1.png?width=572&amp;format=png&amp;auto=webp&amp;s=852e7ffeb30c6d08e8c6cbc81b1c4128d5bf1f25\n\nI reset the network using   `systemctl restart systemd-networkd` but that didn't fix it either.\n\nIs there anything else I should be checking for or trying? I'm out of answers at this point. The vm is clearly up and running but it seems to have lost it's own ip address.", "author_fullname": "t2_3n6y969g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Locked out of Ubuntu vm after power outtage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "media_metadata": {"x639as4j0j6c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/x639as4j0j6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8a716ea593b1552b6430ca90e707b540f6ac1ac"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/x639as4j0j6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=486d797b48cf155e1ec913089aad375296a2617b"}, {"y": 165, "x": 320, "u": "https://preview.redd.it/x639as4j0j6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6e08dadc9429d7bf9c8da3bd7a675508a5a4053"}], "s": {"y": 295, "x": 572, "u": "https://preview.redd.it/x639as4j0j6c1.png?width=572&amp;format=png&amp;auto=webp&amp;s=852e7ffeb30c6d08e8c6cbc81b1c4128d5bf1f25"}, "id": "x639as4j0j6c1"}}, "name": "t3_18jasg7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HBumb0q3gIJBaNvV_wCmb1D28DRtNu2SisP30TwBaMo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702675734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I lost power for about 8 hours last night. After turning my server back on, I noticed I couldn&amp;#39;t access any of my cocker containers (on my ubuntu server vm). I checked the procmoc console and noticed that instead of the usual &amp;quot;welcome to ubuntu server, access via we on &lt;code&gt;MY IP ADDRESS&lt;/code&gt; instead it says to access via the name of my server: &lt;code&gt;https:my-server:9090&lt;/code&gt; which I know is the cockpit socket.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;https:my-server:9090&lt;/code&gt; doesn&amp;#39;t work and neigher does &lt;code&gt;MY IP ADDRESS:9090&lt;/code&gt; Trying to ssh into &lt;code&gt;MY IP ADDRESS&lt;/code&gt; doesn&amp;#39;t work either.&lt;/p&gt;\n\n&lt;p&gt;I removed cockpit to see if it would revert back to showing me the ip address but it doesn&amp;#39;t. I see the welcome screen but no mention of the vm&amp;#39;s ip. &lt;/p&gt;\n\n&lt;p&gt;I tried &lt;code&gt;ip a&lt;/code&gt; and &lt;code&gt;ip addr&lt;/code&gt;and I get 17 lines of output a bunch of random addresses starting with 172 named global br-... I don&amp;#39;t know what these are and I can only see the output from lines 9 through 17 because they don&amp;#39;t all fit in one screen but this is the proxmox shitty console and I&amp;#39;m not able to scroll up or down. I stopped all my docker containers to nesure the output isn&amp;#39;t clogged. &lt;/p&gt;\n\n&lt;p&gt;I redirected the output to a a file: so I could open it with nano and checked the content but it&amp;#39;s still a bunch of those 172 addresses.&lt;/p&gt;\n\n&lt;p&gt;line one has my &lt;a href=\"https://127.0.0.1\"&gt;127.0.0.1&lt;/a&gt; local address but everything else is 172. No 192 address anywhere which should be my vm&amp;#39;s address.&lt;/p&gt;\n\n&lt;p&gt;Finally I checked the vm&amp;#39;s netplan config.yaml file and everything looks the way I set it up using Google and Cloudflare DNS:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x639as4j0j6c1.png?width=572&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=852e7ffeb30c6d08e8c6cbc81b1c4128d5bf1f25\"&gt;https://preview.redd.it/x639as4j0j6c1.png?width=572&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=852e7ffeb30c6d08e8c6cbc81b1c4128d5bf1f25&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I reset the network using   &lt;code&gt;systemctl restart systemd-networkd&lt;/code&gt; but that didn&amp;#39;t fix it either.&lt;/p&gt;\n\n&lt;p&gt;Is there anything else I should be checking for or trying? I&amp;#39;m out of answers at this point. The vm is clearly up and running but it seems to have lost it&amp;#39;s own ip address.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18jasg7", "is_robot_indexable": true, "report_reasons": null, "author": "notdoreen", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18jasg7/locked_out_of_ubuntu_vm_after_power_outtage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18jasg7/locked_out_of_ubuntu_vm_after_power_outtage/", "subreddit_subscribers": 300092, "created_utc": 1702675734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm pretty new to self hosting things, and really just Jellyfin so far. I want to use Tailscale to allow my brother access to my Jellyfin server, but I have some questions about that and the security behind it. I was able to get a subnet set up and active with what is maybe too large of an IP range. I'll be honest I don't understand that part of it very well. I would really only like to expose my particular Jellyfin address to Tailscale, 192.168.*.*: Port, so how do I go about doing that in Windows? Is it possible? I'm just using Windows right now because I'm lazy, and I'm planning a new build that will use Linux/Unraid/whatever later. Also, just so I understand, opening up the subnet this way still only gives Tailscale access to my network, correct? Only approved devices will be able to access my network? I just want to make sure I didn't make any mistakes.", "author_fullname": "t2_t6qqg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tailscale questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j7hwx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702666862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m pretty new to self hosting things, and really just Jellyfin so far. I want to use Tailscale to allow my brother access to my Jellyfin server, but I have some questions about that and the security behind it. I was able to get a subnet set up and active with what is maybe too large of an IP range. I&amp;#39;ll be honest I don&amp;#39;t understand that part of it very well. I would really only like to expose my particular Jellyfin address to Tailscale, 192.168.&lt;em&gt;.&lt;/em&gt;: Port, so how do I go about doing that in Windows? Is it possible? I&amp;#39;m just using Windows right now because I&amp;#39;m lazy, and I&amp;#39;m planning a new build that will use Linux/Unraid/whatever later. Also, just so I understand, opening up the subnet this way still only gives Tailscale access to my network, correct? Only approved devices will be able to access my network? I just want to make sure I didn&amp;#39;t make any mistakes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j7hwx", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyRingo84", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j7hwx/tailscale_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j7hwx/tailscale_questions/", "subreddit_subscribers": 300092, "created_utc": 1702666862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have started to look into logging and performance monitoring, and have been between the Grafana stack (the online one as well as a local one), zabbix and checkmk. Right now I am leaning towards Grafana, but the documentation is very lacking on a proper expenation.\n\nI am running the grafana-agent in flow mode (as suggested in their docs over promtail), and that is alright.\n\nBut my main issue is that way too much data is sent and it is just unuseable. Also I am a bit unsure how to seperate the logs and data if for example I run the agent on two computers. Say I run it on a server, it got its syslogs, for example /var/log/syslog, and then I run it on a raspberry pi (that is handling UPS and such), that also got a /var/log/syslog. \n\nWhen logging into the explore mode on grafana, its just a filename label with the filename, but I have no idea which one belongs to what computer. Is it any best practise flows for this?\n\nAlso any suggestion to filter the logs so it reduce the amount of data sent? I filled up the 10K limit in days.\n\nHere is the example of the config this far:\n\n&amp;#x200B;\n\n    logging {\n      level  = \"error\"\n      format = \"logfmt\"\n    }\n    \n    local.file_match \"unraid\" {\n      path_targets = [{\n        __address__ = \"localhost\",\n        __path__    = \"/var/log/**\",\n        __path_exclude__    = \"/var/log/file.activity.log\",\n      }]\n    }\n    \n    loki.source.file \"files\" {\n    \ttargets    = local.file_match.unraid.targets\n    \tforward_to = [loki.write.default.receiver]\n    }\n    \n    \n    discovery.docker \"flog_scrape\" {\n    \thost             = \"unix:///var/run/docker.sock\"\n    \trefresh_interval = \"5s\"\n    \n    \tfilter {\n    \t\tname   = \"label\"\n    \t\tvalues = [\"logging=promtail\"]\n    \t}\n    }\n    \n    discovery.relabel \"flog_scrape\" {\n    \ttargets = discovery.docker.flog_scrape.targets\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_name\"]\n    \t\tregex         = \"/(.*)\"\n    \t\ttarget_label  = \"container\"\n    \t}\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_log_stream\"]\n    \t\ttarget_label  = \"logstream\"\n    \t}\n    \n    \trule {\n    \t\tsource_labels = [\"__meta_docker_container_label_logging_jobname\"]\n    \t\ttarget_label  = \"job\"\n    \t}\n    }\n    \n    \n    local.file_match \"flog_scrape\" {\n    \tpath_targets = discovery.relabel.flog_scrape.output\n    }\n    \n    loki.source.file \"flog_scrape\" {\n    \ttargets    = local.file_match.flog_scrape.targets\n    \tforward_to = [loki.write.default.receiver]\n    }\n    \n    loki.write \"default\" {\n        endpoint {\n            url = \"https://logs-prod-025.grafana.net/loki/api/v1/push\"\n            basic_auth {\n                username = user\n                password = \"password\"\n            }\n        }\n    }\n    \n\n&amp;#x200B;", "author_fullname": "t2_kvhks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with some best practises in logging and metrics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j6y1z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702665447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started to look into logging and performance monitoring, and have been between the Grafana stack (the online one as well as a local one), zabbix and checkmk. Right now I am leaning towards Grafana, but the documentation is very lacking on a proper expenation.&lt;/p&gt;\n\n&lt;p&gt;I am running the grafana-agent in flow mode (as suggested in their docs over promtail), and that is alright.&lt;/p&gt;\n\n&lt;p&gt;But my main issue is that way too much data is sent and it is just unuseable. Also I am a bit unsure how to seperate the logs and data if for example I run the agent on two computers. Say I run it on a server, it got its syslogs, for example /var/log/syslog, and then I run it on a raspberry pi (that is handling UPS and such), that also got a /var/log/syslog. &lt;/p&gt;\n\n&lt;p&gt;When logging into the explore mode on grafana, its just a filename label with the filename, but I have no idea which one belongs to what computer. Is it any best practise flows for this?&lt;/p&gt;\n\n&lt;p&gt;Also any suggestion to filter the logs so it reduce the amount of data sent? I filled up the 10K limit in days.&lt;/p&gt;\n\n&lt;p&gt;Here is the example of the config this far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;logging {\n  level  = &amp;quot;error&amp;quot;\n  format = &amp;quot;logfmt&amp;quot;\n}\n\nlocal.file_match &amp;quot;unraid&amp;quot; {\n  path_targets = [{\n    __address__ = &amp;quot;localhost&amp;quot;,\n    __path__    = &amp;quot;/var/log/**&amp;quot;,\n    __path_exclude__    = &amp;quot;/var/log/file.activity.log&amp;quot;,\n  }]\n}\n\nloki.source.file &amp;quot;files&amp;quot; {\n    targets    = local.file_match.unraid.targets\n    forward_to = [loki.write.default.receiver]\n}\n\n\ndiscovery.docker &amp;quot;flog_scrape&amp;quot; {\n    host             = &amp;quot;unix:///var/run/docker.sock&amp;quot;\n    refresh_interval = &amp;quot;5s&amp;quot;\n\n    filter {\n        name   = &amp;quot;label&amp;quot;\n        values = [&amp;quot;logging=promtail&amp;quot;]\n    }\n}\n\ndiscovery.relabel &amp;quot;flog_scrape&amp;quot; {\n    targets = discovery.docker.flog_scrape.targets\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_name&amp;quot;]\n        regex         = &amp;quot;/(.*)&amp;quot;\n        target_label  = &amp;quot;container&amp;quot;\n    }\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_log_stream&amp;quot;]\n        target_label  = &amp;quot;logstream&amp;quot;\n    }\n\n    rule {\n        source_labels = [&amp;quot;__meta_docker_container_label_logging_jobname&amp;quot;]\n        target_label  = &amp;quot;job&amp;quot;\n    }\n}\n\n\nlocal.file_match &amp;quot;flog_scrape&amp;quot; {\n    path_targets = discovery.relabel.flog_scrape.output\n}\n\nloki.source.file &amp;quot;flog_scrape&amp;quot; {\n    targets    = local.file_match.flog_scrape.targets\n    forward_to = [loki.write.default.receiver]\n}\n\nloki.write &amp;quot;default&amp;quot; {\n    endpoint {\n        url = &amp;quot;https://logs-prod-025.grafana.net/loki/api/v1/push&amp;quot;\n        basic_auth {\n            username = user\n            password = &amp;quot;password&amp;quot;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j6y1z", "is_robot_indexable": true, "report_reasons": null, "author": "alekslyse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j6y1z/help_with_some_best_practises_in_logging_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j6y1z/help_with_some_best_practises_in_logging_and/", "subreddit_subscribers": 300092, "created_utc": 1702665447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My local network contains a brand new media server in a Proxmox container and I don't want to go to it using [http://ip.address:9000/material](http://ip.address:9000/material) anymore. What would it take for me to set up a local DNS resolver that turns [http://music](http://music) into the above lookup?\n\nI had a pi-hole setup for a brief while as the DNS server of choice. That has this feature. Unfortunately, it wasn't blocking too many ads and it was causing a lot of other problems (I forget) so I shut it off. I still have the container for it. I can probably give it another try if all else fails. Or I can try adguard.\n\nI was hoping my tp-link archer router will have a way for doing this but it doesn't.\n\nFWIW I also have nginx running for a reverse proxy in the same Ubuntu LXC where the media server is installed. But it is for the incoming traffic and it helps me expose a couple of services on my personal domain. This is for internal only.\n\nThanks in advance.", "author_fullname": "t2_11an59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local DNS names", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dnstools", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18j6sbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "DNS Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702665036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My local network contains a brand new media server in a Proxmox container and I don&amp;#39;t want to go to it using &lt;a href=\"http://ip.address:9000/material\"&gt;http://ip.address:9000/material&lt;/a&gt; anymore. What would it take for me to set up a local DNS resolver that turns &lt;a href=\"http://music\"&gt;http://music&lt;/a&gt; into the above lookup?&lt;/p&gt;\n\n&lt;p&gt;I had a pi-hole setup for a brief while as the DNS server of choice. That has this feature. Unfortunately, it wasn&amp;#39;t blocking too many ads and it was causing a lot of other problems (I forget) so I shut it off. I still have the container for it. I can probably give it another try if all else fails. Or I can try adguard.&lt;/p&gt;\n\n&lt;p&gt;I was hoping my tp-link archer router will have a way for doing this but it doesn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;FWIW I also have nginx running for a reverse proxy in the same Ubuntu LXC where the media server is installed. But it is for the incoming traffic and it helps me expose a couple of services on my personal domain. This is for internal only.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f0c1d430-7e6b-11e9-9779-0e688895811a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18j6sbc", "is_robot_indexable": true, "report_reasons": null, "author": "yelloguy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18j6sbc/local_dns_names/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18j6sbc/local_dns_names/", "subreddit_subscribers": 300092, "created_utc": 1702665036.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}