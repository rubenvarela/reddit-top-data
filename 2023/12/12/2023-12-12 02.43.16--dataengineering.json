{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently unemployed for last 6 months. I am having 8 years of experience in ETL, data warehouse building, snowflake, spark and tableau. \n\nI also have bit of hands on experience in low code tools like fivetran, data modelling tools like dbt.\n\nDue to the market conditions I am not receiving any job offers, so planning to upskill in the time being. I already have certifications in aws solution architect associate, snowflake snowpro core and Apache spark developer by Databricks. \n\nMy question is, what new technology can I learn and get certified in to get an edge when the market is up? Should I try my hands on any NoSQL databases? Will learning kafka will open up my job chances? \n\nPS: my priority right now is landing up a job immediately once the market is up. I am continuously applying jobs, but not getting any calls. Seeing that there are not much calls, I am panicked and wants to learn something related to my field but can land me a job.", "author_fullname": "t2_o51po378", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What new to learn in DE now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fusjx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702302069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently unemployed for last 6 months. I am having 8 years of experience in ETL, data warehouse building, snowflake, spark and tableau. &lt;/p&gt;\n\n&lt;p&gt;I also have bit of hands on experience in low code tools like fivetran, data modelling tools like dbt.&lt;/p&gt;\n\n&lt;p&gt;Due to the market conditions I am not receiving any job offers, so planning to upskill in the time being. I already have certifications in aws solution architect associate, snowflake snowpro core and Apache spark developer by Databricks. &lt;/p&gt;\n\n&lt;p&gt;My question is, what new technology can I learn and get certified in to get an edge when the market is up? Should I try my hands on any NoSQL databases? Will learning kafka will open up my job chances? &lt;/p&gt;\n\n&lt;p&gt;PS: my priority right now is landing up a job immediately once the market is up. I am continuously applying jobs, but not getting any calls. Seeing that there are not much calls, I am panicked and wants to learn something related to my field but can land me a job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18fusjx", "is_robot_indexable": true, "report_reasons": null, "author": "NeighborhoodCold5339", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fusjx/what_new_to_learn_in_de_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fusjx/what_new_to_learn_in_de_now/", "subreddit_subscribers": 145425, "created_utc": 1702302069.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys! I work at [Taipy](https://github.com/Avaiga/taipy); we are an Open-Source Python library designed to create web applications using only Python. Some users had problems displaying charts based on big data, e.g., line charts with 100,000 points. We worked on a feature to reduce the number of displayed points while retaining the shape of the curve as much as possible and wanted to share how we did it. Feel free to take a look [here](https://www.taipy.io/posts/python-charting-taming-big-data-without-crashing): \n\n&amp;#x200B;\n\nhttps://preview.redd.it/ekligzx1qo5c1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=f6335259e1b9289d21593aa021b6568ab52be7e7", "author_fullname": "t2_4qttbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plotting 1,000,000 points on a webpage using only Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ekligzx1qo5c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 92, "x": 108, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03281d8d94d7592ca79bbd3ebf80c422d4f9d489"}, {"y": 185, "x": 216, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4f3656f5e88287a02339966edfea0d2a6a6cda4"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ffdac175d1a8f0ef8fd9fc63f3716ce36507415"}, {"y": 550, "x": 640, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=30c966bc3838920c0ea79daff4f07d4e6f5f9ddc"}, {"y": 826, "x": 960, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=25fcfadc9242bc0fd11feb96319abf6bb8f4f385"}], "s": {"y": 910, "x": 1057, "u": "https://preview.redd.it/ekligzx1qo5c1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=f6335259e1b9289d21593aa021b6568ab52be7e7"}, "id": "ekligzx1qo5c1"}}, "name": "t3_18fx7o4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QxFAiEkUJcLtc2aqBETkrHMze1i9Z7HJAjB2xjBDtmM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702308842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! I work at &lt;a href=\"https://github.com/Avaiga/taipy\"&gt;Taipy&lt;/a&gt;; we are an Open-Source Python library designed to create web applications using only Python. Some users had problems displaying charts based on big data, e.g., line charts with 100,000 points. We worked on a feature to reduce the number of displayed points while retaining the shape of the curve as much as possible and wanted to share how we did it. Feel free to take a look &lt;a href=\"https://www.taipy.io/posts/python-charting-taming-big-data-without-crashing\"&gt;here&lt;/a&gt;: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ekligzx1qo5c1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f6335259e1b9289d21593aa021b6568ab52be7e7\"&gt;https://preview.redd.it/ekligzx1qo5c1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f6335259e1b9289d21593aa021b6568ab52be7e7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18fx7o4", "is_robot_indexable": true, "report_reasons": null, "author": "Alyx1337", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fx7o4/plotting_1000000_points_on_a_webpage_using_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fx7o4/plotting_1000000_points_on_a_webpage_using_only/", "subreddit_subscribers": 145425, "created_utc": 1702308842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a few years of experience as a low level data analyst and a year of data engineering. I\u2019ve been doing leetcode to prepare for a move to SWE. Today my company announced a reorg back to data ops. We are expecting to train our replacements and get laid off. \nAs the junior dev market is dead right now should I consider going back to school for a BS in CS? I have a business degree and data engineering seems suboptimal compared to back end dev to me.", "author_fullname": "t2_cimoe09n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expecting a layoff - should I go back to school?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g8ey3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702339565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few years of experience as a low level data analyst and a year of data engineering. I\u2019ve been doing leetcode to prepare for a move to SWE. Today my company announced a reorg back to data ops. We are expecting to train our replacements and get laid off. \nAs the junior dev market is dead right now should I consider going back to school for a BS in CS? I have a business degree and data engineering seems suboptimal compared to back end dev to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18g8ey3", "is_robot_indexable": true, "report_reasons": null, "author": "OkMacaron493", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g8ey3/expecting_a_layoff_should_i_go_back_to_school/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g8ey3/expecting_a_layoff_should_i_go_back_to_school/", "subreddit_subscribers": 145425, "created_utc": 1702339565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wanted to have a discussion with folks with experienced similar things but getting burned out working with messy data. There\u2019s always something that the business wants to add the data is either incomplete or it doesn\u2019t jam with the data model because it\u2019s at a different grain. You can speak up as much as you want but the business just claims it\u2019s super important and so you make an exception to the rule only to have more crappy data come in and screw up an entire data model that you\u2019ve built. \n\nNot looking for any advice, I would just like to hear everyone\u2019s story.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Burnout", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g6a5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702333835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to have a discussion with folks with experienced similar things but getting burned out working with messy data. There\u2019s always something that the business wants to add the data is either incomplete or it doesn\u2019t jam with the data model because it\u2019s at a different grain. You can speak up as much as you want but the business just claims it\u2019s super important and so you make an exception to the rule only to have more crappy data come in and screw up an entire data model that you\u2019ve built. &lt;/p&gt;\n\n&lt;p&gt;Not looking for any advice, I would just like to hear everyone\u2019s story.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g6a5o", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g6a5o/data_burnout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g6a5o/data_burnout/", "subreddit_subscribers": 145425, "created_utc": 1702333835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a (light-hearted) roast at work where Data Scientists poke fun at Data Engineers and vice versa. Any suggestions for content that would roast Data Engineers? \n\nAs an example, I plan to poke some fun at all the lingo Data Engineers throw around at daily stand-ups from using 30 AWS services.", "author_fullname": "t2_mvj12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Roast Content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3odg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702327427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a (light-hearted) roast at work where Data Scientists poke fun at Data Engineers and vice versa. Any suggestions for content that would roast Data Engineers? &lt;/p&gt;\n\n&lt;p&gt;As an example, I plan to poke some fun at all the lingo Data Engineers throw around at daily stand-ups from using 30 AWS services.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g3odg", "is_robot_indexable": true, "report_reasons": null, "author": "succulentBroccoli", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3odg/de_roast_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3odg/de_roast_content/", "subreddit_subscribers": 145425, "created_utc": 1702327427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company just announced a restructuring of our central data platform org and my team was effected.\n\nPreviously we were basically a data engineering team for a specific data domain developing and owning pipelines, data lakes/warehouse, and visualizations. However, post-restructuring we\u2019re now \u201ctechnically\u201d part of the platform team, but from what I understand we\u2019re  basically end-users for the core platform team, and they\u2019ll be building tools for us to ingest, store, transform etc\u2026 we\u2019re just focused on ingestion.\n\nUltimately I\u2019m worried about the long term staying power of a team that ONLY does ingestion using simplified internal tools. What makes matters worse is that the platform team is looking to build these tools for general use by business data engineers. So in a future where other groups can use the same tools to ingest their own data, what\u2019s the value of a central data team?\n\nI\u2019m planning to talk with my manager about this, but I want to come with some idea of a better direction in mind before I have that conversation, so curious if anyone here has advice?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do central data platforms usually have dedicated central ingestion teams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18frbal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702289515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company just announced a restructuring of our central data platform org and my team was effected.&lt;/p&gt;\n\n&lt;p&gt;Previously we were basically a data engineering team for a specific data domain developing and owning pipelines, data lakes/warehouse, and visualizations. However, post-restructuring we\u2019re now \u201ctechnically\u201d part of the platform team, but from what I understand we\u2019re  basically end-users for the core platform team, and they\u2019ll be building tools for us to ingest, store, transform etc\u2026 we\u2019re just focused on ingestion.&lt;/p&gt;\n\n&lt;p&gt;Ultimately I\u2019m worried about the long term staying power of a team that ONLY does ingestion using simplified internal tools. What makes matters worse is that the platform team is looking to build these tools for general use by business data engineers. So in a future where other groups can use the same tools to ingest their own data, what\u2019s the value of a central data team?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning to talk with my manager about this, but I want to come with some idea of a better direction in mind before I have that conversation, so curious if anyone here has advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18frbal", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18frbal/do_central_data_platforms_usually_have_dedicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18frbal/do_central_data_platforms_usually_have_dedicated/", "subreddit_subscribers": 145425, "created_utc": 1702289515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am having some serious issues at work with trying to make user-facing dashboards work with the setup that was mostly made by the previous data engineer.\n\n# Context\n\nThe company makes software where people can book things (for example, meeting rooms). What I've been trying to build is a full-stack application where our users can create and edit dashboards consisting of widgets with KPIs, such as booking rates, most booked resources, locations... You can view it as some sort of homemade Looker, Tableau or Power BI application that is tailored for our use cases. \n\n# The current setup \n\nData is pulled from the transactional databases into a Postgres data warehouse via an ETL made with Luigi, homemade python and cronjobs, once a day. This was objectively enough for the previous use case (Power BI). However, since a Python API that I built is now serving the data for the frontend instead of the data layer of Power BI, the requirements have changed. Response times for some queries is awful (we're talking minutes here, absolutely unacceptable for a user-facing application).\n\n# An example\n\nQueries are sometimes quite complex : I'll walk you through the specs of one of the painful ones. Let's say you are part of \"Company\". Company has meeting rooms that have :  \n\n- an id\n- a location (declined in several columns : country, city, and so on)\n- a type\n- a name\n- a capacity\n- a creation time\n\nPeople have made bookings on these rooms. Bookings are defined as : \n\n- an id\n- a start_time (timestamp with timezone, stored as utc)\n- an end_time (same)\n- a room_id\n\nI've kept a lot of columns out of the definitions so you can better understand this specific use case, just know these are not the only columns in these tables.\n\nNow, we want, for a specific location, and for a given timeframe (can be anything from 1 month to 10 years) the average occupancy rate per hour of the day, however it is part of the specs for the user to be able to filter the time slots he wants. This could be 8AM to 6PM but it might as well be 8-9AM + 10-11AM + 1-2PM... and so on. \n\nSince the bookings are defined as start and end time, and users can filter out hours from the day, I made an incremental DBT model that calculates the occupancy rate of every hour for each room since its creation. That way, this data is only calculated once and can be queried way more easily. This however is *really* long for the first run since our clients may have tens of thousands of rooms and some have been with us for the better part of 10 years, which means they have millions of bookings on these rooms. X years times the amount of hours in a year, for every room... the resulting model is easily hundreds of millions of rows of calculated data.\n\nThis table looks like this :\n\n- timeslot (timestamp with timezone, stored as UTC)\n- client_id\n- room_id\n- occupancy_rate\n\n\nThis DBT model has sped up the queries pretty much 10x. This is not enough however, and even with the biggest RDS instance we've monitored the CPU of the instance to go to 100% for requests handling many rows. It feels like we've hit the limitations of postgres and might need a database more suited to our use cases.\n\n# More requirements and constraints\n\nWe have on-prem clients, and both the infrastructure team and data team are really small (I'm the only software engineer of the data team, and the infra team is made up of 3 people).\nThat means no cloud data warehouse, and avoiding high-maintenance databases.\nAlso, our clients can be anywhere in the world so the database needs to have timezone-related features.\n\n# My ideas for now\n\nAfter doing some benchmarks on a few MPP databases, I feel like Clickhouse may be a good database for this. I've also explored Apache Doris, Starrocks (which unfortunately does not have timezone features), and Apache Pinot.\n\nClickhouse however needs denormalized data to be performant, and changing the DBT model to include the rooms data means we need to be able to update millions of rows when a room's data changes... Which might be quite costly. Still better than the application not working, though.\n\nIf anyone has an idea on how to make this whole situation better, I'm all ears. I feel like I'm in way over my head sometimes. If you need additional information let me know.", "author_fullname": "t2_72swh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current data setup cannot handle user-facing dashboards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fxgna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702309509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am having some serious issues at work with trying to make user-facing dashboards work with the setup that was mostly made by the previous data engineer.&lt;/p&gt;\n\n&lt;h1&gt;Context&lt;/h1&gt;\n\n&lt;p&gt;The company makes software where people can book things (for example, meeting rooms). What I&amp;#39;ve been trying to build is a full-stack application where our users can create and edit dashboards consisting of widgets with KPIs, such as booking rates, most booked resources, locations... You can view it as some sort of homemade Looker, Tableau or Power BI application that is tailored for our use cases. &lt;/p&gt;\n\n&lt;h1&gt;The current setup&lt;/h1&gt;\n\n&lt;p&gt;Data is pulled from the transactional databases into a Postgres data warehouse via an ETL made with Luigi, homemade python and cronjobs, once a day. This was objectively enough for the previous use case (Power BI). However, since a Python API that I built is now serving the data for the frontend instead of the data layer of Power BI, the requirements have changed. Response times for some queries is awful (we&amp;#39;re talking minutes here, absolutely unacceptable for a user-facing application).&lt;/p&gt;\n\n&lt;h1&gt;An example&lt;/h1&gt;\n\n&lt;p&gt;Queries are sometimes quite complex : I&amp;#39;ll walk you through the specs of one of the painful ones. Let&amp;#39;s say you are part of &amp;quot;Company&amp;quot;. Company has meeting rooms that have :  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;an id&lt;/li&gt;\n&lt;li&gt;a location (declined in several columns : country, city, and so on)&lt;/li&gt;\n&lt;li&gt;a type&lt;/li&gt;\n&lt;li&gt;a name&lt;/li&gt;\n&lt;li&gt;a capacity&lt;/li&gt;\n&lt;li&gt;a creation time&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;People have made bookings on these rooms. Bookings are defined as : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;an id&lt;/li&gt;\n&lt;li&gt;a start_time (timestamp with timezone, stored as utc)&lt;/li&gt;\n&lt;li&gt;an end_time (same)&lt;/li&gt;\n&lt;li&gt;a room_id&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve kept a lot of columns out of the definitions so you can better understand this specific use case, just know these are not the only columns in these tables.&lt;/p&gt;\n\n&lt;p&gt;Now, we want, for a specific location, and for a given timeframe (can be anything from 1 month to 10 years) the average occupancy rate per hour of the day, however it is part of the specs for the user to be able to filter the time slots he wants. This could be 8AM to 6PM but it might as well be 8-9AM + 10-11AM + 1-2PM... and so on. &lt;/p&gt;\n\n&lt;p&gt;Since the bookings are defined as start and end time, and users can filter out hours from the day, I made an incremental DBT model that calculates the occupancy rate of every hour for each room since its creation. That way, this data is only calculated once and can be queried way more easily. This however is &lt;em&gt;really&lt;/em&gt; long for the first run since our clients may have tens of thousands of rooms and some have been with us for the better part of 10 years, which means they have millions of bookings on these rooms. X years times the amount of hours in a year, for every room... the resulting model is easily hundreds of millions of rows of calculated data.&lt;/p&gt;\n\n&lt;p&gt;This table looks like this :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;timeslot (timestamp with timezone, stored as UTC)&lt;/li&gt;\n&lt;li&gt;client_id&lt;/li&gt;\n&lt;li&gt;room_id&lt;/li&gt;\n&lt;li&gt;occupancy_rate&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This DBT model has sped up the queries pretty much 10x. This is not enough however, and even with the biggest RDS instance we&amp;#39;ve monitored the CPU of the instance to go to 100% for requests handling many rows. It feels like we&amp;#39;ve hit the limitations of postgres and might need a database more suited to our use cases.&lt;/p&gt;\n\n&lt;h1&gt;More requirements and constraints&lt;/h1&gt;\n\n&lt;p&gt;We have on-prem clients, and both the infrastructure team and data team are really small (I&amp;#39;m the only software engineer of the data team, and the infra team is made up of 3 people).\nThat means no cloud data warehouse, and avoiding high-maintenance databases.\nAlso, our clients can be anywhere in the world so the database needs to have timezone-related features.&lt;/p&gt;\n\n&lt;h1&gt;My ideas for now&lt;/h1&gt;\n\n&lt;p&gt;After doing some benchmarks on a few MPP databases, I feel like Clickhouse may be a good database for this. I&amp;#39;ve also explored Apache Doris, Starrocks (which unfortunately does not have timezone features), and Apache Pinot.&lt;/p&gt;\n\n&lt;p&gt;Clickhouse however needs denormalized data to be performant, and changing the DBT model to include the rooms data means we need to be able to update millions of rows when a room&amp;#39;s data changes... Which might be quite costly. Still better than the application not working, though.&lt;/p&gt;\n\n&lt;p&gt;If anyone has an idea on how to make this whole situation better, I&amp;#39;m all ears. I feel like I&amp;#39;m in way over my head sometimes. If you need additional information let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18fxgna", "is_robot_indexable": true, "report_reasons": null, "author": "Altarim", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fxgna/current_data_setup_cannot_handle_userfacing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fxgna/current_data_setup_cannot_handle_userfacing/", "subreddit_subscribers": 145425, "created_utc": 1702309509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm part of a project that's implementing a new Data warehousing solution and we are just about to scale our team from about 10 people into around 30 divided into 5 teams or so. We are just about to implement DBT and has started building a Data Vault. The increase in team size and the phase we're currently in means that all of the teams will be working on modelling and implementing the Data Vault.\n\nWe are now thinking of how to set up our GIT repo(s) and DBT to accomodate this situation as good as possible. With Data Vault it feels like we need to build it in a mono repo, but with this many people and teams it feels like a recipe for disaster and it would be better to divide the Vault into multiple repos.\n\nHow have you guys handled this situation?", "author_fullname": "t2_o0nay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT and Data Vault with multiple teams, mono repo or not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fveo7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702303860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m part of a project that&amp;#39;s implementing a new Data warehousing solution and we are just about to scale our team from about 10 people into around 30 divided into 5 teams or so. We are just about to implement DBT and has started building a Data Vault. The increase in team size and the phase we&amp;#39;re currently in means that all of the teams will be working on modelling and implementing the Data Vault.&lt;/p&gt;\n\n&lt;p&gt;We are now thinking of how to set up our GIT repo(s) and DBT to accomodate this situation as good as possible. With Data Vault it feels like we need to build it in a mono repo, but with this many people and teams it feels like a recipe for disaster and it would be better to divide the Vault into multiple repos.&lt;/p&gt;\n\n&lt;p&gt;How have you guys handled this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18fveo7", "is_robot_indexable": true, "report_reasons": null, "author": "zirxo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fveo7/dbt_and_data_vault_with_multiple_teams_mono_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fveo7/dbt_and_data_vault_with_multiple_teams_mono_repo/", "subreddit_subscribers": 145425, "created_utc": 1702303860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, this is my first DE project.    [Baitur5/reddit\\_api\\_elt (github.com)](https://github.com/Baitur5/reddit_api_elt) . It is basically about   \na data pipeline that extracts Reddit data for a Google Data Studio report, focusing on a specific subreddit   \nCan you guys check it out , and give some advice &amp; tips on how to improve it or the next things I should add.  \n\n\nP.S. I followed steps from this repository but made some adjustments: [ABZ-Aaron/Reddit-API-Pipeline (github.com)](https://github.com/ABZ-Aaron/Reddit-API-Pipeline) ", "author_fullname": "t2_kq543w8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit ELT Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18froaz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702291003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, this is my first DE project.    &lt;a href=\"https://github.com/Baitur5/reddit_api_elt\"&gt;Baitur5/reddit_api_elt (github.com)&lt;/a&gt; . It is basically about&lt;br/&gt;\na data pipeline that extracts Reddit data for a Google Data Studio report, focusing on a specific subreddit&lt;br/&gt;\nCan you guys check it out , and give some advice &amp;amp; tips on how to improve it or the next things I should add.  &lt;/p&gt;\n\n&lt;p&gt;P.S. I followed steps from this repository but made some adjustments: &lt;a href=\"https://github.com/ABZ-Aaron/Reddit-API-Pipeline\"&gt;ABZ-Aaron/Reddit-API-Pipeline (github.com)&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18froaz", "is_robot_indexable": true, "report_reasons": null, "author": "ulukbekovbr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18froaz/reddit_elt_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18froaz/reddit_elt_pipeline/", "subreddit_subscribers": 145425, "created_utc": 1702291003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm a data engineer at a startup and have been working on getting various operational data into Databricks. My next challenge is to present an overview of our current data assets to the management team (Some C-level stakeholders also like to know). They have also requested an internal dashboard with some key info, but they have no idea what I currently have in the Databricks warehouse, and I and not entirely sure which data they'll find most relevant...As a first step, I'd like to have a clear and simple way to show them what data assets we have.\n\nI'm considering the following:\n\n1. A big data dictionary page in confluence: This is how it was done in my previous company a page starts with a big table with columns: table name, column name, column description, source, logic...etc.  I feel it'll be a good table for data analysts to refer to, but not sure if it will be too detailed for those senior stakeholders.\n2. A dashboard in Databricks: Chatgpt brought up this method to me, by using information tables in databricks, I will be able to create a databricks dashboard for data inventory. the pros will be it will automatically handle the new coming tables and cols which saves a bit of overhead. But I am not sure if it will be easy to add and put notes on the tables/columns or formatting the table in a more insightful way(grouping by topic for example)\n3. A mindmap: Came to my mind that a mindmap is usually easy to follow and helps in capturing the big picture and overall structure.  Perhaps a mind map that branches out based on topics, subtopics, and table names?\n\n4. Do you have any other suggestions for presenting data assets?\n\nThanks in advance!", "author_fullname": "t2_hf67tpfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Presenting Data Inventory to the Management team in the startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fnity", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702273576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineer at a startup and have been working on getting various operational data into Databricks. My next challenge is to present an overview of our current data assets to the management team (Some C-level stakeholders also like to know). They have also requested an internal dashboard with some key info, but they have no idea what I currently have in the Databricks warehouse, and I and not entirely sure which data they&amp;#39;ll find most relevant...As a first step, I&amp;#39;d like to have a clear and simple way to show them what data assets we have.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A big data dictionary page in confluence: This is how it was done in my previous company a page starts with a big table with columns: table name, column name, column description, source, logic...etc.  I feel it&amp;#39;ll be a good table for data analysts to refer to, but not sure if it will be too detailed for those senior stakeholders.&lt;/li&gt;\n&lt;li&gt;A dashboard in Databricks: Chatgpt brought up this method to me, by using information tables in databricks, I will be able to create a databricks dashboard for data inventory. the pros will be it will automatically handle the new coming tables and cols which saves a bit of overhead. But I am not sure if it will be easy to add and put notes on the tables/columns or formatting the table in a more insightful way(grouping by topic for example)&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A mindmap: Came to my mind that a mindmap is usually easy to follow and helps in capturing the big picture and overall structure.  Perhaps a mind map that branches out based on topics, subtopics, and table names?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Do you have any other suggestions for presenting data assets?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18fnity", "is_robot_indexable": true, "report_reasons": null, "author": "East-Garage2337", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fnity/presenting_data_inventory_to_the_management_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fnity/presenting_data_inventory_to_the_management_team/", "subreddit_subscribers": 145425, "created_utc": 1702273576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data in S3 like this (for example)\n\n&amp;#x200B;\n\n|NAME|COUNTRY|SOMETHING|OPERATION|\n|:-|:-|:-|:-|\n|steve|usa|hello|insert|\n|joe|canada|hi|insert|\n|steve|usa|howdy|update|\n\nWhat is the fastest way that you would get this data into Redshit BUT with the final table \"deduplicated\"? (that is, where Steve only appears once and with value for \\`something\\` field being \\`howdy\\`)\n\nEDIT: This may seem like something I can google, but it's not. We actually already achieve this in a couple of ways, but we are not happy with latency. This question was more to see how *you* achieve something like this. Please and thank you.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data from S3 to Redshift, but Deduplicated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g1mam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702323092.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702322434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data in S3 like this (for example)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;NAME&lt;/th&gt;\n&lt;th align=\"left\"&gt;COUNTRY&lt;/th&gt;\n&lt;th align=\"left\"&gt;SOMETHING&lt;/th&gt;\n&lt;th align=\"left\"&gt;OPERATION&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;steve&lt;/td&gt;\n&lt;td align=\"left\"&gt;usa&lt;/td&gt;\n&lt;td align=\"left\"&gt;hello&lt;/td&gt;\n&lt;td align=\"left\"&gt;insert&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;joe&lt;/td&gt;\n&lt;td align=\"left\"&gt;canada&lt;/td&gt;\n&lt;td align=\"left\"&gt;hi&lt;/td&gt;\n&lt;td align=\"left\"&gt;insert&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;steve&lt;/td&gt;\n&lt;td align=\"left\"&gt;usa&lt;/td&gt;\n&lt;td align=\"left\"&gt;howdy&lt;/td&gt;\n&lt;td align=\"left\"&gt;update&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;What is the fastest way that you would get this data into Redshit BUT with the final table &amp;quot;deduplicated&amp;quot;? (that is, where Steve only appears once and with value for `something` field being `howdy`)&lt;/p&gt;\n\n&lt;p&gt;EDIT: This may seem like something I can google, but it&amp;#39;s not. We actually already achieve this in a couple of ways, but we are not happy with latency. This question was more to see how &lt;em&gt;you&lt;/em&gt; achieve something like this. Please and thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g1mam", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g1mam/data_from_s3_to_redshift_but_deduplicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g1mam/data_from_s3_to_redshift_but_deduplicated/", "subreddit_subscribers": 145425, "created_utc": 1702322434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6y0b4txf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why We Built a Streaming SQL Engine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_18fxkru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2J0x5cInVFc4DsbYiW63I9eVgLbm79HBvsP1VKu7kbA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702309813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "epsio.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.epsio.io/blog/why-we-built-a-streaming-sql-engine", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?auto=webp&amp;s=bde1bb439f8042c2066e539de311e97a9b34f68c", "width": 1376, "height": 714}, "resolutions": [{"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eac5d4e9cb92dce7b0b63f164195fd8d9934b59c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=41f34043110161b56e0b27712a353a975d56bf20", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b52001b9486b04f0742e761902c5cfcd8cbbf0dc", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a259d069e4ab50668673eb345d4d655ffd6c5cb5", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4fa737b762cbbbf12c1acfcccbaca8eb8785678f", "width": 960, "height": 498}, {"url": "https://external-preview.redd.it/FnoSiaDUngR1tdl1ppiLK9jThDecKTz8uqybcSLwtIk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=213bb55bc131cf226f4518542ac26d7f7de4a0fa", "width": 1080, "height": 560}], "variants": {}, "id": "L6vsGJtlTpCBQYIHfzVB4U_eHzCDAFcguQ6gS8SW1ns"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18fxkru", "is_robot_indexable": true, "report_reasons": null, "author": "Giladkl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fxkru/why_we_built_a_streaming_sql_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.epsio.io/blog/why-we-built-a-streaming-sql-engine", "subreddit_subscribers": 145425, "created_utc": 1702309813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hullo Data Engineers,\n\nLooking for some guidance. I have a company approach me as an independant contractor, and want me to set up a full on DE infrastructure. This would be my first official contracting job and my plan is to implement something simple according to their needs, along these are the parts that I want to implement. In AWS (new instance):\n\n* PostgreSQL db to start with as a \"Warehouse\".\n* Metabase for visualization on top of the above\n* PG Admin for administration\n* S3 as a Storage/data lake solution\n* MWAA low cost to start with, they have several systems they need data from\n* CI/CD (For the pipelines mwaa to s3 with testing, etc)\n* IaC setup from the start. \n* IAM policies and whatnot\n\nAll in all very exciting, however, I am at a loss as to how much to charge for a full project like this. Any advise? I don't want to over shoot and/or undershoot as much as I can\n\nMany thanks in advance\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_5wyo5ojc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost advise for a project implementation as a consultant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fwab6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702306351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hullo Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;Looking for some guidance. I have a company approach me as an independant contractor, and want me to set up a full on DE infrastructure. This would be my first official contracting job and my plan is to implement something simple according to their needs, along these are the parts that I want to implement. In AWS (new instance):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;PostgreSQL db to start with as a &amp;quot;Warehouse&amp;quot;.&lt;/li&gt;\n&lt;li&gt;Metabase for visualization on top of the above&lt;/li&gt;\n&lt;li&gt;PG Admin for administration&lt;/li&gt;\n&lt;li&gt;S3 as a Storage/data lake solution&lt;/li&gt;\n&lt;li&gt;MWAA low cost to start with, they have several systems they need data from&lt;/li&gt;\n&lt;li&gt;CI/CD (For the pipelines mwaa to s3 with testing, etc)&lt;/li&gt;\n&lt;li&gt;IaC setup from the start. &lt;/li&gt;\n&lt;li&gt;IAM policies and whatnot&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All in all very exciting, however, I am at a loss as to how much to charge for a full project like this. Any advise? I don&amp;#39;t want to over shoot and/or undershoot as much as I can&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18fwab6", "is_robot_indexable": true, "report_reasons": null, "author": "alfredosuac", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18fwab6/cost_advise_for_a_project_implementation_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fwab6/cost_advise_for_a_project_implementation_as_a/", "subreddit_subscribers": 145425, "created_utc": 1702306351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used Facebook API before?\n\nI\u2019ve been off Facebook for months, because the ads and Watch were getting ridiculous.\n\n\nI\u2019m wondering what Facebook API\u2019s limitations are, because it seems like it\u2019d be really simple to build- I\u2019d like to basically browse without any ads or timeline \u201calgorithm\u201d- most recent friends posts sorted by date. Also add Events near me and filter by date once a week maybe. In theory if filtering out posts with less than x likes, it\u2019d take 5 minutes tops per week to get everything needed and none of the garbage. \n\nHas anyone used Facebook API before? I don\u2019t want to ask there because most people monetize and aren\u2019t going to be keen on someone trying to get around their ads.", "author_fullname": "t2_vgxtzjvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ft5sq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702296708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used Facebook API before?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been off Facebook for months, because the ads and Watch were getting ridiculous.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering what Facebook API\u2019s limitations are, because it seems like it\u2019d be really simple to build- I\u2019d like to basically browse without any ads or timeline \u201calgorithm\u201d- most recent friends posts sorted by date. Also add Events near me and filter by date once a week maybe. In theory if filtering out posts with less than x likes, it\u2019d take 5 minutes tops per week to get everything needed and none of the garbage. &lt;/p&gt;\n\n&lt;p&gt;Has anyone used Facebook API before? I don\u2019t want to ask there because most people monetize and aren\u2019t going to be keen on someone trying to get around their ads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ft5sq", "is_robot_indexable": true, "report_reasons": null, "author": "BestTomatillo6197", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ft5sq/facebook_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ft5sq/facebook_api/", "subreddit_subscribers": 145425, "created_utc": 1702296708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work on a global security team and am responsible for building a system that can be used to inform people of changes to different types of risk factors with latency on the order of 15 minutes.\n\nI probably don't need streaming, but, I still wonder if Kafka is something that I should have to make it easier to perform time-series data analytics compared to writing lots of one-off analytics jobs in Python.\n\nI can think of Kafka as being beneficial because it would allow me to create OLAP cubes with Pinot or perform streaming event correlation with Flink, but, since I don't need streaming, this might not be required at all - it's hard to say - just using dbt and DuckDB is probably more than good enough.\n\nI need to track metrics such as when new vulnerabilities are found, when the risk score of a given vulnerability changes, when a vulnerability scanner finishes running, etc., and could probably do all of this with microbatching rather than streaming.\n\nBut, does it still make sense to use Kafka as a layer of abstraction over time-series data?\n\nHere are a few other problems that I work on:\n\n* Batch jobs with multiple levels of event correlation (e.g. a user executed a command, the command resulted in the invocation of (N) subprocesses, these subprocesses produced (M) alerts, etc., but, from the perspective of better understanding what's detectable and what's not - I'm not doing incident response - more data science-y stuff).\n* Data warehousing for time-series data (e.g. historical views into attack surface in different areas of a network)\n* Anomaly detection over time-series data (e.g. out of these 10,000 security vulnerabilities, which have experienced a significant increase in predicted exploitability, which security vulnerabilities have received a significant increase in risk score, etc.).\n* Identifying gaps in sensor coverage in between vulnerability scans that run as batch jobs.\n\nI'm building everything greenfield and am looking at the following stack:\n\n* **Presto** \\+ **DuckDB** \\+ **dbt** and/or **S3** \\+ **Athena** \\+ **Glue** with **Parquet** files\n* **SeaweedFS** \\+ **RabbitMQ** for triggering dbt jobs, since I'd like to avoid loading data into a database until query time, and don't want materialized views - I want lots and lots of column-oriented files\n* **TimescaleDB** for relational and pure time-series analytics (i.e. **Postgres**)\n* **Neo4j** for a graph database - I like how its schemaless\n* **Temporal** and/or **Dagster** for workflow orchestration\n* **Metaflow** for machine learning jobs, Pandas, Pola.rs, Prophet, etc.\n* **ElasticSearch**, **Logstash**, **Kibana** \\- data will be normalized into Elastic Common Schema (ECS) and/or STIX 2.1 format, and ECS would be a great format to use when performing serverless event correlation with DuckDB, etc.\n* **Loki** for logs\n* **Prometheus** and **Grafana** for metrics (not sure what to use for long-term metric storage, maybe TimescaleDB)\n* **Access,** **Superset, Jupyter notebooks**, and **Quarto** for data exploration and visualization\n* **PowerBI** for reporting, since it's built into Microsoft 365\n* **Vagrant**, **Ansible**, **Consul**, **Vault**, **Nomad**, **Boundary** for infrastructure\n\nAgents, sensors, and microservices are written in Go and I'm still trying to figure out which protocol to use for C2 communication - gRPC seems like a good fit, but, so does RabbitMQ with ephemeral queues.\n\nI'd like to keep things as serverless as possible, but, also need to work in a hybrid cloud environment, including in airgapped environments, since I deal with ransomware among other things.\n\nI like how the following companies structure their analytics stacks:\n\n* Uber\n* Netflix\n* AirBnB", "author_fullname": "t2_lwr1wvz8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I deal with a few hundred million time-series data points but don't need streaming - should I still use Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g8z9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702343272.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702341159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on a global security team and am responsible for building a system that can be used to inform people of changes to different types of risk factors with latency on the order of 15 minutes.&lt;/p&gt;\n\n&lt;p&gt;I probably don&amp;#39;t need streaming, but, I still wonder if Kafka is something that I should have to make it easier to perform time-series data analytics compared to writing lots of one-off analytics jobs in Python.&lt;/p&gt;\n\n&lt;p&gt;I can think of Kafka as being beneficial because it would allow me to create OLAP cubes with Pinot or perform streaming event correlation with Flink, but, since I don&amp;#39;t need streaming, this might not be required at all - it&amp;#39;s hard to say - just using dbt and DuckDB is probably more than good enough.&lt;/p&gt;\n\n&lt;p&gt;I need to track metrics such as when new vulnerabilities are found, when the risk score of a given vulnerability changes, when a vulnerability scanner finishes running, etc., and could probably do all of this with microbatching rather than streaming.&lt;/p&gt;\n\n&lt;p&gt;But, does it still make sense to use Kafka as a layer of abstraction over time-series data?&lt;/p&gt;\n\n&lt;p&gt;Here are a few other problems that I work on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Batch jobs with multiple levels of event correlation (e.g. a user executed a command, the command resulted in the invocation of (N) subprocesses, these subprocesses produced (M) alerts, etc., but, from the perspective of better understanding what&amp;#39;s detectable and what&amp;#39;s not - I&amp;#39;m not doing incident response - more data science-y stuff).&lt;/li&gt;\n&lt;li&gt;Data warehousing for time-series data (e.g. historical views into attack surface in different areas of a network)&lt;/li&gt;\n&lt;li&gt;Anomaly detection over time-series data (e.g. out of these 10,000 security vulnerabilities, which have experienced a significant increase in predicted exploitability, which security vulnerabilities have received a significant increase in risk score, etc.).&lt;/li&gt;\n&lt;li&gt;Identifying gaps in sensor coverage in between vulnerability scans that run as batch jobs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m building everything greenfield and am looking at the following stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Presto&lt;/strong&gt; + &lt;strong&gt;DuckDB&lt;/strong&gt; + &lt;strong&gt;dbt&lt;/strong&gt; and/or &lt;strong&gt;S3&lt;/strong&gt; + &lt;strong&gt;Athena&lt;/strong&gt; + &lt;strong&gt;Glue&lt;/strong&gt; with &lt;strong&gt;Parquet&lt;/strong&gt; files&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;SeaweedFS&lt;/strong&gt; + &lt;strong&gt;RabbitMQ&lt;/strong&gt; for triggering dbt jobs, since I&amp;#39;d like to avoid loading data into a database until query time, and don&amp;#39;t want materialized views - I want lots and lots of column-oriented files&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;TimescaleDB&lt;/strong&gt; for relational and pure time-series analytics (i.e. &lt;strong&gt;Postgres&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt; for a graph database - I like how its schemaless&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Temporal&lt;/strong&gt; and/or &lt;strong&gt;Dagster&lt;/strong&gt; for workflow orchestration&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metaflow&lt;/strong&gt; for machine learning jobs, Pandas, Pola.rs, Prophet, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ElasticSearch&lt;/strong&gt;, &lt;strong&gt;Logstash&lt;/strong&gt;, &lt;strong&gt;Kibana&lt;/strong&gt; - data will be normalized into Elastic Common Schema (ECS) and/or STIX 2.1 format, and ECS would be a great format to use when performing serverless event correlation with DuckDB, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Loki&lt;/strong&gt; for logs&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt; and &lt;strong&gt;Grafana&lt;/strong&gt; for metrics (not sure what to use for long-term metric storage, maybe TimescaleDB)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Access,&lt;/strong&gt; &lt;strong&gt;Superset, Jupyter notebooks&lt;/strong&gt;, and &lt;strong&gt;Quarto&lt;/strong&gt; for data exploration and visualization&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;PowerBI&lt;/strong&gt; for reporting, since it&amp;#39;s built into Microsoft 365&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;, &lt;strong&gt;Ansible&lt;/strong&gt;, &lt;strong&gt;Consul&lt;/strong&gt;, &lt;strong&gt;Vault&lt;/strong&gt;, &lt;strong&gt;Nomad&lt;/strong&gt;, &lt;strong&gt;Boundary&lt;/strong&gt; for infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Agents, sensors, and microservices are written in Go and I&amp;#39;m still trying to figure out which protocol to use for C2 communication - gRPC seems like a good fit, but, so does RabbitMQ with ephemeral queues.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to keep things as serverless as possible, but, also need to work in a hybrid cloud environment, including in airgapped environments, since I deal with ransomware among other things.&lt;/p&gt;\n\n&lt;p&gt;I like how the following companies structure their analytics stacks:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Uber&lt;/li&gt;\n&lt;li&gt;Netflix&lt;/li&gt;\n&lt;li&gt;AirBnB&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g8z9k", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Importance-1605", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g8z9k/i_deal_with_a_few_hundred_million_timeseries_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g8z9k/i_deal_with_a_few_hundred_million_timeseries_data/", "subreddit_subscribers": 145425, "created_utc": 1702341159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i'm currently in my fifth year of school with a economics and cs dual degree. I work as a data analyst (not intern) at a pharmaceutical consulting company. I do a lot of excel, power BI, data processing, and help broker data deals between data vendors and buyers. I had a good connection so thats how I landed this job while still in school. I am just nervous that I am not getting the practical experience or learning the skills I should be doing to land a DE job. I am not sure what jobs/internships I should be looking for to put me on the path to become a DE. However, my boss has recently told me to experimenting with python as a tool for data analytics and how we can implement different strategies into the company. I get paid for this time and have been learning a lot which is good. I have been also learning SQL. I was thinking about bringing up to him the fact that I want to be a DE and how I can learn while working with the company to do this and possibly change my job title in the future. However, I feel like I would not be learning very good as we do not have any DE already. Should I stay at this role or start looking at applying for other jobs? Would it be a good idea to develop my skills and experience than start looking at DE roles? ", "author_fullname": "t2_2z2wymyd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some guidance on what path I should take", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g6eub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702334171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m currently in my fifth year of school with a economics and cs dual degree. I work as a data analyst (not intern) at a pharmaceutical consulting company. I do a lot of excel, power BI, data processing, and help broker data deals between data vendors and buyers. I had a good connection so thats how I landed this job while still in school. I am just nervous that I am not getting the practical experience or learning the skills I should be doing to land a DE job. I am not sure what jobs/internships I should be looking for to put me on the path to become a DE. However, my boss has recently told me to experimenting with python as a tool for data analytics and how we can implement different strategies into the company. I get paid for this time and have been learning a lot which is good. I have been also learning SQL. I was thinking about bringing up to him the fact that I want to be a DE and how I can learn while working with the company to do this and possibly change my job title in the future. However, I feel like I would not be learning very good as we do not have any DE already. Should I stay at this role or start looking at applying for other jobs? Would it be a good idea to develop my skills and experience than start looking at DE roles? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g6eub", "is_robot_indexable": true, "report_reasons": null, "author": "cailloudragonballs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g6eub/need_some_guidance_on_what_path_i_should_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g6eub/need_some_guidance_on_what_path_i_should_take/", "subreddit_subscribers": 145425, "created_utc": 1702334171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been going through a few rounds of interviews for my first DE job, and while Im excited to break in to that 'role' from where I'm at now, I'm a bit concerned with the QoL the company seems to have. \n\nMost reviews Ive seen say its a grind, and that it's nonstop - but none of those kinds of reviews exist for the DE team I'd be on - A PS team serving clients data needs and projects. \n\nOn top of that, there are some red flags Ive seen, like the person who would be my manager telling me \"*Our first core tenant is that we don't hire assholes*\". They also 'live on the bleeding edge' and aren't afraid to pivot to new tech asap if old tech isn't working out. I asked how they every skill up and get used to the inner workings of tools they're using if theyre changing tech every 3 months, but he gave a real non-answer.\n\n\nIt has a weirdly 'bro-culture' vibe, and though the glassdoor reviews aren't overtly negative (~3.6), [and actually higher than my current company I work at and like] I still have a weird vibe about the place. I'm just on the fence about it because of the red flags.\n \n**I know DE is usually seen as an internal role to get data to different teams for reporting, so I'm curious if anyone else has worked in a similar client-facing DE role and could talk about it.** \n\nIt'd be like a ~40% raise to what Im making now (putting me at around 130,000) and they use the tools I want to learn that I can't use in my current day to day job (PySpark/Hadoop, PyTorch, and others) so I figure I can grind it out a year to get the skills then bounce - but Im someone who is very focused on maintaining a WLB and it sounds like they don't really have one.", "author_fullname": "t2_f6oir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone do DE on a 'professional services' client-facing team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fxx4a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702310695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been going through a few rounds of interviews for my first DE job, and while Im excited to break in to that &amp;#39;role&amp;#39; from where I&amp;#39;m at now, I&amp;#39;m a bit concerned with the QoL the company seems to have. &lt;/p&gt;\n\n&lt;p&gt;Most reviews Ive seen say its a grind, and that it&amp;#39;s nonstop - but none of those kinds of reviews exist for the DE team I&amp;#39;d be on - A PS team serving clients data needs and projects. &lt;/p&gt;\n\n&lt;p&gt;On top of that, there are some red flags Ive seen, like the person who would be my manager telling me &amp;quot;&lt;em&gt;Our first core tenant is that we don&amp;#39;t hire assholes&lt;/em&gt;&amp;quot;. They also &amp;#39;live on the bleeding edge&amp;#39; and aren&amp;#39;t afraid to pivot to new tech asap if old tech isn&amp;#39;t working out. I asked how they every skill up and get used to the inner workings of tools they&amp;#39;re using if theyre changing tech every 3 months, but he gave a real non-answer.&lt;/p&gt;\n\n&lt;p&gt;It has a weirdly &amp;#39;bro-culture&amp;#39; vibe, and though the glassdoor reviews aren&amp;#39;t overtly negative (~3.6), [and actually higher than my current company I work at and like] I still have a weird vibe about the place. I&amp;#39;m just on the fence about it because of the red flags.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I know DE is usually seen as an internal role to get data to different teams for reporting, so I&amp;#39;m curious if anyone else has worked in a similar client-facing DE role and could talk about it.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d be like a ~40% raise to what Im making now (putting me at around 130,000) and they use the tools I want to learn that I can&amp;#39;t use in my current day to day job (PySpark/Hadoop, PyTorch, and others) so I figure I can grind it out a year to get the skills then bounce - but Im someone who is very focused on maintaining a WLB and it sounds like they don&amp;#39;t really have one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18fxx4a", "is_robot_indexable": true, "report_reasons": null, "author": "XxNerdAtHeartxX", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fxx4a/does_anyone_do_de_on_a_professional_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fxx4a/does_anyone_do_de_on_a_professional_services/", "subreddit_subscribers": 145425, "created_utc": 1702310695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you perform updates and deletes in a data warehouse? I've been told that temporality in a data warehouse should be handled through either temporal surrogation or data vault methods. Neither maintains an \"expired\" attribute.  \n ", "author_fullname": "t2_jg3w8gbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updates and Deletes in a Data Warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fubwe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702300627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you perform updates and deletes in a data warehouse? I&amp;#39;ve been told that temporality in a data warehouse should be handled through either temporal surrogation or data vault methods. Neither maintains an &amp;quot;expired&amp;quot; attribute.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18fubwe", "is_robot_indexable": true, "report_reasons": null, "author": "tamargal91", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fubwe/updates_and_deletes_in_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fubwe/updates_and_deletes_in_a_data_warehouse/", "subreddit_subscribers": 145425, "created_utc": 1702300627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My firm is looking to fill a new position. Because this person manipulates data without modeling it, the HIPPOS currently think the correct title is Data Engineer. I think this title is wrong and will make it harder to find the right person.\n\nThis job will: (1) gather requirements from the scientists (2) understand what's in the data stores (3) write study-specific Python/R pipelines to turn the data from the stores into the (generally highly specified) format the scientists need (4) make sure all the data from studies is put away safely unto future generations.\n\nSeems to me the following titles might be better:\n\n\\- Research software engineer -- except there aren't releases really, just pipelines that are sort of project-specific\n\n\\- Algorithm engineer -- covers that they will be manipulating numeric data and such. But, this often means fancy stuff like ML algorithms which won't be happening\n\n\\- Data analyst -- except the final analysis is by the scientists\n\n\\- Python/R software engineer -- I am leaning to this one although again, software products won't be shipping\n\nThank you for any thoughts and have a pleasant day.  \n", "author_fullname": "t2_2egw0f8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with title for \"data pipeline\" job position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3xxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702328101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My firm is looking to fill a new position. Because this person manipulates data without modeling it, the HIPPOS currently think the correct title is Data Engineer. I think this title is wrong and will make it harder to find the right person.&lt;/p&gt;\n\n&lt;p&gt;This job will: (1) gather requirements from the scientists (2) understand what&amp;#39;s in the data stores (3) write study-specific Python/R pipelines to turn the data from the stores into the (generally highly specified) format the scientists need (4) make sure all the data from studies is put away safely unto future generations.&lt;/p&gt;\n\n&lt;p&gt;Seems to me the following titles might be better:&lt;/p&gt;\n\n&lt;p&gt;- Research software engineer -- except there aren&amp;#39;t releases really, just pipelines that are sort of project-specific&lt;/p&gt;\n\n&lt;p&gt;- Algorithm engineer -- covers that they will be manipulating numeric data and such. But, this often means fancy stuff like ML algorithms which won&amp;#39;t be happening&lt;/p&gt;\n\n&lt;p&gt;- Data analyst -- except the final analysis is by the scientists&lt;/p&gt;\n\n&lt;p&gt;- Python/R software engineer -- I am leaning to this one although again, software products won&amp;#39;t be shipping&lt;/p&gt;\n\n&lt;p&gt;Thank you for any thoughts and have a pleasant day.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g3xxk", "is_robot_indexable": true, "report_reasons": null, "author": "edinburghpotsdam", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3xxk/struggling_with_title_for_data_pipeline_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3xxk/struggling_with_title_for_data_pipeline_job/", "subreddit_subscribers": 145425, "created_utc": 1702328101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a freelancer and this is my first job and I don\u2019t know how to collect the data the client needs. Is it something that can be done? \n\nHere is whole story\n\u201cI'm looking for a person who can do a very specific task. Your profile tells me that you may be the right person. In principle it is like this: Messages are posted in a Telegram channel (always in the same format). These messages contain information in the form of numbers and possibly text. This information should be extracted as soon as the post enters the channel and entered into a database. This database should then be calculated and evaluated so that a live time web dashboard shows insights. The customers who are on my website should be able to view the dashboard on my website. Of course, the dashboard should always be up to date. The amount of data is extremely small and the statistical analysis requires little effort, as it only involves simple insights. Am I at the right place with you or should I look for someone else?\u201d \n\nHow can I start ?", "author_fullname": "t2_fxlwknu3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help/ my first project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3tu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702327813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a freelancer and this is my first job and I don\u2019t know how to collect the data the client needs. Is it something that can be done? &lt;/p&gt;\n\n&lt;p&gt;Here is whole story\n\u201cI&amp;#39;m looking for a person who can do a very specific task. Your profile tells me that you may be the right person. In principle it is like this: Messages are posted in a Telegram channel (always in the same format). These messages contain information in the form of numbers and possibly text. This information should be extracted as soon as the post enters the channel and entered into a database. This database should then be calculated and evaluated so that a live time web dashboard shows insights. The customers who are on my website should be able to view the dashboard on my website. Of course, the dashboard should always be up to date. The amount of data is extremely small and the statistical analysis requires little effort, as it only involves simple insights. Am I at the right place with you or should I look for someone else?\u201d &lt;/p&gt;\n\n&lt;p&gt;How can I start ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g3tu5", "is_robot_indexable": true, "report_reasons": null, "author": "AvailableField7708", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3tu5/help_my_first_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3tu5/help_my_first_project/", "subreddit_subscribers": 145425, "created_utc": 1702327813.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer working in Snowflake/dbt and part of my role is supporting two business analysts who build Tableau dashboards. Small data team, so I'm the Tableau admin as I used to be the one and only analyst. Right now, I build them whatever data sources they need in a presentation-layer Snowflake database. They connect Tableau to Snowflake and do an extract. While this works, it seems to lead to lots of extract duplication as they will use the same tables over and over for different dashboards. My thought is that I could create a single extract for each Presentation-layer table via a Tableau Virtual Connection (or whatever PBI equivalent is, chance we may end up switching next year). With this approach, I'd cut down on duplicate extracts and could even link to dbt documentation in the data source description. Using a VC, they can still join tables together within Tableau.\n\nI'm curious how everyone else handles this as BI scales within an organization, especially a non-technical one.", "author_fullname": "t2_ee8slplxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for exposing DWH tables to Tableau/Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g30px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702325815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer working in Snowflake/dbt and part of my role is supporting two business analysts who build Tableau dashboards. Small data team, so I&amp;#39;m the Tableau admin as I used to be the one and only analyst. Right now, I build them whatever data sources they need in a presentation-layer Snowflake database. They connect Tableau to Snowflake and do an extract. While this works, it seems to lead to lots of extract duplication as they will use the same tables over and over for different dashboards. My thought is that I could create a single extract for each Presentation-layer table via a Tableau Virtual Connection (or whatever PBI equivalent is, chance we may end up switching next year). With this approach, I&amp;#39;d cut down on duplicate extracts and could even link to dbt documentation in the data source description. Using a VC, they can still join tables together within Tableau.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how everyone else handles this as BI scales within an organization, especially a non-technical one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g30px", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Huckleberry-55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g30px/best_practices_for_exposing_dwh_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g30px/best_practices_for_exposing_dwh_tables_to/", "subreddit_subscribers": 145425, "created_utc": 1702325815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI am no newbie to data migration using AWS tech and more. However, I would love to pick the brain of someone who is working with a reliable stack that serves a Business Intelligence team or Data Warehouse population.\n\nWould anyone care to meet on discord to discuss such topics? If you're company is using a combination of AWS and open-source tools to get the job done, and the job IS getting done, I really want to chat with you. The one constraint I would add is that I am not interested in any tooling that requires sending your data to a third-party network for treatment.\n\nTo be clear: I am not looking for work, I am not selling anything, and I am not a beginner. I am sincerely looking for advice and use cases to enrich my understanding in this field.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Request for mentor in AWS Land (for intermediate-advanced topics)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g00ax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702317252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I am no newbie to data migration using AWS tech and more. However, I would love to pick the brain of someone who is working with a reliable stack that serves a Business Intelligence team or Data Warehouse population.&lt;/p&gt;\n\n&lt;p&gt;Would anyone care to meet on discord to discuss such topics? If you&amp;#39;re company is using a combination of AWS and open-source tools to get the job done, and the job IS getting done, I really want to chat with you. The one constraint I would add is that I am not interested in any tooling that requires sending your data to a third-party network for treatment.&lt;/p&gt;\n\n&lt;p&gt;To be clear: I am not looking for work, I am not selling anything, and I am not a beginner. I am sincerely looking for advice and use cases to enrich my understanding in this field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g00ax", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g00ax/request_for_mentor_in_aws_land_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g00ax/request_for_mentor_in_aws_land_for/", "subreddit_subscribers": 145425, "created_utc": 1702317252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi \n\nwhat is the difference between running the query in bigquery or running it using one of the editor such as datagrip or dbvisualizer? \n\nis it cheaper? faster?\n\nwhy people don\u2019t just use bigquery?", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery Computing Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18fpiih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702281816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi &lt;/p&gt;\n\n&lt;p&gt;what is the difference between running the query in bigquery or running it using one of the editor such as datagrip or dbvisualizer? &lt;/p&gt;\n\n&lt;p&gt;is it cheaper? faster?&lt;/p&gt;\n\n&lt;p&gt;why people don\u2019t just use bigquery?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18fpiih", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18fpiih/bigquery_computing_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18fpiih/bigquery_computing_cost/", "subreddit_subscribers": 145425, "created_utc": 1702281816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nI am a employee in an MNC having 2.5 years of experience and currently working on a support based project with the tech stack as webmethods which is a integration tool based out of Java and it is being to connect different systems / businesses. I'm bored and frustrated at the same time because the work is same and almost repetitive with no signs of growth and learning. That's when I decided to switch domain but\n\nI was very confused while choosing between Data Engineering and Java. But I choose Data Engineering and started preparing for it. I currently have experience with python easy to medium, SQL mid to advance level and achieved two cloud certifications AZ-900 &amp; AZ-204 currently preparing for DP-203. I have basic knowledge and hands-on azure df, Synapse and storage. \n\nI tried looking for jobs matching my skills but whenever I started checking the job description I always lack in some or the other skills such as Big data and Spark. So if someone can guide me to tackel with this and land a job in data engineer domain it would be a great help. \n\nThanks in Advance :)", "author_fullname": "t2_ib9mu62z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Carrer switch to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18frtzg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702291672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;I am a employee in an MNC having 2.5 years of experience and currently working on a support based project with the tech stack as webmethods which is a integration tool based out of Java and it is being to connect different systems / businesses. I&amp;#39;m bored and frustrated at the same time because the work is same and almost repetitive with no signs of growth and learning. That&amp;#39;s when I decided to switch domain but&lt;/p&gt;\n\n&lt;p&gt;I was very confused while choosing between Data Engineering and Java. But I choose Data Engineering and started preparing for it. I currently have experience with python easy to medium, SQL mid to advance level and achieved two cloud certifications AZ-900 &amp;amp; AZ-204 currently preparing for DP-203. I have basic knowledge and hands-on azure df, Synapse and storage. &lt;/p&gt;\n\n&lt;p&gt;I tried looking for jobs matching my skills but whenever I started checking the job description I always lack in some or the other skills such as Big data and Spark. So if someone can guide me to tackel with this and land a job in data engineer domain it would be a great help. &lt;/p&gt;\n\n&lt;p&gt;Thanks in Advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18frtzg", "is_robot_indexable": true, "report_reasons": null, "author": "iamDjsahu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18frtzg/carrer_switch_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18frtzg/carrer_switch_to_data_engineering/", "subreddit_subscribers": 145425, "created_utc": 1702291672.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}