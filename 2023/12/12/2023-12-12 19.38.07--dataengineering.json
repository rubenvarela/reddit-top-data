{"kind": "Listing", "data": {"after": "t3_18gk992", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just accepted a data engineering job. Talked about graph databases, unstructured data, python, DAGs, etc during the interview. \n\nDay one I'm told the job will be making dashboards in tableau under the direction of senior data scientist. \n\nWhy?", "author_fullname": "t2_769lgtz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do job descriptions demand skills that are not at all needed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gfpn9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702362999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just accepted a data engineering job. Talked about graph databases, unstructured data, python, DAGs, etc during the interview. &lt;/p&gt;\n\n&lt;p&gt;Day one I&amp;#39;m told the job will be making dashboards in tableau under the direction of senior data scientist. &lt;/p&gt;\n\n&lt;p&gt;Why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18gfpn9", "is_robot_indexable": true, "report_reasons": null, "author": "FisterAct", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gfpn9/why_do_job_descriptions_demand_skills_that_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gfpn9/why_do_job_descriptions_demand_skills_that_are/", "subreddit_subscribers": 145590, "created_utc": 1702362999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Although I work as a Machine Learning Engineer, sometimes I'm requested to build some queries, for instance for dashboarding purposes.\n\nHowever, I find it really tedious when working with SQL. My main reasons being:\n\n1. Most of the times we work with tables in the DataLake we don't own, hence it takes an awful lot of time to get an understanding of how that data is structured (and what kind of data problems it might have)\n2. I feel really unproductive having to wait for query results. It really slows down any kind of exploration one might want do with the data like one would with tools like Pandas or Polars (and loading data locally is not an option as we're talking of billions of records here, which we're handling with Spark)\n3. Sometimes queries grow to be extremely complex, which makes it harder for team mates to review\n4. Along the previous point, I really feel SQL is extremely unreadable as compared to a programming language", "author_fullname": "t2_21rg1aff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you make working with SQL enjoyable (or less tedious)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gn43u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702391339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Although I work as a Machine Learning Engineer, sometimes I&amp;#39;m requested to build some queries, for instance for dashboarding purposes.&lt;/p&gt;\n\n&lt;p&gt;However, I find it really tedious when working with SQL. My main reasons being:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Most of the times we work with tables in the DataLake we don&amp;#39;t own, hence it takes an awful lot of time to get an understanding of how that data is structured (and what kind of data problems it might have)&lt;/li&gt;\n&lt;li&gt;I feel really unproductive having to wait for query results. It really slows down any kind of exploration one might want do with the data like one would with tools like Pandas or Polars (and loading data locally is not an option as we&amp;#39;re talking of billions of records here, which we&amp;#39;re handling with Spark)&lt;/li&gt;\n&lt;li&gt;Sometimes queries grow to be extremely complex, which makes it harder for team mates to review&lt;/li&gt;\n&lt;li&gt;Along the previous point, I really feel SQL is extremely unreadable as compared to a programming language&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gn43u", "is_robot_indexable": true, "report_reasons": null, "author": "barberogaston", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gn43u/how_do_you_make_working_with_sql_enjoyable_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gn43u/how_do_you_make_working_with_sql_enjoyable_or/", "subreddit_subscribers": 145590, "created_utc": 1702391339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a few years of experience as a low level data analyst and a year of data engineering. I\u2019ve been doing leetcode to prepare for a move to SWE. Today my company announced a reorg back to data ops. We are expecting to train our replacements and get laid off. \nAs the junior dev market is dead right now should I consider going back to school for a BS in CS? I have a business degree and data engineering seems suboptimal compared to back end dev to me.", "author_fullname": "t2_cimoe09n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expecting a layoff - should I go back to school?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g8ey3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702339565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few years of experience as a low level data analyst and a year of data engineering. I\u2019ve been doing leetcode to prepare for a move to SWE. Today my company announced a reorg back to data ops. We are expecting to train our replacements and get laid off. \nAs the junior dev market is dead right now should I consider going back to school for a BS in CS? I have a business degree and data engineering seems suboptimal compared to back end dev to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18g8ey3", "is_robot_indexable": true, "report_reasons": null, "author": "OkMacaron493", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g8ey3/expecting_a_layoff_should_i_go_back_to_school/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g8ey3/expecting_a_layoff_should_i_go_back_to_school/", "subreddit_subscribers": 145590, "created_utc": 1702339565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a (light-hearted) roast at work where Data Scientists poke fun at Data Engineers and vice versa. Any suggestions for content that would roast Data Engineers? \n\nAs an example, I plan to poke some fun at all the lingo Data Engineers throw around at daily stand-ups from using 30 AWS services.", "author_fullname": "t2_mvj12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Roast Content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3odg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702327427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a (light-hearted) roast at work where Data Scientists poke fun at Data Engineers and vice versa. Any suggestions for content that would roast Data Engineers? &lt;/p&gt;\n\n&lt;p&gt;As an example, I plan to poke some fun at all the lingo Data Engineers throw around at daily stand-ups from using 30 AWS services.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g3odg", "is_robot_indexable": true, "report_reasons": null, "author": "succulentBroccoli", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3odg/de_roast_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3odg/de_roast_content/", "subreddit_subscribers": 145590, "created_utc": 1702327427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work on a global security team and am responsible for building a system that can be used to inform people of changes to different types of risk factors with latency on the order of 15 minutes.\n\nI probably don't need streaming, but, I still wonder if Kafka is something that I should have to make it easier to perform time-series data analytics compared to writing lots of one-off analytics jobs in Python.\n\nI can think of Kafka as being beneficial because it would allow me to create OLAP cubes with Pinot or perform streaming event correlation with Flink, but, since I don't need streaming, this might not be required at all - it's hard to say - just using dagster, dbt, DuckDB, and Superset is probably more than good enough.\n\nI need to track metrics such as when new vulnerabilities are found, when the risk score of a given vulnerability changes, when a vulnerability scanner finishes running, etc., and could probably do all of this with microbatching rather than streaming.\n\nBut, does it still make sense to use Kafka as a layer of abstraction over time-series data?\n\nHere are a few other problems that I work on:\n\n* Batch jobs with multiple levels of event correlation (e.g. a user executed a command, the command resulted in the invocation of (N) subprocesses, these subprocesses produced (M) alerts, etc., but, from the perspective of better understanding what's detectable and what's not - I'm not doing incident response - more data science-y stuff).\n* Data warehousing for time-series data (e.g. historical views into attack surface in different areas of a network)\n* Anomaly detection over time-series data (e.g. out of these 10,000 security vulnerabilities, which have experienced a significant increase in predicted exploitability, which security vulnerabilities have received a significant increase in risk score, etc.).\n* Identifying gaps in sensor coverage in between vulnerability scans that run as batch jobs.\n\nI'm building everything greenfield and am looking at the following stack:\n\n* **~~Presto~~** \\+ **DuckDB** \\+ **dbt** and/or **S3** \\+ **Athena** \\+ **Glue** with **Parquet** files\n* **~~SeaweedFS~~** ~~+~~ **~~RabbitMQ~~** ~~for triggering dbt jobs, since I'd like to avoid loading data into a database until query time, and don't want materialized views - I want lots and lots of column-oriented files~~\n* **TimescaleDB** for relational and pure time-series analytics (i.e. **Postgres**)\n* **Neo4j** for a graph database - I like how its schemaless\n* **Temporal** and/or **Dagster** for workflow orchestration\n* **Metaflow** for machine learning jobs, Pandas, Pola.rs, Prophet, etc.\n* **ElasticSearch**, **Logstash**, **Kibana** \\- data will be normalized into Elastic Common Schema (ECS) and/or STIX 2.1 format, and ECS would be a great format to use when performing serverless event correlation with DuckDB, etc.\n* **Loki** or **Fluentd** for logs\n* **Prometheus** and **Grafana** for metrics (not sure what to use for long-term metric storage, maybe TimescaleDB)\n* **Access,** **Superset, Jupyter notebooks**, and **Quarto** for data exploration and visualization\n* **PowerBI** for reporting, since it's built into Microsoft 365\n* **Vagrant**, **Ansible**, **~~Consul~~**, **Vault**, **Nomad**, **Boundary** for infrastructure\n\nAgents, sensors, and microservices are written in Go and I'm still trying to figure out which protocol to use for C2 communication - gRPC seems like a good fit, but, so does RabbitMQ with ephemeral queues.\n\nI'd like to keep things as serverless as possible, but, also need to work in a hybrid cloud environment, including in airgapped environments, since I deal with ransomware among other things.\n\nI like how the following companies structure their analytics stacks:\n\n* Uber\n* Netflix\n* AirBnB", "author_fullname": "t2_lwr1wvz8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I deal with a few hundred million time-series data points but don't need streaming - should I still use Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g8z9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702382545.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702341159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on a global security team and am responsible for building a system that can be used to inform people of changes to different types of risk factors with latency on the order of 15 minutes.&lt;/p&gt;\n\n&lt;p&gt;I probably don&amp;#39;t need streaming, but, I still wonder if Kafka is something that I should have to make it easier to perform time-series data analytics compared to writing lots of one-off analytics jobs in Python.&lt;/p&gt;\n\n&lt;p&gt;I can think of Kafka as being beneficial because it would allow me to create OLAP cubes with Pinot or perform streaming event correlation with Flink, but, since I don&amp;#39;t need streaming, this might not be required at all - it&amp;#39;s hard to say - just using dagster, dbt, DuckDB, and Superset is probably more than good enough.&lt;/p&gt;\n\n&lt;p&gt;I need to track metrics such as when new vulnerabilities are found, when the risk score of a given vulnerability changes, when a vulnerability scanner finishes running, etc., and could probably do all of this with microbatching rather than streaming.&lt;/p&gt;\n\n&lt;p&gt;But, does it still make sense to use Kafka as a layer of abstraction over time-series data?&lt;/p&gt;\n\n&lt;p&gt;Here are a few other problems that I work on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Batch jobs with multiple levels of event correlation (e.g. a user executed a command, the command resulted in the invocation of (N) subprocesses, these subprocesses produced (M) alerts, etc., but, from the perspective of better understanding what&amp;#39;s detectable and what&amp;#39;s not - I&amp;#39;m not doing incident response - more data science-y stuff).&lt;/li&gt;\n&lt;li&gt;Data warehousing for time-series data (e.g. historical views into attack surface in different areas of a network)&lt;/li&gt;\n&lt;li&gt;Anomaly detection over time-series data (e.g. out of these 10,000 security vulnerabilities, which have experienced a significant increase in predicted exploitability, which security vulnerabilities have received a significant increase in risk score, etc.).&lt;/li&gt;\n&lt;li&gt;Identifying gaps in sensor coverage in between vulnerability scans that run as batch jobs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m building everything greenfield and am looking at the following stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;del&gt;Presto&lt;/del&gt;&lt;/strong&gt; + &lt;strong&gt;DuckDB&lt;/strong&gt; + &lt;strong&gt;dbt&lt;/strong&gt; and/or &lt;strong&gt;S3&lt;/strong&gt; + &lt;strong&gt;Athena&lt;/strong&gt; + &lt;strong&gt;Glue&lt;/strong&gt; with &lt;strong&gt;Parquet&lt;/strong&gt; files&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;del&gt;SeaweedFS&lt;/del&gt;&lt;/strong&gt; &lt;del&gt;+&lt;/del&gt; &lt;strong&gt;&lt;del&gt;RabbitMQ&lt;/del&gt;&lt;/strong&gt; &lt;del&gt;for triggering dbt jobs, since I&amp;#39;d like to avoid loading data into a database until query time, and don&amp;#39;t want materialized views - I want lots and lots of column-oriented files&lt;/del&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;TimescaleDB&lt;/strong&gt; for relational and pure time-series analytics (i.e. &lt;strong&gt;Postgres&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt; for a graph database - I like how its schemaless&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Temporal&lt;/strong&gt; and/or &lt;strong&gt;Dagster&lt;/strong&gt; for workflow orchestration&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metaflow&lt;/strong&gt; for machine learning jobs, Pandas, Pola.rs, Prophet, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ElasticSearch&lt;/strong&gt;, &lt;strong&gt;Logstash&lt;/strong&gt;, &lt;strong&gt;Kibana&lt;/strong&gt; - data will be normalized into Elastic Common Schema (ECS) and/or STIX 2.1 format, and ECS would be a great format to use when performing serverless event correlation with DuckDB, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Loki&lt;/strong&gt; or &lt;strong&gt;Fluentd&lt;/strong&gt; for logs&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt; and &lt;strong&gt;Grafana&lt;/strong&gt; for metrics (not sure what to use for long-term metric storage, maybe TimescaleDB)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Access,&lt;/strong&gt; &lt;strong&gt;Superset, Jupyter notebooks&lt;/strong&gt;, and &lt;strong&gt;Quarto&lt;/strong&gt; for data exploration and visualization&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;PowerBI&lt;/strong&gt; for reporting, since it&amp;#39;s built into Microsoft 365&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;, &lt;strong&gt;Ansible&lt;/strong&gt;, &lt;strong&gt;&lt;del&gt;Consul&lt;/del&gt;&lt;/strong&gt;, &lt;strong&gt;Vault&lt;/strong&gt;, &lt;strong&gt;Nomad&lt;/strong&gt;, &lt;strong&gt;Boundary&lt;/strong&gt; for infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Agents, sensors, and microservices are written in Go and I&amp;#39;m still trying to figure out which protocol to use for C2 communication - gRPC seems like a good fit, but, so does RabbitMQ with ephemeral queues.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to keep things as serverless as possible, but, also need to work in a hybrid cloud environment, including in airgapped environments, since I deal with ransomware among other things.&lt;/p&gt;\n\n&lt;p&gt;I like how the following companies structure their analytics stacks:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Uber&lt;/li&gt;\n&lt;li&gt;Netflix&lt;/li&gt;\n&lt;li&gt;AirBnB&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g8z9k", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Importance-1605", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18g8z9k/i_deal_with_a_few_hundred_million_timeseries_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g8z9k/i_deal_with_a_few_hundred_million_timeseries_data/", "subreddit_subscribers": 145590, "created_utc": 1702341159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wanted to have a discussion with folks with experienced similar things but getting burned out working with messy data. There\u2019s always something that the business wants to add the data is either incomplete or it doesn\u2019t jam with the data model because it\u2019s at a different grain. You can speak up as much as you want but the business just claims it\u2019s super important and so you make an exception to the rule only to have more crappy data come in and screw up an entire data model that you\u2019ve built. \n\nNot looking for any advice, I would just like to hear everyone\u2019s story.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Burnout", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g6a5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702333835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to have a discussion with folks with experienced similar things but getting burned out working with messy data. There\u2019s always something that the business wants to add the data is either incomplete or it doesn\u2019t jam with the data model because it\u2019s at a different grain. You can speak up as much as you want but the business just claims it\u2019s super important and so you make an exception to the rule only to have more crappy data come in and screw up an entire data model that you\u2019ve built. &lt;/p&gt;\n\n&lt;p&gt;Not looking for any advice, I would just like to hear everyone\u2019s story.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g6a5o", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g6a5o/data_burnout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g6a5o/data_burnout/", "subreddit_subscribers": 145590, "created_utc": 1702333835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data in S3 like this (for example)\n\n&amp;#x200B;\n\n|NAME|COUNTRY|SOMETHING|OPERATION|TIMESTAMP|\n|:-|:-|:-|:-|:-|\n|steve|usa|hello|insert|1702390270|\n|joe|canada|hi|insert|1702390271|\n|steve|usa|howdy|update|1702390272|\n\nWhat is the fastest way that you would get this data into Redshit BUT with the final table \"deduplicated\"? (that is, where Steve only appears once and with value for \\`something\\` field being \\`howdy\\`)\n\nEDIT: This may seem like something I can google, but it's not. We actually already achieve this in a couple of ways, but we are not happy with latency. This question was more to see how *you* achieve something like this. Please and thank you.\n\nEDIT: Thanks to a commenter, I realize that I failed to include a timestamp column in my example, making this question very confusing. I'm sorry.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data from S3 to Redshift, but Deduplicated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g1mam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702390286.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702322434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data in S3 like this (for example)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;NAME&lt;/th&gt;\n&lt;th align=\"left\"&gt;COUNTRY&lt;/th&gt;\n&lt;th align=\"left\"&gt;SOMETHING&lt;/th&gt;\n&lt;th align=\"left\"&gt;OPERATION&lt;/th&gt;\n&lt;th align=\"left\"&gt;TIMESTAMP&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;steve&lt;/td&gt;\n&lt;td align=\"left\"&gt;usa&lt;/td&gt;\n&lt;td align=\"left\"&gt;hello&lt;/td&gt;\n&lt;td align=\"left\"&gt;insert&lt;/td&gt;\n&lt;td align=\"left\"&gt;1702390270&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;joe&lt;/td&gt;\n&lt;td align=\"left\"&gt;canada&lt;/td&gt;\n&lt;td align=\"left\"&gt;hi&lt;/td&gt;\n&lt;td align=\"left\"&gt;insert&lt;/td&gt;\n&lt;td align=\"left\"&gt;1702390271&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;steve&lt;/td&gt;\n&lt;td align=\"left\"&gt;usa&lt;/td&gt;\n&lt;td align=\"left\"&gt;howdy&lt;/td&gt;\n&lt;td align=\"left\"&gt;update&lt;/td&gt;\n&lt;td align=\"left\"&gt;1702390272&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;What is the fastest way that you would get this data into Redshit BUT with the final table &amp;quot;deduplicated&amp;quot;? (that is, where Steve only appears once and with value for `something` field being `howdy`)&lt;/p&gt;\n\n&lt;p&gt;EDIT: This may seem like something I can google, but it&amp;#39;s not. We actually already achieve this in a couple of ways, but we are not happy with latency. This question was more to see how &lt;em&gt;you&lt;/em&gt; achieve something like this. Please and thank you.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Thanks to a commenter, I realize that I failed to include a timestamp column in my example, making this question very confusing. I&amp;#39;m sorry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g1mam", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g1mam/data_from_s3_to_redshift_but_deduplicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g1mam/data_from_s3_to_redshift_but_deduplicated/", "subreddit_subscribers": 145590, "created_utc": 1702322434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m helping a friend who\u2019s writing a paper on a hospital dataset he found. I promised him that would help do some data analysis (I have a data science background), but didn\u2019t expect the dataset to be so big. It\u2019s basically 4 csv files all zipped. Unzipped 3 of them are roughly 20GB each, while the fourth one was only 1GB. Usually when I had to deal with datasets this large it was already in sql so it was much easier to look at. At the moment I can\u2019t even unzip the files on my computer. Any takes on how to get started? I have an AWS account (from my startup) with some credit I can use. I already uploaded the 1GB files into s3 then amazon redshift. Would love to do the same for the other files but open to more ideas", "author_fullname": "t2_tm2yzhjm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opening a giant dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gb7dp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702347853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m helping a friend who\u2019s writing a paper on a hospital dataset he found. I promised him that would help do some data analysis (I have a data science background), but didn\u2019t expect the dataset to be so big. It\u2019s basically 4 csv files all zipped. Unzipped 3 of them are roughly 20GB each, while the fourth one was only 1GB. Usually when I had to deal with datasets this large it was already in sql so it was much easier to look at. At the moment I can\u2019t even unzip the files on my computer. Any takes on how to get started? I have an AWS account (from my startup) with some credit I can use. I already uploaded the 1GB files into s3 then amazon redshift. Would love to do the same for the other files but open to more ideas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gb7dp", "is_robot_indexable": true, "report_reasons": null, "author": "vald_eagle", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gb7dp/opening_a_giant_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gb7dp/opening_a_giant_dataset/", "subreddit_subscribers": 145590, "created_utc": 1702347853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My firm is looking to fill a new position. Because this person manipulates data without modeling it, the HIPPOS currently think the correct title is Data Engineer. I think this title is wrong and will make it harder to find the right person.\n\nThis job will: (1) gather requirements from the scientists (2) understand what's in the data stores (3) write study-specific Python/R pipelines to turn the data from the stores into the (generally highly specified) format the scientists need (4) make sure all the data from studies is put away safely unto future generations.\n\nSeems to me the following titles might be better:\n\n\\- Research software engineer -- except there aren't releases really, just pipelines that are sort of project-specific\n\n\\- Algorithm engineer -- covers that they will be manipulating numeric data and such. But, this often means fancy stuff like ML algorithms which won't be happening\n\n\\- Data analyst -- except the final analysis is by the scientists\n\n\\- Python/R software engineer -- I am leaning to this one although again, software products won't be shipping\n\nThank you for any thoughts and have a pleasant day.  \n", "author_fullname": "t2_2egw0f8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with title for \"data pipeline\" job position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3xxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702328101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My firm is looking to fill a new position. Because this person manipulates data without modeling it, the HIPPOS currently think the correct title is Data Engineer. I think this title is wrong and will make it harder to find the right person.&lt;/p&gt;\n\n&lt;p&gt;This job will: (1) gather requirements from the scientists (2) understand what&amp;#39;s in the data stores (3) write study-specific Python/R pipelines to turn the data from the stores into the (generally highly specified) format the scientists need (4) make sure all the data from studies is put away safely unto future generations.&lt;/p&gt;\n\n&lt;p&gt;Seems to me the following titles might be better:&lt;/p&gt;\n\n&lt;p&gt;- Research software engineer -- except there aren&amp;#39;t releases really, just pipelines that are sort of project-specific&lt;/p&gt;\n\n&lt;p&gt;- Algorithm engineer -- covers that they will be manipulating numeric data and such. But, this often means fancy stuff like ML algorithms which won&amp;#39;t be happening&lt;/p&gt;\n\n&lt;p&gt;- Data analyst -- except the final analysis is by the scientists&lt;/p&gt;\n\n&lt;p&gt;- Python/R software engineer -- I am leaning to this one although again, software products won&amp;#39;t be shipping&lt;/p&gt;\n\n&lt;p&gt;Thank you for any thoughts and have a pleasant day.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g3xxk", "is_robot_indexable": true, "report_reasons": null, "author": "edinburghpotsdam", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3xxk/struggling_with_title_for_data_pipeline_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3xxk/struggling_with_title_for_data_pipeline_job/", "subreddit_subscribers": 145590, "created_utc": 1702328101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Data Processing with Ray Data and MinIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": true, "name": "t3_18gskm2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uzAf_NxB0nLPzpd6yZHTuYbIip8pyxSiP67aPyuEhSU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702405394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?auto=webp&amp;s=60a9a5bb13ad52dc6f983d22a24a53b3b835a119", "width": 1200, "height": 359}, "resolutions": [{"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db2aa38b11de95fa42f9dbf716d73c3b2a64e4f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c18b4e8bc4062930b8490b5721bf20e5d91b96a", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e065467bf6807e1f7014eb05a7e8aef79c5b4e88", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74d1b5b114a455946e7c372fa0cc71907ebdd6dd", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d0ea6ae4d3f00a6c97c690b38471318183ee2c8", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=011a2c8ca8070e4782e8cf151170e64f2db7fd85", "width": 1080, "height": 323}], "variants": {}, "id": "ycJVbgf3bDDq06hpn_WuGtC2gZGgwo5DkVBTrJOe5j8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gskm2", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gskm2/distributed_data_processing_with_ray_data_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=ray_data_and_minio", "subreddit_subscribers": 145590, "created_utc": 1702405394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been modeling NBA data for a couple months, and this is one of my favorite insights so far!\n\n\\- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python  \n\\- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp; Snowflake (Production)  \n\\- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: [paradime.io](https://www.linkedin.com/company/paradimelabs/) (dbt)  \n\\- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - [Lightdash](https://www.linkedin.com/company/lightdash/)\n\nSo, why do the Jazz have the lowest avg. cost per win?  \n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&gt; Malone, Great home-court advantage, stable coaching.  \n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)  \n\ud83e\ude84 Salt Lake City doesn't attract top (expensive) NBA talent \ud83e\udd23  \n\ud83e\ude84 Consistent &amp; competent leadership  \nSeparate note - I'm still shocked by how terrible the Knicks have been historically. They're the biggest market, they're willing to spend (obviously) yet they can't pull it together... Ever\n\nYou can find, critique, and contribute to my NBA project here: [https://github.com/jpooksy/NBA\\_Data\\_Modeling](https://github.com/jpooksy/NBA_Data_Modeling)  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA data modeling wth dbt + Paradime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"lrw4oybekw5c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 130, "x": 108, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49598bbed60ac1dfad30e730226a940d1617ac82"}, {"y": 261, "x": 216, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2633eed8b2e34880131642200e2dacb2083d1b71"}, {"y": 386, "x": 320, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1ad4371601d2889998d2164deba121e4f822f96"}], "s": {"y": 682, "x": 564, "u": "https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;format=png&amp;auto=webp&amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960"}, "id": "lrw4oybekw5c1"}}, "name": "t3_18grxlj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_pUtcBckyyefRo0H27ezy2qeaxhbYnsrdXQXQjFIhAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702403763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been modeling NBA data for a couple months, and this is one of my favorite insights so far!&lt;/p&gt;\n\n&lt;p&gt;- \ud835\udc08\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27: public NBA API + Python&lt;br/&gt;\n- \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e: DuckDB (development) &amp;amp; Snowflake (Production)&lt;br/&gt;\n- \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c: &lt;a href=\"https://www.linkedin.com/company/paradimelabs/\"&gt;paradime.io&lt;/a&gt; (dbt)&lt;br/&gt;\n- \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc2f\ud835\udc22\ud835\udc27\ud835\udc20 (\ud835\udc01\ud835\udc08) - &lt;a href=\"https://www.linkedin.com/company/lightdash/\"&gt;Lightdash&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So, why do the Jazz have the lowest avg. cost per win?&lt;br/&gt;\n\ud83e\ude84 2nd most regular-season wins since 1990. This is due to many factors, including: Stockton -&amp;gt; Malone, Great home-court advantage, stable coaching.&lt;br/&gt;\n\ud83e\ude84 7th lowest luxury tax bill since 1990 (out of 30 teams)&lt;br/&gt;\n\ud83e\ude84 Salt Lake City doesn&amp;#39;t attract top (expensive) NBA talent \ud83e\udd23&lt;br/&gt;\n\ud83e\ude84 Consistent &amp;amp; competent leadership&lt;br/&gt;\nSeparate note - I&amp;#39;m still shocked by how terrible the Knicks have been historically. They&amp;#39;re the biggest market, they&amp;#39;re willing to spend (obviously) yet they can&amp;#39;t pull it together... Ever&lt;/p&gt;\n\n&lt;p&gt;You can find, critique, and contribute to my NBA project here: &lt;a href=\"https://github.com/jpooksy/NBA_Data_Modeling\"&gt;https://github.com/jpooksy/NBA_Data_Modeling&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960\"&gt;https://preview.redd.it/lrw4oybekw5c1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31483f90ad3e5ac997b8c9956b59af9f029dc960&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18grxlj", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18grxlj/nba_data_modeling_wth_dbt_paradime/", "subreddit_subscribers": 145590, "created_utc": 1702403763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, what are you interested to know about orchestrators? \n\nI am looking to do a deep dive on the more popular ones and write about it. \n\nWhat I am interested to understand is what use cases are each of them best at, and the kinds of criteria **you** use to make that choice.  \n\n\nSo my questions to you are:\n\n  \n**- what do you want to know about orchestrators?**\n\n**- what would you compare them on?**\n\n\\- **what killer features or orchestrators do you think I should check out and investigate?**  \n\n\nCurrently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we'll dig in :)  \n\n\nThanks in advance!\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you want to know about orchestrators?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqg6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, what are you interested to know about orchestrators? &lt;/p&gt;\n\n&lt;p&gt;I am looking to do a deep dive on the more popular ones and write about it. &lt;/p&gt;\n\n&lt;p&gt;What I am interested to understand is what use cases are each of them best at, and the kinds of criteria &lt;strong&gt;you&lt;/strong&gt; use to make that choice.  &lt;/p&gt;\n\n&lt;p&gt;So my questions to you are:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what do you want to know about orchestrators?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- what would you compare them on?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;what killer features or orchestrators do you think I should check out and investigate?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Currently on my list are mainstream orchestrators such as Airflow, but also smaller ones, such as git actions. So tell me what you want to know, and we&amp;#39;ll dig in :)  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18gqg6q", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gqg6q/what_do_you_want_to_know_about_orchestrators/", "subreddit_subscribers": 145590, "created_utc": 1702400055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading Jobs Code between Databricks Runtime Versions Made Easier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_18gq1fy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vHriYbg9RY72KUXRAAYKX7WkPAf_TJCsD36ioLiCkEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702399004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?auto=webp&amp;s=e6fff503363810a1a844243d4dc30e20374a7e61", "width": 1200, "height": 639}, "resolutions": [{"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b1bd7c5baa426d324568692cf26b63002b7b9ab", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=632346f8e065aae9f74ea8fe594679ac441da0d7", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a7c5312e6d82b74496104ca1ba5fd37d8edfc97", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d87a636f09f8ab2bf8a00a4eee4eae61323608f8", "width": 640, "height": 340}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9002d9c593d7a4124e0ce8d3e0cba46f56a69233", "width": 960, "height": 511}, {"url": "https://external-preview.redd.it/6CGEVIm1q1TobUixQuDUP9Ws43TA5G0TONrrR2zYDAY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a322c150c48715bdd366d61e7a96a10d7e03776c", "width": 1080, "height": 575}], "variants": {}, "id": "uhonE0yWOOsFkvPBPnnGD6Eg9m5tkICAwlDw0bCdu6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gq1fy", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gq1fy/upgrading_jobs_code_between_databricks_runtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/databricks-labs/upgrading-jobs-code-between-databricks-runtime-versions-made-seamless-29c22e701c3a", "subreddit_subscribers": 145590, "created_utc": 1702399004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is not entirely dedicated to data engineering, but it has touch points.\n\n **Some context:**\n\nIn our small to medium-sized enterprise operating in a production environment with a myriad of applications, the majority of which have point-to-point interfaces with our ERP (a local SQL database), and a considerable amount of legacy systems, the IT team, consisting of just two members, manages all applications and integrations. It's noteworthy that we lack in-house developers. Many of our integrations rely on XML files for data exchange, employing SQL and mapping tools like Altova and sometimes even BizTalk.\n\nLooking ahead, by the end of 2024, we plan to implement a new ERP, likely Dynamics 365 F&amp;O. This transition necessitates the rebuilding of numerous integrations to align with the new ERP. Ideally, we aim to centralize these integrations for improved oversight, addressing issues proactively rather than reactively as is often the case currently.\n\nOur challenges are further compounded when dealing with modern web applications utilizing RESTAPI, especially with our legacy ERP. Typically, we resort to scripting PowerShell and requesting vendors to set up an SFTP server for XML file exchange, incurring additional costs for their extra efforts. To address these issues, we have explored integration platforms such as Mulesoft, Workato, and Boomi.\n\nBoomi was discarded after practical testing due to perceived shortcomings. \n\nMulesoft proved comprehensible, enabling successful use cases, yet its deployment and maintenance seemed burdensome. \n\nWorkato, while lacking robust debugging and offering basic logging, demonstrated ease of use in creating integrations, aligning well with the simplicity of our integration needs. Its variety of connectors reduces the need for custom wrappers or connectors, and it presents automation possibilities.\n\nSome of the use cases that I finalized in the 2 last tools are:  \n\\- I was able to build an extensive integration between ERP and Salesforce, \n\n\\- create an API based on openapi specs and send data between ERP and the web app\n\n\\- do data transformation into an XML file with iterations \n\n**The question at hand** is whether an Integration Platform as a Service (iPaaS) is a suitable solution for our scenario, given that we do not anticipate hiring an in-house developer. Additionally, are there other platforms or tools we might be overlooking? We are seeking insights from those with experience in the listed tools, with Workato emerging as our preferred choice due to its balance of simplicity and functionality, even though Mulesoft offers more robust features. The overarching question is whether the additional functionalities of Mulesoft are necessary for our specific requirements.\n\nTL;DR: We're a small-to-medium enterprise handling various applications with point-to-point interfaces and legacy systems. Two-person IT team, no in-house developers. Looking to rebuild integrations for a new ERP (probably Dynamics 365 F&amp;O) by 2024. Currently considering Workato, Mulesoft, and Boomi. Workato seems suitable due to simplicity and variety of connectors. Wondering if Integration Platform as a Service (iPaaS) is the right solution for us and seeking insights on other tools or experiences with the mentioned platforms. Open to suggestions given our context and the absence of in-house developers.", "author_fullname": "t2_8mnqz0ek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about IPAAS platforms (Mulesoft, Workato,...)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gm0jn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702388156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is not entirely dedicated to data engineering, but it has touch points.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In our small to medium-sized enterprise operating in a production environment with a myriad of applications, the majority of which have point-to-point interfaces with our ERP (a local SQL database), and a considerable amount of legacy systems, the IT team, consisting of just two members, manages all applications and integrations. It&amp;#39;s noteworthy that we lack in-house developers. Many of our integrations rely on XML files for data exchange, employing SQL and mapping tools like Altova and sometimes even BizTalk.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead, by the end of 2024, we plan to implement a new ERP, likely Dynamics 365 F&amp;amp;O. This transition necessitates the rebuilding of numerous integrations to align with the new ERP. Ideally, we aim to centralize these integrations for improved oversight, addressing issues proactively rather than reactively as is often the case currently.&lt;/p&gt;\n\n&lt;p&gt;Our challenges are further compounded when dealing with modern web applications utilizing RESTAPI, especially with our legacy ERP. Typically, we resort to scripting PowerShell and requesting vendors to set up an SFTP server for XML file exchange, incurring additional costs for their extra efforts. To address these issues, we have explored integration platforms such as Mulesoft, Workato, and Boomi.&lt;/p&gt;\n\n&lt;p&gt;Boomi was discarded after practical testing due to perceived shortcomings. &lt;/p&gt;\n\n&lt;p&gt;Mulesoft proved comprehensible, enabling successful use cases, yet its deployment and maintenance seemed burdensome. &lt;/p&gt;\n\n&lt;p&gt;Workato, while lacking robust debugging and offering basic logging, demonstrated ease of use in creating integrations, aligning well with the simplicity of our integration needs. Its variety of connectors reduces the need for custom wrappers or connectors, and it presents automation possibilities.&lt;/p&gt;\n\n&lt;p&gt;Some of the use cases that I finalized in the 2 last tools are:&lt;br/&gt;\n- I was able to build an extensive integration between ERP and Salesforce, &lt;/p&gt;\n\n&lt;p&gt;- create an API based on openapi specs and send data between ERP and the web app&lt;/p&gt;\n\n&lt;p&gt;- do data transformation into an XML file with iterations &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The question at hand&lt;/strong&gt; is whether an Integration Platform as a Service (iPaaS) is a suitable solution for our scenario, given that we do not anticipate hiring an in-house developer. Additionally, are there other platforms or tools we might be overlooking? We are seeking insights from those with experience in the listed tools, with Workato emerging as our preferred choice due to its balance of simplicity and functionality, even though Mulesoft offers more robust features. The overarching question is whether the additional functionalities of Mulesoft are necessary for our specific requirements.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: We&amp;#39;re a small-to-medium enterprise handling various applications with point-to-point interfaces and legacy systems. Two-person IT team, no in-house developers. Looking to rebuild integrations for a new ERP (probably Dynamics 365 F&amp;amp;O) by 2024. Currently considering Workato, Mulesoft, and Boomi. Workato seems suitable due to simplicity and variety of connectors. Wondering if Integration Platform as a Service (iPaaS) is the right solution for us and seeking insights on other tools or experiences with the mentioned platforms. Open to suggestions given our context and the absence of in-house developers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gm0jn", "is_robot_indexable": true, "report_reasons": null, "author": "LangeHamburger", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gm0jn/question_about_ipaas_platforms_mulesoft_workato/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gm0jn/question_about_ipaas_platforms_mulesoft_workato/", "subreddit_subscribers": 145590, "created_utc": 1702388156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm looking to test Airbyte OSS and have deployed the product locally on WSL using the instructions [here](https://docs.airbyte.com/deploying-airbyte/local-deployment). This has create a local repo with all the Airbyte files.\n\nI am looking to use these files to create a connector to ADLS, which is a standard connector on Airbyte, however, all of the documentation is about using Airbyte Cloud and the UI, which I don't want to do. I want to deploy an ADLS connector locally then use Docker to publish to Azure Container Registry, then self-host this container in a VM.\n\nI know how to use Docker and Azure, but am stumped with the first stage. Is there any documentation about how to create a connector using OSS rather than the Cloud version of the product?\n\nThanks, ", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create connectors for Self-Hosted Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gky16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702384695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to test Airbyte OSS and have deployed the product locally on WSL using the instructions &lt;a href=\"https://docs.airbyte.com/deploying-airbyte/local-deployment\"&gt;here&lt;/a&gt;. This has create a local repo with all the Airbyte files.&lt;/p&gt;\n\n&lt;p&gt;I am looking to use these files to create a connector to ADLS, which is a standard connector on Airbyte, however, all of the documentation is about using Airbyte Cloud and the UI, which I don&amp;#39;t want to do. I want to deploy an ADLS connector locally then use Docker to publish to Azure Container Registry, then self-host this container in a VM.&lt;/p&gt;\n\n&lt;p&gt;I know how to use Docker and Azure, but am stumped with the first stage. Is there any documentation about how to create a connector using OSS rather than the Cloud version of the product?&lt;/p&gt;\n\n&lt;p&gt;Thanks, &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gky16", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gky16/how_to_create_connectors_for_selfhosted_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gky16/how_to_create_connectors_for_selfhosted_airbyte/", "subreddit_subscribers": 145590, "created_utc": 1702384695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i'm currently in my fifth year of school with a economics and cs dual degree. I work as a data analyst (not intern) at a pharmaceutical consulting company. I do a lot of excel, power BI, data processing, and help broker data deals between data vendors and buyers. I had a good connection so thats how I landed this job while still in school. I am just nervous that I am not getting the practical experience or learning the skills I should be doing to land a DE job. I am not sure what jobs/internships I should be looking for to put me on the path to become a DE. However, my boss has recently told me to experimenting with python as a tool for data analytics and how we can implement different strategies into the company. I get paid for this time and have been learning a lot which is good. I have been also learning SQL. I was thinking about bringing up to him the fact that I want to be a DE and how I can learn while working with the company to do this and possibly change my job title in the future. However, I feel like I would not be learning very good as we do not have any DE already. Should I stay at this role or start looking at applying for other jobs? Would it be a good idea to develop my skills and experience than start looking at DE roles? ", "author_fullname": "t2_2z2wymyd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some guidance on what path I should take", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g6eub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702334171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m currently in my fifth year of school with a economics and cs dual degree. I work as a data analyst (not intern) at a pharmaceutical consulting company. I do a lot of excel, power BI, data processing, and help broker data deals between data vendors and buyers. I had a good connection so thats how I landed this job while still in school. I am just nervous that I am not getting the practical experience or learning the skills I should be doing to land a DE job. I am not sure what jobs/internships I should be looking for to put me on the path to become a DE. However, my boss has recently told me to experimenting with python as a tool for data analytics and how we can implement different strategies into the company. I get paid for this time and have been learning a lot which is good. I have been also learning SQL. I was thinking about bringing up to him the fact that I want to be a DE and how I can learn while working with the company to do this and possibly change my job title in the future. However, I feel like I would not be learning very good as we do not have any DE already. Should I stay at this role or start looking at applying for other jobs? Would it be a good idea to develop my skills and experience than start looking at DE roles? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g6eub", "is_robot_indexable": true, "report_reasons": null, "author": "cailloudragonballs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g6eub/need_some_guidance_on_what_path_i_should_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g6eub/need_some_guidance_on_what_path_i_should_take/", "subreddit_subscribers": 145590, "created_utc": 1702334171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an Azure Synapse dedicated SQL pool with 400 DWU.  It is set to replicated distribution policy.\n\nWithin this, we have a table with 600,000 rows and approximately 80 columns.  This table is similar to a table in an on-prem SQL Server database.  We have created the same indexes in the SQL pool version of the table that are on the original SQL Server database version.  We have a problem with our query performance.\n\nAggregations are fast but SELECTs are slow (&gt; 5 minutes). Even the count is faster.  The same table in SQL Server runs SELECT in 1 min 30 seconds.\n\nWe have run out of ideas for why the SELECT statement \\[SELECT \\* FROM tablename\\] runs in about 1.5 minutes in the SQL Server version but over 5 minutes in the Azure version.  Has anyone come across a situation like this?  ", "author_fullname": "t2_5lfqidpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Dedicated SQL Pool Performance Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18gtfzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702407615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an Azure Synapse dedicated SQL pool with 400 DWU.  It is set to replicated distribution policy.&lt;/p&gt;\n\n&lt;p&gt;Within this, we have a table with 600,000 rows and approximately 80 columns.  This table is similar to a table in an on-prem SQL Server database.  We have created the same indexes in the SQL pool version of the table that are on the original SQL Server database version.  We have a problem with our query performance.&lt;/p&gt;\n\n&lt;p&gt;Aggregations are fast but SELECTs are slow (&amp;gt; 5 minutes). Even the count is faster.  The same table in SQL Server runs SELECT in 1 min 30 seconds.&lt;/p&gt;\n\n&lt;p&gt;We have run out of ideas for why the SELECT statement [SELECT * FROM tablename] runs in about 1.5 minutes in the SQL Server version but over 5 minutes in the Azure version.  Has anyone come across a situation like this?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gtfzr", "is_robot_indexable": true, "report_reasons": null, "author": "imani_TqiynAZU", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gtfzr/azure_synapse_dedicated_sql_pool_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gtfzr/azure_synapse_dedicated_sql_pool_performance/", "subreddit_subscribers": 145590, "created_utc": 1702407615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone keen to help me do that?", "author_fullname": "t2_7xqqfkwm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for help to build Xero ETL process on Mage.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gqkq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702400376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone keen to help me do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gqkq5", "is_robot_indexable": true, "report_reasons": null, "author": "DisastrousMagician16", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gqkq5/looking_for_help_to_build_xero_etl_process_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gqkq5/looking_for_help_to_build_xero_etl_process_on/", "subreddit_subscribers": 145590, "created_utc": 1702400376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Performance Airbyte Alternative (With marketplace &amp; rev-share option).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_18gocy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RXisw1vYyrryutL98IO-maYwVLytLI2DsmM2KmTLwJY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702394682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/cloudquery/cloudquery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?auto=webp&amp;s=dd143a7f9b6a9015459c3dc772da9e98db7b6f47", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=147893b3db6dd4cae150c8886e4e7626cfbbad73", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1a14790a267d49a600b795d0e69becaa0f880bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89f0f40761cef4a98448da8d705fc0f7ac8da098", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ea4fd467efb9e12fdf42002ceadf2610ce7bb27", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c47a44b980bda39bba79f42cced4432f1d67a1e7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZZLJ03hmDhSN9K9jMakkbWQPxx6jxa-FCr0AVzpqQFo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9817a5e9a3d1d6e3e2cd0fb13006fde1cb8be7a", "width": 1080, "height": 540}], "variants": {}, "id": "PYdEfT0qlVl6WVtoPac0-CRAKGdhmLIlFgFnNSh3Qcw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18gocy7", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gocy7/high_performance_airbyte_alternative_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/cloudquery/cloudquery", "subreddit_subscribers": 145590, "created_utc": 1702394682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e2nemx2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Text Editor Data Structures: Rethinking Undo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18gkb4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3XhzYyw8teAAoZteZx93zMB8muM72xfcryWrIFISW94.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702382410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cdacamar.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cdacamar.github.io/data%20structures/algorithms/benchmarking/text%20editors/c++/rethinking-undo/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_O1NAjuFVHPWSQrxpn9UxuSTuWqP-gDytGjdnGiG5LA.jpg?auto=webp&amp;s=dc979df84fccce2dd97f6684151bc6706e699844", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/_O1NAjuFVHPWSQrxpn9UxuSTuWqP-gDytGjdnGiG5LA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b79a1d8c7c180efe26989df2f93f864bf0e11179", "width": 108, "height": 108}], "variants": {}, "id": "054kh5x7H-LaMjWU8y5O6b3KQqF24aoISBGMUIydDbQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gkb4r", "is_robot_indexable": true, "report_reasons": null, "author": "askredtoy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gkb4r/text_editor_data_structures_rethinking_undo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cdacamar.github.io/data%20structures/algorithms/benchmarking/text%20editors/c++/rethinking-undo/", "subreddit_subscribers": 145590, "created_utc": 1702382410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kind of a noob in Snowflake and need some help. The situation is a little more complicated but I\u2019ll keep it simple. We have a table that was built in Database A with Role X. The privileges for Role X were changed to no longer include access to Database A, and it says Role X is the owner of the table still. The only role Role X has been granted to is ACCOUNTADMIN. Is getting someone with ACCOUNTADMIN access our only option to update schema/delete these tables?", "author_fullname": "t2_oaue187y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Roles/Privileges", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gcwvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702353247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kind of a noob in Snowflake and need some help. The situation is a little more complicated but I\u2019ll keep it simple. We have a table that was built in Database A with Role X. The privileges for Role X were changed to no longer include access to Database A, and it says Role X is the owner of the table still. The only role Role X has been granted to is ACCOUNTADMIN. Is getting someone with ACCOUNTADMIN access our only option to update schema/delete these tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18gcwvj", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Pomegranate8943", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gcwvj/snowflake_rolesprivileges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gcwvj/snowflake_rolesprivileges/", "subreddit_subscribers": 145590, "created_utc": 1702353247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a freelancer and this is my first job and I don\u2019t know how to collect the data the client needs. Is it something that can be done? \n\nHere is whole story\n\u201cI'm looking for a person who can do a very specific task. Your profile tells me that you may be the right person. In principle it is like this: Messages are posted in a Telegram channel (always in the same format). These messages contain information in the form of numbers and possibly text. This information should be extracted as soon as the post enters the channel and entered into a database. This database should then be calculated and evaluated so that a live time web dashboard shows insights. The customers who are on my website should be able to view the dashboard on my website. Of course, the dashboard should always be up to date. The amount of data is extremely small and the statistical analysis requires little effort, as it only involves simple insights. Am I at the right place with you or should I look for someone else?\u201d \n\nHow can I start ?", "author_fullname": "t2_fxlwknu3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help/ my first project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g3tu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702327813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a freelancer and this is my first job and I don\u2019t know how to collect the data the client needs. Is it something that can be done? &lt;/p&gt;\n\n&lt;p&gt;Here is whole story\n\u201cI&amp;#39;m looking for a person who can do a very specific task. Your profile tells me that you may be the right person. In principle it is like this: Messages are posted in a Telegram channel (always in the same format). These messages contain information in the form of numbers and possibly text. This information should be extracted as soon as the post enters the channel and entered into a database. This database should then be calculated and evaluated so that a live time web dashboard shows insights. The customers who are on my website should be able to view the dashboard on my website. Of course, the dashboard should always be up to date. The amount of data is extremely small and the statistical analysis requires little effort, as it only involves simple insights. Am I at the right place with you or should I look for someone else?\u201d &lt;/p&gt;\n\n&lt;p&gt;How can I start ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18g3tu5", "is_robot_indexable": true, "report_reasons": null, "author": "AvailableField7708", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g3tu5/help_my_first_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g3tu5/help_my_first_project/", "subreddit_subscribers": 145590, "created_utc": 1702327813.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer working in Snowflake/dbt and part of my role is supporting two business analysts who build Tableau dashboards. Small data team, so I'm the Tableau admin as I used to be the one and only analyst. Right now, I build them whatever data sources they need in a presentation-layer Snowflake database. They connect Tableau to Snowflake and do an extract. While this works, it seems to lead to lots of extract duplication as they will use the same tables over and over for different dashboards. My thought is that I could create a single extract for each Presentation-layer table via a Tableau Virtual Connection (or whatever PBI equivalent is, chance we may end up switching next year). With this approach, I'd cut down on duplicate extracts and could even link to dbt documentation in the data source description. Using a VC, they can still join tables together within Tableau.\n\nI'm curious how everyone else handles this as BI scales within an organization, especially a non-technical one.", "author_fullname": "t2_ee8slplxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for exposing DWH tables to Tableau/Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18g30px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702325815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer working in Snowflake/dbt and part of my role is supporting two business analysts who build Tableau dashboards. Small data team, so I&amp;#39;m the Tableau admin as I used to be the one and only analyst. Right now, I build them whatever data sources they need in a presentation-layer Snowflake database. They connect Tableau to Snowflake and do an extract. While this works, it seems to lead to lots of extract duplication as they will use the same tables over and over for different dashboards. My thought is that I could create a single extract for each Presentation-layer table via a Tableau Virtual Connection (or whatever PBI equivalent is, chance we may end up switching next year). With this approach, I&amp;#39;d cut down on duplicate extracts and could even link to dbt documentation in the data source description. Using a VC, they can still join tables together within Tableau.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how everyone else handles this as BI scales within an organization, especially a non-technical one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18g30px", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Huckleberry-55", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18g30px/best_practices_for_exposing_dwh_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18g30px/best_practices_for_exposing_dwh_tables_to/", "subreddit_subscribers": 145590, "created_utc": 1702325815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here is a good video on how EARLIER really works in SSAS or Power BI. Learning this vintage function have more benefits than the funtion itself.\n\n[https://www.youtube.com/watch?v=q8zsWqcd1vM](https://www.youtube.com/watch?v=q8zsWqcd1vM)", "author_fullname": "t2_hef0vmnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EARLIER a vintage DAX", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gnv5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702393357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is a good video on how EARLIER really works in SSAS or Power BI. Learning this vintage function have more benefits than the funtion itself.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=q8zsWqcd1vM\"&gt;https://www.youtube.com/watch?v=q8zsWqcd1vM&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UOq9aBM5uJgFcFmb8yTOREjW9aY7N_Yy_2d-Kn2qCR4.jpg?auto=webp&amp;s=23e320986cdd831dcd5e6739a3badbc537145181", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/UOq9aBM5uJgFcFmb8yTOREjW9aY7N_Yy_2d-Kn2qCR4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a4cea66290c0a59cdbd1f46d6cbcdea2fad8f85", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/UOq9aBM5uJgFcFmb8yTOREjW9aY7N_Yy_2d-Kn2qCR4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=32c386882f19a036d2e053185a57d1e878c2d9bc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/UOq9aBM5uJgFcFmb8yTOREjW9aY7N_Yy_2d-Kn2qCR4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=51b513c4e7ac4fa6031c3d3b16aa00c6f7e2ae56", "width": 320, "height": 240}], "variants": {}, "id": "NtlWFciM2skBwE4MLoqEv2tH0EKK0sNVdcntqQeN63Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18gnv5s", "is_robot_indexable": true, "report_reasons": null, "author": "Status-Cap-5236", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gnv5s/earlier_a_vintage_dax/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gnv5s/earlier_a_vintage_dax/", "subreddit_subscribers": 145590, "created_utc": 1702393357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Client gives some business rules to follow, me do that, boss revamps the requirements, me modify existing. Client screams, me wtf. ( caveman lang )", "author_fullname": "t2_76x4aitl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wtf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18gk992", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.34, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702382207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Client gives some business rules to follow, me do that, boss revamps the requirements, me modify existing. Client screams, me wtf. ( caveman lang )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "18gk992", "is_robot_indexable": true, "report_reasons": null, "author": "Scratch_that_Iich", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18gk992/wtf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18gk992/wtf/", "subreddit_subscribers": 145590, "created_utc": 1702382207.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}