{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What opinion about data science would you defend like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18ak46b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 758, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 758, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Afesnyz7I4kvGi6-33Z16-S05Dseb4_ZwnCosB1NQGc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701696235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/20r6sbok4a4c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/20r6sbok4a4c1.jpg?auto=webp&amp;s=be2a7d7b6023e74857b5e709cab451a4c9f3e548", "width": 868, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/20r6sbok4a4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae10c19c8d4b632c620cff42dab92986ddbcecb1", "width": 108, "height": 127}, {"url": "https://preview.redd.it/20r6sbok4a4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=82e2dca7f2f20838b070ff6fc7cfe67210652939", "width": 216, "height": 254}, {"url": "https://preview.redd.it/20r6sbok4a4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7acb3d1574330f9c4dfd03c450bbe8ff53039aa1", "width": 320, "height": 377}, {"url": "https://preview.redd.it/20r6sbok4a4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17c25e280f9da79eef4125d2dd5b34e26cf7e230", "width": 640, "height": 755}], "variants": {}, "id": "zWIGf0acq0-fBatJQKYpaONHl4oeuIn2I26FUEAPaz4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "18ak46b", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 490, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ak46b/what_opinion_about_data_science_would_you_defend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/20r6sbok4a4c1.jpg", "subreddit_subscribers": 1165628, "created_utc": 1701696235.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Everyone in this sub seems to absolutely hate take-home assignments. I used to find it stupid as well until I was involved in a hiring process a few months back.\n\nWe were hiring for a junior to mid level DS position, it only took a couple of days to gather half a thousand applications. (It\u2019s absolutely insane, maybe due to the job being remote) Even after filtering out those with quantitative degrees or relevant experience, we still had to deal with slightly over 100 candidates. Interview all of them is definitely out of the question here.\n\nThe process we had was to get them do a coding test. Easy to medium leetcode questions with some SQL questions. Of the 2/3 that passed, we send them an assignment with one week deadline. Once submitted, they get a zoom interview to present their work. Here\u2019s the thing, **take-home assignments work.** It very effectively cut down the number of applicants to around 10. \n\nI understand it\u2019s not fun doing these assignments, but given the job market, what\u2019s a good alternative that helps you filter among 100s of qualified candidates on paper, and also help you understand how they do their work and communicate? DS resumes these days all look the same. Everyone claims to know everything with no proof of proficiency. Recruiting is very time consuming and costly, and the cost of hiring a fraud DS costs even more.\n\nSome argue that assignments will deter the best candidates from continuing the application. The reality is that, unless it\u2019s meta or google, employers are not obsessed with finding the best person out of hundreds of candidates. They just want to find someone who is **good enough** to perform certain tasks without adding burden to the team. \n\nSo for those really hates take-home assignments, if you\u2019re in the position of hiring, how will you evaluate your applicants?", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What realistically is a good alternative take-home assignments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aif1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701689960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everyone in this sub seems to absolutely hate take-home assignments. I used to find it stupid as well until I was involved in a hiring process a few months back.&lt;/p&gt;\n\n&lt;p&gt;We were hiring for a junior to mid level DS position, it only took a couple of days to gather half a thousand applications. (It\u2019s absolutely insane, maybe due to the job being remote) Even after filtering out those with quantitative degrees or relevant experience, we still had to deal with slightly over 100 candidates. Interview all of them is definitely out of the question here.&lt;/p&gt;\n\n&lt;p&gt;The process we had was to get them do a coding test. Easy to medium leetcode questions with some SQL questions. Of the 2/3 that passed, we send them an assignment with one week deadline. Once submitted, they get a zoom interview to present their work. Here\u2019s the thing, &lt;strong&gt;take-home assignments work.&lt;/strong&gt; It very effectively cut down the number of applicants to around 10. &lt;/p&gt;\n\n&lt;p&gt;I understand it\u2019s not fun doing these assignments, but given the job market, what\u2019s a good alternative that helps you filter among 100s of qualified candidates on paper, and also help you understand how they do their work and communicate? DS resumes these days all look the same. Everyone claims to know everything with no proof of proficiency. Recruiting is very time consuming and costly, and the cost of hiring a fraud DS costs even more.&lt;/p&gt;\n\n&lt;p&gt;Some argue that assignments will deter the best candidates from continuing the application. The reality is that, unless it\u2019s meta or google, employers are not obsessed with finding the best person out of hundreds of candidates. They just want to find someone who is &lt;strong&gt;good enough&lt;/strong&gt; to perform certain tasks without adding burden to the team. &lt;/p&gt;\n\n&lt;p&gt;So for those really hates take-home assignments, if you\u2019re in the position of hiring, how will you evaluate your applicants?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18aif1a", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18aif1a/what_realistically_is_a_good_alternative_takehome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18aif1a/what_realistically_is_a_good_alternative_takehome/", "subreddit_subscribers": 1165628, "created_utc": 1701689960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What\u2019s your sniff test or initial analysis to see if there is any potential for ML in a dataset?\n\nEdit: Maybe I should have added more context.  Assume there is a business problem in mind and there is a target variable that the company would like predicted in the data set and a data analyst is pulling the data you request and then handing it off to you. ", "author_fullname": "t2_495cn7pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handed a dataset, what\u2019s your sniff test?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ahxus", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701704259.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701687964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s your sniff test or initial analysis to see if there is any potential for ML in a dataset?&lt;/p&gt;\n\n&lt;p&gt;Edit: Maybe I should have added more context.  Assume there is a business problem in mind and there is a target variable that the company would like predicted in the data set and a data analyst is pulling the data you request and then handing it off to you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18ahxus", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawayforgainz99", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ahxus/handed_a_dataset_whats_your_sniff_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ahxus/handed_a_dataset_whats_your_sniff_test/", "subreddit_subscribers": 1165628, "created_utc": 1701687964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m turning 40 next year and it\u2019s got me wondering about the future and how I\u2019ll be able to make a living when I\u2019m older.\n\nWe\u2019ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don\u2019t really want to climb the corporate ladder, I\u2019d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. \n\nI\u2019ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. \n\nJust wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?", "author_fullname": "t2_nya9l4wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you see this doing this work past 50 years of age and into retirement?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b1ery", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701743270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m turning 40 next year and it\u2019s got me wondering about the future and how I\u2019ll be able to make a living when I\u2019m older.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don\u2019t really want to climb the corporate ladder, I\u2019d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. &lt;/p&gt;\n\n&lt;p&gt;Just wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18b1ery", "is_robot_indexable": true, "report_reasons": null, "author": "TheUserAboveFarted", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/", "subreddit_subscribers": 1165628, "created_utc": 1701743270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently enrolled in a top MS Statistics program (with Data Science specialization), and I\u2019m taking primarily CS classes: ML, deep learning, NLP, CV, RL, generative models, big data algorithms, parallel programming etc. On top of this I will be taking \u2018pure stats\u2019 courses in stochastics, inference, and applied stats.\n\nI recently learned that I can switch to the MS in Computer Science with the AI specialization and take exactly the same classes, but with OS, programming languages, and logic instead of the aforementioned pure stats classes.\n\nI studied CS (~13 core courses) and biology in undergrad, and graduated with a Bioinformatics degree (so I don\u2019t have BSCS on my resume, but I do have extensive knowledge in CS). I have written a number of software packages in Python and C++, and have a couple years of industry and research experience in DS and MLE roles.\n\n**My question is: For career prospects, is it better for me to stick with my MS in Statistics or switch to the MS in Computer Science?**", "author_fullname": "t2_13co83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS Statistics vs. MS CS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aoqmk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701709595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently enrolled in a top MS Statistics program (with Data Science specialization), and I\u2019m taking primarily CS classes: ML, deep learning, NLP, CV, RL, generative models, big data algorithms, parallel programming etc. On top of this I will be taking \u2018pure stats\u2019 courses in stochastics, inference, and applied stats.&lt;/p&gt;\n\n&lt;p&gt;I recently learned that I can switch to the MS in Computer Science with the AI specialization and take exactly the same classes, but with OS, programming languages, and logic instead of the aforementioned pure stats classes.&lt;/p&gt;\n\n&lt;p&gt;I studied CS (~13 core courses) and biology in undergrad, and graduated with a Bioinformatics degree (so I don\u2019t have BSCS on my resume, but I do have extensive knowledge in CS). I have written a number of software packages in Python and C++, and have a couple years of industry and research experience in DS and MLE roles.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question is: For career prospects, is it better for me to stick with my MS in Statistics or switch to the MS in Computer Science?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18aoqmk", "is_robot_indexable": true, "report_reasons": null, "author": "fastbutlame", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18aoqmk/ms_statistics_vs_ms_cs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18aoqmk/ms_statistics_vs_ms_cs/", "subreddit_subscribers": 1165628, "created_utc": 1701709595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_yjyfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I notice that there are a wide variety of \u201cData Scientist\u201d jobs, that entail different responsibilities: some are more inference/explanation focused, some more MLE/prediction focused, some Product analytics etc. How would you characterize typologies/categories of different DS roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ajjl2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701694285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ajjl2", "is_robot_indexable": true, "report_reasons": null, "author": "Stauce52", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ajjl2/i_notice_that_there_are_a_wide_variety_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ajjl2/i_notice_that_there_are_a_wide_variety_of_data/", "subreddit_subscribers": 1165628, "created_utc": 1701694285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been stuck with package dependency failures with R3.6.1 and can't seem to get out of it.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to manage packages for different versions of R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aqhu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701714212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been stuck with package dependency failures with R3.6.1 and can&amp;#39;t seem to get out of it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18aqhu2", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18aqhu2/whats_the_best_way_to_manage_packages_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18aqhu2/whats_the_best_way_to_manage_packages_for/", "subreddit_subscribers": 1165628, "created_utc": 1701714212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for some good GitHub example repos of a machine learning model deployed in a flask server API. Preferably something deployed in a customer-facing production environment, and preferably **not** a simple toy server example.\n\nMy team has been deploying some of our models, mostly following documentation and tutorials. But I'd love some \"in the wild\" examples to see what other people do differently.\n\nAny recommendations?", "author_fullname": "t2_jqnnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good example of model deployed in flask server API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aq8w1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701713564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some good GitHub example repos of a machine learning model deployed in a flask server API. Preferably something deployed in a customer-facing production environment, and preferably &lt;strong&gt;not&lt;/strong&gt; a simple toy server example.&lt;/p&gt;\n\n&lt;p&gt;My team has been deploying some of our models, mostly following documentation and tutorials. But I&amp;#39;d love some &amp;quot;in the wild&amp;quot; examples to see what other people do differently.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "18aq8w1", "is_robot_indexable": true, "report_reasons": null, "author": "MindlessTime", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18aq8w1/good_example_of_model_deployed_in_flask_server_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18aq8w1/good_example_of_model_deployed_in_flask_server_api/", "subreddit_subscribers": 1165628, "created_utc": 1701713564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more \"production-ready\", then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol", "author_fullname": "t2_oxk1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write OOP from the beginning or refactor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b5s7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701757640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more &amp;quot;production-ready&amp;quot;, then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18b5s7f", "is_robot_indexable": true, "report_reasons": null, "author": "PinstripePride97", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/", "subreddit_subscribers": 1165628, "created_utc": 1701757640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey,  \n\n\nHas anyone tried this model for hierarchical time series forecasting from gluonts? [https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical\\_model\\_tutorial.html](https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html). The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?", "author_fullname": "t2_k7ifh2t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hierarchical Time Series Forecasting using GluonTS DeepVarHierarchical", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ay60f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701733960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,  &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this model for hierarchical time series forecasting from gluonts? &lt;a href=\"https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html\"&gt;https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html&lt;/a&gt;. The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18ay60f", "is_robot_indexable": true, "report_reasons": null, "author": "Moist_Stuff4509", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/", "subreddit_subscribers": 1165628, "created_utc": 1701733960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I'm assuming I will have to make one myself. I'm fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I'm being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.\n\nAre there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?", "author_fullname": "t2_1mt6zlx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make a good dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ausi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701725168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I&amp;#39;m assuming I will have to make one myself. I&amp;#39;m fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I&amp;#39;m being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;Are there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18ausi6", "is_robot_indexable": true, "report_reasons": null, "author": "ixw123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/", "subreddit_subscribers": 1165628, "created_utc": 1701725168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don't have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?\n\nI'm in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I've constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population 'cell', e.g. permutation of geography (postcode in this case), sex, and age bucket:\n\ncell | year | age_bucket | sex | postcode | population\n:--|--:|--:|:--|:--|--:\n1036 | 2021 | 25-30 | Male | 2000 |  4,390\n\nMy intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we'll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.\n\nuser | year | height | weight | age_bucket | sex | postcode\n:---|--:|--:|--:|--:|:--|:--\na89bf96e | 2021| 180 | 80 | 25-30 | Male | 2000\n\nFrom the **user** and **cell** tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).\n\nHowever I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:\n\n\n    # get the total population\n    total_population = data['population'].sum()\n    \n    # get the weighted estimate\n    weighted_bmi_estimate = (data['survey_weight'] * data['bmi']).sum() / total_population\n    \n    # work out the design effect by comparing simple (SRS) and complex variance measures\n    \n    mean_bmi = data['bmi'].mean()\n    simple_variance = ((data['bmi'] - mean_bmi)**2).sum() / (total_population - 1)\n    \n    data['weighted_deviance'] = data['survey_weight'] * (data['bmi'] - weighted_bmi_estimate)**2\n    complex_variance = data['weighted_deviance'].sum() / total_population\n    \n    deff = complex_variance / simple_variance\n    \n    # use the deff to get the rse for the bmi estimate\n    rse = (deff * simple_variance)**0.5\n    \n    # NOTE: when doing an obesity _rate_ instead of BMI we'd use a different calc for the simple_variance\n\n\nTbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it'd be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.\n\nFurther thoughts:\n\n- I will need to interpolate population counts for non-census years or otherwise just take the closest\n- Though I haven't yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it\n- I'll need to handle summation across cells when weighting by only a subset of the cell dimensions \n- To handle distortion from small counts, weight trimming seemed like the simplest solution but I'm unsure if any adjustments are necessary when determining RSEs\n- I'm not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using `approxQuantile` to set the weight caps, broadcasting my means and total_populations)\n\nThank you!", "author_fullname": "t2_i0a3z0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please sense-check my approach for applying survey weights and RSEs in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b113j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701744760.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701742148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don&amp;#39;t have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I&amp;#39;ve constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population &amp;#39;cell&amp;#39;, e.g. permutation of geography (postcode in this case), sex, and age bucket:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;cell&lt;/th&gt;\n&lt;th align=\"right\"&gt;year&lt;/th&gt;\n&lt;th align=\"right\"&gt;age_bucket&lt;/th&gt;\n&lt;th align=\"left\"&gt;sex&lt;/th&gt;\n&lt;th align=\"left\"&gt;postcode&lt;/th&gt;\n&lt;th align=\"right\"&gt;population&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1036&lt;/td&gt;\n&lt;td align=\"right\"&gt;2021&lt;/td&gt;\n&lt;td align=\"right\"&gt;25-30&lt;/td&gt;\n&lt;td align=\"left\"&gt;Male&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;td align=\"right\"&gt;4,390&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;My intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we&amp;#39;ll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;user&lt;/th&gt;\n&lt;th align=\"right\"&gt;year&lt;/th&gt;\n&lt;th align=\"right\"&gt;height&lt;/th&gt;\n&lt;th align=\"right\"&gt;weight&lt;/th&gt;\n&lt;th align=\"right\"&gt;age_bucket&lt;/th&gt;\n&lt;th align=\"left\"&gt;sex&lt;/th&gt;\n&lt;th align=\"left\"&gt;postcode&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;a89bf96e&lt;/td&gt;\n&lt;td align=\"right\"&gt;2021&lt;/td&gt;\n&lt;td align=\"right\"&gt;180&lt;/td&gt;\n&lt;td align=\"right\"&gt;80&lt;/td&gt;\n&lt;td align=\"right\"&gt;25-30&lt;/td&gt;\n&lt;td align=\"left\"&gt;Male&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;From the &lt;strong&gt;user&lt;/strong&gt; and &lt;strong&gt;cell&lt;/strong&gt; tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).&lt;/p&gt;\n\n&lt;p&gt;However I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# get the total population\ntotal_population = data[&amp;#39;population&amp;#39;].sum()\n\n# get the weighted estimate\nweighted_bmi_estimate = (data[&amp;#39;survey_weight&amp;#39;] * data[&amp;#39;bmi&amp;#39;]).sum() / total_population\n\n# work out the design effect by comparing simple (SRS) and complex variance measures\n\nmean_bmi = data[&amp;#39;bmi&amp;#39;].mean()\nsimple_variance = ((data[&amp;#39;bmi&amp;#39;] - mean_bmi)**2).sum() / (total_population - 1)\n\ndata[&amp;#39;weighted_deviance&amp;#39;] = data[&amp;#39;survey_weight&amp;#39;] * (data[&amp;#39;bmi&amp;#39;] - weighted_bmi_estimate)**2\ncomplex_variance = data[&amp;#39;weighted_deviance&amp;#39;].sum() / total_population\n\ndeff = complex_variance / simple_variance\n\n# use the deff to get the rse for the bmi estimate\nrse = (deff * simple_variance)**0.5\n\n# NOTE: when doing an obesity _rate_ instead of BMI we&amp;#39;d use a different calc for the simple_variance\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Tbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it&amp;#39;d be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.&lt;/p&gt;\n\n&lt;p&gt;Further thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I will need to interpolate population counts for non-census years or otherwise just take the closest&lt;/li&gt;\n&lt;li&gt;Though I haven&amp;#39;t yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ll need to handle summation across cells when weighting by only a subset of the cell dimensions &lt;/li&gt;\n&lt;li&gt;To handle distortion from small counts, weight trimming seemed like the simplest solution but I&amp;#39;m unsure if any adjustments are necessary when determining RSEs&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using &lt;code&gt;approxQuantile&lt;/code&gt; to set the weight caps, broadcasting my means and total_populations)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "18b113j", "is_robot_indexable": true, "report_reasons": null, "author": "sansampersamp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/", "subreddit_subscribers": 1165628, "created_utc": 1701742148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI\u2019m a stats major and keep hearing the importance of computer science for any stats major who wants to get a \u201cgood\u201d job (anything beyond data analysis, though I\u2019d be completely happy with a DA job initially). \n\nMy stats major covers programming in R, python, C, and some classes involving sql, tableau, git, etc, so I have decent exposure in that regard. \n\nWhat I\u2019m worried about not having exposure to is data structures and algorithms (I guess aside from electives in text mining and in machine learning). Is it really that important for me to take these classes? I\u2019d have to take a handful of pre reqs (discrete math, programming, differential) and I really don\u2019t see myself wanting a job in that kind of data engineering/software developer role.", "author_fullname": "t2_5412hsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Value in taking classes on data structures/algorithms in stats undergrad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18atvvx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701722808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a stats major and keep hearing the importance of computer science for any stats major who wants to get a \u201cgood\u201d job (anything beyond data analysis, though I\u2019d be completely happy with a DA job initially). &lt;/p&gt;\n\n&lt;p&gt;My stats major covers programming in R, python, C, and some classes involving sql, tableau, git, etc, so I have decent exposure in that regard. &lt;/p&gt;\n\n&lt;p&gt;What I\u2019m worried about not having exposure to is data structures and algorithms (I guess aside from electives in text mining and in machine learning). Is it really that important for me to take these classes? I\u2019d have to take a handful of pre reqs (discrete math, programming, differential) and I really don\u2019t see myself wanting a job in that kind of data engineering/software developer role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18atvvx", "is_robot_indexable": true, "report_reasons": null, "author": "Voldemort57", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18atvvx/value_in_taking_classes_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18atvvx/value_in_taking_classes_on_data/", "subreddit_subscribers": 1165628, "created_utc": 1701722808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I've been on the lookout for some cool code challenges to step up my Python game and explore the data science tools a bit more. Came across these two:\n\n1. [Advent of Code](https://adventofcode.com/)\n2. [Zilliz Advent of Code](https://zilliz.com/advent-of-code)\n\nAnyone else thinking of jumping into these challenges? ", "author_fullname": "t2_54ka7fmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programming challenges", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aqknk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Challenges", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701714413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been on the lookout for some cool code challenges to step up my Python game and explore the data science tools a bit more. Came across these two:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://adventofcode.com/\"&gt;Advent of Code&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://zilliz.com/advent-of-code\"&gt;Zilliz Advent of Code&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anyone else thinking of jumping into these challenges? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "417296a0-70eb-11ee-8c58-122e95e91c4c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffd635", "id": "18aqknk", "is_robot_indexable": true, "report_reasons": null, "author": "Dry_Cattle9399", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18aqknk/programming_challenges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18aqknk/programming_challenges/", "subreddit_subscribers": 1165628, "created_utc": 1701714413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For a model training on a loss function consisting of weighted losses:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;format=png&amp;auto=webp&amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379\n\nI want to know what can be said about a model that converges based on this \u2112 loss in terms of the losses \u2112\\_i, or perhaps the models that converge on the \u2112\\_i losses seperately.For instance, if I have some guarantees / properties for models m\\_i that converge to losses \u2112\\_i, if some of those guarantees properties transition over to the model m that converges on \u2112.\n\nWould greatly appreciate links to theoretical papers that talk on this issue, or even keywords to help me in my search for such papers.\n\nThank you very much in advance for any help / guidance!", "author_fullname": "t2_3ogexpy8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "loss weighting - theoretical guarantees?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0z9fppvyab4c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/0z9fppvyab4c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9661b85b99c23c7c6347e936fb61cb9c2828066b"}], "s": {"y": 77, "x": 153, "u": "https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;format=png&amp;auto=webp&amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379"}, "id": "0z9fppvyab4c1"}}, "name": "t3_18ap2g5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/swc1M3q3qPyP2yL5WAhcG8NuaAPgbM_fB8ZW1OA46kA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701710489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a model training on a loss function consisting of weighted losses:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379\"&gt;https://preview.redd.it/0z9fppvyab4c1.png?width=153&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17375f97298b3b64b1a92ca44e4d037be8c30379&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to know what can be said about a model that converges based on this \u2112 loss in terms of the losses \u2112_i, or perhaps the models that converge on the \u2112_i losses seperately.For instance, if I have some guarantees / properties for models m_i that converge to losses \u2112_i, if some of those guarantees properties transition over to the model m that converges on \u2112.&lt;/p&gt;\n\n&lt;p&gt;Would greatly appreciate links to theoretical papers that talk on this issue, or even keywords to help me in my search for such papers.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much in advance for any help / guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "18ap2g5", "is_robot_indexable": true, "report_reasons": null, "author": "progmayo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ap2g5/loss_weighting_theoretical_guarantees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ap2g5/loss_weighting_theoretical_guarantees/", "subreddit_subscribers": 1165628, "created_utc": 1701710489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All, so i have saved an xgboost sklearn model in a pickle file and when i try to test it on unseen data, it says that predict is not found in xgboost. i have looked at all versions and tried to install the version in which it was trained but it is still showing the same result. i am currently using pyspark and made a pandas df to train my model\n\npls help!!!\n\nPS i have also tried predict\\_proba\n\nthe model im using is: xgb.XGBClassifier", "author_fullname": "t2_aohlpzsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why isnt my model testing?? Error on xgboost, predict not found", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ap3fr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701710569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, so i have saved an xgboost sklearn model in a pickle file and when i try to test it on unseen data, it says that predict is not found in xgboost. i have looked at all versions and tried to install the version in which it was trained but it is still showing the same result. i am currently using pyspark and made a pandas df to train my model&lt;/p&gt;\n\n&lt;p&gt;pls help!!!&lt;/p&gt;\n\n&lt;p&gt;PS i have also tried predict_proba&lt;/p&gt;\n\n&lt;p&gt;the model im using is: xgb.XGBClassifier&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18ap3fr", "is_robot_indexable": true, "report_reasons": null, "author": "LieTechnical1662", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ap3fr/why_isnt_my_model_testing_error_on_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ap3fr/why_isnt_my_model_testing_error_on_xgboost/", "subreddit_subscribers": 1165628, "created_utc": 1701710569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the highest paying jobs for a Master in Data Science graduate? Is the pay comparable to a career in consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18apl85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.31, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701711892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18apl85", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18apl85/what_are_the_highest_paying_jobs_for_a_master_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18apl85/what_are_the_highest_paying_jobs_for_a_master_in/", "subreddit_subscribers": 1165628, "created_utc": 1701711892.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}