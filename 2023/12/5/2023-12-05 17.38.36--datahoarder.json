{"kind": "Listing", "data": {"after": "t3_18b9sf9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "ZFS, snapshots, ECC Ram, 3 backups and a single fuckup is all it takes. I had a major pool of twelve 18TB of zRaid 3. I had 2 smaller pools of about four 14TB drives and four 16TB drives. I decided to merge them to make a single larger backup pool. Before I did that though, I tried to do a replication task to my main pool of something I didn't want to lose.\n\nThe 16 x4 drives were remote. I brought them back to location as moving 40TB of data over the internet is not ideal.\n\nGuess I screwed up the location or something and didn't notice anything wrong. Wiped my backups to be merged instead of just adding another vdev to one of them. I wanted the extra write speed performance that comes with a fresh dual vdev pool when writing as it had multiple purposes.\n\nLow and behold I noticed my personal files were just gone. The Datasets they were in just vanished. The fear sets in. That's okay, I have an encrypted 4th backup of my personal files. The encryption password wasn't working? Oh fuck, oh fuck! My most important files were there! After almost having a panic attack I keep trying different keys I have for encrypted pools but they don't work. After manually opening a json file to extract just the key for one of them does it work.\n\nWhew! I am in the clear. I back up that data. Lesson learned, have another drive unencrypted stored safely somewhere in case you also lose access to the key too.\n\nAt least my plex library looked like it wasn't touched. Try to play something but it errors out. Hmm, strange. I wonder if the permissions accidentally got changed? They did, lets fix that and get the new backup going, don't want any other heart attacks. Nope, still can't play it. Huh, strange. Go to try to play a file manually. They aren't there. Oh no. That's okay, I have snapshots I can revert to. No, all my snapshots from before today are also just gone. The data is still taking the same amount of space according to truenas. However, nothing is there. Is it corrupted now? I don't know. I can try to run a scrub but all my snapshots are just gone.\n\nMaybe when the back finishes it will allow me to view the files, but that is likely just wishful thinking. For some reason my movies are fine, but all else seems gone.\n\nNo matter how prepared you are, a little bit of misfortune and bad timing can just take it all away. If you have any potential solution to files that appear to be taking space but don't show up, I would be thrilled to hear it. The thing I am most upset about now is that I had a massive lossless music library and all the hard work I put into curating and editing metadata is just gone.\n\nIt seemed reasonable at the time, sure I would have only one copy during that time for about 24 hours until it finishes replicating, but with 3 drives of redundancy, how could it ever fail?\n\nEdit: I appear to have also had a 4th copy of my music library, unfortunately before my major lossless addition, but at least I am not at ground zero.\n\nEdit 2: Holy fuck, I might just have a chance of recovery. For whatever reason, making a replication of the bad Data appears to to produce potentially good versions. There may still be hope yet lads!\n\nEdit 3: I shit you not, I rebooted the server to clear some of the keys keeping a  backup unlocked and now everything is back to normal. Why!?! I mean I  am happy that I haven't lost everything, but why is it that rebooting  solves data loss? What went wrong? Am I just an idiot? I don't really care at this point, I am just happy it is back. Yes, I am going to verify everything first. We don't need any new problems.", "author_fullname": "t2_3cxp0v7b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Well it happened, I think lost almost everything. 40 Terabytes gone.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18auavd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 364, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 364, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701786137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701723872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ZFS, snapshots, ECC Ram, 3 backups and a single fuckup is all it takes. I had a major pool of twelve 18TB of zRaid 3. I had 2 smaller pools of about four 14TB drives and four 16TB drives. I decided to merge them to make a single larger backup pool. Before I did that though, I tried to do a replication task to my main pool of something I didn&amp;#39;t want to lose.&lt;/p&gt;\n\n&lt;p&gt;The 16 x4 drives were remote. I brought them back to location as moving 40TB of data over the internet is not ideal.&lt;/p&gt;\n\n&lt;p&gt;Guess I screwed up the location or something and didn&amp;#39;t notice anything wrong. Wiped my backups to be merged instead of just adding another vdev to one of them. I wanted the extra write speed performance that comes with a fresh dual vdev pool when writing as it had multiple purposes.&lt;/p&gt;\n\n&lt;p&gt;Low and behold I noticed my personal files were just gone. The Datasets they were in just vanished. The fear sets in. That&amp;#39;s okay, I have an encrypted 4th backup of my personal files. The encryption password wasn&amp;#39;t working? Oh fuck, oh fuck! My most important files were there! After almost having a panic attack I keep trying different keys I have for encrypted pools but they don&amp;#39;t work. After manually opening a json file to extract just the key for one of them does it work.&lt;/p&gt;\n\n&lt;p&gt;Whew! I am in the clear. I back up that data. Lesson learned, have another drive unencrypted stored safely somewhere in case you also lose access to the key too.&lt;/p&gt;\n\n&lt;p&gt;At least my plex library looked like it wasn&amp;#39;t touched. Try to play something but it errors out. Hmm, strange. I wonder if the permissions accidentally got changed? They did, lets fix that and get the new backup going, don&amp;#39;t want any other heart attacks. Nope, still can&amp;#39;t play it. Huh, strange. Go to try to play a file manually. They aren&amp;#39;t there. Oh no. That&amp;#39;s okay, I have snapshots I can revert to. No, all my snapshots from before today are also just gone. The data is still taking the same amount of space according to truenas. However, nothing is there. Is it corrupted now? I don&amp;#39;t know. I can try to run a scrub but all my snapshots are just gone.&lt;/p&gt;\n\n&lt;p&gt;Maybe when the back finishes it will allow me to view the files, but that is likely just wishful thinking. For some reason my movies are fine, but all else seems gone.&lt;/p&gt;\n\n&lt;p&gt;No matter how prepared you are, a little bit of misfortune and bad timing can just take it all away. If you have any potential solution to files that appear to be taking space but don&amp;#39;t show up, I would be thrilled to hear it. The thing I am most upset about now is that I had a massive lossless music library and all the hard work I put into curating and editing metadata is just gone.&lt;/p&gt;\n\n&lt;p&gt;It seemed reasonable at the time, sure I would have only one copy during that time for about 24 hours until it finishes replicating, but with 3 drives of redundancy, how could it ever fail?&lt;/p&gt;\n\n&lt;p&gt;Edit: I appear to have also had a 4th copy of my music library, unfortunately before my major lossless addition, but at least I am not at ground zero.&lt;/p&gt;\n\n&lt;p&gt;Edit 2: Holy fuck, I might just have a chance of recovery. For whatever reason, making a replication of the bad Data appears to to produce potentially good versions. There may still be hope yet lads!&lt;/p&gt;\n\n&lt;p&gt;Edit 3: I shit you not, I rebooted the server to clear some of the keys keeping a  backup unlocked and now everything is back to normal. Why!?! I mean I  am happy that I haven&amp;#39;t lost everything, but why is it that rebooting  solves data loss? What went wrong? Am I just an idiot? I don&amp;#39;t really care at this point, I am just happy it is back. Yes, I am going to verify everything first. We don&amp;#39;t need any new problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18auavd", "is_robot_indexable": true, "report_reasons": null, "author": "ALittleBurnerAccount", "discussion_type": null, "num_comments": 165, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18auavd/well_it_happened_i_think_lost_almost_everything/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18auavd/well_it_happened_i_think_lost_almost_everything/", "subreddit_subscribers": 716544, "created_utc": 1701723872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nSo, this company, Atlas Obscura, is well-known for unusual places and destinations. I use it all the time to plan my own trips. I think they're not doing great as of recent, and I'm afraid they might discontinue the map - as they did with the community forums last year.\n\nIs there any reasonable way to essentially \"download\" it and store locally?\n\nHere's the link: [https://www.atlasobscura.com/articles/all-places-in-the-atlas-on-one-map](https://www.atlasobscura.com/articles/all-places-in-the-atlas-on-one-map)\n\nEdit: So, even if I can make a local copy - it will look like individual place pages like this: [https://www.atlasobscura.com/places/wall-street-bombing](https://www.atlasobscura.com/places/wall-street-bombing)  \\- where it technically has Google Maps link, GPS coordinates, etc. I can even navigate individual countries through menu - as the places are grouped there. But the map (the actual map available via the link above) is hosted at Google Maps and is owned by AO, so I'm not sure if I'll be  able to download it via WGET.\n\nThanks, and sorry if this is a stupid question to ask", "author_fullname": "t2_6l9t4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A company is probably going to disappear at some point - want to save their map, need help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18arn2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 202, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 202, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701719790.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701717127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;So, this company, Atlas Obscura, is well-known for unusual places and destinations. I use it all the time to plan my own trips. I think they&amp;#39;re not doing great as of recent, and I&amp;#39;m afraid they might discontinue the map - as they did with the community forums last year.&lt;/p&gt;\n\n&lt;p&gt;Is there any reasonable way to essentially &amp;quot;download&amp;quot; it and store locally?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link: &lt;a href=\"https://www.atlasobscura.com/articles/all-places-in-the-atlas-on-one-map\"&gt;https://www.atlasobscura.com/articles/all-places-in-the-atlas-on-one-map&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: So, even if I can make a local copy - it will look like individual place pages like this: &lt;a href=\"https://www.atlasobscura.com/places/wall-street-bombing\"&gt;https://www.atlasobscura.com/places/wall-street-bombing&lt;/a&gt;  - where it technically has Google Maps link, GPS coordinates, etc. I can even navigate individual countries through menu - as the places are grouped there. But the map (the actual map available via the link above) is hosted at Google Maps and is owned by AO, so I&amp;#39;m not sure if I&amp;#39;ll be  able to download it via WGET.&lt;/p&gt;\n\n&lt;p&gt;Thanks, and sorry if this is a stupid question to ask&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HuDDtkAwRY8NpI1livrMY3laApR0q9yJBRz_FYUK2Cc.jpg?auto=webp&amp;s=13c8c463939502ec1104fa517253b5e8fa212c15", "width": 600, "height": 296}, "resolutions": [{"url": "https://external-preview.redd.it/HuDDtkAwRY8NpI1livrMY3laApR0q9yJBRz_FYUK2Cc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfb72ade213bd2a37a296ab2d5e05d9732282e49", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/HuDDtkAwRY8NpI1livrMY3laApR0q9yJBRz_FYUK2Cc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55065974b8f54d6975c02fd2460d67a004df67b8", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/HuDDtkAwRY8NpI1livrMY3laApR0q9yJBRz_FYUK2Cc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f14cfdf7d104f4c056d39537caad70f0a5d71ecb", "width": 320, "height": 157}], "variants": {}, "id": "rP7xfMhC5JJC_8Z2vdB5yVOmZvELEYCGifZb-RRYLa8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18arn2a", "is_robot_indexable": true, "report_reasons": null, "author": "FlamebergU", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18arn2a/a_company_is_probably_going_to_disappear_at_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18arn2a/a_company_is_probably_going_to_disappear_at_some/", "subreddit_subscribers": 716544, "created_utc": 1701717127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_44aeawzh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Molex to sata... Are these safe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18awjek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DVwjXsZBTtmUYhxd91LbdUqn4jvvZ_jgw-qI0QiKmYY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701729695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/c2aa6iuxvc4c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?auto=webp&amp;s=436b5958f7ba2b498419496639af347d8c04e15a", "width": 1545, "height": 1600}, "resolutions": [{"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2142b690369405f78b3bbc2519e620be5a7b47c", "width": 108, "height": 111}, {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed3149f848a8b1c9f7583631d5b5f3457f46c102", "width": 216, "height": 223}, {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb5dbcecaa44bf0d34d201c225e812a8dfe3575b", "width": 320, "height": 331}, {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38704fd91e376b1aa11c25d906bb9832a4250063", "width": 640, "height": 662}, {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e96b818731d30387f20de9a67ec4d17e3cdcbb4", "width": 960, "height": 994}, {"url": "https://preview.redd.it/c2aa6iuxvc4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb2c698d58c7bd5ae829cdb8e750be80a9f685f9", "width": 1080, "height": 1118}], "variants": {}, "id": "8xZ54LThVSrOxepXEYgrno_RFTcaNBVE15R2ivHgdO8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18awjek", "is_robot_indexable": true, "report_reasons": null, "author": "clickyk2019", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18awjek/molex_to_sata_are_these_safe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/c2aa6iuxvc4c1.jpg", "subreddit_subscribers": 716544, "created_utc": 1701729695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got complaints that Plex wasn't up.  I discovered the media mount disappeared.  Checked the Areca controller logs.  Full of \"Under Voltage\" warnings then \"Recovered\" 2 seconds later.  Then today's log shows Drive 1 going offline, then Drive 2, then Drive 16.\n\nWhat the belly rubbin' pit scratchin' nut dunkin' hell is going on.  Drive failures?  PSU?  Cage backplane? Brownouts?\n\nDrive 1 and 2 had gone back to being free drives in the array, meaning \"duh, I dunno what I am but here I am anyway\", and Drive 16 was simply offline.  I put 16 back online, which brought the RAID6 volume back online but in a degraded state.  \n\nSo full marks for Areca RAID controllers - I haven't lost any data.  \"So far\".\n\nBut having two drives fail at the same time is sus as hell but possible since those were both from the same batch/order from 5 years ago. But I dunno.  Drives 1 and 2 in the 24-bay cage failing seems like a backplane problem, but that's going to be a nightmare to isolate.  And I'm not going to rush out to buy a new PSU without knowing it's the culprit.  But at least it's not a mains voltage problem (I think - because it's all connected to a hefty UPS that feeds it nice clean smooth power.  IT BETTER BE.)\n\nI've moved drives 1 and 2 to some free slots to see if the problem follows the drive or the slot, and started a 10 hour rebuild of a 140TB array.  With 2 drives failing though I have to fallback should this thrashing session cause another drive to go offline.\n\nThis is fun.\n\nI'm fine.", "author_fullname": "t2_ldfi7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 Years of non-stop 16-drive hardware RAID6 service. Today, 2 drives failed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ay6pm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701734016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got complaints that Plex wasn&amp;#39;t up.  I discovered the media mount disappeared.  Checked the Areca controller logs.  Full of &amp;quot;Under Voltage&amp;quot; warnings then &amp;quot;Recovered&amp;quot; 2 seconds later.  Then today&amp;#39;s log shows Drive 1 going offline, then Drive 2, then Drive 16.&lt;/p&gt;\n\n&lt;p&gt;What the belly rubbin&amp;#39; pit scratchin&amp;#39; nut dunkin&amp;#39; hell is going on.  Drive failures?  PSU?  Cage backplane? Brownouts?&lt;/p&gt;\n\n&lt;p&gt;Drive 1 and 2 had gone back to being free drives in the array, meaning &amp;quot;duh, I dunno what I am but here I am anyway&amp;quot;, and Drive 16 was simply offline.  I put 16 back online, which brought the RAID6 volume back online but in a degraded state.  &lt;/p&gt;\n\n&lt;p&gt;So full marks for Areca RAID controllers - I haven&amp;#39;t lost any data.  &amp;quot;So far&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;But having two drives fail at the same time is sus as hell but possible since those were both from the same batch/order from 5 years ago. But I dunno.  Drives 1 and 2 in the 24-bay cage failing seems like a backplane problem, but that&amp;#39;s going to be a nightmare to isolate.  And I&amp;#39;m not going to rush out to buy a new PSU without knowing it&amp;#39;s the culprit.  But at least it&amp;#39;s not a mains voltage problem (I think - because it&amp;#39;s all connected to a hefty UPS that feeds it nice clean smooth power.  IT BETTER BE.)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved drives 1 and 2 to some free slots to see if the problem follows the drive or the slot, and started a 10 hour rebuild of a 140TB array.  With 2 drives failing though I have to fallback should this thrashing session cause another drive to go offline.&lt;/p&gt;\n\n&lt;p&gt;This is fun.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "150TB Areca RAID6, near, off &amp; online backup; 25 yrs 0bytes lost", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ay6pm", "is_robot_indexable": true, "report_reasons": null, "author": "SpinCharm", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18ay6pm/5_years_of_nonstop_16drive_hardware_raid6_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ay6pm/5_years_of_nonstop_16drive_hardware_raid6_service/", "subreddit_subscribers": 716544, "created_utc": 1701734016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**Background**\n\nA popular music genre exploration site [everynoise.com](https://everynoise.com/) may be suddenly shut down soon according to [this tweet](https://twitter.com/EveryNoise/status/1731690293391466897). Most likely due to Spotify wanting to charge more for API requests is what most people are thinking.\n\nOne of the best parts of this website is the ability to click on a genre or music artist and instantly hear a \"**snippet**\"(30 second audio file) of music relevant to said genre or artist. \n\n**The Problem**\n\nI've used wget to back up the main page and all individual genre links using this command:\n\n    wget --recursive --level=1 --page-requests https://everynoise.com/\n\nHowever the problem with this is that it doesn't save the \"**snippets**\" of music locally on my machine. And I can't figure out a combination of arguments to achieve this. \n\nLet me show you an example of what I'm trying to achieve. Here is a music genre page. [https://everynoise.com/engenremap-techtrance.html](https://everynoise.com/engenremap-techtrance.html)\n\nNotice that if you click on an artist's name, it will play a 30 second snippet of music. \n\n Now here's a screenshot of a portion of the page source of the previous page:  \n\n[https://i.imgur.com/qtlRCur.jpg](https://i.imgur.com/qtlRCur.jpg)\n\n\nI'm trying to download all the links highlighted in red. That way when I visit the site from my local backup on my machine, I can click on a music artist or music genre and the **snippet** of music I hear is coming from my local machine instead of the internet. \n\nAnd ultimately, my only goal is to back up the everynoise.com page, and just 1 directory down, which would be all the music genre links, artists in the music genre pages, and all the **snippets** of music. I'm not aiming to back up the ENTIRE site, as there is a lot there. Like there are links going all over the place. I just want the top directory, and 1 directory below that. \n\nMaybe this requires a script but I feel like this should be an easy thing to do. I've briefly read through the wget man page and did some googling, but I can't figure this out. And time isn't on my side, which is why I'm urgently asking for help! Thank you so much!", "author_fullname": "t2_slb8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The end may be near for everynoise.com! Need help with preserving audio files with Wget.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18armdx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701717081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;A popular music genre exploration site &lt;a href=\"https://everynoise.com/\"&gt;everynoise.com&lt;/a&gt; may be suddenly shut down soon according to &lt;a href=\"https://twitter.com/EveryNoise/status/1731690293391466897\"&gt;this tweet&lt;/a&gt;. Most likely due to Spotify wanting to charge more for API requests is what most people are thinking.&lt;/p&gt;\n\n&lt;p&gt;One of the best parts of this website is the ability to click on a genre or music artist and instantly hear a &amp;quot;&lt;strong&gt;snippet&lt;/strong&gt;&amp;quot;(30 second audio file) of music relevant to said genre or artist. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Problem&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used wget to back up the main page and all individual genre links using this command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;wget --recursive --level=1 --page-requests https://everynoise.com/\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;However the problem with this is that it doesn&amp;#39;t save the &amp;quot;&lt;strong&gt;snippets&lt;/strong&gt;&amp;quot; of music locally on my machine. And I can&amp;#39;t figure out a combination of arguments to achieve this. &lt;/p&gt;\n\n&lt;p&gt;Let me show you an example of what I&amp;#39;m trying to achieve. Here is a music genre page. &lt;a href=\"https://everynoise.com/engenremap-techtrance.html\"&gt;https://everynoise.com/engenremap-techtrance.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Notice that if you click on an artist&amp;#39;s name, it will play a 30 second snippet of music. &lt;/p&gt;\n\n&lt;p&gt;Now here&amp;#39;s a screenshot of a portion of the page source of the previous page:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.imgur.com/qtlRCur.jpg\"&gt;https://i.imgur.com/qtlRCur.jpg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to download all the links highlighted in red. That way when I visit the site from my local backup on my machine, I can click on a music artist or music genre and the &lt;strong&gt;snippet&lt;/strong&gt; of music I hear is coming from my local machine instead of the internet. &lt;/p&gt;\n\n&lt;p&gt;And ultimately, my only goal is to back up the everynoise.com page, and just 1 directory down, which would be all the music genre links, artists in the music genre pages, and all the &lt;strong&gt;snippets&lt;/strong&gt; of music. I&amp;#39;m not aiming to back up the ENTIRE site, as there is a lot there. Like there are links going all over the place. I just want the top directory, and 1 directory below that. &lt;/p&gt;\n\n&lt;p&gt;Maybe this requires a script but I feel like this should be an easy thing to do. I&amp;#39;ve briefly read through the wget man page and did some googling, but I can&amp;#39;t figure this out. And time isn&amp;#39;t on my side, which is why I&amp;#39;m urgently asking for help! Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?auto=webp&amp;s=42c4139479a07790615db7101f095a1e8bc358f0", "width": 1042, "height": 169}, "resolutions": [{"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1c8bfe02046269afc188827ea6299e822aa141c", "width": 108, "height": 17}, {"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1804ea0f26be212bfbc1fd876df6eb564dcd1519", "width": 216, "height": 35}, {"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=12c274020ee5b46c1adc1f2612a145ea46dffeeb", "width": 320, "height": 51}, {"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d7882954a7bdd4d7fd6c8dfd89be684294f7b743", "width": 640, "height": 103}, {"url": "https://external-preview.redd.it/q8meJ9x4AIbB-xwuoahJJqauUqcVgvvdZjiRkFYryAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7b61c725fb5fdda32bc4b6160ae913575732231", "width": 960, "height": 155}], "variants": {}, "id": "Jk7T7SPIF1kUshftBdiaPfxxTCrARyVW1KOf3T3iYnM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18armdx", "is_robot_indexable": true, "report_reasons": null, "author": "suddenlycirclejerk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18armdx/the_end_may_be_near_for_everynoisecom_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18armdx/the_end_may_be_near_for_everynoisecom_need_help/", "subreddit_subscribers": 716544, "created_utc": 1701717081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My work replaced a few servers sometime last year and IT finally got given the task of disposing of the old equipment. \n\nThe drives were wiped but management also wants us to do additional physical destruction. \n\nWe are just a normal small business so not government related or anything very secure.\n\nWe have a drill press and tried to drill through them. It worked to drill 1 hole in the first one then the bit for metal immeidately got dull and no longer cut through a 2nd hole. \n\nIs there a more specialised drill bit for drilling through whatever material are in HDDs.\n\nIs there an easier way to this? I read some suggestions about magnets. What sort of magnets would be required for this task. ", "author_fullname": "t2_ugxs4jup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best method for physical destruction of HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b3422", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701748507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My work replaced a few servers sometime last year and IT finally got given the task of disposing of the old equipment. &lt;/p&gt;\n\n&lt;p&gt;The drives were wiped but management also wants us to do additional physical destruction. &lt;/p&gt;\n\n&lt;p&gt;We are just a normal small business so not government related or anything very secure.&lt;/p&gt;\n\n&lt;p&gt;We have a drill press and tried to drill through them. It worked to drill 1 hole in the first one then the bit for metal immeidately got dull and no longer cut through a 2nd hole. &lt;/p&gt;\n\n&lt;p&gt;Is there a more specialised drill bit for drilling through whatever material are in HDDs.&lt;/p&gt;\n\n&lt;p&gt;Is there an easier way to this? I read some suggestions about magnets. What sort of magnets would be required for this task. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b3422", "is_robot_indexable": true, "report_reasons": null, "author": "netryn10", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b3422/best_method_for_physical_destruction_of_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b3422/best_method_for_physical_destruction_of_hdd/", "subreddit_subscribers": 716544, "created_utc": 1701748507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I got 2  of the exact same SSD, where one has 44% and says good, where the other has 80% and says caution. \nIt has less hours and written data, but why it says caution? \nIs it to be concerned?", "author_fullname": "t2_a22sm9eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "SSD with caution 80%", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4ssctwvvmh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edbbf5394bb1ab3f0e1ec1669a4c91ea4d606ad7"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ae0b72696e682d390254ba7c9024e421332da7e"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a59f40563462e36506be257a373b7bed781da988"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d631916493cacfcca88b1e2e01c97dca4f003034"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=72a41d36235b61db06483bdff065e43ca9ec6f19"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7149105287c3050e0c7e149536f592d542813689"}], "s": {"y": 3000, "x": 4000, "u": "https://preview.redd.it/4ssctwvvmh4c1.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;s=f78ef3ad99be1e83cd6c5cd2acc39c0853ba90b8"}, "id": "4ssctwvvmh4c1"}, "fdzm6b6wmh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f399857b6a970a3c50a2efbcb0c8d75f64da57ee"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e4c5680e3e29ecb87b55cd44546c5324003c0cd"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af9c8b9906144283615101a4da9521ad694d3e50"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7d0b1de4fd4876a5fcd25f5df808e0b976502a9"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=85932ddc111fd4ba84b70aaf71593f42f5dfe0d4"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b5655b2d888f04c454cdb7682a3950fa3eeae284"}], "s": {"y": 3000, "x": 4000, "u": "https://preview.redd.it/fdzm6b6wmh4c1.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;s=28f84a4a35b3d599819def110e7982577464fe6c"}, "id": "fdzm6b6wmh4c1"}}, "name": "t3_18bdeao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 4, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "4ssctwvvmh4c1", "id": 369776212}, {"media_id": "fdzm6b6wmh4c1", "id": 369776213}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Xou-KXEAwKTPQrmGjcPS3Y9QTpzcorjUKXtZEZEMCQY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701787142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I got 2  of the exact same SSD, where one has 44% and says good, where the other has 80% and says caution. \nIt has less hours and written data, but why it says caution? \nIs it to be concerned?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18bdeao", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18bdeao", "is_robot_indexable": true, "report_reasons": null, "author": "MntDewCodRed", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18bdeao/ssd_with_caution_80/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18bdeao", "subreddit_subscribers": 716544, "created_utc": 1701787142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi.\n\nSo I was finally pretty comfortable with my data storage and recovery solution (BTRFS NAS and Kopia backups), but today I realised i may need something more.\n\nI came across an issue where I wanted to watch a video. I was sure i had downloaded it previously but i couldnt find the file anywhere. It wasnt misplaced into a wrong folder, it was just gone. I wouldnt have deleted it on purpose and to delete a file i would have had to press delete AND confirm deletion. I cant see that happening. My synology logs dont show any recent changes so I cant find out when or how it was removed.\n\nSo I got out one of my 14TB externals which has a Kopia repository on it and sure enough, a snapshot from March this year had the video thats missing. this shows the importance of having incremental backups and data duplication!\n\nI am now considering restoring all of my files from around that date and comparing to my current files just to see if anyhting else is missing.\n\nIs there anything that could have been done to prevent this? I am thinking about turning off automatic emptying of the recycling bin on the NAS. Is there anything else?\n\nIs it possible that there is filesystem corruption or would the Synology have notified me? I do SMART scans every month or 3 i believe and no issues detected.", "author_fullname": "t2_qpfcy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost and recovered a file. How to prevent losing again (accidental deletion or corruption?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18aueew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701724135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;So I was finally pretty comfortable with my data storage and recovery solution (BTRFS NAS and Kopia backups), but today I realised i may need something more.&lt;/p&gt;\n\n&lt;p&gt;I came across an issue where I wanted to watch a video. I was sure i had downloaded it previously but i couldnt find the file anywhere. It wasnt misplaced into a wrong folder, it was just gone. I wouldnt have deleted it on purpose and to delete a file i would have had to press delete AND confirm deletion. I cant see that happening. My synology logs dont show any recent changes so I cant find out when or how it was removed.&lt;/p&gt;\n\n&lt;p&gt;So I got out one of my 14TB externals which has a Kopia repository on it and sure enough, a snapshot from March this year had the video thats missing. this shows the importance of having incremental backups and data duplication!&lt;/p&gt;\n\n&lt;p&gt;I am now considering restoring all of my files from around that date and comparing to my current files just to see if anyhting else is missing.&lt;/p&gt;\n\n&lt;p&gt;Is there anything that could have been done to prevent this? I am thinking about turning off automatic emptying of the recycling bin on the NAS. Is there anything else?&lt;/p&gt;\n\n&lt;p&gt;Is it possible that there is filesystem corruption or would the Synology have notified me? I do SMART scans every month or 3 i believe and no issues detected.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18aueew", "is_robot_indexable": true, "report_reasons": null, "author": "BorisTheBladee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18aueew/lost_and_recovered_a_file_how_to_prevent_losing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18aueew/lost_and_recovered_a_file_how_to_prevent_losing/", "subreddit_subscribers": 716544, "created_utc": 1701724135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hope this is okay (didn't see any rules against it), I've cross-posted this to r/DataHorder, r/HomeServer and r/HomeNAS.\n\nSorry in advance for the word vomit.  I've done some research, but nothing very detailed at this point and I'm a total noob at home server stuff but familiar with building computers, so please keep that in mind.\n\nPlease read all the way through before asking questions or making suggestions.\n\nMy parents have been asking (nagging) me to set up some kind of \"local family storage\", I originally considered getting a DAS (probably the Terramaster D6-320) and putting 6 20 TB HDDs in it.  That limits the storage to just my computer though unless I network share the drives (via Windows (nightmares ensue)).\n\nGiven the expected amount of storage needed and considering future needs, a commercial NAS is going to be way to expensive.  My total budget is $2,500 to $4,000 USD, so I'm trying to save money by making a DIY NAS with what we have on hand plus the parts needed to make it work.  Excluding the 20 TB drives, I'd like to keep the cost under $300 USD.\n\nAfter looking around the house I found five unused computers, three of them I ruled out due to lack of space for HDDs (plus other considerations)\n\n* Gateway 820GM Media Center Desktop (Intel Pentium 4), dumped on me by a family member\n* Dell Dimension 2400 (Intel Pentium 4 or Celeron, I don't remember), dumped on me by a friend\n* Custom built AMD Athlon 64 3200+ in a Cooler Master Praetorian case (built in 2003), used to be the family computer\n\nThe last two I found (details below) could possibly be used as a NAS, but I'm not sure how capable they are for the task.\n\nI would prefer to run the NAS headless after setup if possible and our LAN speed is Gigabit.\n\nI'm leaning toward Openmediavault (using BTRFS) for the OS as these are the primary uses for the NAS at this time\n\n* Mass family file storage - Currently looking at about 50 TB between two computers, two laptops, 5 external USB drives, 4 phones, 3 tablets and between 300-500 CD/DVD/BR discs (plus whatever other family members decide to send us).\n* Cloud storage for phones and tablets - I've seen NextCloud mentioned, any others I should look into?\n* My game libraries (Steam, GOG, Epic, etc.) including old floppy/CD/DVD backups and retro games\n* Backup of the local family computers (OS drives only)\n* A password manager - I know of Bitwarden, are there any others that can be self hosted?\n* A music player - Any suggestions for software?\n\nAnd finally, this is a list of the disks I'm looking at putting in the NAS\n\n* 1    ? GB SSD for boot drive (see question below)\n* 6-8  20 TB HDD for storage (to be bought)\n* 2    1 TB HDD for storage (in current computer)\n* 2  300 GB HDD for storage (in system #1)\n* 1  320 GB HDD for storage (in current computer)\n* 1  500 GB HDD for storage (in system #1)\n\nAnything important would be backed up to removable drives and all devices would be connected to the same router (hardwired (Cat 5E) for the two computers and NAS, wireless for everything else).\n\nI think that covers the current requirements, here are the two systems under consideration:\n\n&amp;#x200B;\n\nSystem #1, currently assembled (unused) (built in 2006)\n\n* CPU: AMD Athlon 64 x2 4600+ (stock heatsink)\n* Motherboard: ASUS M2N-E\n* Memory: 8 GB DDR2-800 (max for MB, Corsair or Kingston, don't remember)\n* Case: Cooler Master CM Stacker (12 5.25\" external drive bays, 11 useable due to moveable front panel I/O block)\n* GPU: HIS Radeon X1900 XT\n* Powersupply: OCZ 800 watt\n* HDDs: 2 300 GB Maxtor (SATA2/3G), 1 300 GB Maxtor (PATA/133), 1 500 GB Seagate (SATA2/3G)\n* ODD: Plextor PX-760A (PATA/133)\n\nThis was my computer until I built the one listed below and gave this to my parents.  I don't know of any issues with this system, it got used up until last year when I built a new computer for my parents and has been kept plugged in just in case it was needed for something.\n\nAfter getting the server set up, I'd remove the GPU and use the x16 slot for the needed HDD expansion/HBA card.\n\n&amp;#x200B;\n\nSystem #2, disassembled (built in 2013)\n\n* CPU: Intel i7-3770k\n* Motherboard: ASRock Z77 Extreme4 (dead?)\n* Heatsink: Cooler Master Hyper 212 Evo\n* Memory: 16 GB Corsair Vengeance LP DDR3-1600\n* GPU: Gigabyte Radeon HD7970 OC\n* Powersupply: PC Power &amp; Cooling Silencer MKII 750 watt\n\nThere is a possibility that some of these components don't work due to a malfunction or short that happened over a year ago.\n\nThis was my second computer and saw multi-hour daily use.  One day I went to get supper (computer was still on), during which there was a power blip (power dropped and instantly recovered), and when I returned the computer was off.\n\nI tried multiple things including removing everything but the CPU and heatsink and using a different power supply, but couldn't get the motherboard to power on.  The Dr.Debug never lit up even when a different power supply was used.\n\nEither the motherboard or the CPU (doubtful) shorted and I have no way of checking.  I do know the power supply turns on, but I'm not sure if there's any damage to it, the GPU or RAM.\n\nThe HDDs that were in this system are currently in other family computers as secondary storage, nobody has reported any issues with them so far.\n\nIf I use this one, the case from above would be reused after I disassembled that system.\n\n&amp;#x200B;\n\nThis is a list of the stuff I know would be needed regardless of which system was used\n\n* 4/8/12 port SATA expansion card(s) (or SAS internal 2/4/8 port controller card)\n* SATA or SATA to SAS cables (depending on card)\n* 6-8 20 TB hard drives (WD Red Pro or Seagate Iron Wolf Pro)\n* 1 4-in-3 drive cage (Cooler Master if possible), currently have 2 in the case, one is already fully populated, might look at a couple of 5-in-3, but that would raise the cost\n* 2 Molex to 4 SATA adapter or SATA extension\n* 1 SSD for boot drive\n\n&amp;#x200B;\n\nIf I do system #2 then I'd also need\n\n* Z77 Motherboard\n\n&amp;#x200B;\n\nQuestions about the system hardware under consideration:\n\n1. Is system #1 viable?  I'm doubtful that it would be up to the task as it only has PCIe Gen1 and SATA2/3G capabilities.  Am I correct and it should be kept for emergency use only or is there something I'm overlooking?\n2. Is system #2 worth taking a chance on with a used motherboard and hope for the best?\n3. Would a different NAS OS suit my use case and hardware better?  Please note that Unraid is out because I'd have to pay for it.\n\n&amp;#x200B;\n\nQuestions about the extra hardware:\n\n1. Most of the 8+ port SATA expansion cards on Amazon seem to be of the PCIe x1 variety.  Is this okay or should I be looking for PCIe x4 or x8?\n2. Would it be better to just get a SAS HBA card?  Going by this ([https://servers.hydrology.cc/2023/01/21/i-ran-out-of-sata-ports/](https://servers.hydrology.cc/2023/01/21/i-ran-out-of-sata-ports/)) should I only consider a 16i HBA given how many storage drives I'm planning to use?\n3. Any recommendations for a 4/5-in-3 drive cage with a SATA backplane that doesn't cost a lot (less than $40 USD)?  All the ones I'm finding are $70+.\n4. What is the smallest SSD that I should get for the boot drive?  Could I use a 16 or 8 GB?\n\n&amp;#x200B;\n\nAnd now for some questions about HDD setup, this is how I'm thinking of doing it:\n\n    Pool 1 - family mass storage\n        3 20 TB (2 data, 1 parity)\n    Pool 2 - cloud storage and music\n        3 20 TB (2 data, 1 parity)\n    Pool 3 - games library, current\n        1 20 TB\n    Pool 4 - games library, retro\n        1 20 TB\n    Pool 5 - system backups\n        2 300 GB (data)\n        1 320 GB (data)\n        1 500 GB (data)\n        1 1 TB (data)\n        1 1 TB (parity)\n\nGiven the above layout, and considering I'm planning to use BTRFS, could I do away with the parity drives?  This would reduce the number of 20 TB drives I'd need to buy and as stated earlier anything important will be backed up to removable drives.\n\nWould it be better to combine Pool 1 &amp; 2?  How would this affect whatever cloud storage and music software I go with and family shares?  Is there a better layout?\n\nI'm not worried about my game libraries as most of the current ones have some kind of file integrity checker and my old media and retro games are already backed up in at least three other places.\n\n&amp;#x200B;\n\nI'm sure there's stuff I forgot to mention, so please feel free to ask.\n\nThanks for taking the time to read this, and for any constructive criticism or advice.", "author_fullname": "t2_m8f4a6f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use any of this old hardware for a NAS? (plus a few questions)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b8q6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701770777.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701770469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this is okay (didn&amp;#39;t see any rules against it), I&amp;#39;ve cross-posted this to &lt;a href=\"/r/DataHorder\"&gt;r/DataHorder&lt;/a&gt;, &lt;a href=\"/r/HomeServer\"&gt;r/HomeServer&lt;/a&gt; and &lt;a href=\"/r/HomeNAS\"&gt;r/HomeNAS&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Sorry in advance for the word vomit.  I&amp;#39;ve done some research, but nothing very detailed at this point and I&amp;#39;m a total noob at home server stuff but familiar with building computers, so please keep that in mind.&lt;/p&gt;\n\n&lt;p&gt;Please read all the way through before asking questions or making suggestions.&lt;/p&gt;\n\n&lt;p&gt;My parents have been asking (nagging) me to set up some kind of &amp;quot;local family storage&amp;quot;, I originally considered getting a DAS (probably the Terramaster D6-320) and putting 6 20 TB HDDs in it.  That limits the storage to just my computer though unless I network share the drives (via Windows (nightmares ensue)).&lt;/p&gt;\n\n&lt;p&gt;Given the expected amount of storage needed and considering future needs, a commercial NAS is going to be way to expensive.  My total budget is $2,500 to $4,000 USD, so I&amp;#39;m trying to save money by making a DIY NAS with what we have on hand plus the parts needed to make it work.  Excluding the 20 TB drives, I&amp;#39;d like to keep the cost under $300 USD.&lt;/p&gt;\n\n&lt;p&gt;After looking around the house I found five unused computers, three of them I ruled out due to lack of space for HDDs (plus other considerations)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Gateway 820GM Media Center Desktop (Intel Pentium 4), dumped on me by a family member&lt;/li&gt;\n&lt;li&gt;Dell Dimension 2400 (Intel Pentium 4 or Celeron, I don&amp;#39;t remember), dumped on me by a friend&lt;/li&gt;\n&lt;li&gt;Custom built AMD Athlon 64 3200+ in a Cooler Master Praetorian case (built in 2003), used to be the family computer&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The last two I found (details below) could possibly be used as a NAS, but I&amp;#39;m not sure how capable they are for the task.&lt;/p&gt;\n\n&lt;p&gt;I would prefer to run the NAS headless after setup if possible and our LAN speed is Gigabit.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m leaning toward Openmediavault (using BTRFS) for the OS as these are the primary uses for the NAS at this time&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mass family file storage - Currently looking at about 50 TB between two computers, two laptops, 5 external USB drives, 4 phones, 3 tablets and between 300-500 CD/DVD/BR discs (plus whatever other family members decide to send us).&lt;/li&gt;\n&lt;li&gt;Cloud storage for phones and tablets - I&amp;#39;ve seen NextCloud mentioned, any others I should look into?&lt;/li&gt;\n&lt;li&gt;My game libraries (Steam, GOG, Epic, etc.) including old floppy/CD/DVD backups and retro games&lt;/li&gt;\n&lt;li&gt;Backup of the local family computers (OS drives only)&lt;/li&gt;\n&lt;li&gt;A password manager - I know of Bitwarden, are there any others that can be self hosted?&lt;/li&gt;\n&lt;li&gt;A music player - Any suggestions for software?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And finally, this is a list of the disks I&amp;#39;m looking at putting in the NAS&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1    ? GB SSD for boot drive (see question below)&lt;/li&gt;\n&lt;li&gt;6-8  20 TB HDD for storage (to be bought)&lt;/li&gt;\n&lt;li&gt;2    1 TB HDD for storage (in current computer)&lt;/li&gt;\n&lt;li&gt;2  300 GB HDD for storage (in system #1)&lt;/li&gt;\n&lt;li&gt;1  320 GB HDD for storage (in current computer)&lt;/li&gt;\n&lt;li&gt;1  500 GB HDD for storage (in system #1)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anything important would be backed up to removable drives and all devices would be connected to the same router (hardwired (Cat 5E) for the two computers and NAS, wireless for everything else).&lt;/p&gt;\n\n&lt;p&gt;I think that covers the current requirements, here are the two systems under consideration:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;System #1, currently assembled (unused) (built in 2006)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CPU: AMD Athlon 64 x2 4600+ (stock heatsink)&lt;/li&gt;\n&lt;li&gt;Motherboard: ASUS M2N-E&lt;/li&gt;\n&lt;li&gt;Memory: 8 GB DDR2-800 (max for MB, Corsair or Kingston, don&amp;#39;t remember)&lt;/li&gt;\n&lt;li&gt;Case: Cooler Master CM Stacker (12 5.25&amp;quot; external drive bays, 11 useable due to moveable front panel I/O block)&lt;/li&gt;\n&lt;li&gt;GPU: HIS Radeon X1900 XT&lt;/li&gt;\n&lt;li&gt;Powersupply: OCZ 800 watt&lt;/li&gt;\n&lt;li&gt;HDDs: 2 300 GB Maxtor (SATA2/3G), 1 300 GB Maxtor (PATA/133), 1 500 GB Seagate (SATA2/3G)&lt;/li&gt;\n&lt;li&gt;ODD: Plextor PX-760A (PATA/133)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This was my computer until I built the one listed below and gave this to my parents.  I don&amp;#39;t know of any issues with this system, it got used up until last year when I built a new computer for my parents and has been kept plugged in just in case it was needed for something.&lt;/p&gt;\n\n&lt;p&gt;After getting the server set up, I&amp;#39;d remove the GPU and use the x16 slot for the needed HDD expansion/HBA card.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;System #2, disassembled (built in 2013)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CPU: Intel i7-3770k&lt;/li&gt;\n&lt;li&gt;Motherboard: ASRock Z77 Extreme4 (dead?)&lt;/li&gt;\n&lt;li&gt;Heatsink: Cooler Master Hyper 212 Evo&lt;/li&gt;\n&lt;li&gt;Memory: 16 GB Corsair Vengeance LP DDR3-1600&lt;/li&gt;\n&lt;li&gt;GPU: Gigabyte Radeon HD7970 OC&lt;/li&gt;\n&lt;li&gt;Powersupply: PC Power &amp;amp; Cooling Silencer MKII 750 watt&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There is a possibility that some of these components don&amp;#39;t work due to a malfunction or short that happened over a year ago.&lt;/p&gt;\n\n&lt;p&gt;This was my second computer and saw multi-hour daily use.  One day I went to get supper (computer was still on), during which there was a power blip (power dropped and instantly recovered), and when I returned the computer was off.&lt;/p&gt;\n\n&lt;p&gt;I tried multiple things including removing everything but the CPU and heatsink and using a different power supply, but couldn&amp;#39;t get the motherboard to power on.  The Dr.Debug never lit up even when a different power supply was used.&lt;/p&gt;\n\n&lt;p&gt;Either the motherboard or the CPU (doubtful) shorted and I have no way of checking.  I do know the power supply turns on, but I&amp;#39;m not sure if there&amp;#39;s any damage to it, the GPU or RAM.&lt;/p&gt;\n\n&lt;p&gt;The HDDs that were in this system are currently in other family computers as secondary storage, nobody has reported any issues with them so far.&lt;/p&gt;\n\n&lt;p&gt;If I use this one, the case from above would be reused after I disassembled that system.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is a list of the stuff I know would be needed regardless of which system was used&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4/8/12 port SATA expansion card(s) (or SAS internal 2/4/8 port controller card)&lt;/li&gt;\n&lt;li&gt;SATA or SATA to SAS cables (depending on card)&lt;/li&gt;\n&lt;li&gt;6-8 20 TB hard drives (WD Red Pro or Seagate Iron Wolf Pro)&lt;/li&gt;\n&lt;li&gt;1 4-in-3 drive cage (Cooler Master if possible), currently have 2 in the case, one is already fully populated, might look at a couple of 5-in-3, but that would raise the cost&lt;/li&gt;\n&lt;li&gt;2 Molex to 4 SATA adapter or SATA extension&lt;/li&gt;\n&lt;li&gt;1 SSD for boot drive&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I do system #2 then I&amp;#39;d also need&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Z77 Motherboard&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Questions about the system hardware under consideration:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is system #1 viable?  I&amp;#39;m doubtful that it would be up to the task as it only has PCIe Gen1 and SATA2/3G capabilities.  Am I correct and it should be kept for emergency use only or is there something I&amp;#39;m overlooking?&lt;/li&gt;\n&lt;li&gt;Is system #2 worth taking a chance on with a used motherboard and hope for the best?&lt;/li&gt;\n&lt;li&gt;Would a different NAS OS suit my use case and hardware better?  Please note that Unraid is out because I&amp;#39;d have to pay for it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Questions about the extra hardware:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Most of the 8+ port SATA expansion cards on Amazon seem to be of the PCIe x1 variety.  Is this okay or should I be looking for PCIe x4 or x8?&lt;/li&gt;\n&lt;li&gt;Would it be better to just get a SAS HBA card?  Going by this (&lt;a href=\"https://servers.hydrology.cc/2023/01/21/i-ran-out-of-sata-ports/\"&gt;https://servers.hydrology.cc/2023/01/21/i-ran-out-of-sata-ports/&lt;/a&gt;) should I only consider a 16i HBA given how many storage drives I&amp;#39;m planning to use?&lt;/li&gt;\n&lt;li&gt;Any recommendations for a 4/5-in-3 drive cage with a SATA backplane that doesn&amp;#39;t cost a lot (less than $40 USD)?  All the ones I&amp;#39;m finding are $70+.&lt;/li&gt;\n&lt;li&gt;What is the smallest SSD that I should get for the boot drive?  Could I use a 16 or 8 GB?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And now for some questions about HDD setup, this is how I&amp;#39;m thinking of doing it:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Pool 1 - family mass storage\n    3 20 TB (2 data, 1 parity)\nPool 2 - cloud storage and music\n    3 20 TB (2 data, 1 parity)\nPool 3 - games library, current\n    1 20 TB\nPool 4 - games library, retro\n    1 20 TB\nPool 5 - system backups\n    2 300 GB (data)\n    1 320 GB (data)\n    1 500 GB (data)\n    1 1 TB (data)\n    1 1 TB (parity)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Given the above layout, and considering I&amp;#39;m planning to use BTRFS, could I do away with the parity drives?  This would reduce the number of 20 TB drives I&amp;#39;d need to buy and as stated earlier anything important will be backed up to removable drives.&lt;/p&gt;\n\n&lt;p&gt;Would it be better to combine Pool 1 &amp;amp; 2?  How would this affect whatever cloud storage and music software I go with and family shares?  Is there a better layout?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not worried about my game libraries as most of the current ones have some kind of file integrity checker and my old media and retro games are already backed up in at least three other places.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s stuff I forgot to mention, so please feel free to ask.&lt;/p&gt;\n\n&lt;p&gt;Thanks for taking the time to read this, and for any constructive criticism or advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b8q6w", "is_robot_indexable": true, "report_reasons": null, "author": "RonnieOnReddit", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b8q6w/can_i_use_any_of_this_old_hardware_for_a_nas_plus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b8q6w/can_i_use_any_of_this_old_hardware_for_a_nas_plus/", "subreddit_subscribers": 716544, "created_utc": 1701770469.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Since this is about data, how would you go by in terms of digitizing hard copy documents. Do you just normally scan individual pages. What software do you use? I have a brother printer and scanner all in one. It has multifeed function. But wondering if this is the effiencent way.", "author_fullname": "t2_xq820", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you guys recommend about digitisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ax3t5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701731164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since this is about data, how would you go by in terms of digitizing hard copy documents. Do you just normally scan individual pages. What software do you use? I have a brother printer and scanner all in one. It has multifeed function. But wondering if this is the effiencent way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ax3t5", "is_robot_indexable": true, "report_reasons": null, "author": "Inkopol", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ax3t5/what_do_you_guys_recommend_about_digitisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ax3t5/what_do_you_guys_recommend_about_digitisation/", "subreddit_subscribers": 716544, "created_utc": 1701731164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Context:\n\nMy wife and I are looking to reduce monthly bills, especially after having our 1 year old and noticing our spending.\n\nAt the moment we have Spotify (\u00a311p/month - only 1 account), Disney+ (\u00a38/month), Netflix (\u00a38/month) &amp; Prime (\u00a39/month). I believe Netflix should be more expensive but for some reason ours is \u00a38 for standard. So total of \u00a336/month.\n\nSo I'm toying with the idea of getting a NAS drive, somethings like the QNAP TS-464 + 4 x 8TB IronWolfs = \\~\u00a31400 + PLEX premium \u00a32.90/month (based on annual billing) and use that to stream music/tv/movies that I have. I'd estimate if I left the NAS on permanently that it would consume about \u00a38/month of energy (I've made some assumptions here but if anyone has any feedback about how realistic this is please LMK)\n\nBut if you say replace HDDs/NAS drive setup every 5 years, then the set up over a 5 year period becomes \u00a323.33 p/month so with PLEX + running costs \\~ \u00a334.23/month which really isn't much cheaper than subscribing to most streaming services as we are now. So why do lots of people use NAS + PLEX? Am I missing somethings, or is there a way to bring down costs?\n\nMuch appreciated!", "author_fullname": "t2_eadenkqm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are NAS drives financially viable for my intended use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bco4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701785085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context:&lt;/p&gt;\n\n&lt;p&gt;My wife and I are looking to reduce monthly bills, especially after having our 1 year old and noticing our spending.&lt;/p&gt;\n\n&lt;p&gt;At the moment we have Spotify (\u00a311p/month - only 1 account), Disney+ (\u00a38/month), Netflix (\u00a38/month) &amp;amp; Prime (\u00a39/month). I believe Netflix should be more expensive but for some reason ours is \u00a38 for standard. So total of \u00a336/month.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m toying with the idea of getting a NAS drive, somethings like the QNAP TS-464 + 4 x 8TB IronWolfs = ~\u00a31400 + PLEX premium \u00a32.90/month (based on annual billing) and use that to stream music/tv/movies that I have. I&amp;#39;d estimate if I left the NAS on permanently that it would consume about \u00a38/month of energy (I&amp;#39;ve made some assumptions here but if anyone has any feedback about how realistic this is please LMK)&lt;/p&gt;\n\n&lt;p&gt;But if you say replace HDDs/NAS drive setup every 5 years, then the set up over a 5 year period becomes \u00a323.33 p/month so with PLEX + running costs ~ \u00a334.23/month which really isn&amp;#39;t much cheaper than subscribing to most streaming services as we are now. So why do lots of people use NAS + PLEX? Am I missing somethings, or is there a way to bring down costs?&lt;/p&gt;\n\n&lt;p&gt;Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18bco4t", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Zelei-Good", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18bco4t/are_nas_drives_financially_viable_for_my_intended/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18bco4t/are_nas_drives_financially_viable_for_my_intended/", "subreddit_subscribers": 716544, "created_utc": 1701785085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I current have the Sabrent EC-WPNE losses connection to the slightest bump. It's extremely frustrating when I'm trying to move files. \n\nSince I'm upgrading, I'm hoping I can find something that can work with both HDD and SSDs. I'll be using it with a Macbook. \n\nDo you guys also have any suggestions for cables? Maybe the connection issue is also due to a bad cable. Would it also be possible that it's just due to a worn out port? \n\nThank you!", "author_fullname": "t2_wo67s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended SSD/HDD External docks/adapters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b2okm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701747149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I current have the Sabrent EC-WPNE losses connection to the slightest bump. It&amp;#39;s extremely frustrating when I&amp;#39;m trying to move files. &lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m upgrading, I&amp;#39;m hoping I can find something that can work with both HDD and SSDs. I&amp;#39;ll be using it with a Macbook. &lt;/p&gt;\n\n&lt;p&gt;Do you guys also have any suggestions for cables? Maybe the connection issue is also due to a bad cable. Would it also be possible that it&amp;#39;s just due to a worn out port? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b2okm", "is_robot_indexable": true, "report_reasons": null, "author": "Jasonwj322a", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18b2okm/recommended_ssdhdd_external_docksadapters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b2okm/recommended_ssdhdd_external_docksadapters/", "subreddit_subscribers": 716544, "created_utc": 1701747149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have tried everything I can think of to grab these episodes but nothing I have tried has succeeded. My last attempt was using \"getFLV\" it failed as well. \n\nThis is the site:\n\n[http://starcade.tv/starcade/games/shows.html](http://starcade.tv/starcade/games/shows.html)\n\nAny help would be appreciated.\n\nSolved!!!\n\nThanks to you all!\n\n", "author_fullname": "t2_7w9n5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help grabbing videos from a website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18azaho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701739273.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701737057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tried everything I can think of to grab these episodes but nothing I have tried has succeeded. My last attempt was using &amp;quot;getFLV&amp;quot; it failed as well. &lt;/p&gt;\n\n&lt;p&gt;This is the site:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://starcade.tv/starcade/games/shows.html\"&gt;http://starcade.tv/starcade/games/shows.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Solved!!!&lt;/p&gt;\n\n&lt;p&gt;Thanks to you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18azaho", "is_robot_indexable": true, "report_reasons": null, "author": "Cosmologyman", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18azaho/need_help_grabbing_videos_from_a_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18azaho/need_help_grabbing_videos_from_a_website/", "subreddit_subscribers": 716544, "created_utc": 1701737057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "While browsing the web, I read a shit ton of material about all kinds of stuff, and naturally I cannot read them all at once, and I need to store them for the future, in an accessible form so that I actually read the stuff and not procrastinate.\n\nI have used pocket and instapaper in the past but neither of those really hit the mark for me. I need a service where you can neatly archive articles, web pages and youtube videos in a neat manner, sorted in folders. It must have a well designed android app and should be free, because I'm broke as fuck.\n\nThanks!", "author_fullname": "t2_3q3fcazv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a service to archive and save articles for later.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18bg8qs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701794687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While browsing the web, I read a shit ton of material about all kinds of stuff, and naturally I cannot read them all at once, and I need to store them for the future, in an accessible form so that I actually read the stuff and not procrastinate.&lt;/p&gt;\n\n&lt;p&gt;I have used pocket and instapaper in the past but neither of those really hit the mark for me. I need a service where you can neatly archive articles, web pages and youtube videos in a neat manner, sorted in folders. It must have a well designed android app and should be free, because I&amp;#39;m broke as fuck.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18bg8qs", "is_robot_indexable": true, "report_reasons": null, "author": "RealTigres", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18bg8qs/recommendations_for_a_service_to_archive_and_save/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18bg8qs/recommendations_for_a_service_to_archive_and_save/", "subreddit_subscribers": 716544, "created_utc": 1701794687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been a long time user of Drivepool, but I\"m building a new home server and considering other options.\n\nunRAID is on the list of candidates, but I have a few questions...\n\nI like that Drivepool lets you pool a bunch of dissimilar disks, automatically balance them, but most importantly; duplicate selected files/folders as many times as you like.\n\nExample, I have a folder with data I cannot lose - I can set this data to be duplicated as many times as I have disks. Now that data is on every physical disk I have - is there a similar function with unRAID?\n\nI also like how you can tell Drivepool that certain folders \\*only\\* get stored on certain disks, and not on others - can unRAID do this?\n\nAppreciate any feedback. :)", "author_fullname": "t2_138kq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drivepool vs unRAID - Duplication of files / folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18be0be", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701789107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a long time user of Drivepool, but I&amp;quot;m building a new home server and considering other options.&lt;/p&gt;\n\n&lt;p&gt;unRAID is on the list of candidates, but I have a few questions...&lt;/p&gt;\n\n&lt;p&gt;I like that Drivepool lets you pool a bunch of dissimilar disks, automatically balance them, but most importantly; duplicate selected files/folders as many times as you like.&lt;/p&gt;\n\n&lt;p&gt;Example, I have a folder with data I cannot lose - I can set this data to be duplicated as many times as I have disks. Now that data is on every physical disk I have - is there a similar function with unRAID?&lt;/p&gt;\n\n&lt;p&gt;I also like how you can tell Drivepool that certain folders *only* get stored on certain disks, and not on others - can unRAID do this?&lt;/p&gt;\n\n&lt;p&gt;Appreciate any feedback. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18be0be", "is_robot_indexable": true, "report_reasons": null, "author": "brobotbee", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18be0be/drivepool_vs_unraid_duplication_of_files_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18be0be/drivepool_vs_unraid_duplication_of_files_folders/", "subreddit_subscribers": 716544, "created_utc": 1701789107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all! \nI've run out of internal HDD space on my home unraid server (it's a simple tower I had laying around.) I still have sata ports on the mobile but I'm also running out of sata power on my PSU, however I could use some converters splitters because my avg load is around 50-100W and my PSU is 500W with 1 unused 6pin and 1 6+2 pin pci-e. \nWhat do you guys think / recommend as the best solution? \nLooking for some external bays with power, without power, or simply getting some adapters for the unused pcie lanes if there is even such a thing? \n\nThank you in advance!", "author_fullname": "t2_1381kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External HDD enclosure with power to disks? Or other solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b74ga", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701763226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! \nI&amp;#39;ve run out of internal HDD space on my home unraid server (it&amp;#39;s a simple tower I had laying around.) I still have sata ports on the mobile but I&amp;#39;m also running out of sata power on my PSU, however I could use some converters splitters because my avg load is around 50-100W and my PSU is 500W with 1 unused 6pin and 1 6+2 pin pci-e. \nWhat do you guys think / recommend as the best solution? \nLooking for some external bays with power, without power, or simply getting some adapters for the unused pcie lanes if there is even such a thing? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "18TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b74ga", "is_robot_indexable": true, "report_reasons": null, "author": "Shapperd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18b74ga/external_hdd_enclosure_with_power_to_disks_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b74ga/external_hdd_enclosure_with_power_to_disks_or/", "subreddit_subscribers": 716544, "created_utc": 1701763226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there!\n\nSo having purchased a Mini ITX, I have no room for the 3.5\" Ultrastars I have at 18TB.\n\nI am looking for a nice sleek dual bay desk enclosure (USB 3.1, no RAID) preferably silver or white, that will work with these drives :)\n\n&amp;#x200B;\n\nThe Yottamaster ones on Amazon and Ali Express say \"2X16TB MAX\" but I am not sure if it's because that was the max when it was made or whatever.... ", "author_fullname": "t2_9a5802tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dual 3.5\" USB 3.1 Enclosure for 2x18TB Ultrastar?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b69f5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701759554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;So having purchased a Mini ITX, I have no room for the 3.5&amp;quot; Ultrastars I have at 18TB.&lt;/p&gt;\n\n&lt;p&gt;I am looking for a nice sleek dual bay desk enclosure (USB 3.1, no RAID) preferably silver or white, that will work with these drives :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Yottamaster ones on Amazon and Ali Express say &amp;quot;2X16TB MAX&amp;quot; but I am not sure if it&amp;#39;s because that was the max when it was made or whatever.... &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b69f5", "is_robot_indexable": true, "report_reasons": null, "author": "testicularbat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b69f5/dual_35_usb_31_enclosure_for_2x18tb_ultrastar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b69f5/dual_35_usb_31_enclosure_for_2x18tb_ultrastar/", "subreddit_subscribers": 716544, "created_utc": 1701759554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to scan larger format Japanese magazines. The sheets are \"A4 wide\", averaging around 9.2\" x 11.7\". Every sheet fed scanner I can find, mostly being the ScanSnap line, only go up to A4. I initially bought a ScanSnap iX1400 thinking it would potentially have the slight bit of extra clearance, but it didn't and the sheet were less than half an inch too wide. My fault. So then I order the ScanSnap iX1500 because the product page specifically states it does up to A3. Great I'm thinking! A3 is wider than I need but will at least allow me to scan my 20 goddamn magazines!\n\nNOPE. Because it doesn't support up to A3 size, it's the SAME GODDAMN SIZE. You have to use a special feeding sheet, and completely bend the oversized sheet in half to scan it. Not only would that defeat the whole point of speed using a sheet-fed scanner, but it would ruin the page which is also not an option. I'm pissed that I now have $900 in pending Amazon returns because both these stupid goddamn scanners weren't wide enough.\n\nSo I need advice from anyone else who's scanned oversized magazines. Do I:\n\nA) Buy this actual A3 scanner from a lesser known brand: [Scanner](https://www.amazon.com/Plustek-SmartOffice-Document-100-page-Legal-Size/dp/B0BJZBRNQR/ref=cm_cr_arp_d_product_top?ie=UTF8). While this one seems like it would work, it has minimal reviews and multiple of them mention that the scanner is bad for photos. I'm scanning magazine pages that feature full-color illustrations almost every page and have a slight gloss to them, and being that I want to archive them quality is important. I would hate to buy a 3rd goddamn scanner just to have to initiate yet another return because it doesn't work.\n\nB) Do I cut my losses completely and just buy a A3 size flatbed scanner. I wanted a sheet-fed scanner because I have many hundreds of pages to scan, and doing it page by page sounded like a nightmare. At this point I'm starting to feel it's the only option.\n\nPlease, if anyone has a product that they think will work for my unique problem, I'm very open to suggestions at this point.\n\nBefore anyone asks, it's not possible to cut the pages down. Many of the pages would loose sections of artwork or even text if I cut the spine all the way to be exactly A4 size. Defeats the whole point of preservation.", "author_fullname": "t2_1063dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At my wits ends trying to find a way to scan magazines larger than A4 size, any recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b02tx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701739325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to scan larger format Japanese magazines. The sheets are &amp;quot;A4 wide&amp;quot;, averaging around 9.2&amp;quot; x 11.7&amp;quot;. Every sheet fed scanner I can find, mostly being the ScanSnap line, only go up to A4. I initially bought a ScanSnap iX1400 thinking it would potentially have the slight bit of extra clearance, but it didn&amp;#39;t and the sheet were less than half an inch too wide. My fault. So then I order the ScanSnap iX1500 because the product page specifically states it does up to A3. Great I&amp;#39;m thinking! A3 is wider than I need but will at least allow me to scan my 20 goddamn magazines!&lt;/p&gt;\n\n&lt;p&gt;NOPE. Because it doesn&amp;#39;t support up to A3 size, it&amp;#39;s the SAME GODDAMN SIZE. You have to use a special feeding sheet, and completely bend the oversized sheet in half to scan it. Not only would that defeat the whole point of speed using a sheet-fed scanner, but it would ruin the page which is also not an option. I&amp;#39;m pissed that I now have $900 in pending Amazon returns because both these stupid goddamn scanners weren&amp;#39;t wide enough.&lt;/p&gt;\n\n&lt;p&gt;So I need advice from anyone else who&amp;#39;s scanned oversized magazines. Do I:&lt;/p&gt;\n\n&lt;p&gt;A) Buy this actual A3 scanner from a lesser known brand: &lt;a href=\"https://www.amazon.com/Plustek-SmartOffice-Document-100-page-Legal-Size/dp/B0BJZBRNQR/ref=cm_cr_arp_d_product_top?ie=UTF8\"&gt;Scanner&lt;/a&gt;. While this one seems like it would work, it has minimal reviews and multiple of them mention that the scanner is bad for photos. I&amp;#39;m scanning magazine pages that feature full-color illustrations almost every page and have a slight gloss to them, and being that I want to archive them quality is important. I would hate to buy a 3rd goddamn scanner just to have to initiate yet another return because it doesn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;B) Do I cut my losses completely and just buy a A3 size flatbed scanner. I wanted a sheet-fed scanner because I have many hundreds of pages to scan, and doing it page by page sounded like a nightmare. At this point I&amp;#39;m starting to feel it&amp;#39;s the only option.&lt;/p&gt;\n\n&lt;p&gt;Please, if anyone has a product that they think will work for my unique problem, I&amp;#39;m very open to suggestions at this point.&lt;/p&gt;\n\n&lt;p&gt;Before anyone asks, it&amp;#39;s not possible to cut the pages down. Many of the pages would loose sections of artwork or even text if I cut the spine all the way to be exactly A4 size. Defeats the whole point of preservation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b02tx", "is_robot_indexable": true, "report_reasons": null, "author": "Killerabbet", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b02tx/at_my_wits_ends_trying_to_find_a_way_to_scan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b02tx/at_my_wits_ends_trying_to_find_a_way_to_scan/", "subreddit_subscribers": 716544, "created_utc": 1701739325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I realize initially the question might sound insane \n\n\"Yes you idiot\" you're screaming at me BACKUP EVERYTHING!\n\nbut as we all know backing up routinely and hw maintenance and upkeep is a process in it of itself so you have to do some cost- benefit assessment.\n\ndo you trust Google drive and Microsoft OneDrive enough to save low to middle priority stuff without doing full backup constantly\n\nI also realize many of you are sophisticated enough to automate this I am however not this savvy. I know with the desktop app you can mirror the same data locally but my issue is I don't have the hardware resources to spare running this from a memory and storage perspective (older hardware) as the computer I'm using is also my daily driver \n\nmaybe if they mirrored to a NAS or something that I didn't have to look at or didnt run persistently on my desktop it would be more feasible. \n\nI ask because I have used lesser known cloud storage services that have since gone belly up and I don't see the aforementioned services going away anytime soon.", "author_fullname": "t2_cr0oek3e9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you bother with backing up small quick data saved on Google or oneDrive into local backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18awtjf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701730424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I realize initially the question might sound insane &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Yes you idiot&amp;quot; you&amp;#39;re screaming at me BACKUP EVERYTHING!&lt;/p&gt;\n\n&lt;p&gt;but as we all know backing up routinely and hw maintenance and upkeep is a process in it of itself so you have to do some cost- benefit assessment.&lt;/p&gt;\n\n&lt;p&gt;do you trust Google drive and Microsoft OneDrive enough to save low to middle priority stuff without doing full backup constantly&lt;/p&gt;\n\n&lt;p&gt;I also realize many of you are sophisticated enough to automate this I am however not this savvy. I know with the desktop app you can mirror the same data locally but my issue is I don&amp;#39;t have the hardware resources to spare running this from a memory and storage perspective (older hardware) as the computer I&amp;#39;m using is also my daily driver &lt;/p&gt;\n\n&lt;p&gt;maybe if they mirrored to a NAS or something that I didn&amp;#39;t have to look at or didnt run persistently on my desktop it would be more feasible. &lt;/p&gt;\n\n&lt;p&gt;I ask because I have used lesser known cloud storage services that have since gone belly up and I don&amp;#39;t see the aforementioned services going away anytime soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18awtjf", "is_robot_indexable": true, "report_reasons": null, "author": "Saergreen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18awtjf/do_you_bother_with_backing_up_small_quick_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18awtjf/do_you_bother_with_backing_up_small_quick_data/", "subreddit_subscribers": 716544, "created_utc": 1701730424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I now have posted the full values. \n\nI don't get why the less used SSD, with less runtime and less written and read data is caution and the other is good.", "author_fullname": "t2_a22sm9eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Why is one 44% good and one 80% caution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fg6051vluh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d7f2507a6324dc70393c53a945681e859594070"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0fb78edb37d0e08aa3c175073e5737cc0432149"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43be4f01182714be894bce07e41dfe5597e743d6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60a0d40c972e7c466cbac68660f7e686c4ed8b7b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8494774f20e4a104e7e4b6dfa21ce85fe89a4165"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7002c2550c4e145028f29e6867eafaac7300115e"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/fg6051vluh4c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=ff476e484033810f21ca2bd93ed70b5006a0f362"}, "id": "fg6051vluh4c1"}, "hokoyjnmuh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7faefbd2abdc173a06562ab23d8d4a2a53cd7f86"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=34f19027111b9257d192b9a6e41e9b0cfadaa66b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a70cda7b40f5c7c459b29b88e248e36d46225c0"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f1620b17ddab80729e92fbebcab80e968f6918d"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4fa302151bd01d4868a9b7e80426246ccada8815"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91357843aec7848900fef671dfa719f9ee747a94"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/hokoyjnmuh4c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=bbbdd1535b9d0f124541b9a822785e88009c21f5"}, "id": "hokoyjnmuh4c1"}, "mefuhx8muh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43daa4da002cb7c676b9fc3ba831023f6890f7f7"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad73491bb9c91bfd483e99164005269b8ad76b18"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=686625d84deb207ec6d115c3d2b99d16e084714a"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6edaec7c55f3bb5b2cfbec5beeea11a18e29a25c"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8bbbf6dccf49245ca7e191671f4be78bfdb76878"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e78634ded55b1137ee6559de46c7d420a60284a2"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/mefuhx8muh4c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=0c4bd0f9f11fa33c5b2ccd8c16f39215bd04ef11"}, "id": "mefuhx8muh4c1"}, "ofpt5h2nuh4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01aefde014a9041e4fb46800bc7e6b0e808816f4"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9269d37ce594fccbb25857b5650b9c562655f44"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f37b21b25b3515d9782dc7af38e9f4760fe5c522"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=462b7974011659c10a9c28be9444af77e88b924c"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d009b733bc266d67852618438f35b172a82b74aa"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3ebc820adf1536deb79913a01523de4ef0302cf5"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/ofpt5h2nuh4c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=343af387920659202da9cc81a5b0243a20676a10"}, "id": "ofpt5h2nuh4c1"}}, "name": "t3_18be8yu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "fg6051vluh4c1", "id": 369787391}, {"media_id": "mefuhx8muh4c1", "id": 369787392}, {"media_id": "hokoyjnmuh4c1", "id": 369787393}, {"media_id": "ofpt5h2nuh4c1", "id": 369787394}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wzIgoc6KxKWYDd3mstw5azdiV5zZoHHgh7X_38duS9w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701789750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I now have posted the full values. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t get why the less used SSD, with less runtime and less written and read data is caution and the other is good.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18be8yu", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18be8yu", "is_robot_indexable": true, "report_reasons": null, "author": "MntDewCodRed", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18be8yu/why_is_one_44_good_and_one_80_caution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18be8yu", "subreddit_subscribers": 716544, "created_utc": 1701789750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "    Hello im pretty new, how do i save a website with login? i am trying to use wget, can someone give me a command or something? i've been trying since a week.. and i didn't manage to.  i tried to use this command.  wget --user=user  --password=password  --mirror --convert-links --page-requisites --adjust-extension --recursive  --no-parent https://ar-liceocastiglione.medialibrary.it --html-extension  --no-clobber https://ar-liceocastiglione.medialibrary.it \n\n&amp;#x200B;\n\ni  replaced user ands pass with my stuff btw. ", "author_fullname": "t2_8beeir59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help for save school book websites with login", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bcmhq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701784957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;Hello im pretty new, how do i save a website with login? i am trying to use wget, can someone give me a command or something? i&amp;#39;ve been trying since a week.. and i didn&amp;#39;t manage to.  i tried to use this command.  wget --user=user  --password=password  --mirror --convert-links --page-requisites --adjust-extension --recursive  --no-parent https://ar-liceocastiglione.medialibrary.it --html-extension  --no-clobber https://ar-liceocastiglione.medialibrary.it \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i  replaced user ands pass with my stuff btw. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18bcmhq", "is_robot_indexable": true, "report_reasons": null, "author": "Alexander_Alexis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18bcmhq/need_help_for_save_school_book_websites_with_login/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18bcmhq/need_help_for_save_school_book_websites_with_login/", "subreddit_subscribers": 716544, "created_utc": 1701784957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello technophone obsessed with hoarding my photos here!\n\nI want to ensure my photos are backed up on a laptop and a HDD in addition to icloud storage. What is the easiest way to back up all my latest icloud photos - They are currently on the icloud only rather than icloud and iphone as my iphone doesn\u2019t quite have enough space for them all (22.2gb)- do I have to download them from cloud one by one? Last time i tried that seemed to be it. Does it help if I do it with a Mac instead of a PC? I have tried both last year but seemed one by one regardless.\n\nWill HEIC format open on PC as well as MAC if I save them to HDD in that format or do I need to convert individually to jpeg? I used to be able to easily copy and paste lots of photos at once few years ago when they were on my iphone and they were all jpeg so it was pretty foolproof!\n\nFinally, some of my older photos are not on the cloud as I used to just move them off onto laptop and HDD - is it easy to upload these to cloud now also - and can they be uploaded as jpegs or would that cause issues?\n\nI can see that some photos do appear to still be stored on my actual phone (just 3gbs) but I figure plugging the phone into the laptop will reveal which those are.\n\nThanks in advance for anyone who can help with any of these questions!! I feel like such a moron who missed the system from a few years ago when it was all fairly idiot proof- perhaps I would find android easier going forward \ud83e\udd14", "author_fullname": "t2_g2sp0qtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help a technophobe hoard photos safely \ud83d\ude48", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b9p58", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701774624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello technophone obsessed with hoarding my photos here!&lt;/p&gt;\n\n&lt;p&gt;I want to ensure my photos are backed up on a laptop and a HDD in addition to icloud storage. What is the easiest way to back up all my latest icloud photos - They are currently on the icloud only rather than icloud and iphone as my iphone doesn\u2019t quite have enough space for them all (22.2gb)- do I have to download them from cloud one by one? Last time i tried that seemed to be it. Does it help if I do it with a Mac instead of a PC? I have tried both last year but seemed one by one regardless.&lt;/p&gt;\n\n&lt;p&gt;Will HEIC format open on PC as well as MAC if I save them to HDD in that format or do I need to convert individually to jpeg? I used to be able to easily copy and paste lots of photos at once few years ago when they were on my iphone and they were all jpeg so it was pretty foolproof!&lt;/p&gt;\n\n&lt;p&gt;Finally, some of my older photos are not on the cloud as I used to just move them off onto laptop and HDD - is it easy to upload these to cloud now also - and can they be uploaded as jpegs or would that cause issues?&lt;/p&gt;\n\n&lt;p&gt;I can see that some photos do appear to still be stored on my actual phone (just 3gbs) but I figure plugging the phone into the laptop will reveal which those are.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for anyone who can help with any of these questions!! I feel like such a moron who missed the system from a few years ago when it was all fairly idiot proof- perhaps I would find android easier going forward \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b9p58", "is_robot_indexable": true, "report_reasons": null, "author": "pro_wonderer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b9p58/help_a_technophobe_hoard_photos_safely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b9p58/help_a_technophobe_hoard_photos_safely/", "subreddit_subscribers": 716544, "created_utc": 1701774624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "RTVE, a Spanish radio station, has a collection of great old jazz podcasts available for free. \n\nThe program is about to be canceled and removed, so I am trying to download the podcasts before they take them down. \n\nThe only issue is the somewhat cumbersome process of manually downloading them by clicking around on their website. I attempted to use yt-dlp to simplify the process, but unfortunately, I encountered error messages.\n\nYou can find the jazz and swing classics on this website: [https://www.rtve.es/play/audios/clasicos-del-jazz-y-del-swing/](https://www.rtve.es/play/audios/clasicos-del-jazz-y-del-swing/)\n\nTo download a podcast manually, you have to click on the three dots next to the podcast, then select 'Download.' This opens a new tab, and you need to click 'Download' again.\n\nI'm not proficient in coding, so I'm looking for suggestions on how to make this process less click-heavy, possibly with a yt-dlp command. Any help in simplifying this would be greatly appreciated.", "author_fullname": "t2_obe8azxwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm trying to grab a bunch of jazz/swing podcasts before they're taken down, but can't figure out how to do it all at once. Any quick ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b1dar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701743148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;RTVE, a Spanish radio station, has a collection of great old jazz podcasts available for free. &lt;/p&gt;\n\n&lt;p&gt;The program is about to be canceled and removed, so I am trying to download the podcasts before they take them down. &lt;/p&gt;\n\n&lt;p&gt;The only issue is the somewhat cumbersome process of manually downloading them by clicking around on their website. I attempted to use yt-dlp to simplify the process, but unfortunately, I encountered error messages.&lt;/p&gt;\n\n&lt;p&gt;You can find the jazz and swing classics on this website: &lt;a href=\"https://www.rtve.es/play/audios/clasicos-del-jazz-y-del-swing/\"&gt;https://www.rtve.es/play/audios/clasicos-del-jazz-y-del-swing/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;To download a podcast manually, you have to click on the three dots next to the podcast, then select &amp;#39;Download.&amp;#39; This opens a new tab, and you need to click &amp;#39;Download&amp;#39; again.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not proficient in coding, so I&amp;#39;m looking for suggestions on how to make this process less click-heavy, possibly with a yt-dlp command. Any help in simplifying this would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HcEFovrxBMHXvAOB-w1fCY6ODcFdh7KoIu_Ywv4-DCo.jpg?auto=webp&amp;s=09229bdd6aa7644bddea748742b0b764ceee199d", "width": 800, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/HcEFovrxBMHXvAOB-w1fCY6ODcFdh7KoIu_Ywv4-DCo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2e3810dcfd8844c3ba1895a1181ebbd9c0747cb0", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/HcEFovrxBMHXvAOB-w1fCY6ODcFdh7KoIu_Ywv4-DCo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1c910e1e291cad5a77c7f8530d7d6ff72913747", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/HcEFovrxBMHXvAOB-w1fCY6ODcFdh7KoIu_Ywv4-DCo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3659836a51922d4c2bdd2e48d33184fd76b86b7e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/HcEFovrxBMHXvAOB-w1fCY6ODcFdh7KoIu_Ywv4-DCo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec0fef9855dcda0f925966f904d6367d64b906f0", "width": 640, "height": 640}], "variants": {}, "id": "jVHqgwCGbZigvpp-x4472jhDjy4qAjF1LyHgYMzxyGc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b1dar", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedTie6013", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b1dar/im_trying_to_grab_a_bunch_of_jazzswing_podcasts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b1dar/im_trying_to_grab_a_bunch_of_jazzswing_podcasts/", "subreddit_subscribers": 716544, "created_utc": 1701743148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, my name is Nathan and I am a data hoarder.   \n\n\nAlright now that I've gotten that out of the way I want to lay out my use cases. I have been a photographer for 15+ years and have saved just about every single image that I've taken. In 2020 I started a photography business to start to fund my addiction and this has of course, added tremendously to the amount of storage that I use. I am currently using \\~30TB in storage with just over a million photos. At the current growth that I'm experiencing I expect that I'll hit 1PB of storage within about 15 years... If not sooner given that my camera can shoot 8K RAW video at a rate of 3TB/hr. I also thoroughly enjoy astrophotography and timelapses and those also EAT storage. For instance I've added 8.3TB of data so far this year.   \n\n\nMy question is should I start researching a tape array at least for a backup and/or archival medium?   \n\n\nAnd yes I do have backups in multiple locations specifically at my parents in a fireproof enclosure. ", "author_fullname": "t2_atmah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I start planning on buying tape storage or wait?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18apgyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701711574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, my name is Nathan and I am a data hoarder.   &lt;/p&gt;\n\n&lt;p&gt;Alright now that I&amp;#39;ve gotten that out of the way I want to lay out my use cases. I have been a photographer for 15+ years and have saved just about every single image that I&amp;#39;ve taken. In 2020 I started a photography business to start to fund my addiction and this has of course, added tremendously to the amount of storage that I use. I am currently using ~30TB in storage with just over a million photos. At the current growth that I&amp;#39;m experiencing I expect that I&amp;#39;ll hit 1PB of storage within about 15 years... If not sooner given that my camera can shoot 8K RAW video at a rate of 3TB/hr. I also thoroughly enjoy astrophotography and timelapses and those also EAT storage. For instance I&amp;#39;ve added 8.3TB of data so far this year.   &lt;/p&gt;\n\n&lt;p&gt;My question is should I start researching a tape array at least for a backup and/or archival medium?   &lt;/p&gt;\n\n&lt;p&gt;And yes I do have backups in multiple locations specifically at my parents in a fireproof enclosure. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB TrueNAS ZFS ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18apgyd", "is_robot_indexable": true, "report_reasons": null, "author": "nks12345", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18apgyd/should_i_start_planning_on_buying_tape_storage_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18apgyd/should_i_start_planning_on_buying_tape_storage_or/", "subreddit_subscribers": 716544, "created_utc": 1701711574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for an ATX tower case to hold 7 HDDs. I'd like at least 1 hot swap slot since I take one of the HDDs off-site frequently. Do y'all have any recommendations?", "author_fullname": "t2_90bwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "case recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b9sf9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701774987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an ATX tower case to hold 7 HDDs. I&amp;#39;d like at least 1 hot swap slot since I take one of the HDDs off-site frequently. Do y&amp;#39;all have any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18b9sf9", "is_robot_indexable": true, "report_reasons": null, "author": "khodo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18b9sf9/case_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18b9sf9/case_recommendation/", "subreddit_subscribers": 716544, "created_utc": 1701774987.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}