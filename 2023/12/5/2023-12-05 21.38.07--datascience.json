{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m turning 40 next year and it\u2019s got me wondering about the future and how I\u2019ll be able to make a living when I\u2019m older.\n\nWe\u2019ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don\u2019t really want to climb the corporate ladder, I\u2019d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. \n\nI\u2019ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. \n\nJust wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?", "author_fullname": "t2_nya9l4wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you see this doing this work past 50 years of age and into retirement?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b1ery", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701743270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m turning 40 next year and it\u2019s got me wondering about the future and how I\u2019ll be able to make a living when I\u2019m older.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve all heard the scary talks of AI replacing our jobs, but besides that I worry about keeping up with the industry and having the motivation. I don\u2019t really want to climb the corporate ladder, I\u2019d rather be an individual contributor even if it means less money. The 50+ year olds in my companies are the ones at VP and Senior levels. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve also heard scary stories of people in their 50s getting laid off and having difficulty finding work which could likely be due to age. &lt;/p&gt;\n\n&lt;p&gt;Just wondering how I should refine my career in the next decade to still be employable. Any advice? Do you plan to continue this to retirement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18b1ery", "is_robot_indexable": true, "report_reasons": null, "author": "TheUserAboveFarted", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b1ery/do_you_see_this_doing_this_work_past_50_years_of/", "subreddit_subscribers": 1166432, "created_utc": 1701743270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This community has been tremendously helpful for me when I was first breaking into data science and MLE, and I'm looking to give back through free online education.\n\nUnfortunately, a lot of AI/ML resources online, especially those for generative AI, are way too math heavy and focus more on tedious proofs rather than what you actually need to know for side projects or to work as an MLE. That's why I created [GPT and Chill](https://www.youtube.com/@GPTandChill/videos), a one stop shop for learning different ML concepts from scratch.\n\nThe structure of most of my videos is first 10 minutes explaining on a whiteboard, last 10 minutes live coding in Python. There's only one video left in my first to be released in my first playlist/series, [Coding a GPT from scratch](https://www.youtube.com/playlist?list=PLf2BgkdQjMYsyPx7HPO4M6aqTfPl2iEPx)\n\nThe next playlist/series will either be explaining how to code a self-driving car, or an image generator like DALL-E! I will also be releasing a companion platform where you can run your code against test cases for sample exercises/questions.\n\nIf anyone has any suggestions for future videos, feel free to leave a comment or DM me!", "author_fullname": "t2_o8bqxbsy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explaining how generative AI works in code, from scratch, without excessive math", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bgpy2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701795917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This community has been tremendously helpful for me when I was first breaking into data science and MLE, and I&amp;#39;m looking to give back through free online education.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, a lot of AI/ML resources online, especially those for generative AI, are way too math heavy and focus more on tedious proofs rather than what you actually need to know for side projects or to work as an MLE. That&amp;#39;s why I created &lt;a href=\"https://www.youtube.com/@GPTandChill/videos\"&gt;GPT and Chill&lt;/a&gt;, a one stop shop for learning different ML concepts from scratch.&lt;/p&gt;\n\n&lt;p&gt;The structure of most of my videos is first 10 minutes explaining on a whiteboard, last 10 minutes live coding in Python. There&amp;#39;s only one video left in my first to be released in my first playlist/series, &lt;a href=\"https://www.youtube.com/playlist?list=PLf2BgkdQjMYsyPx7HPO4M6aqTfPl2iEPx\"&gt;Coding a GPT from scratch&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The next playlist/series will either be explaining how to code a self-driving car, or an image generator like DALL-E! I will also be releasing a companion platform where you can run your code against test cases for sample exercises/questions.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any suggestions for future videos, feel free to leave a comment or DM me!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?auto=webp&amp;s=63e09f3058721ac5a9287eae3674d6bd0b506926", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ce253083bde24aaff6d930d70869d7ebf6d2892", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55ef50f690051b621b3a56caaaa9551a741837ef", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fcb8590f8ffbdde81a5cc8e9ce23555b71565b3e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/pstf6eDwHh52TvQ7_HcOceigfEQ0P2elI8CRCCcOTJw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9afaf5577c46ce889e689b362b2449007e061acc", "width": 640, "height": 640}], "variants": {}, "id": "RqKWZpSnc0py3dnE4oXk9Xiq2NE8I4zvB1IYU2h9gbE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "18bgpy2", "is_robot_indexable": true, "report_reasons": null, "author": "GPTandChill", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/", "subreddit_subscribers": 1166432, "created_utc": 1701795917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI am new to the field and curious as to what your day to day looks like. \n\nAre you hybrid or remote? Do you have meetings or make presentations?", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist day to day", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18baxdp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701779344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am new to the field and curious as to what your day to day looks like. &lt;/p&gt;\n\n&lt;p&gt;Are you hybrid or remote? Do you have meetings or make presentations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18baxdp", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18baxdp/data_scientist_day_to_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18baxdp/data_scientist_day_to_day/", "subreddit_subscribers": 1166432, "created_utc": 1701779344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more \"production-ready\", then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol", "author_fullname": "t2_oxk1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write OOP from the beginning or refactor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b5s7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701757640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a Jr Data Scientist that is in the process of having solid SWE foundations. My regular ML workflow is first work on a Jupyter Notebook where its usually messy because all of the experimentation and then after I get what I want I transfer into a clean Python script and usually refactored with OOP so it has more maintainability and more &amp;quot;production-ready&amp;quot;, then after I finish the refactor code I run some test s so this refactored cleaner code gets sames results as messy notebook. My question is: Should I try to code like this from the beginnning or if im OK keeping doing what im doing?  Could be silly question lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18b5s7f", "is_robot_indexable": true, "report_reasons": null, "author": "PinstripePride97", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b5s7f/write_oop_from_the_beginning_or_refactor/", "subreddit_subscribers": 1166432, "created_utc": 1701757640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I\u2019m working as a Data Scientist for almost a year and I\u2019m trying to figure out where I can find job offers except inside country I live. Is it hard to find remote jobs like that eg in US or anywhere inside Europe (currently living in Poland)? What are your experiences with that topic?", "author_fullname": "t2_babvbok2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What job boards are you recommending for finding remote job in another country?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bi8oh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701799870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019m working as a Data Scientist for almost a year and I\u2019m trying to figure out where I can find job offers except inside country I live. Is it hard to find remote jobs like that eg in US or anywhere inside Europe (currently living in Poland)? What are your experiences with that topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18bi8oh", "is_robot_indexable": true, "report_reasons": null, "author": "jesteartyste", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18bi8oh/what_job_boards_are_you_recommending_for_finding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18bi8oh/what_job_boards_are_you_recommending_for_finding/", "subreddit_subscribers": 1166432, "created_utc": 1701799870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context - I built a V1 of a model and I have an experiment running that takes the results of the model and distributes coupons to users based on the model output. Control is users who don\u2019t receive a coupon. I\u2019m trying to measure how much retention is improved by the coupon. \n\nI built a v2 of the model and I\u2019m not sure about how I should implement it. Do I run it side by side with my v1 to see which one performs better? Or do I wait for my v1 experiment to finish running and then replace it with the v2 and run it for the same period of time? \n\nThe experiment design for situation 1 is tough for me from a CRM perspective. The experiment design in situation 2 is tough for me from a seasonality perspective and it\u2019ll introduce extra work as I\u2019ll have to make adjustments to my analysis.", "author_fullname": "t2_jrhff4f29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For experienced DS - How did you go about the process of experimenting a new model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bijm7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701800645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context - I built a V1 of a model and I have an experiment running that takes the results of the model and distributes coupons to users based on the model output. Control is users who don\u2019t receive a coupon. I\u2019m trying to measure how much retention is improved by the coupon. &lt;/p&gt;\n\n&lt;p&gt;I built a v2 of the model and I\u2019m not sure about how I should implement it. Do I run it side by side with my v1 to see which one performs better? Or do I wait for my v1 experiment to finish running and then replace it with the v2 and run it for the same period of time? &lt;/p&gt;\n\n&lt;p&gt;The experiment design for situation 1 is tough for me from a CRM perspective. The experiment design in situation 2 is tough for me from a seasonality perspective and it\u2019ll introduce extra work as I\u2019ll have to make adjustments to my analysis.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18bijm7", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible-Hamster-342", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18bijm7/for_experienced_ds_how_did_you_go_about_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18bijm7/for_experienced_ds_how_did_you_go_about_the/", "subreddit_subscribers": 1166432, "created_utc": 1701800645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey,  \n\n\nHas anyone tried this model for hierarchical time series forecasting from gluonts? [https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical\\_model\\_tutorial.html](https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html). The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?", "author_fullname": "t2_k7ifh2t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hierarchical Time Series Forecasting using GluonTS DeepVarHierarchical", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ay60f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701733960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,  &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this model for hierarchical time series forecasting from gluonts? &lt;a href=\"https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html\"&gt;https://ts.gluon.ai/dev/tutorials/forecasting/hierarchical_model_tutorial.html&lt;/a&gt;. The paper seems quite interesting, but it is painfully slow and erratic (several times, I am getting nans for predictions). I am not sure if there are additional data transformations that could help here. Is anyone working with hierarchical time series models lately?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18ay60f", "is_robot_indexable": true, "report_reasons": null, "author": "Moist_Stuff4509", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ay60f/hierarchical_time_series_forecasting_using/", "subreddit_subscribers": 1166432, "created_utc": 1701733960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I'm assuming I will have to make one myself. I'm fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I'm being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.\n\nAre there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?", "author_fullname": "t2_1mt6zlx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make a good dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ausi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701725168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project that has medical applications in Botox and am having difficulty finding datasets to use so I&amp;#39;m assuming I will have to make one myself. I&amp;#39;m fairly new to this and have experienceainly with already using well known datasets. So my question is what analysis and metrics should I use when collecting the data to ensure that it is representative of the population and is good data for the task. How can I develop criteria to make sure the data is useful for a specific task. I know I&amp;#39;m being vague but if you need more information to better answer this question just let me know and I will add it to this post. Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;Are there any sources, texts, videos or online things that you would recommend as a good starting point for collecting data and ensuring it is quality data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18ausi6", "is_robot_indexable": true, "report_reasons": null, "author": "ixw123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18ausi6/how_to_make_a_good_dataset/", "subreddit_subscribers": 1166432, "created_utc": 1701725168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When you interview a candidate, is it blatantly obvious that the interviewee is desperate to get out of their bad job and into your company? I\u2019m racking my brain why I keep getting turned down. Maybe it\u2019s arrogance? Maybe forgetting details? Maybe it\u2019s too obvious that I\u2019m trying to find a better role? \n\nMy confidence keeps getting bruised. The job market is so tough. Answer questions perfectly, still get turned down. I just don\u2019t get it. Are yall farming for reasons to send the job to India? Are you just getting inundated with top tier candidates?", "author_fullname": "t2_9l80yrty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hiring managers, is it obvious?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18blxjo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701809304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When you interview a candidate, is it blatantly obvious that the interviewee is desperate to get out of their bad job and into your company? I\u2019m racking my brain why I keep getting turned down. Maybe it\u2019s arrogance? Maybe forgetting details? Maybe it\u2019s too obvious that I\u2019m trying to find a better role? &lt;/p&gt;\n\n&lt;p&gt;My confidence keeps getting bruised. The job market is so tough. Answer questions perfectly, still get turned down. I just don\u2019t get it. Are yall farming for reasons to send the job to India? Are you just getting inundated with top tier candidates?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18blxjo", "is_robot_indexable": true, "report_reasons": null, "author": "cruelbankai", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18blxjo/hiring_managers_is_it_obvious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18blxjo/hiring_managers_is_it_obvious/", "subreddit_subscribers": 1166432, "created_utc": 1701809304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Is there still room for research on techniques and models that are commonly used in the industry? I currently work as a Data Scientist and am considering pursuing a Master's or Ph.D. in machine learning. However, it appears that most recent developments focus primarily on neural networks, especially Large Language Models (LLMs). Despite extensively searching through arXiv articles, I've had little success in finding research on areas like feature engineering, probability models, and tree-based algorithms. If anyone knows professors specializing in these more traditional machine learning aspects, please let me know. ", "author_fullname": "t2_nr338hpnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How alive is traditional machine learning in academia?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bhvfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701798949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there still room for research on techniques and models that are commonly used in the industry? I currently work as a Data Scientist and am considering pursuing a Master&amp;#39;s or Ph.D. in machine learning. However, it appears that most recent developments focus primarily on neural networks, especially Large Language Models (LLMs). Despite extensively searching through arXiv articles, I&amp;#39;ve had little success in finding research on areas like feature engineering, probability models, and tree-based algorithms. If anyone knows professors specializing in these more traditional machine learning aspects, please let me know. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "18bhvfd", "is_robot_indexable": true, "report_reasons": null, "author": "BrDataScientist", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18bhvfd/how_alive_is_traditional_machine_learning_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18bhvfd/how_alive_is_traditional_machine_learning_in/", "subreddit_subscribers": 1166432, "created_utc": 1701798949.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don't have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?\n\nI'm in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I've constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population 'cell', e.g. permutation of geography (postcode in this case), sex, and age bucket:\n\ncell | year | age_bucket | sex | postcode | population\n:--|--:|--:|:--|:--|--:\n1036 | 2021 | 25-30 | Male | 2000 |  4,390\n\nMy intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we'll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.\n\nuser | year | height | weight | age_bucket | sex | postcode\n:---|--:|--:|--:|--:|:--|:--\na89bf96e | 2021| 180 | 80 | 25-30 | Male | 2000\n\nFrom the **user** and **cell** tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).\n\nHowever I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:\n\n\n    # get the total population\n    total_population = data['population'].sum()\n    \n    # get the weighted estimate\n    weighted_bmi_estimate = (data['survey_weight'] * data['bmi']).sum() / total_population\n    \n    # work out the design effect by comparing simple (SRS) and complex variance measures\n    \n    mean_bmi = data['bmi'].mean()\n    simple_variance = ((data['bmi'] - mean_bmi)**2).sum() / (total_population - 1)\n    \n    data['weighted_deviance'] = data['survey_weight'] * (data['bmi'] - weighted_bmi_estimate)**2\n    complex_variance = data['weighted_deviance'].sum() / total_population\n    \n    deff = complex_variance / simple_variance\n    \n    # use the deff to get the rse for the bmi estimate\n    rse = (deff * simple_variance)**0.5\n    \n    # NOTE: when doing an obesity _rate_ instead of BMI we'd use a different calc for the simple_variance\n\n\nTbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it'd be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.\n\nFurther thoughts:\n\n- I will need to interpolate population counts for non-census years or otherwise just take the closest\n- Though I haven't yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it\n- I'll need to handle summation across cells when weighting by only a subset of the cell dimensions \n- To handle distortion from small counts, weight trimming seemed like the simplest solution but I'm unsure if any adjustments are necessary when determining RSEs\n- I'm not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using `approxQuantile` to set the weight caps, broadcasting my means and total_populations)\n\nThank you!", "author_fullname": "t2_i0a3z0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please sense-check my approach for applying survey weights and RSEs in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18b113j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701744760.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701742148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m newish to data engineering/analytics and working for a public health non-profit that is getting height and weight measurements across the population, and want to apply survey weightings to provide more accurate obesity rates and mean BMIs. I have some dev experience but only picked up a couple of stats subjects in uni and we don&amp;#39;t have much in-house expertise yet. Can you please let me know if the following approach sounds reasonable?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in AWS, so S3, Glue/PySpark, and Athena. Observation data streams into parquet buckets, and I&amp;#39;ve constructed a parquet view combining data from the last few census years (2021, 2016, 2011) which is the period measurements have been taken. This gives the population counts for each population &amp;#39;cell&amp;#39;, e.g. permutation of geography (postcode in this case), sex, and age bucket:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;cell&lt;/th&gt;\n&lt;th align=\"right\"&gt;year&lt;/th&gt;\n&lt;th align=\"right\"&gt;age_bucket&lt;/th&gt;\n&lt;th align=\"left\"&gt;sex&lt;/th&gt;\n&lt;th align=\"left\"&gt;postcode&lt;/th&gt;\n&lt;th align=\"right\"&gt;population&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1036&lt;/td&gt;\n&lt;td align=\"right\"&gt;2021&lt;/td&gt;\n&lt;td align=\"right\"&gt;25-30&lt;/td&gt;\n&lt;td align=\"left\"&gt;Male&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;td align=\"right\"&gt;4,390&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;My intended next steps are to take the height and weight observation data and create a user/period-keyed summary table (since a user may have multiple observations in a period, we&amp;#39;ll take the last). I expect to create this as a materialised parquet table incrementally updated nightly.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;user&lt;/th&gt;\n&lt;th align=\"right\"&gt;year&lt;/th&gt;\n&lt;th align=\"right\"&gt;height&lt;/th&gt;\n&lt;th align=\"right\"&gt;weight&lt;/th&gt;\n&lt;th align=\"right\"&gt;age_bucket&lt;/th&gt;\n&lt;th align=\"left\"&gt;sex&lt;/th&gt;\n&lt;th align=\"left\"&gt;postcode&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;a89bf96e&lt;/td&gt;\n&lt;td align=\"right\"&gt;2021&lt;/td&gt;\n&lt;td align=\"right\"&gt;180&lt;/td&gt;\n&lt;td align=\"right\"&gt;80&lt;/td&gt;\n&lt;td align=\"right\"&gt;25-30&lt;/td&gt;\n&lt;td align=\"left\"&gt;Male&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;From the &lt;strong&gt;user&lt;/strong&gt; and &lt;strong&gt;cell&lt;/strong&gt; tables above, I can count the number of observations for a given cell/year, and take the ratio between that and the population to get a simple survey weight. I would then take the survey weight and multiply through to infer the actual population that is or is not obese, for example. I expected I should do this join and calculation at query time in Athena (which would be how the data would be pulled into BI tools or web views).&lt;/p&gt;\n\n&lt;p&gt;However I also want to also attach a relative standard error (RSE) to each measure estimate, which may be beyond Athena and require regenerating a summary table using spark each night. My broad approach here was going to be the following, given the joined table of users with cell weights calculated and addressing the convenience sampling via a design effect factor:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# get the total population\ntotal_population = data[&amp;#39;population&amp;#39;].sum()\n\n# get the weighted estimate\nweighted_bmi_estimate = (data[&amp;#39;survey_weight&amp;#39;] * data[&amp;#39;bmi&amp;#39;]).sum() / total_population\n\n# work out the design effect by comparing simple (SRS) and complex variance measures\n\nmean_bmi = data[&amp;#39;bmi&amp;#39;].mean()\nsimple_variance = ((data[&amp;#39;bmi&amp;#39;] - mean_bmi)**2).sum() / (total_population - 1)\n\ndata[&amp;#39;weighted_deviance&amp;#39;] = data[&amp;#39;survey_weight&amp;#39;] * (data[&amp;#39;bmi&amp;#39;] - weighted_bmi_estimate)**2\ncomplex_variance = data[&amp;#39;weighted_deviance&amp;#39;].sum() / total_population\n\ndeff = complex_variance / simple_variance\n\n# use the deff to get the rse for the bmi estimate\nrse = (deff * simple_variance)**0.5\n\n# NOTE: when doing an obesity _rate_ instead of BMI we&amp;#39;d use a different calc for the simple_variance\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Tbh I could probably do the RSE for a single measure in Athena like this, but spark seems like it&amp;#39;d be better if I want to generalise to different measures and cell dimensions and then not worry if downstream consumers hit the table too frequently.&lt;/p&gt;\n\n&lt;p&gt;Further thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I will need to interpolate population counts for non-census years or otherwise just take the closest&lt;/li&gt;\n&lt;li&gt;Though I haven&amp;#39;t yet used delta/hudi/iceberg table formats I think the user table may be a good use-case for it&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ll need to handle summation across cells when weighting by only a subset of the cell dimensions &lt;/li&gt;\n&lt;li&gt;To handle distortion from small counts, weight trimming seemed like the simplest solution but I&amp;#39;m unsure if any adjustments are necessary when determining RSEs&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m not sure if there are any native statistical functions I should use instead when converting the above pandas to pyspark, or any efficiency issues to watch out for (e.g. using &lt;code&gt;approxQuantile&lt;/code&gt; to set the weight caps, broadcasting my means and total_populations)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "18b113j", "is_robot_indexable": true, "report_reasons": null, "author": "sansampersamp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18b113j/please_sensecheck_my_approach_for_applying_survey/", "subreddit_subscribers": 1166432, "created_utc": 1701742148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wanna do some self learning along with my college, I see lots of these courses that are specific to Microsoft or Google. can I benefit from it? if so in which situations?", "author_fullname": "t2_4rvlor2p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I enroll in Google Cloud/Microsoft Azure courses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18bf2ej", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701791688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanna do some self learning along with my college, I see lots of these courses that are specific to Microsoft or Google. can I benefit from it? if so in which situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18bf2ej", "is_robot_indexable": true, "report_reasons": null, "author": "1kmile", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18bf2ej/should_i_enroll_in_google_cloudmicrosoft_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18bf2ej/should_i_enroll_in_google_cloudmicrosoft_azure/", "subreddit_subscribers": 1166432, "created_utc": 1701791688.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}