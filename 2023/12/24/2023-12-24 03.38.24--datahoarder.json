{"kind": "Listing", "data": {"after": "t3_18p4f0d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_v2a9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do You Test If An EEPROM Can Hold Data For 100 Years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_18p18dz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JPf_BN0C8u-wAgTs5Uahp_3FBsQX6GOjSXVLdp07JS4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703319803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hackaday.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hackaday.com/2023/12/21/how-do-you-test-if-an-eeprom-can-hold-data-for-100-years/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?auto=webp&amp;s=6b166e25037e706ec1549aa3e8726c2311c397ed", "width": 3000, "height": 1815}, "resolutions": [{"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb0ece5921121e85bdde63d8da765dece806c328", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7dc81177220f6d70f11787425c0c47c2ac4e6652", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba67ee587c1e5ed3c838ded2258b3a6a8c8294ca", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=30ecfa35fe2c0e0c4de929a878419ac1bc8ba208", "width": 640, "height": 387}, {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a087138ca695fc95c5511c52209204401306c9d4", "width": 960, "height": 580}, {"url": "https://external-preview.redd.it/m0IgQy2_7CGpYk568yuRzmn_28Xo512tq_xpgpyY-8c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9434cc84ef02babaef568148af20263c93378576", "width": 1080, "height": 653}], "variants": {}, "id": "GufPJHoAEjOVkrn9vS8H26Lg5I8XMnIpEsBI-W8p7OQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p18dz", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy-Red-Fox", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p18dz/how_do_you_test_if_an_eeprom_can_hold_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hackaday.com/2023/12/21/how-do-you-test-if-an-eeprom-can-hold-data-for-100-years/", "subreddit_subscribers": 720118, "created_utc": 1703319803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a brand new 2TB Samsung S7 SDD which I purchased to transfer folders that contain around 200GB of data.   \n\nWhen I try to copy a 40 gb whole folder, for example, I'll get \"interuppted action\" and a message that my hard drive needs around 11GB or so. However, when I copy the subfolders individually in batches it's fine.   \n\nAny idea?\n\nEdit: is there any chance you need space on your original drive to cache the folder as it moves to your external ssd? My if I\u2019m copying over from a drive that\u2019s full perhaps that\u2019s the issue?\n\nEdit 2: if anyone is interested, I\u2019ve run two programes suggested below to see if it\u2019s a genuine drive. Both tests seem to come back okay. I decided not to format the hard drive before running the tests, so I\u2019m not sure if that would cause any issues. \n\nWarning: Only 1645164 of 1907666 MByte tested.\nTest finished without errors.\nYou can now delete the test files *.h2w or verify them again.\nWriting speed: 273 MByte/s\nReading speed: 167 MByte/s\nH2testw v1.4", "author_fullname": "t2_ey91h2hh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung S7 ssd - can't do transfer folders larger than ~ 10GB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p6vqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703384692.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703341954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a brand new 2TB Samsung S7 SDD which I purchased to transfer folders that contain around 200GB of data.   &lt;/p&gt;\n\n&lt;p&gt;When I try to copy a 40 gb whole folder, for example, I&amp;#39;ll get &amp;quot;interuppted action&amp;quot; and a message that my hard drive needs around 11GB or so. However, when I copy the subfolders individually in batches it&amp;#39;s fine.   &lt;/p&gt;\n\n&lt;p&gt;Any idea?&lt;/p&gt;\n\n&lt;p&gt;Edit: is there any chance you need space on your original drive to cache the folder as it moves to your external ssd? My if I\u2019m copying over from a drive that\u2019s full perhaps that\u2019s the issue?&lt;/p&gt;\n\n&lt;p&gt;Edit 2: if anyone is interested, I\u2019ve run two programes suggested below to see if it\u2019s a genuine drive. Both tests seem to come back okay. I decided not to format the hard drive before running the tests, so I\u2019m not sure if that would cause any issues. &lt;/p&gt;\n\n&lt;p&gt;Warning: Only 1645164 of 1907666 MByte tested.\nTest finished without errors.\nYou can now delete the test files *.h2w or verify them again.\nWriting speed: 273 MByte/s\nReading speed: 167 MByte/s\nH2testw v1.4&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p6vqy", "is_robot_indexable": true, "report_reasons": null, "author": "Royal_Difficulty_678", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p6vqy/samsung_s7_ssd_cant_do_transfer_folders_larger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p6vqy/samsung_s7_ssd_cant_do_transfer_folders_larger/", "subreddit_subscribers": 720118, "created_utc": 1703341954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Was wondering if there is a plex-like solution that let's you host your own ebooks (pdf and or epubs) and serves it easily on most devices. A bonus would be if it could also serve it or push it to an e-reader (Kobo, Kindle or any other available e-reader)?", "author_fullname": "t2_4cg63eip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] Ebooks with a plex-like experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p7t4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703344793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was wondering if there is a plex-like solution that let&amp;#39;s you host your own ebooks (pdf and or epubs) and serves it easily on most devices. A bonus would be if it could also serve it or push it to an e-reader (Kobo, Kindle or any other available e-reader)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p7t4d", "is_robot_indexable": true, "report_reasons": null, "author": "TheBlackKey2000", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p7t4d/question_ebooks_with_a_plexlike_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p7t4d/question_ebooks_with_a_plexlike_experience/", "subreddit_subscribers": 720118, "created_utc": 1703344793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nI recently decommissioned my old Synology NAS in favor of connecting the four 3TB drives directly to my computer, using DrivePool to merge them into one drive. I enabled file duplication for the whole pool, and toggled the setting for equal file distribution across drives. I was very pleased with the increased speed and the attractive UI of DrivePool. I then replaced three of the four drives with 4TB ones to increase the capacity of the pool. I replaced them one by one, making sure DrivePool finished duplicating to the new drives before adding the next one. Everything seemed to go fine and I didn't get any errors.\n\nHowever, today I went to watch a movie on my Plex server and got the error \"cannot locate media.\" I checked my DrivePool folder, and to my horror about 15% of my movie files have vanished! The folders are still there; sometimes the folders are empty, and sometimes they contain SRTs that were included with the movie. It seems only the movie files themselves (avi, mp4, mkv, etc.) have been affected.\n\nI'm frantically trying to recover my lost files from the old NAS drives and have sent a support inquiry to DrivePool. Has anyone else had this happen? Thank you in advance!", "author_fullname": "t2_w776kpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DrivePool mysteriously deleting files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pabff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703351969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I recently decommissioned my old Synology NAS in favor of connecting the four 3TB drives directly to my computer, using DrivePool to merge them into one drive. I enabled file duplication for the whole pool, and toggled the setting for equal file distribution across drives. I was very pleased with the increased speed and the attractive UI of DrivePool. I then replaced three of the four drives with 4TB ones to increase the capacity of the pool. I replaced them one by one, making sure DrivePool finished duplicating to the new drives before adding the next one. Everything seemed to go fine and I didn&amp;#39;t get any errors.&lt;/p&gt;\n\n&lt;p&gt;However, today I went to watch a movie on my Plex server and got the error &amp;quot;cannot locate media.&amp;quot; I checked my DrivePool folder, and to my horror about 15% of my movie files have vanished! The folders are still there; sometimes the folders are empty, and sometimes they contain SRTs that were included with the movie. It seems only the movie files themselves (avi, mp4, mkv, etc.) have been affected.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m frantically trying to recover my lost files from the old NAS drives and have sent a support inquiry to DrivePool. Has anyone else had this happen? Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pabff", "is_robot_indexable": true, "report_reasons": null, "author": "greatsonne", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pabff/drivepool_mysteriously_deleting_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pabff/drivepool_mysteriously_deleting_files/", "subreddit_subscribers": 720118, "created_utc": 1703351969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a media server running Windows 10 Pro. i7-7700k, MSI Z270 board, 32gb ram, 5 x 16tb drives running in storage spaces with parity. I\u2019m going to be upgrading to Windows Server 2022 soon to break through the 63tb limit with Win10 Pro. I started to change my cluster size from 16kb to 64kb to prepare for the change. I read some good reviews on EaseUS software and started the cluster size change with it. It doesn\u2019t show a timeframe. Only shows a percentage complete. It\u2019s been on 95% for over a day. I can see the process is still running in task manager. My question is has anyone here had experience with changing cluster sizes with data retention and what kind of time frame should I expect? I\u2019ve heard mixed answers around the web. I wouldn\u2019t expect it to be done in a day or even two. I\u2019d expect at least a week for a collection of that size. Thanks in advance.", "author_fullname": "t2_25eskjyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Timeframe to change cluster size on 63tb array Windows 10", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18oxgf3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703305845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703305217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a media server running Windows 10 Pro. i7-7700k, MSI Z270 board, 32gb ram, 5 x 16tb drives running in storage spaces with parity. I\u2019m going to be upgrading to Windows Server 2022 soon to break through the 63tb limit with Win10 Pro. I started to change my cluster size from 16kb to 64kb to prepare for the change. I read some good reviews on EaseUS software and started the cluster size change with it. It doesn\u2019t show a timeframe. Only shows a percentage complete. It\u2019s been on 95% for over a day. I can see the process is still running in task manager. My question is has anyone here had experience with changing cluster sizes with data retention and what kind of time frame should I expect? I\u2019ve heard mixed answers around the web. I wouldn\u2019t expect it to be done in a day or even two. I\u2019d expect at least a week for a collection of that size. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18oxgf3", "is_robot_indexable": true, "report_reasons": null, "author": "SpcPewPew", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18oxgf3/timeframe_to_change_cluster_size_on_63tb_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18oxgf3/timeframe_to_change_cluster_size_on_63tb_array/", "subreddit_subscribers": 720118, "created_utc": 1703305217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Starting to get low on hdd space. I'm thinking about buying a used 14tb drive from FB. Price is little lower than I would expect so maybe someone is selling it because it's about to die. I know there are software out t here that can scan bad sectors and what not but the few free ones I've found sound like it takes hours if not days to run and complete. Is there any software that can do a quick scan vs hours or days?..\n\n&amp;#x200B;", "author_fullname": "t2_3t7jqq72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External hdd scan software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pbz49", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703356710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting to get low on hdd space. I&amp;#39;m thinking about buying a used 14tb drive from FB. Price is little lower than I would expect so maybe someone is selling it because it&amp;#39;s about to die. I know there are software out t here that can scan bad sectors and what not but the few free ones I&amp;#39;ve found sound like it takes hours if not days to run and complete. Is there any software that can do a quick scan vs hours or days?..&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pbz49", "is_robot_indexable": true, "report_reasons": null, "author": "xracerboy66", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pbz49/external_hdd_scan_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pbz49/external_hdd_scan_software/", "subreddit_subscribers": 720118, "created_utc": 1703356710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So TL:DR, is there a way to add a power source or convert my 5TB portable drive so I can use it without worry?\n\nI got a 5TB removable hard drive about a year ago and at the time I saw it as a great buy. Get some movies on it, put my steam games on it, because primarily I use my laptop since I'm not at my desktop for very long due to work and family. When I started it up, I loaded it with a bunch of games and noticed it was freezing a lot. Eventually I found out that it was drawing so much power that unless it's the only thing plugged in, the other peripherals and such of my computer will cause it to blink in and out, along with everything in a USB port.\n\nSo I instead started storing my movies and shows on it, because with that and my headphones, it seemed to work perfectly. FF to yesterday and I was putting more shows and movies on it when it started doing the same, even without much else going on in terms of power. I got worried because It's only half full of movies and shows right now and I didn't want to lose all that.\n\nA buddy of mine told me it may just need external power, and I would love to convert it if at all possible, but I cannot for the life of me find how to convert it, I see a lot of converting internal storage to external, but nothing like what my friend described, and he can't even find it either. \n\nFood for thought: I have tried different USB ports, with usb 3.0 causing the least amount of issues, my laptop does have a usb-c port but I'm not sure if that would be the best solution or not. It's a 5TB seagate that came with a USB 3 cable and that's it. \n\nAny and all help is appreciated, thank you", "author_fullname": "t2_cvlyv82s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] 5TB causes power issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p952n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703348575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So TL:DR, is there a way to add a power source or convert my 5TB portable drive so I can use it without worry?&lt;/p&gt;\n\n&lt;p&gt;I got a 5TB removable hard drive about a year ago and at the time I saw it as a great buy. Get some movies on it, put my steam games on it, because primarily I use my laptop since I&amp;#39;m not at my desktop for very long due to work and family. When I started it up, I loaded it with a bunch of games and noticed it was freezing a lot. Eventually I found out that it was drawing so much power that unless it&amp;#39;s the only thing plugged in, the other peripherals and such of my computer will cause it to blink in and out, along with everything in a USB port.&lt;/p&gt;\n\n&lt;p&gt;So I instead started storing my movies and shows on it, because with that and my headphones, it seemed to work perfectly. FF to yesterday and I was putting more shows and movies on it when it started doing the same, even without much else going on in terms of power. I got worried because It&amp;#39;s only half full of movies and shows right now and I didn&amp;#39;t want to lose all that.&lt;/p&gt;\n\n&lt;p&gt;A buddy of mine told me it may just need external power, and I would love to convert it if at all possible, but I cannot for the life of me find how to convert it, I see a lot of converting internal storage to external, but nothing like what my friend described, and he can&amp;#39;t even find it either. &lt;/p&gt;\n\n&lt;p&gt;Food for thought: I have tried different USB ports, with usb 3.0 causing the least amount of issues, my laptop does have a usb-c port but I&amp;#39;m not sure if that would be the best solution or not. It&amp;#39;s a 5TB seagate that came with a USB 3 cable and that&amp;#39;s it. &lt;/p&gt;\n\n&lt;p&gt;Any and all help is appreciated, thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p952n", "is_robot_indexable": true, "report_reasons": null, "author": "Trajjed", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p952n/question_5tb_causes_power_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p952n/question_5tb_causes_power_issues/", "subreddit_subscribers": 720118, "created_utc": 1703348575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nHey DataHoarder! \ud83d\udc4b \nI\u2019m looking for some insights on Seagate hard drives, specifically the Exos and Exos Enterprise series. Can anyone shed light on the differences between these two lines?\n\nAlso, I'm curious about the [various X generations](https://www.seagate.com/de/de/products/enterprise-drives/exos-x/) within these series and which one would be the best fit for data backup in a small business setup. Any recommendations or experiences to share? Thanks in advance! \n\nJulez", "author_fullname": "t2_5pnii6pu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Clarity: Difference Between Exos and Exos Enterprise, Understanding X Generation for Small Business Data Backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ow5su", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703300762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DataHoarder! \ud83d\udc4b \nI\u2019m looking for some insights on Seagate hard drives, specifically the Exos and Exos Enterprise series. Can anyone shed light on the differences between these two lines?&lt;/p&gt;\n\n&lt;p&gt;Also, I&amp;#39;m curious about the &lt;a href=\"https://www.seagate.com/de/de/products/enterprise-drives/exos-x/\"&gt;various X generations&lt;/a&gt; within these series and which one would be the best fit for data backup in a small business setup. Any recommendations or experiences to share? Thanks in advance! &lt;/p&gt;\n\n&lt;p&gt;Julez&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?auto=webp&amp;s=b98f58f088fdf8fbeb225a485466816520892a66", "width": 1440, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=800aeac928e4d6917cdf3db161d37c173da92af5", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a9549b2c27b55813f6941439e0246cac408ff1d", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=708b52a8cc3161e776c554b1f4a488231d8bfce6", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93eb129bea186541cdd32a88a0cb2d619f9a954c", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ad5e3bcc25ba7cdf8dd591fb8e247b839fe5aa7", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b52b8bf108499e8a6d3bd58f428c8f644af3085", "width": 1080, "height": 675}], "variants": {}, "id": "GJ9K1o7VNo6J4JXg3IrZBPizWfgWXRc6b6FmSaP5cNc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ow5su", "is_robot_indexable": true, "report_reasons": null, "author": "juIez_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ow5su/seeking_clarity_difference_between_exos_and_exos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ow5su/seeking_clarity_difference_between_exos_and_exos/", "subreddit_subscribers": 720118, "created_utc": 1703300762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4ep4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NEVER order directly from WD.com.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_18pl502", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/syK47vRV7yxny4JR4gXhX0LkwLJ6MKWzYtyvy0MSzj4.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703384157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yfgkjk5hj58c1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?auto=webp&amp;s=05dd7dcc2c063d8c9d00a0345a196c1d86f863e4", "width": 1388, "height": 8105}, "resolutions": [{"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de3389803f402b0f08b261af8d59cfe1d52cf1f6", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec038cfc0849388037944fa0cf37d7a1627fdd7b", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9dc32a585c3b1e07b774c8d75097e267eb75f7fd", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4832294401c0478cb2ce645d53f20f82f1eb3f9c", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae7eeb448f495b4d7b2681152fca0828bd86ba1d", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/yfgkjk5hj58c1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d867520a5abd2a4557be91d7ecae6114c7ae73e", "width": 1080, "height": 2160}], "variants": {}, "id": "SrefvHj8Zy9njzILzCg82VlDxbRlG1xaORyhcf59uUk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "14TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18pl502", "is_robot_indexable": true, "report_reasons": null, "author": "WraithTDK", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18pl502/never_order_directly_from_wdcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yfgkjk5hj58c1.jpeg", "subreddit_subscribers": 720118, "created_utc": 1703384157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to decide what to use to backup my data. I have a two 10TB hard drives in a Sabrent 3.5\" SATA Hard Drive Docking Station connected to a dell R620 server. Which has Proxmox installed running three VM's. A media server(emby), file server, Minecraft server(just family) and web-server. \n\nI add all this details just in case it helps. I am looking to backup movies (.mkv or .mp4) without losing quality when I need to retrieve this data. Also have .md, .txt, .cr3, .jpg and so on. Basically I have lot of different file types I don't think that matters much but maybe it does.  \n\nNeeds\n\n* easy retrieval of data even if the software i use stopped working or longer available for some reason. I can still get my data\n* easy to use would be nice\n* open source is nice but not required\n* protocols like FTP, SSH, WebDAV are good to have\n\nRight now none of my backups are going on any cloud server(trust issues LOL) and cost", "author_fullname": "t2_2tcxls6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding what to use to backup data/hard drive? Borg vs Duplicati", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p136k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703319161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to decide what to use to backup my data. I have a two 10TB hard drives in a Sabrent 3.5&amp;quot; SATA Hard Drive Docking Station connected to a dell R620 server. Which has Proxmox installed running three VM&amp;#39;s. A media server(emby), file server, Minecraft server(just family) and web-server. &lt;/p&gt;\n\n&lt;p&gt;I add all this details just in case it helps. I am looking to backup movies (.mkv or .mp4) without losing quality when I need to retrieve this data. Also have .md, .txt, .cr3, .jpg and so on. Basically I have lot of different file types I don&amp;#39;t think that matters much but maybe it does.  &lt;/p&gt;\n\n&lt;p&gt;Needs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;easy retrieval of data even if the software i use stopped working or longer available for some reason. I can still get my data&lt;/li&gt;\n&lt;li&gt;easy to use would be nice&lt;/li&gt;\n&lt;li&gt;open source is nice but not required&lt;/li&gt;\n&lt;li&gt;protocols like FTP, SSH, WebDAV are good to have&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Right now none of my backups are going on any cloud server(trust issues LOL) and cost&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p136k", "is_robot_indexable": true, "report_reasons": null, "author": "1michaelbrown", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p136k/deciding_what_to_use_to_backup_datahard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p136k/deciding_what_to_use_to_backup_datahard_drive/", "subreddit_subscribers": 720118, "created_utc": 1703319161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m currently archiving pictures, videos, and files (large documents, APK files, and client files) from two mobile games that I play. I\u2019m currently using a 256G Sandisk flash drive to keep my files on, but I\u2019m going to need something much larger very soon. I\u2019m not super knowledgeable about flash drives and external drives (SSD vs HDD) and so on. What drives would you suggest for me to use? I\u2019m probably not even 10% done with everything I need to archive, so I\u2019m looking for something with probably at least a couple of TB, plus something that\u2019s going to last me a while, but will also withstand me constantly moving, opening, and editing files. \n\nThank you!\n\nedit: i found this [Seagate 5TB HDD Drive](https://www.amazon.com/dp/B07VS8QCXC?ref_=cm_sw_r_apin_dp_V19Y44VQ4YEAAYT4DENC&amp;language=en-US) on sale for $110. Is this one good? It seems like it\u2019s mostly used by gamers.", "author_fullname": "t2_fv702abh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about what type of hard drive I need.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pk94y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703381446.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703381238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently archiving pictures, videos, and files (large documents, APK files, and client files) from two mobile games that I play. I\u2019m currently using a 256G Sandisk flash drive to keep my files on, but I\u2019m going to need something much larger very soon. I\u2019m not super knowledgeable about flash drives and external drives (SSD vs HDD) and so on. What drives would you suggest for me to use? I\u2019m probably not even 10% done with everything I need to archive, so I\u2019m looking for something with probably at least a couple of TB, plus something that\u2019s going to last me a while, but will also withstand me constantly moving, opening, and editing files. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;edit: i found this &lt;a href=\"https://www.amazon.com/dp/B07VS8QCXC?ref_=cm_sw_r_apin_dp_V19Y44VQ4YEAAYT4DENC&amp;amp;language=en-US\"&gt;Seagate 5TB HDD Drive&lt;/a&gt; on sale for $110. Is this one good? It seems like it\u2019s mostly used by gamers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pk94y", "is_robot_indexable": true, "report_reasons": null, "author": "moodyhaaze", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pk94y/question_about_what_type_of_hard_drive_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pk94y/question_about_what_type_of_hard_drive_i_need/", "subreddit_subscribers": 720118, "created_utc": 1703381238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys!\n\nI'm looking to see if you guys here know a good software or something that will help automatically backup a certain folder on my pc to an external hard-drive, scheduled like once a week or something. \n\nJust looking to backup my personal art projects to a hard drive im receiving for xmas. Thank you", "author_fullname": "t2_w480d9p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically Back Up A Specific Folder to External Hard-drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pevo2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703365060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to see if you guys here know a good software or something that will help automatically backup a certain folder on my pc to an external hard-drive, scheduled like once a week or something. &lt;/p&gt;\n\n&lt;p&gt;Just looking to backup my personal art projects to a hard drive im receiving for xmas. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pevo2", "is_robot_indexable": true, "report_reasons": null, "author": "xamiaxo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pevo2/automatically_back_up_a_specific_folder_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pevo2/automatically_back_up_a_specific_folder_to/", "subreddit_subscribers": 720118, "created_utc": 1703365060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm new at this stuff and struggling PS: sorry english not my first langage ", "author_fullname": "t2_nsok0d3re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I download a video in swf file (adobe flash) from a link alone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p9e9g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703349330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new at this stuff and struggling PS: sorry english not my first langage &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p9e9g", "is_robot_indexable": true, "report_reasons": null, "author": "No-Bug-3887", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p9e9g/how_do_i_download_a_video_in_swf_file_adobe_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p9e9g/how_do_i_download_a_video_in_swf_file_adobe_flash/", "subreddit_subscribers": 720118, "created_utc": 1703349330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For the longest time I've read that the WD Black HDDs are the best for gaming purposes and the Exos line is best for enterprise uses. I have been using the Exos line (18-22TB; 18x-20x) for a long time for both gaming and mass media storage. \n\nI'm here to ask the community why is it that WD Black drives are always given the gaming HDD crown? Both lines have 256mb cache, 7200rpm, ~260mb/s sustained write, 550tb/year rating, and a few other stats that are identical. \n\nThe only real difference I can see is that the Exos line offers higher capacities and (from my experience) is alot more reliable and FAR cheaper as well as more readily available.\n\nLet me know what you think, I'd love to hear what my fellow HDD people have to say about this.", "author_fullname": "t2_ti0nfdys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wd Black vs SG Exos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p4vkt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703335210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the longest time I&amp;#39;ve read that the WD Black HDDs are the best for gaming purposes and the Exos line is best for enterprise uses. I have been using the Exos line (18-22TB; 18x-20x) for a long time for both gaming and mass media storage. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here to ask the community why is it that WD Black drives are always given the gaming HDD crown? Both lines have 256mb cache, 7200rpm, ~260mb/s sustained write, 550tb/year rating, and a few other stats that are identical. &lt;/p&gt;\n\n&lt;p&gt;The only real difference I can see is that the Exos line offers higher capacities and (from my experience) is alot more reliable and FAR cheaper as well as more readily available.&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think, I&amp;#39;d love to hear what my fellow HDD people have to say about this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p4vkt", "is_robot_indexable": true, "report_reasons": null, "author": "Breeze23412", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p4vkt/wd_black_vs_sg_exos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p4vkt/wd_black_vs_sg_exos/", "subreddit_subscribers": 720118, "created_utc": 1703335210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a batch of used drives - some 14 TBs and some 16 TBs. They have been honest in their power on hours and excellent in service for almost 2 years now, so I decided to chance it with a new model - some HUH728080ALE601s.\n\nInitial testing found this discrepancy in power on hours and the SMART test log. Could this be the work of a rather dim refurbisher, or a firmware / smartctl snag? Online searches suggested that both are possible. Thanks!\n\n[https://imgur.com/a/DQQ7VKf](https://imgur.com/a/DQQ7VKf)", "author_fullname": "t2_utzj5t9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power On Hours vs Lifetime Hours in test log. Unscrupulous \"refurbisher\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p3uwl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703331716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703331288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a batch of used drives - some 14 TBs and some 16 TBs. They have been honest in their power on hours and excellent in service for almost 2 years now, so I decided to chance it with a new model - some HUH728080ALE601s.&lt;/p&gt;\n\n&lt;p&gt;Initial testing found this discrepancy in power on hours and the SMART test log. Could this be the work of a rather dim refurbisher, or a firmware / smartctl snag? Online searches suggested that both are possible. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/DQQ7VKf\"&gt;https://imgur.com/a/DQQ7VKf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p3uwl", "is_robot_indexable": true, "report_reasons": null, "author": "hc530", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p3uwl/power_on_hours_vs_lifetime_hours_in_test_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p3uwl/power_on_hours_vs_lifetime_hours_in_test_log/", "subreddit_subscribers": 720118, "created_utc": 1703331288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I have a QNAP Plex server currently in RAID 6 with 8x18TB hard drives and \\~90TB of data that I am looking to upgrade to 8x22TB RAID 6\n\nI remember when I upgraded from 8x12TB to 8x18TB a few years ago switching the drives one-by-one and then expanding the storage space that it took over a week and just about disabled my system in that timespan. With this much data and these size drives I know this will be even significantly longer\n\nA thought I had to speed up the process was to backup the \\~90TB of media I have to two separate locations and then delete all of that data on the server reducing the data on it to close to 0. Without any media, will the rebuild per 22TB drive be just a matter of minutes due to the lack of data or is there a minimal amount of time each 22TB drive will take even without the data?\n\nIn answer to the inevitable question of why if I am already restoring the \\~90TB to begin with why I don't just install all 8 22TB drives at once and start fresh, with QNAP the Plex folder is a bit of a pain in the ass to manipulate and while backing up my media is fairly straightforward, backing up that folder is a bit trickier and data loss on the Plex side of things would be far worse than the data loss on the media side of things so I'd like to avoid risking that\n\nThanks for the help", "author_fullname": "t2_4539ugppm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID 6 Upgrade/Rebuild Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p3kg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703330082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I have a QNAP Plex server currently in RAID 6 with 8x18TB hard drives and ~90TB of data that I am looking to upgrade to 8x22TB RAID 6&lt;/p&gt;\n\n&lt;p&gt;I remember when I upgraded from 8x12TB to 8x18TB a few years ago switching the drives one-by-one and then expanding the storage space that it took over a week and just about disabled my system in that timespan. With this much data and these size drives I know this will be even significantly longer&lt;/p&gt;\n\n&lt;p&gt;A thought I had to speed up the process was to backup the ~90TB of media I have to two separate locations and then delete all of that data on the server reducing the data on it to close to 0. Without any media, will the rebuild per 22TB drive be just a matter of minutes due to the lack of data or is there a minimal amount of time each 22TB drive will take even without the data?&lt;/p&gt;\n\n&lt;p&gt;In answer to the inevitable question of why if I am already restoring the ~90TB to begin with why I don&amp;#39;t just install all 8 22TB drives at once and start fresh, with QNAP the Plex folder is a bit of a pain in the ass to manipulate and while backing up my media is fairly straightforward, backing up that folder is a bit trickier and data loss on the Plex side of things would be far worse than the data loss on the media side of things so I&amp;#39;d like to avoid risking that&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p3kg9", "is_robot_indexable": true, "report_reasons": null, "author": "SidneyFalco1313", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p3kg9/raid_6_upgraderebuild_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p3kg9/raid_6_upgraderebuild_question/", "subreddit_subscribers": 720118, "created_utc": 1703330082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "G'day to all of you\n\nI need some help archiving all comments on a YT channel.\n\nI would like to archive all comments on all videos on a particular YT channel. It is an old channel that is part of my childhood, it has been active since 2007 and has about 3.1k videos and an average of 10-20 comments per video.\n\nI already have the video part archived, but I can't figure out how to dump the comments from each video to a file.\n\nI have been doing some research on my own, but google only returns paid solutions, I have tried with [https://github.com/terorie/ytpriv](https://github.com/terorie/ytpriv) but I have not been able to get it to work properly.\n\nHas anyone managed to do this?\n\nThanks :)", "author_fullname": "t2_513k5k95c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive all comments on a YT channel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p1wa3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703322707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;G&amp;#39;day to all of you&lt;/p&gt;\n\n&lt;p&gt;I need some help archiving all comments on a YT channel.&lt;/p&gt;\n\n&lt;p&gt;I would like to archive all comments on all videos on a particular YT channel. It is an old channel that is part of my childhood, it has been active since 2007 and has about 3.1k videos and an average of 10-20 comments per video.&lt;/p&gt;\n\n&lt;p&gt;I already have the video part archived, but I can&amp;#39;t figure out how to dump the comments from each video to a file.&lt;/p&gt;\n\n&lt;p&gt;I have been doing some research on my own, but google only returns paid solutions, I have tried with &lt;a href=\"https://github.com/terorie/ytpriv\"&gt;https://github.com/terorie/ytpriv&lt;/a&gt; but I have not been able to get it to work properly.&lt;/p&gt;\n\n&lt;p&gt;Has anyone managed to do this?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?auto=webp&amp;s=2e9eb72aa39a0a5e5bc47df20ffbfb42d04fc242", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4dbefcedcc3cd442d8867785dee91c592a8f5c04", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe2486f9671222a1632cd920669cf8f091bebcab", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f2a110bc746c6e7f1fc37fa0387359b8220f626", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=99b17964b233487b9a186340bc9fcf87b5e4342a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c966bf625db0ad11fd519998de6b4d7f9e7387a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/tR2I07wTbNfPqhty2dI07Ide9MHGJJZF0yQx1Qk-IaU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba8bcafb68ea49318ece26007ed88b938f6308e0", "width": 1080, "height": 540}], "variants": {}, "id": "5nw6JO3jNtM9Zu0_v_RTgaOCg99GP-te76ohS9NWPoY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p1wa3", "is_robot_indexable": true, "report_reasons": null, "author": "Southern_Tip4955", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p1wa3/archive_all_comments_on_a_yt_channel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p1wa3/archive_all_comments_on_a_yt_channel/", "subreddit_subscribers": 720118, "created_utc": 1703322707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am a member of a Telegram group that has over 150.000 files on it. I want to download all of them like I done on the others like save history and check files but there isn't any option to do that.\n\nWhat to do it?\n\nThank you in advance!", "author_fullname": "t2_6ljvypjch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download a lot of file from a Telegram group that has save history and files option disabled?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p0kvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703316951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a member of a Telegram group that has over 150.000 files on it. I want to download all of them like I done on the others like save history and check files but there isn&amp;#39;t any option to do that.&lt;/p&gt;\n\n&lt;p&gt;What to do it?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p0kvg", "is_robot_indexable": true, "report_reasons": null, "author": "SaseCaiFrumosi", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p0kvg/how_to_download_a_lot_of_file_from_a_telegram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p0kvg/how_to_download_a_lot_of_file_from_a_telegram/", "subreddit_subscribers": 720118, "created_utc": 1703316951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I backup terabytes of data to cloud providers like Google and Dropbox. And from time to time, I delete files that I don't need anymore or I feel are taking up more storage than I'd like to use. I use tools like FolderSizes or WizTree to scan drives. I'm hoping someone knows of a disk analyzer similar to DaisyDisk for Windows that also has a feature to scan cloud providers like Dropbox - [https://daisydiskapp.com/guide/cloud-scan](https://daisydiskapp.com/guide/cloud-scan). ", "author_fullname": "t2_54og1flc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-platform disk analyzer including cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p0bu3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703315881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I backup terabytes of data to cloud providers like Google and Dropbox. And from time to time, I delete files that I don&amp;#39;t need anymore or I feel are taking up more storage than I&amp;#39;d like to use. I use tools like FolderSizes or WizTree to scan drives. I&amp;#39;m hoping someone knows of a disk analyzer similar to DaisyDisk for Windows that also has a feature to scan cloud providers like Dropbox - &lt;a href=\"https://daisydiskapp.com/guide/cloud-scan\"&gt;https://daisydiskapp.com/guide/cloud-scan&lt;/a&gt;. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?auto=webp&amp;s=690c8038dda5cf42bd7fcfaf90e955c1c96552ee", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a28735e1595b8b388a6269b3762e42bc7c8347d3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=23d97dc406347e837fec6c5b62327a3b52081897", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cda091a9edb5a25a5d4b1e249bb5c28823f43673", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72aaa8a2fcefcbf125dae9ee2f445585af09c17c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=30b396879a050b2afa13bcb6cdd02b5af919a0d6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/uw-l5RJMB6hijFJCMqrI5ElyXU8OetJI6DxhXT3jOKQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6dfb4c359cd3a7e10b55ac21bfcfa53aab8f4868", "width": 1080, "height": 567}], "variants": {}, "id": "yLC3zkt6g4swal6-aE6TV2qYLbJeCb2LAR36vpF4pms"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p0bu3", "is_robot_indexable": true, "report_reasons": null, "author": "ryanhallinger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p0bu3/multiplatform_disk_analyzer_including_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p0bu3/multiplatform_disk_analyzer_including_cloud/", "subreddit_subscribers": 720118, "created_utc": 1703315881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Early this year I purchased a Mediasonic Probox HF2-SU3S2 after seeing some recommendations on here, and it seemed it be working fine.\n\nRecently I transferred over some working CBR files and got a bunch of CRC errors when I tried to open them. After looking deeper into the problem, it looks like a LOT of my files I've been transferring over for the past year seem to have some form of corruption.\n\nI've monitored the drives with Hard Disk Sentinel and they seem to be perfectly healthy. CHKDSK returned no errors on the drives either. A few days ago I tried copying over some files as a test and got the same CRC errors as before. I then tried switching over to my USB 2.0 port instead of the USB 3.0 I've been using all this time, and this time I got no errors. So I have to assume either there's an issue with the port, or the enclosure has issues transferring with USB 3.0.\n\nHas anyone noticed this issue with this particular USB enclosure, or just USB enclosures in general? At this point I'm hesitant to even keep using it and might look into alternative storage options. Recommendations are welcome.", "author_fullname": "t2_zde8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mediasonic Probox - Corrupted During Transfer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pivs8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703376925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Early this year I purchased a Mediasonic Probox HF2-SU3S2 after seeing some recommendations on here, and it seemed it be working fine.&lt;/p&gt;\n\n&lt;p&gt;Recently I transferred over some working CBR files and got a bunch of CRC errors when I tried to open them. After looking deeper into the problem, it looks like a LOT of my files I&amp;#39;ve been transferring over for the past year seem to have some form of corruption.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve monitored the drives with Hard Disk Sentinel and they seem to be perfectly healthy. CHKDSK returned no errors on the drives either. A few days ago I tried copying over some files as a test and got the same CRC errors as before. I then tried switching over to my USB 2.0 port instead of the USB 3.0 I&amp;#39;ve been using all this time, and this time I got no errors. So I have to assume either there&amp;#39;s an issue with the port, or the enclosure has issues transferring with USB 3.0.&lt;/p&gt;\n\n&lt;p&gt;Has anyone noticed this issue with this particular USB enclosure, or just USB enclosures in general? At this point I&amp;#39;m hesitant to even keep using it and might look into alternative storage options. Recommendations are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pivs8", "is_robot_indexable": true, "report_reasons": null, "author": "Alsage36", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pivs8/mediasonic_probox_corrupted_during_transfer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pivs8/mediasonic_probox_corrupted_during_transfer/", "subreddit_subscribers": 720118, "created_utc": 1703376925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone\n\nI am trying to expand my storage and trying to find max capacity supported by my raid card\n\n Marvell Technology Group Ltd. MV64460/64461/64462 System Controller", "author_fullname": "t2_x9w4f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Marvell Technology Group Ltd. MV64460/64461/64462 System Controller supports 20 TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pfpl9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703367448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone&lt;/p&gt;\n\n&lt;p&gt;I am trying to expand my storage and trying to find max capacity supported by my raid card&lt;/p&gt;\n\n&lt;p&gt;Marvell Technology Group Ltd. MV64460/64461/64462 System Controller&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pfpl9", "is_robot_indexable": true, "report_reasons": null, "author": "GlaciarWish", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pfpl9/marvell_technology_group_ltd_mv644606446164462/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pfpl9/marvell_technology_group_ltd_mv644606446164462/", "subreddit_subscribers": 720118, "created_utc": 1703367448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First time posting here, so be gentle. Wondering if anyone has had this issue before, I'm currently in the process of ripping my library to upload to plex so i have them stored digitally (on an external hard drive). When I put some of the dvd's into the drive it tries to read them and then nothing happens, doesn't start to pull them into DVDFab, doesn't give me the auto-pop up stating a disc has been put into the drive... this has happened with ripping movies and shows, shows are the worst as it'll read and rip the first and third or fourth discs in the season, but not the second etc. Some of these were brand spanking new, I had opened the season minutes before from the cellophane wrapping. Any idea as to what I can do to remedy this? Or does it seem like the drive is just starting to go? It's a DVD-RW in a refurbed Dell optiplex 9020 SFF I bought off amazon a few years ago. Link for the exact model when I bought it in 2020 attached.  It's rather frustrating to be ripping along and gathering everything and I have to set some movies or shows aside to try on a different drive in order to get them to rip, so far out of 300 items i've got probably 20-25 that have had an issue on being read in this slim drive. Thoughts? ", "author_fullname": "t2_a69a03qi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DVD-rom drive not reading some discs, but others just fine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pdvpn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703362169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First time posting here, so be gentle. Wondering if anyone has had this issue before, I&amp;#39;m currently in the process of ripping my library to upload to plex so i have them stored digitally (on an external hard drive). When I put some of the dvd&amp;#39;s into the drive it tries to read them and then nothing happens, doesn&amp;#39;t start to pull them into DVDFab, doesn&amp;#39;t give me the auto-pop up stating a disc has been put into the drive... this has happened with ripping movies and shows, shows are the worst as it&amp;#39;ll read and rip the first and third or fourth discs in the season, but not the second etc. Some of these were brand spanking new, I had opened the season minutes before from the cellophane wrapping. Any idea as to what I can do to remedy this? Or does it seem like the drive is just starting to go? It&amp;#39;s a DVD-RW in a refurbed Dell optiplex 9020 SFF I bought off amazon a few years ago. Link for the exact model when I bought it in 2020 attached.  It&amp;#39;s rather frustrating to be ripping along and gathering everything and I have to set some movies or shows aside to try on a different drive in order to get them to rip, so far out of 300 items i&amp;#39;ve got probably 20-25 that have had an issue on being read in this slim drive. Thoughts? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pdvpn", "is_robot_indexable": true, "report_reasons": null, "author": "r3db3ard0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pdvpn/dvdrom_drive_not_reading_some_discs_but_others/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pdvpn/dvdrom_drive_not_reading_some_discs_but_others/", "subreddit_subscribers": 720118, "created_utc": 1703362169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a DS220j with a 4TB WD Red (WD40EFAX) and I'm looking for a new HDD.\n\nI've recently discovered SMR mess and am wondering which HDD I should buy.\n\nNow I haven't any redundancy (Synology Hybrid RAID without data protection) and I'm only doing backups and I cannot use any types of filesystems but ext4.\n\nSo I need your help: in your opinion, what should I buy?  \n", "author_fullname": "t2_4qv7px88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS220j HDD Upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18pbf3k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703355126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a DS220j with a 4TB WD Red (WD40EFAX) and I&amp;#39;m looking for a new HDD.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently discovered SMR mess and am wondering which HDD I should buy.&lt;/p&gt;\n\n&lt;p&gt;Now I haven&amp;#39;t any redundancy (Synology Hybrid RAID without data protection) and I&amp;#39;m only doing backups and I cannot use any types of filesystems but ext4.&lt;/p&gt;\n\n&lt;p&gt;So I need your help: in your opinion, what should I buy?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18pbf3k", "is_robot_indexable": true, "report_reasons": null, "author": "Theviki20110", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18pbf3k/ds220j_hdd_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18pbf3k/ds220j_hdd_upgrade/", "subreddit_subscribers": 720118, "created_utc": 1703355126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm trying to download a website for med school since I have premium for only 1 month and that it's expensive.\n\nI tried httracks, sitesucker, teleport pro and others but I have errors maybe because it's logging me off or because of the robot.txt rules i really struggle so maybe someone in this sub already did a silimar project and is willing to help me ?\n\nHuge thanks !!\n\n&amp;#x200B;", "author_fullname": "t2_2zwdels4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Options to Download this website that as a login page ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p4uht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703335100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to download a website for med school since I have premium for only 1 month and that it&amp;#39;s expensive.&lt;/p&gt;\n\n&lt;p&gt;I tried httracks, sitesucker, teleport pro and others but I have errors maybe because it&amp;#39;s logging me off or because of the robot.txt rules i really struggle so maybe someone in this sub already did a silimar project and is willing to help me ?&lt;/p&gt;\n\n&lt;p&gt;Huge thanks !!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p4uht", "is_robot_indexable": true, "report_reasons": null, "author": "Kindaboii", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p4uht/best_options_to_download_this_website_that_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p4uht/best_options_to_download_this_website_that_as_a/", "subreddit_subscribers": 720118, "created_utc": 1703335100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to use a WD MyHome device for my father's sign shop, but after having my hardware effectively bricked TWICE by WD, I'm kind of done with them. Looking at replacing it with something that has some sustaining power. We moved to a new state recently-ish and I'm getting things set up in the new place. My father still dabbles in sign stuff even though he's retired (and I help him), and I'm an architect getting ready to launch my own practice. He uses Macs exclusively, and I use both, but live most of my life in Windows. My architectural project files can be fairly big (1 project can be 50+GB) and I need to access them from both in the home office and remotely. I'm a handy person but not an elite haxxor by any stretch. I can configure IPs if needed, but I'd prefer a \"works out of the box\" kind of solution. Thanks for considering.", "author_fullname": "t2_4ii3nxvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended NAS for small business/mixed OS environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18p4f0d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703333434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to use a WD MyHome device for my father&amp;#39;s sign shop, but after having my hardware effectively bricked TWICE by WD, I&amp;#39;m kind of done with them. Looking at replacing it with something that has some sustaining power. We moved to a new state recently-ish and I&amp;#39;m getting things set up in the new place. My father still dabbles in sign stuff even though he&amp;#39;s retired (and I help him), and I&amp;#39;m an architect getting ready to launch my own practice. He uses Macs exclusively, and I use both, but live most of my life in Windows. My architectural project files can be fairly big (1 project can be 50+GB) and I need to access them from both in the home office and remotely. I&amp;#39;m a handy person but not an elite haxxor by any stretch. I can configure IPs if needed, but I&amp;#39;d prefer a &amp;quot;works out of the box&amp;quot; kind of solution. Thanks for considering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18p4f0d", "is_robot_indexable": true, "report_reasons": null, "author": "moistmarbles", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18p4f0d/recommended_nas_for_small_businessmixed_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18p4f0d/recommended_nas_for_small_businessmixed_os/", "subreddit_subscribers": 720118, "created_utc": 1703333434.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}