{"kind": "Listing", "data": {"after": "t3_18lutuc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_nixsez0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does my backup plan look?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2bxa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 174, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 174, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zEbLHapnRMxePXskRWr-9c_dsHoQUEQwsZz0JUxBmyg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702993807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nr9i3jpxa97c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?auto=webp&amp;s=6fa44485265bb6f0e80f179de74502034abcd0f5", "width": 705, "height": 601}, "resolutions": [{"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39a747f24ff40be416bfe9df2a3643babe4111a0", "width": 108, "height": 92}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a2a9c2f72ebcd364a0759f1ff529258de237a66", "width": 216, "height": 184}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d8ab38510897dc2bdad9a9398b0f41376520984", "width": 320, "height": 272}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76c9f9971af0e46b952e008aa465ff8761c93bd9", "width": 640, "height": 545}], "variants": {}, "id": "NKZMmmJh-lDar_MZu8iCp8jSSx1Zz7Y9bZ-vgYZrPY4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m2bxa", "is_robot_indexable": true, "report_reasons": null, "author": "AnApexBread", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18m2bxa/how_does_my_backup_plan_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nr9i3jpxa97c1.png", "subreddit_subscribers": 719300, "created_utc": 1702993807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_saefx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I proudly present my janky testing setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tt3xg8fyra7c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d663397a3f7d90f53f0d396e713135f148987796"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db69bdd499f4e6d47a309ef8552c006a235d5c5a"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e24a11fc2817dd81e4f65c20ee4d08bc21f20b6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2843c9d811a5a753916228a5105719e125e58ab"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1cf2c475c96e87d9b6c244ea540a1f18f5799922"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0cae3d79f9adc2cdf54ff830bb418054fbfd4d14"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=0e185e52217f73464af02be20b07d535d5537168"}, "id": "tt3xg8fyra7c1"}, "7n62g9fyra7c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0920950b45970b042ef526c0e7b0654a0e03e503"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a79998d360a6c2b27a237f9fc88e91af0305fb26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0cb88a9051bbbd333f6b8891bacf9f37f10997da"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=50e472f75e457857f91deeeb91446ff15a69d654"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69b899c5acdb01aebf18e842f5092552dec1e128"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3de35654bcbba18d175bf336dd61c45d83fce5d"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=69da04f39662d7288f0b968136fa51ff39098a54"}, "id": "7n62g9fyra7c1"}}, "name": "t3_18m97ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 55, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "tt3xg8fyra7c1", "id": 376241631}, {"media_id": "7n62g9fyra7c1", "id": 376241632}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OyMdjzQSo5pa6aS8KxIta6XjhvtFjQWrxNkJe2G6Dpo.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703011640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18m97ns", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m97ns", "is_robot_indexable": true, "report_reasons": null, "author": "888Leander", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18m97ns/i_proudly_present_my_janky_testing_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18m97ns", "subreddit_subscribers": 719300, "created_utc": 1703011640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ck2fr5mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive Files Opening Brief In Its Appeal Of Book Publishers\u2019 Win", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18lqs2g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/32tby5F3UarM4Rscy-SkPm3xC4qTq8BKvODeFaylpoU.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702952851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techdirt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techdirt.com/2023/12/18/internet-archive-files-opening-brief-in-its-appeal-of-book-publishers-win/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?auto=webp&amp;s=03a5fde066455710ac1676ca5e55fdf4cff5f177", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd544711a911105c2c84e8778e42492e6627f7ee", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=581443ef43c416964d464ddd6b5b28eec7b2b77c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=98eca8135ccdbe0daad2aad9f2f21c250d1564ab", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60f612dc25b6693520e6d4a342645939506f3afd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=30ce1c1c245620a8b70a4d0a298b39657711ef0e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b24b6b5a4ae88248a5d6b951b789da794832c41", "width": 1080, "height": 567}], "variants": {}, "id": "86PGtE2qmX3coS9Htmb8TUfXMSg2HaYO4Rk8A0YbGow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lqs2g", "is_robot_indexable": true, "report_reasons": null, "author": "AbolishDisney", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18lqs2g/internet_archive_files_opening_brief_in_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techdirt.com/2023/12/18/internet-archive-files-opening-brief-in-its-appeal-of-book-publishers-win/", "subreddit_subscribers": 719300, "created_utc": 1702952851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do you test your backups?\n\n&amp;#x200B;\n\nMany of us have a ton of data we're holding on to, and a lot of it is important enough for us to backup, but how do you test that backup when you have multiple TBs of data? \n\n&amp;#x200B;\n\nDo you just restore small bits of data periodically and hope that if the small amount works, then the rest will work as well, or do you do full restores and eat the cost (in time and money if you're pulling from the cloud)? \n\n&amp;#x200B;\n\nI know a lot of systems \"test\" backups automatically but without actually seeing the data how can you be sure? ", "author_fullname": "t2_nixsez0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you test your backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ls6tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you test your backups?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many of us have a ton of data we&amp;#39;re holding on to, and a lot of it is important enough for us to backup, but how do you test that backup when you have multiple TBs of data? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you just restore small bits of data periodically and hope that if the small amount works, then the rest will work as well, or do you do full restores and eat the cost (in time and money if you&amp;#39;re pulling from the cloud)? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know a lot of systems &amp;quot;test&amp;quot; backups automatically but without actually seeing the data how can you be sure? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ls6tr", "is_robot_indexable": true, "report_reasons": null, "author": "AnApexBread", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18ls6tr/how_do_you_test_your_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ls6tr/how_do_you_test_your_backups/", "subreddit_subscribers": 719300, "created_utc": 1702957065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So far I only cloned HDDs onto other HDD. Is it any difference when you copy from an HDD to an SSD or vice versa? I assume that it should not be any different, just never tried it before.", "author_fullname": "t2_pr4df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything to know when cloning an old HDD to an SSD using Macrium Reflect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ly10y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702978495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far I only cloned HDDs onto other HDD. Is it any difference when you copy from an HDD to an SSD or vice versa? I assume that it should not be any different, just never tried it before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ly10y", "is_robot_indexable": true, "report_reasons": null, "author": "Dron22", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ly10y/anything_to_know_when_cloning_an_old_hdd_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ly10y/anything_to_know_when_cloning_an_old_hdd_to_an/", "subreddit_subscribers": 719300, "created_utc": 1702978495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I made a post on here a while ago asking for tips on a planend NAS build and had a long discussion with someone here. One of the main things that shook me was his claim that RAID isn't really necessary for most people, especially using helium manufac. refurbised hard drives. It's much more important to have both an off-site and cloud backup in additon to your main system. Interested in hearing your guy's thoughts. Thank you", "author_fullname": "t2_mqskseq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is RAID really necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mcdaj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703019593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I made a post on here a while ago asking for tips on a planend NAS build and had a long discussion with someone here. One of the main things that shook me was his claim that RAID isn&amp;#39;t really necessary for most people, especially using helium manufac. refurbised hard drives. It&amp;#39;s much more important to have both an off-site and cloud backup in additon to your main system. Interested in hearing your guy&amp;#39;s thoughts. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mcdaj", "is_robot_indexable": true, "report_reasons": null, "author": "OneSteelTank", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mcdaj/is_raid_really_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mcdaj/is_raid_really_necessary/", "subreddit_subscribers": 719300, "created_utc": 1703019593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't think this is really about hoarding data, but I didn't know where else to ask and figured people here would likely have answers, so here it is.\n\nMy situation: I use a 500GB NVMe SSD for my Windows installation, and a 2TB (soon to be 4TB) SATA SSD for everything that doesn't force itself onto the Windows drive; mostly games, music, images. My backup drive (for both of the other drives) is a 5TB portable HDD. Please ignore the lack of 3-2-1 for now.\n\nFor a few years I've been using Acronis True Image 2019, specifically doing incremental backups with weekly full backups, but with my slow, noisy external HDD this got kind of annoying as it would take times on the order of 6 hours to do a full backup each week, and if I put my computer to sleep in the middle of that, it would sometimes cause Acronis to hang or fail the backup.\n\nIn a big whoopsie recently (but also somewhat tangentially), I accidentally emptied my entire backup drive while trying to clear some files with illegal names left over from a horribly failed Linux experiment, which prompted me (tangentially - since that was obviously user error) to look into better backup solutions after it occurred to me that the method of doing full backups and then having a few increments per week is actually extremely inefficient as a long term file history due to multiplication of data.\n\nSo, while reading some reddit posts, I came across Duplicacy, which I think has a really compelling concept in how efficient it is both in space saving and backup time over long backup histories, as large numbers of snapshots can have large intersections which are wholly deduplicated, and every backup after the first is effectively both incremental and full, without any special differences between them in how each snapshot can be read and restored, so I've been trialing the Web UI version.\n\nHowever, I've realized now that Duplicacy doesn't back up system images; only the C: volume, which I think means that restored backups of the Windows drive will not be bootable (it doesn't matter that the backup itself isn't bootable - just the restored files). On top of that, I've recently found out about hardlinks and want to make use of them in some of my media libraries, and Duplicacy does not preserve those, instead just backing up multiple copies of the file, whereas I think an image backup would preserve the hardlinks and not duplicate the file?\n\nAnyway, to make a long story short, is there any backup software currently available for Windows that combines image backups with a clever chunking system for deduplication, for a long backup history on limited storage space, fast backups every time, preservation of bootability and fancy file linking structure, and which won't implode through a sleep-wake cycle (that last one is less important)? If there's no software in particular, or I'm misunderstanding what an image backup is, is there a strategy that can achieve the same thing? Also, as a side note, I'm looking into buying an external/portable SSD (a really fast one for future-proofing), but it seems like there are a lot of dubious products on the market in that area right now, so I'm not sure where to go with that.\n\nAny additional notes to consider would be appreciated.", "author_fullname": "t2_dzp8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to back up my whole Windows home system efficiently and flexibly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2z80", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice - Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702996943.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702995616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think this is really about hoarding data, but I didn&amp;#39;t know where else to ask and figured people here would likely have answers, so here it is.&lt;/p&gt;\n\n&lt;p&gt;My situation: I use a 500GB NVMe SSD for my Windows installation, and a 2TB (soon to be 4TB) SATA SSD for everything that doesn&amp;#39;t force itself onto the Windows drive; mostly games, music, images. My backup drive (for both of the other drives) is a 5TB portable HDD. Please ignore the lack of 3-2-1 for now.&lt;/p&gt;\n\n&lt;p&gt;For a few years I&amp;#39;ve been using Acronis True Image 2019, specifically doing incremental backups with weekly full backups, but with my slow, noisy external HDD this got kind of annoying as it would take times on the order of 6 hours to do a full backup each week, and if I put my computer to sleep in the middle of that, it would sometimes cause Acronis to hang or fail the backup.&lt;/p&gt;\n\n&lt;p&gt;In a big whoopsie recently (but also somewhat tangentially), I accidentally emptied my entire backup drive while trying to clear some files with illegal names left over from a horribly failed Linux experiment, which prompted me (tangentially - since that was obviously user error) to look into better backup solutions after it occurred to me that the method of doing full backups and then having a few increments per week is actually extremely inefficient as a long term file history due to multiplication of data.&lt;/p&gt;\n\n&lt;p&gt;So, while reading some reddit posts, I came across Duplicacy, which I think has a really compelling concept in how efficient it is both in space saving and backup time over long backup histories, as large numbers of snapshots can have large intersections which are wholly deduplicated, and every backup after the first is effectively both incremental and full, without any special differences between them in how each snapshot can be read and restored, so I&amp;#39;ve been trialing the Web UI version.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve realized now that Duplicacy doesn&amp;#39;t back up system images; only the C: volume, which I think means that restored backups of the Windows drive will not be bootable (it doesn&amp;#39;t matter that the backup itself isn&amp;#39;t bootable - just the restored files). On top of that, I&amp;#39;ve recently found out about hardlinks and want to make use of them in some of my media libraries, and Duplicacy does not preserve those, instead just backing up multiple copies of the file, whereas I think an image backup would preserve the hardlinks and not duplicate the file?&lt;/p&gt;\n\n&lt;p&gt;Anyway, to make a long story short, is there any backup software currently available for Windows that combines image backups with a clever chunking system for deduplication, for a long backup history on limited storage space, fast backups every time, preservation of bootability and fancy file linking structure, and which won&amp;#39;t implode through a sleep-wake cycle (that last one is less important)? If there&amp;#39;s no software in particular, or I&amp;#39;m misunderstanding what an image backup is, is there a strategy that can achieve the same thing? Also, as a side note, I&amp;#39;m looking into buying an external/portable SSD (a really fast one for future-proofing), but it seems like there are a lot of dubious products on the market in that area right now, so I&amp;#39;m not sure where to go with that.&lt;/p&gt;\n\n&lt;p&gt;Any additional notes to consider would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18m2z80", "is_robot_indexable": true, "report_reasons": null, "author": "bjshnog", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m2z80/i_want_to_back_up_my_whole_windows_home_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m2z80/i_want_to_back_up_my_whole_windows_home_system/", "subreddit_subscribers": 719300, "created_utc": 1702995616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " (Hey team. Long story short. I zapped my portable brand new samsung ssd pretty hard and I am a bit upset as the drive was disconnected from pc when zapped, clearly indicating that the charge wasn't \"ignored\". Not sure how these things mitigate such charges and if the drive is unharmed - S.M.A.R.T and block check doesn't hint anything so far)\n\nSo\n\nLooking for advice on whether the product is capable of dissipating human induced ESD transients, because I guess it carries a metallic casing and conducts perfectly with the skin, unlike its shield counterpart....\n\nIncident:\n\n\\-Samsung t7 touch portable ssd in usb.\n\n\\-Me accumulating some good charge due to clothing or couch material (not sure but unlucky and idiot for not grounding, even when handling encased ssd I guess..)\n\n\\-Reaching out for my disk and got the usual stingy \"crackle\" of static discharge on my finger.\n\n\\-SSD **disconnected** from pc from the shock while plugged.. here not sure if the crackle/transfer is a good thing (reaching ground via USB instead of absorbing or if it really messed with the SSD internals.. )\n\nPlugging back again, seems to be the same except for some weird reason **pulling lower number on random IOPS read bench. (Something like 10%** lower but could be as well margin of error?)\n\nI know that it should be ridiculously hard especially on portable ssds, to degrade them by static, on paper. This would really beat all purpose and design. Its a product you are supposed to slide in your pocket and \"live life normally\" with it, instead of being a weirdo touching grounded sockets and pulling it from special pouches...... Never had my smartphone for example react in a similar way to any charges (crackle) , and its a portable device as well but there I am guessing it's the battery itself that mitigates everything safely and its not \"grounded\" per traditional means.\n\nDo you think I should worry about the integrity of the drive's circuitry? Still can't explain *why the drive got ejected when zapped* , and whether the charge has dissipated safely/what was affected. Is it a safety feature to disconnect when detecting abnormal voltage? Is the casing connected to diodes so the surge went through the USB port in the end, triggering the MOBO cutoff instead of messing with the SSD itself?\n\nThe drive carries a ton of cerifications like KC, CE, IS 13252 part1 IEC 60950-1 , TUV certified , and I don't know what else because still researching if a tag on it clearly defines ESD mitigation spec, so in the grand theory of assumption and consumer electronics practices, should be immune to any static electricity from normal scenarios.\n\nAm I too worried in the end..? I just don't want it to have my data and be compromised from day 1 tbh.", "author_fullname": "t2_9dmr41h6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zapped portable external ssd a bit hard, ESD damage possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mczmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703021159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Hey team. Long story short. I zapped my portable brand new samsung ssd pretty hard and I am a bit upset as the drive was disconnected from pc when zapped, clearly indicating that the charge wasn&amp;#39;t &amp;quot;ignored&amp;quot;. Not sure how these things mitigate such charges and if the drive is unharmed - S.M.A.R.T and block check doesn&amp;#39;t hint anything so far)&lt;/p&gt;\n\n&lt;p&gt;So&lt;/p&gt;\n\n&lt;p&gt;Looking for advice on whether the product is capable of dissipating human induced ESD transients, because I guess it carries a metallic casing and conducts perfectly with the skin, unlike its shield counterpart....&lt;/p&gt;\n\n&lt;p&gt;Incident:&lt;/p&gt;\n\n&lt;p&gt;-Samsung t7 touch portable ssd in usb.&lt;/p&gt;\n\n&lt;p&gt;-Me accumulating some good charge due to clothing or couch material (not sure but unlucky and idiot for not grounding, even when handling encased ssd I guess..)&lt;/p&gt;\n\n&lt;p&gt;-Reaching out for my disk and got the usual stingy &amp;quot;crackle&amp;quot; of static discharge on my finger.&lt;/p&gt;\n\n&lt;p&gt;-SSD &lt;strong&gt;disconnected&lt;/strong&gt; from pc from the shock while plugged.. here not sure if the crackle/transfer is a good thing (reaching ground via USB instead of absorbing or if it really messed with the SSD internals.. )&lt;/p&gt;\n\n&lt;p&gt;Plugging back again, seems to be the same except for some weird reason &lt;strong&gt;pulling lower number on random IOPS read bench. (Something like 10%&lt;/strong&gt; lower but could be as well margin of error?)&lt;/p&gt;\n\n&lt;p&gt;I know that it should be ridiculously hard especially on portable ssds, to degrade them by static, on paper. This would really beat all purpose and design. Its a product you are supposed to slide in your pocket and &amp;quot;live life normally&amp;quot; with it, instead of being a weirdo touching grounded sockets and pulling it from special pouches...... Never had my smartphone for example react in a similar way to any charges (crackle) , and its a portable device as well but there I am guessing it&amp;#39;s the battery itself that mitigates everything safely and its not &amp;quot;grounded&amp;quot; per traditional means.&lt;/p&gt;\n\n&lt;p&gt;Do you think I should worry about the integrity of the drive&amp;#39;s circuitry? Still can&amp;#39;t explain &lt;em&gt;why the drive got ejected when zapped&lt;/em&gt; , and whether the charge has dissipated safely/what was affected. Is it a safety feature to disconnect when detecting abnormal voltage? Is the casing connected to diodes so the surge went through the USB port in the end, triggering the MOBO cutoff instead of messing with the SSD itself?&lt;/p&gt;\n\n&lt;p&gt;The drive carries a ton of cerifications like KC, CE, IS 13252 part1 IEC 60950-1 , TUV certified , and I don&amp;#39;t know what else because still researching if a tag on it clearly defines ESD mitigation spec, so in the grand theory of assumption and consumer electronics practices, should be immune to any static electricity from normal scenarios.&lt;/p&gt;\n\n&lt;p&gt;Am I too worried in the end..? I just don&amp;#39;t want it to have my data and be compromised from day 1 tbh.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18mczmg", "is_robot_indexable": true, "report_reasons": null, "author": "Long_Distribution_89", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mczmg/zapped_portable_external_ssd_a_bit_hard_esd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mczmg/zapped_portable_external_ssd_a_bit_hard_esd/", "subreddit_subscribers": 719300, "created_utc": 1703021159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've used SingleFile for most of my website saving names. However, I recently just hit a snap with one very long website with a lot of photos on it. SingleFile says that it can't save it, and even when I try to print to PDF, the PDF generation hangs or doesn't complete correctly.\n\nDoes anyone have any suggestions for how I can save this long website or split it up into multiple saves?", "author_fullname": "t2_8rx1t53xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SingleFile alternative for long websites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mhvba", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703034401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve used SingleFile for most of my website saving names. However, I recently just hit a snap with one very long website with a lot of photos on it. SingleFile says that it can&amp;#39;t save it, and even when I try to print to PDF, the PDF generation hangs or doesn&amp;#39;t complete correctly.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions for how I can save this long website or split it up into multiple saves?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mhvba", "is_robot_indexable": true, "report_reasons": null, "author": "torando39", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mhvba/singlefile_alternative_for_long_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mhvba/singlefile_alternative_for_long_websites/", "subreddit_subscribers": 719300, "created_utc": 1703034401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a lot of large media files. I used to use xpenology but I don't really love it. It's not the fact that it is bootleg, but the fact that the drives are always spun up because of raid (I realize with a real Synology unit spin down probably works better).\n\nI switched over to windows and gave drivepool + snapraid a shot. Drive pool takes days to rebalance 11 tb of files across my sata drives that I haven't even run snapraid yet. Unraid was the same deal. Kind of slow to copy files but I'm willing to give it another shot if the drives can spin down.\n\nAt this point I'm kind of frustrated. I could try trueNAS but it has higher memory requirements and still will require all the drives to be present and spinning to get data out.\n\nI'm thinking of getting a HDD enclosure and using a usbc to a mini PC. Hopefully the enclosure is one that can power down when not using. But then I'm not sure what to use for redundancy across the drives. Maybe just snapraid.\n\nI guess my ideal is some sort of raid that's easy to expand and shrink, runs on windows, presents itself as one large pool, takes little resources to run, still allows the drives to be powered down as needed.", "author_fullname": "t2_yvwer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Home media file storage looking for options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mhu05", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703034289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a lot of large media files. I used to use xpenology but I don&amp;#39;t really love it. It&amp;#39;s not the fact that it is bootleg, but the fact that the drives are always spun up because of raid (I realize with a real Synology unit spin down probably works better).&lt;/p&gt;\n\n&lt;p&gt;I switched over to windows and gave drivepool + snapraid a shot. Drive pool takes days to rebalance 11 tb of files across my sata drives that I haven&amp;#39;t even run snapraid yet. Unraid was the same deal. Kind of slow to copy files but I&amp;#39;m willing to give it another shot if the drives can spin down.&lt;/p&gt;\n\n&lt;p&gt;At this point I&amp;#39;m kind of frustrated. I could try trueNAS but it has higher memory requirements and still will require all the drives to be present and spinning to get data out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of getting a HDD enclosure and using a usbc to a mini PC. Hopefully the enclosure is one that can power down when not using. But then I&amp;#39;m not sure what to use for redundancy across the drives. Maybe just snapraid.&lt;/p&gt;\n\n&lt;p&gt;I guess my ideal is some sort of raid that&amp;#39;s easy to expand and shrink, runs on windows, presents itself as one large pool, takes little resources to run, still allows the drives to be powered down as needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mhu05", "is_robot_indexable": true, "report_reasons": null, "author": "jacksonfalls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mhu05/home_media_file_storage_looking_for_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mhu05/home_media_file_storage_looking_for_options/", "subreddit_subscribers": 719300, "created_utc": 1703034289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's a no-brainer that I should order a new drive to replace the one with bad sectors, especially since it registered 100 bad sectors in just an hour. Consequently, I've removed that drive from my NAS for now. However, this situation is starting to concern me. If this drive is failing, should I expect the others to fail soon as well? Is 70,000 hours a significant amount of operating time for WD Red NAS drives? All the drives were purchased at the same time and have been running continuously since then. \n\nWhat would you honestly recommend in this situation?", "author_fullname": "t2_5tsmwe62", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with Bad Sectors on One Drive Among Others with Over 70,000 Hours of Runtime: Seeking Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m1vvz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702992519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a no-brainer that I should order a new drive to replace the one with bad sectors, especially since it registered 100 bad sectors in just an hour. Consequently, I&amp;#39;ve removed that drive from my NAS for now. However, this situation is starting to concern me. If this drive is failing, should I expect the others to fail soon as well? Is 70,000 hours a significant amount of operating time for WD Red NAS drives? All the drives were purchased at the same time and have been running continuously since then. &lt;/p&gt;\n\n&lt;p&gt;What would you honestly recommend in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m1vvz", "is_robot_indexable": true, "report_reasons": null, "author": "bilstream", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m1vvz/dealing_with_bad_sectors_on_one_drive_among/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m1vvz/dealing_with_bad_sectors_on_one_drive_among/", "subreddit_subscribers": 719300, "created_utc": 1702992519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI am new to NAS/networking in general. I am interested in swapping out a portable HD for a NAS as I have multiple computers.\n\nI am currently looking at 2 NAS which are made by Terra-master and Synology. Which one has more of a learning opportunity? I am open to other suggestions I am not looking to spend an arm and a leg though this will just be for personal use. My thoughts on what I will be using the NAS for is to stream, use outside the LAN, cloud storage, etc. Any recommendations would be appreciated.", "author_fullname": "t2_5z6tme5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best NAS for learning/tinkering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mifqq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703036095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am new to NAS/networking in general. I am interested in swapping out a portable HD for a NAS as I have multiple computers.&lt;/p&gt;\n\n&lt;p&gt;I am currently looking at 2 NAS which are made by Terra-master and Synology. Which one has more of a learning opportunity? I am open to other suggestions I am not looking to spend an arm and a leg though this will just be for personal use. My thoughts on what I will be using the NAS for is to stream, use outside the LAN, cloud storage, etc. Any recommendations would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mifqq", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Layer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mifqq/what_is_the_best_nas_for_learningtinkering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mifqq/what_is_the_best_nas_for_learningtinkering/", "subreddit_subscribers": 719300, "created_utc": 1703036095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently started moving my NAS into a Fractal Define Meshify 2 XL for the additional hard drive space. I also recently picked up a new PSU to handle the extra drives Super Flower Leadex Platinum SE 1000W (SF-1000F14MP V2). The PSU came with four cables consisting of three sata power plugs, however I need a total of 22 ports for complete coverage. \n\nWhat would be the best method to add additional sata power plugs?", "author_fullname": "t2_zbwnj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Additional Sata Power Options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mfn5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703028110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently started moving my NAS into a Fractal Define Meshify 2 XL for the additional hard drive space. I also recently picked up a new PSU to handle the extra drives Super Flower Leadex Platinum SE 1000W (SF-1000F14MP V2). The PSU came with four cables consisting of three sata power plugs, however I need a total of 22 ports for complete coverage. &lt;/p&gt;\n\n&lt;p&gt;What would be the best method to add additional sata power plugs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mfn5n", "is_robot_indexable": true, "report_reasons": null, "author": "ComradeShyGuy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mfn5n/additional_sata_power_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mfn5n/additional_sata_power_options/", "subreddit_subscribers": 719300, "created_utc": 1703028110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have thousands of movies/videos spread across 2 or 3 drives from over the last 5 or 10 years, so I would love something with a UI so I can drag and drop all these into a queue and let it overwrite the existing files with ones with a lower file size. I don't mind giving a list of file paths to a script but given the disorganization of everything, that would be a little more tedious. But anything works.\n\nFollow up question: What is the best set of parameters to give for this? Like would there be any risk/downside to just saying like I don't want any of these to be over 1gb? A lot of these are 1440p/4k, would it be better to scale these down a bit before I even mess with the bit rate/\"max file size\" stuff? I just don't know what to expect or the best way to go about it. Any tips would be appreciated.\n\nThanks!", "author_fullname": "t2_hv5ly9kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a solid Windows app/python script to down downsample thousands of movies/videos that are much larger than I need them to be. Also have a couple of questions about this for anyone with expertise.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mfe71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703027455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have thousands of movies/videos spread across 2 or 3 drives from over the last 5 or 10 years, so I would love something with a UI so I can drag and drop all these into a queue and let it overwrite the existing files with ones with a lower file size. I don&amp;#39;t mind giving a list of file paths to a script but given the disorganization of everything, that would be a little more tedious. But anything works.&lt;/p&gt;\n\n&lt;p&gt;Follow up question: What is the best set of parameters to give for this? Like would there be any risk/downside to just saying like I don&amp;#39;t want any of these to be over 1gb? A lot of these are 1440p/4k, would it be better to scale these down a bit before I even mess with the bit rate/&amp;quot;max file size&amp;quot; stuff? I just don&amp;#39;t know what to expect or the best way to go about it. Any tips would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mfe71", "is_robot_indexable": true, "report_reasons": null, "author": "drippyneon", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mfe71/looking_for_a_solid_windows_apppython_script_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mfe71/looking_for_a_solid_windows_apppython_script_to/", "subreddit_subscribers": 719300, "created_utc": 1703027455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nJust got my first LTO-5 drive and a stack of 27 used tapes to go alongside it. I have a couple of questions regarding tape longevity and margins.\n\nThe HPE Library and Tape Tools health diagnostics reports a Full Volume Equivalents value for cartridges. Is this number equivalent to one full tape write?\n\nSometimes, I get a couple of margin errors on tapes. This ends up meaning the native capacity appears to be reduced. Is this correct? How does software handle this loss (tape abanonment, writing what it can and just accepting the reduction etc)?\n\nI'm concerned something is wrong but I cannot tell if its the tapes or the drive at fault.\n\nThanks", "author_fullname": "t2_1pmvzm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO Native Capacity &amp; Margins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mdxx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703023585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;Just got my first LTO-5 drive and a stack of 27 used tapes to go alongside it. I have a couple of questions regarding tape longevity and margins.&lt;/p&gt;\n\n&lt;p&gt;The HPE Library and Tape Tools health diagnostics reports a Full Volume Equivalents value for cartridges. Is this number equivalent to one full tape write?&lt;/p&gt;\n\n&lt;p&gt;Sometimes, I get a couple of margin errors on tapes. This ends up meaning the native capacity appears to be reduced. Is this correct? How does software handle this loss (tape abanonment, writing what it can and just accepting the reduction etc)?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m concerned something is wrong but I cannot tell if its the tapes or the drive at fault.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mdxx8", "is_robot_indexable": true, "report_reasons": null, "author": "DevelopedLogic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mdxx8/lto_native_capacity_margins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mdxx8/lto_native_capacity_margins/", "subreddit_subscribers": 719300, "created_utc": 1703023585.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've just bought 4x 18tb WD Element drives and plan on shucking them and putting them in a nas server. I'm looking to see what nas devices support 18tb drives and what recommendations you can give me as this will be my first nas and I don't know where to start in all honesty. Thankyou", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS Server that supports 18tb drives? Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m8g1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703009728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just bought 4x 18tb WD Element drives and plan on shucking them and putting them in a nas server. I&amp;#39;m looking to see what nas devices support 18tb drives and what recommendations you can give me as this will be my first nas and I don&amp;#39;t know where to start in all honesty. Thankyou&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m8g1l", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m8g1l/nas_server_that_supports_18tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m8g1l/nas_server_that_supports_18tb_drives/", "subreddit_subscribers": 719300, "created_utc": 1703009728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Found out recently that the contents of my journal on Google Docs were erased due to an oversight. Somehow, I managed to copy an empty version of the journal (it was either incomplete or that I accidentally backspaced its contents) to all four of my backups (local, Google Drive, GitHub, and a physical harddrive), which then overrode the complete file. \n\nMy oversight was that since the file was a Google Doc, all of the version histories across all backups were linking back to that overwritten file, and thus, I was not able to utilise version histories to recover the contents of the file at all. Even worse, was that since this incident happened months ago, and that I just found out just now, I am unable to recover anything due to routine deletions.\n\nI know that reading back on my post, I could have probably done a lot better in safekeeping my data better. I'm still new and learning when it comes to data hoarding, but this incident has really made me want to learn even more. \n\nWhat can I learn from this experience to better safe-keep my data?\n\nTL;DR: Lost data due to a oversight with Google Docs. How to improve?", "author_fullname": "t2_3jk99r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost the contents of an important digital journal. How can I learn from this experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m5dll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703001888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found out recently that the contents of my journal on Google Docs were erased due to an oversight. Somehow, I managed to copy an empty version of the journal (it was either incomplete or that I accidentally backspaced its contents) to all four of my backups (local, Google Drive, GitHub, and a physical harddrive), which then overrode the complete file. &lt;/p&gt;\n\n&lt;p&gt;My oversight was that since the file was a Google Doc, all of the version histories across all backups were linking back to that overwritten file, and thus, I was not able to utilise version histories to recover the contents of the file at all. Even worse, was that since this incident happened months ago, and that I just found out just now, I am unable to recover anything due to routine deletions.&lt;/p&gt;\n\n&lt;p&gt;I know that reading back on my post, I could have probably done a lot better in safekeeping my data better. I&amp;#39;m still new and learning when it comes to data hoarding, but this incident has really made me want to learn even more. &lt;/p&gt;\n\n&lt;p&gt;What can I learn from this experience to better safe-keep my data?&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Lost data due to a oversight with Google Docs. How to improve?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m5dll", "is_robot_indexable": true, "report_reasons": null, "author": "Flame4Fire", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m5dll/lost_the_contents_of_an_important_digital_journal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m5dll/lost_the_contents_of_an_important_digital_journal/", "subreddit_subscribers": 719300, "created_utc": 1703001888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am considering buying a 8-10 TB HDD for desktop usage.\nStorage of films, some games etc.\n\nCurrently WD Gold 8TB is cheaper or same price as WTB Red at my country. Should I go with gold, will there be any problem using it on PC, considering they are both \"NAS, data disks\"\n\nI want to go with gold or red cause I have read they are better quality than the normal green ones, that have been failing me recently.", "author_fullname": "t2_d6vkdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Gold vs WD Red Plus/Pro for desktop PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m3ghe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702996922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am considering buying a 8-10 TB HDD for desktop usage.\nStorage of films, some games etc.&lt;/p&gt;\n\n&lt;p&gt;Currently WD Gold 8TB is cheaper or same price as WTB Red at my country. Should I go with gold, will there be any problem using it on PC, considering they are both &amp;quot;NAS, data disks&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I want to go with gold or red cause I have read they are better quality than the normal green ones, that have been failing me recently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m3ghe", "is_robot_indexable": true, "report_reasons": null, "author": "exstelx", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m3ghe/wd_gold_vs_wd_red_pluspro_for_desktop_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m3ghe/wd_gold_vs_wd_red_pluspro_for_desktop_pc/", "subreddit_subscribers": 719300, "created_utc": 1702996922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently, I have many thousands of files that I am looking to manage, and I am looking for a service to help me manage them.\n\nIn order to help clarify what I am asking for, I'll explain the problem in more detail. There are three steps associated with adding to this collection:\n\n1. **Collection**: This involves the act of collecting the files, which could include downloading them, creating them, or finding them offline.\n2. **Storage**: How are the files stored? What data is stored alongside them? Note that self hosted data is a required option.\n3. **Management**: Once the files and associated data are stored, how can you manage them? A self hosted service would be ideal.\n\nThere exist many solutions for the Storage &amp; Management steps, including OS built-in tools such as Windows File Explorer. These solutions are usually called *Digital Asset Management* (DAM) Services.\n\nThere also of course exist many separate solutions for the Collection step, such as web scraping tools like [Gallery-DL](https://github.com/mikf/gallery-dl) or [yt-dlp](https://github.com/yt-dlp/yt-dlp)\n\nHowever, as many of you probably have encountered, it can be difficult to find solutions that work together well. Even if you do find one that works, it often heavily limits your flexibility.\n\nFor example, say you want to incorporate tags as metadata associated with files for querying purposes. Many DAM services allow this functionality, but what happens if you suddenly want to switch DAM services? It may become remarkably difficult if the tags are stored in a confusing proprietary database that you'll have to parse through to get the metadata back out. Or what if you have tags that you parsed using a web scraping tool that you want to import? Some DAM services don't easily allow this and don't let you automate it (no API or access to the database),  and as such you may find yourself going through the process of either automating the input yourself or manually inputting each tag (yikes). What if you also have files from different data streams such as some parsed from online and some from offline? You would have to put it all into the DAM and forget about any different metadata those files might have. Forget about having a local copy you can look through as well in most cases. Many DAMs also don't support some file types.\n\nThere are also issues associated with functionality such as tagging. There is no universally accepted standard for what tags exist and what format they should be in. The closest I've found is the [Public Tag Repository](https://hydrusnetwork.github.io/hydrus/PTR.html) or [Danbooru's Tags (NSFW)](https://danbooru.donmai.us/tags). Note that the PTR is probably the closest as I cannot find a way to have access to Danbooru's tag database. Its database is also a nightmare with around 64 tables in their database and everything in SQL which requires a migration to change the schema of.\n\nAs such, if you want true flexibility you have to find a way to separate the steps and be able to interchange the solutions you use for each. For collection, you should be able to use any method and scrapers that you want. For storage, files need to be stored in a universally accepted way along with their metadata that is stored either in an associated file or a database. Lastly, the management software needs to be completely separate, meaning you can switch DAMs as you please simply through importing and exporting your data. If you make a change to a file in a DAM service, it needs to be reflected in your storage solution.\n\nNote that there are solutions that try to cover all three steps, such as [Hydrus Network](https://github.com/hydrusnetwork/hydrus) which is a robust solution that acts as a DAM and also as a downloader with users being able to make custom downloaders. However, I've found myself using different downloaders for unsupported sites and struggling to find a way to automate the importing of tags. It also gets difficult when the biggest community made downloaders (e.g. for Danbooru) do not parse everything you want. It also does not support all of the functionalities that someone may want such as easily seeing file children/parents/siblings.\n\nThe only real solution I can think of for this is to store files in a universal file system (simple hierarchical file system such as exFAT) and to store metadata associated with each file's hash in a database that can be flexibly updated to reflect data stored or created in DAM services (exporting files). This means JSON or similar is likely the best option. This solution would also require custom importers and exporters to be made for each DAM service to allow full flexibility. The exporter would need to be able to sync with the universal database. Creating this kind of solution would be difficult and I would like to avoid this if possible. Not to mention if your DAM uses machine learning and likely uses vector databases which would be kinda hard to integrate into JSON.\n\nMy question is if there any tools or standards that accomplish this without needing to create this on my own. Are there existing open source self hosted services that meet this kind of flexibility? Is there an existing standard on what file data there is?\n\nAny help is appreciated. Please feel free to recommend DAMs as I am also looking for better services. [Hydrus Network](https://github.com/hydrusnetwork/hydrus) is currently my overall choice. If you want to look at criteria that some others have for robust DAMs, [this](https://softwarerecs.stackexchange.com/questions/47756/digital-asset-management-for-photography) is a good post.\n\n**TLDR**: Are there any open source &amp; self hosted Digital Asset Management services that allow for true flexibility (i.e. switching DAM services or for storing different kinds of metadata)? Are there any standards to know how to flexibly store files like I've talked about?", "author_fullname": "t2_hokshzbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted File Data Storage Solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lsh46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have many thousands of files that I am looking to manage, and I am looking for a service to help me manage them.&lt;/p&gt;\n\n&lt;p&gt;In order to help clarify what I am asking for, I&amp;#39;ll explain the problem in more detail. There are three steps associated with adding to this collection:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Collection&lt;/strong&gt;: This involves the act of collecting the files, which could include downloading them, creating them, or finding them offline.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: How are the files stored? What data is stored alongside them? Note that self hosted data is a required option.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Management&lt;/strong&gt;: Once the files and associated data are stored, how can you manage them? A self hosted service would be ideal.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There exist many solutions for the Storage &amp;amp; Management steps, including OS built-in tools such as Windows File Explorer. These solutions are usually called &lt;em&gt;Digital Asset Management&lt;/em&gt; (DAM) Services.&lt;/p&gt;\n\n&lt;p&gt;There also of course exist many separate solutions for the Collection step, such as web scraping tools like &lt;a href=\"https://github.com/mikf/gallery-dl\"&gt;Gallery-DL&lt;/a&gt; or &lt;a href=\"https://github.com/yt-dlp/yt-dlp\"&gt;yt-dlp&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, as many of you probably have encountered, it can be difficult to find solutions that work together well. Even if you do find one that works, it often heavily limits your flexibility.&lt;/p&gt;\n\n&lt;p&gt;For example, say you want to incorporate tags as metadata associated with files for querying purposes. Many DAM services allow this functionality, but what happens if you suddenly want to switch DAM services? It may become remarkably difficult if the tags are stored in a confusing proprietary database that you&amp;#39;ll have to parse through to get the metadata back out. Or what if you have tags that you parsed using a web scraping tool that you want to import? Some DAM services don&amp;#39;t easily allow this and don&amp;#39;t let you automate it (no API or access to the database),  and as such you may find yourself going through the process of either automating the input yourself or manually inputting each tag (yikes). What if you also have files from different data streams such as some parsed from online and some from offline? You would have to put it all into the DAM and forget about any different metadata those files might have. Forget about having a local copy you can look through as well in most cases. Many DAMs also don&amp;#39;t support some file types.&lt;/p&gt;\n\n&lt;p&gt;There are also issues associated with functionality such as tagging. There is no universally accepted standard for what tags exist and what format they should be in. The closest I&amp;#39;ve found is the &lt;a href=\"https://hydrusnetwork.github.io/hydrus/PTR.html\"&gt;Public Tag Repository&lt;/a&gt; or &lt;a href=\"https://danbooru.donmai.us/tags\"&gt;Danbooru&amp;#39;s Tags (NSFW)&lt;/a&gt;. Note that the PTR is probably the closest as I cannot find a way to have access to Danbooru&amp;#39;s tag database. Its database is also a nightmare with around 64 tables in their database and everything in SQL which requires a migration to change the schema of.&lt;/p&gt;\n\n&lt;p&gt;As such, if you want true flexibility you have to find a way to separate the steps and be able to interchange the solutions you use for each. For collection, you should be able to use any method and scrapers that you want. For storage, files need to be stored in a universally accepted way along with their metadata that is stored either in an associated file or a database. Lastly, the management software needs to be completely separate, meaning you can switch DAMs as you please simply through importing and exporting your data. If you make a change to a file in a DAM service, it needs to be reflected in your storage solution.&lt;/p&gt;\n\n&lt;p&gt;Note that there are solutions that try to cover all three steps, such as &lt;a href=\"https://github.com/hydrusnetwork/hydrus\"&gt;Hydrus Network&lt;/a&gt; which is a robust solution that acts as a DAM and also as a downloader with users being able to make custom downloaders. However, I&amp;#39;ve found myself using different downloaders for unsupported sites and struggling to find a way to automate the importing of tags. It also gets difficult when the biggest community made downloaders (e.g. for Danbooru) do not parse everything you want. It also does not support all of the functionalities that someone may want such as easily seeing file children/parents/siblings.&lt;/p&gt;\n\n&lt;p&gt;The only real solution I can think of for this is to store files in a universal file system (simple hierarchical file system such as exFAT) and to store metadata associated with each file&amp;#39;s hash in a database that can be flexibly updated to reflect data stored or created in DAM services (exporting files). This means JSON or similar is likely the best option. This solution would also require custom importers and exporters to be made for each DAM service to allow full flexibility. The exporter would need to be able to sync with the universal database. Creating this kind of solution would be difficult and I would like to avoid this if possible. Not to mention if your DAM uses machine learning and likely uses vector databases which would be kinda hard to integrate into JSON.&lt;/p&gt;\n\n&lt;p&gt;My question is if there any tools or standards that accomplish this without needing to create this on my own. Are there existing open source self hosted services that meet this kind of flexibility? Is there an existing standard on what file data there is?&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated. Please feel free to recommend DAMs as I am also looking for better services. &lt;a href=\"https://github.com/hydrusnetwork/hydrus\"&gt;Hydrus Network&lt;/a&gt; is currently my overall choice. If you want to look at criteria that some others have for robust DAMs, &lt;a href=\"https://softwarerecs.stackexchange.com/questions/47756/digital-asset-management-for-photography\"&gt;this&lt;/a&gt; is a good post.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: Are there any open source &amp;amp; self hosted Digital Asset Management services that allow for true flexibility (i.e. switching DAM services or for storing different kinds of metadata)? Are there any standards to know how to flexibly store files like I&amp;#39;ve talked about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?auto=webp&amp;s=e78fa80304b5763bf37ca051e074d40874a13fa0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1181317028bb06cfcedc7db9abfc8d9e4c36576d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=657a4e222f279cd70b47740c49056ff80ba58e87", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fac1fcccba27ea310251950037cd6105485ab509", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=687e01e79c42e341989a31ac6fda4fedf9ba2bd6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c50a8dbad55659e2332d488e5e0ad672e8972a9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e18be8f18cda2b3ce39832f7af86937eddd46417", "width": 1080, "height": 540}], "variants": {}, "id": "NWU29wfBXVE-3lY-1uWtRELB8zJVlEUbK8C7H2XBik8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lsh46", "is_robot_indexable": true, "report_reasons": null, "author": "Estavenz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lsh46/selfhosted_file_data_storage_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lsh46/selfhosted_file_data_storage_solution/", "subreddit_subscribers": 719300, "created_utc": 1702957968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello peeps, got a quick query as someone who knows little to nothing about storage and just needs something to put all my shit onto and free some space on my laptop, mainly large YouTube video files lol \n\nI'm currently looking at two options, the Seagate One Touch line or the Western Digital My Passports. The Seagate being a slightly better option (5TB for \u00a3125) with the Western Digital being 4TB for \u00a3108\n\nI've heard some pretty iffy stuff about Western Digital, like they're basically unusable as a running drive (which sounds like I'll need it to be if I'm editing clips saved to the drive in an editor) and that some people have had catastrophic data loss. So any advice on which is more reliable would be great\n\nMost likely it'll just sit at my desk but in the case I do need to travel with it, would I be better off with an SSD or HDD? \n\n Many thanks", "author_fullname": "t2_37lr9qp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on portable storage - SSD or HDD Seagate/WD portable drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lr7d4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702954106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello peeps, got a quick query as someone who knows little to nothing about storage and just needs something to put all my shit onto and free some space on my laptop, mainly large YouTube video files lol &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at two options, the Seagate One Touch line or the Western Digital My Passports. The Seagate being a slightly better option (5TB for \u00a3125) with the Western Digital being 4TB for \u00a3108&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard some pretty iffy stuff about Western Digital, like they&amp;#39;re basically unusable as a running drive (which sounds like I&amp;#39;ll need it to be if I&amp;#39;m editing clips saved to the drive in an editor) and that some people have had catastrophic data loss. So any advice on which is more reliable would be great&lt;/p&gt;\n\n&lt;p&gt;Most likely it&amp;#39;ll just sit at my desk but in the case I do need to travel with it, would I be better off with an SSD or HDD? &lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lr7d4", "is_robot_indexable": true, "report_reasons": null, "author": "RipCurl69Reddit", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lr7d4/advice_on_portable_storage_ssd_or_hdd_seagatewd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lr7d4/advice_on_portable_storage_ssd_or_hdd_seagatewd/", "subreddit_subscribers": 719300, "created_utc": 1702954106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for the gound zero explanation of how to connect SSDs and HDDs into this [W680D4U-2L2T/G5](https://www.asrockrack.com/general/productdetail.asp?Model=W680D4U-2L2T%2FG5#Specifications) motherboard to see if it would be a reasonable alternative to popular ASUS Pro WS W680-ACE. I don't really understand OCuLink and I'm having a lot of trouble finding accessible explanations. \n\n The OCuLink ports on the board are labeled:\n\n* A: OCuLink (PCIe4.0 x4) \\[CPU\\] (shares lane with PCIe 4.0x4 slot)\n* B: OCuLink (PCIe4.0 x4 or 4 SATA 6Gb/s) \\[PCH\\]\n* C/D:  2 OCuLink (PCIe4.0 x4) \\[PCH\\] \n\nFirst of all, is there a chart of the SFF/oculink/slimsas connectors [similar to this one for USB](https://res.cloudinary.com/rspoc/image/upload/f_auto/q_auto/v1543497710/L8950515-01.jpg)? How do I tell if an oculink port or cable is 4i or 8i?\n\nok back to the motherboard. The HDD QVL lists only 2.5\" U.3 and M.2 2280 drives as being officially validated. I guess that means that I would need either an oculink/u.3 backplane or a oculink to u.3 cable like this one  [PCIe Gen 4 OCulink (SFF-8611) to U.3 (SFF-8639) Cable 150cm (microsatacables.com)](https://www.microsatacables.com/pcie-gen-4-oculink-sff-8611-to-u-3-sff-8639-cable-150cm) to connect a single drive, with no driver board in between?\n\nI would be fine paying SATA drive prices and connecting SATA3 SSDs and HDDs to this board - preferably even with something like the IcyDock [MB998IP-B](https://global.icydock.com/product_169.html) (2x miniSAS ports on back) or [MB998SP-B](https://global.icydock.com/product_167.html) (8x sata ports on back). Do I need something like an HBA, or can I just get a cable like this:  [Supermicro CBL-SAST-0933 50cm OCuLink SFF-8611 (x4) to 4 SATA Cable](https://store.supermicro.com/us_en/supermicro-50cm-oculink-to-4-sata-cable-cbl-sast-0933.html)? In either case, would I be able to use *any* of the OCuLink ports on the motherboard, or *only* the port B, which indicates that it also does SATA? \n\nCan I get this  [Mini SAS SFF-8643 To SFF-8611 Oculink Cable (microsatacables.com)](https://www.microsatacables.com/mini-sas-sff-8643-to-sff-8611-oculink-cable-rml42-0501)  cable, plug it into one of the *other* OCuLink ports (i.e., A, C, or D) and then use SATA SSDs in the ICYDock MB998IP-B?\n\nThe motherboard has just one m.2 slot. if I want to add another, do I have to use something like this card  [Innocard Oculink (SFf-8612) to M.2 NVMe SSD Adapter with Oculink (SFF-8611) to Mini SAS HD (SFF-8643) Cable - Newegg.com](https://www.newegg.com/p/0Y3-00M7-000D1) ? Same question as before, does it matter which port I plug it into?\n\nif I wanted all four OCuLink ports to split into 4 SATA ports for a total of 16, is that possible? I don't need any hardware raid because I'll be using ZFS. ", "author_fullname": "t2_4yuut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5 How do I plug drives into this (OCuLink) motherboard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lqnsv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702952505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for the gound zero explanation of how to connect SSDs and HDDs into this &lt;a href=\"https://www.asrockrack.com/general/productdetail.asp?Model=W680D4U-2L2T%2FG5#Specifications\"&gt;W680D4U-2L2T/G5&lt;/a&gt; motherboard to see if it would be a reasonable alternative to popular ASUS Pro WS W680-ACE. I don&amp;#39;t really understand OCuLink and I&amp;#39;m having a lot of trouble finding accessible explanations. &lt;/p&gt;\n\n&lt;p&gt;The OCuLink ports on the board are labeled:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A: OCuLink (PCIe4.0 x4) [CPU] (shares lane with PCIe 4.0x4 slot)&lt;/li&gt;\n&lt;li&gt;B: OCuLink (PCIe4.0 x4 or 4 SATA 6Gb/s) [PCH]&lt;/li&gt;\n&lt;li&gt;C/D:  2 OCuLink (PCIe4.0 x4) [PCH] &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;First of all, is there a chart of the SFF/oculink/slimsas connectors &lt;a href=\"https://res.cloudinary.com/rspoc/image/upload/f_auto/q_auto/v1543497710/L8950515-01.jpg\"&gt;similar to this one for USB&lt;/a&gt;? How do I tell if an oculink port or cable is 4i or 8i?&lt;/p&gt;\n\n&lt;p&gt;ok back to the motherboard. The HDD QVL lists only 2.5&amp;quot; U.3 and M.2 2280 drives as being officially validated. I guess that means that I would need either an oculink/u.3 backplane or a oculink to u.3 cable like this one  &lt;a href=\"https://www.microsatacables.com/pcie-gen-4-oculink-sff-8611-to-u-3-sff-8639-cable-150cm\"&gt;PCIe Gen 4 OCulink (SFF-8611) to U.3 (SFF-8639) Cable 150cm (microsatacables.com)&lt;/a&gt; to connect a single drive, with no driver board in between?&lt;/p&gt;\n\n&lt;p&gt;I would be fine paying SATA drive prices and connecting SATA3 SSDs and HDDs to this board - preferably even with something like the IcyDock &lt;a href=\"https://global.icydock.com/product_169.html\"&gt;MB998IP-B&lt;/a&gt; (2x miniSAS ports on back) or &lt;a href=\"https://global.icydock.com/product_167.html\"&gt;MB998SP-B&lt;/a&gt; (8x sata ports on back). Do I need something like an HBA, or can I just get a cable like this:  &lt;a href=\"https://store.supermicro.com/us_en/supermicro-50cm-oculink-to-4-sata-cable-cbl-sast-0933.html\"&gt;Supermicro CBL-SAST-0933 50cm OCuLink SFF-8611 (x4) to 4 SATA Cable&lt;/a&gt;? In either case, would I be able to use &lt;em&gt;any&lt;/em&gt; of the OCuLink ports on the motherboard, or &lt;em&gt;only&lt;/em&gt; the port B, which indicates that it also does SATA? &lt;/p&gt;\n\n&lt;p&gt;Can I get this  &lt;a href=\"https://www.microsatacables.com/mini-sas-sff-8643-to-sff-8611-oculink-cable-rml42-0501\"&gt;Mini SAS SFF-8643 To SFF-8611 Oculink Cable (microsatacables.com)&lt;/a&gt;  cable, plug it into one of the &lt;em&gt;other&lt;/em&gt; OCuLink ports (i.e., A, C, or D) and then use SATA SSDs in the ICYDock MB998IP-B?&lt;/p&gt;\n\n&lt;p&gt;The motherboard has just one m.2 slot. if I want to add another, do I have to use something like this card  &lt;a href=\"https://www.newegg.com/p/0Y3-00M7-000D1\"&gt;Innocard Oculink (SFf-8612) to M.2 NVMe SSD Adapter with Oculink (SFF-8611) to Mini SAS HD (SFF-8643) Cable - Newegg.com&lt;/a&gt; ? Same question as before, does it matter which port I plug it into?&lt;/p&gt;\n\n&lt;p&gt;if I wanted all four OCuLink ports to split into 4 SATA ports for a total of 16, is that possible? I don&amp;#39;t need any hardware raid because I&amp;#39;ll be using ZFS. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?auto=webp&amp;s=65133492208d5e8509f8773645ec2598e42be07a", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=68f9434593a55a693236fd99a8f452d87b1b6db3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf3aad54f7e608f89e8c34ed39b063e6f2cdc660", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=32ae02d9f965d3fc8a1a3ac91376dd2e5ebf419d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=998d32a6e91106d6f611bb897553f51fdc948235", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f533ff689dcd15a2614f6c83e1da102978c9b491", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cac3f026c8eec1c08d578ae314ce273496ecaed", "width": 1080, "height": 1080}], "variants": {}, "id": "g5RkO4dPvHrIZnKb9kkutHhjfDx6G0hDMUJOSMJizqI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lqnsv", "is_robot_indexable": true, "report_reasons": null, "author": "verticalfuzz", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lqnsv/eli5_how_do_i_plug_drives_into_this_oculink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lqnsv/eli5_how_do_i_plug_drives_into_this_oculink/", "subreddit_subscribers": 719300, "created_utc": 1702952505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a new 3.5\" internal hard drive and on Newegg I saw many 3rd party sellers which seem to be selling 'new' drives for quite less, compared to Amazon, etc. One particular seller that caught my eye is GoHardDrive. Initially I suspected they're probably selling refurbs as news, but their listings clearly indicate 'new'. Their website also mentions 'renewed' in some listing's titles but not in others. Anyone know what's the catch here ?\n\nSome examples from Newegg:\n\nSeagate Exos 10TB for $130 ($13/TB): https://www.newegg.com/seagate-enterprise-capacity-3-5-st10000nm0016-10tb/p/N82E16822178941\n\nSeagate Exos 10TB for $120 ($12/TB): https://www.newegg.com/seagate-exos-x10-st10000nm0126-10tb/p/1Z4-002P-022A9\n\nThese drives are being sold for higher prices elsewhere.", "author_fullname": "t2_slw4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are GoHardDrive 'new' drives so cheap ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mg63r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703029534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a new 3.5&amp;quot; internal hard drive and on Newegg I saw many 3rd party sellers which seem to be selling &amp;#39;new&amp;#39; drives for quite less, compared to Amazon, etc. One particular seller that caught my eye is GoHardDrive. Initially I suspected they&amp;#39;re probably selling refurbs as news, but their listings clearly indicate &amp;#39;new&amp;#39;. Their website also mentions &amp;#39;renewed&amp;#39; in some listing&amp;#39;s titles but not in others. Anyone know what&amp;#39;s the catch here ?&lt;/p&gt;\n\n&lt;p&gt;Some examples from Newegg:&lt;/p&gt;\n\n&lt;p&gt;Seagate Exos 10TB for $130 ($13/TB): &lt;a href=\"https://www.newegg.com/seagate-enterprise-capacity-3-5-st10000nm0016-10tb/p/N82E16822178941\"&gt;https://www.newegg.com/seagate-enterprise-capacity-3-5-st10000nm0016-10tb/p/N82E16822178941&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Seagate Exos 10TB for $120 ($12/TB): &lt;a href=\"https://www.newegg.com/seagate-exos-x10-st10000nm0126-10tb/p/1Z4-002P-022A9\"&gt;https://www.newegg.com/seagate-exos-x10-st10000nm0126-10tb/p/1Z4-002P-022A9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;These drives are being sold for higher prices elsewhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18mg63r", "is_robot_indexable": true, "report_reasons": null, "author": "ahmadka", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mg63r/why_are_goharddrive_new_drives_so_cheap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mg63r/why_are_goharddrive_new_drives_so_cheap/", "subreddit_subscribers": 719300, "created_utc": 1703029534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've debated about getting a NAS or DAS for a while. All my drives are in my PC and it lives under my desk. It's all backed up manually and it works. I'm very reluctant to change this.\n\nBut it's noisy.\n\nIf I get a NAS/DAS and use it in JBOD, a bit of poking around online suggests the drive will be wiped. Is this really correct? For RAID, understandable, but for JBOD?\n\nAnd secondly, from people's experience with NAS/DAS, do the drives spin down and stay spun down. The ones in my PC spin down but not for long and is one of the reasons for the noise.", "author_fullname": "t2_183x1jsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Two questions regarding NAS/DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m15i9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702990241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve debated about getting a NAS or DAS for a while. All my drives are in my PC and it lives under my desk. It&amp;#39;s all backed up manually and it works. I&amp;#39;m very reluctant to change this.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s noisy.&lt;/p&gt;\n\n&lt;p&gt;If I get a NAS/DAS and use it in JBOD, a bit of poking around online suggests the drive will be wiped. Is this really correct? For RAID, understandable, but for JBOD?&lt;/p&gt;\n\n&lt;p&gt;And secondly, from people&amp;#39;s experience with NAS/DAS, do the drives spin down and stay spun down. The ones in my PC spin down but not for long and is one of the reasons for the noise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m15i9", "is_robot_indexable": true, "report_reasons": null, "author": "i_enjoy_silence", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m15i9/two_questions_regarding_nasdas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m15i9/two_questions_regarding_nasdas/", "subreddit_subscribers": 719300, "created_utc": 1702990241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone here working in IT and cybersecurity fields?\n\nWhat do you do with all network logs? How do you store them and for what purpose?", "author_fullname": "t2_550qnqr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cybersecurity and logs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lx2b3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702974414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here working in IT and cybersecurity fields?&lt;/p&gt;\n\n&lt;p&gt;What do you do with all network logs? How do you store them and for what purpose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18lx2b3", "is_robot_indexable": true, "report_reasons": null, "author": "masterphd2020", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lx2b3/cybersecurity_and_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lx2b3/cybersecurity_and_logs/", "subreddit_subscribers": 719300, "created_utc": 1702974414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. I am trying to think of a solution for migrating away from Windows because I'm finally no longer locked into their ecosystem. Right now I'm running a hardware raid solution that has 160tb usable and 130 used. I want to get away from Windows but currently the filesystem for the array is GPT with NTFS. I don't really have a good reason to swap out the drives anytime soon so I was hoping to just backup the data. Is there some solution, maybe an in person option in the Amsterdam area where I could pay to backup the files for a few days? Or is there an alternative I haven't considered? \n\nI had considered something along the lines of shrinking the partiton size, making a new partition in the empty space, copying the data over, then rinse and repeate. But I was considering using zfs with an hba in the new setup instead of a hardware raid card, so I couldn't do that stepwise. But maybe it makes more sense to try this solution in the short term until I need to upgrade again?", "author_fullname": "t2_15kbxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to change file systems without loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lutuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702965589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I am trying to think of a solution for migrating away from Windows because I&amp;#39;m finally no longer locked into their ecosystem. Right now I&amp;#39;m running a hardware raid solution that has 160tb usable and 130 used. I want to get away from Windows but currently the filesystem for the array is GPT with NTFS. I don&amp;#39;t really have a good reason to swap out the drives anytime soon so I was hoping to just backup the data. Is there some solution, maybe an in person option in the Amsterdam area where I could pay to backup the files for a few days? Or is there an alternative I haven&amp;#39;t considered? &lt;/p&gt;\n\n&lt;p&gt;I had considered something along the lines of shrinking the partiton size, making a new partition in the empty space, copying the data over, then rinse and repeate. But I was considering using zfs with an hba in the new setup instead of a hardware raid card, so I couldn&amp;#39;t do that stepwise. But maybe it makes more sense to try this solution in the short term until I need to upgrade again?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lutuc", "is_robot_indexable": true, "report_reasons": null, "author": "ShrodingersElephant", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lutuc/best_way_to_change_file_systems_without_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lutuc/best_way_to_change_file_systems_without_loss/", "subreddit_subscribers": 719300, "created_utc": 1702965589.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}