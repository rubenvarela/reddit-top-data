{"kind": "Listing", "data": {"after": "t3_18me2df", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throwaway because I know they are sometime on Reddit.\n\nMy boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.\n\nIt ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:\n\n- checking the SQL queries of my colleagues;\n- they want to know if this or that has been documented for tiny operations;\n- they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time\n\nI am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.\n\nThis is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?", "author_fullname": "t2_qa5f09pa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non-technical boss, wanting to micromanage and kills our team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m4e2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702999366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throwaway because I know they are sometime on Reddit.&lt;/p&gt;\n\n&lt;p&gt;My boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.&lt;/p&gt;\n\n&lt;p&gt;It ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;checking the SQL queries of my colleagues;&lt;/li&gt;\n&lt;li&gt;they want to know if this or that has been documented for tiny operations;&lt;/li&gt;\n&lt;li&gt;they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.&lt;/p&gt;\n\n&lt;p&gt;This is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18m4e2i", "is_robot_indexable": true, "report_reasons": null, "author": "SuperMarioDataGalaxy", "discussion_type": null, "num_comments": 54, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "subreddit_subscribers": 147087, "created_utc": 1702999366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked at a company for 4 years after 6 months I stopped opening outlook.\n\nSimply put if it doesn't happen in jira it never happened, I've been so hard on this the rest of my team followed. PM SM and PO were all but hurt now they look at my tickets and are like oh ok I'll check tomorrow.\n\nI put everything in my tickets from git commits, call recordings, results, error codes. I've done this to the point I'm smooth brained when asked questions on the ticket my answer is always what do the comments say?\n\nAnyone else make their communication funnelled through on channel?", "author_fullname": "t2_vtm8z2o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you read emails?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18migud", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703036186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked at a company for 4 years after 6 months I stopped opening outlook.&lt;/p&gt;\n\n&lt;p&gt;Simply put if it doesn&amp;#39;t happen in jira it never happened, I&amp;#39;ve been so hard on this the rest of my team followed. PM SM and PO were all but hurt now they look at my tickets and are like oh ok I&amp;#39;ll check tomorrow.&lt;/p&gt;\n\n&lt;p&gt;I put everything in my tickets from git commits, call recordings, results, error codes. I&amp;#39;ve done this to the point I&amp;#39;m smooth brained when asked questions on the ticket my answer is always what do the comments say?&lt;/p&gt;\n\n&lt;p&gt;Anyone else make their communication funnelled through on channel?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18migud", "is_robot_indexable": true, "report_reasons": null, "author": "Action_Maxim", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18migud/do_you_read_emails/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18migud/do_you_read_emails/", "subreddit_subscribers": 147087, "created_utc": 1703036186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sys-admin and fiddled around with python and just discoverd datasets.\n\nHow awesome is that stuff?! I was flashed.\n\nKnowing about datasets etc would have saved me \\_so\\_ much time back when i started my career, it is hilarious.\n\nI guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! \n\n&amp;#x200B;", "author_fullname": "t2_14rai9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I discoverd datasets in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m5gxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703002123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sys-admin and fiddled around with python and just discoverd datasets.&lt;/p&gt;\n\n&lt;p&gt;How awesome is that stuff?! I was flashed.&lt;/p&gt;\n\n&lt;p&gt;Knowing about datasets etc would have saved me _so_ much time back when i started my career, it is hilarious.&lt;/p&gt;\n\n&lt;p&gt;I guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m5gxj", "is_robot_indexable": true, "report_reasons": null, "author": "toast_one", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "subreddit_subscribers": 147087, "created_utc": 1703002123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am looking to switch my career and move into DE. \n\nI've only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. \n\nThere's still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.\n\nWhat are some red flags that when you see in a job offer you're like \"This company has no structure / it needs three different people for that role / etc.\"?\n\nI am looking for ways to weed out those offers that I shouldn't be using as a baseline for gathering my skills.\n\nThanks.", "author_fullname": "t2_7xz6r2in", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Red flags in DE job offers (beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m14z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702990200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking to switch my career and move into DE. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.&lt;/p&gt;\n\n&lt;p&gt;What are some red flags that when you see in a job offer you&amp;#39;re like &amp;quot;This company has no structure / it needs three different people for that role / etc.&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;I am looking for ways to weed out those offers that I shouldn&amp;#39;t be using as a baseline for gathering my skills.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18m14z5", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent-Drink-235", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "subreddit_subscribers": 147087, "created_utc": 1702990200.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the holidays approach, why not use some of your downtime to dive into a quick and practical data engineering project? This [GitHub repo](https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_airflow_bigquery) offers a chance to see Airbyte, Airflow and dbt in action, working together!\n\nIn less than an hour, you can have a full-fledged data stack to extract e-commerce data and transform it in BigQuery (or any other data warehouse, with a few tweaks). All instructions are in the README. \n\nDesigned for busy professionals and curious learners, this project offers a straightforward but extendable structure.\n\nI hope you will enjoy it! Let me know how it goes and where it can be improved. \n\nDisclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help my fellow engineers experiment and learn.\n\n[End to end DAG](https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5)\n\n[dbt DAG](https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;format=png&amp;auto=webp&amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3)", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Airbyte, Airflow &amp; dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tcs1jwcfxa7c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4585fe4ef43dcf2fa137993774b3cb9e720c6ba0"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cabddcb7e42993c86645282df39f9066d8b929c6"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f88310d9cdda18f566eb7130b55e4f0ab9ef94a6"}, {"y": 326, "x": 640, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f0a419d349035775e01c7d76249bb0d2b0db8a5"}, {"y": 489, "x": 960, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a7223b8f338131b21d49cc04d832e1b01291cd6"}, {"y": 550, "x": 1080, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a5ddf6342374db4be5144b2abdffd5a3eb57f1c"}], "s": {"y": 958, "x": 1880, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;format=png&amp;auto=webp&amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3"}, "id": "tcs1jwcfxa7c1"}, "w1tbxns9xa7c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d1c10ac0a94930899a0a889cdbbe6061d33e325"}, {"y": 64, "x": 216, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=50e1cf2e63a1a49effb7d64e19897b9a6d81abba"}, {"y": 95, "x": 320, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bf1aba786f9c8d4d29c95149a4db6572e64bfd4"}, {"y": 190, "x": 640, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cd409b30e35cefac56645a0c71d9b8c01120d92"}, {"y": 285, "x": 960, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6142356bda8e7b2549dbabdd8ee9439cfc66aadd"}, {"y": 320, "x": 1080, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5690b2f5a07fdd12cfc7ffbd5ba1b9eba22e5259"}], "s": {"y": 402, "x": 1354, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5"}, "id": "w1tbxns9xa7c1"}}, "name": "t3_18m9yto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pouf7O2bHswW7FoCfoyalXWgbHN4PalGFB7Cl00vhmU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1703013525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the holidays approach, why not use some of your downtime to dive into a quick and practical data engineering project? This &lt;a href=\"https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_airflow_bigquery\"&gt;GitHub repo&lt;/a&gt; offers a chance to see Airbyte, Airflow and dbt in action, working together!&lt;/p&gt;\n\n&lt;p&gt;In less than an hour, you can have a full-fledged data stack to extract e-commerce data and transform it in BigQuery (or any other data warehouse, with a few tweaks). All instructions are in the README. &lt;/p&gt;\n\n&lt;p&gt;Designed for busy professionals and curious learners, this project offers a straightforward but extendable structure.&lt;/p&gt;\n\n&lt;p&gt;I hope you will enjoy it! Let me know how it goes and where it can be improved. &lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help my fellow engineers experiment and learn.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5\"&gt;End to end DAG&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3\"&gt;dbt DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?auto=webp&amp;s=2d1bd7ee7e1dacb5ae59ebe4b6a52937118c7eba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4cb3cab32bb4c0377c3bcf465b03a307fae1425", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba542763a1b4351acd1002befba883881db3e31d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31c1718d22be0d9ff790a87a2afd179b8bfb5e5c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b0294daefa0204451abb6e8f3a147d06c940bf2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6cc981f415ac4f15bdb8e3e431a9d34156ab5824", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bea4b583e75edfc9b379e33c725391509e474d0", "width": 1080, "height": 540}], "variants": {}, "id": "TcgpYk8BJNd4uAgmGeO3-7znAtRUmIi5C-Abf1OarDE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18m9yto", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18m9yto/integrating_airbyte_airflow_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m9yto/integrating_airbyte_airflow_dbt/", "subreddit_subscribers": 147087, "created_utc": 1703013525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New video \ud83e\udd73 What's new in Apache Airflow 2.8?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18m30x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18m30x1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W9gW-x75UmKzyC9I0b799PZ2OnmHhIBK7_zD9y5N684.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702995743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/M9qyj5Dszks", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?auto=webp&amp;s=14111aa6adfeb2c33ce6f5e60e93b26adf640e3d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4cfe605ca8eda8a8d053c6cebb0db4699467a79", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2161187bfb9511953e9b866e0bcbd6fd0319ee77", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e1acd7c824946fbb87246bb66219af8fd5f6d8", "width": 320, "height": 240}], "variants": {}, "id": "Sn7V-8gShoAirVVII0LH7BwleF0omtwue3ruXwusF2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18m30x1", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m30x1/new_video_whats_new_in_apache_airflow_28/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/M9qyj5Dszks", "subreddit_subscribers": 147087, "created_utc": 1702995743.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recap of 2023's Transformative Data Landscape", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_18luokv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QC-u87qQqiWYhhkIC7zp7h8awQeZx1F8z1WVloZ5my4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702965072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?auto=webp&amp;s=05cf70f29567b297be9005cc1fe6c52634c548d1", "width": 852, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8235b4ab19fc2ff32de42dcad115918f2e142ea", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac56b2d2c72cfcf52f1d78a8b06cc0971bef6d20", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d507577ef1336581efee9304ad98a549d20d63fe", "width": 320, "height": 225}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e89944c98598044365a90f48cd565f877fa7541c", "width": 640, "height": 450}], "variants": {}, "id": "bU0KynVYqdS53QNQHO7TTIr2Kuty1FCLaOXHnUOQcI0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18luokv", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18luokv/recap_of_2023s_transformative_data_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "subreddit_subscribers": 147087, "created_utc": 1702965072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5ud8qz3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Netflix Data Engineering Summit videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "name": "t3_18mactq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sSDLo57eZMNIp1wzW5IoGguFiQ6_Ua87WD5lDt3x1Es.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703014490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "netflixtechblog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?auto=webp&amp;s=5c559c3b17160025d56491777d567987248931ef", "width": 1111, "height": 571}, "resolutions": [{"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da24254e4bb038691cfdd4c156a5d5244c08c4bf", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=052f735a1ffa64a0e1d6d51c639439521a6f2004", "width": 216, "height": 111}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d0fc2cebd67c1385fae0b1324dc39348b3217f8", "width": 320, "height": 164}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc32a3e086f0217c8aa2eab757773f562dea42d3", "width": 640, "height": 328}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=756a90ecc71cbca89abb9212b906435a9bd267bd", "width": 960, "height": 493}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b00bb639fe14e1acfb87b0939a9785a7a7e3c46", "width": 1080, "height": 555}], "variants": {}, "id": "TMo7-NZlAEt-Oth2MSgWHW_-6WCPBJ0hDscjjgNPtxU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18mactq", "is_robot_indexable": true, "report_reasons": null, "author": "limeslice2020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mactq/netflix_data_engineering_summit_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102", "subreddit_subscribers": 147087, "created_utc": 1703014490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?", "author_fullname": "t2_dxt8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting new records/changes: timestamp vs ingest I\u2019d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m00kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702986364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m00kd", "is_robot_indexable": true, "report_reasons": null, "author": "pokepip", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "subreddit_subscribers": 147087, "created_utc": 1702986364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why storage and compute can't be separated for an OLTP database?", "author_fullname": "t2_fulplt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLTP vs OLAP databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lyljw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702980821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why storage and compute can&amp;#39;t be separated for an OLTP database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lyljw", "is_robot_indexable": true, "report_reasons": null, "author": "ankit_goyal", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "subreddit_subscribers": 147087, "created_utc": 1702980821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expedia Uses WebSockets and Kafka to Query Near Real-Time Streaming Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18lz0me", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_-95beDt0eTU61sjw3MyytCoW7zyk-9mjFOz5cqSkbM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702982547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?auto=webp&amp;s=22be1127b3a032c0428d4bee24b8d2cb2a2233c0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74b528758f8dac132781b7ba52cec3194953941b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b5018e5a478380623b37087dbf9dc4b43bbf70c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1b372ee2d8ab5031fb9f92e22e20238371990e25", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec9e2d3c657a70106b4608c93841f75070af8d79", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3de9be364444c886057dff0f382a0ea14630cb01", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7820fff738d4f7d7dcf3a548b2e8c36161176b6", "width": 1080, "height": 567}], "variants": {}, "id": "BmdzDPEbzLW9dI8d-7eePz_SJf3gyF91hmqD-LM6Od4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18lz0me", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lz0me/expedia_uses_websockets_and_kafka_to_query_near/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "subreddit_subscribers": 147087, "created_utc": 1702982547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all! \n\nMy coworkers worked at Apple on the ML compute platform team and constantly found themselves supporting ML engineers with their large, distributed ML training jobs. ML engineers had to either use less data or they had to rewrite the training jobs to weave in more complicated *data chunking*. They also struggled to keep GPU utilization above 80% because so much time was spent waiting for data to just load: [https://discuss.pytorch.org/t/how-to-load-all-data-into-gpu-for-training/27609](https://discuss.pytorch.org/t/how-to-load-all-data-into-gpu-for-training/27609)\n\nInspired by the pains of that experience, they created an open source library for mounting large datasets inside Kubernetes.\n\nThis way, you can just:\n\n\\- Write &amp; iterate on ML code locally\n\n\\- Deploy the ML job in Kubernetes, mounting the relevant data repo / bucket in seconds\n\n\\- Watch the relevant rows &amp; columns get streamed into different pods just-in-time on an as-needed basis\n\nHere's a link to the short post, which includes a quick tutorial: [https://about.xethub.com/blog/mount-big-data-kubernetes-faster-ml](https://about.xethub.com/blog/mount-big-data-kubernetes-faster-ml)", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubernetes plugin for mounting datasets to speed up model training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mjeeg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703038930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all! &lt;/p&gt;\n\n&lt;p&gt;My coworkers worked at Apple on the ML compute platform team and constantly found themselves supporting ML engineers with their large, distributed ML training jobs. ML engineers had to either use less data or they had to rewrite the training jobs to weave in more complicated &lt;em&gt;data chunking&lt;/em&gt;. They also struggled to keep GPU utilization above 80% because so much time was spent waiting for data to just load: &lt;a href=\"https://discuss.pytorch.org/t/how-to-load-all-data-into-gpu-for-training/27609\"&gt;https://discuss.pytorch.org/t/how-to-load-all-data-into-gpu-for-training/27609&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Inspired by the pains of that experience, they created an open source library for mounting large datasets inside Kubernetes.&lt;/p&gt;\n\n&lt;p&gt;This way, you can just:&lt;/p&gt;\n\n&lt;p&gt;- Write &amp;amp; iterate on ML code locally&lt;/p&gt;\n\n&lt;p&gt;- Deploy the ML job in Kubernetes, mounting the relevant data repo / bucket in seconds&lt;/p&gt;\n\n&lt;p&gt;- Watch the relevant rows &amp;amp; columns get streamed into different pods just-in-time on an as-needed basis&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a link to the short post, which includes a quick tutorial: &lt;a href=\"https://about.xethub.com/blog/mount-big-data-kubernetes-faster-ml\"&gt;https://about.xethub.com/blog/mount-big-data-kubernetes-faster-ml&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KHj2qGPVOhORlWPtHBDXZOjIHZM34SUuxSeNZiO9S3w.jpg?auto=webp&amp;s=b51fbd9f71e54307e3bfafa18d55e4b68ec0bc73", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/KHj2qGPVOhORlWPtHBDXZOjIHZM34SUuxSeNZiO9S3w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=861db8795c84a790d30b3d83b8f7ddab69350f28", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/KHj2qGPVOhORlWPtHBDXZOjIHZM34SUuxSeNZiO9S3w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb24c82e2ebf94027915fc8df913769080417931", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/KHj2qGPVOhORlWPtHBDXZOjIHZM34SUuxSeNZiO9S3w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=940ff4a5a82304edbcfea1666d0cb6c7f35e45ac", "width": 320, "height": 320}], "variants": {}, "id": "0Ikyen85Ad70GrjpN1XA6-Ndv6dFXhI3YkPZAMyxafQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18mjeeg", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mjeeg/kubernetes_plugin_for_mounting_datasets_to_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mjeeg/kubernetes_plugin_for_mounting_datasets_to_speed/", "subreddit_subscribers": 147087, "created_utc": 1703038930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I do all the ETL for my BI team. I'd like to incorporate Python into my ETL process for learning purposes, but I'm not sure where to start. I have a lot of SQL experience but no programming experience.\n\nCurrent process:\n\n* All of our data comes from Azure SQL dbs and federal government APIs. \n\n\n* The data sourced from SQL dbs is ingested via SSIS packages. It is loaded into an on-prem staging database. I then transform and import the data into our reporting warehouse using stored procs and scheduled jobs.\n\n* The data sourced from APIs is ingested via ADF pipelines. Everything else is done just like the SQL pipeline -- I load it to a staging db and complete the transformation and loading with stored procs.\n\nIf you inherited this pipeline, how would you improve it using Python?\n\nThanks!", "author_fullname": "t2_emnkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a BI Developer wanting to transition to DE and have accepted it's time to learn Python. Based on my current workflow, where can I integrate it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18madbk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703014522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I do all the ETL for my BI team. I&amp;#39;d like to incorporate Python into my ETL process for learning purposes, but I&amp;#39;m not sure where to start. I have a lot of SQL experience but no programming experience.&lt;/p&gt;\n\n&lt;p&gt;Current process:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;All of our data comes from Azure SQL dbs and federal government APIs. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The data sourced from SQL dbs is ingested via SSIS packages. It is loaded into an on-prem staging database. I then transform and import the data into our reporting warehouse using stored procs and scheduled jobs.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The data sourced from APIs is ingested via ADF pipelines. Everything else is done just like the SQL pipeline -- I load it to a staging db and complete the transformation and loading with stored procs.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you inherited this pipeline, how would you improve it using Python?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18madbk", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward_Tick0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18madbk/im_a_bi_developer_wanting_to_transition_to_de_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18madbk/im_a_bi_developer_wanting_to_transition_to_de_and/", "subreddit_subscribers": 147087, "created_utc": 1703014522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some advice on best approach/ practise.\n\nBackground :\n\nIm a data analyst working in a team. Breakdown of our reporting flows are :\n\n1. We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.\n\nProblem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. \n\n2. We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. \n\nThis tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. \n\nAnd when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.\n\nSo the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? \n\nMy concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?\n\nAs for to just use no.2 approach, im not sure if pyspark can do exactly what we're doing in no.1 since we lack of the exposure. \n\nSorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.", "author_fullname": "t2_7nk0x7fc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m0x3c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703027106.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702989497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some advice on best approach/ practise.&lt;/p&gt;\n\n&lt;p&gt;Background :&lt;/p&gt;\n\n&lt;p&gt;Im a data analyst working in a team. Breakdown of our reporting flows are :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Problem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. &lt;/p&gt;\n\n&lt;p&gt;And when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.&lt;/p&gt;\n\n&lt;p&gt;So the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? &lt;/p&gt;\n\n&lt;p&gt;My concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?&lt;/p&gt;\n\n&lt;p&gt;As for to just use no.2 approach, im not sure if pyspark can do exactly what we&amp;#39;re doing in no.1 since we lack of the exposure. &lt;/p&gt;\n\n&lt;p&gt;Sorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m0x3c", "is_robot_indexable": true, "report_reasons": null, "author": "Nopal97", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m0x3c/advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m0x3c/advice_needed/", "subreddit_subscribers": 147087, "created_utc": 1702989497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a Data/Software developer. My boss recently told me we are switching our data warehouse to Snowflake from Sql Server.\n\nAnyone have experience with snowflake and share your thoughts?\n\nOur current DWH has a lot of fact and dimensional tables. We also run a lot of batch processes prior to having this data land in the warehouse. Im not fully sure how this will work with snowflake.\n\nLooking for opinions,thoughts, etc.", "author_fullname": "t2_5epqry7a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ml6ay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703044315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a Data/Software developer. My boss recently told me we are switching our data warehouse to Snowflake from Sql Server.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience with snowflake and share your thoughts?&lt;/p&gt;\n\n&lt;p&gt;Our current DWH has a lot of fact and dimensional tables. We also run a lot of batch processes prior to having this data land in the warehouse. Im not fully sure how this will work with snowflake.&lt;/p&gt;\n\n&lt;p&gt;Looking for opinions,thoughts, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ml6ay", "is_robot_indexable": true, "report_reasons": null, "author": "liskeeksil", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ml6ay/thoughts_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ml6ay/thoughts_on_snowflake/", "subreddit_subscribers": 147087, "created_utc": 1703044315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to move from a Microsoft SQL Analysis Service (Excel + SSRS) data stack to a modern data stack using Snowflake and Tableau. My data models are all star schemas and modeled directly in the cube(s).\n\nAs I reviewing how the modern data stack is typically deployed, I see that the data warehouse, like Snowflake, does not maintain a physical data model. It seems as though the data can be orchestrated in a normalized model and live in Snowflake, but my end user connecting Tableau to Snowflake will have to do their own modeling.\n\nIt seems as though a set of denormalized tables might be easier for end users to work with, but I fear the tables will be so wide and so large that they will not perform well.\n\nPerhaps I am missing something in terms of the structure, but how would an end user who isn't a savvy with SQL or truly understand JOINS go about building consistent and clear dashboards? \n\nDoes Tableau allow me to build an enterprise data model that all users can use so they can just drag and drop dimension attributes and metrics onto the page?", "author_fullname": "t2_nuco2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mkxxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703043590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to move from a Microsoft SQL Analysis Service (Excel + SSRS) data stack to a modern data stack using Snowflake and Tableau. My data models are all star schemas and modeled directly in the cube(s).&lt;/p&gt;\n\n&lt;p&gt;As I reviewing how the modern data stack is typically deployed, I see that the data warehouse, like Snowflake, does not maintain a physical data model. It seems as though the data can be orchestrated in a normalized model and live in Snowflake, but my end user connecting Tableau to Snowflake will have to do their own modeling.&lt;/p&gt;\n\n&lt;p&gt;It seems as though a set of denormalized tables might be easier for end users to work with, but I fear the tables will be so wide and so large that they will not perform well.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I am missing something in terms of the structure, but how would an end user who isn&amp;#39;t a savvy with SQL or truly understand JOINS go about building consistent and clear dashboards? &lt;/p&gt;\n\n&lt;p&gt;Does Tableau allow me to build an enterprise data model that all users can use so they can just drag and drop dimension attributes and metrics onto the page?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18mkxxj", "is_robot_indexable": true, "report_reasons": null, "author": "2000gt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mkxxj/data_modeling_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mkxxj/data_modeling_in_snowflake/", "subreddit_subscribers": 147087, "created_utc": 1703043590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp; Jesse Anderson \u2022 GOTO 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18mdpui", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/P-9FwZxO1zE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp;amp; Jesse Anderson \u2022 GOTO 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp; Jesse Anderson \u2022 GOTO 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/P-9FwZxO1zE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp;amp; Jesse Anderson \u2022 GOTO 2023\"&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/P-9FwZxO1zE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/P-9FwZxO1zE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp;amp; Jesse Anderson \u2022 GOTO 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18mdpui", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EG6dIjYfo7koB7YwHcHVp8yD3RXY4TPnkQbuGBMMe60.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703023012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/P-9FwZxO1zE?si=UxntLaaWAtmKBiY7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HmAUe332NFaRs9nHi_AaIW-hxIAsSR-MYRhh_jQSE5Y.jpg?auto=webp&amp;s=c893c1d8ac73658e95fcfa89af76635829a5f0a1", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HmAUe332NFaRs9nHi_AaIW-hxIAsSR-MYRhh_jQSE5Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99c4a68cc33ce73559ee7a00f579d49bdb5bf269", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HmAUe332NFaRs9nHi_AaIW-hxIAsSR-MYRhh_jQSE5Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4857927413c84daab0812d5b736443b5d601f28", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HmAUe332NFaRs9nHi_AaIW-hxIAsSR-MYRhh_jQSE5Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1cb2927d72da9e6d6353b49959f7508ba4c618c", "width": 320, "height": 240}], "variants": {}, "id": "tc09KFreOE8Z89GIDoJawxTXj4KExCL8ftOn_LgGEU8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18mdpui", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mdpui/designing_a_dataintensive_future_expert_talk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/P-9FwZxO1zE?si=UxntLaaWAtmKBiY7", "subreddit_subscribers": 147087, "created_utc": 1703023012.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp; Jesse Anderson \u2022 GOTO 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/P-9FwZxO1zE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Designing A Data-Intensive Future: Expert Talk \u2022 Martin Kleppmann &amp;amp; Jesse Anderson \u2022 GOTO 2023\"&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/P-9FwZxO1zE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title is pretty self-explanatory. \n\nAre y'all noticing recruiter emails coming to your work email ? I don't know how they got my work email into their HR or emailing systems ?! \n\nI'm interested but obvi can't reply from work email lol", "author_fullname": "t2_roct4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recruiters reaching out to you on your work email ? are these emails automated or hand-written ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m6ey9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703013326.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703004561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title is pretty self-explanatory. &lt;/p&gt;\n\n&lt;p&gt;Are y&amp;#39;all noticing recruiter emails coming to your work email ? I don&amp;#39;t know how they got my work email into their HR or emailing systems ?! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested but obvi can&amp;#39;t reply from work email lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6ey9", "is_robot_indexable": true, "report_reasons": null, "author": "dronedesigner", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "subreddit_subscribers": 147087, "created_utc": 1703004561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIam writing a snowflake stored procedure in python language.\n\nBelow is the sample code:\n\n    CREATE OR REPLACE PROCEDURE edw_dev.master.SampleSP(TABLENAMES ARRAY, ORDERBYCOLUMNS ARRAY DEFAULT NULL)\n    RETURNS STRING\n    LANGUAGE PYTHON\n    RUNTIME_VERSION = '3.8'\n    PACKAGES = ('snowflake-snowpark-python')\n    HANDLER = 'process_tables'\n    as\n    $$\n    def process_tables(snowpark_session, TABLENAMES, ORDERBYCOLUMNS):\n        \n                createTableSql = f'CREATE OR REPLACE TABLE {newTableName} LIKE {fullTableName}'\n    \n                snowpark_session.sql(createTableSql).collect()\n    \n    \n    \n    $$;\n\nI need to implement a lock using 'begin transaction' and 'commit' for a section inside my stored procedure. How can we do this in python snowflake stored proc?\n\nI don't see much detail about this in the documentation as it contains details for Snowflake scripting alone.\n\nHas anyone come across this? Appreciate your help in advance.!", "author_fullname": "t2_9fr6if3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help: Snowflake Python Stored procedure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2rg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702995008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Iam writing a snowflake stored procedure in python language.&lt;/p&gt;\n\n&lt;p&gt;Below is the sample code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE OR REPLACE PROCEDURE edw_dev.master.SampleSP(TABLENAMES ARRAY, ORDERBYCOLUMNS ARRAY DEFAULT NULL)\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = &amp;#39;3.8&amp;#39;\nPACKAGES = (&amp;#39;snowflake-snowpark-python&amp;#39;)\nHANDLER = &amp;#39;process_tables&amp;#39;\nas\n$$\ndef process_tables(snowpark_session, TABLENAMES, ORDERBYCOLUMNS):\n\n            createTableSql = f&amp;#39;CREATE OR REPLACE TABLE {newTableName} LIKE {fullTableName}&amp;#39;\n\n            snowpark_session.sql(createTableSql).collect()\n\n\n\n$$;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I need to implement a lock using &amp;#39;begin transaction&amp;#39; and &amp;#39;commit&amp;#39; for a section inside my stored procedure. How can we do this in python snowflake stored proc?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see much detail about this in the documentation as it contains details for Snowflake scripting alone.&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across this? Appreciate your help in advance.!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m2rg5", "is_robot_indexable": true, "report_reasons": null, "author": "aj_here_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m2rg5/help_snowflake_python_stored_procedure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m2rg5/help_snowflake_python_stored_procedure/", "subreddit_subscribers": 147087, "created_utc": 1702995008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m not a data engineer, am a BI analyst whos interested in becoming a DE, so currently I\u2019m trying to observe, ask questions, search\u2026 but I noticed it\u2019s really stressful job and there are a lot of things i need to learn and i feel overwhelmed. \n\nHow you guys dealing with this pressure and what strategies are you using to balance between doing work and continue learning and sharpening your skills?\n\nI also want to ask about how you learned DE and if you know a good source teaching the basics of DE for beginners. \nnote that I\u2019m a BI analyst for almost 3 years :)", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work pressure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lzawl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703013614.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702983685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not a data engineer, am a BI analyst whos interested in becoming a DE, so currently I\u2019m trying to observe, ask questions, search\u2026 but I noticed it\u2019s really stressful job and there are a lot of things i need to learn and i feel overwhelmed. &lt;/p&gt;\n\n&lt;p&gt;How you guys dealing with this pressure and what strategies are you using to balance between doing work and continue learning and sharpening your skills?&lt;/p&gt;\n\n&lt;p&gt;I also want to ask about how you learned DE and if you know a good source teaching the basics of DE for beginners. \nnote that I\u2019m a BI analyst for almost 3 years :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18lzawl", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lzawl/work_pressure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lzawl/work_pressure/", "subreddit_subscribers": 147087, "created_utc": 1702983685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know any good data modelling resources?\n\nBesides, the Kimball book or blog posts with super basic sales facts and dimensions, I'm struggling to find good resources to upskill my data modelling skills. I'm looking for resources that deep-dive into real-world use cases.\n\nI basically would like to be better at answering the questions: \"What is the best way to model those OLTP tables to answer those business analytical use cases?\"", "author_fullname": "t2_2joko4jg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good data modelling resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mmdlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703048190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know any good data modelling resources?&lt;/p&gt;\n\n&lt;p&gt;Besides, the Kimball book or blog posts with super basic sales facts and dimensions, I&amp;#39;m struggling to find good resources to upskill my data modelling skills. I&amp;#39;m looking for resources that deep-dive into real-world use cases.&lt;/p&gt;\n\n&lt;p&gt;I basically would like to be better at answering the questions: &amp;quot;What is the best way to model those OLTP tables to answer those business analytical use cases?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18mmdlx", "is_robot_indexable": true, "report_reasons": null, "author": "Alert_Dragonfly", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mmdlx/any_good_data_modelling_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mmdlx/any_good_data_modelling_resources/", "subreddit_subscribers": 147087, "created_utc": 1703048190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finished bootcamp last week and started applying for jobs but i noticed it is so hard to find entry job for data engineering and they ask for experience like a year sometimes. The question do you think the bootcamp i did was 3 month and the portfolio is enough to get data engineer job or i should try to go for something lower and if so i don't even know what is lower then make my way up to DE maybe like DE internship or data analyst \n\nMy portfolio now have \n*data pipeline on aws and connect to grafana\n*Have another cli python program that takes order, records couriers as well, recorder on file or mysql database either as you want.\n*And other projects such as like blackjack game\nSoduko solver\n*And machine learning project did in engineering degree used knime so i didn't use code to build it just interactive thingy.", "author_fullname": "t2_a3acnwor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on job hunt please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mjey4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703038975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finished bootcamp last week and started applying for jobs but i noticed it is so hard to find entry job for data engineering and they ask for experience like a year sometimes. The question do you think the bootcamp i did was 3 month and the portfolio is enough to get data engineer job or i should try to go for something lower and if so i don&amp;#39;t even know what is lower then make my way up to DE maybe like DE internship or data analyst &lt;/p&gt;\n\n&lt;p&gt;My portfolio now have \n*data pipeline on aws and connect to grafana\n*Have another cli python program that takes order, records couriers as well, recorder on file or mysql database either as you want.\n*And other projects such as like blackjack game\nSoduko solver\n*And machine learning project did in engineering degree used knime so i didn&amp;#39;t use code to build it just interactive thingy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18mjey4", "is_robot_indexable": true, "report_reasons": null, "author": "mahdy_mahmoud", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mjey4/advice_on_job_hunt_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mjey4/advice_on_job_hunt_please/", "subreddit_subscribers": 147087, "created_utc": 1703038975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry if this is an amateur question, I\u2019m not a data engineer, just an analyst that wears a lot of hats except analyzing data. \n\nCurrently we are evaluating how to develop better data processes as a lot of our work is done manually in Excel. We have a SAAS system we produce which does a lot of the calculations (industry specific data transformation software), but before ingesting the data into the system, the analyst must perform a bunch of transformations in Excel and perform a bunch of validations. We want to automate this.\n\nAt first I was leaning towards using SQL and Python if necessary. One of my managers is leading towards using Jedox, a BI tool (really a FP&amp;A tool). Using Jedox would have a lot of benefits, it will most likely be on me to build this, and I\u2019ve automated our reporting in Jedox, but haven\u2019t really built anything with Python or SQL before (at work), so I should be able to move quicker with Jedox. There is also the benefit that we could store aggregated data before processing, after processing, and then while reporting to make sure everything was processed correctly all in the same system. We also have all the security stuff figured out in Jedox, and could give analysts a front end where they could run their own data pipelines and get exports. Jedox also allows us to use Groovy scripting for more complex transformations, running jobs, setting variables, and all that stuff.\n\nThe validations are stuff like making sure no prices were sold below a certain listed price, specific ID\u2019s for specific types of sales are still active in another database, finding any value not contained various reference tables that needs to be added, validating certain amounts are calculated correctly, and so on. The transformations are basic and can be done in Excel. With some rare clients, we have to do weird stuff like consolidate pieces of data from PDF\u2019s to produce a file, but that\u2019s very rare. We are constantly adding new clients though, so this system will need to be able to work for all our clients.\n\nTo me it seems like Jedox could actually be really useful for this, but I know it generally goes against what the type of advice I see here where people generally don\u2019t recommend to use a BI tool for work like this. Is there anything wrong with taking this approach? ", "author_fullname": "t2_8e28mn79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it bad to use a BI tool for Data pre-processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mits6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703037237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is an amateur question, I\u2019m not a data engineer, just an analyst that wears a lot of hats except analyzing data. &lt;/p&gt;\n\n&lt;p&gt;Currently we are evaluating how to develop better data processes as a lot of our work is done manually in Excel. We have a SAAS system we produce which does a lot of the calculations (industry specific data transformation software), but before ingesting the data into the system, the analyst must perform a bunch of transformations in Excel and perform a bunch of validations. We want to automate this.&lt;/p&gt;\n\n&lt;p&gt;At first I was leaning towards using SQL and Python if necessary. One of my managers is leading towards using Jedox, a BI tool (really a FP&amp;amp;A tool). Using Jedox would have a lot of benefits, it will most likely be on me to build this, and I\u2019ve automated our reporting in Jedox, but haven\u2019t really built anything with Python or SQL before (at work), so I should be able to move quicker with Jedox. There is also the benefit that we could store aggregated data before processing, after processing, and then while reporting to make sure everything was processed correctly all in the same system. We also have all the security stuff figured out in Jedox, and could give analysts a front end where they could run their own data pipelines and get exports. Jedox also allows us to use Groovy scripting for more complex transformations, running jobs, setting variables, and all that stuff.&lt;/p&gt;\n\n&lt;p&gt;The validations are stuff like making sure no prices were sold below a certain listed price, specific ID\u2019s for specific types of sales are still active in another database, finding any value not contained various reference tables that needs to be added, validating certain amounts are calculated correctly, and so on. The transformations are basic and can be done in Excel. With some rare clients, we have to do weird stuff like consolidate pieces of data from PDF\u2019s to produce a file, but that\u2019s very rare. We are constantly adding new clients though, so this system will need to be able to work for all our clients.&lt;/p&gt;\n\n&lt;p&gt;To me it seems like Jedox could actually be really useful for this, but I know it generally goes against what the type of advice I see here where people generally don\u2019t recommend to use a BI tool for work like this. Is there anything wrong with taking this approach? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18mits6", "is_robot_indexable": true, "report_reasons": null, "author": "Icy-Big2472", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mits6/is_it_bad_to_use_a_bi_tool_for_data_preprocessing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mits6/is_it_bad_to_use_a_bi_tool_for_data_preprocessing/", "subreddit_subscribers": 147087, "created_utc": 1703037237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I created a YouTube channel focused on Python and mid to senior level software/data engineering topics. Please let me know what you think, I will be uploading frequently. Have a great day!!\n\n[https://www.youtube.com/watch?v=4crPt0OROQ0&amp;t=57s](https://www.youtube.com/watch?v=4crPt0OROQ0&amp;t=57s)", "author_fullname": "t2_qb2z2bsq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I started a Python YouTube channel, will be teaching mid/senior software &amp; data engineering topics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18mhebk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703033023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I created a YouTube channel focused on Python and mid to senior level software/data engineering topics. Please let me know what you think, I will be uploading frequently. Have a great day!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=4crPt0OROQ0&amp;amp;t=57s\"&gt;https://www.youtube.com/watch?v=4crPt0OROQ0&amp;amp;t=57s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5knoksiiHMrNwtkz3IzxnSr_JLA4z_HAlNDTc2pkZ2c.jpg?auto=webp&amp;s=631d80fe92f9e1c0e091e2478039eb86c3f8ad5d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/5knoksiiHMrNwtkz3IzxnSr_JLA4z_HAlNDTc2pkZ2c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cc48e79c291a5b77832b964020bd1c92ed01619", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/5knoksiiHMrNwtkz3IzxnSr_JLA4z_HAlNDTc2pkZ2c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=424f2fad6de4ecff29b6876fb43f08ee357e21a0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/5knoksiiHMrNwtkz3IzxnSr_JLA4z_HAlNDTc2pkZ2c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f9bc875c0840d7e319eac399b21156a531eb5c6", "width": 320, "height": 240}], "variants": {}, "id": "XVh1Qgn094PME8eAQXx7fcAj5ulwtvi-zLveL4B13q8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18mhebk", "is_robot_indexable": true, "report_reasons": null, "author": "EngineeringMug", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mhebk/i_started_a_python_youtube_channel_will_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mhebk/i_started_a_python_youtube_channel_will_be/", "subreddit_subscribers": 147087, "created_utc": 1703033023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have a source table updated from GCS files uploaded daily.\n\nFrom this source table i have another table for my client, cleansed &amp; transformed.\n\n&amp;#x200B;\n\nBut now i would like to only add new incoming data daily from the source table without having a unique key.\n\n  \nHow should i do ?  \n\n\nRegards.", "author_fullname": "t2_4lzse6nu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "update BQ with GCS using DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18me2df", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703023929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have a source table updated from GCS files uploaded daily.&lt;/p&gt;\n\n&lt;p&gt;From this source table i have another table for my client, cleansed &amp;amp; transformed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But now i would like to only add new incoming data daily from the source table without having a unique key.&lt;/p&gt;\n\n&lt;p&gt;How should i do ?  &lt;/p&gt;\n\n&lt;p&gt;Regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18me2df", "is_robot_indexable": true, "report_reasons": null, "author": "Resident_Set204", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18me2df/update_bq_with_gcs_using_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18me2df/update_bq_with_gcs_using_dbt/", "subreddit_subscribers": 147087, "created_utc": 1703023929.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}