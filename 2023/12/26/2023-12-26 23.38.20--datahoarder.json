{"kind": "Listing", "data": {"after": "t3_18revmn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://preview.redd.it/faqrb9f4aj8c1.png?width=500&amp;format=png&amp;auto=webp&amp;s=434ddfa5c6eb11067cc0b1bc729907915ebe15f0\n\nMy Apple iCloud service broke MEGA ToS. As I was creating my account, my iPhone created a random email account as they do to hide personal information in cases of data breach.  \nThe day after, with no previous/after notice MEGA decided to close my account, having no access to my files anymore, and preventing me from creating a new account or starting a new support ticket.\n\nThe day before creating this MEGA account, I backed up and downloaded all my Google Drive/Photos to transfer them to MEGA (almost 17TB but still inside my \"Pro Flexy\" transfer quota terms.), more than 10 years of photos, videos, and work are almost gone forever. This is a fun story to tell later as I didn't delete any physical data, otherwise, it would have been devastating. I learned my lesson, now everything would be physically stored.\n\nI can't believe it is that easy to lose almost 17TB, but I guess I've to stick it up.\n\n  \nTOS: [https://mega.io/terms#SuspensionandTermination](https://mega.io/terms#SuspensionandTermination)\n\nWe may immediately suspend or terminate your access to our services, and (as may be applicable) that of other users within a Business Account, and/or remove any of your Data, with or **without notice to you if:** \n\n**35.6** Any information you provide to us indicates that you may have breached or may intend to breach these Terms, ***including an email address that is offensive, obscene***, discriminatory or is otherwise suggestive of an illegal activity or a breach of these Terms.  \n\n\n&amp;#x200B;", "author_fullname": "t2_imvfg9ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "17TB of Cloud Storage gone FOREVER", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"faqrb9f4aj8c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 151, "x": 108, "u": "https://preview.redd.it/faqrb9f4aj8c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b2fcaf168eb41833b3e47fed567b2e7ad8ea0d3"}, {"y": 302, "x": 216, "u": "https://preview.redd.it/faqrb9f4aj8c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba3026b3a885523f27495f824147e71d00351c24"}, {"y": 448, "x": 320, "u": "https://preview.redd.it/faqrb9f4aj8c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c7f0e430cb222b53d5bb3fb9d3ef3ba6e8725b0"}], "s": {"y": 700, "x": 500, "u": "https://preview.redd.it/faqrb9f4aj8c1.png?width=500&amp;format=png&amp;auto=webp&amp;s=434ddfa5c6eb11067cc0b1bc729907915ebe15f0"}, "id": "faqrb9f4aj8c1"}}, "name": "t3_18qy1wx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 487, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 487, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XFJbsYhwTSzSYDk5X7_z1fw1GDDUiAh33jDdk6PweSQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1703559638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/faqrb9f4aj8c1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=434ddfa5c6eb11067cc0b1bc729907915ebe15f0\"&gt;https://preview.redd.it/faqrb9f4aj8c1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=434ddfa5c6eb11067cc0b1bc729907915ebe15f0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My Apple iCloud service broke MEGA ToS. As I was creating my account, my iPhone created a random email account as they do to hide personal information in cases of data breach.&lt;br/&gt;\nThe day after, with no previous/after notice MEGA decided to close my account, having no access to my files anymore, and preventing me from creating a new account or starting a new support ticket.&lt;/p&gt;\n\n&lt;p&gt;The day before creating this MEGA account, I backed up and downloaded all my Google Drive/Photos to transfer them to MEGA (almost 17TB but still inside my &amp;quot;Pro Flexy&amp;quot; transfer quota terms.), more than 10 years of photos, videos, and work are almost gone forever. This is a fun story to tell later as I didn&amp;#39;t delete any physical data, otherwise, it would have been devastating. I learned my lesson, now everything would be physically stored.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t believe it is that easy to lose almost 17TB, but I guess I&amp;#39;ve to stick it up.&lt;/p&gt;\n\n&lt;p&gt;TOS: &lt;a href=\"https://mega.io/terms#SuspensionandTermination\"&gt;https://mega.io/terms#SuspensionandTermination&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We may immediately suspend or terminate your access to our services, and (as may be applicable) that of other users within a Business Account, and/or remove any of your Data, with or &lt;strong&gt;without notice to you if:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;35.6&lt;/strong&gt; Any information you provide to us indicates that you may have breached or may intend to breach these Terms, &lt;strong&gt;&lt;em&gt;including an email address that is offensive, obscene&lt;/em&gt;&lt;/strong&gt;, discriminatory or is otherwise suggestive of an illegal activity or a breach of these Terms.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?auto=webp&amp;s=de51b4a7972da202c4b318526a10cf7618f0ae47", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6eb7d95ce51884710556fce52be10bf0e1047127", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ea5353de201f81a7ed870b53776d654338933809", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dddfcc9f7b8d18825662cdfa26aa4e8bbd7668b5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df9a7bb52e64dabe5b9b837606913bac956d6dc8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=24ad2bdb9b1b1b74b8332d91c828decc1b0757f5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/IDu1CRc3jf7dhC1SlZqfdSCHAZBeC0L6wITP--ETBSs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5e10818981fa9c0c3db51fcada2a9e94cb4442c6", "width": 1080, "height": 567}], "variants": {}, "id": "TQizw41zQIu0IDmHemY9gA9y3jVWUTODM_llBOKHOBI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18qy1wx", "is_robot_indexable": true, "report_reasons": null, "author": "Inside_Ad_2000", "discussion_type": null, "num_comments": 200, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18qy1wx/17tb_of_cloud_storage_gone_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18qy1wx/17tb_of_cloud_storage_gone_forever/", "subreddit_subscribers": 720766, "created_utc": 1703559638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When GCN+ announced they would be shutting down their streaming service, it was a real shock. I could never subscribe as there was a geo location issue in subscribing. And I could never watch any of their GCN made exclusives.\n\nSomeone in this community backuped all their docs and made 400GB of nearly 200 movies available. I got them all and exploded my data limits for the month.\n\nTHANK YOU PEOPLE IN HERE.\n\nThis is yet another reason why I ALWAYS get a copy of any series, movies, docs I like even youtube ones that you like. I always do and am happy with this setup :)\n\nOn the cloud sucks.", "author_fullname": "t2_5hrw7qpl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A big thank you to the datahoarder community", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r3p1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703579771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When GCN+ announced they would be shutting down their streaming service, it was a real shock. I could never subscribe as there was a geo location issue in subscribing. And I could never watch any of their GCN made exclusives.&lt;/p&gt;\n\n&lt;p&gt;Someone in this community backuped all their docs and made 400GB of nearly 200 movies available. I got them all and exploded my data limits for the month.&lt;/p&gt;\n\n&lt;p&gt;THANK YOU PEOPLE IN HERE.&lt;/p&gt;\n\n&lt;p&gt;This is yet another reason why I ALWAYS get a copy of any series, movies, docs I like even youtube ones that you like. I always do and am happy with this setup :)&lt;/p&gt;\n\n&lt;p&gt;On the cloud sucks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18r3p1n", "is_robot_indexable": true, "report_reasons": null, "author": "Mountainking7", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r3p1n/a_big_thank_you_to_the_datahoarder_community/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r3p1n/a_big_thank_you_to_the_datahoarder_community/", "subreddit_subscribers": 720766, "created_utc": 1703579771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, if you regularly browse [https://diskprices.com/](https://diskprices.com/), inevitably a used disk from a DBSKY will pop up.   \n\n\nHere's an example 10 TB drive for 80$, used, 5 year warranty. Not a bad deal if the warranty is good:   \n[https://www.amazon.com/dp/B0BSB7J2Z8](https://www.amazon.com/dp/B0BSB7J2Z8)  \n\n\nthey sell many disks it seems.  I'm curious if they're good however. Googling their name will yield an old Reddit post about someone replacing 6/10 of their DOA drives, supposedly in an easy process.  This does not bode well for the seller, replacing 6/10 disks, even if easy, is not really something you want to do. Ok, let's say that we can replace these easily. What's the process we may go through? Finding this turns out to be harder than one may think.\n\nHere's the amazon seller page for DBSky:   \n[https://www.amazon.com/sp?ie=UTF8&amp;seller=A18WXU4I7YR6UA](https://www.amazon.com/sp?ie=UTF8&amp;seller=A18WXU4I7YR6UA)  \n\n\nAccording to this page, their website is [dbskyusa.com](https://dbskyusa.com), their business phone is 725-244-0119 and their address is as follows:\n\n7260 W AZURE DR  \nSTE 140-436  \nLAS VEGAS  \nNV\n\nTheir website is a 404 error, so there's not much to see there. strange for a company that's sourcing HDDs for amazon.\n\nTheir address belongs to a service called \\`mostly mail LV\\` ([https://www.mostlymaillv.com/](https://www.mostlymaillv.com/)) which is a proxy mail service \n\nThe whois for their website is all privated\n\nThe business phone is a cell phone from Tmobile, and not a VOIP service, so there's a positive.\n\nThere is an email, and I've emailed asking for instructions.\n\n&amp;#x200B;\n\nSo, I'm out of info here. It seems like there's no other leads to chase down, and until they respond to my email, I'm not sure what else to do but ask here. Are these sorts of sellers reliable in their warranties and products? Have you had to deal with DBSky, or other 'ghost' retailers? Are they a good buy, or something to stay away from?", "author_fullname": "t2_oce3vnqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBSKY, the top diskprice seller- who are they", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r133q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703569501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, if you regularly browse &lt;a href=\"https://diskprices.com/\"&gt;https://diskprices.com/&lt;/a&gt;, inevitably a used disk from a DBSKY will pop up.   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example 10 TB drive for 80$, used, 5 year warranty. Not a bad deal if the warranty is good:&lt;br/&gt;\n&lt;a href=\"https://www.amazon.com/dp/B0BSB7J2Z8\"&gt;https://www.amazon.com/dp/B0BSB7J2Z8&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;they sell many disks it seems.  I&amp;#39;m curious if they&amp;#39;re good however. Googling their name will yield an old Reddit post about someone replacing 6/10 of their DOA drives, supposedly in an easy process.  This does not bode well for the seller, replacing 6/10 disks, even if easy, is not really something you want to do. Ok, let&amp;#39;s say that we can replace these easily. What&amp;#39;s the process we may go through? Finding this turns out to be harder than one may think.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the amazon seller page for DBSky:&lt;br/&gt;\n&lt;a href=\"https://www.amazon.com/sp?ie=UTF8&amp;amp;seller=A18WXU4I7YR6UA\"&gt;https://www.amazon.com/sp?ie=UTF8&amp;amp;seller=A18WXU4I7YR6UA&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;According to this page, their website is &lt;a href=\"https://dbskyusa.com\"&gt;dbskyusa.com&lt;/a&gt;, their business phone is 725-244-0119 and their address is as follows:&lt;/p&gt;\n\n&lt;p&gt;7260 W AZURE DR&lt;br/&gt;\nSTE 140-436&lt;br/&gt;\nLAS VEGAS&lt;br/&gt;\nNV&lt;/p&gt;\n\n&lt;p&gt;Their website is a 404 error, so there&amp;#39;s not much to see there. strange for a company that&amp;#39;s sourcing HDDs for amazon.&lt;/p&gt;\n\n&lt;p&gt;Their address belongs to a service called `mostly mail LV` (&lt;a href=\"https://www.mostlymaillv.com/\"&gt;https://www.mostlymaillv.com/&lt;/a&gt;) which is a proxy mail service &lt;/p&gt;\n\n&lt;p&gt;The whois for their website is all privated&lt;/p&gt;\n\n&lt;p&gt;The business phone is a cell phone from Tmobile, and not a VOIP service, so there&amp;#39;s a positive.&lt;/p&gt;\n\n&lt;p&gt;There is an email, and I&amp;#39;ve emailed asking for instructions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m out of info here. It seems like there&amp;#39;s no other leads to chase down, and until they respond to my email, I&amp;#39;m not sure what else to do but ask here. Are these sorts of sellers reliable in their warranties and products? Have you had to deal with DBSky, or other &amp;#39;ghost&amp;#39; retailers? Are they a good buy, or something to stay away from?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18r133q", "is_robot_indexable": true, "report_reasons": null, "author": "buyingshitformylab", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r133q/dbsky_the_top_diskprice_seller_who_are_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r133q/dbsky_the_top_diskprice_seller_who_are_they/", "subreddit_subscribers": 720766, "created_utc": 1703569501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a desktop PC with OS/applications installed on an SSD, and years of photos/videos stored on a separate internal 4TB drive.  The OS drive I do not care if it disappears, as Windows and applications can always be reinstalled. Contents of the 4TB drive are currently copied to an unlimited GDrive Education account, however the 'unlimited' part is running out and I need to look at an alternate plan. I know a lot of people here recommend building a NAS or buying one, and I just do not think that a NAS is needed for my case. I have read the forum here for WEEKS now, and I think I am just overwhelming myself with options, *and now have an unnecessary fear of bitrot*. I do not need the data to be accessible 100% of the time, I do not mind making manual copies of my photos from my phone or my camera. I thought I was hoarding, but after spending time on this sub, I am *nothing* compared to most of you. \n\n**Is this a solid plan or will I waste time/money? :** \n\nPrimary: 4TB internal \"source\" drive. *Currently have and not even filled to half capacity yet.*   \nOn-site Backup: 4TB external drive - destination / backup. *Will need to buy.* \n\n* Primary 4TB to be manually backed up to external 4TB drive using freefilesync on a weekly basis. \n   * Freefilesync ran using a comparison with 'file content' checking enabled. This should highlight any changes in files due to bitrot/other corruption and I hopefully can just view the two different photos/videos from each drive and see which has noticeable corruption. \n   * If there is a better file copy with verification program available, I am open to it. Seems FFS and TeraCopy are the two most popular with a GUI for Windows. \n\nOff-site Backup: Backblaze backup of Primary drive. *Will need to subscribe.* \n\n* Backblaze agent running on desktop would be handling backups for my cloud copy. \n\nIf I am understanding everything correctly, this plan should cover the 3-2-1 rule, and should work for me and every other 'average' person who may be reading this in the future. What I am concerned about the most is finding an easy way to 'verify' my backups/copies, as most suggestions I have found on this sub rely on CLI applications or Linux which I would like to avoid for simplicity's sake. A lot of threads here have me freaking out about bitrot, maybe more than I should be. I *think* this method will work, but maybe someone who has done this for longer than I have can chime in and point out issues before I run into them. ", "author_fullname": "t2_lagqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a simple backup solution for someone who -thought- they were a hoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18qunbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703549104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a desktop PC with OS/applications installed on an SSD, and years of photos/videos stored on a separate internal 4TB drive.  The OS drive I do not care if it disappears, as Windows and applications can always be reinstalled. Contents of the 4TB drive are currently copied to an unlimited GDrive Education account, however the &amp;#39;unlimited&amp;#39; part is running out and I need to look at an alternate plan. I know a lot of people here recommend building a NAS or buying one, and I just do not think that a NAS is needed for my case. I have read the forum here for WEEKS now, and I think I am just overwhelming myself with options, &lt;em&gt;and now have an unnecessary fear of bitrot&lt;/em&gt;. I do not need the data to be accessible 100% of the time, I do not mind making manual copies of my photos from my phone or my camera. I thought I was hoarding, but after spending time on this sub, I am &lt;em&gt;nothing&lt;/em&gt; compared to most of you. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is this a solid plan or will I waste time/money? :&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Primary: 4TB internal &amp;quot;source&amp;quot; drive. &lt;em&gt;Currently have and not even filled to half capacity yet.&lt;/em&gt;&lt;br/&gt;\nOn-site Backup: 4TB external drive - destination / backup. &lt;em&gt;Will need to buy.&lt;/em&gt; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Primary 4TB to be manually backed up to external 4TB drive using freefilesync on a weekly basis. \n\n&lt;ul&gt;\n&lt;li&gt;Freefilesync ran using a comparison with &amp;#39;file content&amp;#39; checking enabled. This should highlight any changes in files due to bitrot/other corruption and I hopefully can just view the two different photos/videos from each drive and see which has noticeable corruption. &lt;/li&gt;\n&lt;li&gt;If there is a better file copy with verification program available, I am open to it. Seems FFS and TeraCopy are the two most popular with a GUI for Windows. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Off-site Backup: Backblaze backup of Primary drive. &lt;em&gt;Will need to subscribe.&lt;/em&gt; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backblaze agent running on desktop would be handling backups for my cloud copy. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If I am understanding everything correctly, this plan should cover the 3-2-1 rule, and should work for me and every other &amp;#39;average&amp;#39; person who may be reading this in the future. What I am concerned about the most is finding an easy way to &amp;#39;verify&amp;#39; my backups/copies, as most suggestions I have found on this sub rely on CLI applications or Linux which I would like to avoid for simplicity&amp;#39;s sake. A lot of threads here have me freaking out about bitrot, maybe more than I should be. I &lt;em&gt;think&lt;/em&gt; this method will work, but maybe someone who has done this for longer than I have can chime in and point out issues before I run into them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18qunbh", "is_robot_indexable": true, "report_reasons": null, "author": "ridyn", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18qunbh/creating_a_simple_backup_solution_for_someone_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18qunbh/creating_a_simple_backup_solution_for_someone_who/", "subreddit_subscribers": 720766, "created_utc": 1703549104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I stumbled upon this community and the lack of faith people have in external hard drives is...eye-opening. I have questions that I can't find elsewhere so I'm just going to ask, sorry if they've been answered (just link me in the right direction!)\n\nThe biggest one: if any source of media storage is so doomed to inevitable and absolute failure at any moment... does this apply to my computer? My phone? \n\nI've been using my macbooks/ipads/iphones for at least 10 years nows and NEVER had a loss of anything whatsoever, and I was under the impression that in the event of something happening, it could usually be recovered somehow anyway (stories of the fbi finding shit about people on wiped laptops etc). I only recently decided I should get an external hard drive (how I ended up here) because I had the unnerving realization that none of my photography/video footage was actually fully on any of my devices. Since I don't have enough space it's all optimized. I've just been subscribing for 2 TB of icloud to hold it, so I got scared that if something happened on the icloud side, my years of work would be stuck in low-res regardless of the fact that it's on multiple devices. I thought I would be safe by just getting a 2tb macbook as my next replacement to hold everything OR just getting a much cheaper external hard drive. So is there a difference between those two? Or are they both as vulnerable?\n\n2nd question: Is people's fear over this really that immanent? or is it more hypothetical? Of course theoretically ANYTHING can fail but how often does it actually happen? People keep bitcoin on ledgers and trezors, important documents on thumb drives backed up by just their computer. Why have I never heard of someone's iphone files becoming corrupted out of nowhere? Still wrapping my head around what is the practical reality here. We can also get hit by a meteor at any second...\n\n3rd question: this is just more of an item of curiosity, but is cloud backup just as vulnerable? I'm sure there's plenty of backups in that scenario but do they regularly have instances where something fails and they have to switch to a backup? Is one cloud server better than another? \n\nThanks for any info, this sort of thing really stresses me out because I'm a content creator but my adhd makes me really bad with organization of \"intangible\" things, and the stress of fucking something up makes it even worse. I know the standard answer seems to be just buy multiple backup drives but I'm so far from understanding how to incorporate that into my workflow and just thinking about it is overwhelming. I'm learning I have subpar data hygiene and I'm trying to just go step by step to get better, but be thorough in the process.", "author_fullname": "t2_c7aj0brw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clarification on some things I've been reading in this community. Is all the paranoia justified?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rh6rm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703621893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I stumbled upon this community and the lack of faith people have in external hard drives is...eye-opening. I have questions that I can&amp;#39;t find elsewhere so I&amp;#39;m just going to ask, sorry if they&amp;#39;ve been answered (just link me in the right direction!)&lt;/p&gt;\n\n&lt;p&gt;The biggest one: if any source of media storage is so doomed to inevitable and absolute failure at any moment... does this apply to my computer? My phone? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using my macbooks/ipads/iphones for at least 10 years nows and NEVER had a loss of anything whatsoever, and I was under the impression that in the event of something happening, it could usually be recovered somehow anyway (stories of the fbi finding shit about people on wiped laptops etc). I only recently decided I should get an external hard drive (how I ended up here) because I had the unnerving realization that none of my photography/video footage was actually fully on any of my devices. Since I don&amp;#39;t have enough space it&amp;#39;s all optimized. I&amp;#39;ve just been subscribing for 2 TB of icloud to hold it, so I got scared that if something happened on the icloud side, my years of work would be stuck in low-res regardless of the fact that it&amp;#39;s on multiple devices. I thought I would be safe by just getting a 2tb macbook as my next replacement to hold everything OR just getting a much cheaper external hard drive. So is there a difference between those two? Or are they both as vulnerable?&lt;/p&gt;\n\n&lt;p&gt;2nd question: Is people&amp;#39;s fear over this really that immanent? or is it more hypothetical? Of course theoretically ANYTHING can fail but how often does it actually happen? People keep bitcoin on ledgers and trezors, important documents on thumb drives backed up by just their computer. Why have I never heard of someone&amp;#39;s iphone files becoming corrupted out of nowhere? Still wrapping my head around what is the practical reality here. We can also get hit by a meteor at any second...&lt;/p&gt;\n\n&lt;p&gt;3rd question: this is just more of an item of curiosity, but is cloud backup just as vulnerable? I&amp;#39;m sure there&amp;#39;s plenty of backups in that scenario but do they regularly have instances where something fails and they have to switch to a backup? Is one cloud server better than another? &lt;/p&gt;\n\n&lt;p&gt;Thanks for any info, this sort of thing really stresses me out because I&amp;#39;m a content creator but my adhd makes me really bad with organization of &amp;quot;intangible&amp;quot; things, and the stress of fucking something up makes it even worse. I know the standard answer seems to be just buy multiple backup drives but I&amp;#39;m so far from understanding how to incorporate that into my workflow and just thinking about it is overwhelming. I&amp;#39;m learning I have subpar data hygiene and I&amp;#39;m trying to just go step by step to get better, but be thorough in the process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rh6rm", "is_robot_indexable": true, "report_reasons": null, "author": "seeeeeeeeth", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rh6rm/clarification_on_some_things_ive_been_reading_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rh6rm/clarification_on_some_things_ive_been_reading_in/", "subreddit_subscribers": 720766, "created_utc": 1703621893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a simple software with GUI (Windows) that will allow me to scan and catalog all file data for multiple drives, including offline drives. Ideal software would create a thumbnail of each video file so I can visually scan for it as it's probably mislabeled. \n\nI used to catalog all my drives before I moved to NAS units. \n\nMissing a video file and it could be anywhere. \n\nI am NOT LOOKING FOR a way to catalog my physical media collection (DVDs, Blurays, etc). ", "author_fullname": "t2_cvnw1nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PC Media Cataloging tool? (used to be simple)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rex5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703616058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a simple software with GUI (Windows) that will allow me to scan and catalog all file data for multiple drives, including offline drives. Ideal software would create a thumbnail of each video file so I can visually scan for it as it&amp;#39;s probably mislabeled. &lt;/p&gt;\n\n&lt;p&gt;I used to catalog all my drives before I moved to NAS units. &lt;/p&gt;\n\n&lt;p&gt;Missing a video file and it could be anywhere. &lt;/p&gt;\n\n&lt;p&gt;I am NOT LOOKING FOR a way to catalog my physical media collection (DVDs, Blurays, etc). &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rex5c", "is_robot_indexable": true, "report_reasons": null, "author": "FalsettoChild", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rex5c/pc_media_cataloging_tool_used_to_be_simple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rex5c/pc_media_cataloging_tool_used_to_be_simple/", "subreddit_subscribers": 720766, "created_utc": 1703616058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Super Micro JBOD server which is populated with 4TB SAS disks, the disks are starting to fail, so it's time for me to upgrade.   \n\n\nThe unit has 36 bays, 24 at the front are 4tb in a pool (3 parity), 2 x 4tb at the back are the boot disks in mirror. With the increase in available capacity, the 24 4tb coud be replaced with far fewer disks. I'm thinking populate the 10 rear bays with large capacity disks in a new pool.  Copy everything across and then remove the old 4TB.  \n\n\nSimple!  problem is, where to buy disks at reasonable cost, is there anywhere that people find well priced in the UK to buy disks from?  I'm assuming sticking with SAS is my best bet for performance and longevity?  \n\n\nAny suggestions?", "author_fullname": "t2_ldqx7qd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest UK supplier of SAS disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r7fao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703594831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Super Micro JBOD server which is populated with 4TB SAS disks, the disks are starting to fail, so it&amp;#39;s time for me to upgrade.   &lt;/p&gt;\n\n&lt;p&gt;The unit has 36 bays, 24 at the front are 4tb in a pool (3 parity), 2 x 4tb at the back are the boot disks in mirror. With the increase in available capacity, the 24 4tb coud be replaced with far fewer disks. I&amp;#39;m thinking populate the 10 rear bays with large capacity disks in a new pool.  Copy everything across and then remove the old 4TB.  &lt;/p&gt;\n\n&lt;p&gt;Simple!  problem is, where to buy disks at reasonable cost, is there anywhere that people find well priced in the UK to buy disks from?  I&amp;#39;m assuming sticking with SAS is my best bet for performance and longevity?  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18r7fao", "is_robot_indexable": true, "report_reasons": null, "author": "CelticWebs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r7fao/cheapest_uk_supplier_of_sas_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r7fao/cheapest_uk_supplier_of_sas_disks/", "subreddit_subscribers": 720766, "created_utc": 1703594831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "OK, so, preface. I am IT literate, I build, debug and modify my own PCs. I rarely run into issues I can't fix on my own, but I'm aware my knowledge is polarized and narrow.\n\nRecently I came into possession of a RAID card (suspiciously cheap, but I shrugged and decided to roll the dice). It is an LSI-9270CV-8i. From what I can tell, the card itself works. I lack cables for it, which will soon be remedied, and I'm rather perplexed that the card itself has a BIOS that seems to override normal boot and thus causes no end of issues, but &lt;shrug&gt;, I got the damn thing cheap. Oh, and it runs hotter than hell's sauna, but that'll also soon be remedied.\n\nWhat perplexes me is, where exactly is the RAID management suite I keep hearing about? I've checked the official websites, I end up navigating a maze of blindly trying to guess which category my card falls under, and thus far have been unable to find the software listed for it. I've tried trawling the web, and can't find a current copy lying around. Apparently there are different versions? I did find a couple very old copies, but I'm not sure they'll actually work.\n\nI've checked the data hoarder wiki, it's one of the ones that doesn't have a link to relevant software, and I'm still not sure I'm understanding the instructions correctly.\n\nThe links and info I'm getting are vague enough I'm having trouble parsing them and figuring out how to go about this, does anyone know what I'm doing wrong? Where's the software for the card? Is it supposed to come with it on a disc? There's a reference to providing a serial number on the RAID card's BIOS, but I shut it down almost instantly when I saw the temps soaring past 93C.\n\nIs that the necessary next step? Will third-party software talk nice to the card? If so, does anyone know what software? I assumed the software to control a RAID card would be freely available, but I'm discovering it is not.\n\nI'm just plain confused, any help would be greatly appreciated.", "author_fullname": "t2_19wofara", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having trouble getting a RAID card working, what am I doing wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r389v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703577830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OK, so, preface. I am IT literate, I build, debug and modify my own PCs. I rarely run into issues I can&amp;#39;t fix on my own, but I&amp;#39;m aware my knowledge is polarized and narrow.&lt;/p&gt;\n\n&lt;p&gt;Recently I came into possession of a RAID card (suspiciously cheap, but I shrugged and decided to roll the dice). It is an LSI-9270CV-8i. From what I can tell, the card itself works. I lack cables for it, which will soon be remedied, and I&amp;#39;m rather perplexed that the card itself has a BIOS that seems to override normal boot and thus causes no end of issues, but &amp;lt;shrug&amp;gt;, I got the damn thing cheap. Oh, and it runs hotter than hell&amp;#39;s sauna, but that&amp;#39;ll also soon be remedied.&lt;/p&gt;\n\n&lt;p&gt;What perplexes me is, where exactly is the RAID management suite I keep hearing about? I&amp;#39;ve checked the official websites, I end up navigating a maze of blindly trying to guess which category my card falls under, and thus far have been unable to find the software listed for it. I&amp;#39;ve tried trawling the web, and can&amp;#39;t find a current copy lying around. Apparently there are different versions? I did find a couple very old copies, but I&amp;#39;m not sure they&amp;#39;ll actually work.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve checked the data hoarder wiki, it&amp;#39;s one of the ones that doesn&amp;#39;t have a link to relevant software, and I&amp;#39;m still not sure I&amp;#39;m understanding the instructions correctly.&lt;/p&gt;\n\n&lt;p&gt;The links and info I&amp;#39;m getting are vague enough I&amp;#39;m having trouble parsing them and figuring out how to go about this, does anyone know what I&amp;#39;m doing wrong? Where&amp;#39;s the software for the card? Is it supposed to come with it on a disc? There&amp;#39;s a reference to providing a serial number on the RAID card&amp;#39;s BIOS, but I shut it down almost instantly when I saw the temps soaring past 93C.&lt;/p&gt;\n\n&lt;p&gt;Is that the necessary next step? Will third-party software talk nice to the card? If so, does anyone know what software? I assumed the software to control a RAID card would be freely available, but I&amp;#39;m discovering it is not.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just plain confused, any help would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18r389v", "is_robot_indexable": true, "report_reasons": null, "author": "TheType95", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r389v/having_trouble_getting_a_raid_card_working_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r389v/having_trouble_getting_a_raid_card_working_what/", "subreddit_subscribers": 720766, "created_utc": 1703577830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys,\n\nI just learned about DiskFresh to prevent data rotting, but Diskfresh is old (2007), is there any new software that you guys know about? Alternatives and all? If DiskFresh works good until this day, might as well use it, but if there is something you guys can share, please do. I would love to learn from them and I greatly appreciate what you will share to me.\n\nThank you!", "author_fullname": "t2_hi2gpnqc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone knows alternative for DiskFresh program? Even paid ones.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r35bp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703577516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I just learned about DiskFresh to prevent data rotting, but Diskfresh is old (2007), is there any new software that you guys know about? Alternatives and all? If DiskFresh works good until this day, might as well use it, but if there is something you guys can share, please do. I would love to learn from them and I greatly appreciate what you will share to me.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18r35bp", "is_robot_indexable": true, "report_reasons": null, "author": "Lykancubi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r35bp/anyone_knows_alternative_for_diskfresh_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r35bp/anyone_knows_alternative_for_diskfresh_program/", "subreddit_subscribers": 720766, "created_utc": 1703577516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not sure if this is the correct place for this question or not but feel free to remove it if not. So I was tasked with scanning and digitizing a shit ton of family photos. I have no idea how many we have in total but I know it's going to be a lot by the time I get done. I've never used Lightroom before but after some research it seems like the best option. Which version would be best? I'm going to end up distributing all of the photos to my family on hard drives when I get done. I would also like as much information as possible to be included in the photos after I download them on hard drives so they are able to see all of the information I add to the photos. Also, I don't know if this is possible but I would like my family to be able to help me to add relevant information to the photos because I won't know a lot of the people or locations without them having to buy a subscription but I don't have any idea if that's possible. Any help or advice would be greatly appreciated!", "author_fullname": "t2_fa7b06ih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightroom CC vs Classic for digitizing and organizing thousands of family photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r21rz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703573017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure if this is the correct place for this question or not but feel free to remove it if not. So I was tasked with scanning and digitizing a shit ton of family photos. I have no idea how many we have in total but I know it&amp;#39;s going to be a lot by the time I get done. I&amp;#39;ve never used Lightroom before but after some research it seems like the best option. Which version would be best? I&amp;#39;m going to end up distributing all of the photos to my family on hard drives when I get done. I would also like as much information as possible to be included in the photos after I download them on hard drives so they are able to see all of the information I add to the photos. Also, I don&amp;#39;t know if this is possible but I would like my family to be able to help me to add relevant information to the photos because I won&amp;#39;t know a lot of the people or locations without them having to buy a subscription but I don&amp;#39;t have any idea if that&amp;#39;s possible. Any help or advice would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18r21rz", "is_robot_indexable": true, "report_reasons": null, "author": "BuckshotIV96", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18r21rz/lightroom_cc_vs_classic_for_digitizing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18r21rz/lightroom_cc_vs_classic_for_digitizing_and/", "subreddit_subscribers": 720766, "created_utc": 1703573017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have an iPhone and am running out of storage fast. Can you recommend me some ways to store my photos/videos but also have a way to look through them on my phone?\n\nI was looking at Immich or PhotoPrism but I'm open to how you are storing photos and then viewing them over your phones.\n\nThanks and happy holidays!", "author_fullname": "t2_ipv9l8fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for a self-hosted photo library that can also be viewed on phones over internet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18qx0rn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703556350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have an iPhone and am running out of storage fast. Can you recommend me some ways to store my photos/videos but also have a way to look through them on my phone?&lt;/p&gt;\n\n&lt;p&gt;I was looking at Immich or PhotoPrism but I&amp;#39;m open to how you are storing photos and then viewing them over your phones.&lt;/p&gt;\n\n&lt;p&gt;Thanks and happy holidays!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18qx0rn", "is_robot_indexable": true, "report_reasons": null, "author": "asdflmnop_01", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18qx0rn/any_recommendations_for_a_selfhosted_photo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18qx0rn/any_recommendations_for_a_selfhosted_photo/", "subreddit_subscribers": 720766, "created_utc": 1703556350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI am looking for a way to streamline my photo scanning process so I can chomp through my backlog before I die of old age.\n\nNowadays, I have to postprocess my scans in the following way:\n\n1. rotate and crop them so there are not white boundaries\n2. Remove some scratches and dust that was still on the scans\n3. Improve picture quality by tweaking contrast, saturation, etc.\n4. export them to a more readable format (usually a jpeg of 4000 pixels along its longest axis)\n\nI do these manually on Affinity photo now, but I'm wondering if there is a swiss army knife tool that can automate this process. It would need to be able to handle large TIFFs as input and export high resolution images. Preferably locally installed.\n\nAny suggestions?", "author_fullname": "t2_bv035", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automated tool for postprocessing scanned photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18rksvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703631429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking for a way to streamline my photo scanning process so I can chomp through my backlog before I die of old age.&lt;/p&gt;\n\n&lt;p&gt;Nowadays, I have to postprocess my scans in the following way:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;rotate and crop them so there are not white boundaries&lt;/li&gt;\n&lt;li&gt;Remove some scratches and dust that was still on the scans&lt;/li&gt;\n&lt;li&gt;Improve picture quality by tweaking contrast, saturation, etc.&lt;/li&gt;\n&lt;li&gt;export them to a more readable format (usually a jpeg of 4000 pixels along its longest axis)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I do these manually on Affinity photo now, but I&amp;#39;m wondering if there is a swiss army knife tool that can automate this process. It would need to be able to handle large TIFFs as input and export high resolution images. Preferably locally installed.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "170TB Unraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rksvw", "is_robot_indexable": true, "report_reasons": null, "author": "Mathy963", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18rksvw/automated_tool_for_postprocessing_scanned_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rksvw/automated_tool_for_postprocessing_scanned_photos/", "subreddit_subscribers": 720766, "created_utc": 1703631429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, a website that downloads and reupload all the videos in a playlist of another account (it doesn't have to be Youtube). Or download all the videos in a playlist to my computer if that's not possible.\n\nFor more context: I have hundreds of videos saved in dozens of playlists and Youtube is deleting them without even telling the title of the video. If I download them one by one it would take too long and I don't even know if I would have space on my computer.\n\n&amp;#x200B;\n\nps:  *I don't know anything about programming, I can learn quickly if I  need to but teach me step by step instead of just posting codes.* ", "author_fullname": "t2_3u8e8fcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a more efficient way to backup YouTube playlists other than download them one by one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18rkbg1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703630172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, a website that downloads and reupload all the videos in a playlist of another account (it doesn&amp;#39;t have to be Youtube). Or download all the videos in a playlist to my computer if that&amp;#39;s not possible.&lt;/p&gt;\n\n&lt;p&gt;For more context: I have hundreds of videos saved in dozens of playlists and Youtube is deleting them without even telling the title of the video. If I download them one by one it would take too long and I don&amp;#39;t even know if I would have space on my computer.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;ps:  &lt;em&gt;I don&amp;#39;t know anything about programming, I can learn quickly if I  need to but teach me step by step instead of just posting codes.&lt;/em&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rkbg1", "is_robot_indexable": true, "report_reasons": null, "author": "Contraocontra", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rkbg1/is_there_a_more_efficient_way_to_backup_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rkbg1/is_there_a_more_efficient_way_to_backup_youtube/", "subreddit_subscribers": 720766, "created_utc": 1703630172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking to archive an email newsletter. However, I do not know what file format I should use. I don't want to mess up any of the formatting, but I also don't want to store unnecessary information, like the sender or the recipient of the email. Which file format should I use?", "author_fullname": "t2_6p8tgzzt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File format for archiving an email newsletter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18rjs4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703628800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to archive an email newsletter. However, I do not know what file format I should use. I don&amp;#39;t want to mess up any of the formatting, but I also don&amp;#39;t want to store unnecessary information, like the sender or the recipient of the email. Which file format should I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rjs4u", "is_robot_indexable": true, "report_reasons": null, "author": "alt_0140", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rjs4u/file_format_for_archiving_an_email_newsletter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rjs4u/file_format_for_archiving_an_email_newsletter/", "subreddit_subscribers": 720766, "created_utc": 1703628800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. Wall of text incoming.\n\nI've been amassing a large collection of files over the last couple of years (around 1TB total, which is probably not a lot to most of you lol), and have been looking into finally getting around to creating a setup that adheres to the 3-2-1 backup rule.\n\nI've been browsing and searching for beginner tips on this subreddit for a long time today and am just overwhelmed. Lots of terminology and abbreviations that I don't understand. I wouldn't consider myself computer illiterate, but I have never dived into the hardware side of things before.\n\nMy situation / background: I currently live a semi-nomadic lifestyle, and so want something that is portable. I was planning on purchasing 2 external HDDs (2TB or 4TB) to keep with full backups and update weekly / monthly, and keep one in a storage unit. For my 3rd backup I currently use a Sandisk Extreme SSD 1TB, for files or games that I watch / work / play directly off the drive for and that need fast speeds (I may upgrade to a 2TB or 4TB version). I also use both paid MEGA and Protondrive services, but am unable to upload and store my whole collection in, and only use it for very important files or things that I need access to everywhere.\n\nI guess I was just looking for some advice on a few things:\n\n1: Does this backup plan sound like a good plan? Any modifications you would make?\n\n2: Are there any recommendations for brands / basic external drives? How do you avoid drives with low failure rates, just reading online reviews?\n\n3: Is there any essential software I should have to help manage drives / check on drive health?\n\nIf you have any links to specific resources it would be helpful as well.\n\nThank you in advance!", "author_fullname": "t2_1292eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner. Overwhelmed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18rjcm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703627694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. Wall of text incoming.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been amassing a large collection of files over the last couple of years (around 1TB total, which is probably not a lot to most of you lol), and have been looking into finally getting around to creating a setup that adheres to the 3-2-1 backup rule.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been browsing and searching for beginner tips on this subreddit for a long time today and am just overwhelmed. Lots of terminology and abbreviations that I don&amp;#39;t understand. I wouldn&amp;#39;t consider myself computer illiterate, but I have never dived into the hardware side of things before.&lt;/p&gt;\n\n&lt;p&gt;My situation / background: I currently live a semi-nomadic lifestyle, and so want something that is portable. I was planning on purchasing 2 external HDDs (2TB or 4TB) to keep with full backups and update weekly / monthly, and keep one in a storage unit. For my 3rd backup I currently use a Sandisk Extreme SSD 1TB, for files or games that I watch / work / play directly off the drive for and that need fast speeds (I may upgrade to a 2TB or 4TB version). I also use both paid MEGA and Protondrive services, but am unable to upload and store my whole collection in, and only use it for very important files or things that I need access to everywhere.&lt;/p&gt;\n\n&lt;p&gt;I guess I was just looking for some advice on a few things:&lt;/p&gt;\n\n&lt;p&gt;1: Does this backup plan sound like a good plan? Any modifications you would make?&lt;/p&gt;\n\n&lt;p&gt;2: Are there any recommendations for brands / basic external drives? How do you avoid drives with low failure rates, just reading online reviews?&lt;/p&gt;\n\n&lt;p&gt;3: Is there any essential software I should have to help manage drives / check on drive health?&lt;/p&gt;\n\n&lt;p&gt;If you have any links to specific resources it would be helpful as well.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rjcm4", "is_robot_indexable": true, "report_reasons": null, "author": "Coolpop19", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rjcm4/beginner_overwhelmed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rjcm4/beginner_overwhelmed/", "subreddit_subscribers": 720766, "created_utc": 1703627694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So looking to add to my drives, i have been using sucked drives from wd elemental usb drives.. so white labled wd red drives, and i just had a small 6tb wd red duying on me, after being on for 6 years. I know the other drives are getting close to 4 years, so i want to start moving data away from the old drives.\n\nThese 2 drives are cheaper than buying a wd elemental and sucking out the drive, and i heard they were better than wd red?\n\nOriginal i wanted to go with the Toshiba, but with the new owners , i dont know if that is a good idea? im thinking about the warrenty here. ?\n\nthe drives will be on 24/7... if that makes any diffrence. so seagte exos or toshiba mg10 ? both are 20tb drives.", "author_fullname": "t2_4hfmw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba MG10 vs Seagate Exos X20", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18riz5m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703626709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So looking to add to my drives, i have been using sucked drives from wd elemental usb drives.. so white labled wd red drives, and i just had a small 6tb wd red duying on me, after being on for 6 years. I know the other drives are getting close to 4 years, so i want to start moving data away from the old drives.&lt;/p&gt;\n\n&lt;p&gt;These 2 drives are cheaper than buying a wd elemental and sucking out the drive, and i heard they were better than wd red?&lt;/p&gt;\n\n&lt;p&gt;Original i wanted to go with the Toshiba, but with the new owners , i dont know if that is a good idea? im thinking about the warrenty here. ?&lt;/p&gt;\n\n&lt;p&gt;the drives will be on 24/7... if that makes any diffrence. so seagte exos or toshiba mg10 ? both are 20tb drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18riz5m", "is_robot_indexable": true, "report_reasons": null, "author": "gravballe", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18riz5m/toshiba_mg10_vs_seagate_exos_x20/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18riz5m/toshiba_mg10_vs_seagate_exos_x20/", "subreddit_subscribers": 720766, "created_utc": 1703626709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dear hoarders, this post is about Newsgears RSS reader/aggregator, [screenshots are located here](https://imgur.com/a/waj1CO6).\n\nI'm a huge fan of RSS; I think it's a fun and interesting way of exploring the Internet.  I began this project with the goal of simply building the best RSS tools I possibly could using free/open-source frameworks like Vue3 and Vuetify on the front-end, and Spring Boot and ROME on the back-end.  \n\nMain areas of focus: free, open-source, accessible, fully responsive/mobile friendly, secure, modern, all while granting the end-user full and accurate access to every aspect of the syndicated feed payload.\n\nHere are some of the basic features of this finished product: \n\n\\* Topical article queues provide a single view of multiple related feeds\n\n\\* Full-text searching using lunrjs\n\n\\* Multiple layouts (tabular, list, and card)\n\n\\* Light and dark themes\n\n\\* OPML support (import and export)\n\n\\* Fully responsive/usable on very small screens\n\n\\* Accessible and fully keyboard navigable\n\n\\* Integrated media player (vue-plyr)\n\n\\* Available in English, Spanish, and French\n\n\\* Native secure image proxy\n\n\\* Scalable architecture can support thousands of concurrent users\n\n\\*\\*To boot-up:\\*\\* \n\nDownload docker-compose.yml:\n\n    curl -X GET https://raw.githubusercontent.com/lostsidewalk/newsgears-app/main/docker-compose.single-user.yml.sample &gt; docker-compose.yml\n\nDownload nginx.conf:\n\n    curl -X GET https://raw.githubusercontent.com/lostsidewalk/newsgears-app/main/nginx.conf &gt; nginx.conf\n\nStart docker: \n\n    docker-compose up \n\n[Navigate to localhost port 80](http://localhost).\n\nClick the RSS logo icon in the upper-left to start adding feed subscriptions. \n\n**Github main repository for Newsgears: [https://github.com/lostsidewalk/newsgears-app](https://github.com/lostsidewalk/newsgears-app)**\n\nI'd love to hear from anyone who has an interest in RSS.  This project is still in its nascent stages, and I'm highly motivated to make fixes, implement features, etc.  I'm extremely open to suggestions, and collaborating with other devs of any skill level, on this project. Feel free to drop me a line, even if you think this is POS; I'd love to hear from any users.  \n\nNewsgears RSS should be pretty stable on Linux w/Chrome or FF.  I wouldn't be surprised if some chaos resulted from running this on another platform.  I would very much appreciate any form of feedback, especially bug reports.  \n\n\\*\\*Sister project:\\*\\* \n\nComposableRSS is a REST API-driven platform for composing and publishing syndicated web feed content (such as RSS/ATOM feeds, etc.). Basically, you interact with an internal/developer-friendly REST API to create feeds, add content, and generally control all aspects of the web feed lifecycle. ComposableRSS serves those feeds to your users.  ComposableRSS supports formats beyond RSS and ATOM, making it suitable for use as a general-purpose headless content management system.  \n\n**Github main repository for ComposableRSS: [https://github.com/lostsidewalk/composable-rss-app](https://github.com/lostsidewalk/composable-rss-app)**\n\nI have a Discord to discuss matters in real-time if anyone is interested.  Thanks for reading.", "author_fullname": "t2_ojb0752w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Newsgears RSS self-hosted reader/aggregator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18riu9v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703629468.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703626333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear hoarders, this post is about Newsgears RSS reader/aggregator, &lt;a href=\"https://imgur.com/a/waj1CO6\"&gt;screenshots are located here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a huge fan of RSS; I think it&amp;#39;s a fun and interesting way of exploring the Internet.  I began this project with the goal of simply building the best RSS tools I possibly could using free/open-source frameworks like Vue3 and Vuetify on the front-end, and Spring Boot and ROME on the back-end.  &lt;/p&gt;\n\n&lt;p&gt;Main areas of focus: free, open-source, accessible, fully responsive/mobile friendly, secure, modern, all while granting the end-user full and accurate access to every aspect of the syndicated feed payload.&lt;/p&gt;\n\n&lt;p&gt;Here are some of the basic features of this finished product: &lt;/p&gt;\n\n&lt;p&gt;* Topical article queues provide a single view of multiple related feeds&lt;/p&gt;\n\n&lt;p&gt;* Full-text searching using lunrjs&lt;/p&gt;\n\n&lt;p&gt;* Multiple layouts (tabular, list, and card)&lt;/p&gt;\n\n&lt;p&gt;* Light and dark themes&lt;/p&gt;\n\n&lt;p&gt;* OPML support (import and export)&lt;/p&gt;\n\n&lt;p&gt;* Fully responsive/usable on very small screens&lt;/p&gt;\n\n&lt;p&gt;* Accessible and fully keyboard navigable&lt;/p&gt;\n\n&lt;p&gt;* Integrated media player (vue-plyr)&lt;/p&gt;\n\n&lt;p&gt;* Available in English, Spanish, and French&lt;/p&gt;\n\n&lt;p&gt;* Native secure image proxy&lt;/p&gt;\n\n&lt;p&gt;* Scalable architecture can support thousands of concurrent users&lt;/p&gt;\n\n&lt;p&gt;**To boot-up:** &lt;/p&gt;\n\n&lt;p&gt;Download docker-compose.yml:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;curl -X GET https://raw.githubusercontent.com/lostsidewalk/newsgears-app/main/docker-compose.single-user.yml.sample &amp;gt; docker-compose.yml\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Download nginx.conf:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;curl -X GET https://raw.githubusercontent.com/lostsidewalk/newsgears-app/main/nginx.conf &amp;gt; nginx.conf\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Start docker: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;docker-compose up \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"http://localhost\"&gt;Navigate to localhost port 80&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Click the RSS logo icon in the upper-left to start adding feed subscriptions. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Github main repository for Newsgears: &lt;a href=\"https://github.com/lostsidewalk/newsgears-app\"&gt;https://github.com/lostsidewalk/newsgears-app&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear from anyone who has an interest in RSS.  This project is still in its nascent stages, and I&amp;#39;m highly motivated to make fixes, implement features, etc.  I&amp;#39;m extremely open to suggestions, and collaborating with other devs of any skill level, on this project. Feel free to drop me a line, even if you think this is POS; I&amp;#39;d love to hear from any users.  &lt;/p&gt;\n\n&lt;p&gt;Newsgears RSS should be pretty stable on Linux w/Chrome or FF.  I wouldn&amp;#39;t be surprised if some chaos resulted from running this on another platform.  I would very much appreciate any form of feedback, especially bug reports.  &lt;/p&gt;\n\n&lt;p&gt;**Sister project:** &lt;/p&gt;\n\n&lt;p&gt;ComposableRSS is a REST API-driven platform for composing and publishing syndicated web feed content (such as RSS/ATOM feeds, etc.). Basically, you interact with an internal/developer-friendly REST API to create feeds, add content, and generally control all aspects of the web feed lifecycle. ComposableRSS serves those feeds to your users.  ComposableRSS supports formats beyond RSS and ATOM, making it suitable for use as a general-purpose headless content management system.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Github main repository for ComposableRSS: &lt;a href=\"https://github.com/lostsidewalk/composable-rss-app\"&gt;https://github.com/lostsidewalk/composable-rss-app&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a Discord to discuss matters in real-time if anyone is interested.  Thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?auto=webp&amp;s=65b6c42caa98871c0e7702bf888e21b9fbbbe688", "width": 1774, "height": 1929}, "resolutions": [{"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e528ee1c272443dd3355b63eaa4c9fa56965bfa", "width": 108, "height": 117}, {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f6d7648284f6d1af7a0e16dd1d089b0bcb5405b", "width": 216, "height": 234}, {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=760c54796c3fa67b8e1eee91da3af12569828c1d", "width": 320, "height": 347}, {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90ea9a833dea041d9ffc3290c32cb905e982b209", "width": 640, "height": 695}, {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9b9c2e003ad47ebe5b068c2510b26362db4c42ee", "width": 960, "height": 1043}, {"url": "https://external-preview.redd.it/iAX1gytVg8xseGRIrw75vVMBVLushJ4NA5zb8XC3vtM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d21802bd10f713b6f6a722666ddefae9abeb8da", "width": 1080, "height": 1174}], "variants": {}, "id": "svVu7_zWZstpjaX3XfvSMrfAajp8LwT4qHIbogWRK2k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18riu9v", "is_robot_indexable": true, "report_reasons": null, "author": "harrisofpeoria", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18riu9v/introducing_newsgears_rss_selfhosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18riu9v/introducing_newsgears_rss_selfhosted/", "subreddit_subscribers": 720766, "created_utc": 1703626333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know how to install LTO-6 LTFS Drivers for ubuntu, I cannot seem to find any that work or the links are dead. I know mine currently finds it fine as this is the response.  \n`sudo mt -f /dev/st0 status`\n\n`drive type = 114`\n\n`drive status = 1509949440`\n\n`sense key error = 0`\n\n`residue count = 0`\n\n`file number = 0`\n\n`block number = 0`\n\nI'm using Fiber connection with an LTO-6 HPE tape", "author_fullname": "t2_6cwo4rts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO-6 LTFS Ubuntu", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rird4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703626118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know how to install LTO-6 LTFS Drivers for ubuntu, I cannot seem to find any that work or the links are dead. I know mine currently finds it fine as this is the response.&lt;br/&gt;\n&lt;code&gt;sudo mt -f /dev/st0 status&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;drive type = 114&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;drive status = 1509949440&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;sense key error = 0&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;residue count = 0&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;file number = 0&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;block number = 0&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Fiber connection with an LTO-6 HPE tape&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rird4", "is_robot_indexable": true, "report_reasons": null, "author": "DrBrad__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rird4/lto6_ltfs_ubuntu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rird4/lto6_ltfs_ubuntu/", "subreddit_subscribers": 720766, "created_utc": 1703626118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently a college student in the United States looking for some kind of high capacity storage for my personal use. I currently have a 4TB WD My Passport that is almost full. Because I spend most of the year in a dorm on campus, I question the feasibility of building a NAS. I don't spend that much time in my dorm room itself, so any storage solution I use needs to be either portable or accessible anywhere. My coursework also requires me to use external storage, as I often work with very large files that cannot be feasibly stored on something like Google Drive. Is there any external SSD with 8TB or more capacity that would be worth saving money for?", "author_fullname": "t2_42lpqfn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having storage while at college?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rhfvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703622561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a college student in the United States looking for some kind of high capacity storage for my personal use. I currently have a 4TB WD My Passport that is almost full. Because I spend most of the year in a dorm on campus, I question the feasibility of building a NAS. I don&amp;#39;t spend that much time in my dorm room itself, so any storage solution I use needs to be either portable or accessible anywhere. My coursework also requires me to use external storage, as I often work with very large files that cannot be feasibly stored on something like Google Drive. Is there any external SSD with 8TB or more capacity that would be worth saving money for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rhfvo", "is_robot_indexable": true, "report_reasons": null, "author": "FunkmasterFuma", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rhfvo/having_storage_while_at_college/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rhfvo/having_storage_while_at_college/", "subreddit_subscribers": 720766, "created_utc": 1703622561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I would like to upgrade my work computer to have significantly more storage space for high speed NMVE SSDs.  \nI've read that PCI-E SATA Expansion cards aren't reliable and will give me issues.  \nDo you guys have recommendations of a solution that allows me to easily add 4-6 TB (minimum) to my workstation? Nothing too expensive, and easy to buy, if possible.  \nApologies if this is the wrong subreddit, I read the wiki as well and couldn't find a solution that fit me there.", "author_fullname": "t2_aa262", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to expand storage space on my work PC. Heard PCI-E SATA expansion cards are no good. Any recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rgt0a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703620914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I would like to upgrade my work computer to have significantly more storage space for high speed NMVE SSDs.&lt;br/&gt;\nI&amp;#39;ve read that PCI-E SATA Expansion cards aren&amp;#39;t reliable and will give me issues.&lt;br/&gt;\nDo you guys have recommendations of a solution that allows me to easily add 4-6 TB (minimum) to my workstation? Nothing too expensive, and easy to buy, if possible.&lt;br/&gt;\nApologies if this is the wrong subreddit, I read the wiki as well and couldn&amp;#39;t find a solution that fit me there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rgt0a", "is_robot_indexable": true, "report_reasons": null, "author": "Asherahi", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rgt0a/need_to_expand_storage_space_on_my_work_pc_heard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rgt0a/need_to_expand_storage_space_on_my_work_pc_heard/", "subreddit_subscribers": 720766, "created_utc": 1703620914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI\u2019m recently getting not that much on the \u201cquantity over anything else\u201d side of DataHoarder, but the \u201cquality\u201d side, as I only have about 500-1000GB of real irreplaceable data I care about (family stuff, business\u2026) and then, about 5TB of movies and TV Shows I really liked/want to watch on the future and just hoard until then\n\nAbout that 5TB, if I lose it, I don\u2019t really really care, I think of it more like on a temporary/volatile storage: I fill it with what I will need soon (I would like to watch this movie when I\u2019m travelling next time! Or when I\u2019m at the hotel on the next business trip!) but it\u2019s not like I will cry over losing \u201cBarbie\u201d (more so, I usually buy the BD if I really really enjoy a movie I have seen).\n\nBut about that 500-1000GB of personal stuff, I\u2019m starting to lose sight about how to backup it well, if what I do have any sense or could make it better or what. My current setup is:\n\n- Everything is on Google Drive (2TB), so I can access from everywhere, including phone and so on. Historic family videos there, but photos and videos taken by me, on Google Photos (and \u201cEnte\u201d service for backup, the phone uploads to both). I programmed Google Takeout to do a takeout of everything (emails, photos, contacts\u2026) into Drive.\n\nSome contents (sensitive, like business contracts) are encrypted with Cryptomator.\n\n- A NAS at home syncs Google Drive (with the \u201cCryptomator\u201d vault automatically opened) and copies syncs everything clear into an external SSD with Bitlocker (this is to have an offline copy if Internet goes out, and to avoid losing data if Cryptomator one day decides to corrupt data and can\u2019t decrypt anymore).\n\nBecause sync isn\u2019t equal to backup, then, I benefit from that clear copy to make a backup (Macrium) into the same SSD, that is copied into the local SSD and into BackBlaze B2 bucket. The two SSD are because then if one fails, I don\u2019t have to download from BackBlaze basically.\n\nI decided to program that backup as a complete backup every 2 weeks, keeping them for 2 months each, and then, daily incremental, keeping them for 20 days. I thought of going for more time or GFS strategy, but I had fear of going too deep into overthinking/overbackuping (and increasing BackBlaze bill too much for nothing).\n\nJust to finish, I created another BackBlaze bucket with the \u201cFile Lock\u201d option set to the maximum (3.000 days, no edit, no deletes once uploaded) and there I upload/manage manually to put a subset of really really important stuff from this same data, like the family videos.\n\nEverything has 2FA and so on. So at the end, I think I have:\n\n- 5 copies (hot: GDrive, local NAS Sync; mild: local NAS Backup, local external SSD Backup, BackBlaze B2 Backup, up to 2 months of completes and 20 days incrementals; cold: BackBlaze B2 File Lock manual bucket)\n\n- 3 locations (Google, BackBlaze and Local)\n\n- 2 mediums: Cloud and SSD (I was thinking about BD discs for the real important stuff also)\n\nFrom there, I just pray the NAS keeps working forever (as to avoid having to re-make the build lol), every month or 4 months, it depends, I check some of the data or read some backup to see everything is working normal, and just manage Google Drive data (upload, download, edit\u2026) and if necessary to add anything, the BackBlaze lock file bucket (\u201ccold storage\u201d).\n\nWhat do you think? Whats your setup? If you have more experience, what do you think of mine, any input (make it more simple? Something different?). Recently I started to think I maybe overthought everything and just built all that system out of boredom and overwhelmed by random fear of losing family data and so on, so IDK\n\nThanks and have great holidays everyone!", "author_fullname": "t2_1qcse6no", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your backup strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rfhpd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703617509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m recently getting not that much on the \u201cquantity over anything else\u201d side of DataHoarder, but the \u201cquality\u201d side, as I only have about 500-1000GB of real irreplaceable data I care about (family stuff, business\u2026) and then, about 5TB of movies and TV Shows I really liked/want to watch on the future and just hoard until then&lt;/p&gt;\n\n&lt;p&gt;About that 5TB, if I lose it, I don\u2019t really really care, I think of it more like on a temporary/volatile storage: I fill it with what I will need soon (I would like to watch this movie when I\u2019m travelling next time! Or when I\u2019m at the hotel on the next business trip!) but it\u2019s not like I will cry over losing \u201cBarbie\u201d (more so, I usually buy the BD if I really really enjoy a movie I have seen).&lt;/p&gt;\n\n&lt;p&gt;But about that 500-1000GB of personal stuff, I\u2019m starting to lose sight about how to backup it well, if what I do have any sense or could make it better or what. My current setup is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Everything is on Google Drive (2TB), so I can access from everywhere, including phone and so on. Historic family videos there, but photos and videos taken by me, on Google Photos (and \u201cEnte\u201d service for backup, the phone uploads to both). I programmed Google Takeout to do a takeout of everything (emails, photos, contacts\u2026) into Drive.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some contents (sensitive, like business contracts) are encrypted with Cryptomator.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A NAS at home syncs Google Drive (with the \u201cCryptomator\u201d vault automatically opened) and copies syncs everything clear into an external SSD with Bitlocker (this is to have an offline copy if Internet goes out, and to avoid losing data if Cryptomator one day decides to corrupt data and can\u2019t decrypt anymore).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Because sync isn\u2019t equal to backup, then, I benefit from that clear copy to make a backup (Macrium) into the same SSD, that is copied into the local SSD and into BackBlaze B2 bucket. The two SSD are because then if one fails, I don\u2019t have to download from BackBlaze basically.&lt;/p&gt;\n\n&lt;p&gt;I decided to program that backup as a complete backup every 2 weeks, keeping them for 2 months each, and then, daily incremental, keeping them for 20 days. I thought of going for more time or GFS strategy, but I had fear of going too deep into overthinking/overbackuping (and increasing BackBlaze bill too much for nothing).&lt;/p&gt;\n\n&lt;p&gt;Just to finish, I created another BackBlaze bucket with the \u201cFile Lock\u201d option set to the maximum (3.000 days, no edit, no deletes once uploaded) and there I upload/manage manually to put a subset of really really important stuff from this same data, like the family videos.&lt;/p&gt;\n\n&lt;p&gt;Everything has 2FA and so on. So at the end, I think I have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;5 copies (hot: GDrive, local NAS Sync; mild: local NAS Backup, local external SSD Backup, BackBlaze B2 Backup, up to 2 months of completes and 20 days incrementals; cold: BackBlaze B2 File Lock manual bucket)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;3 locations (Google, BackBlaze and Local)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2 mediums: Cloud and SSD (I was thinking about BD discs for the real important stuff also)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;From there, I just pray the NAS keeps working forever (as to avoid having to re-make the build lol), every month or 4 months, it depends, I check some of the data or read some backup to see everything is working normal, and just manage Google Drive data (upload, download, edit\u2026) and if necessary to add anything, the BackBlaze lock file bucket (\u201ccold storage\u201d).&lt;/p&gt;\n\n&lt;p&gt;What do you think? Whats your setup? If you have more experience, what do you think of mine, any input (make it more simple? Something different?). Recently I started to think I maybe overthought everything and just built all that system out of boredom and overwhelmed by random fear of losing family data and so on, so IDK&lt;/p&gt;\n\n&lt;p&gt;Thanks and have great holidays everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rfhpd", "is_robot_indexable": true, "report_reasons": null, "author": "outm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rfhpd/whats_your_backup_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rfhpd/whats_your_backup_strategy/", "subreddit_subscribers": 720766, "created_utc": 1703617509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The project seemingly is only supported on Mac for capture. Linux seemingly is supposed to support capture, but rarely works. \n\nAnyone got it to work?", "author_fullname": "t2_3d55bjdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DVrescue on linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rfcwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703617194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The project seemingly is only supported on Mac for capture. Linux seemingly is supposed to support capture, but rarely works. &lt;/p&gt;\n\n&lt;p&gt;Anyone got it to work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rfcwg", "is_robot_indexable": true, "report_reasons": null, "author": "Clawkikker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18rfcwg/dvrescue_on_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rfcwg/dvrescue_on_linux/", "subreddit_subscribers": 720766, "created_utc": 1703617194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My mother recently had several hours worth of VHS and 8mm home videos digitized. She now wants to find a way to share the videos with relatives and friends living around the world so that they have the opportunity to download the videos and help her identify all the people and events. I've never dealt with such large video files before and am looking for advice on how to best do this, keeping in mind that most of the people accessing the videos would be 60+ years old and not tech savy at all.\n\nI recommended sharing the files via usb drives but this was shot down due to shipping and other related costs. That and getting the addresses of all the different people who would have an interest in the videos would be difficult. She envisions sharing the videos via email using a link that can be passed on to others she may not have an email address for.  I was thinking of setting up a google drive of the videos and creating a share link but am not sure if it would work or not.  I would need to get a 2tb paid plan and am a bit worried as the paid plan mentions \"share with up to 5 people\" and I would need far more than that to be able to have viewing/downloading access.\n\nIf you have any advice, please let me know.", "author_fullname": "t2_uunpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to share 250GB of video mp4 files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rf01f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703616277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mother recently had several hours worth of VHS and 8mm home videos digitized. She now wants to find a way to share the videos with relatives and friends living around the world so that they have the opportunity to download the videos and help her identify all the people and events. I&amp;#39;ve never dealt with such large video files before and am looking for advice on how to best do this, keeping in mind that most of the people accessing the videos would be 60+ years old and not tech savy at all.&lt;/p&gt;\n\n&lt;p&gt;I recommended sharing the files via usb drives but this was shot down due to shipping and other related costs. That and getting the addresses of all the different people who would have an interest in the videos would be difficult. She envisions sharing the videos via email using a link that can be passed on to others she may not have an email address for.  I was thinking of setting up a google drive of the videos and creating a share link but am not sure if it would work or not.  I would need to get a 2tb paid plan and am a bit worried as the paid plan mentions &amp;quot;share with up to 5 people&amp;quot; and I would need far more than that to be able to have viewing/downloading access.&lt;/p&gt;\n\n&lt;p&gt;If you have any advice, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rf01f", "is_robot_indexable": true, "report_reasons": null, "author": "mixxaka", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rf01f/best_way_to_share_250gb_of_video_mp4_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rf01f/best_way_to_share_250gb_of_video_mp4_files/", "subreddit_subscribers": 720766, "created_utc": 1703616277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know how many cd rom drive a M3 Macbook Pro can handle. Planning to rip multiple cds at once.", "author_fullname": "t2_4mxsp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many cd drive on M3 Macbook Pro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18revox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703616304.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703615956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know how many cd rom drive a M3 Macbook Pro can handle. Planning to rip multiple cds at once.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18revox", "is_robot_indexable": true, "report_reasons": null, "author": "ErvSkee", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18revox/how_many_cd_drive_on_m3_macbook_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18revox/how_many_cd_drive_on_m3_macbook_pro/", "subreddit_subscribers": 720766, "created_utc": 1703615956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nA few questions regarding One Drive\n\n1. Has anyone here successfully used the OneDrive Family 365 accounts together using Rclone's union?\n\n2. Can Rclone Union work across services (Google/ MS)?\n\n3. How big of a drawback is the 400 char limit on OneDrive? Any way I can check which folders/files may break that limit?", "author_fullname": "t2_435uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OneDrive(s) Rclone Union", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18revmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703615951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;A few questions regarding One Drive&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Has anyone here successfully used the OneDrive Family 365 accounts together using Rclone&amp;#39;s union?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Can Rclone Union work across services (Google/ MS)?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How big of a drawback is the 400 char limit on OneDrive? Any way I can check which folders/files may break that limit?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "0.035PB and climbing", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18revmn", "is_robot_indexable": true, "report_reasons": null, "author": "Xirious", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18revmn/onedrives_rclone_union/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18revmn/onedrives_rclone_union/", "subreddit_subscribers": 720766, "created_utc": 1703615951.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}