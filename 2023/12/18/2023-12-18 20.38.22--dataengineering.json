{"kind": "Listing", "data": {"after": "t3_18l45pg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are you thinking about getting new skills? What will you suggest if you want to be a updated data engineer or data manager?\n\nAny certifications? Any courses? Any local or enterprise projects? Any ideas to launch your personal brand?", "author_fullname": "t2_nobkhscod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2024 Data Engineering Top Skills that you will prepare for", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kt2fc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702852013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you thinking about getting new skills? What will you suggest if you want to be a updated data engineer or data manager?&lt;/p&gt;\n\n&lt;p&gt;Any certifications? Any courses? Any local or enterprise projects? Any ideas to launch your personal brand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18kt2fc", "is_robot_indexable": true, "report_reasons": null, "author": "A-Global-Citizen", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kt2fc/2024_data_engineering_top_skills_that_you_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kt2fc/2024_data_engineering_top_skills_that_you_will/", "subreddit_subscribers": 146790, "created_utc": 1702852013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have spoken with many friends in Canada and the US. Most of them have mentioned that the demand for professionals in the data space is quite high, and there aren't many proficient data engineers or scientists available. \n\nI wanted to confirm if this is an actual scenario. I would love to hear your opinion on this. \n\nThank you.", "author_fullname": "t2_8i81bbqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that the demand for data engineers is higher, whereas the supply is low?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l0c01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702874243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have spoken with many friends in Canada and the US. Most of them have mentioned that the demand for professionals in the data space is quite high, and there aren&amp;#39;t many proficient data engineers or scientists available. &lt;/p&gt;\n\n&lt;p&gt;I wanted to confirm if this is an actual scenario. I would love to hear your opinion on this. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18l0c01", "is_robot_indexable": true, "report_reasons": null, "author": "trafalgar28", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l0c01/is_it_true_that_the_demand_for_data_engineers_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l0c01/is_it_true_that_the_demand_for_data_engineers_is/", "subreddit_subscribers": 146790, "created_utc": 1702874243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can someone with 2 years of experience with knowledge of frontend ,backend, data science, data engineering . \nAnd with a salary of fresher \ud83d\ude02", "author_fullname": "t2_7yh1jlaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are they looking for with title data science full stack engineer \ud83d\ude02", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18l9aak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I2DODH87LArpY7Q0No33HAnH9HM8iSSkxTp5zR0q_BM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702907789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can someone with 2 years of experience with knowledge of frontend ,backend, data science, data engineering . \nAnd with a salary of fresher \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nj9g27m5727c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nj9g27m5727c1.png?auto=webp&amp;s=347c1914017958f6b4f7e9894143d00a13f2ff12", "width": 864, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/nj9g27m5727c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53eef121b6d3d770eacbc4c1cd77816f1117811a", "width": 108, "height": 216}, {"url": "https://preview.redd.it/nj9g27m5727c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=63cc156ebcc7d8bf0ba7938ff8ef3573e3675ab5", "width": 216, "height": 432}, {"url": "https://preview.redd.it/nj9g27m5727c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6044c57acc15a31afe2151b098699f2ef2299a97", "width": 320, "height": 640}, {"url": "https://preview.redd.it/nj9g27m5727c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9fc2085fe28631b831089554e8f0e0b7c293bca", "width": 640, "height": 1280}], "variants": {}, "id": "CpK-Ssd2TVq8YW3JUm933R4rYDFyIwjJ9KqAr6dmjdY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "18l9aak", "is_robot_indexable": true, "report_reasons": null, "author": "Foot_Straight", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18l9aak/what_are_they_looking_for_with_title_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nj9g27m5727c1.png", "subreddit_subscribers": 146790, "created_utc": 1702907789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bachelor\u2019s degree in economics and have been working as a business analyst for 2 years. Part of my job involves writing SQL queries for reports and I\u2019ve enjoyed it so far.\nNow I\u2019m looking to transition into a data engineering career. \nMy employer offers tuition assistance, so I\u2019m planning on doing an online program while working as a BA. My options are the following:\n1. MS Computer Information Systems at Boston University with a concentration in database management and business intelligence ($30,000)\n2. BS Computer Science at WGU ($15,000)\n\nWhich would prepare me more for a data engineering career?", "author_fullname": "t2_5uz2eb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best degree for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18krumy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702848706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bachelor\u2019s degree in economics and have been working as a business analyst for 2 years. Part of my job involves writing SQL queries for reports and I\u2019ve enjoyed it so far.\nNow I\u2019m looking to transition into a data engineering career. \nMy employer offers tuition assistance, so I\u2019m planning on doing an online program while working as a BA. My options are the following:\n1. MS Computer Information Systems at Boston University with a concentration in database management and business intelligence ($30,000)\n2. BS Computer Science at WGU ($15,000)&lt;/p&gt;\n\n&lt;p&gt;Which would prepare me more for a data engineering career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18krumy", "is_robot_indexable": true, "report_reasons": null, "author": "abc__901", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18krumy/best_degree_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18krumy/best_degree_for_data_engineering/", "subreddit_subscribers": 146790, "created_utc": 1702848706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm developing a data pipeline that takes data from a video game API about player's matches, transforms the data, and loads it into the database.\n\nFirst, I have to get a list of all the match IDs in order to then access their info, but in order to prevent duplicate entries to the player\\_matches table, I remove the match IDs that I already have in my database, from the list of match IDs I receive in the current call.\n\nThe problem comes when I want to do testing on any step in the pipeline, when there are no matches found. If there are no matches found, then the program rightfully exits early because all the subsequent logic is for processing new matches not already in the database.\n\nI had the idea of setting a development flag that would rollback and changes to the database if it's set. That way, I can always test the entirety of the pipeline without having to find new player that have played matches in real time since I last ran the pipeline.\n\nAfter talking about this with ChatGPT, it said this is called a \"dry run.\" I'm not seeing a whole lot of information about it online, so I'm wondering if this is normal practice when developing data pipelines.\n\nEdit: I'm fairly confident this problem has nothing to do with my environment setup or having multiple database environments either. This is a pipeline problem only", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is doing a \"dry run\" of a data pipeline - so that changes to the database are either rolled back or not committed, for testing purposes - normal practice in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kqo3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702847010.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702845590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m developing a data pipeline that takes data from a video game API about player&amp;#39;s matches, transforms the data, and loads it into the database.&lt;/p&gt;\n\n&lt;p&gt;First, I have to get a list of all the match IDs in order to then access their info, but in order to prevent duplicate entries to the player_matches table, I remove the match IDs that I already have in my database, from the list of match IDs I receive in the current call.&lt;/p&gt;\n\n&lt;p&gt;The problem comes when I want to do testing on any step in the pipeline, when there are no matches found. If there are no matches found, then the program rightfully exits early because all the subsequent logic is for processing new matches not already in the database.&lt;/p&gt;\n\n&lt;p&gt;I had the idea of setting a development flag that would rollback and changes to the database if it&amp;#39;s set. That way, I can always test the entirety of the pipeline without having to find new player that have played matches in real time since I last ran the pipeline.&lt;/p&gt;\n\n&lt;p&gt;After talking about this with ChatGPT, it said this is called a &amp;quot;dry run.&amp;quot; I&amp;#39;m not seeing a whole lot of information about it online, so I&amp;#39;m wondering if this is normal practice when developing data pipelines.&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m fairly confident this problem has nothing to do with my environment setup or having multiple database environments either. This is a pipeline problem only&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18kqo3p", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kqo3p/is_doing_a_dry_run_of_a_data_pipeline_so_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kqo3p/is_doing_a_dry_run_of_a_data_pipeline_so_that/", "subreddit_subscribers": 146790, "created_utc": 1702845590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been hearing the term \u201creal-time data integration\u201d a lot in the business meetings lately, but i haven\u2019t really came a cross any business situation where real time is really needed (especially in startups and retail and saas companies where I work)\n\nso, is it really beneficial for businesses? what cases or scenarios real time will be helpful?", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realtime sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l7gcz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702902281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been hearing the term \u201creal-time data integration\u201d a lot in the business meetings lately, but i haven\u2019t really came a cross any business situation where real time is really needed (especially in startups and retail and saas companies where I work)&lt;/p&gt;\n\n&lt;p&gt;so, is it really beneficial for businesses? what cases or scenarios real time will be helpful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18l7gcz", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l7gcz/realtime_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l7gcz/realtime_sync/", "subreddit_subscribers": 146790, "created_utc": 1702902281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious as to where Databricks SQL and Warehouses actually fit into the lakehouse medallion architecture? Databricks material says that Databricks SQL is used for data warehousing on the lakehouse. Great, but it really just seems like Databricks SQL is designed for analysts who just want to query existing tables and objects to support a report. However, when I think of \"data warehousing\", I think of transforming raw data into dimensional models to support analysts and their queries.\n\nDoes Databricks just refer to \"Data Warehousing\" as the ability to query tables in the lakehouse and provide an endpoint for BI tools? That doesn't really seem like \"data warehousing\" to me, but rather just analytics. or am I wrong here?\n\nLets assume DBMS -&gt; Landing (Ephemeral) -&gt; Bronze (CDC Appends) -&gt; Silver (Integrated 3NF) -&gt; Gold (facts &amp; dimensions). What is exactly is the role of Databricks SQL and Warehouses here? Is Databricks SQL just being used as an interactive query engine for analysts that want to write ad-hoc SQL queries on top of silver or gold tables? Or does Databricks SQL have a larger role to be used by BI Developers to build and update the Fact and Dimensions in Gold?", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks SQL and Warehouses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lery0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702921811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious as to where Databricks SQL and Warehouses actually fit into the lakehouse medallion architecture? Databricks material says that Databricks SQL is used for data warehousing on the lakehouse. Great, but it really just seems like Databricks SQL is designed for analysts who just want to query existing tables and objects to support a report. However, when I think of &amp;quot;data warehousing&amp;quot;, I think of transforming raw data into dimensional models to support analysts and their queries.&lt;/p&gt;\n\n&lt;p&gt;Does Databricks just refer to &amp;quot;Data Warehousing&amp;quot; as the ability to query tables in the lakehouse and provide an endpoint for BI tools? That doesn&amp;#39;t really seem like &amp;quot;data warehousing&amp;quot; to me, but rather just analytics. or am I wrong here?&lt;/p&gt;\n\n&lt;p&gt;Lets assume DBMS -&amp;gt; Landing (Ephemeral) -&amp;gt; Bronze (CDC Appends) -&amp;gt; Silver (Integrated 3NF) -&amp;gt; Gold (facts &amp;amp; dimensions). What is exactly is the role of Databricks SQL and Warehouses here? Is Databricks SQL just being used as an interactive query engine for analysts that want to write ad-hoc SQL queries on top of silver or gold tables? Or does Databricks SQL have a larger role to be used by BI Developers to build and update the Fact and Dimensions in Gold?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lery0", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lery0/databricks_sql_and_warehouses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lery0/databricks_sql_and_warehouses/", "subreddit_subscribers": 146790, "created_utc": 1702921811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nMy company allocates some budget for training purpose, we can make use of this budget to buy some learning materials. Im looking for courses that take my data engineering from intermediate to advanced level. ( I would like to go indepth of advance concepts). Are there any course which can help me?  \n\n\nArea of interest:  \n\n\n1. Python ( coding )\n2. Data Warehouse / data modelling\n3. AWS for data analytics/engineering\n4. Distributed systems\n\netc....  \n", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paid courses for excelling data engineering skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l9vbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702909389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;My company allocates some budget for training purpose, we can make use of this budget to buy some learning materials. Im looking for courses that take my data engineering from intermediate to advanced level. ( I would like to go indepth of advance concepts). Are there any course which can help me?  &lt;/p&gt;\n\n&lt;p&gt;Area of interest:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python ( coding )&lt;/li&gt;\n&lt;li&gt;Data Warehouse / data modelling&lt;/li&gt;\n&lt;li&gt;AWS for data analytics/engineering&lt;/li&gt;\n&lt;li&gt;Distributed systems&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;etc....  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l9vbb", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18l9vbb/paid_courses_for_excelling_data_engineering_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l9vbb/paid_courses_for_excelling_data_engineering_skills/", "subreddit_subscribers": 146790, "created_utc": 1702909389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New data engineer here (team of 1) looking for inspiration on how to improve a process!\n\nCurrently dagster open source runs on a windows machine behind our firewall. This machine orchestrates python scripts (etl, reporting, events, DBT in bigquery, etc). A primary source is sql server, which I am currently querying with this machine, loading data into pandas, then using the pandas bigquery library to upload to bigquery tables.\n\nIt has been fine with many dimensional tables but I have been running into issues adding more large table ingests. Primarily it is just exhausting memory and just slowing down the process, especially on backfills of big tables. I know that I could potentially query and store in memory using an arrow ready format vs data frames, but before I make those changes what would be the most elegant way to handle this? Should I move the execution off of this machine into either gcp or the sql server in some way?", "author_fullname": "t2_ronx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about a system design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kvzzk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702860308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New data engineer here (team of 1) looking for inspiration on how to improve a process!&lt;/p&gt;\n\n&lt;p&gt;Currently dagster open source runs on a windows machine behind our firewall. This machine orchestrates python scripts (etl, reporting, events, DBT in bigquery, etc). A primary source is sql server, which I am currently querying with this machine, loading data into pandas, then using the pandas bigquery library to upload to bigquery tables.&lt;/p&gt;\n\n&lt;p&gt;It has been fine with many dimensional tables but I have been running into issues adding more large table ingests. Primarily it is just exhausting memory and just slowing down the process, especially on backfills of big tables. I know that I could potentially query and store in memory using an arrow ready format vs data frames, but before I make those changes what would be the most elegant way to handle this? Should I move the execution off of this machine into either gcp or the sql server in some way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18kvzzk", "is_robot_indexable": true, "report_reasons": null, "author": "seanpool3", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18kvzzk/question_about_a_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kvzzk/question_about_a_system_design/", "subreddit_subscribers": 146790, "created_utc": 1702860308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When we were a smaller company, Fivetran made sense due to the value vs effort. We still like them but we are definitely being penalized for high amounts of MAR.\n\nBasically, we have activity data that we record and would like to do analytics on top of it. This data was low at one point and has now increased. This data also lives in the same relational db as the other tables so ideally I'd want a connector that can reliably sync all the data.\n\nWhat alternatives would you recommend for Aurora PostgreSQL database sync to snowflake? Small team so need something as decent as fivetran without any headaches. We are willing to pay, just way less than what they're charging us.", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran alternatives for Amazon Aurora PostgreSQL to Snowflake ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lda1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702918104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When we were a smaller company, Fivetran made sense due to the value vs effort. We still like them but we are definitely being penalized for high amounts of MAR.&lt;/p&gt;\n\n&lt;p&gt;Basically, we have activity data that we record and would like to do analytics on top of it. This data was low at one point and has now increased. This data also lives in the same relational db as the other tables so ideally I&amp;#39;d want a connector that can reliably sync all the data.&lt;/p&gt;\n\n&lt;p&gt;What alternatives would you recommend for Aurora PostgreSQL database sync to snowflake? Small team so need something as decent as fivetran without any headaches. We are willing to pay, just way less than what they&amp;#39;re charging us.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lda1q", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lda1q/fivetran_alternatives_for_amazon_aurora/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lda1q/fivetran_alternatives_for_amazon_aurora/", "subreddit_subscribers": 146790, "created_utc": 1702918104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI'm doing an internship research on the future of our intern datawarehouse (quite simple dwh) and facing the decision between Azure Data Factory (pipelines and dataflows) and SSIS Packages (run by Integration Runtime). Wondering if there's any research or experiences on which performs better in different scenarios and considerations when making the choice.\n\nSpecifically:\n\n1. **Scenarios:** When does Azure Data Factory outperform SSIS Packages and vice versa? Any standout use cases for each?\n2. **Building a New Data Warehouse:** Which is more suitable when setting up a new data warehouse? Any specific pros or cons to be aware of?\n3. **Cost Efficiency:** Generally, which option is more cost-efficient? Any hidden costs to consider?\n4. **Futureproofing:** With evolving tech landscapes, which is more futureproof? Any trends indicating a preference over the long term?\n\nAppreciate your insights and experiences. If you've conducted research or can recommend resources, please share. \n\nThanks!", "author_fullname": "t2_744ig7bc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question: Azure Data Factory vs. SSIS Packages - Best Choice for a New (simple) Data Warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l3779", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702885156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing an internship research on the future of our intern datawarehouse (quite simple dwh) and facing the decision between Azure Data Factory (pipelines and dataflows) and SSIS Packages (run by Integration Runtime). Wondering if there&amp;#39;s any research or experiences on which performs better in different scenarios and considerations when making the choice.&lt;/p&gt;\n\n&lt;p&gt;Specifically:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Scenarios:&lt;/strong&gt; When does Azure Data Factory outperform SSIS Packages and vice versa? Any standout use cases for each?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Building a New Data Warehouse:&lt;/strong&gt; Which is more suitable when setting up a new data warehouse? Any specific pros or cons to be aware of?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost Efficiency:&lt;/strong&gt; Generally, which option is more cost-efficient? Any hidden costs to consider?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Futureproofing:&lt;/strong&gt; With evolving tech landscapes, which is more futureproof? Any trends indicating a preference over the long term?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Appreciate your insights and experiences. If you&amp;#39;ve conducted research or can recommend resources, please share. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l3779", "is_robot_indexable": true, "report_reasons": null, "author": "NoAbbreviations8629", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l3779/question_azure_data_factory_vs_ssis_packages_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l3779/question_azure_data_factory_vs_ssis_packages_best/", "subreddit_subscribers": 146790, "created_utc": 1702885156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, suggest a data pipeline to read sales data from a website and send a notification if a product crosses x number of orders in last 1 hour. Use cloud computing.\n\nMy thought is to do something like below, please help with suggestions:\n\nWebserver &gt; aws managed kafka &gt; spark structured streaming with 5 min sliding window over 1 hour &gt; store 5 min aggregate in a time series db like influx &gt; lambda to aggregate over 1 hour and send sns notifications, schedule lambda to run every 5 mins &gt; delete data older than 1 hour in database.", "author_fullname": "t2_kfvc08j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design a real time notification system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ky2wk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702866863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, suggest a data pipeline to read sales data from a website and send a notification if a product crosses x number of orders in last 1 hour. Use cloud computing.&lt;/p&gt;\n\n&lt;p&gt;My thought is to do something like below, please help with suggestions:&lt;/p&gt;\n\n&lt;p&gt;Webserver &amp;gt; aws managed kafka &amp;gt; spark structured streaming with 5 min sliding window over 1 hour &amp;gt; store 5 min aggregate in a time series db like influx &amp;gt; lambda to aggregate over 1 hour and send sns notifications, schedule lambda to run every 5 mins &amp;gt; delete data older than 1 hour in database.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ky2wk", "is_robot_indexable": true, "report_reasons": null, "author": "RepulsiveCry8412", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ky2wk/design_a_real_time_notification_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ky2wk/design_a_real_time_notification_system/", "subreddit_subscribers": 146790, "created_utc": 1702866863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! Data Analyst with 5 years of experience here. I have been using SQL and Python in my job, but it hasn't been anything too advanced. SQL has mainly been queries that have involved CTEs and the fundementals (WHERE vs. HAVING, INNER/LEFT JOINS, UNION vs. UNION ALL, some windows functions when needed like LAG and LEAD), and Python has been data exploration in Pandas and some web scraping.\n\nA few months ago I began getting interested in Data Engineering and doing some basic projects involving getting information out of an API, cleaning it, and having it run in Pandas. I have done 2 projects in AWS using many of their systems, but it has very much been a \"follow along\".\n\nThe job description says\n\n* Advanced SQL Skills expected\n\n* Python skills required.\n\n* AWS experienced required.\n\nI feel like I am just very basic in all of those, although my fundamentals are good.\n\nWhat are some questions you may expect to be asked in each? Just curious if anyone has any first-hand experience with interviews lately, or have interviewed folks!\n\nI'm nervous and excited! Thanks!", "author_fullname": "t2_6iptp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Interview incoming! Can I have some advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kwb0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702861505.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702861250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! Data Analyst with 5 years of experience here. I have been using SQL and Python in my job, but it hasn&amp;#39;t been anything too advanced. SQL has mainly been queries that have involved CTEs and the fundementals (WHERE vs. HAVING, INNER/LEFT JOINS, UNION vs. UNION ALL, some windows functions when needed like LAG and LEAD), and Python has been data exploration in Pandas and some web scraping.&lt;/p&gt;\n\n&lt;p&gt;A few months ago I began getting interested in Data Engineering and doing some basic projects involving getting information out of an API, cleaning it, and having it run in Pandas. I have done 2 projects in AWS using many of their systems, but it has very much been a &amp;quot;follow along&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The job description says&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Advanced SQL Skills expected&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Python skills required.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AWS experienced required.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I feel like I am just very basic in all of those, although my fundamentals are good.&lt;/p&gt;\n\n&lt;p&gt;What are some questions you may expect to be asked in each? Just curious if anyone has any first-hand experience with interviews lately, or have interviewed folks!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m nervous and excited! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18kwb0r", "is_robot_indexable": true, "report_reasons": null, "author": "tits_mcgee_92", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kwb0r/data_engineer_interview_incoming_can_i_have_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kwb0r/data_engineer_interview_incoming_can_i_have_some/", "subreddit_subscribers": 146790, "created_utc": 1702861250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in charge of, or rather I volunteered to create the documentation that will be the foundation for the development of data pipelines and ETL processes using Python. Part of that documentation includes establishing the configuration/environment used for development. (We currently use SSIS and SQL Server for our pipelines)\n\nI will be using Visual Studio Code and Python 3.\n\nWhat extensions would you recommend that would help with Data Engineering with Python?\n\nIn addition, what extensions would help with other necessary steps in development, such as Version Control, syntax (PEP8), and Testing?", "author_fullname": "t2_aiumhm29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python for Data Engineering VSCode Extensions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lcjqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702916251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in charge of, or rather I volunteered to create the documentation that will be the foundation for the development of data pipelines and ETL processes using Python. Part of that documentation includes establishing the configuration/environment used for development. (We currently use SSIS and SQL Server for our pipelines)&lt;/p&gt;\n\n&lt;p&gt;I will be using Visual Studio Code and Python 3.&lt;/p&gt;\n\n&lt;p&gt;What extensions would you recommend that would help with Data Engineering with Python?&lt;/p&gt;\n\n&lt;p&gt;In addition, what extensions would help with other necessary steps in development, such as Version Control, syntax (PEP8), and Testing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lcjqp", "is_robot_indexable": true, "report_reasons": null, "author": "Upbeat_Count_7568", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lcjqp/python_for_data_engineering_vscode_extensions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lcjqp/python_for_data_engineering_vscode_extensions/", "subreddit_subscribers": 146790, "created_utc": 1702916251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there! \n\nI\u2019m here to take your advice and inputs on the cloud and let me tell you a backstory. \n\nMost of the people I meet who is on data(Data Engineering, Data visualisation, data analysis or whatever on data) are advising me to go with cloud (mostly Azure and AWS) but nobody is telling anything about anything specific or if there is anything specific related data? \n\nBasically I\u2019m new to cloud and appreciate any information on this that can help.", "author_fullname": "t2_484n21ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specifics on cloud for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l6tlv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702900050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m here to take your advice and inputs on the cloud and let me tell you a backstory. &lt;/p&gt;\n\n&lt;p&gt;Most of the people I meet who is on data(Data Engineering, Data visualisation, data analysis or whatever on data) are advising me to go with cloud (mostly Azure and AWS) but nobody is telling anything about anything specific or if there is anything specific related data? &lt;/p&gt;\n\n&lt;p&gt;Basically I\u2019m new to cloud and appreciate any information on this that can help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18l6tlv", "is_robot_indexable": true, "report_reasons": null, "author": "Solivagant_here", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l6tlv/specifics_on_cloud_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l6tlv/specifics_on_cloud_for_data_engineers/", "subreddit_subscribers": 146790, "created_utc": 1702900050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, Right now I am working on a project that needs Databricks and BI experience. Can you guys suggest some real time experience courses for both Databricks and Power BI", "author_fullname": "t2_nlmrmy2ow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best course for Databricks and BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18lhjsr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702928583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Right now I am working on a project that needs Databricks and BI experience. Can you guys suggest some real time experience courses for both Databricks and Power BI&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18lhjsr", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Koala_609", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lhjsr/best_course_for_databricks_and_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lhjsr/best_course_for_databricks_and_bi/", "subreddit_subscribers": 146790, "created_utc": 1702928583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DE!\n\nI'm on the lookout for the perfect orchestration solution, but I'm not quite seasoned enough to be aware of all the options out there. Here's the challenge: I have a customer who lays out ETL/ELT tasks in extensive flow diagrams with intricate conditions and interactions.\n\nWhat I'm after is a solution that allows these tasks to be relatively atomic for easy testing, yet straightforward to define and code. Additionally, I need support for ML workflows, flow versioning, and the flexibility to deploy both in the cloud and locally. Ideally, I'm aiming for something lightweight that can effortlessly work with minimal setup, drawing from a configuration source featuring DAGs and tasks.\n\nI'm aware of another team in my company working on a substantial system for a similar task, leveraging Kafka, Kubernetes, and node-red. However, this setup seems a bit too hefty for my needs, and I'm not a fan of how they are hardcoding custom tasks in node-red.\n\nI also found this awesome list of [workflow engines](https://github.com/meirwah/awesome-workflow-engines)\n\nAny suggestions or recommendations for a solution that strikes the right balance for my requirements? Thanks in advance!", "author_fullname": "t2_7i2kfbec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best user friendly orchestration tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lf3uj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702922607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DE!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the lookout for the perfect orchestration solution, but I&amp;#39;m not quite seasoned enough to be aware of all the options out there. Here&amp;#39;s the challenge: I have a customer who lays out ETL/ELT tasks in extensive flow diagrams with intricate conditions and interactions.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m after is a solution that allows these tasks to be relatively atomic for easy testing, yet straightforward to define and code. Additionally, I need support for ML workflows, flow versioning, and the flexibility to deploy both in the cloud and locally. Ideally, I&amp;#39;m aiming for something lightweight that can effortlessly work with minimal setup, drawing from a configuration source featuring DAGs and tasks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of another team in my company working on a substantial system for a similar task, leveraging Kafka, Kubernetes, and node-red. However, this setup seems a bit too hefty for my needs, and I&amp;#39;m not a fan of how they are hardcoding custom tasks in node-red.&lt;/p&gt;\n\n&lt;p&gt;I also found this awesome list of &lt;a href=\"https://github.com/meirwah/awesome-workflow-engines\"&gt;workflow engines&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or recommendations for a solution that strikes the right balance for my requirements? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?auto=webp&amp;s=b1fe2cc2ffd4873a5d343debf9808bb93b2dda1d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43acdbac9b761d7856283ff0546bcc148ceed9d2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f37a04aebefac1e04fdf4aa4f2f317eed939547", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b1fe2d902f40d902f2a7aba37b9bdfecdd241d14", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c756d6046c053bb95216b4c3b5497adba34e393d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6e1147407d0942d0dd9a5abd75bd67b94c3c0f87", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a74d378d3d7f80dc71c79d33ee779f49074f9a70", "width": 1080, "height": 540}], "variants": {}, "id": "AEPkqSVO-ZS9X-zj_UTJDoVNL-W4vCzHWkMh32X3mbc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18lf3uj", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible-Rule3619", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lf3uj/best_user_friendly_orchestration_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lf3uj/best_user_friendly_orchestration_tool/", "subreddit_subscribers": 146790, "created_utc": 1702922607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\n\nFor better or for worse,I have 31 tables under a dataset in GCP that are tied to an individual tab in a gsheet which automatically pulls in data once it is entered.\n\nAll I really need to do is union them all and do some transformation on them on this intermediate table before finally pushing out a final reporting table.\n\nI can't do the wildcard * select that GCP supports because the tables have slightly different schemas but they do have a common set of columns.\n\nI don't want to code it all in SQL since new tables may land in this dataset so I was thinking of something more automated via Python on GCP.\n\nHas anyone dealt with something like this, any thoughts?\n\nSome ideas I had were:\n\n* Using cloud functions and the big frames API to loop through each table and combine them and pushing them out to an intermediate table.\n\n* (Less Preferred) but use procedural SQL that BigQuery supports and create an automatic sql string that way", "author_fullname": "t2_zhg21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle 31 mini tables in GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l8wm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702906736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;For better or for worse,I have 31 tables under a dataset in GCP that are tied to an individual tab in a gsheet which automatically pulls in data once it is entered.&lt;/p&gt;\n\n&lt;p&gt;All I really need to do is union them all and do some transformation on them on this intermediate table before finally pushing out a final reporting table.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t do the wildcard * select that GCP supports because the tables have slightly different schemas but they do have a common set of columns.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to code it all in SQL since new tables may land in this dataset so I was thinking of something more automated via Python on GCP.&lt;/p&gt;\n\n&lt;p&gt;Has anyone dealt with something like this, any thoughts?&lt;/p&gt;\n\n&lt;p&gt;Some ideas I had were:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Using cloud functions and the big frames API to loop through each table and combine them and pushing them out to an intermediate table.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;(Less Preferred) but use procedural SQL that BigQuery supports and create an automatic sql string that way&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l8wm1", "is_robot_indexable": true, "report_reasons": null, "author": "studentofarkad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l8wm1/how_to_handle_31_mini_tables_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l8wm1/how_to_handle_31_mini_tables_in_gcp/", "subreddit_subscribers": 146790, "created_utc": 1702906736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  I work in finance and I\u2019m on a B.I. team which mainly uses Power BI as its analysis tool and Dremio to obtain this data; there\u2019s a table  that\u2019s used by most apps and it\u2019s heavy, which means that many times the load will break due to version recovery conflicts.\n\n  The problem is that 100s of apps use slightly different versions of this query and all of them are refreshed daily, making it really heavy on the server, kind of redundant and also very prone to NOT update correctly.\n\n  The current data pipeline is PostgreSQL &gt; Dremio &gt; ODBC connection in PBI. We want to have one main source so that the table is refreshed only once per day, avoiding useless refreshes; dataflow + incremental refresh is out of questions since manager is not willing to pay for PBI premium.\n\n  I\u2019m fairly proficient with python, which means that using airflow I could create a script that performs this incremental refresh and saves the table as .parquet, however, this is kind of reinventing the wheel, since the database and datalake should already be performing this part of the task.\n\n  My question is: how should I approach this? I\u2019m willing to use/learn any technology that helps me solve this issue (since I want to eventually become a data engineer).\n\n  My current idea would be saving the whole data to a .parquet and have all the apps reading from this file, since it will be updated daily and PBI is good at reading .parquet files. I understand that having the apps use incremental refresh could solve this issue, however we can almost never get it to do the initial load.", "author_fullname": "t2_h8ts7kb34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help to avoid having multiple apps refreshing the same information separately", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l8sr3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702906428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in finance and I\u2019m on a B.I. team which mainly uses Power BI as its analysis tool and Dremio to obtain this data; there\u2019s a table  that\u2019s used by most apps and it\u2019s heavy, which means that many times the load will break due to version recovery conflicts.&lt;/p&gt;\n\n&lt;p&gt;The problem is that 100s of apps use slightly different versions of this query and all of them are refreshed daily, making it really heavy on the server, kind of redundant and also very prone to NOT update correctly.&lt;/p&gt;\n\n&lt;p&gt;The current data pipeline is PostgreSQL &amp;gt; Dremio &amp;gt; ODBC connection in PBI. We want to have one main source so that the table is refreshed only once per day, avoiding useless refreshes; dataflow + incremental refresh is out of questions since manager is not willing to pay for PBI premium.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m fairly proficient with python, which means that using airflow I could create a script that performs this incremental refresh and saves the table as .parquet, however, this is kind of reinventing the wheel, since the database and datalake should already be performing this part of the task.&lt;/p&gt;\n\n&lt;p&gt;My question is: how should I approach this? I\u2019m willing to use/learn any technology that helps me solve this issue (since I want to eventually become a data engineer).&lt;/p&gt;\n\n&lt;p&gt;My current idea would be saving the whole data to a .parquet and have all the apps reading from this file, since it will be updated daily and PBI is good at reading .parquet files. I understand that having the apps use incremental refresh could solve this issue, however we can almost never get it to do the initial load.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l8sr3", "is_robot_indexable": true, "report_reasons": null, "author": "gbarza", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l8sr3/need_help_to_avoid_having_multiple_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l8sr3/need_help_to_avoid_having_multiple_apps/", "subreddit_subscribers": 146790, "created_utc": 1702906428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to get thoughts on how to best solve this problem. \n\nThe platform I\u2019m working on has about 10m records that are searchable by the user. We currently showcase all attributes in this view on the UI and can include up to 140 attributes but creating a complex query that pulls in the data from all the various tables into one big view. \n\nWhen the user undertakes a CRUD on the main\ndatabase (MSSQL) changes happen instantly. \n\nWe then have an app function that goes off an d generates the massive SQL query to execute and then we push that result back into elasticsearch. This process is the bottleneck. \n\nI\u2019m think of using CDC or something similar to stream changes into elasticsearch instead. \n\nAny thoughts or experiences with data steaming from MSSQL into elasticsearch ?", "author_fullname": "t2_xhvhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSSQL to ElasticSearch streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l8fk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702905351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to get thoughts on how to best solve this problem. &lt;/p&gt;\n\n&lt;p&gt;The platform I\u2019m working on has about 10m records that are searchable by the user. We currently showcase all attributes in this view on the UI and can include up to 140 attributes but creating a complex query that pulls in the data from all the various tables into one big view. &lt;/p&gt;\n\n&lt;p&gt;When the user undertakes a CRUD on the main\ndatabase (MSSQL) changes happen instantly. &lt;/p&gt;\n\n&lt;p&gt;We then have an app function that goes off an d generates the massive SQL query to execute and then we push that result back into elasticsearch. This process is the bottleneck. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m think of using CDC or something similar to stream changes into elasticsearch instead. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts or experiences with data steaming from MSSQL into elasticsearch ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l8fk5", "is_robot_indexable": true, "report_reasons": null, "author": "jinsy1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l8fk5/mssql_to_elasticsearch_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l8fk5/mssql_to_elasticsearch_streaming/", "subreddit_subscribers": 146790, "created_utc": 1702905351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m new to the field. I\u2019m a BI analyst and trying to learn DE concept\u2019s because i find it quite interesting! \n\nI\u2019ve heard someone asking about this case: Same client in different systems, have different IDs. \nFor example client A in the marketing system its ID = 136 \nbut in the accounting system, client A ID = 510\n\nin the above situation, how they can be mapped? I mean what is the method called? \n\nbecause in a BI analyst pov i only join IDs to generate the report. But i didn\u2019t know that something similar happens in the backend. \n\nso, i am curious to learn more about it and search it up but i couldn\u2019t do a proper searching because i don\u2019t know whats the method called.", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l7y53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702903856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m new to the field. I\u2019m a BI analyst and trying to learn DE concept\u2019s because i find it quite interesting! &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve heard someone asking about this case: Same client in different systems, have different IDs. \nFor example client A in the marketing system its ID = 136 \nbut in the accounting system, client A ID = 510&lt;/p&gt;\n\n&lt;p&gt;in the above situation, how they can be mapped? I mean what is the method called? &lt;/p&gt;\n\n&lt;p&gt;because in a BI analyst pov i only join IDs to generate the report. But i didn\u2019t know that something similar happens in the backend. &lt;/p&gt;\n\n&lt;p&gt;so, i am curious to learn more about it and search it up but i couldn\u2019t do a proper searching because i don\u2019t know whats the method called.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18l7y53", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l7y53/data_governance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l7y53/data_governance/", "subreddit_subscribers": 146790, "created_utc": 1702903856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have an api link for a csv file with a username and password how can i upload it to dataiku", "author_fullname": "t2_7ps6tajn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "uploading data to dataiku", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l7sln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702903365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have an api link for a csv file with a username and password how can i upload it to dataiku&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l7sln", "is_robot_indexable": true, "report_reasons": null, "author": "Shoddy_Quality", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l7sln/uploading_data_to_dataiku/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l7sln/uploading_data_to_dataiku/", "subreddit_subscribers": 146790, "created_utc": 1702903365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to ingest Salesforce data/tables into Snowflake.   \nAnyone has worked on a resilient data ingestion pipelines? Are they custom pipelines or have used ingestion tools like airbyte or Fivetron. Please share your thoughts. ", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion form salesforce to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18l46d7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702889317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to ingest Salesforce data/tables into Snowflake.&lt;br/&gt;\nAnyone has worked on a resilient data ingestion pipelines? Are they custom pipelines or have used ingestion tools like airbyte or Fivetron. Please share your thoughts. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18l46d7", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l46d7/data_ingestion_form_salesforce_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l46d7/data_ingestion_form_salesforce_to_snowflake/", "subreddit_subscribers": 146790, "created_utc": 1702889317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I've put together a Docker Compose setup that includes tools like Hadoop, Hive, Spark, PySpark, Jupyter, and Airflow. It's designed to be easy for anyone to set up and start using.\n\nJust clone the [repository](https://github.com/carteakey/data-pipeline-compose) and spin up all services using \\`docker compose up -d\\`.\n\nThe purpose is to just streamline the initial configuration process without the usual setup hassles, which can often be a roadblock for someone trying to get their hands into DE.\n\nLet me know if you have any suggestions / feedback.", "author_fullname": "t2_dy2vwvki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data-pipeline-compose - Data Engineering environment setup using Docker Compose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18kqgcq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702845962.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702845018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;ve put together a Docker Compose setup that includes tools like Hadoop, Hive, Spark, PySpark, Jupyter, and Airflow. It&amp;#39;s designed to be easy for anyone to set up and start using.&lt;/p&gt;\n\n&lt;p&gt;Just clone the &lt;a href=\"https://github.com/carteakey/data-pipeline-compose\"&gt;repository&lt;/a&gt; and spin up all services using `docker compose up -d`.&lt;/p&gt;\n\n&lt;p&gt;The purpose is to just streamline the initial configuration process without the usual setup hassles, which can often be a roadblock for someone trying to get their hands into DE.&lt;/p&gt;\n\n&lt;p&gt;Let me know if you have any suggestions / feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?auto=webp&amp;s=36bf0a22bba6a2a7d1d4b79a57ae8a4747d31b21", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a38719866a3a024c5cae9c40e8d7114a86d5dc1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3863951cc22e89d14d365c1a4985954eb48df551", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0742b4d74d60f7ed3d115a3ce55842fb6ef7cfb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4067d1729385147a328e04df989a90dfb686fdf6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c616e99051a82cc5406da4f2c8f4d93a70ade7d7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NjrBq4Hm5D3q71ZwAS7CxyBv__TwX1VE3VljmaU8FPI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3889262a6c4d922ceb30d055bc7589a95ee9aa58", "width": 1080, "height": 540}], "variants": {}, "id": "5sG3ddbTVX7UyJNxaXu479stuzePSzohwXGcYKXzae0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18kqgcq", "is_robot_indexable": true, "report_reasons": null, "author": "carteakey", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18kqgcq/datapipelinecompose_data_engineering_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18kqgcq/datapipelinecompose_data_engineering_environment/", "subreddit_subscribers": 146790, "created_utc": 1702845018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Line-of-Sight Analysis in Digital Elevation Models using Python](https://preview.redd.it/8brtr07yn07c1.png?width=1107&amp;format=png&amp;auto=webp&amp;s=31cbc7e5ad55619fc6743a666f897a9f6da4ce14)\n\n[Line-of-Sight Analysis in Digital Elevation Models using Python](https://spatial-dev.guru/2023/12/10/line-of-sight-analysis-in-digital-elevation-models-using-python/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Line-of-Sight Analysis in Digital Elevation Models using Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8brtr07yn07c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a49c3a2af2750d6b3a27082a5d1e35cca3f1b1d2"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d2d18da8f9aac3bff7227580b7f11d721f450c9"}, {"y": 228, "x": 320, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd417cbcdb26d30997f3b941e6dc6d9dd6640838"}, {"y": 457, "x": 640, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=49bf6ed27499444813a7979c11a6fa9bdd957468"}, {"y": 685, "x": 960, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=54380630061961c583cf6c34424283a3feace673"}, {"y": 771, "x": 1080, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99f8e3ebf6fda478b13ddeeeed44ff9ef2e8ab5a"}], "s": {"y": 791, "x": 1107, "u": "https://preview.redd.it/8brtr07yn07c1.png?width=1107&amp;format=png&amp;auto=webp&amp;s=31cbc7e5ad55619fc6743a666f897a9f6da4ce14"}, "id": "8brtr07yn07c1"}}, "name": "t3_18l45pg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/63SxyWYs6_HchEfzAOSUmEsZr_3FIIjMYnf3PXX2U30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1702889232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8brtr07yn07c1.png?width=1107&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31cbc7e5ad55619fc6743a666f897a9f6da4ce14\"&gt;Line-of-Sight Analysis in Digital Elevation Models using Python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/12/10/line-of-sight-analysis-in-digital-elevation-models-using-python/\"&gt;Line-of-Sight Analysis in Digital Elevation Models using Python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?auto=webp&amp;s=b093589fba39eafa78fa2da46be03d5b8a1b58e9", "width": 1024, "height": 715}, "resolutions": [{"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=76519dff7d4577867f88d1a37ce6f00137bbf94c", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8774c97eed81e062b9483502f2cfeb32ac0f753", "width": 216, "height": 150}, {"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63d731a9a8afa725e4aadc13b41515beda2a2aa8", "width": 320, "height": 223}, {"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cece1032cd1e79b38b16f2a4570b510a66439af0", "width": 640, "height": 446}, {"url": "https://external-preview.redd.it/7nXs1LlZ1Gx4eNGlT4PKMCJvkmFg5FZZDUneeU2v7OA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21099de2db6b77566389d20bfa1a3fdcf8fa801b", "width": 960, "height": 670}], "variants": {}, "id": "ci5YzksIc26EtEnMS73KxsdZhDJkQbC3Br6z-ycukko"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18l45pg", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18l45pg/lineofsight_analysis_in_digital_elevation_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18l45pg/lineofsight_analysis_in_digital_elevation_models/", "subreddit_subscribers": 146790, "created_utc": 1702889232.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}