{"kind": "Listing", "data": {"after": "t3_188il0x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Before end of year I hear many data influencers talking about shrinking data teams, modern data stack tools dying and AI taking over the data world. Do you guys see data engineering in such a perspective? Maybe I am wrong, but looking at the real world (not the influencer clickbait, but down to earth real world we work in), I do not see data engineering shrinking in the nearest  10 years. Most of customers I deal with are big corporates and they enjoy idea of deploying AI, cutting costs but thats just idea and branding. When you look at their stack, rate of change and business mentality (like trusting AI, governance, etc), I do not see any critical shifts nearby. For sure, AI will help writing code, analytics, but nowhere near to replace architects, devs and ops admins. Whats your take? ", "author_fullname": "t2_is8b1hg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doom predictions for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1883wyz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701408099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before end of year I hear many data influencers talking about shrinking data teams, modern data stack tools dying and AI taking over the data world. Do you guys see data engineering in such a perspective? Maybe I am wrong, but looking at the real world (not the influencer clickbait, but down to earth real world we work in), I do not see data engineering shrinking in the nearest  10 years. Most of customers I deal with are big corporates and they enjoy idea of deploying AI, cutting costs but thats just idea and branding. When you look at their stack, rate of change and business mentality (like trusting AI, governance, etc), I do not see any critical shifts nearby. For sure, AI will help writing code, analytics, but nowhere near to replace architects, devs and ops admins. Whats your take? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1883wyz", "is_robot_indexable": true, "report_reasons": null, "author": "vee920", "discussion_type": null, "num_comments": 131, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1883wyz/doom_predictions_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1883wyz/doom_predictions_for_data_engineering/", "subreddit_subscribers": 142999, "created_utc": 1701408099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&amp;#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion - Dec 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo", "t3_13xldpd", "t3_167b3ep", "t3_188grde"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1701450046.836, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ia7kdykk8dlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=814f58d3eef18e16ebfd881a24dc42c6278c74a5"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=220aef8c88d2d3542556dbc0ceda11308fae54cd"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc0f5873d0a5e748e4664a4925eb409775331c20"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd"}, "id": "ia7kdykk8dlb1"}}, "name": "t3_188grde", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 17, "domain": "self.dataengineering", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/WxbPZZDAlp5ZrmC7zINz_BAGO251Q2TbQDAOSYvGspE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1701450046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\"&gt;https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://tally.so/r/nraYkN\"&gt;Submit your salary here&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can view and analyze all of the data on our &lt;a href=\"https://dataengineering.wiki/Community/Salaries\"&gt;DE salary page&lt;/a&gt; and get involved with this open-source project &lt;a href=\"https://github.com/data-engineering-community/data-engineering-salaries\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Current title&lt;/li&gt;\n&lt;li&gt;Years of experience (YOE)&lt;/li&gt;\n&lt;li&gt;Location&lt;/li&gt;\n&lt;li&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/li&gt;\n&lt;li&gt;Bonuses/Equity (optional)&lt;/li&gt;\n&lt;li&gt;Industry (optional)&lt;/li&gt;\n&lt;li&gt;Tech stack (optional)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?auto=webp&amp;s=c116639b0e48888e352e060ba2c5f56c07ab43d9", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab73c993eac3ccefd58966d64ec6e5a5dd05f808", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1955a17c66a64ef42bfc6aa52227a3b0a183660b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfad0ea778337cf0589b3428603d1e71cff228fb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a6b65e67a3bcf61b738f8852810c86c1b01298f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b95d64dc6f3995876325c594dbe2dd77c627d406", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=079bd9b9cebe8cd705d7824f7f2a75c5213c3cf7", "width": 1080, "height": 567}], "variants": {}, "id": "vXOF8G9GBUU_-_vM38jf2S1-5UiTZqBcFWecpk4eHS4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188grde", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 26, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188grde/quarterly_salary_discussion_dec_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/188grde/quarterly_salary_discussion_dec_2023/", "subreddit_subscribers": 142999, "created_utc": 1701450046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lmk if that analogy makes sense. \n\nAlso would be great to hear what tech is best used and also how to pivot , ensure to grow my career in that direction. \n\nBeen in data for awhile but want to stay relevant (understand tho there are many relevant use cases for data that are valuable and varying levels of sexiness). \n\nAlso, asking about data engineering roles not like some other tech role , ie people that focus on data problems ", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most valuable data engineering roles ? Ie if ai is a gold rush and data engineering are making shovels , how do we make sure we are making shovels used for gold minding and not just dirt moving ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188eyqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701445414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lmk if that analogy makes sense. &lt;/p&gt;\n\n&lt;p&gt;Also would be great to hear what tech is best used and also how to pivot , ensure to grow my career in that direction. &lt;/p&gt;\n\n&lt;p&gt;Been in data for awhile but want to stay relevant (understand tho there are many relevant use cases for data that are valuable and varying levels of sexiness). &lt;/p&gt;\n\n&lt;p&gt;Also, asking about data engineering roles not like some other tech role , ie people that focus on data problems &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188eyqq", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188eyqq/what_are_the_most_valuable_data_engineering_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188eyqq/what_are_the_most_valuable_data_engineering_roles/", "subreddit_subscribers": 142999, "created_utc": 1701445414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 4 years of experience and I am non-EU what is the reasonable amount in Euros that I should ask for? (German start up)\n\nI am currently based on UAE and I get paid 73k but here it is 0 taxes, If I want to get paid just as much I am being paid right now after the 40% income taxes (which is something I don\u2019t mind, I just want to relocate for fun and i like the company/team) I need to ask for 150k not sure if it is reasonable, over or under. What do you guys think?", "author_fullname": "t2_5b03yxcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineer salary in Europe (start up)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188fla3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701448378.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701447008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4 years of experience and I am non-EU what is the reasonable amount in Euros that I should ask for? (German start up)&lt;/p&gt;\n\n&lt;p&gt;I am currently based on UAE and I get paid 73k but here it is 0 taxes, If I want to get paid just as much I am being paid right now after the 40% income taxes (which is something I don\u2019t mind, I just want to relocate for fun and i like the company/team) I need to ask for 150k not sure if it is reasonable, over or under. What do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188fla3", "is_robot_indexable": true, "report_reasons": null, "author": "nullisist", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188fla3/senior_data_engineer_salary_in_europe_start_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188fla3/senior_data_engineer_salary_in_europe_start_up/", "subreddit_subscribers": 142999, "created_utc": 1701447008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you guys think that Rust is going to be used extensively data engineering, getting a lot of youtube recommendation about it. I know there is Apache Ballista Project (Apache Spark competitor) which is written in Rust but still in early development.", "author_fullname": "t2_7jtukhcz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1882mam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701403937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys think that Rust is going to be used extensively data engineering, getting a lot of youtube recommendation about it. I know there is Apache Ballista Project (Apache Spark competitor) which is written in Rust but still in early development.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1882mam", "is_robot_indexable": true, "report_reasons": null, "author": "Headbanger1321", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1882mam/rust_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1882mam/rust_for_data_engineering/", "subreddit_subscribers": 142999, "created_utc": 1701403937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am quite new to data engineering. Trying to switch roles from data analyst to data engineer. Recently in one of the interviews, I was asked :\n\nHow would you ensure quality of data in the outputs, visualisation while having a semi real time pipeline which is continuously running?\n\nI said :\n\nI will set up some sort of alerting system which will get triggered everything there is an issue with the data flow.\n\nBut apparently the answer wasn\u2019t good enough. Any suggestions what could be procedure to follow for better data quality?", "author_fullname": "t2_sjfy1rn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real time pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188ckak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701439284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am quite new to data engineering. Trying to switch roles from data analyst to data engineer. Recently in one of the interviews, I was asked :&lt;/p&gt;\n\n&lt;p&gt;How would you ensure quality of data in the outputs, visualisation while having a semi real time pipeline which is continuously running?&lt;/p&gt;\n\n&lt;p&gt;I said :&lt;/p&gt;\n\n&lt;p&gt;I will set up some sort of alerting system which will get triggered everything there is an issue with the data flow.&lt;/p&gt;\n\n&lt;p&gt;But apparently the answer wasn\u2019t good enough. Any suggestions what could be procedure to follow for better data quality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "188ckak", "is_robot_indexable": true, "report_reasons": null, "author": "Pro_Panda_Puppy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188ckak/real_time_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188ckak/real_time_pipeline/", "subreddit_subscribers": 142999, "created_utc": 1701439284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven\u2019t start experimenting Airflow yet but just curious that what sort of benefit I will get from Airflow. \n\nPersonally i think that Azure function is much convenience since we don\u2019t have to manage any infra work. I am just wondering what makes Airflow so famous in data engineering space and is there additional use case outside of data engineering.", "author_fullname": "t2_dgqi4197", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs Azure Function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1884240", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701408559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven\u2019t start experimenting Airflow yet but just curious that what sort of benefit I will get from Airflow. &lt;/p&gt;\n\n&lt;p&gt;Personally i think that Azure function is much convenience since we don\u2019t have to manage any infra work. I am just wondering what makes Airflow so famous in data engineering space and is there additional use case outside of data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1884240", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Criticism-8127", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1884240/airflow_vs_azure_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1884240/airflow_vs_azure_function/", "subreddit_subscribers": 142999, "created_utc": 1701408559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The dataplatform on which I work on is following the medaillon architecture (we call them tiers): T1 for raw data, T2 for slightly refined/partitioned data, T3 for business specific data.\nEach of this tier is a file based storage (on GCP) and between each of these tiers data is being transfered/transformed by dataflow streaming jobs in an event driven fashion.\nBut because it is file based the latency between the moment we receive an event from a producer (kafka) and the moment it is available to be used by users (in T2 or T3) is around 5 minutes. It also makes the whole process undeterministic because each pipeline between tiers can be lagging a bit which can increase this latency.\n\nWe would like to enable realtime analytics (&lt;few seconds between the moment we receive the data and the moment it is available to be queried) in this context.\nWhat would be the best way to implement it in your opinion ?", "author_fullname": "t2_514a0zu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to combine realtime analytics with a tiered architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187w5ks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701385783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The dataplatform on which I work on is following the medaillon architecture (we call them tiers): T1 for raw data, T2 for slightly refined/partitioned data, T3 for business specific data.\nEach of this tier is a file based storage (on GCP) and between each of these tiers data is being transfered/transformed by dataflow streaming jobs in an event driven fashion.\nBut because it is file based the latency between the moment we receive an event from a producer (kafka) and the moment it is available to be used by users (in T2 or T3) is around 5 minutes. It also makes the whole process undeterministic because each pipeline between tiers can be lagging a bit which can increase this latency.&lt;/p&gt;\n\n&lt;p&gt;We would like to enable realtime analytics (&amp;lt;few seconds between the moment we receive the data and the moment it is available to be queried) in this context.\nWhat would be the best way to implement it in your opinion ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "187w5ks", "is_robot_indexable": true, "report_reasons": null, "author": "bretzeldalsace", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187w5ks/how_to_combine_realtime_analytics_with_a_tiered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187w5ks/how_to_combine_realtime_analytics_with_a_tiered/", "subreddit_subscribers": 142999, "created_utc": 1701385783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m392e2dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking Data Insights with Databricks Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_18870pp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8WiHo2Clu7YtQ__go91hTCXQ5emgV8-WaJ6DimcbUes.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701419607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/data-insights-databricks-notebooks/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?auto=webp&amp;s=9afd2e67e2e0866c4b0ff84dbfde07fb313f5311", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8d1fb25f3d158b43b188049ff2a4b1a0b9d4eee", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84dd3dcb4403560727cde9791e041da09cc8c370", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e6710095586d21050f5612018f30559107e8f02", "width": 320, "height": 274}], "variants": {}, "id": "0T3KDe0T4-QxpiEdbaSZ8fXPQ24Ga4lF-62bhoamp74"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18870pp", "is_robot_indexable": true, "report_reasons": null, "author": "sunher444", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18870pp/unlocking_data_insights_with_databricks_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/data-insights-databricks-notebooks/", "subreddit_subscribers": 142999, "created_utc": 1701419607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a DS but my projects are often blocked because we don\u2019t have enough DE. I want to help share the load but not be a burden. I asked the DE but they said they don\u2019t have time to train. Our stack is Apache based (Hadoop, Impala, Spark, Cassandra) plus some other stuff like Kubernetes, REST API, and Rabbit MQ.\n\nMy background is stats and I know SQL and Python. I have no CS background. Not sure where to begin. Thanks.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a Data Scientist how do I expand my engineering knowledge to help the team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187z0tw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701393387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DS but my projects are often blocked because we don\u2019t have enough DE. I want to help share the load but not be a burden. I asked the DE but they said they don\u2019t have time to train. Our stack is Apache based (Hadoop, Impala, Spark, Cassandra) plus some other stuff like Kubernetes, REST API, and Rabbit MQ.&lt;/p&gt;\n\n&lt;p&gt;My background is stats and I know SQL and Python. I have no CS background. Not sure where to begin. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "187z0tw", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187z0tw/as_a_data_scientist_how_do_i_expand_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187z0tw/as_a_data_scientist_how_do_i_expand_my/", "subreddit_subscribers": 142999, "created_utc": 1701393387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How ngrok uses Dagster to run our data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_188ebz5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/B2KEz8dKXM5TO7CLeNpiCS_HHOcw-CMg-_gTPzNOJME.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701443765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ngrok.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?auto=webp&amp;s=d7495ccc708106170153547f85aeb15b9fddf837", "width": 2000, "height": 1047}, "resolutions": [{"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b76888143e713da79ccb474b052553b6bb45b55", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5cb78f3328d47c620f863dbe33f6f6a42492836", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a71c835f200398fe4ccfa31fd2a52ec7c328fef8", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf8f3305dc687a2aa93ecd0e626f07cfa6f9447e", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=237e9950892f4a61b9ba5c14b02faa3a53b5d173", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4263800e3162b6e8400053c3a5429b2d8fb4c5fa", "width": 1080, "height": 565}], "variants": {}, "id": "M1lscahhg0tO_VSCnQfckWjPGPHlakUNvuck7KkVgyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "188ebz5", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188ebz5/how_ngrok_uses_dagster_to_run_our_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform", "subreddit_subscribers": 142999, "created_utc": 1701443765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dahhpma5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta sues FTC over child data dispute, claiming \u2018unconstitutional authority\u2019", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_188a1oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AYzF2_DTPXQ15H0eE0lHDuyDVQ3RaDk1EAzxs5v2oBM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701431551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newyorkverified.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://newyorkverified.com/4335822-meta-sues-ftc-over-child-data-dispute-claiming-unconstitutional-authority/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?auto=webp&amp;s=0bb573c4672243e3689b34f5a04248d7b38dc2f6", "width": 1280, "height": 719}, "resolutions": [{"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0285ecf01abccc670e90eaa11b9a5c7e460a0b50", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb0052b2d32de398af56bab8b79e4cf9c7a46ba9", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c495ffef0cdc7499d7b75623aebc8a86216889d2", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7b1b676815c137d138afa193a4bf1e8ee7baf39c", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=653c941ee30f67828fd21c01970d88ae022cb90f", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d086e7bafe3339c4fa61bc5ee7f7f7c4aaf4bed", "width": 1080, "height": 606}], "variants": {}, "id": "9dC5E05J_dmwcO4MTkZtkHiE7bFNFAa2fQpGGFrDO6I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188a1oi", "is_robot_indexable": true, "report_reasons": null, "author": "anujtomar_17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188a1oi/meta_sues_ftc_over_child_data_dispute_claiming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://newyorkverified.com/4335822-meta-sues-ftc-over-child-data-dispute-claiming-unconstitutional-authority/", "subreddit_subscribers": 142999, "created_utc": 1701431551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is beginning an analytics platform redesign and we've decided to invest in a strong semantic layer tool for our BI, because we have a small analytics team and a lot of complex derived performance metrics that need to be consistent (we do forecasting and order replenishment along with manage a large user base).\n\nWe were originally excited about Looker + LookML but they are coming in at an astronomically high price. [Cube.dev](https://Cube.dev) \\+ Metabase looks like a good alternative, but I can't find any real people's accounts of using it beyond their demo videos. Can anyone who migrated from Looker -&gt; cube.dev/metabase share their experience, especially if there were important features that were missing or things that were easy that broke? \n\nThanks a ton! ", "author_fullname": "t2_6h777rv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to Cube.dev + Metabase from Looker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187zlkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701394987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is beginning an analytics platform redesign and we&amp;#39;ve decided to invest in a strong semantic layer tool for our BI, because we have a small analytics team and a lot of complex derived performance metrics that need to be consistent (we do forecasting and order replenishment along with manage a large user base).&lt;/p&gt;\n\n&lt;p&gt;We were originally excited about Looker + LookML but they are coming in at an astronomically high price. &lt;a href=\"https://Cube.dev\"&gt;Cube.dev&lt;/a&gt; + Metabase looks like a good alternative, but I can&amp;#39;t find any real people&amp;#39;s accounts of using it beyond their demo videos. Can anyone who migrated from Looker -&amp;gt; cube.dev/metabase share their experience, especially if there were important features that were missing or things that were easy that broke? &lt;/p&gt;\n\n&lt;p&gt;Thanks a ton! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "187zlkv", "is_robot_indexable": true, "report_reasons": null, "author": "waitingfortheset", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187zlkv/moving_to_cubedev_metabase_from_looker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187zlkv/moving_to_cubedev_metabase_from_looker/", "subreddit_subscribers": 142999, "created_utc": 1701394987.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At my workplace, we're currently weighing our options in data engineering. It's a choice between going all-in with integration tests, CI/CD pipelines, and test-driven development, or taking a more straightforward route that emphasizes data quality checks and business-driven unit tests. The first approach seems robust but might be a bit overwhelming, particularly with the unpredictability of our data. On the other hand, the second approach, while less regimented, offers more flexibility, especially for business-centric data analysis. I'm curious to know how others in the field have tackled this. Have you had to make a similar decision? What worked for you, and what didn't? I'd really appreciate any insights or experiences you can share!", "author_fullname": "t2_83hz4r8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing Between Rigorous Data Engineering Practices and Flexible, Business-Driven Approaches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188mq7d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701465500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my workplace, we&amp;#39;re currently weighing our options in data engineering. It&amp;#39;s a choice between going all-in with integration tests, CI/CD pipelines, and test-driven development, or taking a more straightforward route that emphasizes data quality checks and business-driven unit tests. The first approach seems robust but might be a bit overwhelming, particularly with the unpredictability of our data. On the other hand, the second approach, while less regimented, offers more flexibility, especially for business-centric data analysis. I&amp;#39;m curious to know how others in the field have tackled this. Have you had to make a similar decision? What worked for you, and what didn&amp;#39;t? I&amp;#39;d really appreciate any insights or experiences you can share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188mq7d", "is_robot_indexable": true, "report_reasons": null, "author": "General-Young4322", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188mq7d/choosing_between_rigorous_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188mq7d/choosing_between_rigorous_data_engineering/", "subreddit_subscribers": 142999, "created_utc": 1701465500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ewsdi5ave", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Query optimization through minimum expression and column subset in subselects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 110, "top_awarded_type": null, "hide_score": false, "name": "t3_188huh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4MN6luqpNkD0QYY7RdtoXLfaDEhrLfn-uh5hsDHVJeM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701452787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "oxla.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://oxla.com/minimum-expression-and-column-subset-in-subselects/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?auto=webp&amp;s=9aaa2fee6e5c5a13cfde121313582dd79009fb9a", "width": 1916, "height": 1509}, "resolutions": [{"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2589cbe35597be978ff2fde17e8fa1e2f138c5db", "width": 108, "height": 85}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7a0633c6ef5656026731440cfae6d4bddc08fb", "width": 216, "height": 170}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3faf30d5b5acf4fc64fbc13bd568ccde52a037cf", "width": 320, "height": 252}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=abaac78ab7f59e87f02dbd1bfd9478c564a08824", "width": 640, "height": 504}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ef92174b202cce779d7975c2af65b3feb2640e4", "width": 960, "height": 756}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a568f31d81ca0aef448e816bffd1c5c5cf4abf4a", "width": 1080, "height": 850}], "variants": {}, "id": "b4HsGfo1VdTN0M_Q1BQvmzxik792VsNl4OEhFIQhz_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "188huh8", "is_robot_indexable": true, "report_reasons": null, "author": "adam_optimizer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188huh8/sql_query_optimization_through_minimum_expression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://oxla.com/minimum-expression-and-column-subset-in-subselects/", "subreddit_subscribers": 142999, "created_utc": 1701452787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, has anyone actually landed an interview because of a personal project on their resume? Should i even bother listing one?", "author_fullname": "t2_2r5n0ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into data engineering w/ personal project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188dkhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701441847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, has anyone actually landed an interview because of a personal project on their resume? Should i even bother listing one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188dkhd", "is_robot_indexable": true, "report_reasons": null, "author": "naq98", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188dkhd/breaking_into_data_engineering_w_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188dkhd/breaking_into_data_engineering_w_personal_project/", "subreddit_subscribers": 142999, "created_utc": 1701441847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My experience has mostly been in setting up data for dashboarding, so I'm struggling to approach the question in the title, which is for an interview. \n\nHow would you approach the scenario if you had limited time to setup a whole data system and architecture, and had to serve 3 general requirements:\n\n1. Dashboard for aggregate data and reporting purposes\n2. Recommendation engine for very granular data that takes input from a variety of sources\n3. Internal tracker (think fancy Excel spreadsheet) for non-technical, business stakeholders\n\nAssume the incoming data is relatively clean, somewhat related to each other, and the sources are all identified, and this would be on AWS.\n\nMy take/approach on this:\n\n1. Land data into S3, then move to Redshift/Snowflake. Probably in an ELT pattern\n2. This is where I would appreciate input, since I've never built a recommendation engine. Would a NoSQL storage like DynamoDB be better? Or would putting data onto the same database as #1 (Redshift/Snowflake) be perfectly fine? What should I be concerned about in setting up a recommendation engine?\n3. Do the same as #1 again, or honestly suggest doing this all on Excel to accommodate for manual data entry/input. Might suggest using Glue. \n\nFor orchestration, I might suggest MWAA, Data Pipeline, or Lambda. Any other AWS services that you all would suggest using as part of a data architecture for this?", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How differently would you setup the back-end for a dashboard vs recommendation engine vs internal tracker?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188d6s7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701440889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My experience has mostly been in setting up data for dashboarding, so I&amp;#39;m struggling to approach the question in the title, which is for an interview. &lt;/p&gt;\n\n&lt;p&gt;How would you approach the scenario if you had limited time to setup a whole data system and architecture, and had to serve 3 general requirements:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Dashboard for aggregate data and reporting purposes&lt;/li&gt;\n&lt;li&gt;Recommendation engine for very granular data that takes input from a variety of sources&lt;/li&gt;\n&lt;li&gt;Internal tracker (think fancy Excel spreadsheet) for non-technical, business stakeholders&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Assume the incoming data is relatively clean, somewhat related to each other, and the sources are all identified, and this would be on AWS.&lt;/p&gt;\n\n&lt;p&gt;My take/approach on this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Land data into S3, then move to Redshift/Snowflake. Probably in an ELT pattern&lt;/li&gt;\n&lt;li&gt;This is where I would appreciate input, since I&amp;#39;ve never built a recommendation engine. Would a NoSQL storage like DynamoDB be better? Or would putting data onto the same database as #1 (Redshift/Snowflake) be perfectly fine? What should I be concerned about in setting up a recommendation engine?&lt;/li&gt;\n&lt;li&gt;Do the same as #1 again, or honestly suggest doing this all on Excel to accommodate for manual data entry/input. Might suggest using Glue. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For orchestration, I might suggest MWAA, Data Pipeline, or Lambda. Any other AWS services that you all would suggest using as part of a data architecture for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188d6s7", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188d6s7/how_differently_would_you_setup_the_backend_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188d6s7/how_differently_would_you_setup_the_backend_for_a/", "subreddit_subscribers": 142999, "created_utc": 1701440889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI've currently been applying to junior/entry level data engineer roles in the UK solidly for a few months now and having next to no luck. The only application I got a response from I got to a second round interview for before being rejected. This is from both me applying myself + some recruiters reaching out for me.\n\nCurrently have just over a year's experience as a Data Consultant which has given me exposure to both consultancy and engineering practices which is what's making me want to specialise on the more technical side - my CV is currently much more tailored towards the data engineering experiences I've had over the past year but I feel as though my applications may be getting overlooked for those who already have (more) experience in specifically DE roles?\n\nAm feeling stuck as I'd love to leave consultancy and build out a career in a DE role as I've always heavily preferred those aspects to my job roles - but I'm not sure how to best go about gaining entry into the field.\n\nI know there's a case to be made for staying at my current role a bit longer but I feel like I'd have to start at a junior level regardless of how long I stay, as my job is not DE specific and is missing some key tech stacks (like use of Azure/AWS/GCP for e.g.) - so would rather move and gain experience in these as soon as possible.\n\nThanks in advance for any words of advice.\n\n\\--\n\n*Quick summary of my exp: UCL STEM Grad, 1yr experience as a Data Consultant - (re DE skills) using primarily SQL + SSMS, Python (pandas, selenium , various web/pdf scrapers + excel writers), SSIS for ETL tool, Databricks, Power BI + Tableau*", "author_fullname": "t2_ggdul3b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to find an entry point into Junior/Entry level DE roles despite having a data background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188cc5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701441067.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701438659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve currently been applying to junior/entry level data engineer roles in the UK solidly for a few months now and having next to no luck. The only application I got a response from I got to a second round interview for before being rejected. This is from both me applying myself + some recruiters reaching out for me.&lt;/p&gt;\n\n&lt;p&gt;Currently have just over a year&amp;#39;s experience as a Data Consultant which has given me exposure to both consultancy and engineering practices which is what&amp;#39;s making me want to specialise on the more technical side - my CV is currently much more tailored towards the data engineering experiences I&amp;#39;ve had over the past year but I feel as though my applications may be getting overlooked for those who already have (more) experience in specifically DE roles?&lt;/p&gt;\n\n&lt;p&gt;Am feeling stuck as I&amp;#39;d love to leave consultancy and build out a career in a DE role as I&amp;#39;ve always heavily preferred those aspects to my job roles - but I&amp;#39;m not sure how to best go about gaining entry into the field.&lt;/p&gt;\n\n&lt;p&gt;I know there&amp;#39;s a case to be made for staying at my current role a bit longer but I feel like I&amp;#39;d have to start at a junior level regardless of how long I stay, as my job is not DE specific and is missing some key tech stacks (like use of Azure/AWS/GCP for e.g.) - so would rather move and gain experience in these as soon as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any words of advice.&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Quick summary of my exp: UCL STEM Grad, 1yr experience as a Data Consultant - (re DE skills) using primarily SQL + SSMS, Python (pandas, selenium , various web/pdf scrapers + excel writers), SSIS for ETL tool, Databricks, Power BI + Tableau&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188cc5u", "is_robot_indexable": true, "report_reasons": null, "author": "DeviceNew9623", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188cc5u/struggling_to_find_an_entry_point_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188cc5u/struggling_to_find_an_entry_point_into/", "subreddit_subscribers": 142999, "created_utc": 1701438659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a data team in a very legacy platform and we're struggling under a constant demand from business side to bring in adhoc spreadsheets they receive from business partners and the like (sales leads, prospects on joint projects, points of contact for partnerships etc) and we don't have any kind of ERP or other software that would let them bring it on other than literally copy pasting it into plain text to dump into a corporate record. We do have a data lake but there's just no corporate supported interface or app for the users to bring this in themselves so we're usually asked to make adhoc dashboards and viz. \n\nNow, we do have some schemas and other legacy resources (avro and protobuf) we could use to model these better into some kind of standard schema for 80% of these situations, but no resources to deploy a custom data entry solution here. Our team is somewhat technical but not much on the coding side to just do this in Python for every ETL job.\n\nI've been searching across the python and ETL world but I just can't seem to find any decent libraries that could help template this out a bit. Like, given a CSV, type in matching columns to normalize them into the schema and then write this to our data warehouse (currently impala but looking to migrate to postgres).\n\nAm I missing some sort of obvious framework, library or ETL package that would support this or is writing out custom Python ETL scripts from scratch the only solution? Any good examples of managing data tranaforma between different schemas on python, pyspark etc?", "author_fullname": "t2_o60763zfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Supporting adhoc ETL of spreadsheets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187xjav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701389388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a data team in a very legacy platform and we&amp;#39;re struggling under a constant demand from business side to bring in adhoc spreadsheets they receive from business partners and the like (sales leads, prospects on joint projects, points of contact for partnerships etc) and we don&amp;#39;t have any kind of ERP or other software that would let them bring it on other than literally copy pasting it into plain text to dump into a corporate record. We do have a data lake but there&amp;#39;s just no corporate supported interface or app for the users to bring this in themselves so we&amp;#39;re usually asked to make adhoc dashboards and viz. &lt;/p&gt;\n\n&lt;p&gt;Now, we do have some schemas and other legacy resources (avro and protobuf) we could use to model these better into some kind of standard schema for 80% of these situations, but no resources to deploy a custom data entry solution here. Our team is somewhat technical but not much on the coding side to just do this in Python for every ETL job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching across the python and ETL world but I just can&amp;#39;t seem to find any decent libraries that could help template this out a bit. Like, given a CSV, type in matching columns to normalize them into the schema and then write this to our data warehouse (currently impala but looking to migrate to postgres).&lt;/p&gt;\n\n&lt;p&gt;Am I missing some sort of obvious framework, library or ETL package that would support this or is writing out custom Python ETL scripts from scratch the only solution? Any good examples of managing data tranaforma between different schemas on python, pyspark etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "187xjav", "is_robot_indexable": true, "report_reasons": null, "author": "YieldingSign", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187xjav/supporting_adhoc_etl_of_spreadsheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187xjav/supporting_adhoc_etl_of_spreadsheets/", "subreddit_subscribers": 142999, "created_utc": 1701389388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TLDR:** *I'm not quite a DE but don't really know where I fit. I think I need a change but I just don't know where to go. I feel like I need some type of advice but I don't know where to find it. My network is small, so I've looked into local tech/data meetup groups but there doesn't appear to be high attendance (3-4 people). Would it be worth trying anyway? Would it make sense to pursue some type of career coach/mentor? If so, what is the best way to go about finding that?*\n\n\n**More about me:**\n\nIn 2019, I got masters in Business Analytics and started as a BA at a tech startup, where I used SQL to build charts and dashboards in a BI tool. Current state, I've worked up to \"analytics manager\" at the same company, which is an inflated way of saying I'm the main person here that:\n\n\n- 'manages' our ETL tool (Fivetran, which is pretty much just point and click)\n\n- 'manages' our dbt project and BI tool(s)/transitions when leadership decides on a new one (building dashboards for internal and external use), etc\n\n- I also use R for larger scale scripts/automation, but my most advanced/used tech skills are SQL/dbt and BI 'development', if you can call it that\n\n- No direct reports, no python, I don't know what Spark or Airflow are, and most of my CI/CD knowledge comes from watered down dbt automations\n\n\n**Where I feel stuck/ranting:**\n\nManager started as BizOps Lead but over time has taken strategy/admin/general hiring responsibilities, and become more and more resistant to participating/understanding the technical BizOps/BI side of our department. We hired another analyst early in '21 who technically was more professionally mature than me when hired, but has not ramped in skill with me and it still feels like there is an expectation that I spend a lot of time coaching and mentoring even though they do not report to me.\n\n\nSince I started the company went from ~30 people to ~65+, and my team has been 2-3. I estimate we're about 50% software engineers, but my role feels so isolated from the technical side of our company. We've acquired other SaaS products in the last year that leadership, product, and clients need reported on, but I don't have the resources/manpower to get it all done cleanly and in the timeframe expected. I rely on SWEs to verify my understanding of specific tables/columns, but I'm understandably instructed not to take up much of their time.\n\n\nI feel technically more advanced than my team, but far behind our SWEs. Since we were a young startup when I joined I developed our SQL standards, built our dbt project and git flows from scratch, etc. Most of the analytics processes in place were designed by me but with limited feedback/collaboration/prior exposure, it could honestly be trash. I'm not able to develop deeper DE skills due to the division and have a lot of gaps, so I'm not sure what I am or could be based on my skillset. I want a change, but I don't know what type of role I should be looking for or working towards.\n\n\nAnyone else been in a relatable career spot? What'd you do? Is it something worth finding a career coach, mentor, network, someone to talk through?", "author_fullname": "t2_spwsseep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who do you talk to at career crossroads? Any stories working with mentors/coaches or building your network from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_188p0sg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701471589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; &lt;em&gt;I&amp;#39;m not quite a DE but don&amp;#39;t really know where I fit. I think I need a change but I just don&amp;#39;t know where to go. I feel like I need some type of advice but I don&amp;#39;t know where to find it. My network is small, so I&amp;#39;ve looked into local tech/data meetup groups but there doesn&amp;#39;t appear to be high attendance (3-4 people). Would it be worth trying anyway? Would it make sense to pursue some type of career coach/mentor? If so, what is the best way to go about finding that?&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;More about me:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In 2019, I got masters in Business Analytics and started as a BA at a tech startup, where I used SQL to build charts and dashboards in a BI tool. Current state, I&amp;#39;ve worked up to &amp;quot;analytics manager&amp;quot; at the same company, which is an inflated way of saying I&amp;#39;m the main person here that:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&amp;#39;manages&amp;#39; our ETL tool (Fivetran, which is pretty much just point and click)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&amp;#39;manages&amp;#39; our dbt project and BI tool(s)/transitions when leadership decides on a new one (building dashboards for internal and external use), etc&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I also use R for larger scale scripts/automation, but my most advanced/used tech skills are SQL/dbt and BI &amp;#39;development&amp;#39;, if you can call it that&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;No direct reports, no python, I don&amp;#39;t know what Spark or Airflow are, and most of my CI/CD knowledge comes from watered down dbt automations&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Where I feel stuck/ranting:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Manager started as BizOps Lead but over time has taken strategy/admin/general hiring responsibilities, and become more and more resistant to participating/understanding the technical BizOps/BI side of our department. We hired another analyst early in &amp;#39;21 who technically was more professionally mature than me when hired, but has not ramped in skill with me and it still feels like there is an expectation that I spend a lot of time coaching and mentoring even though they do not report to me.&lt;/p&gt;\n\n&lt;p&gt;Since I started the company went from ~30 people to ~65+, and my team has been 2-3. I estimate we&amp;#39;re about 50% software engineers, but my role feels so isolated from the technical side of our company. We&amp;#39;ve acquired other SaaS products in the last year that leadership, product, and clients need reported on, but I don&amp;#39;t have the resources/manpower to get it all done cleanly and in the timeframe expected. I rely on SWEs to verify my understanding of specific tables/columns, but I&amp;#39;m understandably instructed not to take up much of their time.&lt;/p&gt;\n\n&lt;p&gt;I feel technically more advanced than my team, but far behind our SWEs. Since we were a young startup when I joined I developed our SQL standards, built our dbt project and git flows from scratch, etc. Most of the analytics processes in place were designed by me but with limited feedback/collaboration/prior exposure, it could honestly be trash. I&amp;#39;m not able to develop deeper DE skills due to the division and have a lot of gaps, so I&amp;#39;m not sure what I am or could be based on my skillset. I want a change, but I don&amp;#39;t know what type of role I should be looking for or working towards.&lt;/p&gt;\n\n&lt;p&gt;Anyone else been in a relatable career spot? What&amp;#39;d you do? Is it something worth finding a career coach, mentor, network, someone to talk through?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188p0sg", "is_robot_indexable": true, "report_reasons": null, "author": "hairc-ut", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188p0sg/who_do_you_talk_to_at_career_crossroads_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188p0sg/who_do_you_talk_to_at_career_crossroads_any/", "subreddit_subscribers": 142999, "created_utc": 1701471589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, our current data infrastructure is quite messy, involving SAP BW for ERP data, a data lake responsible for delivering data to various web applications, and another warehouse (Postgres) dedicated to reporting on non-ERP data sourced from APIs and local databases. Like many others, we are in the process of evaluating a platform or stack that can centralize our data into a single analytical platform for our organization. This platform should enable us to perform ad hoc queries, construct standardized data models for major business facts, execute data science workloads, manage and build machine learning models, and **develop web applications.**\n\nMy primary concern is around the handling of data for web applications. While common advice discourages the use of data warehouses for web applications, a data warehouse mostly aligns with our other requirements. The web applications are hosted on their dedicated Kubernetes cluster, I just need to ensure they seamlessly access data from the chosen platform.\n\nIn our existing setup, data is extracted and loaded from source systems to a centralized data lake in Parquet format. Each data application has a queue that receives a message when a new Parquet file is created for a table in the data lake relevant to the application. Subsequently, a consumer for the data application reads the new Parquet file and loads its contents into its backend database, typically Postgres or MongoDB. These application-specific databases handle raw data from various sources, performing the transformation with specific business logic and calculations tailored for each web application.\n\nHowever, I find this setup suboptimal as each backend database independently performs transformations to construct the required data model for its respective application. This approach creates silos, isolating the process from other aspects of our data infrastructure.\n\nConsider if we were using Databricks instead. Rather than loading raw data into separate application-specific database and having those databases perform transformations to build the required data model, wouldn't it be more efficient to leverage Databricks for these tasks? In this scenario, Databricks would handle the transformations, and the resulting data model would be persisted in the Gold layer. As a result, web applications would simply query this centralized Gold layer as the backend, instead of relying on individual siloed databases. Additional benefits would be that these data models are no longer siloed, and can be used for other analytical tasks in the future.\n\n As we explore potential solutions for our data infrastructure, we are currently evaluating Databricks, Snowflake, Dremio, Starburst Data, ClickHouse, and Druid. While ClickHouse and Druid seem promising for addressing the needs of our web applications, there are concerns about their capability to handle other essential data warehousing tasks. ", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform to Support Data (Web) Apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_188n7tn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701467167.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701466780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, our current data infrastructure is quite messy, involving SAP BW for ERP data, a data lake responsible for delivering data to various web applications, and another warehouse (Postgres) dedicated to reporting on non-ERP data sourced from APIs and local databases. Like many others, we are in the process of evaluating a platform or stack that can centralize our data into a single analytical platform for our organization. This platform should enable us to perform ad hoc queries, construct standardized data models for major business facts, execute data science workloads, manage and build machine learning models, and &lt;strong&gt;develop web applications.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My primary concern is around the handling of data for web applications. While common advice discourages the use of data warehouses for web applications, a data warehouse mostly aligns with our other requirements. The web applications are hosted on their dedicated Kubernetes cluster, I just need to ensure they seamlessly access data from the chosen platform.&lt;/p&gt;\n\n&lt;p&gt;In our existing setup, data is extracted and loaded from source systems to a centralized data lake in Parquet format. Each data application has a queue that receives a message when a new Parquet file is created for a table in the data lake relevant to the application. Subsequently, a consumer for the data application reads the new Parquet file and loads its contents into its backend database, typically Postgres or MongoDB. These application-specific databases handle raw data from various sources, performing the transformation with specific business logic and calculations tailored for each web application.&lt;/p&gt;\n\n&lt;p&gt;However, I find this setup suboptimal as each backend database independently performs transformations to construct the required data model for its respective application. This approach creates silos, isolating the process from other aspects of our data infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Consider if we were using Databricks instead. Rather than loading raw data into separate application-specific database and having those databases perform transformations to build the required data model, wouldn&amp;#39;t it be more efficient to leverage Databricks for these tasks? In this scenario, Databricks would handle the transformations, and the resulting data model would be persisted in the Gold layer. As a result, web applications would simply query this centralized Gold layer as the backend, instead of relying on individual siloed databases. Additional benefits would be that these data models are no longer siloed, and can be used for other analytical tasks in the future.&lt;/p&gt;\n\n&lt;p&gt;As we explore potential solutions for our data infrastructure, we are currently evaluating Databricks, Snowflake, Dremio, Starburst Data, ClickHouse, and Druid. While ClickHouse and Druid seem promising for addressing the needs of our web applications, there are concerns about their capability to handle other essential data warehousing tasks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188n7tn", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188n7tn/data_platform_to_support_data_web_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188n7tn/data_platform_to_support_data_web_apps/", "subreddit_subscribers": 142999, "created_utc": 1701466780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting resource published on managing consistency in stream data processing. Also explains how streaming complements OLAP/OLTP systems. Features insights from O'Reilly authors of \"Streaming Databases.\" \n\nLink to watch directly without registration: https://youtu.be/MhSB5NqkylU\n\nPS, I was one of the contributors for this session. Please let me know if you found this useful or have any feedback. Thanks.", "author_fullname": "t2_n0ywlxbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resource: Managing consistency in stream processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188ms7m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701465652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting resource published on managing consistency in stream data processing. Also explains how streaming complements OLAP/OLTP systems. Features insights from O&amp;#39;Reilly authors of &amp;quot;Streaming Databases.&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Link to watch directly without registration: &lt;a href=\"https://youtu.be/MhSB5NqkylU\"&gt;https://youtu.be/MhSB5NqkylU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;PS, I was one of the contributors for this session. Please let me know if you found this useful or have any feedback. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hPhe6TA0pTUELUpCQYCrYKW8e-40bpeB0hgTxudSV5Q.jpg?auto=webp&amp;s=a7c9bbc5af512eb8689d908b3ab0e4004588af1d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/hPhe6TA0pTUELUpCQYCrYKW8e-40bpeB0hgTxudSV5Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=292bc6db61fcaabc48fa581e478e4c8a669e4f5c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/hPhe6TA0pTUELUpCQYCrYKW8e-40bpeB0hgTxudSV5Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=165606bc9efe19ab7e5fd9b86a4feb82a321fb2d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/hPhe6TA0pTUELUpCQYCrYKW8e-40bpeB0hgTxudSV5Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=917e91b5e7097f67c597161f9afecbbec5ee682a", "width": 320, "height": 240}], "variants": {}, "id": "nuXNhFVRoaxLO61CPCR-KRg02vXvZlQVYBEeaEmibuc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "188ms7m", "is_robot_indexable": true, "report_reasons": null, "author": "muditjps", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188ms7m/resource_managing_consistency_in_stream_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188ms7m/resource_managing_consistency_in_stream_processing/", "subreddit_subscribers": 142999, "created_utc": 1701465652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "tl;dr: I need to get logs from STDOUT on GCP VM sent to GCP cloud logging.\n\nHey I have a job running on a gcp VM where some imported libraries are logging to stdout with the print or python logging library, and I also have written a lot of code where the output is logged to stdout with the python logging library (e.g. [`logging.info`](https://logging.info)`(\"*** INFO ***\")` ). I'm running into an issue where the logs are printing to STDOUT but not sent to GCP cloud logging. I have tried so many things such as installing the logging agent on the VM, going through a bunch of GCP docs, using deprecated logging libraries, etc, but nothing has worked. Here are some examples:\n\n`gcp_log_example.py` \\- The 'HI' log get sent to GCP cloud logging but none of the logs in builtin\\_logger.py. This is why I cannot use this approach.\n\n    import subprocess\n    import google.cloud.logging\n    import logging\n    \n    client = google.cloud.logging.Client()\n    client.setup_logging()\n    logging.info('HI')\n    \n    subprocess.run('python3 builtin_logger.py', shell=True)\n\n\\^\\^ I will not use this approach because I'm pretty sure it requires me to go through every library and integrate GCP logging. No way anyone is going to do that.\n\n`builtin_logger.py`\n\n    import logging\n    logging.basicConfig(level=logging.INFO)\n    print('*** print! ***')\n    logging.info('*** INFO! ***')\n    logging.warning('*** WARNING! ***')\n    logging.critical('*** CRITICAL! ***')\n    sys.stdout.flush()\n\n\\^ These logs get sent to stdout but are not sent to GCP.\n\n&amp;#x200B;\n\nI've also tried running it like this but in this case the severity level is not captured but the logs are sent to GCP cloud logging (twice though --- the logs are duplicated)\n\n[`tmp.sh`](https://tmp.sh)\n\n    #!/bin/bash\n    \n    python3 builtin_log.py 2&gt;&amp;1 | logger -t \"builtin_log.py\"\n\nHelp is greatly appreciated, thanks!", "author_fullname": "t2_8xq51rif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud logging with GCP question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188kljc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701460375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701459942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr: I need to get logs from STDOUT on GCP VM sent to GCP cloud logging.&lt;/p&gt;\n\n&lt;p&gt;Hey I have a job running on a gcp VM where some imported libraries are logging to stdout with the print or python logging library, and I also have written a lot of code where the output is logged to stdout with the python logging library (e.g. &lt;a href=\"https://logging.info\"&gt;&lt;code&gt;logging.info&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(&amp;quot;*** INFO ***&amp;quot;)&lt;/code&gt; ). I&amp;#39;m running into an issue where the logs are printing to STDOUT but not sent to GCP cloud logging. I have tried so many things such as installing the logging agent on the VM, going through a bunch of GCP docs, using deprecated logging libraries, etc, but nothing has worked. Here are some examples:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;gcp_log_example.py&lt;/code&gt; - The &amp;#39;HI&amp;#39; log get sent to GCP cloud logging but none of the logs in builtin_logger.py. This is why I cannot use this approach.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import subprocess\nimport google.cloud.logging\nimport logging\n\nclient = google.cloud.logging.Client()\nclient.setup_logging()\nlogging.info(&amp;#39;HI&amp;#39;)\n\nsubprocess.run(&amp;#39;python3 builtin_logger.py&amp;#39;, shell=True)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;^^ I will not use this approach because I&amp;#39;m pretty sure it requires me to go through every library and integrate GCP logging. No way anyone is going to do that.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;builtin_logger.py&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import logging\nlogging.basicConfig(level=logging.INFO)\nprint(&amp;#39;*** print! ***&amp;#39;)\nlogging.info(&amp;#39;*** INFO! ***&amp;#39;)\nlogging.warning(&amp;#39;*** WARNING! ***&amp;#39;)\nlogging.critical(&amp;#39;*** CRITICAL! ***&amp;#39;)\nsys.stdout.flush()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;^ These logs get sent to stdout but are not sent to GCP.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also tried running it like this but in this case the severity level is not captured but the logs are sent to GCP cloud logging (twice though --- the logs are duplicated)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://tmp.sh\"&gt;&lt;code&gt;tmp.sh&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;#!/bin/bash\n\npython3 builtin_log.py 2&amp;gt;&amp;amp;1 | logger -t &amp;quot;builtin_log.py&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Help is greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "188kljc", "is_robot_indexable": true, "report_reasons": null, "author": "Training_Butterfly70", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188kljc/cloud_logging_with_gcp_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188kljc/cloud_logging_with_gcp_question/", "subreddit_subscribers": 142999, "created_utc": 1701459942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I graduated 2023 March and have been working since April at the place I interned for. My official role is data engineer but I\u2019m basically an analytics engineer who has no set role since my manager is very hands off and absent - I can basically just do whatever I want. My role can be best summed up as making dbt models and mostly working with stakeholders to enable their data, create dashboards for them, do some small infra and data modeling work on our database (no one is a data architect or has any DE principles on my team since they are all analysts so it\u2019s basically blind leading the blind).\n\nI\u2019m pretty frustrated at my current position since I have a CS/Math degree so I feel like I\u2019m in the wrong position. The team is a mess and has no clear direction and is disjoint, so I want to leave but I have a weird skillset now.\n\nI think Technical Product Manager roles would fit me well since my experience, or Data Analyst roles. I think SWE roles fit my experience from my degree. Another team who works closely to mine is hiring MLEs so I want to move their ideally but they aren\u2019t hiring entry level people and I don\u2019t have the quals, but I know the data pretty well since I\u2019ve been working here for over a year and im one of the only grunt workers who has truly dove deep in the complete mess of data we have while other ppl on my team and pillar just manage a small amount of ppl to do this. Analysts are focused on one area of data but I have a good understanding of most of it since I\u2019ve worked with multiple teams and stakeholders since I\u2019m an DE/AE and not a designated analyst \n\nI\u2019m kind of lost in the direction I should move in and the market has not been kind from me applying", "author_fullname": "t2_qeq05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What type of jobs am I qualified for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188kixs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701460451.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701459750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated 2023 March and have been working since April at the place I interned for. My official role is data engineer but I\u2019m basically an analytics engineer who has no set role since my manager is very hands off and absent - I can basically just do whatever I want. My role can be best summed up as making dbt models and mostly working with stakeholders to enable their data, create dashboards for them, do some small infra and data modeling work on our database (no one is a data architect or has any DE principles on my team since they are all analysts so it\u2019s basically blind leading the blind).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty frustrated at my current position since I have a CS/Math degree so I feel like I\u2019m in the wrong position. The team is a mess and has no clear direction and is disjoint, so I want to leave but I have a weird skillset now.&lt;/p&gt;\n\n&lt;p&gt;I think Technical Product Manager roles would fit me well since my experience, or Data Analyst roles. I think SWE roles fit my experience from my degree. Another team who works closely to mine is hiring MLEs so I want to move their ideally but they aren\u2019t hiring entry level people and I don\u2019t have the quals, but I know the data pretty well since I\u2019ve been working here for over a year and im one of the only grunt workers who has truly dove deep in the complete mess of data we have while other ppl on my team and pillar just manage a small amount of ppl to do this. Analysts are focused on one area of data but I have a good understanding of most of it since I\u2019ve worked with multiple teams and stakeholders since I\u2019m an DE/AE and not a designated analyst &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kind of lost in the direction I should move in and the market has not been kind from me applying&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188kixs", "is_robot_indexable": true, "report_reasons": null, "author": "therealhm2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188kixs/what_type_of_jobs_am_i_qualified_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188kixs/what_type_of_jobs_am_i_qualified_for/", "subreddit_subscribers": 142999, "created_utc": 1701459750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a client that is exploring cost reduction opportunities. They currently have about 1tb of data in Snowflake, and this database serves a Streamlit application. Costs are getting out of control (like 50-80k per month). I still don't have access to the Snowflake console to explore the queries that are running, as I'm waiting on access. My gut is that Snowflake is overkill, but I'm not certain. The couple tables that the app pulls from are pre-calculated and have over 1 billion rows. Data is ingested into Snf only once a month, but pulled from frequently. They are playing with downsizing the cluster. My questions are...could another database type serve this role better and for lower cost? Redshift? Azure Synapse? What about traditional RDS? I wish I had more details for ya'll - what are your experiences between different databases and DWs in terms of cost and use?\n\nAnother question - could I send the pre-calculated tables to another service like RDS and use that for the application instead? Think it'd be cheaper? Could RDS cheaply and efficiently handle queries to a couple of tables with a bil rows each?", "author_fullname": "t2_4n94s86o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to reduce costs - which service to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188il0x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701460795.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701454680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a client that is exploring cost reduction opportunities. They currently have about 1tb of data in Snowflake, and this database serves a Streamlit application. Costs are getting out of control (like 50-80k per month). I still don&amp;#39;t have access to the Snowflake console to explore the queries that are running, as I&amp;#39;m waiting on access. My gut is that Snowflake is overkill, but I&amp;#39;m not certain. The couple tables that the app pulls from are pre-calculated and have over 1 billion rows. Data is ingested into Snf only once a month, but pulled from frequently. They are playing with downsizing the cluster. My questions are...could another database type serve this role better and for lower cost? Redshift? Azure Synapse? What about traditional RDS? I wish I had more details for ya&amp;#39;ll - what are your experiences between different databases and DWs in terms of cost and use?&lt;/p&gt;\n\n&lt;p&gt;Another question - could I send the pre-calculated tables to another service like RDS and use that for the application instead? Think it&amp;#39;d be cheaper? Could RDS cheaply and efficiently handle queries to a couple of tables with a bil rows each?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "188il0x", "is_robot_indexable": true, "report_reasons": null, "author": "GuyWhoWantsToFly", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188il0x/need_to_reduce_costs_which_service_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188il0x/need_to_reduce_costs_which_service_to_use/", "subreddit_subscribers": 142999, "created_utc": 1701454680.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}