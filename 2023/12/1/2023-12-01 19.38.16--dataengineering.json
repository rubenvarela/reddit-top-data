{"kind": "Listing", "data": {"after": "t3_188hbus", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Before end of year I hear many data influencers talking about shrinking data teams, modern data stack tools dying and AI taking over the data world. Do you guys see data engineering in such a perspective? Maybe I am wrong, but looking at the real world (not the influencer clickbait, but down to earth real world we work in), I do not see data engineering shrinking in the nearest  10 years. Most of customers I deal with are big corporates and they enjoy idea of deploying AI, cutting costs but thats just idea and branding. When you look at their stack, rate of change and business mentality (like trusting AI, governance, etc), I do not see any critical shifts nearby. For sure, AI will help writing code, analytics, but nowhere near to replace architects, devs and ops admins. Whats your take? ", "author_fullname": "t2_is8b1hg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doom predictions for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1883wyz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701408099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before end of year I hear many data influencers talking about shrinking data teams, modern data stack tools dying and AI taking over the data world. Do you guys see data engineering in such a perspective? Maybe I am wrong, but looking at the real world (not the influencer clickbait, but down to earth real world we work in), I do not see data engineering shrinking in the nearest  10 years. Most of customers I deal with are big corporates and they enjoy idea of deploying AI, cutting costs but thats just idea and branding. When you look at their stack, rate of change and business mentality (like trusting AI, governance, etc), I do not see any critical shifts nearby. For sure, AI will help writing code, analytics, but nowhere near to replace architects, devs and ops admins. Whats your take? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1883wyz", "is_robot_indexable": true, "report_reasons": null, "author": "vee920", "discussion_type": null, "num_comments": 119, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1883wyz/doom_predictions_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1883wyz/doom_predictions_for_data_engineering/", "subreddit_subscribers": 142954, "created_utc": 1701408099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Picked up a contract role for DE role at a large healthcare company. \n\nThey use MSSQL, SSIS, the works. The architecture is very confusing since everything is pretty much on prem. Servers are split out running multiple jobs in illogical ways. \n\nWhat\u2019s really jarring, is the rate of failures they have. SQL server executes the SSIS jobs. Instead of having immediate alerts, there\u2019s another job that runs every 20 mins to query failures in sql server and SSIS logging table. The logging is abysmal. It\u2019s so bad they have an on call rotation where someone sits and watches an email queue to notify people of alerts and triage them correctly. \n\nI am unfortunately part of this on call rotation. You\u2019re guaranteed multiple high priority alerts everyday and because of the poor logging and infra you have to do a lot of digging to figure out what happened. This is very different from other jobs where I used airflow and the failed task just shows the failed status and logging right there. \n\nI\u2019m about to just quit this contract cause this org seems like a dumpster fire. Is this how all SSIS shops operate or is this just a bad one?", "author_fullname": "t2_1kset4fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are SSIS Shops Always This Bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187rd9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701373895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Picked up a contract role for DE role at a large healthcare company. &lt;/p&gt;\n\n&lt;p&gt;They use MSSQL, SSIS, the works. The architecture is very confusing since everything is pretty much on prem. Servers are split out running multiple jobs in illogical ways. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s really jarring, is the rate of failures they have. SQL server executes the SSIS jobs. Instead of having immediate alerts, there\u2019s another job that runs every 20 mins to query failures in sql server and SSIS logging table. The logging is abysmal. It\u2019s so bad they have an on call rotation where someone sits and watches an email queue to notify people of alerts and triage them correctly. &lt;/p&gt;\n\n&lt;p&gt;I am unfortunately part of this on call rotation. You\u2019re guaranteed multiple high priority alerts everyday and because of the poor logging and infra you have to do a lot of digging to figure out what happened. This is very different from other jobs where I used airflow and the failed task just shows the failed status and logging right there. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to just quit this contract cause this org seems like a dumpster fire. Is this how all SSIS shops operate or is this just a bad one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "187rd9z", "is_robot_indexable": true, "report_reasons": null, "author": "shittyfuckdick", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187rd9z/are_ssis_shops_always_this_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187rd9z/are_ssis_shops_always_this_bad/", "subreddit_subscribers": 142954, "created_utc": 1701373895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I just got an offer for this position. I don't know much about data engineering; my background is more related to that of a data analyst or data scientist. But regardless, I randomly applied for this job titled \"ETL Developer/Operation Analyst\" when I was auto-applying to multiple job openings on LinkedIn, somehow got called for an HR to User interview, followed through, and then they surprisingly gave the offer.\n\nAnd now I'm panicking because I didn't expect this at all. Plus, I'm actually looking forward to a data scientist job that I'm still in the process of getting.\n\nWhat should I learn? What should I know about this job? What would the job look like? What would I be doing? I don't use much of the ETL tools, but I did learn a few things on Apache NiFi. For my self-projects, I mostly just extract data with API requests using Python, either via Google Colab or VS Code. I had experience using OAuth 2.0 and BigQuery too for mock-up projects, but I mostly just practice SQL through HackerRank.\n\nThey say I will also be meeting international clients from their telecommunications partner companies. I haven't really gotten the big picture of what the job description is like. Can you guys share your experience in this industry????", "author_fullname": "t2_hzshhr1a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does an ETL developer in the telecommunications industry do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187twba", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701380180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just got an offer for this position. I don&amp;#39;t know much about data engineering; my background is more related to that of a data analyst or data scientist. But regardless, I randomly applied for this job titled &amp;quot;ETL Developer/Operation Analyst&amp;quot; when I was auto-applying to multiple job openings on LinkedIn, somehow got called for an HR to User interview, followed through, and then they surprisingly gave the offer.&lt;/p&gt;\n\n&lt;p&gt;And now I&amp;#39;m panicking because I didn&amp;#39;t expect this at all. Plus, I&amp;#39;m actually looking forward to a data scientist job that I&amp;#39;m still in the process of getting.&lt;/p&gt;\n\n&lt;p&gt;What should I learn? What should I know about this job? What would the job look like? What would I be doing? I don&amp;#39;t use much of the ETL tools, but I did learn a few things on Apache NiFi. For my self-projects, I mostly just extract data with API requests using Python, either via Google Colab or VS Code. I had experience using OAuth 2.0 and BigQuery too for mock-up projects, but I mostly just practice SQL through HackerRank.&lt;/p&gt;\n\n&lt;p&gt;They say I will also be meeting international clients from their telecommunications partner companies. I haven&amp;#39;t really gotten the big picture of what the job description is like. Can you guys share your experience in this industry????&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "187twba", "is_robot_indexable": true, "report_reasons": null, "author": "DecentPerson011", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187twba/what_does_an_etl_developer_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187twba/what_does_an_etl_developer_in_the/", "subreddit_subscribers": 142954, "created_utc": 1701380180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 4 years of experience and I am non-EU what is the reasonable amount in Euros that I should ask for? (German start up)\n\nI am currently based on UAE and I get paid 73k but here it is 0 taxes, If I want to get paid just as much I am being paid right now after the 40% income taxes (which is something I don\u2019t mind, I just want to relocate for fun and i like the company/team) I need to ask for 150k not sure if it is reasonable, over or under. What do you guys think?", "author_fullname": "t2_5b03yxcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineer salary in Europe (start up)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188fla3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701448378.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701447008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4 years of experience and I am non-EU what is the reasonable amount in Euros that I should ask for? (German start up)&lt;/p&gt;\n\n&lt;p&gt;I am currently based on UAE and I get paid 73k but here it is 0 taxes, If I want to get paid just as much I am being paid right now after the 40% income taxes (which is something I don\u2019t mind, I just want to relocate for fun and i like the company/team) I need to ask for 150k not sure if it is reasonable, over or under. What do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188fla3", "is_robot_indexable": true, "report_reasons": null, "author": "nullisist", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188fla3/senior_data_engineer_salary_in_europe_start_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188fla3/senior_data_engineer_salary_in_europe_start_up/", "subreddit_subscribers": 142954, "created_utc": 1701447008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m392e2dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking Data Insights with Databricks Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_18870pp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8WiHo2Clu7YtQ__go91hTCXQ5emgV8-WaJ6DimcbUes.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701419607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/data-insights-databricks-notebooks/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?auto=webp&amp;s=9afd2e67e2e0866c4b0ff84dbfde07fb313f5311", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8d1fb25f3d158b43b188049ff2a4b1a0b9d4eee", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84dd3dcb4403560727cde9791e041da09cc8c370", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/5oMxAvOdPYyeUBN1i5VzYKlS9n89oZBAOocCHlVvm7E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e6710095586d21050f5612018f30559107e8f02", "width": 320, "height": 274}], "variants": {}, "id": "0T3KDe0T4-QxpiEdbaSZ8fXPQ24Ga4lF-62bhoamp74"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18870pp", "is_robot_indexable": true, "report_reasons": null, "author": "sunher444", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18870pp/unlocking_data_insights_with_databricks_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/data-insights-databricks-notebooks/", "subreddit_subscribers": 142954, "created_utc": 1701419607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven\u2019t start experimenting Airflow yet but just curious that what sort of benefit I will get from Airflow. \n\nPersonally i think that Azure function is much convenience since we don\u2019t have to manage any infra work. I am just wondering what makes Airflow so famous in data engineering space and is there additional use case outside of data engineering.", "author_fullname": "t2_dgqi4197", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs Azure Function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1884240", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701408559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven\u2019t start experimenting Airflow yet but just curious that what sort of benefit I will get from Airflow. &lt;/p&gt;\n\n&lt;p&gt;Personally i think that Azure function is much convenience since we don\u2019t have to manage any infra work. I am just wondering what makes Airflow so famous in data engineering space and is there additional use case outside of data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1884240", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Criticism-8127", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1884240/airflow_vs_azure_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1884240/airflow_vs_azure_function/", "subreddit_subscribers": 142954, "created_utc": 1701408559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The dataplatform on which I work on is following the medaillon architecture (we call them tiers): T1 for raw data, T2 for slightly refined/partitioned data, T3 for business specific data.\nEach of this tier is a file based storage (on GCP) and between each of these tiers data is being transfered/transformed by dataflow streaming jobs in an event driven fashion.\nBut because it is file based the latency between the moment we receive an event from a producer (kafka) and the moment it is available to be used by users (in T2 or T3) is around 5 minutes. It also makes the whole process undeterministic because each pipeline between tiers can be lagging a bit which can increase this latency.\n\nWe would like to enable realtime analytics (&lt;few seconds between the moment we receive the data and the moment it is available to be queried) in this context.\nWhat would be the best way to implement it in your opinion ?", "author_fullname": "t2_514a0zu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to combine realtime analytics with a tiered architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187w5ks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701385783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The dataplatform on which I work on is following the medaillon architecture (we call them tiers): T1 for raw data, T2 for slightly refined/partitioned data, T3 for business specific data.\nEach of this tier is a file based storage (on GCP) and between each of these tiers data is being transfered/transformed by dataflow streaming jobs in an event driven fashion.\nBut because it is file based the latency between the moment we receive an event from a producer (kafka) and the moment it is available to be used by users (in T2 or T3) is around 5 minutes. It also makes the whole process undeterministic because each pipeline between tiers can be lagging a bit which can increase this latency.&lt;/p&gt;\n\n&lt;p&gt;We would like to enable realtime analytics (&amp;lt;few seconds between the moment we receive the data and the moment it is available to be queried) in this context.\nWhat would be the best way to implement it in your opinion ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "187w5ks", "is_robot_indexable": true, "report_reasons": null, "author": "bretzeldalsace", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187w5ks/how_to_combine_realtime_analytics_with_a_tiered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187w5ks/how_to_combine_realtime_analytics_with_a_tiered/", "subreddit_subscribers": 142954, "created_utc": 1701385783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data scientists are not easily able to prototype on non-static data. This is our approach to getting real-time plotting in Jupyter.  [https://pathway.com/developers/showcases/live\\_data\\_jupyter/](https://pathway.com/developers/showcases/live_data_jupyter/) .  Would love your feedback and comments", "author_fullname": "t2_48nrgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time plotting and insights in Jupyter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187qu7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701401249.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701372572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data scientists are not easily able to prototype on non-static data. This is our approach to getting real-time plotting in Jupyter.  &lt;a href=\"https://pathway.com/developers/showcases/live_data_jupyter/\"&gt;https://pathway.com/developers/showcases/live_data_jupyter/&lt;/a&gt; .  Would love your feedback and comments&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?auto=webp&amp;s=f36a6bf0cb99bd3c6b7a7b9101db7da5f707b8c7", "width": 1400, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=31527d6355e8386b0db348634750a517553174f3", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5a390d3a6855e5eaf23ad1d9e9a7021a5f4fd3b", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0022220fee56b30b70b96437287fcab7061a563", "width": 320, "height": 137}, {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff738be64c50f7fd79a8c733994fec0d0f165e5b", "width": 640, "height": 274}, {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93480d9d7f1e813ed10ab785ddafd79974f1378e", "width": 960, "height": 411}, {"url": "https://external-preview.redd.it/SWd6POPwK7BN_UA5Pgs-okzJqoIfRBkgfLJ3sDTWLsg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=496223d96870751d12c9c6a8da96cc3b0b4d8964", "width": 1080, "height": 462}], "variants": {}, "id": "anmyn7byvOYtIvnIWHM2C9dFRHboaBu2lPXaH5yrJgM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "187qu7t", "is_robot_indexable": true, "report_reasons": null, "author": "anupsurendran", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187qu7t/realtime_plotting_and_insights_in_jupyter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187qu7t/realtime_plotting_and_insights_in_jupyter/", "subreddit_subscribers": 142954, "created_utc": 1701372572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&amp;#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion - Dec 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo", "t3_13xldpd", "t3_167b3ep", "t3_188grde"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1701450046.836, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ia7kdykk8dlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=814f58d3eef18e16ebfd881a24dc42c6278c74a5"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=220aef8c88d2d3542556dbc0ceda11308fae54cd"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc0f5873d0a5e748e4664a4925eb409775331c20"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd"}, "id": "ia7kdykk8dlb1"}}, "name": "t3_188grde", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 6, "domain": "self.dataengineering", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/WxbPZZDAlp5ZrmC7zINz_BAGO251Q2TbQDAOSYvGspE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1701450046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\"&gt;https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://tally.so/r/nraYkN\"&gt;Submit your salary here&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can view and analyze all of the data on our &lt;a href=\"https://dataengineering.wiki/Community/Salaries\"&gt;DE salary page&lt;/a&gt; and get involved with this open-source project &lt;a href=\"https://github.com/data-engineering-community/data-engineering-salaries\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Current title&lt;/li&gt;\n&lt;li&gt;Years of experience (YOE)&lt;/li&gt;\n&lt;li&gt;Location&lt;/li&gt;\n&lt;li&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/li&gt;\n&lt;li&gt;Bonuses/Equity (optional)&lt;/li&gt;\n&lt;li&gt;Industry (optional)&lt;/li&gt;\n&lt;li&gt;Tech stack (optional)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?auto=webp&amp;s=c116639b0e48888e352e060ba2c5f56c07ab43d9", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab73c993eac3ccefd58966d64ec6e5a5dd05f808", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1955a17c66a64ef42bfc6aa52227a3b0a183660b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfad0ea778337cf0589b3428603d1e71cff228fb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a6b65e67a3bcf61b738f8852810c86c1b01298f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b95d64dc6f3995876325c594dbe2dd77c627d406", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=079bd9b9cebe8cd705d7824f7f2a75c5213c3cf7", "width": 1080, "height": 567}], "variants": {}, "id": "vXOF8G9GBUU_-_vM38jf2S1-5UiTZqBcFWecpk4eHS4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188grde", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188grde/quarterly_salary_discussion_dec_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/188grde/quarterly_salary_discussion_dec_2023/", "subreddit_subscribers": 142954, "created_utc": 1701450046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dahhpma5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta sues FTC over child data dispute, claiming \u2018unconstitutional authority\u2019", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_188a1oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AYzF2_DTPXQ15H0eE0lHDuyDVQ3RaDk1EAzxs5v2oBM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701431551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newyorkverified.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://newyorkverified.com/4335822-meta-sues-ftc-over-child-data-dispute-claiming-unconstitutional-authority/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?auto=webp&amp;s=0bb573c4672243e3689b34f5a04248d7b38dc2f6", "width": 1280, "height": 719}, "resolutions": [{"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0285ecf01abccc670e90eaa11b9a5c7e460a0b50", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb0052b2d32de398af56bab8b79e4cf9c7a46ba9", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c495ffef0cdc7499d7b75623aebc8a86216889d2", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7b1b676815c137d138afa193a4bf1e8ee7baf39c", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=653c941ee30f67828fd21c01970d88ae022cb90f", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/t13HSCCp6Id4SMn4fub4FGx7T14pMrCRpCT3q6ZzXq4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d086e7bafe3339c4fa61bc5ee7f7f7c4aaf4bed", "width": 1080, "height": 606}], "variants": {}, "id": "9dC5E05J_dmwcO4MTkZtkHiE7bFNFAa2fQpGGFrDO6I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188a1oi", "is_robot_indexable": true, "report_reasons": null, "author": "anujtomar_17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188a1oi/meta_sues_ftc_over_child_data_dispute_claiming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://newyorkverified.com/4335822-meta-sues-ftc-over-child-data-dispute-claiming-unconstitutional-authority/", "subreddit_subscribers": 142954, "created_utc": 1701431551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am quite new to data engineering. Trying to switch roles from data analyst to data engineer. Recently in one of the interviews, I was asked :\n\nHow would you ensure quality of data in the outputs, visualisation while having a semi real time pipeline which is continuously running?\n\nI said :\n\nI will set up some sort of alerting system which will get triggered everything there is an issue with the data flow.\n\nBut apparently the answer wasn\u2019t good enough. Any suggestions what could be procedure to follow for better data quality?", "author_fullname": "t2_sjfy1rn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real time pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188ckak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701439284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am quite new to data engineering. Trying to switch roles from data analyst to data engineer. Recently in one of the interviews, I was asked :&lt;/p&gt;\n\n&lt;p&gt;How would you ensure quality of data in the outputs, visualisation while having a semi real time pipeline which is continuously running?&lt;/p&gt;\n\n&lt;p&gt;I said :&lt;/p&gt;\n\n&lt;p&gt;I will set up some sort of alerting system which will get triggered everything there is an issue with the data flow.&lt;/p&gt;\n\n&lt;p&gt;But apparently the answer wasn\u2019t good enough. Any suggestions what could be procedure to follow for better data quality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "188ckak", "is_robot_indexable": true, "report_reasons": null, "author": "Pro_Panda_Puppy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188ckak/real_time_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188ckak/real_time_pipeline/", "subreddit_subscribers": 142954, "created_utc": 1701439284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you guys think that Rust is going to be used extensively data engineering, getting a lot of youtube recommendation about it. I know there is Apache Ballista Project (Apache Spark competitor) which is written in Rust but still in early development.", "author_fullname": "t2_7jtukhcz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1882mam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701403937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys think that Rust is going to be used extensively data engineering, getting a lot of youtube recommendation about it. I know there is Apache Ballista Project (Apache Spark competitor) which is written in Rust but still in early development.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1882mam", "is_robot_indexable": true, "report_reasons": null, "author": "Headbanger1321", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1882mam/rust_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1882mam/rust_for_data_engineering/", "subreddit_subscribers": 142954, "created_utc": 1701403937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is beginning an analytics platform redesign and we've decided to invest in a strong semantic layer tool for our BI, because we have a small analytics team and a lot of complex derived performance metrics that need to be consistent (we do forecasting and order replenishment along with manage a large user base).\n\nWe were originally excited about Looker + LookML but they are coming in at an astronomically high price. [Cube.dev](https://Cube.dev) \\+ Metabase looks like a good alternative, but I can't find any real people's accounts of using it beyond their demo videos. Can anyone who migrated from Looker -&gt; cube.dev/metabase share their experience, especially if there were important features that were missing or things that were easy that broke? \n\nThanks a ton! ", "author_fullname": "t2_6h777rv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to Cube.dev + Metabase from Looker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187zlkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701394987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is beginning an analytics platform redesign and we&amp;#39;ve decided to invest in a strong semantic layer tool for our BI, because we have a small analytics team and a lot of complex derived performance metrics that need to be consistent (we do forecasting and order replenishment along with manage a large user base).&lt;/p&gt;\n\n&lt;p&gt;We were originally excited about Looker + LookML but they are coming in at an astronomically high price. &lt;a href=\"https://Cube.dev\"&gt;Cube.dev&lt;/a&gt; + Metabase looks like a good alternative, but I can&amp;#39;t find any real people&amp;#39;s accounts of using it beyond their demo videos. Can anyone who migrated from Looker -&amp;gt; cube.dev/metabase share their experience, especially if there were important features that were missing or things that were easy that broke? &lt;/p&gt;\n\n&lt;p&gt;Thanks a ton! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "187zlkv", "is_robot_indexable": true, "report_reasons": null, "author": "waitingfortheset", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187zlkv/moving_to_cubedev_metabase_from_looker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187zlkv/moving_to_cubedev_metabase_from_looker/", "subreddit_subscribers": 142954, "created_utc": 1701394987.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lmk if that analogy makes sense. \n\nAlso would be great to hear what tech is best used and also how to pivot , ensure to grow my career in that direction. \n\nBeen in data for awhile but want to stay relevant (understand tho there are many relevant use cases for data that are valuable and varying levels of sexiness). \n\nAlso, asking about data engineering roles not like some other tech role , ie people that focus on data problems ", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most valuable data engineering roles ? Ie if ai is a gold rush and data engineering are making shovels , how do we make sure we are making shovels used for gold minding and not just dirt moving ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188eyqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701445414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lmk if that analogy makes sense. &lt;/p&gt;\n\n&lt;p&gt;Also would be great to hear what tech is best used and also how to pivot , ensure to grow my career in that direction. &lt;/p&gt;\n\n&lt;p&gt;Been in data for awhile but want to stay relevant (understand tho there are many relevant use cases for data that are valuable and varying levels of sexiness). &lt;/p&gt;\n\n&lt;p&gt;Also, asking about data engineering roles not like some other tech role , ie people that focus on data problems &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "188eyqq", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188eyqq/what_are_the_most_valuable_data_engineering_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188eyqq/what_are_the_most_valuable_data_engineering_roles/", "subreddit_subscribers": 142954, "created_utc": 1701445414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How ngrok uses Dagster to run our data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_188ebz5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/B2KEz8dKXM5TO7CLeNpiCS_HHOcw-CMg-_gTPzNOJME.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701443765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ngrok.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?auto=webp&amp;s=d7495ccc708106170153547f85aeb15b9fddf837", "width": 2000, "height": 1047}, "resolutions": [{"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b76888143e713da79ccb474b052553b6bb45b55", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5cb78f3328d47c620f863dbe33f6f6a42492836", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a71c835f200398fe4ccfa31fd2a52ec7c328fef8", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf8f3305dc687a2aa93ecd0e626f07cfa6f9447e", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=237e9950892f4a61b9ba5c14b02faa3a53b5d173", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/TiLhFR84GYx54vQHIX1-_I17F_c0qQwwZ6P48xp4ZRg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4263800e3162b6e8400053c3a5429b2d8fb4c5fa", "width": 1080, "height": 565}], "variants": {}, "id": "M1lscahhg0tO_VSCnQfckWjPGPHlakUNvuck7KkVgyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "188ebz5", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188ebz5/how_ngrok_uses_dagster_to_run_our_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform", "subreddit_subscribers": 142954, "created_utc": 1701443765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey data engineers, \nThe company that I work with track fleet of cars with gps tracker, it has a php program that read the data from those gps trackers and store it in on MySQL database, and than they read the data from it to display it on their mobile and web app, note that they have a delay of 10s with this approach and analytic request take a bit of times to respond.\nMy question is I want to improve their architecture by adding a data warehouse for analytics and to use apache Kafka to read the data from the gps trackers and then send it to different targets. Is this a good approach? Note that the company doesn't want to spend a lot of money on cloud service providers\nI also want to know if this is a good idea or it will just make the process more complex. Should they just insert the data from gps trackers into the database without the use of Kafka and then process and analyse that data from the database? ", "author_fullname": "t2_e1i3duqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187twfz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701383634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701380189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data engineers, \nThe company that I work with track fleet of cars with gps tracker, it has a php program that read the data from those gps trackers and store it in on MySQL database, and than they read the data from it to display it on their mobile and web app, note that they have a delay of 10s with this approach and analytic request take a bit of times to respond.\nMy question is I want to improve their architecture by adding a data warehouse for analytics and to use apache Kafka to read the data from the gps trackers and then send it to different targets. Is this a good approach? Note that the company doesn&amp;#39;t want to spend a lot of money on cloud service providers\nI also want to know if this is a good idea or it will just make the process more complex. Should they just insert the data from gps trackers into the database without the use of Kafka and then process and analyse that data from the database? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "187twfz", "is_robot_indexable": true, "report_reasons": null, "author": "ryan7ait", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187twfz/apache_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187twfz/apache_kafka/", "subreddit_subscribers": 142954, "created_utc": 1701380189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow Data Engineers,\n\nI've recently been delving into the role of business layers and data modeling in data warehouses and came across two fascinating yet opposing views. The first article, by Markus Winand ([Why Enterprise Data Models Don\u2019t Work](https://www.feststelltaste.de/why-enterprise-data-models-dont-work/)), argues that enterprise data models are often impractical and don't effectively serve the needs of businesses. Winand suggests that these models are too rigid and don't adapt well to the dynamic nature of business requirements.\n\nOn the other hand, Marko Oja's article ([Data Models Never Become Obsolete](https://www.linkedin.com/pulse/data-models-never-become-obsolete-marko-oja/)) presents a contrasting perspective. Oja defends the timelessness of data models, emphasizing their foundational role in understanding and managing data, irrespective of evolving technologies and practices.\n\nThis difference of opinion raises several questions:\n\nHow do we balance the need for structured data models with the agility required by modern business processes? Can data models evolve with technological advancements without losing their core value? Are traditional data modeling approaches still relevant, or do we need a paradigm shift? As someone who is deeply involved in the data engineering field, I find these perspectives intriguing. I'm curious to hear your thoughts and experiences. How do you approach data modeling in your work? What challenges have you faced, and what solutions have you found effective?\n\n I'm eager to hear your perspectives and experiences. But first, let's start with a quick poll:  \n\n\n**Challenges in Current Data Modeling Practices**\n\n[View Poll](https://www.reddit.com/poll/187rs0k)", "author_fullname": "t2_5zyyjiwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling and Business Layer in DWH: Evolution or Obsolescence?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187rs0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701374924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been delving into the role of business layers and data modeling in data warehouses and came across two fascinating yet opposing views. The first article, by Markus Winand (&lt;a href=\"https://www.feststelltaste.de/why-enterprise-data-models-dont-work/\"&gt;Why Enterprise Data Models Don\u2019t Work&lt;/a&gt;), argues that enterprise data models are often impractical and don&amp;#39;t effectively serve the needs of businesses. Winand suggests that these models are too rigid and don&amp;#39;t adapt well to the dynamic nature of business requirements.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, Marko Oja&amp;#39;s article (&lt;a href=\"https://www.linkedin.com/pulse/data-models-never-become-obsolete-marko-oja/\"&gt;Data Models Never Become Obsolete&lt;/a&gt;) presents a contrasting perspective. Oja defends the timelessness of data models, emphasizing their foundational role in understanding and managing data, irrespective of evolving technologies and practices.&lt;/p&gt;\n\n&lt;p&gt;This difference of opinion raises several questions:&lt;/p&gt;\n\n&lt;p&gt;How do we balance the need for structured data models with the agility required by modern business processes? Can data models evolve with technological advancements without losing their core value? Are traditional data modeling approaches still relevant, or do we need a paradigm shift? As someone who is deeply involved in the data engineering field, I find these perspectives intriguing. I&amp;#39;m curious to hear your thoughts and experiences. How do you approach data modeling in your work? What challenges have you faced, and what solutions have you found effective?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your perspectives and experiences. But first, let&amp;#39;s start with a quick poll:  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Challenges in Current Data Modeling Practices&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/187rs0k\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LYeJiwIB2uw1q0jUgpV0rbdpjJHRRDCDyWf7zTKID_s.jpg?auto=webp&amp;s=5e015294e2eba012be84402890b23075b6354472", "width": 270, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/LYeJiwIB2uw1q0jUgpV0rbdpjJHRRDCDyWf7zTKID_s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d47209b78279f4686c9b4fee7386a5f0cdddd45b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/LYeJiwIB2uw1q0jUgpV0rbdpjJHRRDCDyWf7zTKID_s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b93e5ad5dd12c1caef72d622b98c8f312f450845", "width": 216, "height": 216}], "variants": {}, "id": "0gsPJ1gJ_UPTpXw-YHyhiG-JRFpQQ6Xu35_29Nu1rTI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "187rs0k", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed_Cantaloupe_9", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1701979724650, "options": [{"text": "Inflexibility to adapt to business changes.", "id": "26212133"}, {"text": "Complexity and difficulty in understanding.", "id": "26212134"}, {"text": "Lack of integration with modern data tools.", "id": "26212135"}, {"text": "Scalability issues with large data sets.", "id": "26212136"}, {"text": "No major challenges noted.", "id": "26212137"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 14, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187rs0k/data_modeling_and_business_layer_in_dwh_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/187rs0k/data_modeling_and_business_layer_in_dwh_evolution/", "subreddit_subscribers": 142954, "created_utc": 1701374924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data team at Metabase created an [open source financial modeling package for startups](https://www.metabase.com/startup-guide/package/setup). It's MIT licensed, so feel free to modify, contribute, use however.\n\nLooking for suggestions on how to improve the workflow; minimize prerequisites and speed up the dap output. Right now it's a bit heavy-handed (copy the template -&gt; clone the repo -&gt; install dependencies -&gt; set up py -&gt; run commands -&gt; etc.)\n\nIf anyone has experience working with/on a similar project, can you drop a Github link/advice? Having trouble finding similar packages that model existing data and and output it to a product.", "author_fullname": "t2_g5hys8957", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving an open source financial modeling package", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188hgiw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701451812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data team at Metabase created an &lt;a href=\"https://www.metabase.com/startup-guide/package/setup\"&gt;open source financial modeling package for startups&lt;/a&gt;. It&amp;#39;s MIT licensed, so feel free to modify, contribute, use however.&lt;/p&gt;\n\n&lt;p&gt;Looking for suggestions on how to improve the workflow; minimize prerequisites and speed up the dap output. Right now it&amp;#39;s a bit heavy-handed (copy the template -&amp;gt; clone the repo -&amp;gt; install dependencies -&amp;gt; set up py -&amp;gt; run commands -&amp;gt; etc.)&lt;/p&gt;\n\n&lt;p&gt;If anyone has experience working with/on a similar project, can you drop a Github link/advice? Having trouble finding similar packages that model existing data and and output it to a product.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?auto=webp&amp;s=ee4d1f594d0a8ecdbc757064e02ea47184c1b9ec", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf405997fe808b1c7bd2394d8aec195d0ad69bbd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae6e0d64f4392b98ccc808aacc4c95af7a6849c0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8594f08331b3730de1ca94867ea49691cc7ae334", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d74a0e5c18c62b0d6efee05f83c5a8cdbf0f7313", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=df20c8098c7f2cb2af909cf3168fe6ed04033e5c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9ZTVuf17E7YdirkUiAJUfB8vA2ZwmxD6VENvheTWLZI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f29bb8bc586f565c47a385968d715de3ae5dcf08", "width": 1080, "height": 567}], "variants": {}, "id": "j890m6Os9XXMcHOhMlnLhRqPrwfsV0bPDP2U1-jPaJE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "188hgiw", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Pepper-645", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188hgiw/improving_an_open_source_financial_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188hgiw/improving_an_open_source_financial_modeling/", "subreddit_subscribers": 142954, "created_utc": 1701451812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI've currently been applying to junior/entry level data engineer roles in the UK solidly for a few months now and having next to no luck. The only application I got a response from I got to a second round interview for before being rejected. This is from both me applying myself + some recruiters reaching out for me.\n\nCurrently have just over a year's experience as a Data Consultant which has given me exposure to both consultancy and engineering practices which is what's making me want to specialise on the more technical side - my CV is currently much more tailored towards the data engineering experiences I've had over the past year but I feel as though my applications may be getting overlooked for those who already have (more) experience in specifically DE roles?\n\nAm feeling stuck as I'd love to leave consultancy and build out a career in a DE role as I've always heavily preferred those aspects to my job roles - but I'm not sure how to best go about gaining entry into the field.\n\nI know there's a case to be made for staying at my current role a bit longer but I feel like I'd have to start at a junior level regardless of how long I stay, as my job is not DE specific and is missing some key tech stacks (like use of Azure/AWS/GCP for e.g.) - so would rather move and gain experience in these as soon as possible.\n\nThanks in advance for any words of advice.\n\n\\--\n\n*Quick summary of my exp: UCL STEM Grad, 1yr experience as a Data Consultant - (re DE skills) using primarily SQL + SSMS, Python (pandas, selenium , various web/pdf scrapers + excel writers), SSIS for ETL tool, Databricks, Power BI + Tableau*", "author_fullname": "t2_ggdul3b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to find an entry point into Junior/Entry level DE roles despite having a data background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188cc5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701441067.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701438659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve currently been applying to junior/entry level data engineer roles in the UK solidly for a few months now and having next to no luck. The only application I got a response from I got to a second round interview for before being rejected. This is from both me applying myself + some recruiters reaching out for me.&lt;/p&gt;\n\n&lt;p&gt;Currently have just over a year&amp;#39;s experience as a Data Consultant which has given me exposure to both consultancy and engineering practices which is what&amp;#39;s making me want to specialise on the more technical side - my CV is currently much more tailored towards the data engineering experiences I&amp;#39;ve had over the past year but I feel as though my applications may be getting overlooked for those who already have (more) experience in specifically DE roles?&lt;/p&gt;\n\n&lt;p&gt;Am feeling stuck as I&amp;#39;d love to leave consultancy and build out a career in a DE role as I&amp;#39;ve always heavily preferred those aspects to my job roles - but I&amp;#39;m not sure how to best go about gaining entry into the field.&lt;/p&gt;\n\n&lt;p&gt;I know there&amp;#39;s a case to be made for staying at my current role a bit longer but I feel like I&amp;#39;d have to start at a junior level regardless of how long I stay, as my job is not DE specific and is missing some key tech stacks (like use of Azure/AWS/GCP for e.g.) - so would rather move and gain experience in these as soon as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any words of advice.&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Quick summary of my exp: UCL STEM Grad, 1yr experience as a Data Consultant - (re DE skills) using primarily SQL + SSMS, Python (pandas, selenium , various web/pdf scrapers + excel writers), SSIS for ETL tool, Databricks, Power BI + Tableau&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188cc5u", "is_robot_indexable": true, "report_reasons": null, "author": "DeviceNew9623", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188cc5u/struggling_to_find_an_entry_point_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188cc5u/struggling_to_find_an_entry_point_into/", "subreddit_subscribers": 142954, "created_utc": 1701438659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a DS but my projects are often blocked because we don\u2019t have enough DE. I want to help share the load but not be a burden. I asked the DE but they said they don\u2019t have time to train. Our stack is Apache based (Hadoop, Impala, Spark, Cassandra) plus some other stuff like Kubernetes, REST API, and Rabbit MQ.\n\nMy background is stats and I know SQL and Python. I have no CS background. Not sure where to begin. Thanks.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a Data Scientist how do I expand my engineering knowledge to help the team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187z0tw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701393387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DS but my projects are often blocked because we don\u2019t have enough DE. I want to help share the load but not be a burden. I asked the DE but they said they don\u2019t have time to train. Our stack is Apache based (Hadoop, Impala, Spark, Cassandra) plus some other stuff like Kubernetes, REST API, and Rabbit MQ.&lt;/p&gt;\n\n&lt;p&gt;My background is stats and I know SQL and Python. I have no CS background. Not sure where to begin. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "187z0tw", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187z0tw/as_a_data_scientist_how_do_i_expand_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187z0tw/as_a_data_scientist_how_do_i_expand_my/", "subreddit_subscribers": 142954, "created_utc": 1701393387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a data team in a very legacy platform and we're struggling under a constant demand from business side to bring in adhoc spreadsheets they receive from business partners and the like (sales leads, prospects on joint projects, points of contact for partnerships etc) and we don't have any kind of ERP or other software that would let them bring it on other than literally copy pasting it into plain text to dump into a corporate record. We do have a data lake but there's just no corporate supported interface or app for the users to bring this in themselves so we're usually asked to make adhoc dashboards and viz. \n\nNow, we do have some schemas and other legacy resources (avro and protobuf) we could use to model these better into some kind of standard schema for 80% of these situations, but no resources to deploy a custom data entry solution here. Our team is somewhat technical but not much on the coding side to just do this in Python for every ETL job.\n\nI've been searching across the python and ETL world but I just can't seem to find any decent libraries that could help template this out a bit. Like, given a CSV, type in matching columns to normalize them into the schema and then write this to our data warehouse (currently impala but looking to migrate to postgres).\n\nAm I missing some sort of obvious framework, library or ETL package that would support this or is writing out custom Python ETL scripts from scratch the only solution? Any good examples of managing data tranaforma between different schemas on python, pyspark etc?", "author_fullname": "t2_o60763zfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Supporting adhoc ETL of spreadsheets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187xjav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701389388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a data team in a very legacy platform and we&amp;#39;re struggling under a constant demand from business side to bring in adhoc spreadsheets they receive from business partners and the like (sales leads, prospects on joint projects, points of contact for partnerships etc) and we don&amp;#39;t have any kind of ERP or other software that would let them bring it on other than literally copy pasting it into plain text to dump into a corporate record. We do have a data lake but there&amp;#39;s just no corporate supported interface or app for the users to bring this in themselves so we&amp;#39;re usually asked to make adhoc dashboards and viz. &lt;/p&gt;\n\n&lt;p&gt;Now, we do have some schemas and other legacy resources (avro and protobuf) we could use to model these better into some kind of standard schema for 80% of these situations, but no resources to deploy a custom data entry solution here. Our team is somewhat technical but not much on the coding side to just do this in Python for every ETL job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching across the python and ETL world but I just can&amp;#39;t seem to find any decent libraries that could help template this out a bit. Like, given a CSV, type in matching columns to normalize them into the schema and then write this to our data warehouse (currently impala but looking to migrate to postgres).&lt;/p&gt;\n\n&lt;p&gt;Am I missing some sort of obvious framework, library or ETL package that would support this or is writing out custom Python ETL scripts from scratch the only solution? Any good examples of managing data tranaforma between different schemas on python, pyspark etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "187xjav", "is_robot_indexable": true, "report_reasons": null, "author": "YieldingSign", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/187xjav/supporting_adhoc_etl_of_spreadsheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/187xjav/supporting_adhoc_etl_of_spreadsheets/", "subreddit_subscribers": 142954, "created_utc": 1701389388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a client that is exploring cost reduction opportunities. They currently have about 1tb of data in Snowflake, and this database serves a Streamlit application. Costs are getting out of control (like 50-80k per month). I still don't have access to the Snowflake console to explore the queries that are running, as I'm waiting on access. My gut is that Snowflake is overkill, but I'm not certain. The couple tables that the app pulls from are pre-calculated and have over 1 billion rows. They are playing with downsizing the cluster. My questions are...could another database type serve this role better and for lower cost? Redshift? Azure Synapse? What about traditional RDS? I wish I had more details for ya'll - what are your experiences between different databases and DWs in terms of cost and use?  \n\n\nAnother question - could I send the pre-calculated tables to another service like RDS use that for the application instead? ", "author_fullname": "t2_4n94s86o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to reduce costs - which service to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_188il0x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701458033.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701454680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a client that is exploring cost reduction opportunities. They currently have about 1tb of data in Snowflake, and this database serves a Streamlit application. Costs are getting out of control (like 50-80k per month). I still don&amp;#39;t have access to the Snowflake console to explore the queries that are running, as I&amp;#39;m waiting on access. My gut is that Snowflake is overkill, but I&amp;#39;m not certain. The couple tables that the app pulls from are pre-calculated and have over 1 billion rows. They are playing with downsizing the cluster. My questions are...could another database type serve this role better and for lower cost? Redshift? Azure Synapse? What about traditional RDS? I wish I had more details for ya&amp;#39;ll - what are your experiences between different databases and DWs in terms of cost and use?  &lt;/p&gt;\n\n&lt;p&gt;Another question - could I send the pre-calculated tables to another service like RDS use that for the application instead? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "188il0x", "is_robot_indexable": true, "report_reasons": null, "author": "GuyWhoWantsToFly", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188il0x/need_to_reduce_costs_which_service_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188il0x/need_to_reduce_costs_which_service_to_use/", "subreddit_subscribers": 142954, "created_utc": 1701454680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently trying to work on a personal project where I extracted 200k message from a group chat and I'm working on some visualisations with it.\n\n I'm using seaborn for the plotting part but... It's very slow. Is there any better lib for this ? Vispy seem to be GPU powered but I feel it's pretty limited, so any advice is welcome", "author_fullname": "t2_kupm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Effective Dataviz", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_188igno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701454368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently trying to work on a personal project where I extracted 200k message from a group chat and I&amp;#39;m working on some visualisations with it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using seaborn for the plotting part but... It&amp;#39;s very slow. Is there any better lib for this ? Vispy seem to be GPU powered but I feel it&amp;#39;s pretty limited, so any advice is welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "188igno", "is_robot_indexable": true, "report_reasons": null, "author": "JalanJr", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188igno/effective_dataviz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188igno/effective_dataviz/", "subreddit_subscribers": 142954, "created_utc": 1701454368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ewsdi5ave", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Query optimization through minimum expression and column subset in subselects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 110, "top_awarded_type": null, "hide_score": true, "name": "t3_188huh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4MN6luqpNkD0QYY7RdtoXLfaDEhrLfn-uh5hsDHVJeM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701452787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "oxla.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://oxla.com/minimum-expression-and-column-subset-in-subselects/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?auto=webp&amp;s=9aaa2fee6e5c5a13cfde121313582dd79009fb9a", "width": 1916, "height": 1509}, "resolutions": [{"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2589cbe35597be978ff2fde17e8fa1e2f138c5db", "width": 108, "height": 85}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7a0633c6ef5656026731440cfae6d4bddc08fb", "width": 216, "height": 170}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3faf30d5b5acf4fc64fbc13bd568ccde52a037cf", "width": 320, "height": 252}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=abaac78ab7f59e87f02dbd1bfd9478c564a08824", "width": 640, "height": 504}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ef92174b202cce779d7975c2af65b3feb2640e4", "width": 960, "height": 756}, {"url": "https://external-preview.redd.it/lxeLlzDTTY6WfGUKb_YpCGlYl9HPwNxNDh8RWIEzi3o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a568f31d81ca0aef448e816bffd1c5c5cf4abf4a", "width": 1080, "height": 850}], "variants": {}, "id": "b4HsGfo1VdTN0M_Q1BQvmzxik792VsNl4OEhFIQhz_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "188huh8", "is_robot_indexable": true, "report_reasons": null, "author": "adam_optimizer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188huh8/sql_query_optimization_through_minimum_expression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://oxla.com/minimum-expression-and-column-subset-in-subselects/", "subreddit_subscribers": 142954, "created_utc": 1701452787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently junior CS at college. I did DE internship my sophomore year. Even though I liked it, my initial goal was to explore SWE first and go to other fields later on. On internship hunt for next year (last one before I graduate), I noticed that most interviews I would get are DE positions and even when I had final interview for Data Analytics department for F200 company, they wanted me to work on automation/ETL pipeline in their teams. What worries me is that I could be short sighted on this field if I\u2019m locked in so early. With mixed feelings, I wanted to get some inputs from y\u2019all how I should navigate career", "author_fullname": "t2_62rd0le", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling stuck with DE at early career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_188hbus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701451487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently junior CS at college. I did DE internship my sophomore year. Even though I liked it, my initial goal was to explore SWE first and go to other fields later on. On internship hunt for next year (last one before I graduate), I noticed that most interviews I would get are DE positions and even when I had final interview for Data Analytics department for F200 company, they wanted me to work on automation/ETL pipeline in their teams. What worries me is that I could be short sighted on this field if I\u2019m locked in so early. With mixed feelings, I wanted to get some inputs from y\u2019all how I should navigate career&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "188hbus", "is_robot_indexable": true, "report_reasons": null, "author": "topjarvanIV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/188hbus/feeling_stuck_with_de_at_early_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/188hbus/feeling_stuck_with_de_at_early_career/", "subreddit_subscribers": 142954, "created_utc": 1701451487.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}