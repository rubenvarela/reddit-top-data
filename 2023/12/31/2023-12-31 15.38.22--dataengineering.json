{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to build the data/analytics function in a non-tech/data organization. We are not a startup, I have an on-prem Oracle ERP database that has about 25 years of activity in it (\\~ 500GB). We have a few cloud-based enterprise apps (CRM for instance) that are cloud-based that we use but up to now we've not tried to extract data or do any integration. I've been tasked to change that. Operational data is mostly done via Access queries on the OLTP ERP database and shared Excel files. I just started using PowerBI to build out a couple dashboards for leadership but data governance/quality is a real issue. We have one DBA and myself to work on this.\n\nMy question is ... since we haven't moved to the cloud yet (although I see that coming at some point), and I see the need for data governance and something like a data warehouse/mart (i.e. modeled data, cleaned up snapshots over time, etc.) in order for us to make headway on providing data that is actionable, is it worth looking at modern data stack tools or should I really be looking at 90's era tools and techniques? Is something like Snowflake or Databricks reasonable for small data (never going to be more than 1 TB total)? Or should I just focus on building a local Postgres warehouse with Kimball/Inmon and ignore things like data lakes, Fivetran, DBT, Snowflake, and Airflow? Is there an in-between/hybrid approach that would work?", "author_fullname": "t2_f7itpbq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is modern data stack relevant for small data orgs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18uote4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703967911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to build the data/analytics function in a non-tech/data organization. We are not a startup, I have an on-prem Oracle ERP database that has about 25 years of activity in it (~ 500GB). We have a few cloud-based enterprise apps (CRM for instance) that are cloud-based that we use but up to now we&amp;#39;ve not tried to extract data or do any integration. I&amp;#39;ve been tasked to change that. Operational data is mostly done via Access queries on the OLTP ERP database and shared Excel files. I just started using PowerBI to build out a couple dashboards for leadership but data governance/quality is a real issue. We have one DBA and myself to work on this.&lt;/p&gt;\n\n&lt;p&gt;My question is ... since we haven&amp;#39;t moved to the cloud yet (although I see that coming at some point), and I see the need for data governance and something like a data warehouse/mart (i.e. modeled data, cleaned up snapshots over time, etc.) in order for us to make headway on providing data that is actionable, is it worth looking at modern data stack tools or should I really be looking at 90&amp;#39;s era tools and techniques? Is something like Snowflake or Databricks reasonable for small data (never going to be more than 1 TB total)? Or should I just focus on building a local Postgres warehouse with Kimball/Inmon and ignore things like data lakes, Fivetran, DBT, Snowflake, and Airflow? Is there an in-between/hybrid approach that would work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18uote4", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable_Log9395", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18uote4/is_modern_data_stack_relevant_for_small_data_orgs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18uote4/is_modern_data_stack_relevant_for_small_data_orgs/", "subreddit_subscribers": 149614, "created_utc": 1703967911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data engineer is a type of software engineer and everywhere suggests that software engineers should  know data structures and algorithms like insertion sort, merge sort,  binary search, etc.\n\nI feel like I'm not using any of them at all (or maybe I'm using some but don't aware that I am), but I still able to write tons of Python programs in my ETL development and they work just fine.\n\nAs my background is not actually from com sci, I feel it will take me so much time and effort to learn and not worthwhile comparing learning other stuffs and concepts in data engineering like data quality, data modeling, data warehousing, SQL mastery, unit testing, distributed data processing frameworks, streaming, machine learning, MLOps, IaC, DevOps, etc. \n\n&amp;#x200B;\n\nHappy New Year :)", "author_fullname": "t2_fl127m5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need to know coding algorithms in your job as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v0dn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704000412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data engineer is a type of software engineer and everywhere suggests that software engineers should  know data structures and algorithms like insertion sort, merge sort,  binary search, etc.&lt;/p&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m not using any of them at all (or maybe I&amp;#39;m using some but don&amp;#39;t aware that I am), but I still able to write tons of Python programs in my ETL development and they work just fine.&lt;/p&gt;\n\n&lt;p&gt;As my background is not actually from com sci, I feel it will take me so much time and effort to learn and not worthwhile comparing learning other stuffs and concepts in data engineering like data quality, data modeling, data warehousing, SQL mastery, unit testing, distributed data processing frameworks, streaming, machine learning, MLOps, IaC, DevOps, etc. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Happy New Year :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18v0dn0", "is_robot_indexable": true, "report_reasons": null, "author": "soravispr", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v0dn0/do_you_really_need_to_know_coding_algorithms_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v0dn0/do_you_really_need_to_know_coding_algorithms_in/", "subreddit_subscribers": 149614, "created_utc": 1704000412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What i am infering (not sure is ) the difference is with informatica there is a vendor lockin while with spark its not . . is it the main diffeernce .  \nBut I am not able to believe if its correct guess . . because i am seeing lot of big shot presentation on informatica +databricks [https://www.databricks.com/partners/informatica](https://www.databricks.com/partners/informatica)and lot of investment in informatica to support in modern cloud .So what is the use case of Informatica/talend +Databricks . . vs Pyspark +Databricks\n\n***PLEASE NOTE***  : I am not referring to the old legacy ETL only tool functionality of informatica but comparing the latest clould one with DataBricks .  \n\n\nPlease note that i agree that Old ETL only informatica /talend had significant scalability issue , IMy qn is not wrt the old etl tool when data lake was never a concept .  \n\n\nMy qn is wrt latest  informatica /talend clould inegration with DataBricks which they  marketing themseves as highly scalable for big data . So is the quesion in that context   \n **Informatica(latest cloud) with DataBricks vs Pyspark with DataBricks**    \n", "author_fullname": "t2_hwqrk3yk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica(latest cloud) with DataBricks vs Pyspark with DataBricks for modern Data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18um0uk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703961072.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703960694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What i am infering (not sure is ) the difference is with informatica there is a vendor lockin while with spark its not . . is it the main diffeernce .&lt;br/&gt;\nBut I am not able to believe if its correct guess . . because i am seeing lot of big shot presentation on informatica +databricks &lt;a href=\"https://www.databricks.com/partners/informatica\"&gt;https://www.databricks.com/partners/informatica&lt;/a&gt;and lot of investment in informatica to support in modern cloud .So what is the use case of Informatica/talend +Databricks . . vs Pyspark +Databricks&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;PLEASE NOTE&lt;/em&gt;&lt;/strong&gt;  : I am not referring to the old legacy ETL only tool functionality of informatica but comparing the latest clould one with DataBricks .  &lt;/p&gt;\n\n&lt;p&gt;Please note that i agree that Old ETL only informatica /talend had significant scalability issue , IMy qn is not wrt the old etl tool when data lake was never a concept .  &lt;/p&gt;\n\n&lt;p&gt;My qn is wrt latest  informatica /talend clould inegration with DataBricks which they  marketing themseves as highly scalable for big data . So is the quesion in that context&lt;br/&gt;\n &lt;strong&gt;Informatica(latest cloud) with DataBricks vs Pyspark with DataBricks&lt;/strong&gt;    &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18um0uk", "is_robot_indexable": true, "report_reasons": null, "author": "Data5kull", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18um0uk/informaticalatest_cloud_with_databricks_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18um0uk/informaticalatest_cloud_with_databricks_vs/", "subreddit_subscribers": 149614, "created_utc": 1703960694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me personally developing on the cloud is a pain. I'm used to and love my local setup, so I wrote a quick plugin to send commands to a databricks cluster from vim: [vim-databricks](https://github.com/kentkr/vim-databricks). The implementation is light weight and currently only supports sending python scripts or lines within those scripts, but there's more to come. Check it out and I'd love to get feedback, thanks!  \n\n\n&amp;#x200B;", "author_fullname": "t2_b8aole0pt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kick the cloud, use vim-databricks to develop locally", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18uth0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703980013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me personally developing on the cloud is a pain. I&amp;#39;m used to and love my local setup, so I wrote a quick plugin to send commands to a databricks cluster from vim: &lt;a href=\"https://github.com/kentkr/vim-databricks\"&gt;vim-databricks&lt;/a&gt;. The implementation is light weight and currently only supports sending python scripts or lines within those scripts, but there&amp;#39;s more to come. Check it out and I&amp;#39;d love to get feedback, thanks!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?auto=webp&amp;s=8c5ea9fe9ed382b3e17664bf3f41cf720d0d2b66", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7bbd9af8710259872f5f4058237fd97c775e0e73", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8277a1205bd8b0c0b7a11f237033ec34242d464a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7360b415079738380e1b2cde0e91fce4bca7bb40", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3097af9add8133ecbe364f40d32ecf9177bbe04c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23a7e987c7c973944785d5383e749f83001c1dae", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vcOL_xAL2S3svtT9LxvNc1FJl6-EcZogkpf0TjRLFZw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eefe3bc495962242c99d930bc8f083c443e5bd54", "width": 1080, "height": 540}], "variants": {}, "id": "W_qQKXG8q90rsMqydP_qXKr_Y2uWXS1jrzvQZrNyUt8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18uth0e", "is_robot_indexable": true, "report_reasons": null, "author": "IntroductionAny3343", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18uth0e/kick_the_cloud_use_vimdatabricks_to_develop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18uth0e/kick_the_cloud_use_vimdatabricks_to_develop/", "subreddit_subscribers": 149614, "created_utc": 1703980013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DataEngineering community!\n\nQuick heads up\u2014I'm not a storytelling pro and my word game is a bit meh. Got a little assist from ChatGPT for this post. \ud83d\ude05\n\nI'm diving into the data field and noticed something missing \u2013 a tool dedicated to PySpark practice in a practical setting. So, I'm brainstorming a new tool and would love your thoughts.\n\n**The Concept:**\n\n*Imagine a website tailored for data engineers, offering concise PySpark case studies from easy to challenging. Here's the twist \u2013 users won't practice on the site itself like Kaggle. Instead, they'll get detailed problem statements and corresponding datasets. They'll use their preferred environment to solve the challenges.*\n\n**Key Features:**\n\n**Daily mini-case studies:** Short, focused challenges covering everything from data cleaning to analysis, all curated from easy to mind-bending.\n\n**Corresponding datasets:** Each case study comes with its own unique, messy-as-life dataset, generated on the fly. Get your hands dirty with realistic data, not those squeaky-clean textbook examples.\n\n**Level-up your profile:** Conquer challenges, climb the leaderboard, and become a PySpark sensei! Track your progress, see where you shine, and where you might need a bit more training.\n\n**Stuck? No sweat!** Get hints and tips along the way to guide you through the trickiest parts. But remember, the real reward is figuring it out yourself!\n\n**What I'm Asking:**\n\nI need your insights! Does this sound beneficial? Could it help newcomers like me? What features are essential, and do you see any potential challenges?\n\nI'm eager to hear your thoughts! This project might be a crazy idea from a data newbie, but with your help, I believe it could turn into something truly valuable for our whole community. \n\n**Tech Talk:**\n\nLooking for advice on the tech side. Thinking of Streamlit, Python, and maybe GPT-3.5 for content.  But keen to hear your take on this idea\u2014what tech stack do you think require to materialize the idea.\n\nP.S. Even if you're newer to PySpark than a baby otter, your voice matters! Share your thoughts, experiences, and suggestions.", "author_fullname": "t2_db4lzqgcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback for a New PySpark Learning Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ujut9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703955028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DataEngineering community!&lt;/p&gt;\n\n&lt;p&gt;Quick heads up\u2014I&amp;#39;m not a storytelling pro and my word game is a bit meh. Got a little assist from ChatGPT for this post. \ud83d\ude05&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m diving into the data field and noticed something missing \u2013 a tool dedicated to PySpark practice in a practical setting. So, I&amp;#39;m brainstorming a new tool and would love your thoughts.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Concept:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Imagine a website tailored for data engineers, offering concise PySpark case studies from easy to challenging. Here&amp;#39;s the twist \u2013 users won&amp;#39;t practice on the site itself like Kaggle. Instead, they&amp;#39;ll get detailed problem statements and corresponding datasets. They&amp;#39;ll use their preferred environment to solve the challenges.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Daily mini-case studies:&lt;/strong&gt; Short, focused challenges covering everything from data cleaning to analysis, all curated from easy to mind-bending.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Corresponding datasets:&lt;/strong&gt; Each case study comes with its own unique, messy-as-life dataset, generated on the fly. Get your hands dirty with realistic data, not those squeaky-clean textbook examples.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Level-up your profile:&lt;/strong&gt; Conquer challenges, climb the leaderboard, and become a PySpark sensei! Track your progress, see where you shine, and where you might need a bit more training.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Stuck? No sweat!&lt;/strong&gt; Get hints and tips along the way to guide you through the trickiest parts. But remember, the real reward is figuring it out yourself!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m Asking:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I need your insights! Does this sound beneficial? Could it help newcomers like me? What features are essential, and do you see any potential challenges?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your thoughts! This project might be a crazy idea from a data newbie, but with your help, I believe it could turn into something truly valuable for our whole community. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tech Talk:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Looking for advice on the tech side. Thinking of Streamlit, Python, and maybe GPT-3.5 for content.  But keen to hear your take on this idea\u2014what tech stack do you think require to materialize the idea.&lt;/p&gt;\n\n&lt;p&gt;P.S. Even if you&amp;#39;re newer to PySpark than a baby otter, your voice matters! Share your thoughts, experiences, and suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ujut9", "is_robot_indexable": true, "report_reasons": null, "author": "DataWhizJunior", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ujut9/seeking_feedback_for_a_new_pyspark_learning_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ujut9/seeking_feedback_for_a_new_pyspark_learning_tool/", "subreddit_subscribers": 149614, "created_utc": 1703955028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a long application and interview process i finally landed a DE position after being a DA on the operations side for 2 years with a mechanical engineering background. I will be starting in the new year and this new company will be much more code heavy and utilize AWS, Docker, and github much more than i currently have used. \n\nWhat are some resources i can use to familiarize myself with these new tools since i don\u2019t have a CS background, how does a production environment compare to personal projects, and what are some good questions to ask my manager as i am onboarding to facilitate my transition?\n\nAny other general tips are also appreciated!", "author_fullname": "t2_sfg62", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips for new DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18uozj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703968364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a long application and interview process i finally landed a DE position after being a DA on the operations side for 2 years with a mechanical engineering background. I will be starting in the new year and this new company will be much more code heavy and utilize AWS, Docker, and github much more than i currently have used. &lt;/p&gt;\n\n&lt;p&gt;What are some resources i can use to familiarize myself with these new tools since i don\u2019t have a CS background, how does a production environment compare to personal projects, and what are some good questions to ask my manager as i am onboarding to facilitate my transition?&lt;/p&gt;\n\n&lt;p&gt;Any other general tips are also appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18uozj4", "is_robot_indexable": true, "report_reasons": null, "author": "2teknical", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18uozj4/tips_for_new_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18uozj4/tips_for_new_de/", "subreddit_subscribers": 149614, "created_utc": 1703968364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working on data engineering role even though my job title is software engineer. \nI have expertise in spark scala , AWS and terraform.\nI know my way around spark , spark optimisations (not just writing joins using dataframe), I also have lots of good exposure to AWS services and terraform.\n\nRecently I've been feeling little bored and routine work in my role. I've never worked on web related projects.\n\nAnd I'm afraid if I keep working in this role , I might not be able to switch to web dev in later stages of my career.\n\nI have a hard time deciding if I want to be in data engineering or move to web dev.\nI've been seeing online regarding SDEs trying to switch to data engineering and data science, especially in faang companies \n\nI'm really confused about which path to take.\nAny advice would be immensely appreciated.\n\nI'd want to know which path would have the most growth and scope and innovation.\n\nWhich role would be better in the long run and how difficult is to switch from one domain to another.\n\nI've been seeing sde roles paying better than data engineering.\n\n\nI brought it up with my manager and he said you could not get working with this huge amount of data nor infrastructure anywhere but you can always learn web developement on your own. And data engineering is close to AI ML than sde.\n\nPlease Help me understand the pros and cons in terms of pay, growth and value.\n\nWhich path would be helpful career and financial wise.\n\nNote: I'm having 2.5 years experience and I feel if I waste anymore time it'll be too late to switch domains as I will no longer be considered entry level. I've been promoted for my work last year and my manager says I'm on the fastest track to my next promotion.", "author_fullname": "t2_uchkkfwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering vs software engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v20x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704006143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on data engineering role even though my job title is software engineer. \nI have expertise in spark scala , AWS and terraform.\nI know my way around spark , spark optimisations (not just writing joins using dataframe), I also have lots of good exposure to AWS services and terraform.&lt;/p&gt;\n\n&lt;p&gt;Recently I&amp;#39;ve been feeling little bored and routine work in my role. I&amp;#39;ve never worked on web related projects.&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m afraid if I keep working in this role , I might not be able to switch to web dev in later stages of my career.&lt;/p&gt;\n\n&lt;p&gt;I have a hard time deciding if I want to be in data engineering or move to web dev.\nI&amp;#39;ve been seeing online regarding SDEs trying to switch to data engineering and data science, especially in faang companies &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really confused about which path to take.\nAny advice would be immensely appreciated.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d want to know which path would have the most growth and scope and innovation.&lt;/p&gt;\n\n&lt;p&gt;Which role would be better in the long run and how difficult is to switch from one domain to another.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been seeing sde roles paying better than data engineering.&lt;/p&gt;\n\n&lt;p&gt;I brought it up with my manager and he said you could not get working with this huge amount of data nor infrastructure anywhere but you can always learn web developement on your own. And data engineering is close to AI ML than sde.&lt;/p&gt;\n\n&lt;p&gt;Please Help me understand the pros and cons in terms of pay, growth and value.&lt;/p&gt;\n\n&lt;p&gt;Which path would be helpful career and financial wise.&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m having 2.5 years experience and I feel if I waste anymore time it&amp;#39;ll be too late to switch domains as I will no longer be considered entry level. I&amp;#39;ve been promoted for my work last year and my manager says I&amp;#39;m on the fastest track to my next promotion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18v20x7", "is_robot_indexable": true, "report_reasons": null, "author": "FreshAnalysis1139", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v20x7/data_engineering_vs_software_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v20x7/data_engineering_vs_software_engineering/", "subreddit_subscribers": 149614, "created_utc": 1704006143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in the data space for quite a few years. I\u2019ve recently been tasked to migrate from Big Query to Databricks.\n\nAny gotchas, migration paths, advice etc?\n\nPlease no people who are gona explain why their preferred vendor is better. It\u2019s annoying and not relevant", "author_fullname": "t2_vgdhv159", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from Big Query To Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18usv34", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703978407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in the data space for quite a few years. I\u2019ve recently been tasked to migrate from Big Query to Databricks.&lt;/p&gt;\n\n&lt;p&gt;Any gotchas, migration paths, advice etc?&lt;/p&gt;\n\n&lt;p&gt;Please no people who are gona explain why their preferred vendor is better. It\u2019s annoying and not relevant&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18usv34", "is_robot_indexable": true, "report_reasons": null, "author": "ThrowRA91010101323", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18usv34/migrating_from_big_query_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18usv34/migrating_from_big_query_to_databricks/", "subreddit_subscribers": 149614, "created_utc": 1703978407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This sounds a bit impossible because versioning schema changes sounds like keeping an sql file that builds the database schema from scratch. However, you don\u2019t `alter` a database the same way that you `create` one. So there\u2019s a translation layer there that I\u2019m not sure would be easy to overcome for automation.\n\nIs this sort of pipeline possible? Has it already been built?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to set up git for versioning schema changes to Postgres, with GitHub Actions for CI/CD ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v2vpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704009494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This sounds a bit impossible because versioning schema changes sounds like keeping an sql file that builds the database schema from scratch. However, you don\u2019t &lt;code&gt;alter&lt;/code&gt; a database the same way that you &lt;code&gt;create&lt;/code&gt; one. So there\u2019s a translation layer there that I\u2019m not sure would be easy to overcome for automation.&lt;/p&gt;\n\n&lt;p&gt;Is this sort of pipeline possible? Has it already been built?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18v2vpm", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v2vpm/is_it_possible_to_set_up_git_for_versioning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v2vpm/is_it_possible_to_set_up_git_for_versioning/", "subreddit_subscribers": 149614, "created_utc": 1704009494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked in the same data team for the past 5 years, and up until a year ago we were *the* data team for a \\~100 person startup; we designed, built, and maintained all data pipelines, databases, and related applications. We were acquired last year, and our company is now at 6,000 people. As part of this acquisition, our data team was transitioned from the business into IT as part of the data platform team. The issue here is that while the platform team is responsible for building the core tools needed to ingest, transform, and store data, our sub team is now *only* responsible for designing and implementing data use cases, *and* completed data products (data pipelines, databases, etc.) are given back to the business to maintain. This is a now also a service that business units need to use their own cost centers to finance...\n\nI see so many issues with this new organization:\n\n1. Our team now technically has no ownership. We're in the platform team in name only, in reality we're end users for the actual platform team. Because everything we build needs to be handed back to the business (wet lab scientists) for maintenance, we don't technically own any pipeline, database, or models either.\n2. The business (wet lab scientists) don't want to be data engineers, and no one wants to maintain these pipelines. We've had pushbacks every time we've tried to transfer a completed project back to the business, and the business has elevated the issue up the C-level.\n3. The stupidest thing is the financial part, where if any group from the business wants to work with us, they need to use their own cost center to fund us. At this point we're basically internal contractors, and I have no clue why this decision was made. No other groups in the company operate like this, and all I see this doing is putting a wall between the business projects and us. \n\nI'm at a loss of what to do. I've tried to work in this new mode for the past year, and in that time all of our existing projects dried up and we basically spend the year doing busywork on a single data product. It's honestly embarrassing and demotivating. I no-longer see our team's importance in the company so I can't imagine how an outsider can...\n\nRight now I *think* that a change needs to be made because there are fundamental issues. I think either:\n\n1. Our team fully joins the platform team and is involved in actual infrastructure planning, implementation, and maintenance.\n2. Our team provides long term maintenance for all data products we create; if this can't be done as part of IT we should transition back to the business.\n\nI'm interested in any advice here because I only have experience in startups, and maybe this is common in larger companies? I am in a position where I can influence change, but no one internally seems to have a good idea what they should be doing :)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data team in identity crisis post-acquisition. How should data engineering work in biotech?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18uv35j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703984357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked in the same data team for the past 5 years, and up until a year ago we were &lt;em&gt;the&lt;/em&gt; data team for a ~100 person startup; we designed, built, and maintained all data pipelines, databases, and related applications. We were acquired last year, and our company is now at 6,000 people. As part of this acquisition, our data team was transitioned from the business into IT as part of the data platform team. The issue here is that while the platform team is responsible for building the core tools needed to ingest, transform, and store data, our sub team is now &lt;em&gt;only&lt;/em&gt; responsible for designing and implementing data use cases, &lt;em&gt;and&lt;/em&gt; completed data products (data pipelines, databases, etc.) are given back to the business to maintain. This is a now also a service that business units need to use their own cost centers to finance...&lt;/p&gt;\n\n&lt;p&gt;I see so many issues with this new organization:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our team now technically has no ownership. We&amp;#39;re in the platform team in name only, in reality we&amp;#39;re end users for the actual platform team. Because everything we build needs to be handed back to the business (wet lab scientists) for maintenance, we don&amp;#39;t technically own any pipeline, database, or models either.&lt;/li&gt;\n&lt;li&gt;The business (wet lab scientists) don&amp;#39;t want to be data engineers, and no one wants to maintain these pipelines. We&amp;#39;ve had pushbacks every time we&amp;#39;ve tried to transfer a completed project back to the business, and the business has elevated the issue up the C-level.&lt;/li&gt;\n&lt;li&gt;The stupidest thing is the financial part, where if any group from the business wants to work with us, they need to use their own cost center to fund us. At this point we&amp;#39;re basically internal contractors, and I have no clue why this decision was made. No other groups in the company operate like this, and all I see this doing is putting a wall between the business projects and us. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m at a loss of what to do. I&amp;#39;ve tried to work in this new mode for the past year, and in that time all of our existing projects dried up and we basically spend the year doing busywork on a single data product. It&amp;#39;s honestly embarrassing and demotivating. I no-longer see our team&amp;#39;s importance in the company so I can&amp;#39;t imagine how an outsider can...&lt;/p&gt;\n\n&lt;p&gt;Right now I &lt;em&gt;think&lt;/em&gt; that a change needs to be made because there are fundamental issues. I think either:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our team fully joins the platform team and is involved in actual infrastructure planning, implementation, and maintenance.&lt;/li&gt;\n&lt;li&gt;Our team provides long term maintenance for all data products we create; if this can&amp;#39;t be done as part of IT we should transition back to the business.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m interested in any advice here because I only have experience in startups, and maybe this is common in larger companies? I am in a position where I can influence change, but no one internally seems to have a good idea what they should be doing :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18uv35j", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18uv35j/data_team_in_identity_crisis_postacquisition_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18uv35j/data_team_in_identity_crisis_postacquisition_how/", "subreddit_subscribers": 149614, "created_utc": 1703984357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learn Spark  via Databricks Community edition or Local Hadoop environment in Ubuntu\n\n\nHi DEs\nI am a data analyst with 5YOE from India and have worked on ETL  using SQL(Redshift, Oracle, MySQL). I also worked on Python mainly pandas for data crunching. \n\nI want to get into Data Engineering and I have to learn Spark. Should I learn and hands on Using browser based Databricks community edition or install hadoop, Hive, Spark on my Ubuntu laptop .\n\n\nDoes it even makes any difference learning from Pre-configured Data bricks and installing and configuring Hadoop enviromenr on my laptop?", "author_fullname": "t2_l6b7kbp7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn Spark via Databricks Community edition or Local Hadoop environment in Ubuntu", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v4s1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704017271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learn Spark  via Databricks Community edition or Local Hadoop environment in Ubuntu&lt;/p&gt;\n\n&lt;p&gt;Hi DEs\nI am a data analyst with 5YOE from India and have worked on ETL  using SQL(Redshift, Oracle, MySQL). I also worked on Python mainly pandas for data crunching. &lt;/p&gt;\n\n&lt;p&gt;I want to get into Data Engineering and I have to learn Spark. Should I learn and hands on Using browser based Databricks community edition or install hadoop, Hive, Spark on my Ubuntu laptop .&lt;/p&gt;\n\n&lt;p&gt;Does it even makes any difference learning from Pre-configured Data bricks and installing and configuring Hadoop enviromenr on my laptop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18v4s1q", "is_robot_indexable": true, "report_reasons": null, "author": "vainothisside", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v4s1q/learn_spark_via_databricks_community_edition_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v4s1q/learn_spark_via_databricks_community_edition_or/", "subreddit_subscribers": 149614, "created_utc": 1704017271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Webhooks and Event Consumption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18v2o1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yGaRLQJ8TGvUs_lbyU-jgN5vg7jMmJ5wkL90qZ_h2H8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704008615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@memphis-dev/comparing-webhooks-and-event-consumption-38225e3b5d9d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?auto=webp&amp;s=d095abcba7f13fa9c9cdbd34e06f59233270f8c7", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c4df145009a2062cb3ccb60917f4dadb1fbac8c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d238ef3a92900924695febaf861063ca2c38d49", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=01bcaa644d016c9e92007ecd4eb4f4702979e1ad", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=536feeb16a046abb7953a84b7c713a15820069d8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc72ce4895e347a9aa2129db9039eb8415f4eb40", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/pdiFNMavIr9dRAwee28tx3dsqVomCxO20zA50KPP5MQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b3db2d728f6eab4e85d2cd90ad9161ce986182f4", "width": 1080, "height": 607}], "variants": {}, "id": "LMW5vuEmRJ9Heh5ykxM7cxKnlZ1oSE0svlI8SOmjhA0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18v2o1m", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v2o1m/comparing_webhooks_and_event_consumption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@memphis-dev/comparing-webhooks-and-event-consumption-38225e3b5d9d", "subreddit_subscribers": 149614, "created_utc": 1704008615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title is pretty self-explanatory. I'm curious as to how quickly you get results after doing a Snowpro certification. I'm planning to do the Snowpro Core cert soon, and might schedule it sooner so that I can slap it on my resume/apps.", "author_fullname": "t2_1k8fjdz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those who have done a Snowflake certification (Snowpro), do you get results immediately?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ukb0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703956175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title is pretty self-explanatory. I&amp;#39;m curious as to how quickly you get results after doing a Snowpro certification. I&amp;#39;m planning to do the Snowpro Core cert soon, and might schedule it sooner so that I can slap it on my resume/apps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ukb0f", "is_robot_indexable": true, "report_reasons": null, "author": "jbnpoc", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ukb0f/for_those_who_have_done_a_snowflake_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ukb0f/for_those_who_have_done_a_snowflake_certification/", "subreddit_subscribers": 149614, "created_utc": 1703956175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering : \n1. what would be the criterias of data engineering interviews in maang companies\n\n2. do they require us to build pipeline while assessment? Or do they only test problem solving skills and scenario based questions?\n\n3. At what level should we have our knowledge ?", "author_fullname": "t2_s7xgvfa5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to prepare for data engineering interviews for MAANG companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v2t5j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704009191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering : \n1. what would be the criterias of data engineering interviews in maang companies&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;do they require us to build pipeline while assessment? Or do they only test problem solving skills and scenario based questions?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;At what level should we have our knowledge ?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18v2t5j", "is_robot_indexable": true, "report_reasons": null, "author": "Mission-Stage-6640", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v2t5j/how_to_prepare_for_data_engineering_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v2t5j/how_to_prepare_for_data_engineering_interviews/", "subreddit_subscribers": 149614, "created_utc": 1704009191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi fellow data engineers,\n\nI'm interested in doing some consulting work for small businesses as a side gig, where I can offer 10-15 hours of my expertise per week.\n\nHow do you find clients for this kind of work? Do you have any tips or strategies to share? I would appreciate your insights.\n\n\nLocation - Ontario, Canada \n\nTech stack - Python, Azure, BI dashboard, ETL\n\nThanks.", "author_fullname": "t2_qawtfyx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering incrop / consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18uyk93", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703994565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow data engineers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in doing some consulting work for small businesses as a side gig, where I can offer 10-15 hours of my expertise per week.&lt;/p&gt;\n\n&lt;p&gt;How do you find clients for this kind of work? Do you have any tips or strategies to share? I would appreciate your insights.&lt;/p&gt;\n\n&lt;p&gt;Location - Ontario, Canada &lt;/p&gt;\n\n&lt;p&gt;Tech stack - Python, Azure, BI dashboard, ETL&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18uyk93", "is_robot_indexable": true, "report_reasons": null, "author": "BirthdayAccording438", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18uyk93/data_engineering_incrop_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18uyk93/data_engineering_incrop_consulting/", "subreddit_subscribers": 149614, "created_utc": 1703994565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, all. \n\nI'm currently preparing for potential technical interviews I may encounter when I start applying for DE roles in early spring. The problem is, I don't really use SQL (anymore) in my day to day activities for work, so my skills have atrophied a bit, but I'm very familiar with the syntax and it's the coding language I'm most comfortable using. I'm trying not to burn myself out on strata scratch questions, but I'm attempting to complete 150-200 questions before late february. The problem is, some of the concepts I'm learning during this process aren't sticking, and that may be due to the sense of urgency I have. To be brief: should I just focus on mastering the 80-85 questions I've answered so far (and their concepts), and if I'm applying for D/E roles, what level should I aim it (entry or mid)  \n\nSome background on me: \n\n* 2-3 years of experience \n* A masters degree in analytics \n* Don't want to reveal any more personal information, but I've essentially worked as a data analyst (with some D/E) work for the past two years\n\nAny tips or advice would be greatly appreciated ", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In preparation for potential technical interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18usz11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703978696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, all. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently preparing for potential technical interviews I may encounter when I start applying for DE roles in early spring. The problem is, I don&amp;#39;t really use SQL (anymore) in my day to day activities for work, so my skills have atrophied a bit, but I&amp;#39;m very familiar with the syntax and it&amp;#39;s the coding language I&amp;#39;m most comfortable using. I&amp;#39;m trying not to burn myself out on strata scratch questions, but I&amp;#39;m attempting to complete 150-200 questions before late february. The problem is, some of the concepts I&amp;#39;m learning during this process aren&amp;#39;t sticking, and that may be due to the sense of urgency I have. To be brief: should I just focus on mastering the 80-85 questions I&amp;#39;ve answered so far (and their concepts), and if I&amp;#39;m applying for D/E roles, what level should I aim it (entry or mid)  &lt;/p&gt;\n\n&lt;p&gt;Some background on me: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2-3 years of experience &lt;/li&gt;\n&lt;li&gt;A masters degree in analytics &lt;/li&gt;\n&lt;li&gt;Don&amp;#39;t want to reveal any more personal information, but I&amp;#39;ve essentially worked as a data analyst (with some D/E) work for the past two years&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any tips or advice would be greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18usz11", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18usz11/in_preparation_for_potential_technical_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18usz11/in_preparation_for_potential_technical_interviews/", "subreddit_subscribers": 149614, "created_utc": 1703978696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry newbie here with modern data stack , Say I am doing ELT , now lets say data is there in the warehouse with relational data and also lot of non relational data eg. xml ,json , mainly json , logs   \n\n\nNow I want to do transformation via DBT   \n1) is it targetted towards BI use case . . ie DBT is for helping making the star schema from the raw data ?    \n\n\n2) Can DBT (yes via sql ) be used to query and transform both relational and non relational data from the data ware house .  \nIf yes then . . can u pls give one e.g. how will sql alone do join or query with non relational data . .  \n\n\n2a)\n\nIf no then   \nOr we are saying that club PySpark +DBT to query relational +non relational together for transformation   \n3)Can DBT (Batch )+ PySpark(streaming) -effectively replace any major traditional or upgraded ETL tool like informatica ?   \n\n\nI googled and read through previous thread on same but i am not able to infer a confident answer ,Any senior can guide would be grateful .", "author_fullname": "t2_hwqrk3yk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT (SQL ) for querying Non relational data &amp; use case in Data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ulpgs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703959872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry newbie here with modern data stack , Say I am doing ELT , now lets say data is there in the warehouse with relational data and also lot of non relational data eg. xml ,json , mainly json , logs   &lt;/p&gt;\n\n&lt;p&gt;Now I want to do transformation via DBT&lt;br/&gt;\n1) is it targetted towards BI use case . . ie DBT is for helping making the star schema from the raw data ?    &lt;/p&gt;\n\n&lt;p&gt;2) Can DBT (yes via sql ) be used to query and transform both relational and non relational data from the data ware house .&lt;br/&gt;\nIf yes then . . can u pls give one e.g. how will sql alone do join or query with non relational data . .  &lt;/p&gt;\n\n&lt;p&gt;2a)&lt;/p&gt;\n\n&lt;p&gt;If no then&lt;br/&gt;\nOr we are saying that club PySpark +DBT to query relational +non relational together for transformation&lt;br/&gt;\n3)Can DBT (Batch )+ PySpark(streaming) -effectively replace any major traditional or upgraded ETL tool like informatica ?   &lt;/p&gt;\n\n&lt;p&gt;I googled and read through previous thread on same but i am not able to infer a confident answer ,Any senior can guide would be grateful .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ulpgs", "is_robot_indexable": true, "report_reasons": null, "author": "Data5kull", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ulpgs/dbt_sql_for_querying_non_relational_data_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ulpgs/dbt_sql_for_querying_non_relational_data_use_case/", "subreddit_subscribers": 149614, "created_utc": 1703959872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have started trying to use dagster for a personal project and am trying to migrate some legacy windows scheduled jobs  (I'm just using subprocess with a meaningless return value to execute these).  It's generally working well, but I have one particular issue I am struggling with.  If any ther dagster users can give me any pointers I would be very grateful.\n\nUpstream asset is a web scraper:\n\n* The target website has one page per 'url-date', and the content of the page changes.\n* Using a scheduled job, on each day, (t) the scraper should scrape data for pages dated t-1, t-2 and t-7.\n* I want to partition the asset.\n* 'url-date' is a natural partition dimension\n* age *might* be a good partition dimension too (to allow simple recording of age)\n* the scraper should only be run for one partition concurrently (due to throttling)\n\nI have no experience on dagster (other than manual, videos and trial and error I have been doing) or any similar system so could really just do with **someone telling me if I am going about things the wrong way or on the right track, please**?\n\nHere is what I have tried:\n\nSetup the scraper as an asset with multi-partition of ('url-date', 'ageInDays-at-materialization'=\\[1,2,7\\])\n\n* Attempt 1 - set up an scheduled op-job which accepts a run-date and calls materialize() 3 times on the asset for partitions:(run-date-1,2,7)\\*(t-1,2,7).  The issue here is that in the GUI the asset-partition never shows as materialized (possibly due to the job being an 'ephemeral\\_asset\\_job' and running in a temp folder / with a different default io-manager).  I suspect his is incorrect/unintended usage of materialize()\n* Attempt 2 - set up a scheduler which returns a 3 runRequests one for each (url-date=\\[run-date-1,2,7\\])\\*(age=\\[1,2,7\\]).  The issue here is that the runRequests run concurrently. To solve this I will try using 'Limiting specific runs using tags' [https://docs.dagster.io/guides/limiting-concurrency-in-data-pipelines](https://docs.dagster.io/guides/limiting-concurrency-in-data-pipelines).  Perhaps this will work...  I did originally expect the whole scheduled task to run in one run, but that might be unrealistic.\n* Attempt 3 - set up a scheduler to run a single runRequest for a range of partitions. As well as scraping the incorrect partitions this returns ''dagster.\\_core.storage.fs\\_io\\_manager.PickledObjectFilesystemIOManager'&gt; does not support persisting an output associated with multiple partitions. '\n\nOther thoughts:\n\n* Partitioning by url-date\\*age means I will have many existing and empty partitions (which we are not able to materialize yet) and so will have to handle/ignore these in downstream dependencies.  Generally seems less than ideal.\n* Partitioning by sample-date\\*age seems like it would be so much more straightforward to implement, but provide a worse user experience (since sample-date is nowhere near as important to the user as url-date)", "author_fullname": "t2_ip724", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dagster project design help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v64o8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704023196.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704022996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started trying to use dagster for a personal project and am trying to migrate some legacy windows scheduled jobs  (I&amp;#39;m just using subprocess with a meaningless return value to execute these).  It&amp;#39;s generally working well, but I have one particular issue I am struggling with.  If any ther dagster users can give me any pointers I would be very grateful.&lt;/p&gt;\n\n&lt;p&gt;Upstream asset is a web scraper:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The target website has one page per &amp;#39;url-date&amp;#39;, and the content of the page changes.&lt;/li&gt;\n&lt;li&gt;Using a scheduled job, on each day, (t) the scraper should scrape data for pages dated t-1, t-2 and t-7.&lt;/li&gt;\n&lt;li&gt;I want to partition the asset.&lt;/li&gt;\n&lt;li&gt;&amp;#39;url-date&amp;#39; is a natural partition dimension&lt;/li&gt;\n&lt;li&gt;age &lt;em&gt;might&lt;/em&gt; be a good partition dimension too (to allow simple recording of age)&lt;/li&gt;\n&lt;li&gt;the scraper should only be run for one partition concurrently (due to throttling)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have no experience on dagster (other than manual, videos and trial and error I have been doing) or any similar system so could really just do with &lt;strong&gt;someone telling me if I am going about things the wrong way or on the right track, please&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;Here is what I have tried:&lt;/p&gt;\n\n&lt;p&gt;Setup the scraper as an asset with multi-partition of (&amp;#39;url-date&amp;#39;, &amp;#39;ageInDays-at-materialization&amp;#39;=[1,2,7])&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Attempt 1 - set up an scheduled op-job which accepts a run-date and calls materialize() 3 times on the asset for partitions:(run-date-1,2,7)*(t-1,2,7).  The issue here is that in the GUI the asset-partition never shows as materialized (possibly due to the job being an &amp;#39;ephemeral_asset_job&amp;#39; and running in a temp folder / with a different default io-manager).  I suspect his is incorrect/unintended usage of materialize()&lt;/li&gt;\n&lt;li&gt;Attempt 2 - set up a scheduler which returns a 3 runRequests one for each (url-date=[run-date-1,2,7])*(age=[1,2,7]).  The issue here is that the runRequests run concurrently. To solve this I will try using &amp;#39;Limiting specific runs using tags&amp;#39; &lt;a href=\"https://docs.dagster.io/guides/limiting-concurrency-in-data-pipelines\"&gt;https://docs.dagster.io/guides/limiting-concurrency-in-data-pipelines&lt;/a&gt;.  Perhaps this will work...  I did originally expect the whole scheduled task to run in one run, but that might be unrealistic.&lt;/li&gt;\n&lt;li&gt;Attempt 3 - set up a scheduler to run a single runRequest for a range of partitions. As well as scraping the incorrect partitions this returns &amp;#39;&amp;#39;dagster._core.storage.fs_io_manager.PickledObjectFilesystemIOManager&amp;#39;&amp;gt; does not support persisting an output associated with multiple partitions. &amp;#39;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Other thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Partitioning by url-date*age means I will have many existing and empty partitions (which we are not able to materialize yet) and so will have to handle/ignore these in downstream dependencies.  Generally seems less than ideal.&lt;/li&gt;\n&lt;li&gt;Partitioning by sample-date*age seems like it would be so much more straightforward to implement, but provide a worse user experience (since sample-date is nowhere near as important to the user as url-date)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?auto=webp&amp;s=d9eec3bfbfc3fd565643229f8a84c399bc1fe73b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=499be57a5b257c149c9417e04fb72b227c3fc6bc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=41c03559a31ecfba73ee7ff44bd6293216bcd5f6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1f3696c3a4f7025280b0a98110eadfe130536c4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a12aeb324dd791c5dbd277a3131545efcfa5b3fe", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bceae394da1ca70512dad8f5ec6ce1e142472e86", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29800a80de6287c32b91b05133f7c8e4a2d57eb2", "width": 1080, "height": 567}], "variants": {}, "id": "gUU0nwKC8lE8qWjp6y6pjjOolTxbCTTaSrkKGe3Kq6A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18v64o8", "is_robot_indexable": true, "report_reasons": null, "author": "BeigePerson", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v64o8/dagster_project_design_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v64o8/dagster_project_design_help/", "subreddit_subscribers": 149614, "created_utc": 1704022996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\u00a0  \n\n\nI am building a realtime dashboard using Databricks Delta Live Tables Pipeline and using the following steps : -\u00a0  \n\n\n**Bronze Table** : Using the autoloader functionality provided by databricks, its incrementally ingesting new files records into a bronze table.  \n**Silver Table** : Using the **read\\_stream function** provided in spark for structured streaming, we are creating the silver table by filtering the records and selecting few fields from the bronze table that are required.  \n**Gold Table** : Using the **read function** provided in spark for reading complete record, we are creating the gold table, which is the materialized view and also using aggregate function (SUM), and group by clause to create it.  \n\n\n**Problem :**\u00a0  \nBronze and silver table are doing incremental ingestion, however incase of gold table, the entire record in the table is getting recomputed everytime a new record is received in the silver table.  \n\n\nWhat I want to ensure is that for the particular group by clause only updates should be performed and rest of the records are locked and dont require any update.\u00a0  \n\n\nI have also tried using streaming table instead of materialized view for gold as well, in this case also the entire records are getting recomputed.  \nAny help would be appreciated.", "author_fullname": "t2_pkzywi0r5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DLT || Python || Aggregate Functions recomputing all the records", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18v078v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703999835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\u00a0  &lt;/p&gt;\n\n&lt;p&gt;I am building a realtime dashboard using Databricks Delta Live Tables Pipeline and using the following steps : -\u00a0  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bronze Table&lt;/strong&gt; : Using the autoloader functionality provided by databricks, its incrementally ingesting new files records into a bronze table.&lt;br/&gt;\n&lt;strong&gt;Silver Table&lt;/strong&gt; : Using the &lt;strong&gt;read_stream function&lt;/strong&gt; provided in spark for structured streaming, we are creating the silver table by filtering the records and selecting few fields from the bronze table that are required.&lt;br/&gt;\n&lt;strong&gt;Gold Table&lt;/strong&gt; : Using the &lt;strong&gt;read function&lt;/strong&gt; provided in spark for reading complete record, we are creating the gold table, which is the materialized view and also using aggregate function (SUM), and group by clause to create it.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem :&lt;/strong&gt;\u00a0&lt;br/&gt;\nBronze and silver table are doing incremental ingestion, however incase of gold table, the entire record in the table is getting recomputed everytime a new record is received in the silver table.  &lt;/p&gt;\n\n&lt;p&gt;What I want to ensure is that for the particular group by clause only updates should be performed and rest of the records are locked and dont require any update.\u00a0  &lt;/p&gt;\n\n&lt;p&gt;I have also tried using streaming table instead of materialized view for gold as well, in this case also the entire records are getting recomputed.&lt;br/&gt;\nAny help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18v078v", "is_robot_indexable": true, "report_reasons": null, "author": "cerebral-assassin26", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18v078v/dlt_python_aggregate_functions_recomputing_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18v078v/dlt_python_aggregate_functions_recomputing_all/", "subreddit_subscribers": 149614, "created_utc": 1703999835.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}