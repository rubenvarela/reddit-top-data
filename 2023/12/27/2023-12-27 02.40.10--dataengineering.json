{"kind": "Listing", "data": {"after": null, "dist": 11, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe it's the recent lay offs and hiring freeze for graduates but I've had two different jobs at 2 different companies in the last 2 years were I was easily the only person under 40 in the team.\n\nHas anyone else noticed this?", "author_fullname": "t2_hiu1pyq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data engineers, architects and programmers in general getting older?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rjrrf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703628773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe it&amp;#39;s the recent lay offs and hiring freeze for graduates but I&amp;#39;ve had two different jobs at 2 different companies in the last 2 years were I was easily the only person under 40 in the team.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else noticed this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18rjrrf", "is_robot_indexable": true, "report_reasons": null, "author": "PureLavishness8654", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18rjrrf/are_data_engineers_architects_and_programmers_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18rjrrf/are_data_engineers_architects_and_programmers_in/", "subreddit_subscribers": 148570, "created_utc": 1703628773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am currently evaluating which BI tool will be implemented across the company. In my earlier companies I have used Superset where I wrote SQL queries for each dashboard or insight requirement and created a visualisation directly from them.\n\nI realised that in Power BI I can't write SQL queries directly, I can only connect directly to the database tables and do the transformation inside Power BI. A workaround would be to write sql queries separately and create a view in my db and then connect power BI to the view to create a dashboard.\n\nI want to ask for your opinions on this.\n\n1. Should I move to a tool where I can write queries and make visualisations.\n\n2. Use views with power BI.\n\n3. Simply abandon SQL queries and just do transformations entirely in power BI.", "author_fullname": "t2_158u5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Superset/Metabase vs Power BI/Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18re6it", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703614155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently evaluating which BI tool will be implemented across the company. In my earlier companies I have used Superset where I wrote SQL queries for each dashboard or insight requirement and created a visualisation directly from them.&lt;/p&gt;\n\n&lt;p&gt;I realised that in Power BI I can&amp;#39;t write SQL queries directly, I can only connect directly to the database tables and do the transformation inside Power BI. A workaround would be to write sql queries separately and create a view in my db and then connect power BI to the view to create a dashboard.&lt;/p&gt;\n\n&lt;p&gt;I want to ask for your opinions on this.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Should I move to a tool where I can write queries and make visualisations.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use views with power BI.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Simply abandon SQL queries and just do transformations entirely in power BI.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18re6it", "is_robot_indexable": true, "report_reasons": null, "author": "chutiyaw", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18re6it/supersetmetabase_vs_power_bitableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18re6it/supersetmetabase_vs_power_bitableau/", "subreddit_subscribers": 148570, "created_utc": 1703614155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently introduced DBT in our data pipeline, and I am trying to orchestrate the pipeline with airflow and create a tool so that the analytics team can make their changes on their own.  \n\n\nCan anyone suggest some guidelines for this process?", "author_fullname": "t2_ao3wkczf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Core orchestration in-house implementation - OPINION", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r0n54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703567977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently introduced DBT in our data pipeline, and I am trying to orchestrate the pipeline with airflow and create a tool so that the analytics team can make their changes on their own.  &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest some guidelines for this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18r0n54", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Big-75", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18r0n54/dbt_core_orchestration_inhouse_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18r0n54/dbt_core_orchestration_inhouse_implementation/", "subreddit_subscribers": 148570, "created_utc": 1703567977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI am a seasoned Senior BI Developer with a decade of experience primarily in the Microsoft BI Stack, including SSIS, SSRS, Power BI, SSAS, and T-SQL programming. I also have exposure to Azure cloud tools like Azure Data Factory and Azure Data Warehouse. Recently, I made a career move to a new organization, accepting a junior-level BI specialist position for financial and job security reasons, with the intention of transitioning into data engineering.\n\nHowever, my current role at the new organization is turning out to be quite different from typical BI or data engineering positions. It involves manual processes and lacks exposure to cutting-edge technologies. While the job is stable with low pressure, I am now questioning whether I made the right decision.\n\nI have two options in mind and would appreciate advice on the following:\n\n1. Return to the previous organization. Despite being volatile in terms of job stability, it has expressed interest in retaining me by matching my current salary. However, this would mean returning to the old technology stack.\n\n2. Stick with the current organization for the next 6 months to a year, utilizing the stability and lower job pressure to self-teach and transition into data engineering, eventually moving to a role that aligns better with my career goals.\n\nI am seeking guidance on which path would be more beneficial for my career growth", "author_fullname": "t2_838vdjqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r5efi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703586933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a seasoned Senior BI Developer with a decade of experience primarily in the Microsoft BI Stack, including SSIS, SSRS, Power BI, SSAS, and T-SQL programming. I also have exposure to Azure cloud tools like Azure Data Factory and Azure Data Warehouse. Recently, I made a career move to a new organization, accepting a junior-level BI specialist position for financial and job security reasons, with the intention of transitioning into data engineering.&lt;/p&gt;\n\n&lt;p&gt;However, my current role at the new organization is turning out to be quite different from typical BI or data engineering positions. It involves manual processes and lacks exposure to cutting-edge technologies. While the job is stable with low pressure, I am now questioning whether I made the right decision.&lt;/p&gt;\n\n&lt;p&gt;I have two options in mind and would appreciate advice on the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Return to the previous organization. Despite being volatile in terms of job stability, it has expressed interest in retaining me by matching my current salary. However, this would mean returning to the old technology stack.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Stick with the current organization for the next 6 months to a year, utilizing the stability and lower job pressure to self-teach and transition into data engineering, eventually moving to a role that aligns better with my career goals.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am seeking guidance on which path would be more beneficial for my career growth&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18r5efi", "is_robot_indexable": true, "report_reasons": null, "author": "Adventurous_Ad8087", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18r5efi/career_dilemma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18r5efi/career_dilemma/", "subreddit_subscribers": 148570, "created_utc": 1703586933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data pipeline, extracts data from APIs using Cloud Functions and drop them in GCS bucket. Another cloud function that takes those files and pushes them to Bigqquery.   \nThe second Cloud function has a linear backoff to handle 10ops/5sec limit. But data is too much and coming at much faster rate that we still see failed instances of data loaded to bigquery.  \n\n\nI can think of 2 ways to fix it:  \n\\- Reduce the speed to data extraction. This is done via Cloud Tasks and may be I can add throttling to it so that API calls are made at lower rate.   \n\\- I think there is also a possibility to add a a messaging service in between but I have not used pub sub before. So not entirely sure about it. The idea could be to push data to pub sub instead of Google Storage (since we are not really making any use of this data, in case of issues we prefer to just extract it again).  \n\n\nDo you have any recommendations or suggestion what might be a better option? Our whole extraction process is simply API calls to a dozen or more sources (each in its own cloud function and then source table) and processing later in Bigquery.   \n", "author_fullname": "t2_4x8s649h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data loading to bigquery failing with rate limit error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r1fou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703570735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data pipeline, extracts data from APIs using Cloud Functions and drop them in GCS bucket. Another cloud function that takes those files and pushes them to Bigqquery.&lt;br/&gt;\nThe second Cloud function has a linear backoff to handle 10ops/5sec limit. But data is too much and coming at much faster rate that we still see failed instances of data loaded to bigquery.  &lt;/p&gt;\n\n&lt;p&gt;I can think of 2 ways to fix it:&lt;br/&gt;\n- Reduce the speed to data extraction. This is done via Cloud Tasks and may be I can add throttling to it so that API calls are made at lower rate.&lt;br/&gt;\n- I think there is also a possibility to add a a messaging service in between but I have not used pub sub before. So not entirely sure about it. The idea could be to push data to pub sub instead of Google Storage (since we are not really making any use of this data, in case of issues we prefer to just extract it again).  &lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations or suggestion what might be a better option? Our whole extraction process is simply API calls to a dozen or more sources (each in its own cloud function and then source table) and processing later in Bigquery.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18r1fou", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Carob897", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18r1fou/data_loading_to_bigquery_failing_with_rate_limit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18r1fou/data_loading_to_bigquery_failing_with_rate_limit/", "subreddit_subscribers": 148570, "created_utc": 1703570735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious as to which major would be ideal if I want to go into Data/ML Engineering. I've applied for Statistics and am planning on a CS minor. Or is a direct approach with a Data Science major a good idea?", "author_fullname": "t2_a5l1pcph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Undergraduate major", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ri1ox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703624185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious as to which major would be ideal if I want to go into Data/ML Engineering. I&amp;#39;ve applied for Statistics and am planning on a CS minor. Or is a direct approach with a Data Science major a good idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ri1ox", "is_robot_indexable": true, "report_reasons": null, "author": "Complex-Ad-7801", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ri1ox/undergraduate_major/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ri1ox/undergraduate_major/", "subreddit_subscribers": 148570, "created_utc": 1703624185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Yes I know there are already a lot of tools that are out there, both paid and FOSS. I've been through a few of them by now and I always end up becoming this engineer that has the job of stitching together 10 different tools together to finally have a full data engineering \"platform\".\n\nThe only tool I have come across that even gets close to solving this problem is Meltano ([https://docs.meltano.com/](https://docs.meltano.com/)). But it too has it's flaws, just to add some meat to this bone I'm trying to pick: managing bigger projects quickly become tedious, there are some conventions in how other packages implement the Meltano SDK but they are not always fully implemented and I end up just using the native packages (DBT my example here, I'd much rather use the official cli.) Then there's the whole governance (and should I even mention trying out data mesh anymore.)\n\nSo I want to solve my own issues here and (probably) make it open-source. So, dear reddit, I have some ideas of what I want to do but want to get some more broad ideas of what people are struggling with while sharing some thing here as I go.\n\nAnd I'm and going to go 1 step further. It's not going to be done in python, nor java, nor scala. I want to use either go or rust and no, not for hype. These currently have great community support and have great potential for larger scale deployments where we need to run loads of small jobs that need to speak to our sources and stores.\n\nSo then where to next? Source data, store it, transform it and keep going. I'm mainly here looking for issues people are running into and things I can keep in mind as I go. Mine are:\n- self-service (want teams within a single company to manage/secure their own data)\n- observability\n- governance (having a backing auditing system as a really don't want to lose another breath working on this ever again)\n- end to end scheduling (I will not touch airflow, not even with a 10 meter stick)\n- a ui for that is actually useful for more than 1 function (this will probably be done using NextJS as it's what I know but open to suggestions.)\n\nLooking forward to comments, complaints and criticism.\n\n[View Poll](https://www.reddit.com/poll/18ra5tp)", "author_fullname": "t2_qc574", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building another data platform.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ra5tp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703603543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes I know there are already a lot of tools that are out there, both paid and FOSS. I&amp;#39;ve been through a few of them by now and I always end up becoming this engineer that has the job of stitching together 10 different tools together to finally have a full data engineering &amp;quot;platform&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The only tool I have come across that even gets close to solving this problem is Meltano (&lt;a href=\"https://docs.meltano.com/\"&gt;https://docs.meltano.com/&lt;/a&gt;). But it too has it&amp;#39;s flaws, just to add some meat to this bone I&amp;#39;m trying to pick: managing bigger projects quickly become tedious, there are some conventions in how other packages implement the Meltano SDK but they are not always fully implemented and I end up just using the native packages (DBT my example here, I&amp;#39;d much rather use the official cli.) Then there&amp;#39;s the whole governance (and should I even mention trying out data mesh anymore.)&lt;/p&gt;\n\n&lt;p&gt;So I want to solve my own issues here and (probably) make it open-source. So, dear reddit, I have some ideas of what I want to do but want to get some more broad ideas of what people are struggling with while sharing some thing here as I go.&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m and going to go 1 step further. It&amp;#39;s not going to be done in python, nor java, nor scala. I want to use either go or rust and no, not for hype. These currently have great community support and have great potential for larger scale deployments where we need to run loads of small jobs that need to speak to our sources and stores.&lt;/p&gt;\n\n&lt;p&gt;So then where to next? Source data, store it, transform it and keep going. I&amp;#39;m mainly here looking for issues people are running into and things I can keep in mind as I go. Mine are:\n- self-service (want teams within a single company to manage/secure their own data)\n- observability\n- governance (having a backing auditing system as a really don&amp;#39;t want to lose another breath working on this ever again)\n- end to end scheduling (I will not touch airflow, not even with a 10 meter stick)\n- a ui for that is actually useful for more than 1 function (this will probably be done using NextJS as it&amp;#39;s what I know but open to suggestions.)&lt;/p&gt;\n\n&lt;p&gt;Looking forward to comments, complaints and criticism.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/18ra5tp\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ra5tp", "is_robot_indexable": true, "report_reasons": null, "author": "SomeRainbowRays", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1703862743831, "options": [{"text": "Rust", "id": "26511841"}, {"text": "Go", "id": "26511842"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 62, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ra5tp/building_another_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/18ra5tp/building_another_data_platform/", "subreddit_subscribers": 148570, "created_utc": 1703603543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Found this gem on Medium. Probably written by someone on this sub.  I run into a lot of cases where people don't understand where their dbt errors come from. Must read for anyone using dbt.\n\nThanks to u/badketchup for a better link.\n\nhttps://www.arecadata.com/the-definitive-guide-for-debugging-dbt/\n", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Definitive Guide to Debugging Dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ravdf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703625799.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703605475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found this gem on Medium. Probably written by someone on this sub.  I run into a lot of cases where people don&amp;#39;t understand where their dbt errors come from. Must read for anyone using dbt.&lt;/p&gt;\n\n&lt;p&gt;Thanks to &lt;a href=\"/u/badketchup\"&gt;u/badketchup&lt;/a&gt; for a better link.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.arecadata.com/the-definitive-guide-for-debugging-dbt/\"&gt;https://www.arecadata.com/the-definitive-guide-for-debugging-dbt/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?auto=webp&amp;s=0f8d5f405e3dafd40ad563bc8e1e54bbb901d19a", "width": 960, "height": 469}, "resolutions": [{"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=33949a86e8eb9dcdccaaaa2cf71baf6c16cbe553", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6128a2d28db95339c0ddea963167d1bdfe7ac14", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5748b825ad8e98434c213f635b1fcc3dead983e", "width": 320, "height": 156}, {"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af6f5d2159e5422f8b7b9531dcd128acd364e0e1", "width": 640, "height": 312}, {"url": "https://external-preview.redd.it/0beT3b4GrO61u1cLvjLLcRhklqQWFaoiuMaqABK9fkM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=316b11b304652f6803e1ce477844554304cf039e", "width": 960, "height": 469}], "variants": {}, "id": "pSBIgHxG7KfLR74hJ-LjxaxhReC0MO6sH_ifBI9dx-Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ravdf", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ravdf/definitive_guide_to_debugging_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ravdf/definitive_guide_to_debugging_dbt/", "subreddit_subscribers": 148570, "created_utc": 1703605475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\nI'm a grad student doing my masters in Data engineering l'm on the hunt for some solid resources to level up in Data Structures and Algorithms. All I know is little bit of python Do you have any go-to books or YouTube channels that you swear by? Looking for something that's clear, practical, and includes some hands-on problems. All suggestions are welcome!\nThanks in advance!", "author_fullname": "t2_ede09jcq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations to start learning DSA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18rok4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703641714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!\nI&amp;#39;m a grad student doing my masters in Data engineering l&amp;#39;m on the hunt for some solid resources to level up in Data Structures and Algorithms. All I know is little bit of python Do you have any go-to books or YouTube channels that you swear by? Looking for something that&amp;#39;s clear, practical, and includes some hands-on problems. All suggestions are welcome!\nThanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18rok4s", "is_robot_indexable": true, "report_reasons": null, "author": "DataNinjaSoul", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18rok4s/recommendations_to_start_learning_dsa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18rok4s/recommendations_to_start_learning_dsa/", "subreddit_subscribers": 148570, "created_utc": 1703641714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!   \nI am faced with the task of scraping data from a search engine, which takes a string and searches for all occurrences of this string, case-insensitive. Search engine returns only first 15 occurences, no pagination, only way to get some another value -- change query string.  \nNaive implementation of engine like this for example on Python.  \n```python\n@dataclass\nclass DataModel:\n  id: int\n  name: str\n\ndata: List[DataModel] = [ ... ]\n\ndef search(query: str) -&gt; List[DataModel]:\n  return list(value for value in data if query in value.name.lower())[:15]\n```\nMy task is to fetch all the data from this search engine. There is no API, only this option. Please tell me what is the best way to do this? So far, the options have been to sequentially sort through all the characters of the Latin alphabet + numbers, but this is estimated to be a very long option, even if you parallelize this task into several tasks with breaking up the alphabet and processing the resulting \"query batches\".\nThank you!", "author_fullname": "t2_csfi1tdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to fetch data from substring search engine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rdy2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703613557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;br/&gt;\nI am faced with the task of scraping data from a search engine, which takes a string and searches for all occurrences of this string, case-insensitive. Search engine returns only first 15 occurences, no pagination, only way to get some another value -- change query string.&lt;br/&gt;\nNaive implementation of engine like this for example on Python.&lt;br/&gt;\n```python\n@dataclass\nclass DataModel:\n  id: int\n  name: str&lt;/p&gt;\n\n&lt;p&gt;data: List[DataModel] = [ ... ]&lt;/p&gt;\n\n&lt;p&gt;def search(query: str) -&amp;gt; List[DataModel]:\n  return list(value for value in data if query in value.name.lower())[:15]\n```\nMy task is to fetch all the data from this search engine. There is no API, only this option. Please tell me what is the best way to do this? So far, the options have been to sequentially sort through all the characters of the Latin alphabet + numbers, but this is estimated to be a very long option, even if you parallelize this task into several tasks with breaking up the alphabet and processing the resulting &amp;quot;query batches&amp;quot;.\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18rdy2r", "is_robot_indexable": true, "report_reasons": null, "author": "After_Thought8437", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18rdy2r/how_to_fetch_data_from_substring_search_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18rdy2r/how_to_fetch_data_from_substring_search_engine/", "subreddit_subscribers": 148570, "created_utc": 1703613557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy,\n\nI've been tasked to migrate one of the existing solutions from AWS to GCP. The solution is rather simple, it's a combination of Lambda, Batch Job (fargate running ecr image) and S3. Basically lambda triggers batch job which does data processing and saves the outcome to s3. On top of that we have Athena running queries on that outcome s3 bucket.\n\nWould you be so kind and recommend me a blog post, video tutorial or some other material, that would help person that is fairly proficient with AWS services to build something similar on GCP considering mentioned architecture?\n\nAny recommendation is helpful.\nThanks!", "author_fullname": "t2_fw1zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data transformation solution from AWS to GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18r4573", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703581708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been tasked to migrate one of the existing solutions from AWS to GCP. The solution is rather simple, it&amp;#39;s a combination of Lambda, Batch Job (fargate running ecr image) and S3. Basically lambda triggers batch job which does data processing and saves the outcome to s3. On top of that we have Athena running queries on that outcome s3 bucket.&lt;/p&gt;\n\n&lt;p&gt;Would you be so kind and recommend me a blog post, video tutorial or some other material, that would help person that is fairly proficient with AWS services to build something similar on GCP considering mentioned architecture?&lt;/p&gt;\n\n&lt;p&gt;Any recommendation is helpful.\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18r4573", "is_robot_indexable": true, "report_reasons": null, "author": "saif3r", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18r4573/moving_data_transformation_solution_from_aws_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18r4573/moving_data_transformation_solution_from_aws_to/", "subreddit_subscribers": 148570, "created_utc": 1703581708.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}