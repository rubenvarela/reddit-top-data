{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sorry to ask this kind of question, but my PM told me about this.\n\n\"Snowflake plans to buy the iceberg and will turn it into a private project.\"\n\nAnd I tried to check the facts about this, but can't find the source on the internet anywhere.\n\nHe said he will provide the source in next week's meeting, but I can't wait 'till then.\n\nBesides, this cannot be true, I mean, what about Netflix and other major companies?\n\nThis is unrealistic.", "author_fullname": "t2_1c81q43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Snowflake planning to buy Apache Iceberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18skpea", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703736775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sorry to ask this kind of question, but my PM told me about this.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Snowflake plans to buy the iceberg and will turn it into a private project.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;And I tried to check the facts about this, but can&amp;#39;t find the source on the internet anywhere.&lt;/p&gt;\n\n&lt;p&gt;He said he will provide the source in next week&amp;#39;s meeting, but I can&amp;#39;t wait &amp;#39;till then.&lt;/p&gt;\n\n&lt;p&gt;Besides, this cannot be true, I mean, what about Netflix and other major companies?&lt;/p&gt;\n\n&lt;p&gt;This is unrealistic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18skpea", "is_robot_indexable": true, "report_reasons": null, "author": "nonaln", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18skpea/is_snowflake_planning_to_buy_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18skpea/is_snowflake_planning_to_buy_apache_iceberg/", "subreddit_subscribers": 149028, "created_utc": 1703736775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what are the differentiators when both of them are encroaching into each other's territories ", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who would emerge as the winner between Databricks and Snowflake in the race of all things Data and AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18svyhx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703785056.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703775868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what are the differentiators when both of them are encroaching into each other&amp;#39;s territories &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18svyhx", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18svyhx/who_would_emerge_as_the_winner_between_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18svyhx/who_would_emerge_as_the_winner_between_databricks/", "subreddit_subscribers": 149028, "created_utc": 1703775868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I'm currently a data science graduate student just done with my first semester with a 4gpa but that doesn't matter. I have 2 years of work experience as a data engineer working on Oracle sql, PL/SQL, ODI (Oracle Data Integrator) and almost all the Oracle etl tools, I worked only with star schemas in this company,know dtaat modeling, created ODI packages, mappings, procedures, etc. Crested and modified existing views, triggers, PL/sql packages that are related to pretty important subject areas. There's a lot I've done in just those 2 years. I've also managed a complete data migration project from SQL server to Oracle sql. It was a small Saas company with American clients. \n\nNow, I'm trying to secure an internship in the summer in the USA but to no avail. I'm getting rejected left, right and center. As if my work experience does not matter at all. I know that's not everything but I need more feedback on where I'm going wrong. I'm willing to learn new ETL tools and also am pretty good with Python. Currently I'm working on creating pipelines using python to schedule the data extraction and merge into a table which can be used to create visualizations using that table data (I've not mentioned this in my resume). I have 2 more internships as well and a bachelor's degree in computer science. I have a best paper award from my paper presentation at a conference relating to data analysis and a publication for that paper.\n\nI need to know where I'm lacking. I can't know every ETL tool or process but I'm willing to learn whatever is being used. I am pretty desperate for an internship otherwise I'll be wasting my summer break. I'm on an F1 visa just for more clarity. Willing to share resume on DM as well for a thorough feedback (I'll appreciate this a lot)\n\nTldr: have 2 years of ETL experience but getting rejected for data engineering internships for summer 2024.", "author_fullname": "t2_2odru1hi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Internship Rejections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18se7td", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703718802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;m currently a data science graduate student just done with my first semester with a 4gpa but that doesn&amp;#39;t matter. I have 2 years of work experience as a data engineer working on Oracle sql, PL/SQL, ODI (Oracle Data Integrator) and almost all the Oracle etl tools, I worked only with star schemas in this company,know dtaat modeling, created ODI packages, mappings, procedures, etc. Crested and modified existing views, triggers, PL/sql packages that are related to pretty important subject areas. There&amp;#39;s a lot I&amp;#39;ve done in just those 2 years. I&amp;#39;ve also managed a complete data migration project from SQL server to Oracle sql. It was a small Saas company with American clients. &lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m trying to secure an internship in the summer in the USA but to no avail. I&amp;#39;m getting rejected left, right and center. As if my work experience does not matter at all. I know that&amp;#39;s not everything but I need more feedback on where I&amp;#39;m going wrong. I&amp;#39;m willing to learn new ETL tools and also am pretty good with Python. Currently I&amp;#39;m working on creating pipelines using python to schedule the data extraction and merge into a table which can be used to create visualizations using that table data (I&amp;#39;ve not mentioned this in my resume). I have 2 more internships as well and a bachelor&amp;#39;s degree in computer science. I have a best paper award from my paper presentation at a conference relating to data analysis and a publication for that paper.&lt;/p&gt;\n\n&lt;p&gt;I need to know where I&amp;#39;m lacking. I can&amp;#39;t know every ETL tool or process but I&amp;#39;m willing to learn whatever is being used. I am pretty desperate for an internship otherwise I&amp;#39;ll be wasting my summer break. I&amp;#39;m on an F1 visa just for more clarity. Willing to share resume on DM as well for a thorough feedback (I&amp;#39;ll appreciate this a lot)&lt;/p&gt;\n\n&lt;p&gt;Tldr: have 2 years of ETL experience but getting rejected for data engineering internships for summer 2024.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18se7td", "is_robot_indexable": true, "report_reasons": null, "author": "deathstroke3718", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18se7td/data_engineer_internship_rejections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18se7td/data_engineer_internship_rejections/", "subreddit_subscribers": 149028, "created_utc": 1703718802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Small career synopsis: I am a self-taught programmer that learned SQL and Python. Current career length is about 6 years. Started when I moved into an analyst role at my company and then a year later received a great opportunity to be a data engineer on the new data engineering team that formed here. Three years later I was promoted to Senior and it\u2019s been two years since then. \n\nI picked up a lot of experience around their Microsoft tech stack: SQL Server, SSIS, SSAS, Git (used RedGate as well), CI/CD, some PowerBI, DAX. Our servers are all on VM machines on Azure so I don\u2019t use Azure really. At a point I felt like I wasn\u2019t being challenged enough and I wrote a Python framework for file ingestion. It was the first time the team had used Python for anything. It uses Azure KeyVault for secrets. I\u2019ve also really dove into SQL Performance Tuning the whole time and am fairly advanced in that area. I really love the complexity of it.\n\nI\u2019ll be moving on from the company soon-ish and I was looking for advice on how to make the jump into a more modern tech stack for data engineering. Personally I really like Spark and the complexities with that architecture. Obvious route would be to dive into maybe an Azure certification. Databricks seems pretty cool too. What would you do if you were in my position? I have a solid grasp of data engineering fundamentals and a knack at looking at the bigger architecture picture, I just need to be able to get my foot in the door at a company with a more modern stack where I can be challenged again. Appreciate any advice, it\u2019s annoying when I know I could handle the shift, but I can only say I\u2019ve worked with an 8TB data warehouse on SQL Server in an interview. It like immediately disqualifies me", "author_fullname": "t2_13hsgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to move towards modern data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s9o4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703707289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Small career synopsis: I am a self-taught programmer that learned SQL and Python. Current career length is about 6 years. Started when I moved into an analyst role at my company and then a year later received a great opportunity to be a data engineer on the new data engineering team that formed here. Three years later I was promoted to Senior and it\u2019s been two years since then. &lt;/p&gt;\n\n&lt;p&gt;I picked up a lot of experience around their Microsoft tech stack: SQL Server, SSIS, SSAS, Git (used RedGate as well), CI/CD, some PowerBI, DAX. Our servers are all on VM machines on Azure so I don\u2019t use Azure really. At a point I felt like I wasn\u2019t being challenged enough and I wrote a Python framework for file ingestion. It was the first time the team had used Python for anything. It uses Azure KeyVault for secrets. I\u2019ve also really dove into SQL Performance Tuning the whole time and am fairly advanced in that area. I really love the complexity of it.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll be moving on from the company soon-ish and I was looking for advice on how to make the jump into a more modern tech stack for data engineering. Personally I really like Spark and the complexities with that architecture. Obvious route would be to dive into maybe an Azure certification. Databricks seems pretty cool too. What would you do if you were in my position? I have a solid grasp of data engineering fundamentals and a knack at looking at the bigger architecture picture, I just need to be able to get my foot in the door at a company with a more modern stack where I can be challenged again. Appreciate any advice, it\u2019s annoying when I know I could handle the shift, but I can only say I\u2019ve worked with an 8TB data warehouse on SQL Server in an interview. It like immediately disqualifies me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18s9o4n", "is_robot_indexable": true, "report_reasons": null, "author": "highlanderaffliction", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s9o4n/wanting_to_move_towards_modern_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s9o4n/wanting_to_move_towards_modern_data_engineering/", "subreddit_subscribers": 149028, "created_utc": 1703707289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building your Sausage Machine for Data Products \ud83c\udf2d: Less Tech, More Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_18slkpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3Z4_KPoVYBQq131p2u4-779xr1fHERjOVVgBZOFYq-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703739572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/building-your-sausage-machine-for", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?auto=webp&amp;s=59604d8ad6a5334d857bbe9241f8e00b603673f5", "width": 480, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0ca30e1ba4144896018ef9ad06cd5c1ee1af1631", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5443e473fc8dd038e2d4db1551248117a2dd94a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2e6fa0ed4bc3b93b0dd7337fae94972f0749362", "width": 320, "height": 213}], "variants": {}, "id": "E1ORrH4Z89_FwFmh3ZN0rWHAhLMpl3i0v1R-nPof3ng"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18slkpq", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18slkpq/building_your_sausage_machine_for_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/building-your-sausage-machine-for", "subreddit_subscribers": 149028, "created_utc": 1703739572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! \n\nWe are implementing Delta table logic on an on-prem HDFS cluster using Spark for data processing. We append daily partitions to BRONZE layer which contain new records and updates from the previous day. We want to upsert a daily partition from BRONZE to SILVER layer, but it takes an unreasonable amount of time. If we simply append the data to SILVER, the whole ETL process is around 7 minutes (the write iself around 4 minutes) for a daily partition, which contains roughly 1 million rows. If we switch to merge write, then the runtime grows to roughly 30 minutes (read + transform only takes a few minutes, rest is the merge write step). I get that the merge operation is slower because of the join, but I wouldn't expect it to be this slow for only 1 million rows. Keep in mind that these performance tests were done with only a few daily partitions in the tables. We had the same performance when we worked with only one partition in the target table. Do you guys have any idea what we should do to optimize the performance? \n\nThe things we have tried so far without any significant result:\n- Add more resource to the Spark job\n- Run OPTIMIZE command on target table\n- Tried creating the delta tables with explicit and implicit partitioning\n- By default, Spark does a SortMergeJoin at the MERGE step. We coerced other kinds of joins, but SortMergeJoin seemed to be the fastest one\n\nThe merge itself is fairly simple. We merge to the target table using a daily partition from BRONZE (roughly 1 million rows) on one matching ID of string type. If we have a match, we update the whole set (UPDATE SET *), otherwise INSERT *.\nWe will expect a relatively big amount of updates later, but right now we are working with test data which contains a couple of updates maximum per daily batch.", "author_fullname": "t2_vun99h9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge very slow for small amount of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sr2k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703760102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;We are implementing Delta table logic on an on-prem HDFS cluster using Spark for data processing. We append daily partitions to BRONZE layer which contain new records and updates from the previous day. We want to upsert a daily partition from BRONZE to SILVER layer, but it takes an unreasonable amount of time. If we simply append the data to SILVER, the whole ETL process is around 7 minutes (the write iself around 4 minutes) for a daily partition, which contains roughly 1 million rows. If we switch to merge write, then the runtime grows to roughly 30 minutes (read + transform only takes a few minutes, rest is the merge write step). I get that the merge operation is slower because of the join, but I wouldn&amp;#39;t expect it to be this slow for only 1 million rows. Keep in mind that these performance tests were done with only a few daily partitions in the tables. We had the same performance when we worked with only one partition in the target table. Do you guys have any idea what we should do to optimize the performance? &lt;/p&gt;\n\n&lt;p&gt;The things we have tried so far without any significant result:\n- Add more resource to the Spark job\n- Run OPTIMIZE command on target table\n- Tried creating the delta tables with explicit and implicit partitioning\n- By default, Spark does a SortMergeJoin at the MERGE step. We coerced other kinds of joins, but SortMergeJoin seemed to be the fastest one&lt;/p&gt;\n\n&lt;p&gt;The merge itself is fairly simple. We merge to the target table using a daily partition from BRONZE (roughly 1 million rows) on one matching ID of string type. If we have a match, we update the whole set (UPDATE SET *), otherwise INSERT *.\nWe will expect a relatively big amount of updates later, but right now we are working with test data which contains a couple of updates maximum per daily batch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18sr2k6", "is_robot_indexable": true, "report_reasons": null, "author": "justadataengineer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sr2k6/delta_merge_very_slow_for_small_amount_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sr2k6/delta_merge_very_slow_for_small_amount_of_data/", "subreddit_subscribers": 149028, "created_utc": 1703760102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The biggest blockade to me learning an orchestration framework is the aversion that they have to \u201cstatefulness.\u201d\n  \nI\u2019m not asking HOW do pass \u201cstate\u201d between tasks (I know that it\u2019s XComs in Airflow and IOManagers in Dagster), but WHY does it force us to do it in a roundabout way?\n  \nMost everything that I\u2019ve ever coded has been written in a pretty stateful, object-oriented manner, so switching to this roundabout, functional approach has been difficult to grasp. What\u2019s the intuition behind this design pattern?", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why can\u2019t I pass context between tasks in Airflow/Dagster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sz7ta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703784129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The biggest blockade to me learning an orchestration framework is the aversion that they have to \u201cstatefulness.\u201d&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not asking HOW do pass \u201cstate\u201d between tasks (I know that it\u2019s XComs in Airflow and IOManagers in Dagster), but WHY does it force us to do it in a roundabout way?&lt;/p&gt;\n\n&lt;p&gt;Most everything that I\u2019ve ever coded has been written in a pretty stateful, object-oriented manner, so switching to this roundabout, functional approach has been difficult to grasp. What\u2019s the intuition behind this design pattern?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18sz7ta", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sz7ta/why_cant_i_pass_context_between_tasks_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sz7ta/why_cant_i_pass_context_between_tasks_in/", "subreddit_subscribers": 149028, "created_utc": 1703784129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nMy team is scoping some new design patterns for coordinating file/data movement to/from SFTP servers and from API's.  These eventually will get consumed by PySpark/Glue and stored as Parquet in our Data Lake, but we are exploring the best ways to coordinate all of this upstream ingestion.  We have several ideas about patterns that will fit, but I wanted to pulse the community to see if anyone has something we haven't considered or ideas that could help us refine our approaches.\n\nSome background\n\n&amp;#x200B;\n\n* Need to integrate with several things like SFTP, API's for downloading files and also API's that send JSON payloads of data.\n* Have to connect to a few SASS offerings like Hubspot, but some of these are not API's that will be on a marketplace and will need to be custom integrated.\n* In a regulated environment (Healthcare).\n* Current setup is Terraform, AWS Glue, S3, RDS\n\nGeneral patterns we are weighing are:  \n\n\n* Modules in Terraform: We use terraform for IAC on AWS, so modularization of infrastructure using terraform could solve our issues entirely.  However, this requires possibly writing a fair bit of terraform code to coordinate all of this.  Not really an issue, but we'd currently don't have the best practices around deploying and managing Lambdas and other AWS technologies so theres some legwork there to improve our over all patterns.  Not to mention, our general fluency on Terraform isn't amazing right now on the team.\n* Framework like Chalice or Zappa: We have been exploring this possibility more broadly than this use case, so possibly deploying an app on one of these frameworks would allow us to handle the deployment of multiple AWS infrastructure items in an easier way than only leveraging Terraform modules.  Additionally, there are adaptors that translate Chalice to Terraform, so we can leverage our current deployment patterns still.\n* Other options:  Theres a ton of \"SASS\" type solutions for connectors and file movement.  While we aren't super thrilled to possibly pay for another SASS solution, if its monumentally easier to implement we may consider it.  I know tools like Airbyte have an SFTP connector and some other connectors we might need, but we also have some more complicated API's we'd need to integrate with that these types of SASS solutions wont solve for.\n\n&amp;#x200B;\n\nThanks everyone! ", "author_fullname": "t2_3tfgc8z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design patterns for coordinating data from files/API's to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18stkc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703769014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;My team is scoping some new design patterns for coordinating file/data movement to/from SFTP servers and from API&amp;#39;s.  These eventually will get consumed by PySpark/Glue and stored as Parquet in our Data Lake, but we are exploring the best ways to coordinate all of this upstream ingestion.  We have several ideas about patterns that will fit, but I wanted to pulse the community to see if anyone has something we haven&amp;#39;t considered or ideas that could help us refine our approaches.&lt;/p&gt;\n\n&lt;p&gt;Some background&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Need to integrate with several things like SFTP, API&amp;#39;s for downloading files and also API&amp;#39;s that send JSON payloads of data.&lt;/li&gt;\n&lt;li&gt;Have to connect to a few SASS offerings like Hubspot, but some of these are not API&amp;#39;s that will be on a marketplace and will need to be custom integrated.&lt;/li&gt;\n&lt;li&gt;In a regulated environment (Healthcare).&lt;/li&gt;\n&lt;li&gt;Current setup is Terraform, AWS Glue, S3, RDS&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;General patterns we are weighing are:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Modules in Terraform: We use terraform for IAC on AWS, so modularization of infrastructure using terraform could solve our issues entirely.  However, this requires possibly writing a fair bit of terraform code to coordinate all of this.  Not really an issue, but we&amp;#39;d currently don&amp;#39;t have the best practices around deploying and managing Lambdas and other AWS technologies so theres some legwork there to improve our over all patterns.  Not to mention, our general fluency on Terraform isn&amp;#39;t amazing right now on the team.&lt;/li&gt;\n&lt;li&gt;Framework like Chalice or Zappa: We have been exploring this possibility more broadly than this use case, so possibly deploying an app on one of these frameworks would allow us to handle the deployment of multiple AWS infrastructure items in an easier way than only leveraging Terraform modules.  Additionally, there are adaptors that translate Chalice to Terraform, so we can leverage our current deployment patterns still.&lt;/li&gt;\n&lt;li&gt;Other options:  Theres a ton of &amp;quot;SASS&amp;quot; type solutions for connectors and file movement.  While we aren&amp;#39;t super thrilled to possibly pay for another SASS solution, if its monumentally easier to implement we may consider it.  I know tools like Airbyte have an SFTP connector and some other connectors we might need, but we also have some more complicated API&amp;#39;s we&amp;#39;d need to integrate with that these types of SASS solutions wont solve for.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18stkc3", "is_robot_indexable": true, "report_reasons": null, "author": "deepeyesmusic", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18stkc3/design_patterns_for_coordinating_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18stkc3/design_patterns_for_coordinating_data_from/", "subreddit_subscribers": 149028, "created_utc": 1703769014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a PMP (Project Management Professional) from a previous professional career. I know that it is meaningless in tech and anyone who has a PMP will tell you what a joke it is and that forcing new employees to get their PMP is often used as a hazing ritual. However, the company that sponsors the cert spends a lot of money on marketing and thus a PMP is held is very high esteem by traditional boomer management and by recruiters.  \n\nShould I put my PMP on my resume? I am in DE now and just looking to change companies.", "author_fullname": "t2_o1c691xd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Put PMP on resume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sslei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703765803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PMP (Project Management Professional) from a previous professional career. I know that it is meaningless in tech and anyone who has a PMP will tell you what a joke it is and that forcing new employees to get their PMP is often used as a hazing ritual. However, the company that sponsors the cert spends a lot of money on marketing and thus a PMP is held is very high esteem by traditional boomer management and by recruiters.  &lt;/p&gt;\n\n&lt;p&gt;Should I put my PMP on my resume? I am in DE now and just looking to change companies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18sslei", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive-One6226", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sslei/put_pmp_on_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sslei/put_pmp_on_resume/", "subreddit_subscribers": 149028, "created_utc": 1703765803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to this, I was checking the certification and it is asking for company email?", "author_fullname": "t2_153hv15z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can u get databricks lakehouse fundamentals if you are not working for a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ssp71", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703766158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to this, I was checking the certification and it is asking for company email?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ssp71", "is_robot_indexable": true, "report_reasons": null, "author": "hayleybts", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ssp71/can_u_get_databricks_lakehouse_fundamentals_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ssp71/can_u_get_databricks_lakehouse_fundamentals_if/", "subreddit_subscribers": 149028, "created_utc": 1703766158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "( Please Forgive any typos or mistakes, typing this after a mini panic attack)\n\nSo, I work in a BIG Financial firm in the states as ITAM ( IT asset management), where I recently got to be part of a team to designing schemas and tools for internal use for the Global ITAM teams, I created the tables and their relation to each other along with rules specific privilege in those tools.  I also helped communicate the LOB's needs to the dev team and provide solutions to accommodate any problems that were raised in this process.  My main job is doing Data quality across the East coast Data centers ( ensuring things are right and nothing has wrong data registered to it ). I also create  reports and provide KPI changes monthly to upper management to measure the progress or state of things.\n\nI've picked interest in Data in general and in particular Data engineering. I went over the IBM Data engineering Certificate from Coursera and basically finished it ( it was easier for me \\~ simpler concepts and I found myself understanding the information rather quickly than expected ).\n\nI then got interested in the Masters program offered by Illinois tech in Data Science and I'm currently doing that part time.I also decided to go and specialize in Microsoft's Azure platform, since I know that it is used within the firm and such, so right now I'm doing the Data engineer one ( DP - 203 )\n\nOn a personal level I am feeling like I'm way far from that goal given the requirements I see in LinkedIn Or Indeed. I am not going through the best financial state rn so thats where I am getting little anxious and just want  if I am doing the right things in terms of the track itself or not ?, from your pov, since I wanna start applying to the jobs after I get my Microsoft cert that way I can have a cert that says I know how to do \" work \" in Azure.  \\~ I found lots of negative words about IBM's Cert.\n\nIf I'm missing something or doing something wrong, What would be your advice to me?\n\n&amp;#x200B;", "author_fullname": "t2_g0zsw8kzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance on What I am doing, Feeling lost/ far away from a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sf7dn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703722581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703721307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;( Please Forgive any typos or mistakes, typing this after a mini panic attack)&lt;/p&gt;\n\n&lt;p&gt;So, I work in a BIG Financial firm in the states as ITAM ( IT asset management), where I recently got to be part of a team to designing schemas and tools for internal use for the Global ITAM teams, I created the tables and their relation to each other along with rules specific privilege in those tools.  I also helped communicate the LOB&amp;#39;s needs to the dev team and provide solutions to accommodate any problems that were raised in this process.  My main job is doing Data quality across the East coast Data centers ( ensuring things are right and nothing has wrong data registered to it ). I also create  reports and provide KPI changes monthly to upper management to measure the progress or state of things.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve picked interest in Data in general and in particular Data engineering. I went over the IBM Data engineering Certificate from Coursera and basically finished it ( it was easier for me ~ simpler concepts and I found myself understanding the information rather quickly than expected ).&lt;/p&gt;\n\n&lt;p&gt;I then got interested in the Masters program offered by Illinois tech in Data Science and I&amp;#39;m currently doing that part time.I also decided to go and specialize in Microsoft&amp;#39;s Azure platform, since I know that it is used within the firm and such, so right now I&amp;#39;m doing the Data engineer one ( DP - 203 )&lt;/p&gt;\n\n&lt;p&gt;On a personal level I am feeling like I&amp;#39;m way far from that goal given the requirements I see in LinkedIn Or Indeed. I am not going through the best financial state rn so thats where I am getting little anxious and just want  if I am doing the right things in terms of the track itself or not ?, from your pov, since I wanna start applying to the jobs after I get my Microsoft cert that way I can have a cert that says I know how to do &amp;quot; work &amp;quot; in Azure.  ~ I found lots of negative words about IBM&amp;#39;s Cert.&lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m missing something or doing something wrong, What would be your advice to me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18sf7dn", "is_robot_indexable": true, "report_reasons": null, "author": "the_wizard_hokage10", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sf7dn/guidance_on_what_i_am_doing_feeling_lost_far_away/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sf7dn/guidance_on_what_i_am_doing_feeling_lost_far_away/", "subreddit_subscribers": 149028, "created_utc": 1703721307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone - I have a sort of unique use case and I wanted to see if anyone has already solved this problem.\n\n&amp;#x200B;\n\nI'm working on building a comprehensive data set about buildings in a particular city. I have a data source to populate and update my data warehouse - for example, if a new building is constructed or the data source updates the size of an existing building, those additions/updates will be captured into the data warehouse when the source is ETL'd next and the changes tracked with SCD2. Pretty straightforward.\n\n&amp;#x200B;\n\nHowever, I have noticed that sometimes the data source is out of date or just incorrect. For example, a newly constructed building might not be entered into the data source for months after it was constructed, or it might have undergone a renovation that has not yet been reported to the data source. Sometimes there are duplicate records. I want to be able to update my internal data warehouse with these changes before they are made in the data source (which sometimes doesn't happen at all).\n\n&amp;#x200B;\n\nSome key things:  \n\n\n1- Typically my solution would be to make sure the data source itself is updated and let the regular ETL pick it up. However, this data source is not owned by me and I have a strong incentive not to provide my \"fixed\" data to the data source.\n\n&amp;#x200B;\n\n2- I'd like to be able to track the changes. I currently track the changes from the data source using the SCD2 pattern, but would like to accommodate the end-user updates in the process as well.\n\n&amp;#x200B;\n\nAny thoughts about this problem? Thanks!", "author_fullname": "t2_3jryuv2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices, pattern(s), or software to allow management (CRUD, merge) of data by end users with other updating sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sc5ip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703713598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - I have a sort of unique use case and I wanted to see if anyone has already solved this problem.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on building a comprehensive data set about buildings in a particular city. I have a data source to populate and update my data warehouse - for example, if a new building is constructed or the data source updates the size of an existing building, those additions/updates will be captured into the data warehouse when the source is ETL&amp;#39;d next and the changes tracked with SCD2. Pretty straightforward.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, I have noticed that sometimes the data source is out of date or just incorrect. For example, a newly constructed building might not be entered into the data source for months after it was constructed, or it might have undergone a renovation that has not yet been reported to the data source. Sometimes there are duplicate records. I want to be able to update my internal data warehouse with these changes before they are made in the data source (which sometimes doesn&amp;#39;t happen at all).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Some key things:  &lt;/p&gt;\n\n&lt;p&gt;1- Typically my solution would be to make sure the data source itself is updated and let the regular ETL pick it up. However, this data source is not owned by me and I have a strong incentive not to provide my &amp;quot;fixed&amp;quot; data to the data source.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2- I&amp;#39;d like to be able to track the changes. I currently track the changes from the data source using the SCD2 pattern, but would like to accommodate the end-user updates in the process as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts about this problem? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18sc5ip", "is_robot_indexable": true, "report_reasons": null, "author": "jsxgd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sc5ip/best_practices_patterns_or_software_to_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sc5ip/best_practices_patterns_or_software_to_allow/", "subreddit_subscribers": 149028, "created_utc": 1703713598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Training with Ray Train and MinIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": true, "name": "t3_18t0d7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pXB1rtyTSkezkckvRPpVBRBheU46VB6zOkxCTcYrptY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703786948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/distributed-training-with-ray-train-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=distributed_training_ray_train", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?auto=webp&amp;s=f680295353da4f7a0719aec553d414776a06ec8e", "width": 1200, "height": 359}, "resolutions": [{"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a4478915d12439a59e1d2b63dfe1f8375fc0bf5", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2d770520fcb9e3c577c921c0bb4bdbae5956799", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=51659b839a56a92b71c44c92567b0d863aae6bf6", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df14f4043708b02b89059c9812a69b0dea9c5412", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e23bf2170a5565b664f959ba1819f2d531e68fa3", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/usfqNvzII57kX_Fua5j1tgLS8sBS8X-G9dRNh_9A99k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5bc807b0bbfad25f9b27697284195896d37d93bd", "width": 1080, "height": 323}], "variants": {}, "id": "1qHNuiFMkCibNNa1eJMHDYp4L_pBECFWE3FCV56M8Mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18t0d7o", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18t0d7o/distributed_training_with_ray_train_and_minio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/distributed-training-with-ray-train-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=distributed_training_ray_train", "subreddit_subscribers": 149028, "created_utc": 1703786948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an on-premise Apache Superset 2.1.0, it works in a docker container. It's basically in a PoC stage, where we are trying to assess if Superset is the right fit for our purposes.\n\nOne requirement that we have is to be able to share created dashboards with people without accounts. Someone in the higher management, for example. \n\nIdeally, it would work in a user-friendly way, when dashboard creator can make it public on his own. Without having to provide access to the underlying datasets to a specific role or having us do that for him. Just a simple \"make it public\" kind of a button :)\n\nI've tried multiple things with the help of Google Bard, none of which worked.\n\nI've then tried [this guide](https://github.com/apache/superset/discussions/25299), but it didn't work either. In general, searching for help on Superset is frustrating, because it seems that everyone uses a different version with different options on basically anything.\n\nCan you guys show me the way? How tf do I make these dashboards easily available to people without logins?\n\n*Bonus question: Redis container is a part of the package, but superset init shows that it uses local cache for some reason. Am I doing something wrong here?*", "author_fullname": "t2_6n04s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Superset help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18stjub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703768970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an on-premise Apache Superset 2.1.0, it works in a docker container. It&amp;#39;s basically in a PoC stage, where we are trying to assess if Superset is the right fit for our purposes.&lt;/p&gt;\n\n&lt;p&gt;One requirement that we have is to be able to share created dashboards with people without accounts. Someone in the higher management, for example. &lt;/p&gt;\n\n&lt;p&gt;Ideally, it would work in a user-friendly way, when dashboard creator can make it public on his own. Without having to provide access to the underlying datasets to a specific role or having us do that for him. Just a simple &amp;quot;make it public&amp;quot; kind of a button :)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried multiple things with the help of Google Bard, none of which worked.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve then tried &lt;a href=\"https://github.com/apache/superset/discussions/25299\"&gt;this guide&lt;/a&gt;, but it didn&amp;#39;t work either. In general, searching for help on Superset is frustrating, because it seems that everyone uses a different version with different options on basically anything.&lt;/p&gt;\n\n&lt;p&gt;Can you guys show me the way? How tf do I make these dashboards easily available to people without logins?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Bonus question: Redis container is a part of the package, but superset init shows that it uses local cache for some reason. Am I doing something wrong here?&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?auto=webp&amp;s=26f8bdf747636c8495bbb8c93635125c8c64ae4b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff185993d7cd9a682d80d237fb1645786d1ada7f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=70959835ac078c408d4892ab09cdcf2af256093a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa153c6b5bc8eefb0d907d8722541ecc5e8cb2b5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bced786232bbbf930522136421cd27ac632bd4b5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=df64af16268a4ac0cdde14bcac3afca2057b42a2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c91fb009ff6f185989c225df09b520b166cf265", "width": 1080, "height": 540}], "variants": {}, "id": "16eJ5hLQsuM8YctxRwpxnWB8Rtb_KGeyMayQ6P0noBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18stjub", "is_robot_indexable": true, "report_reasons": null, "author": "zlobendog", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18stjub/apache_superset_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18stjub/apache_superset_help_needed/", "subreddit_subscribers": 149028, "created_utc": 1703768970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productionizing Jupyter Notebooks with Versatile Data Kit (VDK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_18srpzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hGxnGSA7jk4a0Y_ztroxbp7mbXKk89XC3eZ3AzKzKSM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703762624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/versatile-data-kit/productionizing-jupyter-notebooks-with-versatile-data-kit-vdk-ec5824d31b77", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?auto=webp&amp;s=2e8caf5a2c4797cf40de240469a67f9b1cc0c60a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=53300dee93c4fc589e35b1d090234f8a0fc99fb8", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b580813ab95367b6df0eaf65e67a79c5b6733499", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6672fe6cff422da5f0e99c9fdd082c1340c8ed0f", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00fcee8da15e51419025aceb9f9deb393a26733f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8582180f9e5a9a40f69ffc30807137488c47653f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ee64fb2fad82d0c86d9200d4c3d13d7dab58b4ac", "width": 1080, "height": 720}], "variants": {}, "id": "TBVSJ3r1aaIX6zc3PW78ubLcDKNcOqTRDgaSGqozetw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18srpzd", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18srpzd/productionizing_jupyter_notebooks_with_versatile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/versatile-data-kit/productionizing-jupyter-notebooks-with-versatile-data-kit-vdk-ec5824d31b77", "subreddit_subscribers": 149028, "created_utc": 1703762624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://substack.com/@datasketch](https://substack.com/@datasketch)\n\nI write about my learnings in data world in quest to help others.", "author_fullname": "t2_q3nzgktvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "check out my new sub stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18szyuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703785976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://substack.com/@datasketch\"&gt;https://substack.com/@datasketch&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I write about my learnings in data world in quest to help others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?auto=webp&amp;s=92c57c3a1defad23f51945b66cac1689dc98276d", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=def47b6cf968530a09c7b5cc10e161ff42089bb7", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36b52d18b6c496d9e8cfd8b93e157a4e4e7840d7", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07fc1aa52df8d8f84e750b763f897530b0c39611", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb7e9de0320ef81b26b8c3f39ec8d0172ad9c199", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4aae428e9fb9e5236bc540c9802770fb360e7df1", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/K57aZZkzqhSyDIneiPrzuSEbbtIZnmPWxGxzpjW6y48.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6a6c40b80e20145dbab4494ee676bf0bafaa82b", "width": 1080, "height": 1440}], "variants": {}, "id": "wvvQKXA_i3KizWZEX596BfSLFrzYyb35RFR68HvHbMQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18szyuz", "is_robot_indexable": true, "report_reasons": null, "author": "photon223", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18szyuz/check_out_my_new_sub_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18szyuz/check_out_my_new_sub_stack/", "subreddit_subscribers": 149028, "created_utc": 1703785976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://eash98.medium.com/debunking-5-myths-on-adopting-databricks-18140cc3d183", "author_fullname": "t2_15opju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An article on adopting Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18szr7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703785453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://eash98.medium.com/debunking-5-myths-on-adopting-databricks-18140cc3d183\"&gt;https://eash98.medium.com/debunking-5-myths-on-adopting-databricks-18140cc3d183&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?auto=webp&amp;s=9e5d2c1683c85385941635fec64eec342fb396db", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2197c78f927364ebbb3f3f7dd972c0afae43b83", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77cb6b9a6f2d363f9f27b59c416402c91bb544c0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ecb8e3790ad8ffcb19bc659cb1fe799fd5062b6", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db967054ecd0770990fc3d9ed481543022722e4b", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=539af44070a74c2d3aefacc1346cb8a348eac4e6", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/UUDJZB8xbXnOrvGUfFAIpnmWNq5ITjRG2m2U-rxdRyc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17a06a5652bd0bfe5eef28d7195dad685f8d0016", "width": 1080, "height": 720}], "variants": {}, "id": "vylC4vmEtiWDdOM4__p_JX4NIAZwtyVx3edHg4idIb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18szr7u", "is_robot_indexable": true, "report_reasons": null, "author": "eash_98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18szr7u/an_article_on_adopting_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18szr7u/an_article_on_adopting_databricks/", "subreddit_subscribers": 149028, "created_utc": 1703785453.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}