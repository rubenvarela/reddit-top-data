{"kind": "Listing", "data": {"after": "t3_18s6exa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I noticed that my drive was frequently coming online and offline. I opened my server to insepct it, and found that the sata connection snapped off.  The drive is fully functional if I carefully insert a cable. I wiped the drive already with the intention of tossing it, since it has already been replaced. It just hurts to throw a 14tb drive out while it still functions. Is there anyway I can salvage this or make a repair? It is a Seagate exos x16.", "author_fullname": "t2_14din1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Any hope or ideas on how to repair this drive, or is it toast?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jrj2st4lwv8c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=68388ab792b994ac8cfa9e100a70f330e5225b6b"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b0ed9febfa3019b0fc9cf06dff89d57bf2a9d724"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6076d6ab5b717a3aef7ed4fc4feba4c03ecd0ad1"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=265db3d8fc6185056225dfa107870445c7b77525"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0cb9cc45db808d12ebcaefd8b8393596af58c888"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e740caa70be2a48f54431688e7cf6af10ed32fa"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/jrj2st4lwv8c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=8efa6d4d44c5062703bbc7179d1ee866daa8abdf"}, "id": "jrj2st4lwv8c1"}, "of1cw07lwv8c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=89071e1beb9fa0ea201e237b22c73a30c6349559"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55f0a8642433214e6b7b4d4fe0d388f1036456ec"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f228da5f6814bbdc1c763949372272e95475f54"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e97f016dde285e074b4ce214a39c5d866b66169c"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0101573bdc4a5c107db8a1b5d493dee5d97e3e2c"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a84a2e48fecf8f55470d919198228c61bafa596e"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/of1cw07lwv8c1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=157efd8d562b625d2e1ee4d1fa5a59857726452e"}, "id": "of1cw07lwv8c1"}}, "name": "t3_18s8334", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 46, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "jrj2st4lwv8c1", "id": 379987854}, {"media_id": "of1cw07lwv8c1", "id": 379987855}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TdAjyYAgtdHM7ggd8sISir77F5RdMUBY2tWyEg9rZQI.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703703288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I noticed that my drive was frequently coming online and offline. I opened my server to insepct it, and found that the sata connection snapped off.  The drive is fully functional if I carefully insert a cable. I wiped the drive already with the intention of tossing it, since it has already been replaced. It just hurts to throw a 14tb drive out while it still functions. Is there anyway I can salvage this or make a repair? It is a Seagate exos x16.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18s8334", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s8334", "is_robot_indexable": true, "report_reasons": null, "author": "My_Name_Is_Not_Mark", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18s8334/any_hope_or_ideas_on_how_to_repair_this_drive_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18s8334", "subreddit_subscribers": 721262, "created_utc": 1703703288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all. I'm new to the DataHoarder community, but not new to having numerous hard drives in my desk. \n\nTLDR: Sent in my 4TB External HDD for recovery because I deleted files to save space. Deleted the corrupted or broken recovered files, organized the remaining good files, de-duplicated them, moved them to my main 8TB HDD, formatted the 8TB transfer drive, then moved all the files back onto the freshly formatted 8TB transfer drive.\n\n&amp;#x200B;\n\nHere's the full story:\n\nBack in October 2020, I decided to delete a bunch of videos off my measly 4TB Seagate External HDD since it was getting full. Later in February 2021, I got an 8TB External HDD that I still use to this day for videography and other purposes that I use daily. I moved all my data from my 4TB HDD to my 8TB HDD, basically leaving the 4TB completely empty. However (and luckily), I did not use it at all since that day.\n\nJust this past November, I saved up enough to hire [$300 Dollar Data Recovery](https://www.300dollardatarecovery.com/) to recover ALL of the data on the 4TB, specifically the videos that I deleted way back in 2020. I filled out their forms, and sent another 8TB Internal HDD I had, and the 4TB from before.\n\nWhen they shipped back both drives, I was surprised to find that there was a little over 5TB worth of data, all coming from a drive that has 3.63TB of storage. Everything from videos to really small files 1KB or less files, totaling about a million files and several tens of thousands of folders.\n\nThe FIRST thing I had to do was painstakingly sort out all the corrupted or \"broken\" files that weren't playable or were distorted beyond recognition. So I had to carefully plan and make the process as efficient and fast as possible.\n\nFor videos and photo, I opened up File Explorer in full screen and put it in TILE view. I used Ctrl + Scroll and zoomed out as far as I could, just before going into a different view, to have as many icons as possible on my screen.\n\nI also sorted the files by size, because most of the corrupt files were either \\~1KB or gigantic (400+ MB for a corrupted photo). Doing this would group all the small and large files together, making it so I could simply drag around the blue box and select a bunch of them at once, and unselect the few good ones from my selection while holding down Ctrl.\n\nI would let File Explorer load all the thumbnails for the photos/videos, and whatever didn't have a thumbnail I simply selected and moved to a folder called \"Broken Files\", since opening them would simply give me a corrupted file error 99% of the time. Then I would simply scroll, wait a couple seconds for File Explorer to load the thumbnails, quickly scan for any files missing a thumbnail, then slowly scroll again.\n\nFor MP3 or other audio files, since all of them combined was only about \\~100GB, I decided it wasn't worth my time to comb through lots of more files to free up less space. For HTML, SVG, WAV, RTF, etc... all of them combined was only about \\~40GB, with over 200k files, so again, it wasn't worth my time trying to free up such little space with so many small files to comb through.\n\nAfter weeding out the corrupted or broken files, I made folders that were organized by year (2017, 2018, 2019, etc etc). I sorted the video/photos by their dates, and moved them into their respective year folders. I did this by again, having File Explorer in fullscreen, then putting it into DETAIL view (so I could see the date), sorted by date, then dragged the mouse all the way down, letting it autoscroll down until I've selected all the files for that year. \n\nFor the other files (HTML, WAV, RTF, etc), I again used File Explorer in full screen, but this time put it in LIST view instead of tile view (although you could use small icon view), and then sorted by file type. I then did the same for above, but instead of dates, it was file type (duh). I then put all the selected files into their respective folders (HTML, WAV, etc).\n\nAt this point in the recovery (or organization, really), I had a bunch of folders ranging from 2015 to 2021, and a few other folders for different file types. I put all of these folders in one big giant folder called \"good files\", then used DupeGuru to remove any duplicates from that folder. I set my 8TB HDD as a reference, and let DupeGuru sort through 300k+ files overnight.\n\nThe next morning I came back and saw a lot of duplicates, all with a 100% match. I made sure to save the results on my computer just in case. I went ahead and sorted by file size, and saw that the video files and all others were all matching up by year, file size, and even filename. The small \\~10kB files I knew luckily weren't that important to me, so I just let it slide, since they were probably some program files or PNG's that aren't family pictures or selfies.\n\nI moved all the duplicate files into another folder called \"good duplicates\". I then moved all of the \"good files\" to my 8TB HDD, totaling 1.5TB being moved via File Explorer. \n\nI then ran DupeGuru once more for good measure, setting the \"good duplicates\" folder against my 8TB HDD and the \"good files\". I saw one photo slide, and \\~200 small files like RTF, HTML, etc, after moving the duplicates to yet another folder called \"good duplicates 2\". I then moved the remaining non-duplicates to my 8TB HDD, and called it a day.\n\nI then went ahead and formatted the 8TB TRANSFER drive (not my 8TB HDD mentioned previously of course!) to get rid of any pesky files or anything that could interfere with storing data. Before I did any deletion or formatting, I made sure that the only files that were on the transfer drive were either broken files, or duplicates, which I confirmed they were.\n\n&amp;#x200B;\n\nThe data recovery itself took a little over a week from shipping to getting it back in the mail. The \n\nI formatted the 8TB transfer drive yesterday, and starting moving all the files I wish to move from my 8TB HDD to the 8TB transfer drive. It's about 5.3TB worth of data being moved over to my transfer drive, which will now be used as extra storage. As I'm typing this story down this morning, my data is still being transferred over, and has been doing so since last night, so I will give it probably a full 24 hours or so to fully transfer 5.3TB worth of data.", "author_fullname": "t2_n10mx4oww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got done recovering ~5TB worth of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s41pk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703693080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all. I&amp;#39;m new to the DataHoarder community, but not new to having numerous hard drives in my desk. &lt;/p&gt;\n\n&lt;p&gt;TLDR: Sent in my 4TB External HDD for recovery because I deleted files to save space. Deleted the corrupted or broken recovered files, organized the remaining good files, de-duplicated them, moved them to my main 8TB HDD, formatted the 8TB transfer drive, then moved all the files back onto the freshly formatted 8TB transfer drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the full story:&lt;/p&gt;\n\n&lt;p&gt;Back in October 2020, I decided to delete a bunch of videos off my measly 4TB Seagate External HDD since it was getting full. Later in February 2021, I got an 8TB External HDD that I still use to this day for videography and other purposes that I use daily. I moved all my data from my 4TB HDD to my 8TB HDD, basically leaving the 4TB completely empty. However (and luckily), I did not use it at all since that day.&lt;/p&gt;\n\n&lt;p&gt;Just this past November, I saved up enough to hire &lt;a href=\"https://www.300dollardatarecovery.com/\"&gt;$300 Dollar Data Recovery&lt;/a&gt; to recover ALL of the data on the 4TB, specifically the videos that I deleted way back in 2020. I filled out their forms, and sent another 8TB Internal HDD I had, and the 4TB from before.&lt;/p&gt;\n\n&lt;p&gt;When they shipped back both drives, I was surprised to find that there was a little over 5TB worth of data, all coming from a drive that has 3.63TB of storage. Everything from videos to really small files 1KB or less files, totaling about a million files and several tens of thousands of folders.&lt;/p&gt;\n\n&lt;p&gt;The FIRST thing I had to do was painstakingly sort out all the corrupted or &amp;quot;broken&amp;quot; files that weren&amp;#39;t playable or were distorted beyond recognition. So I had to carefully plan and make the process as efficient and fast as possible.&lt;/p&gt;\n\n&lt;p&gt;For videos and photo, I opened up File Explorer in full screen and put it in TILE view. I used Ctrl + Scroll and zoomed out as far as I could, just before going into a different view, to have as many icons as possible on my screen.&lt;/p&gt;\n\n&lt;p&gt;I also sorted the files by size, because most of the corrupt files were either ~1KB or gigantic (400+ MB for a corrupted photo). Doing this would group all the small and large files together, making it so I could simply drag around the blue box and select a bunch of them at once, and unselect the few good ones from my selection while holding down Ctrl.&lt;/p&gt;\n\n&lt;p&gt;I would let File Explorer load all the thumbnails for the photos/videos, and whatever didn&amp;#39;t have a thumbnail I simply selected and moved to a folder called &amp;quot;Broken Files&amp;quot;, since opening them would simply give me a corrupted file error 99% of the time. Then I would simply scroll, wait a couple seconds for File Explorer to load the thumbnails, quickly scan for any files missing a thumbnail, then slowly scroll again.&lt;/p&gt;\n\n&lt;p&gt;For MP3 or other audio files, since all of them combined was only about ~100GB, I decided it wasn&amp;#39;t worth my time to comb through lots of more files to free up less space. For HTML, SVG, WAV, RTF, etc... all of them combined was only about ~40GB, with over 200k files, so again, it wasn&amp;#39;t worth my time trying to free up such little space with so many small files to comb through.&lt;/p&gt;\n\n&lt;p&gt;After weeding out the corrupted or broken files, I made folders that were organized by year (2017, 2018, 2019, etc etc). I sorted the video/photos by their dates, and moved them into their respective year folders. I did this by again, having File Explorer in fullscreen, then putting it into DETAIL view (so I could see the date), sorted by date, then dragged the mouse all the way down, letting it autoscroll down until I&amp;#39;ve selected all the files for that year. &lt;/p&gt;\n\n&lt;p&gt;For the other files (HTML, WAV, RTF, etc), I again used File Explorer in full screen, but this time put it in LIST view instead of tile view (although you could use small icon view), and then sorted by file type. I then did the same for above, but instead of dates, it was file type (duh). I then put all the selected files into their respective folders (HTML, WAV, etc).&lt;/p&gt;\n\n&lt;p&gt;At this point in the recovery (or organization, really), I had a bunch of folders ranging from 2015 to 2021, and a few other folders for different file types. I put all of these folders in one big giant folder called &amp;quot;good files&amp;quot;, then used DupeGuru to remove any duplicates from that folder. I set my 8TB HDD as a reference, and let DupeGuru sort through 300k+ files overnight.&lt;/p&gt;\n\n&lt;p&gt;The next morning I came back and saw a lot of duplicates, all with a 100% match. I made sure to save the results on my computer just in case. I went ahead and sorted by file size, and saw that the video files and all others were all matching up by year, file size, and even filename. The small ~10kB files I knew luckily weren&amp;#39;t that important to me, so I just let it slide, since they were probably some program files or PNG&amp;#39;s that aren&amp;#39;t family pictures or selfies.&lt;/p&gt;\n\n&lt;p&gt;I moved all the duplicate files into another folder called &amp;quot;good duplicates&amp;quot;. I then moved all of the &amp;quot;good files&amp;quot; to my 8TB HDD, totaling 1.5TB being moved via File Explorer. &lt;/p&gt;\n\n&lt;p&gt;I then ran DupeGuru once more for good measure, setting the &amp;quot;good duplicates&amp;quot; folder against my 8TB HDD and the &amp;quot;good files&amp;quot;. I saw one photo slide, and ~200 small files like RTF, HTML, etc, after moving the duplicates to yet another folder called &amp;quot;good duplicates 2&amp;quot;. I then moved the remaining non-duplicates to my 8TB HDD, and called it a day.&lt;/p&gt;\n\n&lt;p&gt;I then went ahead and formatted the 8TB TRANSFER drive (not my 8TB HDD mentioned previously of course!) to get rid of any pesky files or anything that could interfere with storing data. Before I did any deletion or formatting, I made sure that the only files that were on the transfer drive were either broken files, or duplicates, which I confirmed they were.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The data recovery itself took a little over a week from shipping to getting it back in the mail. The &lt;/p&gt;\n\n&lt;p&gt;I formatted the 8TB transfer drive yesterday, and starting moving all the files I wish to move from my 8TB HDD to the 8TB transfer drive. It&amp;#39;s about 5.3TB worth of data being moved over to my transfer drive, which will now be used as extra storage. As I&amp;#39;m typing this story down this morning, my data is still being transferred over, and has been doing so since last night, so I will give it probably a full 24 hours or so to fully transfer 5.3TB worth of data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?auto=webp&amp;s=b60e1e5ce678ffb4aedb0243d62264f74de0ad4e", "width": 1000, "height": 474}, "resolutions": [{"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8abdcef72df2093bf758152201afa04bf6e057bf", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6e677071f813a21dcf0f718f62e269a544bceb3", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=09c16fd6ebedfd8bc66c13bdd68a4e2636838060", "width": 320, "height": 151}, {"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7eeda53972ba146d14da874ffe1535e7f85ea97", "width": 640, "height": 303}, {"url": "https://external-preview.redd.it/SjgP2r8duzoP40999EnERIcTn6JJw0WM2yjankvwgRs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=af269d1b86d58ad8f6938810a1ff26559b9df570", "width": 960, "height": 455}], "variants": {}, "id": "Lj79sn9bvI9itLtGCoV9Mp-NCuBvuY6FKn4cO6LIhnA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18s41pk", "is_robot_indexable": true, "report_reasons": null, "author": "EveningDay5261", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s41pk/just_got_done_recovering_5tb_worth_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s41pk/just_got_done_recovering_5tb_worth_of_data/", "subreddit_subscribers": 721262, "created_utc": 1703693080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently moving my entire media file collection to a better file management system ([Hydrus Network](https://hydrusnetwork.github.io/hydrus/index.html) if you're interested) and I realized that I also want to preserve the creation times of the original files.\n\nThis means that I have to effectively double the storage space needed for my current collection as I need to store the original files as well to preserve metadata. Eventually I will also spend hours (probably days) developing a custom database solution and script to record the timestamps and all other original metadata for future reference.\n\nThis is absurd. I'm substantially increasing my workload and storage needs simply because I have a stupid desire to preserve all data no matter what. I tell myself that I may need to have the timestamps for some data analysis projects in the future and that just enhances this unnecessary obligation to data preservation.\n\nJust wanted to share my frustration with this impractical addiction to data hoarding and to warn you guys to try and avoid becoming this bad. \n\nData hoarding is at the end of the day just a kind of hoarding.", "author_fullname": "t2_hokshzbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Addiction to Preserving Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rwdue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703667526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently moving my entire media file collection to a better file management system (&lt;a href=\"https://hydrusnetwork.github.io/hydrus/index.html\"&gt;Hydrus Network&lt;/a&gt; if you&amp;#39;re interested) and I realized that I also want to preserve the creation times of the original files.&lt;/p&gt;\n\n&lt;p&gt;This means that I have to effectively double the storage space needed for my current collection as I need to store the original files as well to preserve metadata. Eventually I will also spend hours (probably days) developing a custom database solution and script to record the timestamps and all other original metadata for future reference.&lt;/p&gt;\n\n&lt;p&gt;This is absurd. I&amp;#39;m substantially increasing my workload and storage needs simply because I have a stupid desire to preserve all data no matter what. I tell myself that I may need to have the timestamps for some data analysis projects in the future and that just enhances this unnecessary obligation to data preservation.&lt;/p&gt;\n\n&lt;p&gt;Just wanted to share my frustration with this impractical addiction to data hoarding and to warn you guys to try and avoid becoming this bad. &lt;/p&gt;\n\n&lt;p&gt;Data hoarding is at the end of the day just a kind of hoarding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18rwdue", "is_robot_indexable": true, "report_reasons": null, "author": "Estavenz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rwdue/addiction_to_preserving_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rwdue/addiction_to_preserving_data/", "subreddit_subscribers": 721262, "created_utc": 1703667526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello jpg hoarders! I wrote a python app to fly over an image collection (in my case, an adult collection) and view thousands of images at once. Zoom in and out from one image to small thumbnails with your mousewheel in seconds. All images are grouped as you have them on your disk and arranged in a huge landscape. RuGiVi can work with hundred thousand of images at once.\n\nhttps://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=93fec3e993d589e0211034972caeb88d1389722c\n\n[https://github.com/pronopython/rugivi](https://github.com/pronopython/rugivi)\n\nIt runs under Linux and Windows.\n\nI've tested it with over 700.000 images, the \"landscape\" looks like this (one pixel is one image):\n\nhttps://preview.redd.it/znlg3sxebv8c1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=e1a4c7589469bffecf3d8a37d796f937fa8ae2c1\n\nI think especially the map generation design is something for you data-hoarders :-)\n\n* Works with hundreds of thousands of images at the same time\n* Tested with around 700.000 images (see the world map shown here), that's a RuGiVi Pixel size of 4.600.000 x 4.400.000 pixels or 20.240.000 Megapixels or 10.120.000 Full HD Screens to be scrolled through\n* Dynamic view rendering - screen is updated partially when drawing takes more time\n* Thumbnails are cached in a database\n* It is open source, as it should be with anything sensitive!\n\nAs I've seen here people with bigger collections I'm really looking forward on feedback (it's still an alpha release), ideas, maybe your maps (how your collection looks from above :-) ).\n\nI have more open source apps to organize and enjoy a collection, have a look at them: [https://github.com/pronopython](https://github.com/pronopython)", "author_fullname": "t2_qtxw3hpvv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RuGiVi - Adult media landscape browser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w5vuy0z4bv8c1": {"status": "valid", "e": "Image", "m": "image/jpg", "o": [{"y": 686, "x": 1200, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1080&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=331c8fe8daf221ad2df25bd978bc52d2d9948434"}], "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4ebb817d69687e8fdc09df2afb401d9e4b79d76"}, {"y": 123, "x": 216, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac916ef73a05cf339cafb1e74a5c1a436b8a7104"}, {"y": 182, "x": 320, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0cc6318b9c61b4829ee10fafb595defcf012e01f"}, {"y": 365, "x": 640, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bfb07a185d1bf2286a1b810ce77d10aaa316e3ea"}, {"y": 548, "x": 960, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a990267381d788965e5d584c1975d74671b53d08"}, {"y": 617, "x": 1080, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53e58321ff426f255a8561d450e272382daea6ff"}], "s": {"y": 686, "x": 1200, "u": "https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=93fec3e993d589e0211034972caeb88d1389722c"}, "id": "w5vuy0z4bv8c1"}, "znlg3sxebv8c1": {"status": "valid", "e": "Image", "m": "image/jpg", "o": [{"y": 1728, "x": 1280, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=1080&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=4af60d7510383e4e10e69175714e966d02b60f8d"}], "p": [{"y": 145, "x": 108, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3fb2eac1eafdcfc60ac1147725e3960a233f414"}, {"y": 291, "x": 216, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b6874a435da4a246f2484875810827e06886e54"}, {"y": 432, "x": 320, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c7e988157b5f26c9bebe20978f1700898d64390"}, {"y": 864, "x": 640, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36dd868c8adf876b7299ccb1adfee95b2085c1d2"}, {"y": 1296, "x": 960, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=72cdcfc0105ad1f41d5ca655e108de39f9dba443"}, {"y": 1458, "x": 1080, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a72789cb46a567e2a001d51af9396350b46c2af"}], "s": {"y": 1728, "x": 1280, "u": "https://preview.redd.it/znlg3sxebv8c1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=e1a4c7589469bffecf3d8a37d796f937fa8ae2c1"}, "id": "znlg3sxebv8c1"}}, "name": "t3_18s5k9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1703696965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello jpg hoarders! I wrote a python app to fly over an image collection (in my case, an adult collection) and view thousands of images at once. Zoom in and out from one image to small thumbnails with your mousewheel in seconds. All images are grouped as you have them on your disk and arranged in a huge landscape. RuGiVi can work with hundred thousand of images at once.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=93fec3e993d589e0211034972caeb88d1389722c\"&gt;https://preview.redd.it/w5vuy0z4bv8c1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=93fec3e993d589e0211034972caeb88d1389722c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/pronopython/rugivi\"&gt;https://github.com/pronopython/rugivi&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It runs under Linux and Windows.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tested it with over 700.000 images, the &amp;quot;landscape&amp;quot; looks like this (one pixel is one image):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/znlg3sxebv8c1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e1a4c7589469bffecf3d8a37d796f937fa8ae2c1\"&gt;https://preview.redd.it/znlg3sxebv8c1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e1a4c7589469bffecf3d8a37d796f937fa8ae2c1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I think especially the map generation design is something for you data-hoarders :-)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Works with hundreds of thousands of images at the same time&lt;/li&gt;\n&lt;li&gt;Tested with around 700.000 images (see the world map shown here), that&amp;#39;s a RuGiVi Pixel size of 4.600.000 x 4.400.000 pixels or 20.240.000 Megapixels or 10.120.000 Full HD Screens to be scrolled through&lt;/li&gt;\n&lt;li&gt;Dynamic view rendering - screen is updated partially when drawing takes more time&lt;/li&gt;\n&lt;li&gt;Thumbnails are cached in a database&lt;/li&gt;\n&lt;li&gt;It is open source, as it should be with anything sensitive!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As I&amp;#39;ve seen here people with bigger collections I&amp;#39;m really looking forward on feedback (it&amp;#39;s still an alpha release), ideas, maybe your maps (how your collection looks from above :-) ).&lt;/p&gt;\n\n&lt;p&gt;I have more open source apps to organize and enjoy a collection, have a look at them: &lt;a href=\"https://github.com/pronopython\"&gt;https://github.com/pronopython&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?auto=webp&amp;s=217e669d5d905ffb22c8679f7d58d5347fc7f13e", "width": 1200, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cfa32c43bee32239449df17857bbed6d6a158ec5", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b62f52ec49d69e4aa810df10f1c5cff4bda8dab7", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=793918a02c38d05b4856c8e5941ba12ade6d1af7", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=12980a4cf23732fe166f3f4fa3411b4d5454b276", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8acfdedf02011303dddc76c5a59baafc7100df4b", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c7d9d8c451ba78afdde3fb62c80bcb884c35052", "width": 1080, "height": 617}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f164d8dbd99b5a53d4469482f3f8b9c71f752d41", "width": 1200, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=dbbbebc6133990793c3d73849b5823af6ae3a372", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=6ce2744fb3756b044c21109bd1a8cb215089b2bf", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=870f491b767e8a1ec986662bea1ff68a1e6a686a", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2e6cb5069ea18b13157279f2f1470ef7e7dc4832", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=9ac8e176d20f9eba189bc02f9fca854a9c342756", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=6c14eecb6cd777197041d976d3ab1ef7fb13b413", "width": 1080, "height": 617}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=f164d8dbd99b5a53d4469482f3f8b9c71f752d41", "width": 1200, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=dbbbebc6133990793c3d73849b5823af6ae3a372", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=6ce2744fb3756b044c21109bd1a8cb215089b2bf", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=870f491b767e8a1ec986662bea1ff68a1e6a686a", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=2e6cb5069ea18b13157279f2f1470ef7e7dc4832", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=9ac8e176d20f9eba189bc02f9fca854a9c342756", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/Snn4hAGOma3CFznd2r-UGKyBjno-FnqaxHPJzaaH4hc.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=6c14eecb6cd777197041d976d3ab1ef7fb13b413", "width": 1080, "height": 617}]}}, "id": "9zI6XQ0nXaRFIMl2hWOCVriOx_ueZUceUVT2Fmy-tHA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s5k9u", "is_robot_indexable": true, "report_reasons": null, "author": "pronopython", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s5k9u/rugivi_adult_media_landscape_browser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s5k9u/rugivi_adult_media_landscape_browser/", "subreddit_subscribers": 721262, "created_utc": 1703696965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Good evening all\n\nI have just finished moving data over from my dying laptop to a new PC (windows) and saw the fallibility of single backup. Whilst I do have backblaze for my computer with constant sync, I realized that my main media drive is not constantly plugged in for access, nor is there a more reliable method of storage for it. I am hoping to build something that will allow me to put my DVDs in it (digital copy) and music so I can stream it from other machines. From what I read, this is a good choice for JellyFin to play the media.\n\nI did some research on material that i need and other software, but I have only gotten more confused reading through this stuff than I learned. I realized this is some people's entire careers is just this section of how to run a computer.\n\nI am hoping for an intro to basic storage for 172 DVDs and 160 vhs videos, as well as 40gb of audio. This is probably peanuts compared to some numbers I've seen, but Start early is my main idea, so it is not severely daunting\n\nTLDR: I am looking for what I need to set up a basic linux computer (hardware/software) to have a system of better backup than a dying tiny external drive. I read about JellyFin for playing, but nothing for actual storage", "author_fullname": "t2_dacwz4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time here, first time seriously considering big backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rq1ig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703646273.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703646051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening all&lt;/p&gt;\n\n&lt;p&gt;I have just finished moving data over from my dying laptop to a new PC (windows) and saw the fallibility of single backup. Whilst I do have backblaze for my computer with constant sync, I realized that my main media drive is not constantly plugged in for access, nor is there a more reliable method of storage for it. I am hoping to build something that will allow me to put my DVDs in it (digital copy) and music so I can stream it from other machines. From what I read, this is a good choice for JellyFin to play the media.&lt;/p&gt;\n\n&lt;p&gt;I did some research on material that i need and other software, but I have only gotten more confused reading through this stuff than I learned. I realized this is some people&amp;#39;s entire careers is just this section of how to run a computer.&lt;/p&gt;\n\n&lt;p&gt;I am hoping for an intro to basic storage for 172 DVDs and 160 vhs videos, as well as 40gb of audio. This is probably peanuts compared to some numbers I&amp;#39;ve seen, but Start early is my main idea, so it is not severely daunting&lt;/p&gt;\n\n&lt;p&gt;TLDR: I am looking for what I need to set up a basic linux computer (hardware/software) to have a system of better backup than a dying tiny external drive. I read about JellyFin for playing, but nothing for actual storage&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rq1ig", "is_robot_indexable": true, "report_reasons": null, "author": "97cweb", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rq1ig/first_time_here_first_time_seriously_considering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rq1ig/first_time_here_first_time_seriously_considering/", "subreddit_subscribers": 721262, "created_utc": 1703646051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, \n\n&amp;#x200B;\n\n   I was looking to do some VHS conversion for some old VHS tapes that need to go away.  I have an old TV / VHS combo [https://www.mediapollution.tv/product-page/rca-t19060gy](https://www.mediapollution.tv/product-page/rca-t19060gy) specifically.  \n\n&amp;#x200B;\n\nI was thinking of getting something like this, [https://www.amazon.com/ClearClick-Digital-Converter-3-0-Generation/dp/B0B8BY5HCG/](https://www.amazon.com/ClearClick-Digital-Converter-3-0-Generation/dp/B0B8BY5HCG/) and converting it myself.  My concern that I have is that the TV/VHS combo seems to only have one audio output.  (ie.  It doesn't have a red, yellow, white but only the white and yellow which I assume is one of the audio channels).  Would this matter? I'd hate to convert and get bad quality audio because of this, when I could have gotten a better quality if I took it to a service or acquired a better VHS player.  \n\n&amp;#x200B;\n\nAny thoughts?\n\n&amp;#x200B;", "author_fullname": "t2_pujhcq07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting VHS Tapes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s5otb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703697280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was looking to do some VHS conversion for some old VHS tapes that need to go away.  I have an old TV / VHS combo &lt;a href=\"https://www.mediapollution.tv/product-page/rca-t19060gy\"&gt;https://www.mediapollution.tv/product-page/rca-t19060gy&lt;/a&gt; specifically.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was thinking of getting something like this, &lt;a href=\"https://www.amazon.com/ClearClick-Digital-Converter-3-0-Generation/dp/B0B8BY5HCG/\"&gt;https://www.amazon.com/ClearClick-Digital-Converter-3-0-Generation/dp/B0B8BY5HCG/&lt;/a&gt; and converting it myself.  My concern that I have is that the TV/VHS combo seems to only have one audio output.  (ie.  It doesn&amp;#39;t have a red, yellow, white but only the white and yellow which I assume is one of the audio channels).  Would this matter? I&amp;#39;d hate to convert and get bad quality audio because of this, when I could have gotten a better quality if I took it to a service or acquired a better VHS player.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4G9BAtiUEPm3uxpZErd7-6gQT9WW_CKJQOxHMa6Sztw.jpg?auto=webp&amp;s=b600d0192f6abd0abaa216ea632444247206875f", "width": 500, "height": 375}, "resolutions": [{"url": "https://external-preview.redd.it/4G9BAtiUEPm3uxpZErd7-6gQT9WW_CKJQOxHMa6Sztw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c56eda873c1d53ea4a01e159d209a85385404fe", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/4G9BAtiUEPm3uxpZErd7-6gQT9WW_CKJQOxHMa6Sztw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=afbdf406e275b69ddf76009ddcef20d2e430aa15", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/4G9BAtiUEPm3uxpZErd7-6gQT9WW_CKJQOxHMa6Sztw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c2b15856f08a574c232bdeb79aaba3c0bbf7b69", "width": 320, "height": 240}], "variants": {}, "id": "z1CDdnCRodlx8CWMOliStCIDXgB2nzP8ur3vMcLW0jE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s5otb", "is_robot_indexable": true, "report_reasons": null, "author": "csgeek3674", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s5otb/converting_vhs_tapes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s5otb/converting_vhs_tapes/", "subreddit_subscribers": 721262, "created_utc": 1703697280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can I rip my personal DVD/Blu-ray collection while preserving multiple audio languages? I'm new to ripping and want to digitize my collection. Specifically, I want to keep both the original English and the dubbed Spanish audio tracks. Any advice for a beginner in this process?\n\nThanks!  \n", "author_fullname": "t2_5cyhhwlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ripping DVDs/Blu-rays with Multiple Audio Languages?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rp8qf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703643685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can I rip my personal DVD/Blu-ray collection while preserving multiple audio languages? I&amp;#39;m new to ripping and want to digitize my collection. Specifically, I want to keep both the original English and the dubbed Spanish audio tracks. Any advice for a beginner in this process?&lt;/p&gt;\n\n&lt;p&gt;Thanks!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rp8qf", "is_robot_indexable": true, "report_reasons": null, "author": "JoshALogs", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rp8qf/ripping_dvdsblurays_with_multiple_audio_languages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rp8qf/ripping_dvdsblurays_with_multiple_audio_languages/", "subreddit_subscribers": 721262, "created_utc": 1703643685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "#TL;DR - Powered PC off + unplugged for 3 days. Turned back on, SSD dead. Software doesn't see it except Hard Disk Sentinel. Windows asks to initialize in Disk Manager. Ubuntu doesn't see it via gparted, dmesg shows it failed via softresets. Replaceable data but would rather somehow copy files off if at all possible one last time.\n\nSo, I went on vacation for 3 days, powering off and unplugging my PC before leaving (including turning off the switch on the PSU). Fast forward to when I return home, plug everything back in, and my PC takes an oddly long time to boot.\n\nTurns out my storage SSD, a Samsung 860 Evo, no longer gets detected in Windows. If I open disk management, [it shows this](https://i.imgur.com/CkNWmGI.png) and asks me to initialize it, something I obviously won't do.\n\nNothing else detects it from what I tried, except Hard Disk Sentinel: somehow, making it view it as an offline disk shows [disk activity at 100%](https://i.imgur.com/DjNPPho.png). Yes, this is live, not a snapshot. The average disk activity percentage kept going up until it reached 100%. Yet it remained \"offline\".\n\nI've also tried using gparted and dmesg Ubuntu to no avail. I live booted into Ubuntu via a USB, with the faulty SSD as the only internal drive in a spare desktop I have lying around. [These](https://i.imgur.com/bvixzlq.jpg) are all instances of \"/sd\" in dmesg. These [softreset](https://i.imgur.com/D4gMNNm.jpg) instances are what I believe are the faulty SSD.\n\nOther things I've tried include testdisk, which did not see the SSD in neither Windows nor Ubuntu, R-Studio Technician Edition which did not see the SSD, Macrium Reflect, and Easeus, neither of which saw the SSD either.\n\nI've also tried using a couple USB HDD docks that I have. I found that plugging it in to a dock does not get detected at all, but after a couple minutes of leaving it on, Windows will make a connection sound as though something's getting plugged in, then explorer will start slowing down every now and then. All the while, Windows will not detect a drive, but will claim there's a 0B storage device plugged into H (the drive's original drive letter).\n\nI read about the power cycling method where you unplug the SATA data cable and just leave the power cable connected, and turning on the PC for 30 mins in the BIOS, turning off for 30 secs, turning on for another 30 mins, turning off for 30 secs again, then finally plugging the SATA cable back and hoping for the best. Sadly, this did nothing. \n\nI then repeated this except left my PC on booted in Windows overnight (6 hours). When I woke up, I powered off, plugged SATA back in, and sadly nothing changed. Drive is still undetectable, and still asks to be initialized in Disk Management.\n\nI've done the same trick once more now that I'm at work, and will check back when I get home (should be on for 9 hours this time). But I don't have high hopes.\n\n#Is there anything else I can try? The data isn't important enough to warrant using an expensive data recovery professional. It's all replaceable, it would just be very bothersome and time consuming to replace it all (bunch of portable apps I've been using since 2015 along with music I've been meaning to tag and sync to my library).\n\nI thankfully know exactly what was on it thanks to VoidTools' Search Everything keeping track of what files were last on the drive, so I know what I'm missing. I just really hope there's something I can do to get one last breath of life out of this drive so I can simply copy everything off and save myself some time.\n\nWhat's really annoying is I was planning on making a backup system via Macrium (which I have been using for years) to make backups of all my SSDs, but hadn't gotten around to it yet. If I did, I wouldn't be trying so hard to recover this drive. \n\nP.S. This is my third storage failure this year, all of which are samsung devices (two 512GB microSDs of the same model, and now this 860 Evo SSD). It's bad enough that Samsung has a non-existent warranty in Canada where I can't even get a replacement, as though the higher price of their products wasn't already bad enough.", "author_fullname": "t2_ja9d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung 860 Evo 500GB SSD Died - Any recourse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s5x5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703699241.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703697861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;TL;DR - Powered PC off + unplugged for 3 days. Turned back on, SSD dead. Software doesn&amp;#39;t see it except Hard Disk Sentinel. Windows asks to initialize in Disk Manager. Ubuntu doesn&amp;#39;t see it via gparted, dmesg shows it failed via softresets. Replaceable data but would rather somehow copy files off if at all possible one last time.&lt;/h1&gt;\n\n&lt;p&gt;So, I went on vacation for 3 days, powering off and unplugging my PC before leaving (including turning off the switch on the PSU). Fast forward to when I return home, plug everything back in, and my PC takes an oddly long time to boot.&lt;/p&gt;\n\n&lt;p&gt;Turns out my storage SSD, a Samsung 860 Evo, no longer gets detected in Windows. If I open disk management, &lt;a href=\"https://i.imgur.com/CkNWmGI.png\"&gt;it shows this&lt;/a&gt; and asks me to initialize it, something I obviously won&amp;#39;t do.&lt;/p&gt;\n\n&lt;p&gt;Nothing else detects it from what I tried, except Hard Disk Sentinel: somehow, making it view it as an offline disk shows &lt;a href=\"https://i.imgur.com/DjNPPho.png\"&gt;disk activity at 100%&lt;/a&gt;. Yes, this is live, not a snapshot. The average disk activity percentage kept going up until it reached 100%. Yet it remained &amp;quot;offline&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also tried using gparted and dmesg Ubuntu to no avail. I live booted into Ubuntu via a USB, with the faulty SSD as the only internal drive in a spare desktop I have lying around. &lt;a href=\"https://i.imgur.com/bvixzlq.jpg\"&gt;These&lt;/a&gt; are all instances of &amp;quot;/sd&amp;quot; in dmesg. These &lt;a href=\"https://i.imgur.com/D4gMNNm.jpg\"&gt;softreset&lt;/a&gt; instances are what I believe are the faulty SSD.&lt;/p&gt;\n\n&lt;p&gt;Other things I&amp;#39;ve tried include testdisk, which did not see the SSD in neither Windows nor Ubuntu, R-Studio Technician Edition which did not see the SSD, Macrium Reflect, and Easeus, neither of which saw the SSD either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also tried using a couple USB HDD docks that I have. I found that plugging it in to a dock does not get detected at all, but after a couple minutes of leaving it on, Windows will make a connection sound as though something&amp;#39;s getting plugged in, then explorer will start slowing down every now and then. All the while, Windows will not detect a drive, but will claim there&amp;#39;s a 0B storage device plugged into H (the drive&amp;#39;s original drive letter).&lt;/p&gt;\n\n&lt;p&gt;I read about the power cycling method where you unplug the SATA data cable and just leave the power cable connected, and turning on the PC for 30 mins in the BIOS, turning off for 30 secs, turning on for another 30 mins, turning off for 30 secs again, then finally plugging the SATA cable back and hoping for the best. Sadly, this did nothing. &lt;/p&gt;\n\n&lt;p&gt;I then repeated this except left my PC on booted in Windows overnight (6 hours). When I woke up, I powered off, plugged SATA back in, and sadly nothing changed. Drive is still undetectable, and still asks to be initialized in Disk Management.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done the same trick once more now that I&amp;#39;m at work, and will check back when I get home (should be on for 9 hours this time). But I don&amp;#39;t have high hopes.&lt;/p&gt;\n\n&lt;h1&gt;Is there anything else I can try? The data isn&amp;#39;t important enough to warrant using an expensive data recovery professional. It&amp;#39;s all replaceable, it would just be very bothersome and time consuming to replace it all (bunch of portable apps I&amp;#39;ve been using since 2015 along with music I&amp;#39;ve been meaning to tag and sync to my library).&lt;/h1&gt;\n\n&lt;p&gt;I thankfully know exactly what was on it thanks to VoidTools&amp;#39; Search Everything keeping track of what files were last on the drive, so I know what I&amp;#39;m missing. I just really hope there&amp;#39;s something I can do to get one last breath of life out of this drive so I can simply copy everything off and save myself some time.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s really annoying is I was planning on making a backup system via Macrium (which I have been using for years) to make backups of all my SSDs, but hadn&amp;#39;t gotten around to it yet. If I did, I wouldn&amp;#39;t be trying so hard to recover this drive. &lt;/p&gt;\n\n&lt;p&gt;P.S. This is my third storage failure this year, all of which are samsung devices (two 512GB microSDs of the same model, and now this 860 Evo SSD). It&amp;#39;s bad enough that Samsung has a non-existent warranty in Canada where I can&amp;#39;t even get a replacement, as though the higher price of their products wasn&amp;#39;t already bad enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yht5wobzaXVkPYJGkpm7iaDP42pugRNBTpKM-Ay6kPE.png?auto=webp&amp;s=4c16fc4536173d43a5b3d697e42680a256c6c0c5", "width": 754, "height": 597}, "resolutions": [{"url": "https://external-preview.redd.it/yht5wobzaXVkPYJGkpm7iaDP42pugRNBTpKM-Ay6kPE.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1018555122c35a70dd7b63733295795d0f2e846", "width": 108, "height": 85}, {"url": "https://external-preview.redd.it/yht5wobzaXVkPYJGkpm7iaDP42pugRNBTpKM-Ay6kPE.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4a545d51f6daa31d7212a758800bcbe632caf5a", "width": 216, "height": 171}, {"url": "https://external-preview.redd.it/yht5wobzaXVkPYJGkpm7iaDP42pugRNBTpKM-Ay6kPE.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4d56152c5816c210339b47afe7e94e7945b19fd", "width": 320, "height": 253}, {"url": "https://external-preview.redd.it/yht5wobzaXVkPYJGkpm7iaDP42pugRNBTpKM-Ay6kPE.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b81481999de57c73482541399940a4641125fec1", "width": 640, "height": 506}], "variants": {}, "id": "pMkX3NtqxIdMXFFMCHA53rmqZqUEQjVdDrXKQgk5J4E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "111TB Externals", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s5x5t", "is_robot_indexable": true, "report_reasons": null, "author": "sonicrings4", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18s5x5t/samsung_860_evo_500gb_ssd_died_any_recourse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s5x5t/samsung_860_evo_500gb_ssd_died_any_recourse/", "subreddit_subscribers": 721262, "created_utc": 1703697861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, are there any third-party downloaders for Windows to download GDrive files (each file is 80+GB .) to my PC? The default client is awful. I need functions like auto pause / resume and verifying every byte since most are encrypted zips.", "author_fullname": "t2_wdpu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MEGA like downloader for GDrive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rzaln", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703678940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, are there any third-party downloaders for Windows to download GDrive files (each file is 80+GB .) to my PC? The default client is awful. I need functions like auto pause / resume and verifying every byte since most are encrypted zips.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rzaln", "is_robot_indexable": true, "report_reasons": null, "author": "sdw23", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rzaln/mega_like_downloader_for_gdrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rzaln/mega_like_downloader_for_gdrive/", "subreddit_subscribers": 721262, "created_utc": 1703678940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use TeraCopy and it preserves the time stamps flawlessly, however it copies everything within the directory. I only want to copy some folders/subfolders/files but maintain its folder structure and maintain time stamps. FreeFileSync seems perfect but doesn't maintain timestamps for folders.\n\nIs there an alternate software?\n\n&amp;#x200B;", "author_fullname": "t2_12qmo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GUI software that allows me to click which folders/subfolders/files to copy to destination and preserve time stamps and directory/structure/hierarchy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18rrbb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703649937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use TeraCopy and it preserves the time stamps flawlessly, however it copies everything within the directory. I only want to copy some folders/subfolders/files but maintain its folder structure and maintain time stamps. FreeFileSync seems perfect but doesn&amp;#39;t maintain timestamps for folders.&lt;/p&gt;\n\n&lt;p&gt;Is there an alternate software?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18rrbb0", "is_robot_indexable": true, "report_reasons": null, "author": "Snowblind45", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18rrbb0/gui_software_that_allows_me_to_click_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18rrbb0/gui_software_that_allows_me_to_click_which/", "subreddit_subscribers": 721262, "created_utc": 1703649937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[This is an update to a previous post.](https://www.reddit.com/r/DataHoarder/s/uease3deGD)\n\nWell...\n\nI've gone off the deep end.\n\nIt started when I realized the QNAP software was actual trash, and the hardware wasn't all that great either. So I upgraded the RAM, installed an SSD and TrueNAS Scale. I've only only filled up about 11.5TB so far, but...\n\nThat wasn't enough for me. The CPU was pegged at 100% utilization and running far too hot far too often.\n\nSo I decided I'd begin piecing together a new system. Let's just say that happened quickly. \n\n[I just bought all of this](https://pcpartpicker.com/list/ZcMWmD) less the 1080 (had it laying around) and four of the Exos drives (had them in the QNAP) and boys let me tell you I am *EXCITED* to piece this all together.\n\nThe only thing I may still add is a multigig NIC (looking at the x550-ts) when I upgrade to 10gig sometime in the near future.\n\nI cannot wait to continue trying to make /r/DataHoarder proud - but man. You really **are** bad influences!", "author_fullname": "t2_pprqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Update To: DataHoarder is a bad influence.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18shamn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703726736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/s/uease3deGD\"&gt;This is an update to a previous post.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Well...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve gone off the deep end.&lt;/p&gt;\n\n&lt;p&gt;It started when I realized the QNAP software was actual trash, and the hardware wasn&amp;#39;t all that great either. So I upgraded the RAM, installed an SSD and TrueNAS Scale. I&amp;#39;ve only only filled up about 11.5TB so far, but...&lt;/p&gt;\n\n&lt;p&gt;That wasn&amp;#39;t enough for me. The CPU was pegged at 100% utilization and running far too hot far too often.&lt;/p&gt;\n\n&lt;p&gt;So I decided I&amp;#39;d begin piecing together a new system. Let&amp;#39;s just say that happened quickly. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pcpartpicker.com/list/ZcMWmD\"&gt;I just bought all of this&lt;/a&gt; less the 1080 (had it laying around) and four of the Exos drives (had them in the QNAP) and boys let me tell you I am &lt;em&gt;EXCITED&lt;/em&gt; to piece this all together.&lt;/p&gt;\n\n&lt;p&gt;The only thing I may still add is a multigig NIC (looking at the x550-ts) when I upgrade to 10gig sometime in the near future.&lt;/p&gt;\n\n&lt;p&gt;I cannot wait to continue trying to make &lt;a href=\"/r/DataHoarder\"&gt;/r/DataHoarder&lt;/a&gt; proud - but man. You really &lt;strong&gt;are&lt;/strong&gt; bad influences!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18shamn", "is_robot_indexable": true, "report_reasons": null, "author": "iamseventwelve", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18shamn/an_update_to_datahoarder_is_a_bad_influence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18shamn/an_update_to_datahoarder_is_a_bad_influence/", "subreddit_subscribers": 721262, "created_utc": 1703726736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nI'm looking into buying a couple of M.2 NVMe drives. I was going to go for the WD Black SN850X, but I saw that it doesn't have hardware encryption, which is something that the other drive I was considering, a Samsung 980 Pro, has.\n\nProtection against physical thefts is something I would like to have, and I'm guessing that hardware encryption will help a lot here. Is this the case?", "author_fullname": "t2_74ggsl9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware vs Software encryption in case of theft", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18seffx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703719338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking into buying a couple of M.2 NVMe drives. I was going to go for the WD Black SN850X, but I saw that it doesn&amp;#39;t have hardware encryption, which is something that the other drive I was considering, a Samsung 980 Pro, has.&lt;/p&gt;\n\n&lt;p&gt;Protection against physical thefts is something I would like to have, and I&amp;#39;m guessing that hardware encryption will help a lot here. Is this the case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18seffx", "is_robot_indexable": true, "report_reasons": null, "author": "pab_lo_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18seffx/hardware_vs_software_encryption_in_case_of_theft/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18seffx/hardware_vs_software_encryption_in_case_of_theft/", "subreddit_subscribers": 721262, "created_utc": 1703719338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm transferring old VHS tapes by running my VHS player into my hi8 camera via component jacks and then using a firewire cable to go from my camera to my computer (OBS). But I noticed these moving lines going up and down the screen. I pumped the exposure so it can be easily seen as this is more hidden in the actual footage but I'm trying to figure out what this could be. Old tape? VHS player with a weak signal? Can anyone help identify these lines so I know what's causing them? I can provide more spec info if needed but:\n\nThe Hi8 camera I'm using: sony dcr trv340\n\nVHS player is a Sony VHS/DVD Combo which works well.\n\nThanks!!", "author_fullname": "t2_buyl9wgp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring VHS tapes glitch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sbs0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703712643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m transferring old VHS tapes by running my VHS player into my hi8 camera via component jacks and then using a firewire cable to go from my camera to my computer (OBS). But I noticed these moving lines going up and down the screen. I pumped the exposure so it can be easily seen as this is more hidden in the actual footage but I&amp;#39;m trying to figure out what this could be. Old tape? VHS player with a weak signal? Can anyone help identify these lines so I know what&amp;#39;s causing them? I can provide more spec info if needed but:&lt;/p&gt;\n\n&lt;p&gt;The Hi8 camera I&amp;#39;m using: sony dcr trv340&lt;/p&gt;\n\n&lt;p&gt;VHS player is a Sony VHS/DVD Combo which works well.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18sbs0i", "is_robot_indexable": true, "report_reasons": null, "author": "desperado491", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18sbs0i/transferring_vhs_tapes_glitch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18sbs0i/transferring_vhs_tapes_glitch/", "subreddit_subscribers": 721262, "created_utc": 1703712643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, am I completely off base here?\n\n I'll ask this group because it's data recovery related, but any Linux Admin's out there please chime in as well (and I'll ask other subs for that demographic as well, yes). \n\nI have 6 4TB HDD's in a machine that is failing (mobo/cpu). I have a need to get the data off of these drives and my available resources are a rack mounted server w/ 60 free TB's of space but no room for additional drives, and a second tower machine that does NOT have room for all of the drives or power for more than one or 2 of them. \n\nI tried, putting a 6 port SATA card in tower 2, using tower 1's PSU to power the drives while I boot tower 2 into linux and reassemble and read the array. The issue is that tower 1's CPU issues just make the whole thing reboot after about 20 minutes or so, even causing the PSU to reboot. Disconnecting the mobo in Tower 1 won't let the PSU actually power up for some reason. So that's not going anywhere.\n\nSince I don't have time, or funds right now honestly to order a new mobo/cpu for Tower 1, my current plan (plan F) is to remove one drive at a time, put it into Tower 2, and use something to create an ISO (or something else I might not be aware of) out of each drive into the rack mount NAS... then use the NAS to rebuild the array out of those ISO images and mount it into itself... or something. \n\nAm I smoking dreams and dropped packets here? Or is anything like this even possible? Wife's photography archives are trapped on these 6 disks - which have not had any issues - and we need to get the data off, onto the new NAS, and readable so we can continue working with it. \n\nIs there anyway to hotwire a PSU to just power drives without being hooked to a living MOBO? \n\nIs there anyway to ISO a MDADM drive, and then use mulitple ISO's to re-create the array on another machine? \n\nIs buying hardware and replacing it the only, or far safer (yet less adventurous!), way to do this? The machines are all living at a friends house (my TX 'datacenter') so I only have remote access when I'm in town which is for a few hours, while I'm in town... making ordering hardware, installing, and doing all of this impractical over the next few months.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_nq184", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linux MDADM ... from ISO files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s9867", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question / Sanity-check", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703706149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, am I completely off base here?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll ask this group because it&amp;#39;s data recovery related, but any Linux Admin&amp;#39;s out there please chime in as well (and I&amp;#39;ll ask other subs for that demographic as well, yes). &lt;/p&gt;\n\n&lt;p&gt;I have 6 4TB HDD&amp;#39;s in a machine that is failing (mobo/cpu). I have a need to get the data off of these drives and my available resources are a rack mounted server w/ 60 free TB&amp;#39;s of space but no room for additional drives, and a second tower machine that does NOT have room for all of the drives or power for more than one or 2 of them. &lt;/p&gt;\n\n&lt;p&gt;I tried, putting a 6 port SATA card in tower 2, using tower 1&amp;#39;s PSU to power the drives while I boot tower 2 into linux and reassemble and read the array. The issue is that tower 1&amp;#39;s CPU issues just make the whole thing reboot after about 20 minutes or so, even causing the PSU to reboot. Disconnecting the mobo in Tower 1 won&amp;#39;t let the PSU actually power up for some reason. So that&amp;#39;s not going anywhere.&lt;/p&gt;\n\n&lt;p&gt;Since I don&amp;#39;t have time, or funds right now honestly to order a new mobo/cpu for Tower 1, my current plan (plan F) is to remove one drive at a time, put it into Tower 2, and use something to create an ISO (or something else I might not be aware of) out of each drive into the rack mount NAS... then use the NAS to rebuild the array out of those ISO images and mount it into itself... or something. &lt;/p&gt;\n\n&lt;p&gt;Am I smoking dreams and dropped packets here? Or is anything like this even possible? Wife&amp;#39;s photography archives are trapped on these 6 disks - which have not had any issues - and we need to get the data off, onto the new NAS, and readable so we can continue working with it. &lt;/p&gt;\n\n&lt;p&gt;Is there anyway to hotwire a PSU to just power drives without being hooked to a living MOBO? &lt;/p&gt;\n\n&lt;p&gt;Is there anyway to ISO a MDADM drive, and then use mulitple ISO&amp;#39;s to re-create the array on another machine? &lt;/p&gt;\n\n&lt;p&gt;Is buying hardware and replacing it the only, or far safer (yet less adventurous!), way to do this? The machines are all living at a friends house (my TX &amp;#39;datacenter&amp;#39;) so I only have remote access when I&amp;#39;m in town which is for a few hours, while I&amp;#39;m in town... making ordering hardware, installing, and doing all of this impractical over the next few months.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "VHS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18s9867", "is_robot_indexable": true, "report_reasons": null, "author": "546875674c6966650d0a", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18s9867/linux_mdadm_from_iso_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s9867/linux_mdadm_from_iso_files/", "subreddit_subscribers": 721262, "created_utc": 1703706149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, as I was doing some research on making backups of my photo files, I came across sometime called cold storage. I currently run a Mac Mini system, I have Time Machine turned on, and mostly I'm concerned about keeping my nearly 4TB of photos preserved. With cost also being my factor. Would it be reasonable for me to get a 4TB hard drive, make a copy of all my photos, then store the drive away? I don't plan on keeping it hooked up to the Mac and keep it running. I also read about the format of the backup drive... running a Mac, does it matter what format I pick for the back up drive? APFS? Ex-FAT? And when I make the back up... what's the best way to move a large amount of files safely? Some mentioned copy but not move? And when people suggest I refresh the backup drive every few months, does that mean to re-copy everything over from the working drive again? Thanks in advance.", "author_fullname": "t2_16pgzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just came across the concept of cold storage...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s8zp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703705542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, as I was doing some research on making backups of my photo files, I came across sometime called cold storage. I currently run a Mac Mini system, I have Time Machine turned on, and mostly I&amp;#39;m concerned about keeping my nearly 4TB of photos preserved. With cost also being my factor. Would it be reasonable for me to get a 4TB hard drive, make a copy of all my photos, then store the drive away? I don&amp;#39;t plan on keeping it hooked up to the Mac and keep it running. I also read about the format of the backup drive... running a Mac, does it matter what format I pick for the back up drive? APFS? Ex-FAT? And when I make the back up... what&amp;#39;s the best way to move a large amount of files safely? Some mentioned copy but not move? And when people suggest I refresh the backup drive every few months, does that mean to re-copy everything over from the working drive again? Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s8zp9", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyRPN", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s8zp9/just_came_across_the_concept_of_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s8zp9/just_came_across_the_concept_of_cold_storage/", "subreddit_subscribers": 721262, "created_utc": 1703705542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all! Been a lurker for a while. \n\nI am currently sitting on close to 70 TB of data. All of it is replaceable, although ***very*** time consuming and somewhat costly to replace. \n\nI have a decent home server running Unraid with 2 parity drives, but due to cost of electricity, components and drives, I simply cannot justify spending money on an off-site hot spare/hot backup solution. \n\nThe cold storage backup will only need to be fetched in the event of a catastrophic failure (failure of 3 drives, fire, etc.), so assume that the data would never need to be fetched. It would be stored in a dry room-temperature environment.\n\nIdeally, I will update the off-site backup once every 4 months (\\~4 TB added every time).\n\nI have looked at several solutions (price pr. GB):\n\n* Google coldline/AWS glacier storage: 0.0012$ (monthly, minimum storage time 365 days)\n* Cold storage drives (E.g. Seagate Exos): 0.0156$ (one-time payment)\n* LTO tape: Initial \\~1600$ investment for LTO7 drive, then 0,003$ \n\nIt seems like they all have downsides, ranging from price to reliability. As this is my last resolution in case of failure, the chance of failure should be low. I have the option to maintain/validate previous backups every 4 months when new data is added.\n\nAny solutions I missed? How do HDDs hold up for long term cold storage?", "author_fullname": "t2_buy1kbxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cold storage solution for 70 TB of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s6kdm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703718439.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703699512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! Been a lurker for a while. &lt;/p&gt;\n\n&lt;p&gt;I am currently sitting on close to 70 TB of data. All of it is replaceable, although &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; time consuming and somewhat costly to replace. &lt;/p&gt;\n\n&lt;p&gt;I have a decent home server running Unraid with 2 parity drives, but due to cost of electricity, components and drives, I simply cannot justify spending money on an off-site hot spare/hot backup solution. &lt;/p&gt;\n\n&lt;p&gt;The cold storage backup will only need to be fetched in the event of a catastrophic failure (failure of 3 drives, fire, etc.), so assume that the data would never need to be fetched. It would be stored in a dry room-temperature environment.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I will update the off-site backup once every 4 months (~4 TB added every time).&lt;/p&gt;\n\n&lt;p&gt;I have looked at several solutions (price pr. GB):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Google coldline/AWS glacier storage: 0.0012$ (monthly, minimum storage time 365 days)&lt;/li&gt;\n&lt;li&gt;Cold storage drives (E.g. Seagate Exos): 0.0156$ (one-time payment)&lt;/li&gt;\n&lt;li&gt;LTO tape: Initial ~1600$ investment for LTO7 drive, then 0,003$ &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It seems like they all have downsides, ranging from price to reliability. As this is my last resolution in case of failure, the chance of failure should be low. I have the option to maintain/validate previous backups every 4 months when new data is added.&lt;/p&gt;\n\n&lt;p&gt;Any solutions I missed? How do HDDs hold up for long term cold storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s6kdm", "is_robot_indexable": true, "report_reasons": null, "author": "KabsDK", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s6kdm/cold_storage_solution_for_70_tb_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s6kdm/cold_storage_solution_for_70_tb_of_data/", "subreddit_subscribers": 721262, "created_utc": 1703699512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Apologies if this has been asked, but I've searched and have come up with nothing. I've exported my Tumblr Blog and have all of the post html files and associated images, as well as the index, however, I'd like to be able to scroll through the index and see it all stitched together like on my tumblr page.  Are there any tools or utilities that can do this?\n\nI figure there must be something that can stich multiple htmls into one long one via an index filed, but am coming up blank.", "author_fullname": "t2_479u9c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tumblr Export - Recreate Blog from the Index HTML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s4swq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703695061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this has been asked, but I&amp;#39;ve searched and have come up with nothing. I&amp;#39;ve exported my Tumblr Blog and have all of the post html files and associated images, as well as the index, however, I&amp;#39;d like to be able to scroll through the index and see it all stitched together like on my tumblr page.  Are there any tools or utilities that can do this?&lt;/p&gt;\n\n&lt;p&gt;I figure there must be something that can stich multiple htmls into one long one via an index filed, but am coming up blank.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s4swq", "is_robot_indexable": true, "report_reasons": null, "author": "ggodfrey", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s4swq/tumblr_export_recreate_blog_from_the_index_html/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s4swq/tumblr_export_recreate_blog_from_the_index_html/", "subreddit_subscribers": 721262, "created_utc": 1703695061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two 14TB HDD running on my windows pc for plex and (linux isos). Obviously this isn\u2019t the ideal setup, but it gets the job done for me.", "author_fullname": "t2_dzy5buj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My humble setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_18shnsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OYLRDb0GbV5YRVtq92g7xpuGS7_gPYcPxq23zvfTOeE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703727753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two 14TB HDD running on my windows pc for plex and (linux isos). Obviously this isn\u2019t the ideal setup, but it gets the job done for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yvw6132cxx8c1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?auto=webp&amp;s=60e52c9ae52d7e081c99f7f09f6a0199c08e1f5d", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=70d84ef0dcb40dc9705d75172e424444a111fe90", "width": 108, "height": 144}, {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=30f4718bcb429d73c94b52b99706ccad97c6fa40", "width": 216, "height": 288}, {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ba20723731c74aabe5d4bde81b8e1ade6ab78b9", "width": 320, "height": 426}, {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d612e6945485384509f02c747c0998f4f1d8caa4", "width": 640, "height": 853}, {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d0ce8a24008f7cdf3bad65e52d29415fa3a3850d", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/yvw6132cxx8c1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=706e1e32a8d3f3b46921c3cdb4c018486182ac67", "width": 1080, "height": 1440}], "variants": {}, "id": "N7_fei-xKoJtIgrl8QqLnkI3Dz681bVSrmqITL5Y8J0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18shnsq", "is_robot_indexable": true, "report_reasons": null, "author": "iStronglyDislikeMath", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18shnsq/my_humble_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yvw6132cxx8c1.jpeg", "subreddit_subscribers": 721262, "created_utc": 1703727753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i already know the absolute click extension method, but you need to click download video 1 by 1, is there a way to mass download?", "author_fullname": "t2_9lllqk55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to mass download doodstream video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18shnou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703727745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i already know the absolute click extension method, but you need to click download video 1 by 1, is there a way to mass download?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18shnou", "is_robot_indexable": true, "report_reasons": null, "author": "by_ru", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18shnou/is_there_a_way_to_mass_download_doodstream_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18shnou/is_there_a_way_to_mass_download_doodstream_video/", "subreddit_subscribers": 721262, "created_utc": 1703727745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone know of a program (or a way?) to validate checksums between files during the copy process?\n\nThere used to be a tool that did something like that.  Rather than just clicking on copy in windows, I\u2019m talking about some command line series or an external program that copies, then validates the copied file\u2019s checksum against the new file, then continues to copy in batch.", "author_fullname": "t2_4tob3sk2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validating checksums while copying", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18sgfbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703724419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know of a program (or a way?) to validate checksums between files during the copy process?&lt;/p&gt;\n\n&lt;p&gt;There used to be a tool that did something like that.  Rather than just clicking on copy in windows, I\u2019m talking about some command line series or an external program that copies, then validates the copied file\u2019s checksum against the new file, then continues to copy in batch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18sgfbt", "is_robot_indexable": true, "report_reasons": null, "author": "hmmqzaz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18sgfbt/validating_checksums_while_copying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18sgfbt/validating_checksums_while_copying/", "subreddit_subscribers": 721262, "created_utc": 1703724419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n[transfer SSD to HDD - always starts with 400+ MB\\/s, goes down to the ol' \\~100 MB\\/s](https://preview.redd.it/6l1nyso45x8c1.png?width=481&amp;format=png&amp;auto=webp&amp;s=c0896c20c9732f61c71e6b2667bd63d343772d4a)\n\n&amp;#x200B;\n\n[HDD to SSD always has a constant 120 MB\\/s](https://preview.redd.it/pd42ez4d5x8c1.png?width=454&amp;format=png&amp;auto=webp&amp;s=8b7aed496496481ac921d32a2b7d94f69226a137)\n\nI am using the external SSD through my USB 3.0 port (tried all 4 of them, and even through a 3.0 hub), and the 'preferred' speed is 120 MB/s. I am saying 'preferred', because it seems that when it's SSD to HDD, it does get a speed of 400MB/s (around the expected value), but only for a few seconds, then it drops.\n\nI am testing this with a 16GB file.\n\nUASP is enabled (at least it appears in Device Manager of Windows, and it is also specified in the Samsung Magician software). Speaking of the software, the benchmark tests do show results of around 450 MB/s write and read.\n\nSo what could be the problem with this 120MB/s limit? Cable is the one given by Samsung, ports are all blue with SS symbol. I even tried enabling Write-caching option, and formatted it to NTFS.\n\nThank you in advance, people, and I also apologize if I am not in the right place, this is my first post here.", "author_fullname": "t2_cfh6uqnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung T7 Shield External SSD - USB 3.0 port - around 120mb/s speed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pd42ez4d5x8c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 68, "x": 108, "u": "https://preview.redd.it/pd42ez4d5x8c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8e79fd955cf83d2228ec258a0249a1548d607c9"}, {"y": 137, "x": 216, "u": "https://preview.redd.it/pd42ez4d5x8c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1aff2dd7e67685cb695cfa7331372d8407759c4"}, {"y": 202, "x": 320, "u": "https://preview.redd.it/pd42ez4d5x8c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b3ec1b45f941c1c7255e398a1fa6d7ca9a69db14"}], "s": {"y": 288, "x": 454, "u": "https://preview.redd.it/pd42ez4d5x8c1.png?width=454&amp;format=png&amp;auto=webp&amp;s=8b7aed496496481ac921d32a2b7d94f69226a137"}, "id": "pd42ez4d5x8c1"}, "6l1nyso45x8c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 68, "x": 108, "u": "https://preview.redd.it/6l1nyso45x8c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=616ee20961096a650e245c92f4f04be486ed3641"}, {"y": 136, "x": 216, "u": "https://preview.redd.it/6l1nyso45x8c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=09f5ed22ca475205100b0340ea7a33cf533d1c87"}, {"y": 202, "x": 320, "u": "https://preview.redd.it/6l1nyso45x8c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=95a1aeb0ef90c61a4ee6c8342af8524c41b3cf56"}], "s": {"y": 305, "x": 481, "u": "https://preview.redd.it/6l1nyso45x8c1.png?width=481&amp;format=png&amp;auto=webp&amp;s=c0896c20c9732f61c71e6b2667bd63d343772d4a"}, "id": "6l1nyso45x8c1"}}, "name": "t3_18se930", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lmkhqSQNPGyxVLelAU4Fjx_v_N_G_oUm88DC9LYqeTM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703718890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6l1nyso45x8c1.png?width=481&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c0896c20c9732f61c71e6b2667bd63d343772d4a\"&gt;transfer SSD to HDD - always starts with 400+ MB/s, goes down to the ol&amp;#39; ~100 MB/s&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pd42ez4d5x8c1.png?width=454&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8b7aed496496481ac921d32a2b7d94f69226a137\"&gt;HDD to SSD always has a constant 120 MB/s&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am using the external SSD through my USB 3.0 port (tried all 4 of them, and even through a 3.0 hub), and the &amp;#39;preferred&amp;#39; speed is 120 MB/s. I am saying &amp;#39;preferred&amp;#39;, because it seems that when it&amp;#39;s SSD to HDD, it does get a speed of 400MB/s (around the expected value), but only for a few seconds, then it drops.&lt;/p&gt;\n\n&lt;p&gt;I am testing this with a 16GB file.&lt;/p&gt;\n\n&lt;p&gt;UASP is enabled (at least it appears in Device Manager of Windows, and it is also specified in the Samsung Magician software). Speaking of the software, the benchmark tests do show results of around 450 MB/s write and read.&lt;/p&gt;\n\n&lt;p&gt;So what could be the problem with this 120MB/s limit? Cable is the one given by Samsung, ports are all blue with SS symbol. I even tried enabling Write-caching option, and formatted it to NTFS.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance, people, and I also apologize if I am not in the right place, this is my first post here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18se930", "is_robot_indexable": true, "report_reasons": null, "author": "Chachables", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18se930/samsung_t7_shield_external_ssd_usb_30_port_around/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18se930/samsung_t7_shield_external_ssd_usb_30_port_around/", "subreddit_subscribers": 721262, "created_utc": 1703718890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Saw these drives from goHardDrive\n\n[https://www.goharddrive.com/Seagate-ST10000NM0016-10TB-3-5-Hard-Drive-p/g01-1086.htm](https://www.goharddrive.com/Seagate-ST10000NM0016-10TB-3-5-Hard-Drive-p/g01-1086.htm)\n\nI'm asking because I've seen people saying to not buy NOS drive and it looks like a good deal.", "author_fullname": "t2_fu9rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are NOS / New Old Stock HDDs worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sdsj6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703717738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw these drives from goHardDrive&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.goharddrive.com/Seagate-ST10000NM0016-10TB-3-5-Hard-Drive-p/g01-1086.htm\"&gt;https://www.goharddrive.com/Seagate-ST10000NM0016-10TB-3-5-Hard-Drive-p/g01-1086.htm&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking because I&amp;#39;ve seen people saying to not buy NOS drive and it looks like a good deal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BYxE2RDEYQZnP52B1be1ygHHcFnWizVdEjmDbjVnNJc.jpg?auto=webp&amp;s=9d2d30c77f8a141675f032104c072454642c6053", "width": 250, "height": 190}, "resolutions": [{"url": "https://external-preview.redd.it/BYxE2RDEYQZnP52B1be1ygHHcFnWizVdEjmDbjVnNJc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ebcf6442b20d48f316bff9eab76f811c3f4deafe", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/BYxE2RDEYQZnP52B1be1ygHHcFnWizVdEjmDbjVnNJc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ca0b26d895ec12c2976d95a51d474697038c8565", "width": 216, "height": 164}], "variants": {}, "id": "X6CxezILhMzgvQlawwCRiCgz0M29kTorpurNxEqBTUg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18sdsj6", "is_robot_indexable": true, "report_reasons": null, "author": "GearFourth", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18sdsj6/are_nos_new_old_stock_hdds_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18sdsj6/are_nos_new_old_stock_hdds_worth_it/", "subreddit_subscribers": 721262, "created_utc": 1703717738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Lots of experiences made with this case out of curiosity...\n\nI got a peculiar case, strangely at the same time as I discovered bit rot on an SSD in rarely ever touched data. It seems now a harddisk has failed at its job, too, because I have a HGST 4 TB in a USB dock that I only use for a differential backup every two days or so. And while it is already ten years old (to my surprise - how time flies!), I never had any issues with the frequent phase of writing new data to the drive. But then eventually I did a full-scale read scan and suddenly discovered lots of severely damaged areas.\n\nIf the harddisk needed refreshes of old data, it should have prioritized it, but didn't. All new write operations until the last day didn't give any indication of platter aging or such, but apparently areas not touched in a long time showed not just soft errors but out of curiosity I have now razed all data on it, triggered several low level formats, SMART data resets etc., did full reads and writes, chkdsk, Victoria (which sadly offered writing only once, mysteriously, me having no idea why it worked once but never else) and AOMEI Partition Assitant (which offers to wipe partitions or empty space, so I can somewhat direct it).\n\nSo now I know various spots that are damaged, of course tried to navigate around them to preserve some lowest-priority storage, but it is so annoying how often the drive freezes up and needs a restart when various software tries to access it. AOMEI is usually more successful at least without partitions on it, and I already flagged it offline to the LVM because that one loves to freeze.\n\nI had phases where chkdsk /r stumbled over certain regions several times, indicating no exclusion happening, but then Victoria blazed over it without any issues. In fact, the beginning sectors are quite fine, and some previously problematic areas have been fixed, some not by remapping which can be heard with the head buzzing when going over it, but some previously extremely problematic areas are now totally fine again.\n\nIt also doesn't help that the internal low level formating process is obscure in when it has finished, and it might even continue its work between power cycles, dunno.\n\nIn-between all this, the reallocated sectors reached a peak point where it seems the drive throttled writes to 7.5 MB/s. But the drive often tickers a little by itself and keeps adding more pending sectors, and then falls asleep after two minutes unless it gets another SMART request, in which case it continues. One time I let this go on for hours and learned that the pending sectors counter maxes at 65535 and then begins from 0 again.\n\nIt is frustrating how badly this all works, because apparently lots of surface can be recovered and the rest excluded, in theory.\n\nBut again, the most upsetting is that the disk didn't give any indication that its old data had already rotted. So much for SMART monitoring. - And now I am wondering whether this hadn't happened if the drive had been running long enough to get bored and do some self-checking of disk surface.\n\nIt is funny. The one time long after suffering through the DeathStar debacle I buy a Deskstar again and it fails on me. (Earlier also a WD Black 4 TB.) I now got myself an Ironwolf 8 TB as main (since I have a whole age range of ancient Seagates that are all still in great condition despite having served as system disks and then secondary/tertiary backup), moving my WD Red 6 TB to primary backup (which has zero motor vibration while the lighter and newer Ironwolf has a little), but I am worried the same might happen to the WD and don't know how long I'd have to keep it online so that it takes good care of its data. The HGST case is really an unexpected surprise, since I took such good care of it.\n\nMy goal was to not have it reallocate to the max but just avoid the bad sectors. Would be great if it was possible to exclude sector ranges manually - much more elegant than the finnicky mess the drive does by itself.\n\nEDIT: It is wacky: Victoria can be tricked into allowing write mode, which works totally fine. I have to trigger an operation that freezes for a bit, like reading a single sector that is bad, and then the options cease being grayed out, and then I have to select write mode and when the stall is over, it is grayed out again but selected. - It is just weird because the first time I had it available, it wasn't even grayed out. - And write mode really works much better than read mode. Read tends to make it hang for a long time, but write actually feels like it is repairing what can be repaired.", "author_fullname": "t2_c79ls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Harddisk only online for backup actually a bad idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sb54f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703713511.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703711012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of experiences made with this case out of curiosity...&lt;/p&gt;\n\n&lt;p&gt;I got a peculiar case, strangely at the same time as I discovered bit rot on an SSD in rarely ever touched data. It seems now a harddisk has failed at its job, too, because I have a HGST 4 TB in a USB dock that I only use for a differential backup every two days or so. And while it is already ten years old (to my surprise - how time flies!), I never had any issues with the frequent phase of writing new data to the drive. But then eventually I did a full-scale read scan and suddenly discovered lots of severely damaged areas.&lt;/p&gt;\n\n&lt;p&gt;If the harddisk needed refreshes of old data, it should have prioritized it, but didn&amp;#39;t. All new write operations until the last day didn&amp;#39;t give any indication of platter aging or such, but apparently areas not touched in a long time showed not just soft errors but out of curiosity I have now razed all data on it, triggered several low level formats, SMART data resets etc., did full reads and writes, chkdsk, Victoria (which sadly offered writing only once, mysteriously, me having no idea why it worked once but never else) and AOMEI Partition Assitant (which offers to wipe partitions or empty space, so I can somewhat direct it).&lt;/p&gt;\n\n&lt;p&gt;So now I know various spots that are damaged, of course tried to navigate around them to preserve some lowest-priority storage, but it is so annoying how often the drive freezes up and needs a restart when various software tries to access it. AOMEI is usually more successful at least without partitions on it, and I already flagged it offline to the LVM because that one loves to freeze.&lt;/p&gt;\n\n&lt;p&gt;I had phases where chkdsk /r stumbled over certain regions several times, indicating no exclusion happening, but then Victoria blazed over it without any issues. In fact, the beginning sectors are quite fine, and some previously problematic areas have been fixed, some not by remapping which can be heard with the head buzzing when going over it, but some previously extremely problematic areas are now totally fine again.&lt;/p&gt;\n\n&lt;p&gt;It also doesn&amp;#39;t help that the internal low level formating process is obscure in when it has finished, and it might even continue its work between power cycles, dunno.&lt;/p&gt;\n\n&lt;p&gt;In-between all this, the reallocated sectors reached a peak point where it seems the drive throttled writes to 7.5 MB/s. But the drive often tickers a little by itself and keeps adding more pending sectors, and then falls asleep after two minutes unless it gets another SMART request, in which case it continues. One time I let this go on for hours and learned that the pending sectors counter maxes at 65535 and then begins from 0 again.&lt;/p&gt;\n\n&lt;p&gt;It is frustrating how badly this all works, because apparently lots of surface can be recovered and the rest excluded, in theory.&lt;/p&gt;\n\n&lt;p&gt;But again, the most upsetting is that the disk didn&amp;#39;t give any indication that its old data had already rotted. So much for SMART monitoring. - And now I am wondering whether this hadn&amp;#39;t happened if the drive had been running long enough to get bored and do some self-checking of disk surface.&lt;/p&gt;\n\n&lt;p&gt;It is funny. The one time long after suffering through the DeathStar debacle I buy a Deskstar again and it fails on me. (Earlier also a WD Black 4 TB.) I now got myself an Ironwolf 8 TB as main (since I have a whole age range of ancient Seagates that are all still in great condition despite having served as system disks and then secondary/tertiary backup), moving my WD Red 6 TB to primary backup (which has zero motor vibration while the lighter and newer Ironwolf has a little), but I am worried the same might happen to the WD and don&amp;#39;t know how long I&amp;#39;d have to keep it online so that it takes good care of its data. The HGST case is really an unexpected surprise, since I took such good care of it.&lt;/p&gt;\n\n&lt;p&gt;My goal was to not have it reallocate to the max but just avoid the bad sectors. Would be great if it was possible to exclude sector ranges manually - much more elegant than the finnicky mess the drive does by itself.&lt;/p&gt;\n\n&lt;p&gt;EDIT: It is wacky: Victoria can be tricked into allowing write mode, which works totally fine. I have to trigger an operation that freezes for a bit, like reading a single sector that is bad, and then the options cease being grayed out, and then I have to select write mode and when the stall is over, it is grayed out again but selected. - It is just weird because the first time I had it available, it wasn&amp;#39;t even grayed out. - And write mode really works much better than read mode. Read tends to make it hang for a long time, but write actually feels like it is repairing what can be repaired.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18sb54f", "is_robot_indexable": true, "report_reasons": null, "author": "Dowlphin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18sb54f/harddisk_only_online_for_backup_actually_a_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18sb54f/harddisk_only_online_for_backup_actually_a_bad/", "subreddit_subscribers": 721262, "created_utc": 1703711012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to back-up around 100gb of photos and videos to an HDD. Is there a way to back-up the Samsung gallery directly, so that all my folders are kept?\nAlso, do I need any adapters or can I just plug in an HDD with usb c directly to my phone?\n\nHow long does it usually take to transfer 100gb of data to an average HDD?\n\nI was also contemplating getting an SSD, but I'm not sure I need the faster read speeds, because I would plug the HDD to my phone maybe 2 or 3 times a year to look at/show some photos.\n\nLastly, are there any HDD's that you guys can recommend specifically for my needs?", "author_fullname": "t2_54itytzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photos and videos from Samsung Galaxy S20 to HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s7qk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703702415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to back-up around 100gb of photos and videos to an HDD. Is there a way to back-up the Samsung gallery directly, so that all my folders are kept?\nAlso, do I need any adapters or can I just plug in an HDD with usb c directly to my phone?&lt;/p&gt;\n\n&lt;p&gt;How long does it usually take to transfer 100gb of data to an average HDD?&lt;/p&gt;\n\n&lt;p&gt;I was also contemplating getting an SSD, but I&amp;#39;m not sure I need the faster read speeds, because I would plug the HDD to my phone maybe 2 or 3 times a year to look at/show some photos.&lt;/p&gt;\n\n&lt;p&gt;Lastly, are there any HDD&amp;#39;s that you guys can recommend specifically for my needs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s7qk2", "is_robot_indexable": true, "report_reasons": null, "author": "bubble121212", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s7qk2/photos_and_videos_from_samsung_galaxy_s20_to_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s7qk2/photos_and_videos_from_samsung_galaxy_s20_to_hdd/", "subreddit_subscribers": 721262, "created_utc": 1703702415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, long-time hoarder, first-time caller. I've been searching for answers in this sub and elsewhere, and maybe I just don't know how to frame the questions right, but I'm still puzzled. Any assistance appreciated!\n\nI've had good luck/experience with Samsung drives (though if you can solve my problem with another brand, I'm all ears!). I have some of their 2TB and 4TB portable SSDs. I don't really *need* them to be portable, but it's handy (really what I want is high capacity, *relatively* fast, and the robustness of an SSD). So aiming for an 8TB drive, I noticed they have one ... but only for inside computers?!\n\n**This is what I'm looking at: SAMSUNG 870 QVO SATA III SSD 8TB 2.5\"**\n\nThe price looks fine, size looks great, and speeds are decent so ... what gives? Why is this priced so well, have a higher capacity than the externals, etc....? The only thing I can see is that the speeds are a fair bit slower, but that's fine by me (and still doesn't account for the capacity difference?). **So couldn't I just get an enclosure and use it as an external drive? (Related: if so, any recommendations for a good enclosure?)**\n\n*P.S. I'm also in the market for any good rec's for a different, robust/quality/mid-to-high-speed 8-12TB external drive. My use case is 'second order storage' -- basically, a large, single-unit backup space for my multiple 2-to-4-TB SSDs. It would be nice if it were physically smaller than a WD Book but I'm flexible.*", "author_fullname": "t2_3ue2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung has external SSDs up to 4TB, but internal ones up to 8TB that don't seem any larger or more expensive. Why? And can I use an enclosure to utilize the 8TB internal as an external?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s6exa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703699322.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703699128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, long-time hoarder, first-time caller. I&amp;#39;ve been searching for answers in this sub and elsewhere, and maybe I just don&amp;#39;t know how to frame the questions right, but I&amp;#39;m still puzzled. Any assistance appreciated!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had good luck/experience with Samsung drives (though if you can solve my problem with another brand, I&amp;#39;m all ears!). I have some of their 2TB and 4TB portable SSDs. I don&amp;#39;t really &lt;em&gt;need&lt;/em&gt; them to be portable, but it&amp;#39;s handy (really what I want is high capacity, &lt;em&gt;relatively&lt;/em&gt; fast, and the robustness of an SSD). So aiming for an 8TB drive, I noticed they have one ... but only for inside computers?!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This is what I&amp;#39;m looking at: SAMSUNG 870 QVO SATA III SSD 8TB 2.5&amp;quot;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The price looks fine, size looks great, and speeds are decent so ... what gives? Why is this priced so well, have a higher capacity than the externals, etc....? The only thing I can see is that the speeds are a fair bit slower, but that&amp;#39;s fine by me (and still doesn&amp;#39;t account for the capacity difference?). &lt;strong&gt;So couldn&amp;#39;t I just get an enclosure and use it as an external drive? (Related: if so, any recommendations for a good enclosure?)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;P.S. I&amp;#39;m also in the market for any good rec&amp;#39;s for a different, robust/quality/mid-to-high-speed 8-12TB external drive. My use case is &amp;#39;second order storage&amp;#39; -- basically, a large, single-unit backup space for my multiple 2-to-4-TB SSDs. It would be nice if it were physically smaller than a WD Book but I&amp;#39;m flexible.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18s6exa", "is_robot_indexable": true, "report_reasons": null, "author": "misnamed", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18s6exa/samsung_has_external_ssds_up_to_4tb_but_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18s6exa/samsung_has_external_ssds_up_to_4tb_but_internal/", "subreddit_subscribers": 721262, "created_utc": 1703699128.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}