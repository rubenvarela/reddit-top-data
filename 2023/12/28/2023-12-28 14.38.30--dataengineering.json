{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sorry to ask this kind of question, but my PM told me about this.\n\n\"Snowflake plans to buy the iceberg and will turn it into a private project.\"\n\nAnd I tried to check the facts about this, but can't find the source on the internet anywhere.\n\nHe said he will provide the source in next week's meeting, but I can't wait 'till then.\n\nBesides, this cannot be true, I mean, what about Netflix and other major companies?\n\nThis is unrealistic.", "author_fullname": "t2_1c81q43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Snowflake planning to buy Apache Iceberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18skpea", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703736775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sorry to ask this kind of question, but my PM told me about this.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Snowflake plans to buy the iceberg and will turn it into a private project.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;And I tried to check the facts about this, but can&amp;#39;t find the source on the internet anywhere.&lt;/p&gt;\n\n&lt;p&gt;He said he will provide the source in next week&amp;#39;s meeting, but I can&amp;#39;t wait &amp;#39;till then.&lt;/p&gt;\n\n&lt;p&gt;Besides, this cannot be true, I mean, what about Netflix and other major companies?&lt;/p&gt;\n\n&lt;p&gt;This is unrealistic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18skpea", "is_robot_indexable": true, "report_reasons": null, "author": "nonaln", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18skpea/is_snowflake_planning_to_buy_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18skpea/is_snowflake_planning_to_buy_apache_iceberg/", "subreddit_subscribers": 148968, "created_utc": 1703736775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is going to try Agile.  We're also a company that is doing pretty constant, severe transitions in technology and structure, and we're very much a support group as well.\n\nI like the concept of Agile, but I wonder how the planning out workloads etc. meshes with one-off, urgent support requests (which we deal with frequently). \n\nOne of my old places had a department that practiced agile.  In retrospect, I think their solution to project vs support was *to drop support entirely*. \n \n  * They used a seperate IM app from the rest of the company - no pinging them\n  * Other depts weren't allowd in their office area uninvited - no pinging them\n  * Emails were mostly ignored, up to and including from the CEO. \n\nNaturally, they weren't real popular. \n\nSo like, how does one do Agile when saying \"well our velocity is 15 points a week...unless a large emergency came up, then it's 2, or if somehow everything was quiet, then it's 25...so to answer how long this 50 point project will take...\"\n\n**EDIT** case and point - I'm on vacation, but just got a direct email about the report we use to bill our largest client is \"being weird'.  They didn't use the ticketing system even, as they know it'd be me anyway. ", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you combine Agile dev work, with unpredictable support tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s5uuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703702160.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703697697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is going to try Agile.  We&amp;#39;re also a company that is doing pretty constant, severe transitions in technology and structure, and we&amp;#39;re very much a support group as well.&lt;/p&gt;\n\n&lt;p&gt;I like the concept of Agile, but I wonder how the planning out workloads etc. meshes with one-off, urgent support requests (which we deal with frequently). &lt;/p&gt;\n\n&lt;p&gt;One of my old places had a department that practiced agile.  In retrospect, I think their solution to project vs support was &lt;em&gt;to drop support entirely&lt;/em&gt;. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;They used a seperate IM app from the rest of the company - no pinging them&lt;/li&gt;\n&lt;li&gt;Other depts weren&amp;#39;t allowd in their office area uninvited - no pinging them&lt;/li&gt;\n&lt;li&gt;Emails were mostly ignored, up to and including from the CEO. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Naturally, they weren&amp;#39;t real popular. &lt;/p&gt;\n\n&lt;p&gt;So like, how does one do Agile when saying &amp;quot;well our velocity is 15 points a week...unless a large emergency came up, then it&amp;#39;s 2, or if somehow everything was quiet, then it&amp;#39;s 25...so to answer how long this 50 point project will take...&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; case and point - I&amp;#39;m on vacation, but just got a direct email about the report we use to bill our largest client is &amp;quot;being weird&amp;#39;.  They didn&amp;#39;t use the ticketing system even, as they know it&amp;#39;d be me anyway. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18s5uuo", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s5uuo/how_do_you_combine_agile_dev_work_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s5uuo/how_do_you_combine_agile_dev_work_with/", "subreddit_subscribers": 148968, "created_utc": 1703697697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone \ud83d\udc4b\ud83c\udffc\n\n  \nWe've built a [product](https://gist.github.com/jpmarionata/30e6c8c210b5c7ac3a4f193ce8291dff) to expose low-latency data APIs from multiple data sources in less than a minute. We'll release it in the upcoming weeks and would love to hear your feedback!  \nGeneral opinion?  \nWhat would you like to remove/add or change?  \nWhat do you think of the approach?  \nWhat use-cases do you have in mind?  \nAnything else \ud83d\ude01\n\n  \nYou can check it out in this [gist](https://gist.github.com/jpmarionata/30e6c8c210b5c7ac3a4f193ce8291dff) \\- looking forward to hearing your thoughts!", "author_fullname": "t2_crhg4y71r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low-latency data APIs in lesss than a min!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s32z1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703690520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone \ud83d\udc4b\ud83c\udffc&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve built a &lt;a href=\"https://gist.github.com/jpmarionata/30e6c8c210b5c7ac3a4f193ce8291dff\"&gt;product&lt;/a&gt; to expose low-latency data APIs from multiple data sources in less than a minute. We&amp;#39;ll release it in the upcoming weeks and would love to hear your feedback!&lt;br/&gt;\nGeneral opinion?&lt;br/&gt;\nWhat would you like to remove/add or change?&lt;br/&gt;\nWhat do you think of the approach?&lt;br/&gt;\nWhat use-cases do you have in mind?&lt;br/&gt;\nAnything else \ud83d\ude01&lt;/p&gt;\n\n&lt;p&gt;You can check it out in this &lt;a href=\"https://gist.github.com/jpmarionata/30e6c8c210b5c7ac3a4f193ce8291dff\"&gt;gist&lt;/a&gt; - looking forward to hearing your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?auto=webp&amp;s=9ae035fbdcd6bb503ab0b4a605b8db6de46647ee", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9bcab7b79864ff27bf48116cb335a6f825bfb124", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4e925345605c644eebe8abd69916915fc4fbcf7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=614b06d5b40c890a59e355191a6e2d75cdf50789", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62ca4cb88917f17e7200a6f1c665b5d959713745", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5f4a30974a8e6bad0d617a79935bc70c954e3e8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DaucjXMGsNHM-CtmdilC9-Be6MC8V2z4ykjVCgOkTFc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=476793be11eaac4604b6b0c938b45c7c3b52d450", "width": 1080, "height": 540}], "variants": {}, "id": "OAXSl8SY6T3JK9MGQyKxkoYbqZ71HQRYXLeB8CV0NXg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18s32z1", "is_robot_indexable": true, "report_reasons": null, "author": "WarmZucchini2257", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s32z1/lowlatency_data_apis_in_lesss_than_a_min/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s32z1/lowlatency_data_apis_in_lesss_than_a_min/", "subreddit_subscribers": 148968, "created_utc": 1703690520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Small career synopsis: I am a self-taught programmer that learned SQL and Python. Current career length is about 6 years. Started when I moved into an analyst role at my company and then a year later received a great opportunity to be a data engineer on the new data engineering team that formed here. Three years later I was promoted to Senior and it\u2019s been two years since then. \n\nI picked up a lot of experience around their Microsoft tech stack: SQL Server, SSIS, SSAS, Git (used RedGate as well), CI/CD, some PowerBI, DAX. Our servers are all on VM machines on Azure so I don\u2019t use Azure really. At a point I felt like I wasn\u2019t being challenged enough and I wrote a Python framework for file ingestion. It was the first time the team had used Python for anything. It uses Azure KeyVault for secrets. I\u2019ve also really dove into SQL Performance Tuning the whole time and am fairly advanced in that area. I really love the complexity of it.\n\nI\u2019ll be moving on from the company soon-ish and I was looking for advice on how to make the jump into a more modern tech stack for data engineering. Personally I really like Spark and the complexities with that architecture. Obvious route would be to dive into maybe an Azure certification. Databricks seems pretty cool too. What would you do if you were in my position? I have a solid grasp of data engineering fundamentals and a knack at looking at the bigger architecture picture, I just need to be able to get my foot in the door at a company with a more modern stack where I can be challenged again. Appreciate any advice, it\u2019s annoying when I know I could handle the shift, but I can only say I\u2019ve worked with an 8TB data warehouse on SQL Server in an interview. It like immediately disqualifies me", "author_fullname": "t2_13hsgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to move towards modern data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s9o4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703707289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Small career synopsis: I am a self-taught programmer that learned SQL and Python. Current career length is about 6 years. Started when I moved into an analyst role at my company and then a year later received a great opportunity to be a data engineer on the new data engineering team that formed here. Three years later I was promoted to Senior and it\u2019s been two years since then. &lt;/p&gt;\n\n&lt;p&gt;I picked up a lot of experience around their Microsoft tech stack: SQL Server, SSIS, SSAS, Git (used RedGate as well), CI/CD, some PowerBI, DAX. Our servers are all on VM machines on Azure so I don\u2019t use Azure really. At a point I felt like I wasn\u2019t being challenged enough and I wrote a Python framework for file ingestion. It was the first time the team had used Python for anything. It uses Azure KeyVault for secrets. I\u2019ve also really dove into SQL Performance Tuning the whole time and am fairly advanced in that area. I really love the complexity of it.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll be moving on from the company soon-ish and I was looking for advice on how to make the jump into a more modern tech stack for data engineering. Personally I really like Spark and the complexities with that architecture. Obvious route would be to dive into maybe an Azure certification. Databricks seems pretty cool too. What would you do if you were in my position? I have a solid grasp of data engineering fundamentals and a knack at looking at the bigger architecture picture, I just need to be able to get my foot in the door at a company with a more modern stack where I can be challenged again. Appreciate any advice, it\u2019s annoying when I know I could handle the shift, but I can only say I\u2019ve worked with an 8TB data warehouse on SQL Server in an interview. It like immediately disqualifies me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18s9o4n", "is_robot_indexable": true, "report_reasons": null, "author": "highlanderaffliction", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s9o4n/wanting_to_move_towards_modern_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s9o4n/wanting_to_move_towards_modern_data_engineering/", "subreddit_subscribers": 148968, "created_utc": 1703707289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Sorting &amp; Partitioning (Find more at youtube.com/@alexmerceddata)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18s1mal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/ivovjr98iu8c1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/ivovjr98iu8c1/DASH_96.mp4", "dash_url": "https://v.redd.it/ivovjr98iu8c1/DASHPlaylist.mpd?a=1706366310%2CYzg4MmRhYjJjYTk2MGE4YTE5ZmI0YTY4MjgzODA1MjM5ZmZlNDAxYWUwMTk0NTgzNTg4MmQ2NmMzMzQyZDc5Ng%3D%3D&amp;v=1&amp;f=sd", "duration": 730, "hls_url": "https://v.redd.it/ivovjr98iu8c1/HLSPlaylist.m3u8?a=1706366310%2CYTlhMTQ0YzRkNDQ3ZWU0Nzg4MDkwZGVhZjI0OThkYjkyNDY3Zjc0MDI5MWJlYTgxM2FjNmVhYWI4NmViZjY2Ng%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=6ef1f6ba6e9dae143ba472bcf88f081d168aa4da", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703686435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/ivovjr98iu8c1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?format=pjpg&amp;auto=webp&amp;s=afc40d6fa7925c91d33beaa9ca97120f2bc29052", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=619a6583ef94697e114e5240b62ea596644681f5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c6be524014d2396a9affbfa673201da949bb6ef9", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=de784ff00d009056a7949049753be050b0d596f7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a91901d01d869c3c9527d55e556ec58cde395134", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c4d07c63e83035b31e804a9c5377fd84c38fe9e4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=38850c5a39d1ac798faae626fa7a9e3e6667949b", "width": 1080, "height": 607}], "variants": {}, "id": "M29iOXkyM2hpdThjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18s1mal", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s1mal/understanding_sorting_partitioning_find_more_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/ivovjr98iu8c1", "subreddit_subscribers": 148968, "created_utc": 1703686435.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/ivovjr98iu8c1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/ivovjr98iu8c1/DASH_96.mp4", "dash_url": "https://v.redd.it/ivovjr98iu8c1/DASHPlaylist.mpd?a=1706366310%2CYzg4MmRhYjJjYTk2MGE4YTE5ZmI0YTY4MjgzODA1MjM5ZmZlNDAxYWUwMTk0NTgzNTg4MmQ2NmMzMzQyZDc5Ng%3D%3D&amp;v=1&amp;f=sd", "duration": 730, "hls_url": "https://v.redd.it/ivovjr98iu8c1/HLSPlaylist.m3u8?a=1706366310%2CYTlhMTQ0YzRkNDQ3ZWU0Nzg4MDkwZGVhZjI0OThkYjkyNDY3Zjc0MDI5MWJlYTgxM2FjNmVhYWI4NmViZjY2Ng%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! \n\nI have an API data source from which I get data and perform some processing. Currently I use Jupiter notebook and libraries like requests. Pandas, etc to do this and finally save as CSV/ excel file.\n\nThe API takes from and to date as inputs.\n\nI want to have a dashboard that external users can access and input the from and to dates, choose if they want to download the output as CSV or excel.\n\nWhat would be the best way to make this possible? I know this has to be something implemented on a cloud platform so it can be accessed by external users. I am looking for some guidance on what cloud tools/ technologies can be used to achieve this.\n\nThanks in advance for your time!", "author_fullname": "t2_t05ji4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options for a dashboard that gets user inputs to run python code and can be accessed by external users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s2gn9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703688830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! &lt;/p&gt;\n\n&lt;p&gt;I have an API data source from which I get data and perform some processing. Currently I use Jupiter notebook and libraries like requests. Pandas, etc to do this and finally save as CSV/ excel file.&lt;/p&gt;\n\n&lt;p&gt;The API takes from and to date as inputs.&lt;/p&gt;\n\n&lt;p&gt;I want to have a dashboard that external users can access and input the from and to dates, choose if they want to download the output as CSV or excel.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to make this possible? I know this has to be something implemented on a cloud platform so it can be accessed by external users. I am looking for some guidance on what cloud tools/ technologies can be used to achieve this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18s2gn9", "is_robot_indexable": true, "report_reasons": null, "author": "kkchn001", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s2gn9/options_for_a_dashboard_that_gets_user_inputs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s2gn9/options_for_a_dashboard_that_gets_user_inputs_to/", "subreddit_subscribers": 148968, "created_utc": 1703688830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building your Sausage Machine for Data Products \ud83c\udf2d: Less Tech, More Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_18slkpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3Z4_KPoVYBQq131p2u4-779xr1fHERjOVVgBZOFYq-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703739572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/building-your-sausage-machine-for", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?auto=webp&amp;s=59604d8ad6a5334d857bbe9241f8e00b603673f5", "width": 480, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0ca30e1ba4144896018ef9ad06cd5c1ee1af1631", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5443e473fc8dd038e2d4db1551248117a2dd94a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dd2_Hd_i58iLbBg1GeR-TcJDkYWZMxJ41XxARTqswsA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2e6fa0ed4bc3b93b0dd7337fae94972f0749362", "width": 320, "height": 213}], "variants": {}, "id": "E1ORrH4Z89_FwFmh3ZN0rWHAhLMpl3i0v1R-nPof3ng"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18slkpq", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18slkpq/building_your_sausage_machine_for_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/building-your-sausage-machine-for", "subreddit_subscribers": 148968, "created_utc": 1703739572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I'm currently a data science graduate student just done with my first semester with a 4gpa but that doesn't matter. I have 2 years of work experience as a data engineer working on Oracle sql, PL/SQL, ODI (Oracle Data Integrator) and almost all the Oracle etl tools, I worked only with star schemas in this company,know dtaat modeling, created ODI packages, mappings, procedures, etc. Crested and modified existing views, triggers, PL/sql packages that are related to pretty important subject areas. There's a lot I've done in just those 2 years. I've also managed a complete data migration project from SQL server to Oracle sql. It was a small Saas company with American clients. \n\nNow, I'm trying to secure an internship in the summer in the USA but to no avail. I'm getting rejected left, right and center. As if my work experience does not matter at all. I know that's not everything but I need more feedback on where I'm going wrong. I'm willing to learn new ETL tools and also am pretty good with Python. Currently I'm working on creating pipelines using python to schedule the data extraction and merge into a table which can be used to create visualizations using that table data (I've not mentioned this in my resume). I have 2 more internships as well and a bachelor's degree in computer science. I have a best paper award from my paper presentation at a conference relating to data analysis and a publication for that paper.\n\nI need to know where I'm lacking. I can't know every ETL tool or process but I'm willing to learn whatever is being used. I am pretty desperate for an internship otherwise I'll be wasting my summer break. I'm on an F1 visa just for more clarity. Willing to share resume on DM as well for a thorough feedback (I'll appreciate this a lot)\n\nTldr: have 2 years of ETL experience but getting rejected for data engineering internships for summer 2024.", "author_fullname": "t2_2odru1hi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Internship Rejections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18se7td", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703718802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;m currently a data science graduate student just done with my first semester with a 4gpa but that doesn&amp;#39;t matter. I have 2 years of work experience as a data engineer working on Oracle sql, PL/SQL, ODI (Oracle Data Integrator) and almost all the Oracle etl tools, I worked only with star schemas in this company,know dtaat modeling, created ODI packages, mappings, procedures, etc. Crested and modified existing views, triggers, PL/sql packages that are related to pretty important subject areas. There&amp;#39;s a lot I&amp;#39;ve done in just those 2 years. I&amp;#39;ve also managed a complete data migration project from SQL server to Oracle sql. It was a small Saas company with American clients. &lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m trying to secure an internship in the summer in the USA but to no avail. I&amp;#39;m getting rejected left, right and center. As if my work experience does not matter at all. I know that&amp;#39;s not everything but I need more feedback on where I&amp;#39;m going wrong. I&amp;#39;m willing to learn new ETL tools and also am pretty good with Python. Currently I&amp;#39;m working on creating pipelines using python to schedule the data extraction and merge into a table which can be used to create visualizations using that table data (I&amp;#39;ve not mentioned this in my resume). I have 2 more internships as well and a bachelor&amp;#39;s degree in computer science. I have a best paper award from my paper presentation at a conference relating to data analysis and a publication for that paper.&lt;/p&gt;\n\n&lt;p&gt;I need to know where I&amp;#39;m lacking. I can&amp;#39;t know every ETL tool or process but I&amp;#39;m willing to learn whatever is being used. I am pretty desperate for an internship otherwise I&amp;#39;ll be wasting my summer break. I&amp;#39;m on an F1 visa just for more clarity. Willing to share resume on DM as well for a thorough feedback (I&amp;#39;ll appreciate this a lot)&lt;/p&gt;\n\n&lt;p&gt;Tldr: have 2 years of ETL experience but getting rejected for data engineering internships for summer 2024.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18se7td", "is_robot_indexable": true, "report_reasons": null, "author": "deathstroke3718", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18se7td/data_engineer_internship_rejections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18se7td/data_engineer_internship_rejections/", "subreddit_subscribers": 148968, "created_utc": 1703718802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're building a project where we have to ingest some csv files, transform them and then store them as parquet with tables built on top of the parquet files.\n\nCurrently the guys are considering an azure databricks based solution. \n\nThe files are not huge, so would another solution that is not built on distributed computing be better for this scenario? What tools would that use, preferably available in the azure cloud.\n\nOr would it be the same thing to run the databricks based solution on a single node cluster in terms of cost?", "author_fullname": "t2_3t7n6f1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a non-distributed (non - spark) alternative to this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s6bf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703698876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re building a project where we have to ingest some csv files, transform them and then store them as parquet with tables built on top of the parquet files.&lt;/p&gt;\n\n&lt;p&gt;Currently the guys are considering an azure databricks based solution. &lt;/p&gt;\n\n&lt;p&gt;The files are not huge, so would another solution that is not built on distributed computing be better for this scenario? What tools would that use, preferably available in the azure cloud.&lt;/p&gt;\n\n&lt;p&gt;Or would it be the same thing to run the databricks based solution on a single node cluster in terms of cost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18s6bf7", "is_robot_indexable": true, "report_reasons": null, "author": "-HumbleBee-", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s6bf7/what_would_be_a_nondistributed_non_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s6bf7/what_would_be_a_nondistributed_non_spark/", "subreddit_subscribers": 148968, "created_utc": 1703698876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im curious to see if anyone knows how carfax gets all of there data  \n\n\ni understand they source it from insurance, state records, inspection agencies, auctions,etc   \n\n\nbut what is the process of finding that information and how can I create a product similar (to carfax)  \n\n\nAny help or insight is greatly appreciated!", "author_fullname": "t2_tz68no1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does carfax get all of its data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s5vnb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703697753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im curious to see if anyone knows how carfax gets all of there data  &lt;/p&gt;\n\n&lt;p&gt;i understand they source it from insurance, state records, inspection agencies, auctions,etc   &lt;/p&gt;\n\n&lt;p&gt;but what is the process of finding that information and how can I create a product similar (to carfax)  &lt;/p&gt;\n\n&lt;p&gt;Any help or insight is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18s5vnb", "is_robot_indexable": true, "report_reasons": null, "author": "TheLordNico", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s5vnb/how_does_carfax_get_all_of_its_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s5vnb/how_does_carfax_get_all_of_its_data/", "subreddit_subscribers": 148968, "created_utc": 1703697753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently looked at AI / LLM / GenAI features that various products offer but none of them seem to actually be good enough / effectively help my day-to-day workflow. Most of the \"explain to me in plain text\" or \"generate SQL from text\" are more gimmicks than anything else.  \n\n\nWhat are some things where you actually feel like as an engineer (not as an analyst) you would benefit from GenAI applications in the data pipeline building workflow?", "author_fullname": "t2_beueng4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI / LLM features that engineers actually need", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s274f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703688099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently looked at AI / LLM / GenAI features that various products offer but none of them seem to actually be good enough / effectively help my day-to-day workflow. Most of the &amp;quot;explain to me in plain text&amp;quot; or &amp;quot;generate SQL from text&amp;quot; are more gimmicks than anything else.  &lt;/p&gt;\n\n&lt;p&gt;What are some things where you actually feel like as an engineer (not as an analyst) you would benefit from GenAI applications in the data pipeline building workflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18s274f", "is_robot_indexable": true, "report_reasons": null, "author": "Thybrat", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s274f/ai_llm_features_that_engineers_actually_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s274f/ai_llm_features_that_engineers_actually_need/", "subreddit_subscribers": 148968, "created_utc": 1703688099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "( Please Forgive any typos or mistakes, typing this after a mini panic attack)\n\nSo, I work in a BIG Financial firm in the states as ITAM ( IT asset management), where I recently got to be part of a team to designing schemas and tools for internal use for the Global ITAM teams, I created the tables and their relation to each other along with rules specific privilege in those tools.  I also helped communicate the LOB's needs to the dev team and provide solutions to accommodate any problems that were raised in this process.  My main job is doing Data quality across the East coast Data centers ( ensuring things are right and nothing has wrong data registered to it ). I also create  reports and provide KPI changes monthly to upper management to measure the progress or state of things.\n\nI've picked interest in Data in general and in particular Data engineering. I went over the IBM Data engineering Certificate from Coursera and basically finished it ( it was easier for me \\~ simpler concepts and I found myself understanding the information rather quickly than expected ).\n\nI then got interested in the Masters program offered by Illinois tech in Data Science and I'm currently doing that part time.I also decided to go and specialize in Microsoft's Azure platform, since I know that it is used within the firm and such, so right now I'm doing the Data engineer one ( DP - 203 )\n\nOn a personal level I am feeling like I'm way far from that goal given the requirements I see in LinkedIn Or Indeed. I am not going through the best financial state rn so thats where I am getting little anxious and just want  if I am doing the right things in terms of the track itself or not ?, from your pov, since I wanna start applying to the jobs after I get my Microsoft cert that way I can have a cert that says I know how to do \" work \" in Azure.  \\~ I found lots of negative words about IBM's Cert.\n\nIf I'm missing something or doing something wrong, What would be your advice to me?\n\n&amp;#x200B;", "author_fullname": "t2_g0zsw8kzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance on What I am doing, Feeling lost/ far away from a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sf7dn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703722581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703721307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;( Please Forgive any typos or mistakes, typing this after a mini panic attack)&lt;/p&gt;\n\n&lt;p&gt;So, I work in a BIG Financial firm in the states as ITAM ( IT asset management), where I recently got to be part of a team to designing schemas and tools for internal use for the Global ITAM teams, I created the tables and their relation to each other along with rules specific privilege in those tools.  I also helped communicate the LOB&amp;#39;s needs to the dev team and provide solutions to accommodate any problems that were raised in this process.  My main job is doing Data quality across the East coast Data centers ( ensuring things are right and nothing has wrong data registered to it ). I also create  reports and provide KPI changes monthly to upper management to measure the progress or state of things.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve picked interest in Data in general and in particular Data engineering. I went over the IBM Data engineering Certificate from Coursera and basically finished it ( it was easier for me ~ simpler concepts and I found myself understanding the information rather quickly than expected ).&lt;/p&gt;\n\n&lt;p&gt;I then got interested in the Masters program offered by Illinois tech in Data Science and I&amp;#39;m currently doing that part time.I also decided to go and specialize in Microsoft&amp;#39;s Azure platform, since I know that it is used within the firm and such, so right now I&amp;#39;m doing the Data engineer one ( DP - 203 )&lt;/p&gt;\n\n&lt;p&gt;On a personal level I am feeling like I&amp;#39;m way far from that goal given the requirements I see in LinkedIn Or Indeed. I am not going through the best financial state rn so thats where I am getting little anxious and just want  if I am doing the right things in terms of the track itself or not ?, from your pov, since I wanna start applying to the jobs after I get my Microsoft cert that way I can have a cert that says I know how to do &amp;quot; work &amp;quot; in Azure.  ~ I found lots of negative words about IBM&amp;#39;s Cert.&lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m missing something or doing something wrong, What would be your advice to me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18sf7dn", "is_robot_indexable": true, "report_reasons": null, "author": "the_wizard_hokage10", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sf7dn/guidance_on_what_i_am_doing_feeling_lost_far_away/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sf7dn/guidance_on_what_i_am_doing_feeling_lost_far_away/", "subreddit_subscribers": 148968, "created_utc": 1703721307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone - I have a sort of unique use case and I wanted to see if anyone has already solved this problem.\n\n&amp;#x200B;\n\nI'm working on building a comprehensive data set about buildings in a particular city. I have a data source to populate and update my data warehouse - for example, if a new building is constructed or the data source updates the size of an existing building, those additions/updates will be captured into the data warehouse when the source is ETL'd next and the changes tracked with SCD2. Pretty straightforward.\n\n&amp;#x200B;\n\nHowever, I have noticed that sometimes the data source is out of date or just incorrect. For example, a newly constructed building might not be entered into the data source for months after it was constructed, or it might have undergone a renovation that has not yet been reported to the data source. Sometimes there are duplicate records. I want to be able to update my internal data warehouse with these changes before they are made in the data source (which sometimes doesn't happen at all).\n\n&amp;#x200B;\n\nSome key things:  \n\n\n1- Typically my solution would be to make sure the data source itself is updated and let the regular ETL pick it up. However, this data source is not owned by me and I have a strong incentive not to provide my \"fixed\" data to the data source.\n\n&amp;#x200B;\n\n2- I'd like to be able to track the changes. I currently track the changes from the data source using the SCD2 pattern, but would like to accommodate the end-user updates in the process as well.\n\n&amp;#x200B;\n\nAny thoughts about this problem? Thanks!", "author_fullname": "t2_3jryuv2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices, pattern(s), or software to allow management (CRUD, merge) of data by end users with other updating sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sc5ip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703713598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - I have a sort of unique use case and I wanted to see if anyone has already solved this problem.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on building a comprehensive data set about buildings in a particular city. I have a data source to populate and update my data warehouse - for example, if a new building is constructed or the data source updates the size of an existing building, those additions/updates will be captured into the data warehouse when the source is ETL&amp;#39;d next and the changes tracked with SCD2. Pretty straightforward.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, I have noticed that sometimes the data source is out of date or just incorrect. For example, a newly constructed building might not be entered into the data source for months after it was constructed, or it might have undergone a renovation that has not yet been reported to the data source. Sometimes there are duplicate records. I want to be able to update my internal data warehouse with these changes before they are made in the data source (which sometimes doesn&amp;#39;t happen at all).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Some key things:  &lt;/p&gt;\n\n&lt;p&gt;1- Typically my solution would be to make sure the data source itself is updated and let the regular ETL pick it up. However, this data source is not owned by me and I have a strong incentive not to provide my &amp;quot;fixed&amp;quot; data to the data source.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2- I&amp;#39;d like to be able to track the changes. I currently track the changes from the data source using the SCD2 pattern, but would like to accommodate the end-user updates in the process as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts about this problem? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18sc5ip", "is_robot_indexable": true, "report_reasons": null, "author": "jsxgd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sc5ip/best_practices_patterns_or_software_to_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sc5ip/best_practices_patterns_or_software_to_allow/", "subreddit_subscribers": 148968, "created_utc": 1703713598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nMy team is scoping some new design patterns for coordinating file/data movement to/from SFTP servers and from API's.  These eventually will get consumed by PySpark/Glue and stored as Parquet in our Data Lake, but we are exploring the best ways to coordinate all of this upstream ingestion.  We have several ideas about patterns that will fit, but I wanted to pulse the community to see if anyone has something we haven't considered or ideas that could help us refine our approaches.\n\nSome background\n\n&amp;#x200B;\n\n* Need to integrate with several things like SFTP, API's for downloading files and also API's that send JSON payloads of data.\n* Have to connect to a few SASS offerings like Hubspot, but some of these are not API's that will be on a marketplace and will need to be custom integrated.\n* In a regulated environment (Healthcare).\n* Current setup is Terraform, AWS Glue, S3, RDS\n\nGeneral patterns we are weighing are:  \n\n\n* Modules in Terraform: We use terraform for IAC on AWS, so modularization of infrastructure using terraform could solve our issues entirely.  However, this requires possibly writing a fair bit of terraform code to coordinate all of this.  Not really an issue, but we'd currently don't have the best practices around deploying and managing Lambdas and other AWS technologies so theres some legwork there to improve our over all patterns.  Not to mention, our general fluency on Terraform isn't amazing right now on the team.\n* Framework like Chalice or Zappa: We have been exploring this possibility more broadly than this use case, so possibly deploying an app on one of these frameworks would allow us to handle the deployment of multiple AWS infrastructure items in an easier way than only leveraging Terraform modules.  Additionally, there are adaptors that translate Chalice to Terraform, so we can leverage our current deployment patterns still.\n* Other options:  Theres a ton of \"SASS\" type solutions for connectors and file movement.  While we aren't super thrilled to possibly pay for another SASS solution, if its monumentally easier to implement we may consider it.  I know tools like Airbyte have an SFTP connector and some other connectors we might need, but we also have some more complicated API's we'd need to integrate with that these types of SASS solutions wont solve for.\n\n&amp;#x200B;\n\nThanks everyone! ", "author_fullname": "t2_3tfgc8z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design patterns for coordinating data from files/API's to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18stkc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703769014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;My team is scoping some new design patterns for coordinating file/data movement to/from SFTP servers and from API&amp;#39;s.  These eventually will get consumed by PySpark/Glue and stored as Parquet in our Data Lake, but we are exploring the best ways to coordinate all of this upstream ingestion.  We have several ideas about patterns that will fit, but I wanted to pulse the community to see if anyone has something we haven&amp;#39;t considered or ideas that could help us refine our approaches.&lt;/p&gt;\n\n&lt;p&gt;Some background&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Need to integrate with several things like SFTP, API&amp;#39;s for downloading files and also API&amp;#39;s that send JSON payloads of data.&lt;/li&gt;\n&lt;li&gt;Have to connect to a few SASS offerings like Hubspot, but some of these are not API&amp;#39;s that will be on a marketplace and will need to be custom integrated.&lt;/li&gt;\n&lt;li&gt;In a regulated environment (Healthcare).&lt;/li&gt;\n&lt;li&gt;Current setup is Terraform, AWS Glue, S3, RDS&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;General patterns we are weighing are:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Modules in Terraform: We use terraform for IAC on AWS, so modularization of infrastructure using terraform could solve our issues entirely.  However, this requires possibly writing a fair bit of terraform code to coordinate all of this.  Not really an issue, but we&amp;#39;d currently don&amp;#39;t have the best practices around deploying and managing Lambdas and other AWS technologies so theres some legwork there to improve our over all patterns.  Not to mention, our general fluency on Terraform isn&amp;#39;t amazing right now on the team.&lt;/li&gt;\n&lt;li&gt;Framework like Chalice or Zappa: We have been exploring this possibility more broadly than this use case, so possibly deploying an app on one of these frameworks would allow us to handle the deployment of multiple AWS infrastructure items in an easier way than only leveraging Terraform modules.  Additionally, there are adaptors that translate Chalice to Terraform, so we can leverage our current deployment patterns still.&lt;/li&gt;\n&lt;li&gt;Other options:  Theres a ton of &amp;quot;SASS&amp;quot; type solutions for connectors and file movement.  While we aren&amp;#39;t super thrilled to possibly pay for another SASS solution, if its monumentally easier to implement we may consider it.  I know tools like Airbyte have an SFTP connector and some other connectors we might need, but we also have some more complicated API&amp;#39;s we&amp;#39;d need to integrate with that these types of SASS solutions wont solve for.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18stkc3", "is_robot_indexable": true, "report_reasons": null, "author": "deepeyesmusic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18stkc3/design_patterns_for_coordinating_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18stkc3/design_patterns_for_coordinating_data_from/", "subreddit_subscribers": 148968, "created_utc": 1703769014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an on-premise Apache Superset 2.1.0, it works in a docker container. It's basically in a PoC stage, where we are trying to assess if Superset is the right fit for our purposes.\n\nOne requirement that we have is to be able to share created dashboards with people without accounts. Someone in the higher management, for example. \n\nIdeally, it would work in a user-friendly way, when dashboard creator can make it public on his own. Without having to provide access to the underlying datasets to a specific role or having us do that for him. Just a simple \"make it public\" kind of a button :)\n\nI've tried multiple things with the help of Google Bard, none of which worked.\n\nI've then tried [this guide](https://github.com/apache/superset/discussions/25299), but it didn't work either. In general, searching for help on Superset is frustrating, because it seems that everyone uses a different version with different options on basically anything.\n\nCan you guys show me the way? How tf do I make these dashboards easily available to people without logins?\n\n*Bonus question: Redis container is a part of the package, but superset init shows that it uses local cache for some reason. Am I doing something wrong here?*", "author_fullname": "t2_6n04s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Superset help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18stjub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703768970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an on-premise Apache Superset 2.1.0, it works in a docker container. It&amp;#39;s basically in a PoC stage, where we are trying to assess if Superset is the right fit for our purposes.&lt;/p&gt;\n\n&lt;p&gt;One requirement that we have is to be able to share created dashboards with people without accounts. Someone in the higher management, for example. &lt;/p&gt;\n\n&lt;p&gt;Ideally, it would work in a user-friendly way, when dashboard creator can make it public on his own. Without having to provide access to the underlying datasets to a specific role or having us do that for him. Just a simple &amp;quot;make it public&amp;quot; kind of a button :)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried multiple things with the help of Google Bard, none of which worked.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve then tried &lt;a href=\"https://github.com/apache/superset/discussions/25299\"&gt;this guide&lt;/a&gt;, but it didn&amp;#39;t work either. In general, searching for help on Superset is frustrating, because it seems that everyone uses a different version with different options on basically anything.&lt;/p&gt;\n\n&lt;p&gt;Can you guys show me the way? How tf do I make these dashboards easily available to people without logins?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Bonus question: Redis container is a part of the package, but superset init shows that it uses local cache for some reason. Am I doing something wrong here?&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?auto=webp&amp;s=26f8bdf747636c8495bbb8c93635125c8c64ae4b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff185993d7cd9a682d80d237fb1645786d1ada7f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=70959835ac078c408d4892ab09cdcf2af256093a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa153c6b5bc8eefb0d907d8722541ecc5e8cb2b5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bced786232bbbf930522136421cd27ac632bd4b5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=df64af16268a4ac0cdde14bcac3afca2057b42a2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hEgqhIbmxNjumxj84yLjyXG9zhd2oxNHwz41c2m2fO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c91fb009ff6f185989c225df09b520b166cf265", "width": 1080, "height": 540}], "variants": {}, "id": "16eJ5hLQsuM8YctxRwpxnWB8Rtb_KGeyMayQ6P0noBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18stjub", "is_robot_indexable": true, "report_reasons": null, "author": "zlobendog", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18stjub/apache_superset_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18stjub/apache_superset_help_needed/", "subreddit_subscribers": 148968, "created_utc": 1703768970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help me finding ny specific book or something else for mathematics used in \nData science.", "author_fullname": "t2_ittm1src", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggest me a book Or anything else for mathematics used in data science please.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18stj5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703768908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help me finding ny specific book or something else for mathematics used in \nData science.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18stj5c", "is_robot_indexable": true, "report_reasons": null, "author": "Aleric_saltsman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18stj5c/suggest_me_a_book_or_anything_else_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18stj5c/suggest_me_a_book_or_anything_else_for/", "subreddit_subscribers": 148968, "created_utc": 1703768908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! \n\nWe are implementing Delta table logic on an on-prem HDFS cluster using Spark for data processing. We append daily partitions to BRONZE layer which contain new records and updates from the previous day. We want to upsert a daily partition from BRONZE to SILVER layer, but it takes an unreasonable amount of time. If we simply append the data to SILVER, the whole ETL process is around 7 minutes (the write iself around 4 minutes) for a daily partition, which contains roughly 1 million rows. If we switch to merge write, then the runtime grows to roughly 30 minutes (read + transform only takes a few minutes, rest is the merge write step). I get that the merge operation is slower because of the join, but I wouldn't expect it to be this slow for only 1 million rows. Keep in mind that these performance tests were done with only a few daily partitions in the tables. We had the same performance when we worked with only one partition in the target table. Do you guys have any idea what we should do to optimize the performance? \n\nThe things we have tried so far without any significant result:\n- Add more resource to the Spark job\n- Run OPTIMIZE command on target table\n- Tried creating the delta tables with explicit and implicit partitioning\n- By default, Spark does a SortMergeJoin at the MERGE step. We coerced other kinds of joins, but SortMergeJoin seemed to be the fastest one\n\nThe merge itself is fairly simple. We merge to the target table using a daily partition from BRONZE (roughly 1 million rows) on one matching ID of string type. If we have a match, we update the whole set (UPDATE SET *), otherwise INSERT *.\nWe will expect a relatively big amount of updates later, but right now we are working with test data which contains a couple of updates maximum per daily batch.", "author_fullname": "t2_vun99h9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge very slow for small amount of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sr2k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703760102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;We are implementing Delta table logic on an on-prem HDFS cluster using Spark for data processing. We append daily partitions to BRONZE layer which contain new records and updates from the previous day. We want to upsert a daily partition from BRONZE to SILVER layer, but it takes an unreasonable amount of time. If we simply append the data to SILVER, the whole ETL process is around 7 minutes (the write iself around 4 minutes) for a daily partition, which contains roughly 1 million rows. If we switch to merge write, then the runtime grows to roughly 30 minutes (read + transform only takes a few minutes, rest is the merge write step). I get that the merge operation is slower because of the join, but I wouldn&amp;#39;t expect it to be this slow for only 1 million rows. Keep in mind that these performance tests were done with only a few daily partitions in the tables. We had the same performance when we worked with only one partition in the target table. Do you guys have any idea what we should do to optimize the performance? &lt;/p&gt;\n\n&lt;p&gt;The things we have tried so far without any significant result:\n- Add more resource to the Spark job\n- Run OPTIMIZE command on target table\n- Tried creating the delta tables with explicit and implicit partitioning\n- By default, Spark does a SortMergeJoin at the MERGE step. We coerced other kinds of joins, but SortMergeJoin seemed to be the fastest one&lt;/p&gt;\n\n&lt;p&gt;The merge itself is fairly simple. We merge to the target table using a daily partition from BRONZE (roughly 1 million rows) on one matching ID of string type. If we have a match, we update the whole set (UPDATE SET *), otherwise INSERT *.\nWe will expect a relatively big amount of updates later, but right now we are working with test data which contains a couple of updates maximum per daily batch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18sr2k6", "is_robot_indexable": true, "report_reasons": null, "author": "justadataengineer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sr2k6/delta_merge_very_slow_for_small_amount_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sr2k6/delta_merge_very_slow_for_small_amount_of_data/", "subreddit_subscribers": 148968, "created_utc": 1703760102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6en6384s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "$200 OFF on Coursera Plus Annual Subscription - New Year Event", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18sp79d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5LgY9EZo13c?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"$200 OFF on Coursera Plus Annual Subscription - New Year Event\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "$200 OFF on Coursera Plus Annual Subscription - New Year Event", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5LgY9EZo13c?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"$200 OFF on Coursera Plus Annual Subscription - New Year Event\"&gt;&lt;/iframe&gt;", "author_name": "Fixing Tiny Tedious Things!", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/5LgY9EZo13c/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@topitguy"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5LgY9EZo13c?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"$200 OFF on Coursera Plus Annual Subscription - New Year Event\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18sp79d", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AUdguMStRVcF90A0QMCj0-NVjaCIdh9gQtk4V49Dzvw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703752668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/5LgY9EZo13c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xgw-thDSv9_3U7sLJZINtHS3sI-gKHCRuGCvo1IDMto.jpg?auto=webp&amp;s=b100ac844686df7a2b923c43658310c2e197d1a0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/xgw-thDSv9_3U7sLJZINtHS3sI-gKHCRuGCvo1IDMto.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8259791e3409d3e79568a6ae5ffc1d8094985b77", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/xgw-thDSv9_3U7sLJZINtHS3sI-gKHCRuGCvo1IDMto.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f0f25139033d5ad980da76bab01344fc883fe58", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/xgw-thDSv9_3U7sLJZINtHS3sI-gKHCRuGCvo1IDMto.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=449c44522794c29b17b9b3311e721726adf3081a", "width": 320, "height": 240}], "variants": {}, "id": "99YRBpzr0bo7rg2iTCKJu-vh7cWuVH2EM72BvEYCKRM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18sp79d", "is_robot_indexable": true, "report_reasons": null, "author": "ampankajsharma", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sp79d/200_off_on_coursera_plus_annual_subscription_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/5LgY9EZo13c", "subreddit_subscribers": 148968, "created_utc": 1703752668.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "$200 OFF on Coursera Plus Annual Subscription - New Year Event", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5LgY9EZo13c?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"$200 OFF on Coursera Plus Annual Subscription - New Year Event\"&gt;&lt;/iframe&gt;", "author_name": "Fixing Tiny Tedious Things!", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/5LgY9EZo13c/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@topitguy"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am a fresher  in a MNC.  as you all know MNCs give random domains to freshers! \nI got QEA Automation Testing with Selenium Java. Few people say that is a good domain! \nBut I want to upgrade myself and switch to Data Engineering. \nWhat things should I start learning? \nI already have knowledge in Python and SQL, I'm studying NoSQL. \nPlease let me know what are the other things I need to learn and from where..\nAnd also how I can present my learning to my POCs so that they consider me as a fit for the role.", "author_fullname": "t2_dh8pk5g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18snda3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703745612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am a fresher  in a MNC.  as you all know MNCs give random domains to freshers! \nI got QEA Automation Testing with Selenium Java. Few people say that is a good domain! \nBut I want to upgrade myself and switch to Data Engineering. \nWhat things should I start learning? \nI already have knowledge in Python and SQL, I&amp;#39;m studying NoSQL. \nPlease let me know what are the other things I need to learn and from where..\nAnd also how I can present my learning to my POCs so that they consider me as a fit for the role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18snda3", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveCat2133", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18snda3/switch_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18snda3/switch_to_data_engineering/", "subreddit_subscribers": 148968, "created_utc": 1703745612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don\u2019t have experience in the field of data management, but as a data analyst who wants to be more involved in data management this certificate could boost me up and be beneficial to me. I really hope to get your advice on how to study and prepare for the exam based on your experiences.", "author_fullname": "t2_abkn5l5p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any advice Regarding CDMP Certificate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18s4asg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703693756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t have experience in the field of data management, but as a data analyst who wants to be more involved in data management this certificate could boost me up and be beneficial to me. I really hope to get your advice on how to study and prepare for the exam based on your experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18s4asg", "is_robot_indexable": true, "report_reasons": null, "author": "DelayAccomplished679", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18s4asg/any_advice_regarding_cdmp_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18s4asg/any_advice_regarding_cdmp_certificate/", "subreddit_subscribers": 148968, "created_utc": 1703693756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to this, I was checking the certification and it is asking for company email?", "author_fullname": "t2_153hv15z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can u get databricks lakehouse fundamentals if you are not working for a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ssp71", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703766158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to this, I was checking the certification and it is asking for company email?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ssp71", "is_robot_indexable": true, "report_reasons": null, "author": "hayleybts", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ssp71/can_u_get_databricks_lakehouse_fundamentals_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ssp71/can_u_get_databricks_lakehouse_fundamentals_if/", "subreddit_subscribers": 148968, "created_utc": 1703766158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a PMP (Project Management Professional) from a previous professional career. I know that it is meaningless in tech and anyone who has a PMP will tell you what a joke it is and that forcing new employees to get their PMP is often used as a hazing ritual. However, the company that sponsors the cert spends a lot of money on marketing and thus a PMP is held is very high esteem by traditional boomer management and by recruiters.  \n\nShould I put my PMP on my resume? I am in DE now and just looking to change companies.", "author_fullname": "t2_o1c691xd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Put PMP on resume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18sslei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703765803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PMP (Project Management Professional) from a previous professional career. I know that it is meaningless in tech and anyone who has a PMP will tell you what a joke it is and that forcing new employees to get their PMP is often used as a hazing ritual. However, the company that sponsors the cert spends a lot of money on marketing and thus a PMP is held is very high esteem by traditional boomer management and by recruiters.  &lt;/p&gt;\n\n&lt;p&gt;Should I put my PMP on my resume? I am in DE now and just looking to change companies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18sslei", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive-One6226", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18sslei/put_pmp_on_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18sslei/put_pmp_on_resume/", "subreddit_subscribers": 148968, "created_utc": 1703765803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productionizing Jupyter Notebooks with Versatile Data Kit (VDK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_18srpzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hGxnGSA7jk4a0Y_ztroxbp7mbXKk89XC3eZ3AzKzKSM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703762624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/versatile-data-kit/productionizing-jupyter-notebooks-with-versatile-data-kit-vdk-ec5824d31b77", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?auto=webp&amp;s=2e8caf5a2c4797cf40de240469a67f9b1cc0c60a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=53300dee93c4fc589e35b1d090234f8a0fc99fb8", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b580813ab95367b6df0eaf65e67a79c5b6733499", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6672fe6cff422da5f0e99c9fdd082c1340c8ed0f", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00fcee8da15e51419025aceb9f9deb393a26733f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8582180f9e5a9a40f69ffc30807137488c47653f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/5h4o3ZdEzAcNlfPHCi-d05lnlhPRRLPoekJDhz8Jjj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ee64fb2fad82d0c86d9200d4c3d13d7dab58b4ac", "width": 1080, "height": 720}], "variants": {}, "id": "TBVSJ3r1aaIX6zc3PW78ubLcDKNcOqTRDgaSGqozetw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18srpzd", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18srpzd/productionizing_jupyter_notebooks_with_versatile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/versatile-data-kit/productionizing-jupyter-notebooks-with-versatile-data-kit-vdk-ec5824d31b77", "subreddit_subscribers": 148968, "created_utc": 1703762624.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}