{"kind": "Listing", "data": {"after": "t3_18lzawl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!\n\n[https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra\\_5PGH&amp;index=6&amp;t=689s](https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=6&amp;t=689s)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a crash course on Polars library of Python (Great library for working with big data) and uploaded it on Youtube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lsb9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=6&amp;amp;t=689s\"&gt;https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=6&amp;amp;t=689s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?auto=webp&amp;s=7297230f4639915c7e57af7b9a255708da17bfa9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=784a54eeca77266e76144dcc7477cdae8da54cbb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76e755d0518dfef7107139a615d64e1857715e31", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcd0428c65436c58727868ae2eae5a9b4a6d541d", "width": 320, "height": 240}], "variants": {}, "id": "_rVKQNaxcPqL1qZYn-JkINnf7oHCvdPuQq4k6I3ej4A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18lsb9p", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lsb9p/i_recorded_a_crash_course_on_polars_library_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lsb9p/i_recorded_a_crash_course_on_polars_library_of/", "subreddit_subscribers": 147001, "created_utc": 1702957460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throwaway because I know they are sometime on Reddit.\n\nMy boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.\n\nIt ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:\n\n- checking the SQL queries of my colleagues;\n- they want to know if this or that has been documented for tiny operations;\n- they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time\n\nI am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.\n\nThis is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?", "author_fullname": "t2_qa5f09pa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non-technical boss, wanting to micromanage and kills our team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m4e2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702999366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throwaway because I know they are sometime on Reddit.&lt;/p&gt;\n\n&lt;p&gt;My boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.&lt;/p&gt;\n\n&lt;p&gt;It ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;checking the SQL queries of my colleagues;&lt;/li&gt;\n&lt;li&gt;they want to know if this or that has been documented for tiny operations;&lt;/li&gt;\n&lt;li&gt;they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.&lt;/p&gt;\n\n&lt;p&gt;This is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18m4e2i", "is_robot_indexable": true, "report_reasons": null, "author": "SuperMarioDataGalaxy", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "subreddit_subscribers": 147001, "created_utc": 1702999366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, Right now I am working on a project that needs Databricks and BI experience. Can you guys suggest some real time experience courses for both Databricks and Power BI", "author_fullname": "t2_nlmrmy2ow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best course for Databricks and BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lhjsr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702928583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Right now I am working on a project that needs Databricks and BI experience. Can you guys suggest some real time experience courses for both Databricks and Power BI&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18lhjsr", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Koala_609", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lhjsr/best_course_for_databricks_and_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lhjsr/best_course_for_databricks_and_bi/", "subreddit_subscribers": 147001, "created_utc": 1702928583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recap of 2023's Transformative Data Landscape", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_18luokv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QC-u87qQqiWYhhkIC7zp7h8awQeZx1F8z1WVloZ5my4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702965072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?auto=webp&amp;s=05cf70f29567b297be9005cc1fe6c52634c548d1", "width": 852, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8235b4ab19fc2ff32de42dcad115918f2e142ea", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac56b2d2c72cfcf52f1d78a8b06cc0971bef6d20", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d507577ef1336581efee9304ad98a549d20d63fe", "width": 320, "height": 225}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e89944c98598044365a90f48cd565f877fa7541c", "width": 640, "height": 450}], "variants": {}, "id": "bU0KynVYqdS53QNQHO7TTIr2Kuty1FCLaOXHnUOQcI0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18luokv", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18luokv/recap_of_2023s_transformative_data_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "subreddit_subscribers": 147001, "created_utc": 1702965072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New video \ud83e\udd73 What's new in Apache Airflow 2.8?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18m30x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18m30x1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W9gW-x75UmKzyC9I0b799PZ2OnmHhIBK7_zD9y5N684.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702995743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/M9qyj5Dszks", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?auto=webp&amp;s=14111aa6adfeb2c33ce6f5e60e93b26adf640e3d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4cfe605ca8eda8a8d053c6cebb0db4699467a79", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2161187bfb9511953e9b866e0bcbd6fd0319ee77", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e1acd7c824946fbb87246bb66219af8fd5f6d8", "width": 320, "height": 240}], "variants": {}, "id": "Sn7V-8gShoAirVVII0LH7BwleF0omtwue3ruXwusF2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18m30x1", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m30x1/new_video_whats_new_in_apache_airflow_28/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/M9qyj5Dszks", "subreddit_subscribers": 147001, "created_utc": 1702995743.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am looking to switch my career and move into DE. \n\nI've only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. \n\nThere's still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.\n\nWhat are some red flags that when you see in a job offer you're like \"This company has no structure / it needs three different people for that role / etc.\"?\n\nI am looking for ways to weed out those offers that I shouldn't be using as a baseline for gathering my skills.\n\nThanks.", "author_fullname": "t2_7xz6r2in", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Red flags in DE job offers (beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m14z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702990200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking to switch my career and move into DE. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.&lt;/p&gt;\n\n&lt;p&gt;What are some red flags that when you see in a job offer you&amp;#39;re like &amp;quot;This company has no structure / it needs three different people for that role / etc.&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;I am looking for ways to weed out those offers that I shouldn&amp;#39;t be using as a baseline for gathering my skills.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18m14z5", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent-Drink-235", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "subreddit_subscribers": 147001, "created_utc": 1702990200.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?", "author_fullname": "t2_dxt8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting new records/changes: timestamp vs ingest I\u2019d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m00kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702986364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m00kd", "is_robot_indexable": true, "report_reasons": null, "author": "pokepip", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "subreddit_subscribers": 147001, "created_utc": 1702986364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why storage and compute can't be separated for an OLTP database?", "author_fullname": "t2_fulplt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLTP vs OLAP databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lyljw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702980821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why storage and compute can&amp;#39;t be separated for an OLTP database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lyljw", "is_robot_indexable": true, "report_reasons": null, "author": "ankit_goyal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "subreddit_subscribers": 147001, "created_utc": 1702980821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why is the cost for hightouch so high? Are there cheaper options? I am trying to figure out how to lower cost. Is Rudderstack a better solution?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hightouch Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lmjjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702941056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is the cost for hightouch so high? Are there cheaper options? I am trying to figure out how to lower cost. Is Rudderstack a better solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lmjjz", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lmjjz/hightouch_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lmjjz/hightouch_cost/", "subreddit_subscribers": 147001, "created_utc": 1702941056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack](https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack)\n\nWe open sourced PG Slot Notify, a tool we've been actively using to monitor replication slot size and alert us when there are abnormalities.\n\nIf you have Postgres databases with replication slots, this tool would come very handy!! It involves 5 mins of setup time and you should be good to go!", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PG Slot Notify: Monitor Postgres Replication Slot Growth in Slack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ll3w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702937409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack\"&gt;https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We open sourced PG Slot Notify, a tool we&amp;#39;ve been actively using to monitor replication slot size and alert us when there are abnormalities.&lt;/p&gt;\n\n&lt;p&gt;If you have Postgres databases with replication slots, this tool would come very handy!! It involves 5 mins of setup time and you should be good to go!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?auto=webp&amp;s=f2c640396c48ee4e87e81497df05c6f09b0481db", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=584fe42ee441fed66d044e42f0bc778750228572", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83938a1b51284fa54354b4819bd85c7322d70795", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a53d612801375bd9e1406e912037e2df91c2803", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f42ba9b2be0e2be031475dd9c3d9c7bcaf856525", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fecc1bf0eed3569e71cb61e79f62d243659df902", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a06cbf070c88c8326046b408d2c5be8c1af54614", "width": 1080, "height": 567}], "variants": {}, "id": "CXHCBuyAiQklJzG9M75ycT_nl9F2gQjEziJ40F9-sp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18ll3w9", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ll3w9/pg_slot_notify_monitor_postgres_replication_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ll3w9/pg_slot_notify_monitor_postgres_replication_slot/", "subreddit_subscribers": 147001, "created_utc": 1702937409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expedia Uses WebSockets and Kafka to Query Near Real-Time Streaming Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18lz0me", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_-95beDt0eTU61sjw3MyytCoW7zyk-9mjFOz5cqSkbM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702982547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?auto=webp&amp;s=22be1127b3a032c0428d4bee24b8d2cb2a2233c0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74b528758f8dac132781b7ba52cec3194953941b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b5018e5a478380623b37087dbf9dc4b43bbf70c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1b372ee2d8ab5031fb9f92e22e20238371990e25", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec9e2d3c657a70106b4608c93841f75070af8d79", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3de9be364444c886057dff0f382a0ea14630cb01", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7820fff738d4f7d7dcf3a548b2e8c36161176b6", "width": 1080, "height": 567}], "variants": {}, "id": "BmdzDPEbzLW9dI8d-7eePz_SJf3gyF91hmqD-LM6Od4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18lz0me", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lz0me/expedia_uses_websockets_and_kafka_to_query_near/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "subreddit_subscribers": 147001, "created_utc": 1702982547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some advice on best approach/ practise.\n\nBackground :\n\nIm a data analyst working in a team. Breakdown of our reporting flows are :\n\n1. We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.\n\nProblem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. \n\n2. We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. \n\nThis tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. \n\nAnd when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.\n\nSo the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? \n\nMy concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?\n\nAs for to just use no.2 approach, im not sure if pyspark can do exactly what we're doing in no.1 since we lack of the exposure. \n\nSorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.", "author_fullname": "t2_7nk0x7fc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m0x3c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702989497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some advice on best approach/ practise.&lt;/p&gt;\n\n&lt;p&gt;Background :&lt;/p&gt;\n\n&lt;p&gt;Im a data analyst working in a team. Breakdown of our reporting flows are :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Problem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. &lt;/p&gt;\n\n&lt;p&gt;And when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.&lt;/p&gt;\n\n&lt;p&gt;So the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? &lt;/p&gt;\n\n&lt;p&gt;My concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?&lt;/p&gt;\n\n&lt;p&gt;As for to just use no.2 approach, im not sure if pyspark can do exactly what we&amp;#39;re doing in no.1 since we lack of the exposure. &lt;/p&gt;\n\n&lt;p&gt;Sorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m0x3c", "is_robot_indexable": true, "report_reasons": null, "author": "Nopal97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m0x3c/advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m0x3c/advice_needed/", "subreddit_subscribers": 147001, "created_utc": 1702989497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was just wondering what do you think of this DE internship :   \n\n&amp;#x200B;\n\nWhat you will do:\n\n* Work closely with several stakeholders such as CRM, and Customer Support to understand their needs and challenges.\n* Integrate relevant data sources that contain user information and campaign data\n* Design ETL data pipeline for cleansing, enriching, and structuring the data for analysis\n* Develop a user-friendly reporting tool for accessing and interpreting the reason behind the non-delivery of CRM campaigns\n* Improve the code base to optimize the cost of our cloud computing resources\n* Ensure that all the code written is high quality, scalable, and testable\n* Develop, test, and maintain big-data scripts that generate the datasets used by Customer and Monetization tools\n* Work closely with the whole team to achieve company objectives\n\n**Qualifications**\n\nThis role is excellent for a person with:\n\n* You are currently enrolled in your last year or have just graduated with a Master\u2019s Degree in Software Engineering, Data Science, or a related technical field\n* Passion for Software Engineering and/or data analysis\n* Experience in SQL and Python programming\n* Experience using a visualization tool (Looker Studio, Tableau, Power BI, or similar)\n* Curious: Being ready to tackle complex problems with insights and analyses at the crossroads of tech, product, data, and business\n* Fluent working in French &amp; English\n\nSkills that we value:\n\n* Eager to learn new programming languages and Big data frameworks\n* Experience with one of the following Big data tools is a plus: BigQuery, Scala, Hadoop, Spark, Elasticsearch\n* Good communication skills and the capacity to adapt to non-technical interlocutors\n* At ease in teamwork, familiar with agile methodology and pair-programming ", "author_fullname": "t2_6jwsskq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good 6 Months Internship ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18m7hzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703007299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was just wondering what do you think of this DE internship :   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What you will do:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Work closely with several stakeholders such as CRM, and Customer Support to understand their needs and challenges.&lt;/li&gt;\n&lt;li&gt;Integrate relevant data sources that contain user information and campaign data&lt;/li&gt;\n&lt;li&gt;Design ETL data pipeline for cleansing, enriching, and structuring the data for analysis&lt;/li&gt;\n&lt;li&gt;Develop a user-friendly reporting tool for accessing and interpreting the reason behind the non-delivery of CRM campaigns&lt;/li&gt;\n&lt;li&gt;Improve the code base to optimize the cost of our cloud computing resources&lt;/li&gt;\n&lt;li&gt;Ensure that all the code written is high quality, scalable, and testable&lt;/li&gt;\n&lt;li&gt;Develop, test, and maintain big-data scripts that generate the datasets used by Customer and Monetization tools&lt;/li&gt;\n&lt;li&gt;Work closely with the whole team to achieve company objectives&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Qualifications&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This role is excellent for a person with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You are currently enrolled in your last year or have just graduated with a Master\u2019s Degree in Software Engineering, Data Science, or a related technical field&lt;/li&gt;\n&lt;li&gt;Passion for Software Engineering and/or data analysis&lt;/li&gt;\n&lt;li&gt;Experience in SQL and Python programming&lt;/li&gt;\n&lt;li&gt;Experience using a visualization tool (Looker Studio, Tableau, Power BI, or similar)&lt;/li&gt;\n&lt;li&gt;Curious: Being ready to tackle complex problems with insights and analyses at the crossroads of tech, product, data, and business&lt;/li&gt;\n&lt;li&gt;Fluent working in French &amp;amp; English&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Skills that we value:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Eager to learn new programming languages and Big data frameworks&lt;/li&gt;\n&lt;li&gt;Experience with one of the following Big data tools is a plus: BigQuery, Scala, Hadoop, Spark, Elasticsearch&lt;/li&gt;\n&lt;li&gt;Good communication skills and the capacity to adapt to non-technical interlocutors&lt;/li&gt;\n&lt;li&gt;At ease in teamwork, familiar with agile methodology and pair-programming &lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m7hzm", "is_robot_indexable": true, "report_reasons": null, "author": "Slow_Low206", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m7hzm/is_this_a_good_6_months_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m7hzm/is_this_a_good_6_months_internship/", "subreddit_subscribers": 147001, "created_utc": 1703007299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this tutorial, we share an approach to web scraping that leverages a distributed cloud network with thousands of residential gaming PCs. \n\nYou can read the tutorial here: [**https://substack.thewebscraping.club/p/web-dragon-llm-powered-web-scraping**](https://substack.thewebscraping.club/p/web-dragon-llm-powered-web-scraping) \n\nBut why do this? \n\nThe AI boom and the resulting increase &amp; importance of web scraping has two challenges: \n\n\\- Website technology preventing automatic extraction\n\n\\- Website changes breaking manually coded screapers\n\nThe nature of a distributed network offers solutions to both of the main challenges faced by scrapers. \n\nIn this tutorial, we use SaladCloud but there are also other distributed cloud networks for you to choose from.\n\nSince every Salad node is an actual residential computer, loading a page from these nodes ***looks*** like legitimate human traffic to most websites, and is much less likely to get blocked. \n\nAdditionally, these gaming PCs have GPUs capable of running modern Large Language Models(LLMs), providing a potentially much more flexible and resilient option for parsing website content. \n\n## Key Takeaways \n\n* Actually accessing page content was extremely easy on a distributed cloud, with more than 99% of pages viewed successfully within 2 tries. Just as we humans are occasionally presented with CAPTCHAs, our crawlers also ran into CAPTCHAs from time to time. We dealt with this by retrying the URL with a different queue worker (and therefore a different IP in a different location). \n* Once the boilerplate is set up, the process of writing the data extraction layer is a lot simpler and more intuitive than traditional web-scraping techniques, consisting mostly of asking natural language questions. It\u2019s easy to imagine giving this framework a simple web interface that would allow the creation of custom web scrapers with no coding knowledge required at all.\n* LLM\u2019s are not a magic bullet for the problems faced by Web Scraping. Prompts that work reliably with one website may not work very well at all with another site. You\u2019re still going to do some per-site customization.\n* Setting up a proof-of-concept RAG application is pretty straightforward with off-the-shelf open-source tools. As is the case for most software, developing that proof-of-concept into something production-ready is non-trivial.\n* There are a lot of choices to make, knobs to adjust, variables to tweak in using the LLM approach to data extraction. There\u2019s going to be a significant amount of experimentation involved in reliably getting the results you want. Everything from what models to use, how to split your webpage into chunks, and how you write your prompts can have a major impact on both the efficiency and accuracy of data extraction.\n* Using LLMs and Vector Databases is much more computationally intensive than traditional methods of web scraping, which rely on highly efficient HTML selectors and other low-cost text processing techniques. In our test run with [Harrods.com](http://harrods.com/), each page took about 9s to process on an RTX 3080 Ti, yielding a JSON object like this:\n\n&amp;#8203;\n\n    {   \"name\": \"Moncler 999 x adidas Originals NMD Padded Boots\",   \"manufacturer\": \"Moncler, adidas Originals\",   \"price\": 637,   \"currency\": \"USD\",   \"description\": \"The Moncler x adidas Originals NMD Padded Boots are a collaboration between the two renowned brands. These boots are designed with a focus on functionality and style, featuring a unique combination of materials. The lining is made of other materials, providing added comfort and warmth, while the sole is also crafted from other materials. These boots are currently available for personal shopping and in-store purchase only, as they are not currently available for online purchase.\",   \"is_available_online\": false }\n\n* Whether this technique is worth the extra computational cost will depend a lot on your particular use case. At scale, it\u2019s likely that your savings in engineering time would significantly outweigh the additional costs from computing, especially given Salad\u2019s low costs compared to traditional clouds.\n* The LLM space is developing at a breakneck pace. It\u2019s possible (likely even) that by the time you\u2019re reading this article, none of the models I\u2019ve chosen are still considered state-of-the-art. The good news is that open-source inference servers like [\ud83e\udd17Text Embeddings Inference](https://huggingface.co/docs/text-embeddings-inference/index) and [\ud83e\udd17Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index) make it very easy to try out new models without changing the rest of your code, each requiring only a single environment variable (MODEL\\_ID  \n) to configure models from Huggingface Hub.\n\nYou can try it yourself here: [www.salad.com](https://www.salad.com)", "author_fullname": "t2_2ju1icfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM-powered web scraping with 1000s of residential gaming PCs on a distributed cloud [Tutorial with Workflow included]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m1v88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702992462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this tutorial, we share an approach to web scraping that leverages a distributed cloud network with thousands of residential gaming PCs. &lt;/p&gt;\n\n&lt;p&gt;You can read the tutorial here: &lt;a href=\"https://substack.thewebscraping.club/p/web-dragon-llm-powered-web-scraping\"&gt;&lt;strong&gt;https://substack.thewebscraping.club/p/web-dragon-llm-powered-web-scraping&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;But why do this? &lt;/p&gt;\n\n&lt;p&gt;The AI boom and the resulting increase &amp;amp; importance of web scraping has two challenges: &lt;/p&gt;\n\n&lt;p&gt;- Website technology preventing automatic extraction&lt;/p&gt;\n\n&lt;p&gt;- Website changes breaking manually coded screapers&lt;/p&gt;\n\n&lt;p&gt;The nature of a distributed network offers solutions to both of the main challenges faced by scrapers. &lt;/p&gt;\n\n&lt;p&gt;In this tutorial, we use SaladCloud but there are also other distributed cloud networks for you to choose from.&lt;/p&gt;\n\n&lt;p&gt;Since every Salad node is an actual residential computer, loading a page from these nodes &lt;strong&gt;&lt;em&gt;looks&lt;/em&gt;&lt;/strong&gt; like legitimate human traffic to most websites, and is much less likely to get blocked. &lt;/p&gt;\n\n&lt;p&gt;Additionally, these gaming PCs have GPUs capable of running modern Large Language Models(LLMs), providing a potentially much more flexible and resilient option for parsing website content. &lt;/p&gt;\n\n&lt;h2&gt;Key Takeaways&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Actually accessing page content was extremely easy on a distributed cloud, with more than 99% of pages viewed successfully within 2 tries. Just as we humans are occasionally presented with CAPTCHAs, our crawlers also ran into CAPTCHAs from time to time. We dealt with this by retrying the URL with a different queue worker (and therefore a different IP in a different location). &lt;/li&gt;\n&lt;li&gt;Once the boilerplate is set up, the process of writing the data extraction layer is a lot simpler and more intuitive than traditional web-scraping techniques, consisting mostly of asking natural language questions. It\u2019s easy to imagine giving this framework a simple web interface that would allow the creation of custom web scrapers with no coding knowledge required at all.&lt;/li&gt;\n&lt;li&gt;LLM\u2019s are not a magic bullet for the problems faced by Web Scraping. Prompts that work reliably with one website may not work very well at all with another site. You\u2019re still going to do some per-site customization.&lt;/li&gt;\n&lt;li&gt;Setting up a proof-of-concept RAG application is pretty straightforward with off-the-shelf open-source tools. As is the case for most software, developing that proof-of-concept into something production-ready is non-trivial.&lt;/li&gt;\n&lt;li&gt;There are a lot of choices to make, knobs to adjust, variables to tweak in using the LLM approach to data extraction. There\u2019s going to be a significant amount of experimentation involved in reliably getting the results you want. Everything from what models to use, how to split your webpage into chunks, and how you write your prompts can have a major impact on both the efficiency and accuracy of data extraction.&lt;/li&gt;\n&lt;li&gt;Using LLMs and Vector Databases is much more computationally intensive than traditional methods of web scraping, which rely on highly efficient HTML selectors and other low-cost text processing techniques. In our test run with &lt;a href=\"http://harrods.com/\"&gt;Harrods.com&lt;/a&gt;, each page took about 9s to process on an RTX 3080 Ti, yielding a JSON object like this:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#8203;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{   &amp;quot;name&amp;quot;: &amp;quot;Moncler 999 x adidas Originals NMD Padded Boots&amp;quot;,   &amp;quot;manufacturer&amp;quot;: &amp;quot;Moncler, adidas Originals&amp;quot;,   &amp;quot;price&amp;quot;: 637,   &amp;quot;currency&amp;quot;: &amp;quot;USD&amp;quot;,   &amp;quot;description&amp;quot;: &amp;quot;The Moncler x adidas Originals NMD Padded Boots are a collaboration between the two renowned brands. These boots are designed with a focus on functionality and style, featuring a unique combination of materials. The lining is made of other materials, providing added comfort and warmth, while the sole is also crafted from other materials. These boots are currently available for personal shopping and in-store purchase only, as they are not currently available for online purchase.&amp;quot;,   &amp;quot;is_available_online&amp;quot;: false }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Whether this technique is worth the extra computational cost will depend a lot on your particular use case. At scale, it\u2019s likely that your savings in engineering time would significantly outweigh the additional costs from computing, especially given Salad\u2019s low costs compared to traditional clouds.&lt;/li&gt;\n&lt;li&gt;The LLM space is developing at a breakneck pace. It\u2019s possible (likely even) that by the time you\u2019re reading this article, none of the models I\u2019ve chosen are still considered state-of-the-art. The good news is that open-source inference servers like &lt;a href=\"https://huggingface.co/docs/text-embeddings-inference/index\"&gt;\ud83e\udd17Text Embeddings Inference&lt;/a&gt; and &lt;a href=\"https://huggingface.co/docs/text-generation-inference/index\"&gt;\ud83e\udd17Text Generation Inference&lt;/a&gt; make it very easy to try out new models without changing the rest of your code, each requiring only a single environment variable (MODEL_ID&lt;br/&gt;\n) to configure models from Huggingface Hub.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can try it yourself here: &lt;a href=\"https://www.salad.com\"&gt;www.salad.com&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?auto=webp&amp;s=a034b88769582cf9f063a2ade2be0ea3ad4624f9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=394162b253cd95a1f26a3d9165d0c3c4d7171de7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff9a546836814d89b09482b7bc1defcea8067339", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=401cc6c5f7d41ba533dbcf05406a34f434a24169", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eb56830ef1ebb4173f88cbbe5548c26943d8c26e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8fec7f1d5728157a5c0cba7b7394c0590274ffb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Nq9QnvdZOrmmnPIPwCcUYYGq3yIvf7RQpKmgZSZegBs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f0b90e8ac6cf3e94f212088ef0b0d2e71a9f6977", "width": 1080, "height": 540}], "variants": {}, "id": "msV-zSy9fohwGXKfs_vyRiEzzu8VT8oE-Ix3N9KdV88"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18m1v88", "is_robot_indexable": true, "report_reasons": null, "author": "SaladChefs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m1v88/llmpowered_web_scraping_with_1000s_of_residential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m1v88/llmpowered_web_scraping_with_1000s_of_residential/", "subreddit_subscribers": 147001, "created_utc": 1702992462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dose hosting the system on your environment will change the source you\u2019re reading from? \n\nFor example System x is hosted now on the provider side, if the IT said we need to host it on our environment, dose that means the data source in fivetran connector have to be changed? I\u2019m I gonna establish a connector to my own environment rather that to x system? \n\ni\u2019m not familiar to cloud however I assume no need to do that it sounds weird.. however I heard people here say they have to \ud83e\udd14", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting the tool on your environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ltbyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702960586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dose hosting the system on your environment will change the source you\u2019re reading from? &lt;/p&gt;\n\n&lt;p&gt;For example System x is hosted now on the provider side, if the IT said we need to host it on our environment, dose that means the data source in fivetran connector have to be changed? I\u2019m I gonna establish a connector to my own environment rather that to x system? &lt;/p&gt;\n\n&lt;p&gt;i\u2019m not familiar to cloud however I assume no need to do that it sounds weird.. however I heard people here say they have to \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ltbyp", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ltbyp/hosting_the_tool_on_your_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ltbyp/hosting_the_tool_on_your_environment/", "subreddit_subscribers": 147001, "created_utc": 1702960586.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, my company is in the process of evaluating a new data platform (think DWH, DL, LH), they've asked for me to help, and it's clear they haven't thought this through much (both the type of architecture they want and how to structure an evaluation). I'm not looking for specific product recommendations, but advice on the process you go through to make a decision and not just wander in circles doing trials and POCs for the next 18 months. \n\nHere are some of the specific questions I have, but I'm all ears for other advice too:\n\n* Do you prefer trials that are fully-managed or self-managed? What are the pros/cons to each? When products have both, how do I choose? \n* When you first trial a piece of data infra, what do you focus on in the first 30-60min?\n\nI'm thinking mostly about the beginning of the evaluation right now since we're just starting, so advice on that stage would be most helpful. Thanks!\n\n&amp;#x200B;", "author_fullname": "t2_vad5s0up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips for Evaluating new data platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lj7yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702932727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, my company is in the process of evaluating a new data platform (think DWH, DL, LH), they&amp;#39;ve asked for me to help, and it&amp;#39;s clear they haven&amp;#39;t thought this through much (both the type of architecture they want and how to structure an evaluation). I&amp;#39;m not looking for specific product recommendations, but advice on the process you go through to make a decision and not just wander in circles doing trials and POCs for the next 18 months. &lt;/p&gt;\n\n&lt;p&gt;Here are some of the specific questions I have, but I&amp;#39;m all ears for other advice too:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do you prefer trials that are fully-managed or self-managed? What are the pros/cons to each? When products have both, how do I choose? &lt;/li&gt;\n&lt;li&gt;When you first trial a piece of data infra, what do you focus on in the first 30-60min?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m thinking mostly about the beginning of the evaluation right now since we&amp;#39;re just starting, so advice on that stage would be most helpful. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18lj7yt", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Gorges", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lj7yt/tips_for_evaluating_new_data_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lj7yt/tips_for_evaluating_new_data_platforms/", "subreddit_subscribers": 147001, "created_utc": 1702932727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a complex challenge where I'm exploring ways to simplify our orchestration structure where some \"tasks\" are more traditional running of small scripts or processes, but others are data transformations involving sometimes thousands of hardcoded conditional steps in a single task. \n\nI was thinking about refactoring the more complex workflows to be more independent when the possibly bad idea struck me to store the refactored code in a table format and use code injection or maybe grouped and composed in a pre-compilation step. So this is a sort of data-driven programming paradigm where the code is stored as a data object that is parsed and applied using a general bit of code.  that way I could test the code snippets atomically, generate data transformation tasks dynamically...\n\nSo has anyone experimented with storing code as data in a table format for complex workflows? What about using code injection or compilation for orchestration tasks? Any insights or warnings you can share would be incredibly helpful!", "author_fullname": "t2_4hepb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data-driven programming?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18limft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702931216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a complex challenge where I&amp;#39;m exploring ways to simplify our orchestration structure where some &amp;quot;tasks&amp;quot; are more traditional running of small scripts or processes, but others are data transformations involving sometimes thousands of hardcoded conditional steps in a single task. &lt;/p&gt;\n\n&lt;p&gt;I was thinking about refactoring the more complex workflows to be more independent when the possibly bad idea struck me to store the refactored code in a table format and use code injection or maybe grouped and composed in a pre-compilation step. So this is a sort of data-driven programming paradigm where the code is stored as a data object that is parsed and applied using a general bit of code.  that way I could test the code snippets atomically, generate data transformation tasks dynamically...&lt;/p&gt;\n\n&lt;p&gt;So has anyone experimented with storing code as data in a table format for complex workflows? What about using code injection or compilation for orchestration tasks? Any insights or warnings you can share would be incredibly helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18limft", "is_robot_indexable": true, "report_reasons": null, "author": "theinexplicablefuzz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18limft/datadriven_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18limft/datadriven_programming/", "subreddit_subscribers": 147001, "created_utc": 1702931216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DE!\n\nI'm on the lookout for the perfect orchestration solution, but I'm not quite seasoned enough to be aware of all the options out there. Here's the challenge: I have a customer who lays out ETL/ELT tasks in extensive flow diagrams with intricate conditions and interactions.\n\nWhat I'm after is a solution that allows these tasks to be relatively atomic for easy testing, yet straightforward to define and code. Additionally, I need support for ML workflows, flow versioning, and the flexibility to deploy both in the cloud and locally. Ideally, I'm aiming for something lightweight that can effortlessly work with minimal setup, drawing from a configuration source featuring DAGs and tasks.\n\nI'm aware of another team in my company working on a substantial system for a similar task, leveraging Kafka, Kubernetes, and node-red. However, this setup seems a bit too hefty for my needs, and I'm not a fan of how they are hardcoding custom tasks in node-red.\n\nI also found this awesome list of [workflow engines](https://github.com/meirwah/awesome-workflow-engines)\n\nAny suggestions or recommendations for a solution that strikes the right balance for my requirements? Thanks in advance!", "author_fullname": "t2_7i2kfbec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best user friendly orchestration tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lf3uj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702922607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DE!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the lookout for the perfect orchestration solution, but I&amp;#39;m not quite seasoned enough to be aware of all the options out there. Here&amp;#39;s the challenge: I have a customer who lays out ETL/ELT tasks in extensive flow diagrams with intricate conditions and interactions.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m after is a solution that allows these tasks to be relatively atomic for easy testing, yet straightforward to define and code. Additionally, I need support for ML workflows, flow versioning, and the flexibility to deploy both in the cloud and locally. Ideally, I&amp;#39;m aiming for something lightweight that can effortlessly work with minimal setup, drawing from a configuration source featuring DAGs and tasks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of another team in my company working on a substantial system for a similar task, leveraging Kafka, Kubernetes, and node-red. However, this setup seems a bit too hefty for my needs, and I&amp;#39;m not a fan of how they are hardcoding custom tasks in node-red.&lt;/p&gt;\n\n&lt;p&gt;I also found this awesome list of &lt;a href=\"https://github.com/meirwah/awesome-workflow-engines\"&gt;workflow engines&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or recommendations for a solution that strikes the right balance for my requirements? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?auto=webp&amp;s=b1fe2cc2ffd4873a5d343debf9808bb93b2dda1d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43acdbac9b761d7856283ff0546bcc148ceed9d2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f37a04aebefac1e04fdf4aa4f2f317eed939547", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b1fe2d902f40d902f2a7aba37b9bdfecdd241d14", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c756d6046c053bb95216b4c3b5497adba34e393d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6e1147407d0942d0dd9a5abd75bd67b94c3c0f87", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Gg5M0EsvrCF9UFGDlN_Z23sUeFVDuqN-H2DKSif_gdo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a74d378d3d7f80dc71c79d33ee779f49074f9a70", "width": 1080, "height": 540}], "variants": {}, "id": "AEPkqSVO-ZS9X-zj_UTJDoVNL-W4vCzHWkMh32X3mbc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18lf3uj", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible-Rule3619", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lf3uj/best_user_friendly_orchestration_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lf3uj/best_user_friendly_orchestration_tool/", "subreddit_subscribers": 147001, "created_utc": 1702922607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nNon DE here. \n\nI started a project that creates a node-flow system with Python that consists of data extraction and transformation of a movie's [dataset in Kaggle](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/code). Here's my [notebook](https://www.kaggle.com/marcosmonge/etl-creation-with-python/edit). \n\nMy question is is this project the role of a DE? Or more SE?\n\nI understand it is a data pipeline, but do you guys as DE work on things like this?\n\n&amp;#x200B;", "author_fullname": "t2_e0e3dp5bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Node System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18m7j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703007372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Non DE here. &lt;/p&gt;\n\n&lt;p&gt;I started a project that creates a node-flow system with Python that consists of data extraction and transformation of a movie&amp;#39;s &lt;a href=\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/code\"&gt;dataset in Kaggle&lt;/a&gt;. Here&amp;#39;s my &lt;a href=\"https://www.kaggle.com/marcosmonge/etl-creation-with-python/edit\"&gt;notebook&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;My question is is this project the role of a DE? Or more SE?&lt;/p&gt;\n\n&lt;p&gt;I understand it is a data pipeline, but do you guys as DE work on things like this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?auto=webp&amp;s=9f872613f793ddc8ae298345a7845d5ed121a5e0", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=118259d6d40de5d03ab52c66bb32ac51da993b74", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36b1b83c79599a0294e11a0b79049cb691ac199f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed2ae04117cbc9a768d009d70dd54abf37818c98", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec4eb477221d272415ce5a9d46fba2a4bf762683", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1684bd1ccc4a32b02513dfc79ce6495576fa97a1", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6c8f7c52833ffec695ecbc9ab08c5bff0e96a2a0", "width": 1080, "height": 1080}], "variants": {}, "id": "_LRlay9lu1SzOLMgUzoEMxCQJwTXrarRsWZlKtSCqhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m7j16", "is_robot_indexable": true, "report_reasons": null, "author": "kana_diense", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m7j16/etl_node_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m7j16/etl_node_system/", "subreddit_subscribers": 147001, "created_utc": 1703007372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does your company ever look into optimizing the cost of monitoring tools (we use Datadog) and cloud-based data platforms (Snowflake)? It seems like the discussion comes up quite often for us, but I'm not sure if this is something I should look into - what are your thoughts and experience with these?\n\nCloud cost is obviously a thing, but I am not sure how to think about these other pay-per-use tools", "author_fullname": "t2_e613am79m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "cloud-based data platforms and observability cost?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18m6nwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703005203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does your company ever look into optimizing the cost of monitoring tools (we use Datadog) and cloud-based data platforms (Snowflake)? It seems like the discussion comes up quite often for us, but I&amp;#39;m not sure if this is something I should look into - what are your thoughts and experience with these?&lt;/p&gt;\n\n&lt;p&gt;Cloud cost is obviously a thing, but I am not sure how to think about these other pay-per-use tools&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6nwq", "is_robot_indexable": true, "report_reasons": null, "author": "DataHoneyBadger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6nwq/cloudbased_data_platforms_and_observability_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6nwq/cloudbased_data_platforms_and_observability_cost/", "subreddit_subscribers": 147001, "created_utc": 1703005203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title is pretty self-explanatory. \n\nAre y'all noticing recruiter emails coming to your work email ?! I'm interested but obvi can't reply from work email lol", "author_fullname": "t2_roct4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recruiters reaching out to you on your work email ? are these emails automated or hand-written ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18m6ey9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703004561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title is pretty self-explanatory. &lt;/p&gt;\n\n&lt;p&gt;Are y&amp;#39;all noticing recruiter emails coming to your work email ?! I&amp;#39;m interested but obvi can&amp;#39;t reply from work email lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6ey9", "is_robot_indexable": true, "report_reasons": null, "author": "dronedesigner", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "subreddit_subscribers": 147001, "created_utc": 1703004561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sys-admin and fiddled around with python and just discoverd datasets.\n\nHow awesome is that stuff?! I was flashed.\n\nKnowing about datasets etc would have saved me \\_so\\_ much time back when i started my career, it is hilarious.\n\nI guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! \n\n&amp;#x200B;", "author_fullname": "t2_14rai9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I discoverd datasets in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m5gxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703002123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sys-admin and fiddled around with python and just discoverd datasets.&lt;/p&gt;\n\n&lt;p&gt;How awesome is that stuff?! I was flashed.&lt;/p&gt;\n\n&lt;p&gt;Knowing about datasets etc would have saved me _so_ much time back when i started my career, it is hilarious.&lt;/p&gt;\n\n&lt;p&gt;I guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m5gxj", "is_robot_indexable": true, "report_reasons": null, "author": "toast_one", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "subreddit_subscribers": 147001, "created_utc": 1703002123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, need some advice here, i used to work as database operator, my main skill is in T-SQL, beside some DB administration, self studied CCNA, MCSA, mongoDB, took a BigData specization on coursera which I never used or had a hand-on experience. \nRight now, i am interested in data engineering, and took GC prof. DE, but found it kinda confusing, especially with the diagnostic questions. \nDid i start from the right place? \nNeed your suggestions and advice. \nThanks in advance.", "author_fullname": "t2_16ck4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m38sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702996344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, need some advice here, i used to work as database operator, my main skill is in T-SQL, beside some DB administration, self studied CCNA, MCSA, mongoDB, took a BigData specization on coursera which I never used or had a hand-on experience. \nRight now, i am interested in data engineering, and took GC prof. DE, but found it kinda confusing, especially with the diagnostic questions. \nDid i start from the right place? \nNeed your suggestions and advice. \nThanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m38sb", "is_robot_indexable": true, "report_reasons": null, "author": "signofnothing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m38sb/google_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m38sb/google_cloud/", "subreddit_subscribers": 147001, "created_utc": 1702996344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIam writing a snowflake stored procedure in python language.\n\nBelow is the sample code:\n\n    CREATE OR REPLACE PROCEDURE edw_dev.master.SampleSP(TABLENAMES ARRAY, ORDERBYCOLUMNS ARRAY DEFAULT NULL)\n    RETURNS STRING\n    LANGUAGE PYTHON\n    RUNTIME_VERSION = '3.8'\n    PACKAGES = ('snowflake-snowpark-python')\n    HANDLER = 'process_tables'\n    as\n    $$\n    def process_tables(snowpark_session, TABLENAMES, ORDERBYCOLUMNS):\n        \n                createTableSql = f'CREATE OR REPLACE TABLE {newTableName} LIKE {fullTableName}'\n    \n                snowpark_session.sql(createTableSql).collect()\n    \n    \n    \n    $$;\n\nI need to implement a lock using 'begin transaction' and 'commit' for a section inside my stored procedure. How can we do this in python snowflake stored proc?\n\nI don't see much detail about this in the documentation as it contains details for Snowflake scripting alone.\n\nHas anyone come across this? Appreciate your help in advance.!", "author_fullname": "t2_9fr6if3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help: Snowflake Python Stored procedure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2rg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702995008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Iam writing a snowflake stored procedure in python language.&lt;/p&gt;\n\n&lt;p&gt;Below is the sample code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE OR REPLACE PROCEDURE edw_dev.master.SampleSP(TABLENAMES ARRAY, ORDERBYCOLUMNS ARRAY DEFAULT NULL)\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = &amp;#39;3.8&amp;#39;\nPACKAGES = (&amp;#39;snowflake-snowpark-python&amp;#39;)\nHANDLER = &amp;#39;process_tables&amp;#39;\nas\n$$\ndef process_tables(snowpark_session, TABLENAMES, ORDERBYCOLUMNS):\n\n            createTableSql = f&amp;#39;CREATE OR REPLACE TABLE {newTableName} LIKE {fullTableName}&amp;#39;\n\n            snowpark_session.sql(createTableSql).collect()\n\n\n\n$$;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I need to implement a lock using &amp;#39;begin transaction&amp;#39; and &amp;#39;commit&amp;#39; for a section inside my stored procedure. How can we do this in python snowflake stored proc?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see much detail about this in the documentation as it contains details for Snowflake scripting alone.&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across this? Appreciate your help in advance.!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m2rg5", "is_robot_indexable": true, "report_reasons": null, "author": "aj_here_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m2rg5/help_snowflake_python_stored_procedure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m2rg5/help_snowflake_python_stored_procedure/", "subreddit_subscribers": 147001, "created_utc": 1702995008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m not a data engineer, am a BI analyst whos interested in becoming a DE, so currently I\u2019m trying to observe, ask questions, search\u2026 but I noticed it\u2019s really stressful job and there a lot of things i need to learn and i feel overwhelmed. \n\nHow you guys dealing with this pressure and what strategies are you using to balance between doing work and continue learning and sharpening your skills?\n\nI also want to ask about how you learned DE and if you know a geed source teaching the basics of DE for beginners. \nnote that I\u2019m a BI analyst for almost 3 years :)", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work pressure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lzawl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702983685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not a data engineer, am a BI analyst whos interested in becoming a DE, so currently I\u2019m trying to observe, ask questions, search\u2026 but I noticed it\u2019s really stressful job and there a lot of things i need to learn and i feel overwhelmed. &lt;/p&gt;\n\n&lt;p&gt;How you guys dealing with this pressure and what strategies are you using to balance between doing work and continue learning and sharpening your skills?&lt;/p&gt;\n\n&lt;p&gt;I also want to ask about how you learned DE and if you know a geed source teaching the basics of DE for beginners. \nnote that I\u2019m a BI analyst for almost 3 years :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18lzawl", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lzawl/work_pressure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lzawl/work_pressure/", "subreddit_subscribers": 147001, "created_utc": 1702983685.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}