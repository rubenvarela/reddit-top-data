{"kind": "Listing", "data": {"after": "t3_18m38sb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!\n\n[https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra\\_5PGH&amp;index=6&amp;t=689s](https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=6&amp;t=689s)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a crash course on Polars library of Python (Great library for working with big data) and uploaded it on Youtube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lsb9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=6&amp;amp;t=689s\"&gt;https://www.youtube.com/watch?v=aiHSMYvoqYE&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=6&amp;amp;t=689s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?auto=webp&amp;s=7297230f4639915c7e57af7b9a255708da17bfa9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=784a54eeca77266e76144dcc7477cdae8da54cbb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76e755d0518dfef7107139a615d64e1857715e31", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/1PDIkye6LArTIWWNy8yF79XX41KoySrft8dUlTpOS7g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcd0428c65436c58727868ae2eae5a9b4a6d541d", "width": 320, "height": 240}], "variants": {}, "id": "_rVKQNaxcPqL1qZYn-JkINnf7oHCvdPuQq4k6I3ej4A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18lsb9p", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lsb9p/i_recorded_a_crash_course_on_polars_library_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lsb9p/i_recorded_a_crash_course_on_polars_library_of/", "subreddit_subscribers": 147030, "created_utc": 1702957460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throwaway because I know they are sometime on Reddit.\n\nMy boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.\n\nIt ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:\n\n- checking the SQL queries of my colleagues;\n- they want to know if this or that has been documented for tiny operations;\n- they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time\n\nI am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.\n\nThis is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?", "author_fullname": "t2_qa5f09pa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non-technical boss, wanting to micromanage and kills our team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m4e2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702999366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throwaway because I know they are sometime on Reddit.&lt;/p&gt;\n\n&lt;p&gt;My boss is constantly asking for unnecessary details and micromanaging us. I am out of ideas on how to manage them.&lt;/p&gt;\n\n&lt;p&gt;It ranges from anything like wanting to be in meetings where we change the name of a cluster, up to asking why we need a tool to track bugs (and since we never had one before, why bother now?). Even not being technical they are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;checking the SQL queries of my colleagues;&lt;/li&gt;\n&lt;li&gt;they want to know if this or that has been documented for tiny operations;&lt;/li&gt;\n&lt;li&gt;they are asking for ingestion of new datasets before we have even finished patching bugs or validating stuff, no unit tests because we are always short on time&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am trying to handle the stress of cascading requests by having a roadmap and shielding our team, but my manager will constantly challenge the roadmap and put pressure on my reports.&lt;/p&gt;\n\n&lt;p&gt;This is not tenable in the long term, do you have any advice on managing stakeholders above that aren\u2019t technical?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18m4e2i", "is_robot_indexable": true, "report_reasons": null, "author": "SuperMarioDataGalaxy", "discussion_type": null, "num_comments": 44, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m4e2i/nontechnical_boss_wanting_to_micromanage_and/", "subreddit_subscribers": 147030, "created_utc": 1702999366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sys-admin and fiddled around with python and just discoverd datasets.\n\nHow awesome is that stuff?! I was flashed.\n\nKnowing about datasets etc would have saved me \\_so\\_ much time back when i started my career, it is hilarious.\n\nI guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! \n\n&amp;#x200B;", "author_fullname": "t2_14rai9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I discoverd datasets in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m5gxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703002123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sys-admin and fiddled around with python and just discoverd datasets.&lt;/p&gt;\n\n&lt;p&gt;How awesome is that stuff?! I was flashed.&lt;/p&gt;\n\n&lt;p&gt;Knowing about datasets etc would have saved me _so_ much time back when i started my career, it is hilarious.&lt;/p&gt;\n\n&lt;p&gt;I guess it is time to start learning again(this is not the 1000 post asking for advice, this sub seems to have pretty good resources)! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m5gxj", "is_robot_indexable": true, "report_reasons": null, "author": "toast_one", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m5gxj/i_discoverd_datasets_in_python/", "subreddit_subscribers": 147030, "created_utc": 1703002123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New video \ud83e\udd73 What's new in Apache Airflow 2.8?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18m30x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18m30x1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W9gW-x75UmKzyC9I0b799PZ2OnmHhIBK7_zD9y5N684.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702995743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/M9qyj5Dszks", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?auto=webp&amp;s=14111aa6adfeb2c33ce6f5e60e93b26adf640e3d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4cfe605ca8eda8a8d053c6cebb0db4699467a79", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2161187bfb9511953e9b866e0bcbd6fd0319ee77", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QXKmfKRtkK5dfP9afHt8uOZ1FSxHfDvKOTGJVXdJMEQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e1acd7c824946fbb87246bb66219af8fd5f6d8", "width": 320, "height": 240}], "variants": {}, "id": "Sn7V-8gShoAirVVII0LH7BwleF0omtwue3ruXwusF2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18m30x1", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m30x1/new_video_whats_new_in_apache_airflow_28/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/M9qyj5Dszks", "subreddit_subscribers": 147030, "created_utc": 1702995743.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.8?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M9qyj5Dszks?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.8?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M9qyj5Dszks/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am looking to switch my career and move into DE. \n\nI've only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. \n\nThere's still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.\n\nWhat are some red flags that when you see in a job offer you're like \"This company has no structure / it needs three different people for that role / etc.\"?\n\nI am looking for ways to weed out those offers that I shouldn't be using as a baseline for gathering my skills.\n\nThanks.", "author_fullname": "t2_7xz6r2in", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Red flags in DE job offers (beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m14z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702990200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking to switch my career and move into DE. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only covered basics of Python, SQL, MySQL, PostgreSQL, Linux, bash scripting, Database administration + a few rdbms tools like pgadmin4, phpmyadmin or dbeaver. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still a long way to go for me, but I am already looking at some job offers to see what specific tools and skills companies in my area require.&lt;/p&gt;\n\n&lt;p&gt;What are some red flags that when you see in a job offer you&amp;#39;re like &amp;quot;This company has no structure / it needs three different people for that role / etc.&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;I am looking for ways to weed out those offers that I shouldn&amp;#39;t be using as a baseline for gathering my skills.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18m14z5", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent-Drink-235", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m14z5/red_flags_in_de_job_offers_beginner/", "subreddit_subscribers": 147030, "created_utc": 1702990200.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recap of 2023's Transformative Data Landscape", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_18luokv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QC-u87qQqiWYhhkIC7zp7h8awQeZx1F8z1WVloZ5my4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702965072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?auto=webp&amp;s=05cf70f29567b297be9005cc1fe6c52634c548d1", "width": 852, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8235b4ab19fc2ff32de42dcad115918f2e142ea", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac56b2d2c72cfcf52f1d78a8b06cc0971bef6d20", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d507577ef1336581efee9304ad98a549d20d63fe", "width": 320, "height": 225}, {"url": "https://external-preview.redd.it/McBDtjackmJxipnxmo2grRRcVo8lpGsP1S5KQmF4E2g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e89944c98598044365a90f48cd565f877fa7541c", "width": 640, "height": 450}], "variants": {}, "id": "bU0KynVYqdS53QNQHO7TTIr2Kuty1FCLaOXHnUOQcI0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18luokv", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18luokv/recap_of_2023s_transformative_data_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/recap-of-2023s-transformative-data", "subreddit_subscribers": 147030, "created_utc": 1702965072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?", "author_fullname": "t2_dxt8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting new records/changes: timestamp vs ingest I\u2019d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m00kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702986364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the company I am currently contracting in they have a central data warehouse running on Postgres with about 30 terabytes of data. Users of the warehouse are expected to pull data out of the database into their own environments. \nAs many of the tables are too large to do a full sync, we need to do incremental sync on new/updated data. The person that created the central warehouse has created a system where every record is tagged with the id of the batch of data that it was ingested from. These are not necessarily in incrementing order. This is done per table. Thus, every system working with the data warehouse has to maintain their own logic for every table that they use of which transactions they have already processed. When I look at their ETL scripts about half of the code is spent on this logic. \nTo me this seems overly convoluted compared to a database generated timestamp that I can query for changed data. It also means that I cannot use default functionality for incremental loads in dbt and meltano. Am I overlooking something here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m00kd", "is_robot_indexable": true, "report_reasons": null, "author": "pokepip", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m00kd/detecting_new_recordschanges_timestamp_vs_ingest/", "subreddit_subscribers": 147030, "created_utc": 1702986364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why storage and compute can't be separated for an OLTP database?", "author_fullname": "t2_fulplt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLTP vs OLAP databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lyljw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702980821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why storage and compute can&amp;#39;t be separated for an OLTP database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lyljw", "is_robot_indexable": true, "report_reasons": null, "author": "ankit_goyal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lyljw/oltp_vs_olap_databases/", "subreddit_subscribers": 147030, "created_utc": 1702980821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why is the cost for hightouch so high? Are there cheaper options? I am trying to figure out how to lower cost. Is Rudderstack a better solution?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hightouch Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lmjjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702941056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is the cost for hightouch so high? Are there cheaper options? I am trying to figure out how to lower cost. Is Rudderstack a better solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18lmjjz", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lmjjz/hightouch_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18lmjjz/hightouch_cost/", "subreddit_subscribers": 147030, "created_utc": 1702941056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack](https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack)\n\nWe open sourced PG Slot Notify, a tool we've been actively using to monitor replication slot size and alert us when there are abnormalities.\n\nIf you have Postgres databases with replication slots, this tool would come very handy!! It involves 5 mins of setup time and you should be good to go!", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PG Slot Notify: Monitor Postgres Replication Slot Growth in Slack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ll3w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702937409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack\"&gt;https://blog.peerdb.io/pg-slot-notify-monitor-postgres-slot-growth-in-slack&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We open sourced PG Slot Notify, a tool we&amp;#39;ve been actively using to monitor replication slot size and alert us when there are abnormalities.&lt;/p&gt;\n\n&lt;p&gt;If you have Postgres databases with replication slots, this tool would come very handy!! It involves 5 mins of setup time and you should be good to go!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?auto=webp&amp;s=f2c640396c48ee4e87e81497df05c6f09b0481db", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=584fe42ee441fed66d044e42f0bc778750228572", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83938a1b51284fa54354b4819bd85c7322d70795", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a53d612801375bd9e1406e912037e2df91c2803", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f42ba9b2be0e2be031475dd9c3d9c7bcaf856525", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fecc1bf0eed3569e71cb61e79f62d243659df902", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/10TWVuDGR9WBJnT0IViO5YZTX6U_RoIKWXRXNHdU6Xo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a06cbf070c88c8326046b408d2c5be8c1af54614", "width": 1080, "height": 567}], "variants": {}, "id": "CXHCBuyAiQklJzG9M75ycT_nl9F2gQjEziJ40F9-sp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18ll3w9", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ll3w9/pg_slot_notify_monitor_postgres_replication_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ll3w9/pg_slot_notify_monitor_postgres_replication_slot/", "subreddit_subscribers": 147030, "created_utc": 1702937409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expedia Uses WebSockets and Kafka to Query Near Real-Time Streaming Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18lz0me", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_-95beDt0eTU61sjw3MyytCoW7zyk-9mjFOz5cqSkbM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702982547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?auto=webp&amp;s=22be1127b3a032c0428d4bee24b8d2cb2a2233c0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74b528758f8dac132781b7ba52cec3194953941b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b5018e5a478380623b37087dbf9dc4b43bbf70c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1b372ee2d8ab5031fb9f92e22e20238371990e25", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec9e2d3c657a70106b4608c93841f75070af8d79", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3de9be364444c886057dff0f382a0ea14630cb01", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oDquMrZue4nfq8ELf06QbeFTrQhOEwsl9KHtE8Dgca4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7820fff738d4f7d7dcf3a548b2e8c36161176b6", "width": 1080, "height": 567}], "variants": {}, "id": "BmdzDPEbzLW9dI8d-7eePz_SJf3gyF91hmqD-LM6Od4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18lz0me", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18lz0me/expedia_uses_websockets_and_kafka_to_query_near/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/12/expedia-websockets-kafka-query/", "subreddit_subscribers": 147030, "created_utc": 1702982547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5ud8qz3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Netflix Data Engineering Summit videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "name": "t3_18mactq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sSDLo57eZMNIp1wzW5IoGguFiQ6_Ua87WD5lDt3x1Es.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703014490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "netflixtechblog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?auto=webp&amp;s=5c559c3b17160025d56491777d567987248931ef", "width": 1111, "height": 571}, "resolutions": [{"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da24254e4bb038691cfdd4c156a5d5244c08c4bf", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=052f735a1ffa64a0e1d6d51c639439521a6f2004", "width": 216, "height": 111}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d0fc2cebd67c1385fae0b1324dc39348b3217f8", "width": 320, "height": 164}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc32a3e086f0217c8aa2eab757773f562dea42d3", "width": 640, "height": 328}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=756a90ecc71cbca89abb9212b906435a9bd267bd", "width": 960, "height": 493}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b00bb639fe14e1acfb87b0939a9785a7a7e3c46", "width": 1080, "height": 555}], "variants": {}, "id": "TMo7-NZlAEt-Oth2MSgWHW_-6WCPBJ0hDscjjgNPtxU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18mactq", "is_robot_indexable": true, "report_reasons": null, "author": "limeslice2020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mactq/netflix_data_engineering_summit_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102", "subreddit_subscribers": 147030, "created_utc": 1703014490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some advice on best approach/ practise.\n\nBackground :\n\nIm a data analyst working in a team. Breakdown of our reporting flows are :\n\n1. We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.\n\nProblem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. \n\n2. We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. \n\nThis tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. \n\nAnd when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.\n\nSo the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? \n\nMy concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?\n\nAs for to just use no.2 approach, im not sure if pyspark can do exactly what we're doing in no.1 since we lack of the exposure. \n\nSorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.", "author_fullname": "t2_7nk0x7fc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m0x3c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702989497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some advice on best approach/ practise.&lt;/p&gt;\n\n&lt;p&gt;Background :&lt;/p&gt;\n\n&lt;p&gt;Im a data analyst working in a team. Breakdown of our reporting flows are :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We remote into VM and pull data using SQL. Then do the necessary conditioning or merging or etc and automate these stuffs using the task scheduler. We need python because we interact with google sheet a lot.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Problem i have with this is approach is that currently we dont have a proper Git framework whatsoever. Everybody just remote and change the code directly on the VM. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We have internal data tools that connects to the datawarehouse. Mainly the workflows are being done on SQL which has proper logging, code versioning etc as they were built and maintained in house. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This tool is actually quite solid, it even supports pyspark and spark sql. The only problem is that our team have never leveraged spark on this internal data platform. Just SQL. &lt;/p&gt;\n\n&lt;p&gt;And when we need massive update on google sheets reporting flows we just use the no.1 approach, do everything on the VM.&lt;/p&gt;\n\n&lt;p&gt;So the advice i need is, i want to understand if approach no.1 is bad practise and should we bring everything over on approach no.2? &lt;/p&gt;\n\n&lt;p&gt;My concern for keeping no.1 is that there is no proper Git framework to it. Everything is just so messy. Should i introduce Git and keep it around?&lt;/p&gt;\n\n&lt;p&gt;As for to just use no.2 approach, im not sure if pyspark can do exactly what we&amp;#39;re doing in no.1 since we lack of the exposure. &lt;/p&gt;\n\n&lt;p&gt;Sorry for lack of knowledge, im new to these kinds of infra. I dont know much other than just writing good SQL queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m0x3c", "is_robot_indexable": true, "report_reasons": null, "author": "Nopal97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m0x3c/advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m0x3c/advice_needed/", "subreddit_subscribers": 147030, "created_utc": 1702989497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I do all the ETL for my BI team. I'd like to incorporate Python into my ETL process for learning purposes, but I'm not sure where to start. I have a lot of SQL experience but no programming experience.\n\nCurrent process:\n\n* All of our data comes from Azure SQL dbs and federal government APIs. \n\n\n* The data sourced from SQL dbs is ingested via SSIS packages. It is loaded into an on-prem staging database. I then transform and import the data into our reporting warehouse using stored procs and scheduled jobs.\n\n* The data sourced from APIs is ingested via ADF pipelines. Everything else is done just like the SQL pipeline -- I load it to a staging db and complete the transformation and loading with stored procs.\n\nIf you inherited this pipeline, how would you improve it using Python?\n\nThanks!", "author_fullname": "t2_emnkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a BI Developer wanting to transition to DE and have accepted it's time to learn Python. Based on my current workflow, where can I integrate it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18madbk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703014522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I do all the ETL for my BI team. I&amp;#39;d like to incorporate Python into my ETL process for learning purposes, but I&amp;#39;m not sure where to start. I have a lot of SQL experience but no programming experience.&lt;/p&gt;\n\n&lt;p&gt;Current process:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;All of our data comes from Azure SQL dbs and federal government APIs. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The data sourced from SQL dbs is ingested via SSIS packages. It is loaded into an on-prem staging database. I then transform and import the data into our reporting warehouse using stored procs and scheduled jobs.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The data sourced from APIs is ingested via ADF pipelines. Everything else is done just like the SQL pipeline -- I load it to a staging db and complete the transformation and loading with stored procs.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you inherited this pipeline, how would you improve it using Python?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18madbk", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward_Tick0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18madbk/im_a_bi_developer_wanting_to_transition_to_de_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18madbk/im_a_bi_developer_wanting_to_transition_to_de_and/", "subreddit_subscribers": 147030, "created_utc": 1703014522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the holidays approach, why not use some of your downtime to dive into a quick and practical data engineering project? This [GitHub repo](https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_airflow_bigquery) offers a chance to see Airbyte, Airflow and dbt in action, working together!\n\nIn less than an hour, you can have a full-fledged data stack to extract e-commerce data and transform it in BigQuery (or any other data warehouse, with a few tweaks). All instructions are in the README. \n\nDesigned for busy professionals and curious learners, this project offers a straightforward but extendable structure.\n\nI hope you will enjoy it! Let me know how it goes and where it can be improved. \n\nDisclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help my fellow engineers experiment and learn.\n\n[End to end DAG](https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5)\n\n[dbt DAG](https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;format=png&amp;auto=webp&amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3)", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Airbyte, Airflow &amp; dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tcs1jwcfxa7c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4585fe4ef43dcf2fa137993774b3cb9e720c6ba0"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cabddcb7e42993c86645282df39f9066d8b929c6"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f88310d9cdda18f566eb7130b55e4f0ab9ef94a6"}, {"y": 326, "x": 640, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f0a419d349035775e01c7d76249bb0d2b0db8a5"}, {"y": 489, "x": 960, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a7223b8f338131b21d49cc04d832e1b01291cd6"}, {"y": 550, "x": 1080, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a5ddf6342374db4be5144b2abdffd5a3eb57f1c"}], "s": {"y": 958, "x": 1880, "u": "https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;format=png&amp;auto=webp&amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3"}, "id": "tcs1jwcfxa7c1"}, "w1tbxns9xa7c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d1c10ac0a94930899a0a889cdbbe6061d33e325"}, {"y": 64, "x": 216, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=50e1cf2e63a1a49effb7d64e19897b9a6d81abba"}, {"y": 95, "x": 320, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bf1aba786f9c8d4d29c95149a4db6572e64bfd4"}, {"y": 190, "x": 640, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cd409b30e35cefac56645a0c71d9b8c01120d92"}, {"y": 285, "x": 960, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6142356bda8e7b2549dbabdd8ee9439cfc66aadd"}, {"y": 320, "x": 1080, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5690b2f5a07fdd12cfc7ffbd5ba1b9eba22e5259"}], "s": {"y": 402, "x": 1354, "u": "https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;format=png&amp;auto=webp&amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5"}, "id": "w1tbxns9xa7c1"}}, "name": "t3_18m9yto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pouf7O2bHswW7FoCfoyalXWgbHN4PalGFB7Cl00vhmU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1703013525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the holidays approach, why not use some of your downtime to dive into a quick and practical data engineering project? This &lt;a href=\"https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_airflow_bigquery\"&gt;GitHub repo&lt;/a&gt; offers a chance to see Airbyte, Airflow and dbt in action, working together!&lt;/p&gt;\n\n&lt;p&gt;In less than an hour, you can have a full-fledged data stack to extract e-commerce data and transform it in BigQuery (or any other data warehouse, with a few tweaks). All instructions are in the README. &lt;/p&gt;\n\n&lt;p&gt;Designed for busy professionals and curious learners, this project offers a straightforward but extendable structure.&lt;/p&gt;\n\n&lt;p&gt;I hope you will enjoy it! Let me know how it goes and where it can be improved. &lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help my fellow engineers experiment and learn.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w1tbxns9xa7c1.png?width=1354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aee24208c9e649211d422ae12e5eeffae2f4abd5\"&gt;End to end DAG&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tcs1jwcfxa7c1.png?width=1880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdb19c1aedfeb8469ac52beea683ff03246f1aa3\"&gt;dbt DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?auto=webp&amp;s=2d1bd7ee7e1dacb5ae59ebe4b6a52937118c7eba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4cb3cab32bb4c0377c3bcf465b03a307fae1425", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba542763a1b4351acd1002befba883881db3e31d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31c1718d22be0d9ff790a87a2afd179b8bfb5e5c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b0294daefa0204451abb6e8f3a147d06c940bf2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6cc981f415ac4f15bdb8e3e431a9d34156ab5824", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/j1aTRlxBce-WIwvNzjW33AqeMOSCAOuMmv_8bYGymf4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bea4b583e75edfc9b379e33c725391509e474d0", "width": 1080, "height": 540}], "variants": {}, "id": "TcgpYk8BJNd4uAgmGeO3-7znAtRUmIi5C-Abf1OarDE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18m9yto", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18m9yto/integrating_airbyte_airflow_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m9yto/integrating_airbyte_airflow_dbt/", "subreddit_subscribers": 147030, "created_utc": 1703013525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title is pretty self-explanatory. \n\nAre y'all noticing recruiter emails coming to your work email ? I don't know how they got my work email into their HR or emailing systems ?! \n\nI'm interested but obvi can't reply from work email lol", "author_fullname": "t2_roct4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recruiters reaching out to you on your work email ? are these emails automated or hand-written ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m6ey9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703013326.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703004561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title is pretty self-explanatory. &lt;/p&gt;\n\n&lt;p&gt;Are y&amp;#39;all noticing recruiter emails coming to your work email ? I don&amp;#39;t know how they got my work email into their HR or emailing systems ?! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested but obvi can&amp;#39;t reply from work email lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6ey9", "is_robot_indexable": true, "report_reasons": null, "author": "dronedesigner", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6ey9/recruiters_reaching_out_to_you_on_your_work_email/", "subreddit_subscribers": 147030, "created_utc": 1703004561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dose hosting the system on your environment will change the source you\u2019re reading from? \n\nFor example System x is hosted now on the provider side, if the IT said we need to host it on our environment, dose that means the data source in fivetran connector have to be changed? I\u2019m I gonna establish a connector to my own environment rather that to x system? \n\ni\u2019m not familiar to cloud however I assume no need to do that it sounds weird.. however I heard people here say they have to \ud83e\udd14", "author_fullname": "t2_fludc35u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting the tool on your environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ltbyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702960586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dose hosting the system on your environment will change the source you\u2019re reading from? &lt;/p&gt;\n\n&lt;p&gt;For example System x is hosted now on the provider side, if the IT said we need to host it on our environment, dose that means the data source in fivetran connector have to be changed? I\u2019m I gonna establish a connector to my own environment rather that to x system? &lt;/p&gt;\n\n&lt;p&gt;i\u2019m not familiar to cloud however I assume no need to do that it sounds weird.. however I heard people here say they have to \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ltbyp", "is_robot_indexable": true, "report_reasons": null, "author": "OddElk1083", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ltbyp/hosting_the_tool_on_your_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ltbyp/hosting_the_tool_on_your_environment/", "subreddit_subscribers": 147030, "created_utc": 1702960586.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Explore the world of data insights with Microsoft's potent business analytics tool, Power BI. These pointers will enable you to fully utilize Power BI to find insightful information, regardless of your level of experience as a data analyst.\n\n**Efficiency at Your Fingertips:**\n\n* ***Tip 1***: Use smooth keyboard operations to speed up analysis.\n* ***Tip 2***: Get familiar with Power BI shortcuts for fast navigation, like Ctrl + S, Ctrl + C, and Ctrl + V.\n\n**Customize Your Work Area:**\n\n* ***Tip 3***: To create a targeted workflow, personalize your Power BI workspace.\n* ***Tip 4***: For efficiency, add quick-access buttons and eliminate unnecessary components.\n\n**Maximize Data Modeling**\n\n* ***Tip 5***: Benefit from Power BI's extensive data modeling features.\n* ***Tip 6***: Master linking tables, optimize data types, and extract valuable insights from calculated columns and measurements.\n\n**Visual Impact:**\n\n* ***Tip 7***: Improve your reports by incorporating creative visuals.\n* ***Tip 8***: To convey your data in an engaging and understandable way, try out different charts, maps, and unique visualizations.\n\n**Data Conversion Magic:**\n\n* ***Tip 9***: Use the data transformation tools in Power BI to do perceptive analysis.\n* ***Tip 10***: Sort, organize, and merge data from many sources.\n\n**Cloud-based Collaboration:**\n\n* ***Tip 11***: Use Power BI Service to facilitate cloud-based communication.\n* ***Tip 12***: Share insights in real-time, create dashboards, and publish reports\n\n**Utilize Power Query:**\n\n* ***Tip 13***: Make your data preparation process more efficient by using Power Query.\n* ***Tip 14***: To save time and guarantee consistency in your studies, automate data transformation, loading, and cleansing processes.\n\n**Make Use of DAX Formulas:**\n\n* ***Tip 15***: Use Data Analysis Expressions (DAX) formulas to take analysis to new levels.\n* ***Tip 16***: To improve the depth of analysis, investigate complex computations.\n\n**Power BI on the Go:**\n\n* ***Tip 17***: Increase analytical capabilities by utilizing Power BI Mobile.\n* ***Tip 18***: Reports and dashboards can be accessed and used while mobile.\n\n**Community Connection:**\n\n* ***Tip 19***: Connect with the Power BI communities and talk about the newest features.\n* ***Tip 20***: Stay updated with valuable tips, seek advice, and engage in continuous learning.\n\nThese Power BI pointers can help you uncover insightful information and successfully manage the complexities of corporate analytics. Implement them into your normal data analysis tasks.\n\nHappy analyzing!", "author_fullname": "t2_ll90672v5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Maximize Power BI to Harness Data Insights: Tips for Data Enthusiasts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mc9i9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703019329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Explore the world of data insights with Microsoft&amp;#39;s potent business analytics tool, Power BI. These pointers will enable you to fully utilize Power BI to find insightful information, regardless of your level of experience as a data analyst.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Efficiency at Your Fingertips:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 1&lt;/em&gt;&lt;/strong&gt;: Use smooth keyboard operations to speed up analysis.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 2&lt;/em&gt;&lt;/strong&gt;: Get familiar with Power BI shortcuts for fast navigation, like Ctrl + S, Ctrl + C, and Ctrl + V.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Customize Your Work Area:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 3&lt;/em&gt;&lt;/strong&gt;: To create a targeted workflow, personalize your Power BI workspace.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 4&lt;/em&gt;&lt;/strong&gt;: For efficiency, add quick-access buttons and eliminate unnecessary components.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Maximize Data Modeling&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 5&lt;/em&gt;&lt;/strong&gt;: Benefit from Power BI&amp;#39;s extensive data modeling features.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 6&lt;/em&gt;&lt;/strong&gt;: Master linking tables, optimize data types, and extract valuable insights from calculated columns and measurements.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Visual Impact:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 7&lt;/em&gt;&lt;/strong&gt;: Improve your reports by incorporating creative visuals.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 8&lt;/em&gt;&lt;/strong&gt;: To convey your data in an engaging and understandable way, try out different charts, maps, and unique visualizations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Conversion Magic:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 9&lt;/em&gt;&lt;/strong&gt;: Use the data transformation tools in Power BI to do perceptive analysis.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 10&lt;/em&gt;&lt;/strong&gt;: Sort, organize, and merge data from many sources.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Cloud-based Collaboration:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 11&lt;/em&gt;&lt;/strong&gt;: Use Power BI Service to facilitate cloud-based communication.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 12&lt;/em&gt;&lt;/strong&gt;: Share insights in real-time, create dashboards, and publish reports&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Utilize Power Query:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 13&lt;/em&gt;&lt;/strong&gt;: Make your data preparation process more efficient by using Power Query.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 14&lt;/em&gt;&lt;/strong&gt;: To save time and guarantee consistency in your studies, automate data transformation, loading, and cleansing processes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Make Use of DAX Formulas:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 15&lt;/em&gt;&lt;/strong&gt;: Use Data Analysis Expressions (DAX) formulas to take analysis to new levels.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 16&lt;/em&gt;&lt;/strong&gt;: To improve the depth of analysis, investigate complex computations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Power BI on the Go:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 17&lt;/em&gt;&lt;/strong&gt;: Increase analytical capabilities by utilizing Power BI Mobile.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 18&lt;/em&gt;&lt;/strong&gt;: Reports and dashboards can be accessed and used while mobile.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Connection:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 19&lt;/em&gt;&lt;/strong&gt;: Connect with the Power BI communities and talk about the newest features.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tip 20&lt;/em&gt;&lt;/strong&gt;: Stay updated with valuable tips, seek advice, and engage in continuous learning.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These Power BI pointers can help you uncover insightful information and successfully manage the complexities of corporate analytics. Implement them into your normal data analysis tasks.&lt;/p&gt;\n\n&lt;p&gt;Happy analyzing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18mc9i9", "is_robot_indexable": true, "report_reasons": null, "author": "geeker-on-demand", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mc9i9/maximize_power_bi_to_harness_data_insights_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mc9i9/maximize_power_bi_to_harness_data_insights_tips/", "subreddit_subscribers": 147030, "created_utc": 1703019329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm a data engineer with 10 years of experience in Europe, seeking a job in the UK. Despite holding settled status and not requiring visa sponsorship, I'm facing challenges in my job hunt.\n\nHow did you find a job? I'd appreciate any insights or advice on effective strategies or platforms for finding data engineering roles in the UK or just general advice for someone in my situation.\n\nMany thanks!", "author_fullname": "t2_hnhowjrxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UK Data Engineers: How and where did you find a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mc050", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703018658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineer with 10 years of experience in Europe, seeking a job in the UK. Despite holding settled status and not requiring visa sponsorship, I&amp;#39;m facing challenges in my job hunt.&lt;/p&gt;\n\n&lt;p&gt;How did you find a job? I&amp;#39;d appreciate any insights or advice on effective strategies or platforms for finding data engineering roles in the UK or just general advice for someone in my situation.&lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18mc050", "is_robot_indexable": true, "report_reasons": null, "author": "BubblyImpress7078", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mc050/uk_data_engineers_how_and_where_did_you_find_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mc050/uk_data_engineers_how_and_where_did_you_find_a_job/", "subreddit_subscribers": 147030, "created_utc": 1703018658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is building a data lake from a number of different ERPs (we have several subsidiaries). Unfortunately, we cannot seem to find any meaningful backend support for integrating the data from Unleashed and Xero (one of our companies uses them in tandem).\n\nDoes anyone here have experience querying and working with the backend of either of these platforms? Do you know someone who does? We basically just need a Q&amp;A session for the team to ask questions about where to find specific dimensions.\n\nThanks in advance!\n\nPS - Sorry if this is too close to a job post, I'm just running out of logistical resources trying to find an SME to consult on this.", "author_fullname": "t2_o1ln6yad", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here worked with Xero/Unleashed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mbe32", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703017100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is building a data lake from a number of different ERPs (we have several subsidiaries). Unfortunately, we cannot seem to find any meaningful backend support for integrating the data from Unleashed and Xero (one of our companies uses them in tandem).&lt;/p&gt;\n\n&lt;p&gt;Does anyone here have experience querying and working with the backend of either of these platforms? Do you know someone who does? We basically just need a Q&amp;amp;A session for the team to ask questions about where to find specific dimensions.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;PS - Sorry if this is too close to a job post, I&amp;#39;m just running out of logistical resources trying to find an SME to consult on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18mbe32", "is_robot_indexable": true, "report_reasons": null, "author": "_tr9800a_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18mbe32/anyone_here_worked_with_xerounleashed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18mbe32/anyone_here_worked_with_xerounleashed/", "subreddit_subscribers": 147030, "created_utc": 1703017100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nNon DE here. \n\nI started a project that creates a node-flow system with Python that consists of data extraction and transformation of a movie's [dataset in Kaggle](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/code). Here's my [notebook](https://www.kaggle.com/marcosmonge/etl-creation-with-python/edit). \n\nMy question is is this project the role of a DE? Or more SE?\n\nI understand it is a data pipeline, but do you guys as DE work on things like this?\n\n&amp;#x200B;", "author_fullname": "t2_e0e3dp5bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Node System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m7j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703007372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Non DE here. &lt;/p&gt;\n\n&lt;p&gt;I started a project that creates a node-flow system with Python that consists of data extraction and transformation of a movie&amp;#39;s &lt;a href=\"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/code\"&gt;dataset in Kaggle&lt;/a&gt;. Here&amp;#39;s my &lt;a href=\"https://www.kaggle.com/marcosmonge/etl-creation-with-python/edit\"&gt;notebook&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;My question is is this project the role of a DE? Or more SE?&lt;/p&gt;\n\n&lt;p&gt;I understand it is a data pipeline, but do you guys as DE work on things like this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?auto=webp&amp;s=9f872613f793ddc8ae298345a7845d5ed121a5e0", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=118259d6d40de5d03ab52c66bb32ac51da993b74", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36b1b83c79599a0294e11a0b79049cb691ac199f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed2ae04117cbc9a768d009d70dd54abf37818c98", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec4eb477221d272415ce5a9d46fba2a4bf762683", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1684bd1ccc4a32b02513dfc79ce6495576fa97a1", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/Kml5Hq9H6yiUl39D0GsZQOmRmrMvmIK0bW7S70FvXTg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6c8f7c52833ffec695ecbc9ab08c5bff0e96a2a0", "width": 1080, "height": 1080}], "variants": {}, "id": "_LRlay9lu1SzOLMgUzoEMxCQJwTXrarRsWZlKtSCqhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m7j16", "is_robot_indexable": true, "report_reasons": null, "author": "kana_diense", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m7j16/etl_node_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m7j16/etl_node_system/", "subreddit_subscribers": 147030, "created_utc": 1703007372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was just wondering what do you think of this DE internship :   \n\n&amp;#x200B;\n\nWhat you will do:\n\n* Work closely with several stakeholders such as CRM, and Customer Support to understand their needs and challenges.\n* Integrate relevant data sources that contain user information and campaign data\n* Design ETL data pipeline for cleansing, enriching, and structuring the data for analysis\n* Develop a user-friendly reporting tool for accessing and interpreting the reason behind the non-delivery of CRM campaigns\n* Improve the code base to optimize the cost of our cloud computing resources\n* Ensure that all the code written is high quality, scalable, and testable\n* Develop, test, and maintain big-data scripts that generate the datasets used by Customer and Monetization tools\n* Work closely with the whole team to achieve company objectives\n\n**Qualifications**\n\nThis role is excellent for a person with:\n\n* You are currently enrolled in your last year or have just graduated with a Master\u2019s Degree in Software Engineering, Data Science, or a related technical field\n* Passion for Software Engineering and/or data analysis\n* Experience in SQL and Python programming\n* Experience using a visualization tool (Looker Studio, Tableau, Power BI, or similar)\n* Curious: Being ready to tackle complex problems with insights and analyses at the crossroads of tech, product, data, and business\n* Fluent working in French &amp; English\n\nSkills that we value:\n\n* Eager to learn new programming languages and Big data frameworks\n* Experience with one of the following Big data tools is a plus: BigQuery, Scala, Hadoop, Spark, Elasticsearch\n* Good communication skills and the capacity to adapt to non-technical interlocutors\n* At ease in teamwork, familiar with agile methodology and pair-programming ", "author_fullname": "t2_6jwsskq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good 6 Months Internship ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m7hzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703007299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was just wondering what do you think of this DE internship :   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What you will do:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Work closely with several stakeholders such as CRM, and Customer Support to understand their needs and challenges.&lt;/li&gt;\n&lt;li&gt;Integrate relevant data sources that contain user information and campaign data&lt;/li&gt;\n&lt;li&gt;Design ETL data pipeline for cleansing, enriching, and structuring the data for analysis&lt;/li&gt;\n&lt;li&gt;Develop a user-friendly reporting tool for accessing and interpreting the reason behind the non-delivery of CRM campaigns&lt;/li&gt;\n&lt;li&gt;Improve the code base to optimize the cost of our cloud computing resources&lt;/li&gt;\n&lt;li&gt;Ensure that all the code written is high quality, scalable, and testable&lt;/li&gt;\n&lt;li&gt;Develop, test, and maintain big-data scripts that generate the datasets used by Customer and Monetization tools&lt;/li&gt;\n&lt;li&gt;Work closely with the whole team to achieve company objectives&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Qualifications&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This role is excellent for a person with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You are currently enrolled in your last year or have just graduated with a Master\u2019s Degree in Software Engineering, Data Science, or a related technical field&lt;/li&gt;\n&lt;li&gt;Passion for Software Engineering and/or data analysis&lt;/li&gt;\n&lt;li&gt;Experience in SQL and Python programming&lt;/li&gt;\n&lt;li&gt;Experience using a visualization tool (Looker Studio, Tableau, Power BI, or similar)&lt;/li&gt;\n&lt;li&gt;Curious: Being ready to tackle complex problems with insights and analyses at the crossroads of tech, product, data, and business&lt;/li&gt;\n&lt;li&gt;Fluent working in French &amp;amp; English&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Skills that we value:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Eager to learn new programming languages and Big data frameworks&lt;/li&gt;\n&lt;li&gt;Experience with one of the following Big data tools is a plus: BigQuery, Scala, Hadoop, Spark, Elasticsearch&lt;/li&gt;\n&lt;li&gt;Good communication skills and the capacity to adapt to non-technical interlocutors&lt;/li&gt;\n&lt;li&gt;At ease in teamwork, familiar with agile methodology and pair-programming &lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m7hzm", "is_robot_indexable": true, "report_reasons": null, "author": "Slow_Low206", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m7hzm/is_this_a_good_6_months_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m7hzm/is_this_a_good_6_months_internship/", "subreddit_subscribers": 147030, "created_utc": 1703007299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does your company ever look into optimizing the cost of monitoring tools (we use Datadog) and cloud-based data platforms (Snowflake)? It seems like the discussion comes up quite often for us, but I'm not sure if this is something I should look into - what are your thoughts and experience with these?\n\nCloud cost is obviously a thing, but I am not sure how to think about these other pay-per-use tools", "author_fullname": "t2_e613am79m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "cloud-based data platforms and observability cost?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m6nwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703005203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does your company ever look into optimizing the cost of monitoring tools (we use Datadog) and cloud-based data platforms (Snowflake)? It seems like the discussion comes up quite often for us, but I&amp;#39;m not sure if this is something I should look into - what are your thoughts and experience with these?&lt;/p&gt;\n\n&lt;p&gt;Cloud cost is obviously a thing, but I am not sure how to think about these other pay-per-use tools&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6nwq", "is_robot_indexable": true, "report_reasons": null, "author": "DataHoneyBadger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6nwq/cloudbased_data_platforms_and_observability_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6nwq/cloudbased_data_platforms_and_observability_cost/", "subreddit_subscribers": 147030, "created_utc": 1703005203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm starting out a data team in a $5M ARR startup. We have nothing: no DWH, no reporting tool, no orchestration engine. It's pure greenfield.\n\nI'm planning to deploy a little DWH on Postgres (our data sizes are not large as of today and near future) where we will integrate data raw from sources with Airbyte and then run all transformations with dbt until a nice mart layer we can use for dashboards and consumption from savvy end users (ELT approach). I'm planning on using dbt core.\n\nI understand that one would usually use Airflow/Prefect as an orchestration engine and use that to handle the scheduling and monitoring of dbt runs. That's definitely the direction I want to go to, but I don't want to have to wait until I have a fully deployed engine (I'll take a bit because I've never deployed one from scratch) to be able to just run a silly dbt run each night for a &lt;50 models dbt project.\n\nSo my question is, what dramatically simple approach would you recommend for this initial stage in terms of scheduling/triggering the dbt runs?\n\nMy current idea is: deploy a tiny VM in the same network as the Postgres instance. Make a bash script that clones the git repo where the dbt project lives, executes the dbt run, and leaves some minimal trace so I can quickly check with SSH if the job ran properly or failed.  \n", "author_fullname": "t2_owp2ws8z2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice: barebone dbt run scheduling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m6n69", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703005149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting out a data team in a $5M ARR startup. We have nothing: no DWH, no reporting tool, no orchestration engine. It&amp;#39;s pure greenfield.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to deploy a little DWH on Postgres (our data sizes are not large as of today and near future) where we will integrate data raw from sources with Airbyte and then run all transformations with dbt until a nice mart layer we can use for dashboards and consumption from savvy end users (ELT approach). I&amp;#39;m planning on using dbt core.&lt;/p&gt;\n\n&lt;p&gt;I understand that one would usually use Airflow/Prefect as an orchestration engine and use that to handle the scheduling and monitoring of dbt runs. That&amp;#39;s definitely the direction I want to go to, but I don&amp;#39;t want to have to wait until I have a fully deployed engine (I&amp;#39;ll take a bit because I&amp;#39;ve never deployed one from scratch) to be able to just run a silly dbt run each night for a &amp;lt;50 models dbt project.&lt;/p&gt;\n\n&lt;p&gt;So my question is, what dramatically simple approach would you recommend for this initial stage in terms of scheduling/triggering the dbt runs?&lt;/p&gt;\n\n&lt;p&gt;My current idea is: deploy a tiny VM in the same network as the Postgres instance. Make a bash script that clones the git repo where the dbt project lives, executes the dbt run, and leaves some minimal trace so I can quickly check with SSH if the job ran properly or failed.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18m6n69", "is_robot_indexable": true, "report_reasons": null, "author": "boringde", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m6n69/looking_for_advice_barebone_dbt_run_scheduling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m6n69/looking_for_advice_barebone_dbt_run_scheduling/", "subreddit_subscribers": 147030, "created_utc": 1703005149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, need some advice here, i used to work as database operator, my main skill is in T-SQL, beside some DB administration, self studied CCNA, MCSA, mongoDB, took a BigData specization on coursera which I never used or had a hand-on experience. \nRight now, i am interested in data engineering, and took GC prof. DE, but found it kinda confusing, especially with the diagnostic questions. \nDid i start from the right place? \nNeed your suggestions and advice. \nThanks in advance.", "author_fullname": "t2_16ck4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m38sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702996344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, need some advice here, i used to work as database operator, my main skill is in T-SQL, beside some DB administration, self studied CCNA, MCSA, mongoDB, took a BigData specization on coursera which I never used or had a hand-on experience. \nRight now, i am interested in data engineering, and took GC prof. DE, but found it kinda confusing, especially with the diagnostic questions. \nDid i start from the right place? \nNeed your suggestions and advice. \nThanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18m38sb", "is_robot_indexable": true, "report_reasons": null, "author": "signofnothing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18m38sb/google_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18m38sb/google_cloud/", "subreddit_subscribers": 147030, "created_utc": 1702996344.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}