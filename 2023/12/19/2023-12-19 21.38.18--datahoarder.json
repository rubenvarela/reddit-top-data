{"kind": "Listing", "data": {"after": "t3_18lm3tk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_nixsez0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does my backup plan look?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2bxa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 122, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zEbLHapnRMxePXskRWr-9c_dsHoQUEQwsZz0JUxBmyg.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702993807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nr9i3jpxa97c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?auto=webp&amp;s=6fa44485265bb6f0e80f179de74502034abcd0f5", "width": 705, "height": 601}, "resolutions": [{"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39a747f24ff40be416bfe9df2a3643babe4111a0", "width": 108, "height": 92}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a2a9c2f72ebcd364a0759f1ff529258de237a66", "width": 216, "height": 184}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d8ab38510897dc2bdad9a9398b0f41376520984", "width": 320, "height": 272}, {"url": "https://preview.redd.it/nr9i3jpxa97c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76c9f9971af0e46b952e008aa465ff8761c93bd9", "width": 640, "height": 545}], "variants": {}, "id": "NKZMmmJh-lDar_MZu8iCp8jSSx1Zz7Y9bZ-vgYZrPY4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m2bxa", "is_robot_indexable": true, "report_reasons": null, "author": "AnApexBread", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18m2bxa/how_does_my_backup_plan_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nr9i3jpxa97c1.png", "subreddit_subscribers": 719249, "created_utc": 1702993807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The 1.2TB cache, which is being called the \u201cteraleak,\u201d could be a really big deal for preservationists, especially because many older apps are no longer available to download in any form.", "author_fullname": "t2_7k499ptf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Game preservationists dig for lost apps in TestFlight \u201cteraleak\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18ln0gk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/osE0cSs0hb-ILLQ1VnjYrPbu0L6OBGSyfirxXLFODeQ.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702942273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theverge.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The 1.2TB cache, which is being called the \u201cteraleak,\u201d could be a really big deal for preservationists, especially because many older apps are no longer available to download in any form.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theverge.com/2023/12/18/24006406/testflight-teraleak-game-preservationists", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?auto=webp&amp;s=341c75432488a5870fec0b8194a1ea66eb839d31", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7dbc40f247da04396efb25b165e48874a70cdb99", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=59aefda3d44d2597ba92e22f9d5840a5bfe64cfe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3b69e2fa0b96b6c0c6a43a477b35de0a5341393", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf3e547c7113cec676d855ba8df2d435093b48ad", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b18ac78cc608c98fa5fefb3cc51d99f9b4872f2e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/bz1ecbGZz3tOpooWMyHbAfa4kISrUYDwMiqoujhqtfQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=11d1e4dc85cd087bbe95684e68d7aaca79a343db", "width": 1080, "height": 565}], "variants": {}, "id": "SfCeBl87uS43ZWjcG9aUJ-N_VcETcrxY6uwMLXJ4xP4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Collector", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ln0gk", "is_robot_indexable": true, "report_reasons": null, "author": "NXGZ", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18ln0gk/game_preservationists_dig_for_lost_apps_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theverge.com/2023/12/18/24006406/testflight-teraleak-game-preservationists", "subreddit_subscribers": 719249, "created_utc": 1702942273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wasn't aware of this technology at all and would agree with the creator that it seems a shame that it's not more common.", "author_fullname": "t2_vdieh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Very interesting vid on zero-edge scanner for non-destructive book scanning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18loafw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 70, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-mOLXOGxWMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Archival Grade Flatbed Book Scanner - Avision FB6080E\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Archival Grade Flatbed Book Scanner - Avision FB6080E", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-mOLXOGxWMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Archival Grade Flatbed Book Scanner - Avision FB6080E\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Tech Tangents", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/-mOLXOGxWMs/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TechTangents"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-mOLXOGxWMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Archival Grade Flatbed Book Scanner - Avision FB6080E\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/18loafw", "height": 200}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d4w-THHXhvI0cDsChscZtrHrTmEjItbMdo4EpVH-GbA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702945708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wasn&amp;#39;t aware of this technology at all and would agree with the creator that it seems a shame that it&amp;#39;s not more common.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/-mOLXOGxWMs?si=qwcovXLwH3BSRc_-", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GLqnZfbiSfflChm93kpHWtEMtVePYzVUKg5QGlJQqZA.jpg?auto=webp&amp;s=0cbe0442469124285ac18afc989f2848dc034bd3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/GLqnZfbiSfflChm93kpHWtEMtVePYzVUKg5QGlJQqZA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a72810400b09e33fc1db66243e83a3a657cc7047", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/GLqnZfbiSfflChm93kpHWtEMtVePYzVUKg5QGlJQqZA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c6466407cb6b9da028143a9ce85035533dbafc07", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/GLqnZfbiSfflChm93kpHWtEMtVePYzVUKg5QGlJQqZA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=893622a9b157bb4cf242c0fb0d69d35e574dd1c1", "width": 320, "height": 240}], "variants": {}, "id": "wiOfg12x2Gp9englN332HS6ja1TEAwPeznYF4FQ-ru0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18loafw", "is_robot_indexable": true, "report_reasons": null, "author": "pennanbeach", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18loafw/very_interesting_vid_on_zeroedge_scanner_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/-mOLXOGxWMs?si=qwcovXLwH3BSRc_-", "subreddit_subscribers": 719249, "created_utc": 1702945708.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "Archival Grade Flatbed Book Scanner - Avision FB6080E", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-mOLXOGxWMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Archival Grade Flatbed Book Scanner - Avision FB6080E\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Tech Tangents", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/-mOLXOGxWMs/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TechTangents"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ck2fr5mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive Files Opening Brief In Its Appeal Of Book Publishers\u2019 Win", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18lqs2g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/32tby5F3UarM4Rscy-SkPm3xC4qTq8BKvODeFaylpoU.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702952851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techdirt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techdirt.com/2023/12/18/internet-archive-files-opening-brief-in-its-appeal-of-book-publishers-win/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?auto=webp&amp;s=03a5fde066455710ac1676ca5e55fdf4cff5f177", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd544711a911105c2c84e8778e42492e6627f7ee", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=581443ef43c416964d464ddd6b5b28eec7b2b77c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=98eca8135ccdbe0daad2aad9f2f21c250d1564ab", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60f612dc25b6693520e6d4a342645939506f3afd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=30ce1c1c245620a8b70a4d0a298b39657711ef0e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/wKm0XDzoASM6BrarQXoG18WnZ5CIUPM3ZBe5zppuyFw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b24b6b5a4ae88248a5d6b951b789da794832c41", "width": 1080, "height": 567}], "variants": {}, "id": "86PGtE2qmX3coS9Htmb8TUfXMSg2HaYO4Rk8A0YbGow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lqs2g", "is_robot_indexable": true, "report_reasons": null, "author": "AbolishDisney", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18lqs2g/internet_archive_files_opening_brief_in_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techdirt.com/2023/12/18/internet-archive-files-opening-brief-in-its-appeal-of-book-publishers-win/", "subreddit_subscribers": 719249, "created_utc": 1702952851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_saefx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I proudly present my janky testing setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tt3xg8fyra7c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d663397a3f7d90f53f0d396e713135f148987796"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db69bdd499f4e6d47a309ef8552c006a235d5c5a"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e24a11fc2817dd81e4f65c20ee4d08bc21f20b6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2843c9d811a5a753916228a5105719e125e58ab"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1cf2c475c96e87d9b6c244ea540a1f18f5799922"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0cae3d79f9adc2cdf54ff830bb418054fbfd4d14"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/tt3xg8fyra7c1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=0e185e52217f73464af02be20b07d535d5537168"}, "id": "tt3xg8fyra7c1"}, "7n62g9fyra7c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0920950b45970b042ef526c0e7b0654a0e03e503"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a79998d360a6c2b27a237f9fc88e91af0305fb26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0cb88a9051bbbd333f6b8891bacf9f37f10997da"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=50e472f75e457857f91deeeb91446ff15a69d654"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69b899c5acdb01aebf18e842f5092552dec1e128"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3de35654bcbba18d175bf336dd61c45d83fce5d"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/7n62g9fyra7c1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=69da04f39662d7288f0b968136fa51ff39098a54"}, "id": "7n62g9fyra7c1"}}, "name": "t3_18m97ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 21, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "tt3xg8fyra7c1", "id": 376241631}, {"media_id": "7n62g9fyra7c1", "id": 376241632}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OyMdjzQSo5pa6aS8KxIta6XjhvtFjQWrxNkJe2G6Dpo.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1703011640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18m97ns", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m97ns", "is_robot_indexable": true, "report_reasons": null, "author": "888Leander", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18m97ns/i_proudly_present_my_janky_testing_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18m97ns", "subreddit_subscribers": 719249, "created_utc": 1703011640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do you test your backups?\n\n&amp;#x200B;\n\nMany of us have a ton of data we're holding on to, and a lot of it is important enough for us to backup, but how do you test that backup when you have multiple TBs of data? \n\n&amp;#x200B;\n\nDo you just restore small bits of data periodically and hope that if the small amount works, then the rest will work as well, or do you do full restores and eat the cost (in time and money if you're pulling from the cloud)? \n\n&amp;#x200B;\n\nI know a lot of systems \"test\" backups automatically but without actually seeing the data how can you be sure? ", "author_fullname": "t2_nixsez0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you test your backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ls6tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you test your backups?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many of us have a ton of data we&amp;#39;re holding on to, and a lot of it is important enough for us to backup, but how do you test that backup when you have multiple TBs of data? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you just restore small bits of data periodically and hope that if the small amount works, then the rest will work as well, or do you do full restores and eat the cost (in time and money if you&amp;#39;re pulling from the cloud)? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know a lot of systems &amp;quot;test&amp;quot; backups automatically but without actually seeing the data how can you be sure? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ls6tr", "is_robot_indexable": true, "report_reasons": null, "author": "AnApexBread", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18ls6tr/how_do_you_test_your_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ls6tr/how_do_you_test_your_backups/", "subreddit_subscribers": 719249, "created_utc": 1702957065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So far I only cloned HDDs onto other HDD. Is it any difference when you copy from an HDD to an SSD or vice versa? I assume that it should not be any different, just never tried it before.", "author_fullname": "t2_pr4df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything to know when cloning an old HDD to an SSD using Macrium Reflect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ly10y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702978495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far I only cloned HDDs onto other HDD. Is it any difference when you copy from an HDD to an SSD or vice versa? I assume that it should not be any different, just never tried it before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ly10y", "is_robot_indexable": true, "report_reasons": null, "author": "Dron22", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ly10y/anything_to_know_when_cloning_an_old_hdd_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ly10y/anything_to_know_when_cloning_an_old_hdd_to_an/", "subreddit_subscribers": 719249, "created_utc": 1702978495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't think this is really about hoarding data, but I didn't know where else to ask and figured people here would likely have answers, so here it is.\n\nMy situation: I use a 500GB NVMe SSD for my Windows installation, and a 2TB (soon to be 4TB) SATA SSD for everything that doesn't force itself onto the Windows drive; mostly games, music, images. My backup drive (for both of the other drives) is a 5TB portable HDD. Please ignore the lack of 3-2-1 for now.\n\nFor a few years I've been using Acronis True Image 2019, specifically doing incremental backups with weekly full backups, but with my slow, noisy external HDD this got kind of annoying as it would take times on the order of 6 hours to do a full backup each week, and if I put my computer to sleep in the middle of that, it would sometimes cause Acronis to hang or fail the backup.\n\nIn a big whoopsie recently (but also somewhat tangentially), I accidentally emptied my entire backup drive while trying to clear some files with illegal names left over from a horribly failed Linux experiment, which prompted me (tangentially - since that was obviously user error) to look into better backup solutions after it occurred to me that the method of doing full backups and then having a few increments per week is actually extremely inefficient as a long term file history due to multiplication of data.\n\nSo, while reading some reddit posts, I came across Duplicacy, which I think has a really compelling concept in how efficient it is both in space saving and backup time over long backup histories, as large numbers of snapshots can have large intersections which are wholly deduplicated, and every backup after the first is effectively both incremental and full, without any special differences between them in how each snapshot can be read and restored, so I've been trialing the Web UI version.\n\nHowever, I've realized now that Duplicacy doesn't back up system images; only the C: volume, which I think means that restored backups of the Windows drive will not be bootable (it doesn't matter that the backup itself isn't bootable - just the restored files). On top of that, I've recently found out about hardlinks and want to make use of them in some of my media libraries, and Duplicacy does not preserve those, instead just backing up multiple copies of the file, whereas I think an image backup would preserve the hardlinks and not duplicate the file?\n\nAnyway, to make a long story short, is there any backup software currently available for Windows that combines image backups with a clever chunking system for deduplication, for a long backup history on limited storage space, fast backups every time, preservation of bootability and fancy file linking structure, and which won't implode through a sleep-wake cycle (that last one is less important)? If there's no software in particular, or I'm misunderstanding what an image backup is, is there a strategy that can achieve the same thing? Also, as a side note, I'm looking into buying an external/portable SSD (a really fast one for future-proofing), but it seems like there are a lot of dubious products on the market in that area right now, so I'm not sure where to go with that.\n\nAny additional notes to consider would be appreciated.", "author_fullname": "t2_dzp8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to back up my whole Windows home system efficiently and flexibly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m2z80", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice - Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702996943.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702995616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think this is really about hoarding data, but I didn&amp;#39;t know where else to ask and figured people here would likely have answers, so here it is.&lt;/p&gt;\n\n&lt;p&gt;My situation: I use a 500GB NVMe SSD for my Windows installation, and a 2TB (soon to be 4TB) SATA SSD for everything that doesn&amp;#39;t force itself onto the Windows drive; mostly games, music, images. My backup drive (for both of the other drives) is a 5TB portable HDD. Please ignore the lack of 3-2-1 for now.&lt;/p&gt;\n\n&lt;p&gt;For a few years I&amp;#39;ve been using Acronis True Image 2019, specifically doing incremental backups with weekly full backups, but with my slow, noisy external HDD this got kind of annoying as it would take times on the order of 6 hours to do a full backup each week, and if I put my computer to sleep in the middle of that, it would sometimes cause Acronis to hang or fail the backup.&lt;/p&gt;\n\n&lt;p&gt;In a big whoopsie recently (but also somewhat tangentially), I accidentally emptied my entire backup drive while trying to clear some files with illegal names left over from a horribly failed Linux experiment, which prompted me (tangentially - since that was obviously user error) to look into better backup solutions after it occurred to me that the method of doing full backups and then having a few increments per week is actually extremely inefficient as a long term file history due to multiplication of data.&lt;/p&gt;\n\n&lt;p&gt;So, while reading some reddit posts, I came across Duplicacy, which I think has a really compelling concept in how efficient it is both in space saving and backup time over long backup histories, as large numbers of snapshots can have large intersections which are wholly deduplicated, and every backup after the first is effectively both incremental and full, without any special differences between them in how each snapshot can be read and restored, so I&amp;#39;ve been trialing the Web UI version.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve realized now that Duplicacy doesn&amp;#39;t back up system images; only the C: volume, which I think means that restored backups of the Windows drive will not be bootable (it doesn&amp;#39;t matter that the backup itself isn&amp;#39;t bootable - just the restored files). On top of that, I&amp;#39;ve recently found out about hardlinks and want to make use of them in some of my media libraries, and Duplicacy does not preserve those, instead just backing up multiple copies of the file, whereas I think an image backup would preserve the hardlinks and not duplicate the file?&lt;/p&gt;\n\n&lt;p&gt;Anyway, to make a long story short, is there any backup software currently available for Windows that combines image backups with a clever chunking system for deduplication, for a long backup history on limited storage space, fast backups every time, preservation of bootability and fancy file linking structure, and which won&amp;#39;t implode through a sleep-wake cycle (that last one is less important)? If there&amp;#39;s no software in particular, or I&amp;#39;m misunderstanding what an image backup is, is there a strategy that can achieve the same thing? Also, as a side note, I&amp;#39;m looking into buying an external/portable SSD (a really fast one for future-proofing), but it seems like there are a lot of dubious products on the market in that area right now, so I&amp;#39;m not sure where to go with that.&lt;/p&gt;\n\n&lt;p&gt;Any additional notes to consider would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18m2z80", "is_robot_indexable": true, "report_reasons": null, "author": "bjshnog", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m2z80/i_want_to_back_up_my_whole_windows_home_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m2z80/i_want_to_back_up_my_whole_windows_home_system/", "subreddit_subscribers": 719249, "created_utc": 1702995616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm not sure if I am posting in the correct sub, so please let me know if my post fits better elsewhere.  \nI want to delete my discord account, but I don't want to lose my DM's with another person. Is it possible to somehow archive the DM's with this one person if I intend to delete my account? ", "author_fullname": "t2_q4k0xaog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving discord chat", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lkcfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702935517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m not sure if I am posting in the correct sub, so please let me know if my post fits better elsewhere.&lt;br/&gt;\nI want to delete my discord account, but I don&amp;#39;t want to lose my DM&amp;#39;s with another person. Is it possible to somehow archive the DM&amp;#39;s with this one person if I intend to delete my account? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lkcfk", "is_robot_indexable": true, "report_reasons": null, "author": "notfeelingbueno", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lkcfk/archiving_discord_chat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lkcfk/archiving_discord_chat/", "subreddit_subscribers": 719249, "created_utc": 1702935517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I made a post on here a while ago asking for tips on a planend NAS build and had a long discussion with someone here. One of the main things that shook me was his claim that RAID isn't really necessary for most people, especially using helium manufac. refurbised hard drives. It's much more important to have both an off-site and cloud backup in additon to your main system. Interested in hearing your guy's thoughts. Thank you", "author_fullname": "t2_mqskseq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is RAID really necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18mcdaj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703019593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I made a post on here a while ago asking for tips on a planend NAS build and had a long discussion with someone here. One of the main things that shook me was his claim that RAID isn&amp;#39;t really necessary for most people, especially using helium manufac. refurbised hard drives. It&amp;#39;s much more important to have both an off-site and cloud backup in additon to your main system. Interested in hearing your guy&amp;#39;s thoughts. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18mcdaj", "is_robot_indexable": true, "report_reasons": null, "author": "OneSteelTank", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18mcdaj/is_raid_really_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18mcdaj/is_raid_really_necessary/", "subreddit_subscribers": 719249, "created_utc": 1703019593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've just bought 4x 18tb WD Element drives and plan on shucking them and putting them in a nas server. I'm looking to see what nas devices support 18tb drives and what recommendations you can give me as this will be my first nas and I don't know where to start in all honesty. Thankyou", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS Server that supports 18tb drives? Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m8g1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703009728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just bought 4x 18tb WD Element drives and plan on shucking them and putting them in a nas server. I&amp;#39;m looking to see what nas devices support 18tb drives and what recommendations you can give me as this will be my first nas and I don&amp;#39;t know where to start in all honesty. Thankyou&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m8g1l", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m8g1l/nas_server_that_supports_18tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m8g1l/nas_server_that_supports_18tb_drives/", "subreddit_subscribers": 719249, "created_utc": 1703009728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dropbox claims 256Bit AES encryption, which sounds great, but is it really any different from OneDrive/Google Drive?", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Dropbox really encryted at rest?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m84py", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703008916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dropbox claims 256Bit AES encryption, which sounds great, but is it really any different from OneDrive/Google Drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m84py", "is_robot_indexable": true, "report_reasons": null, "author": "[deleted]", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18m84py/is_dropbox_really_encryted_at_rest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m84py/is_dropbox_really_encryted_at_rest/", "subreddit_subscribers": 719249, "created_utc": 1703008916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Found out recently that the contents of my journal on Google Docs were erased due to an oversight. Somehow, I managed to copy an empty version of the journal (it was either incomplete or that I accidentally backspaced its contents) to all four of my backups (local, Google Drive, GitHub, and a physical harddrive), which then overrode the complete file. \n\nMy oversight was that since the file was a Google Doc, all of the version histories across all backups were linking back to that overwritten file, and thus, I was not able to utilise version histories to recover the contents of the file at all. Even worse, was that since this incident happened months ago, and that I just found out just now, I am unable to recover anything due to routine deletions.\n\nI know that reading back on my post, I could have probably done a lot better in safekeeping my data better. I'm still new and learning when it comes to data hoarding, but this incident has really made me want to learn even more. \n\nWhat can I learn from this experience to better safe-keep my data?\n\nTL;DR: Lost data due to a oversight with Google Docs. How to improve?", "author_fullname": "t2_3jk99r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost the contents of an important digital journal. How can I learn from this experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m5dll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703001888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found out recently that the contents of my journal on Google Docs were erased due to an oversight. Somehow, I managed to copy an empty version of the journal (it was either incomplete or that I accidentally backspaced its contents) to all four of my backups (local, Google Drive, GitHub, and a physical harddrive), which then overrode the complete file. &lt;/p&gt;\n\n&lt;p&gt;My oversight was that since the file was a Google Doc, all of the version histories across all backups were linking back to that overwritten file, and thus, I was not able to utilise version histories to recover the contents of the file at all. Even worse, was that since this incident happened months ago, and that I just found out just now, I am unable to recover anything due to routine deletions.&lt;/p&gt;\n\n&lt;p&gt;I know that reading back on my post, I could have probably done a lot better in safekeeping my data better. I&amp;#39;m still new and learning when it comes to data hoarding, but this incident has really made me want to learn even more. &lt;/p&gt;\n\n&lt;p&gt;What can I learn from this experience to better safe-keep my data?&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Lost data due to a oversight with Google Docs. How to improve?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m5dll", "is_robot_indexable": true, "report_reasons": null, "author": "Flame4Fire", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m5dll/lost_the_contents_of_an_important_digital_journal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m5dll/lost_the_contents_of_an_important_digital_journal/", "subreddit_subscribers": 719249, "created_utc": 1703001888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am considering buying a 8-10 TB HDD for desktop usage.\nStorage of films, some games etc.\n\nCurrently WD Gold 8TB is cheaper or same price as WTB Red at my country. Should I go with gold, will there be any problem using it on PC, considering they are both \"NAS, data disks\"\n\nI want to go with gold or red cause I have read they are better quality than the normal green ones, that have been failing me recently.", "author_fullname": "t2_d6vkdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Gold vs WD Red Plus/Pro for desktop PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m3ghe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702996922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am considering buying a 8-10 TB HDD for desktop usage.\nStorage of films, some games etc.&lt;/p&gt;\n\n&lt;p&gt;Currently WD Gold 8TB is cheaper or same price as WTB Red at my country. Should I go with gold, will there be any problem using it on PC, considering they are both &amp;quot;NAS, data disks&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I want to go with gold or red cause I have read they are better quality than the normal green ones, that have been failing me recently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m3ghe", "is_robot_indexable": true, "report_reasons": null, "author": "exstelx", "discussion_type": null, "num_comments": 9, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m3ghe/wd_gold_vs_wd_red_pluspro_for_desktop_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m3ghe/wd_gold_vs_wd_red_pluspro_for_desktop_pc/", "subreddit_subscribers": 719249, "created_utc": 1702996922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's a no-brainer that I should order a new drive to replace the one with bad sectors, especially since it registered 100 bad sectors in just an hour. Consequently, I've removed that drive from my NAS for now. However, this situation is starting to concern me. If this drive is failing, should I expect the others to fail soon as well? Is 70,000 hours a significant amount of operating time for WD Red NAS drives? All the drives were purchased at the same time and have been running continuously since then. \n\nWhat would you honestly recommend in this situation?", "author_fullname": "t2_5tsmwe62", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with Bad Sectors on One Drive Among Others with Over 70,000 Hours of Runtime: Seeking Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m1vvz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702992519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a no-brainer that I should order a new drive to replace the one with bad sectors, especially since it registered 100 bad sectors in just an hour. Consequently, I&amp;#39;ve removed that drive from my NAS for now. However, this situation is starting to concern me. If this drive is failing, should I expect the others to fail soon as well? Is 70,000 hours a significant amount of operating time for WD Red NAS drives? All the drives were purchased at the same time and have been running continuously since then. &lt;/p&gt;\n\n&lt;p&gt;What would you honestly recommend in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m1vvz", "is_robot_indexable": true, "report_reasons": null, "author": "bilstream", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m1vvz/dealing_with_bad_sectors_on_one_drive_among/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m1vvz/dealing_with_bad_sectors_on_one_drive_among/", "subreddit_subscribers": 719249, "created_utc": 1702992519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently, I have many thousands of files that I am looking to manage, and I am looking for a service to help me manage them.\n\nIn order to help clarify what I am asking for, I'll explain the problem in more detail. There are three steps associated with adding to this collection:\n\n1. **Collection**: This involves the act of collecting the files, which could include downloading them, creating them, or finding them offline.\n2. **Storage**: How are the files stored? What data is stored alongside them? Note that self hosted data is a required option.\n3. **Management**: Once the files and associated data are stored, how can you manage them? A self hosted service would be ideal.\n\nThere exist many solutions for the Storage &amp; Management steps, including OS built-in tools such as Windows File Explorer. These solutions are usually called *Digital Asset Management* (DAM) Services.\n\nThere also of course exist many separate solutions for the Collection step, such as web scraping tools like [Gallery-DL](https://github.com/mikf/gallery-dl) or [yt-dlp](https://github.com/yt-dlp/yt-dlp)\n\nHowever, as many of you probably have encountered, it can be difficult to find solutions that work together well. Even if you do find one that works, it often heavily limits your flexibility.\n\nFor example, say you want to incorporate tags as metadata associated with files for querying purposes. Many DAM services allow this functionality, but what happens if you suddenly want to switch DAM services? It may become remarkably difficult if the tags are stored in a confusing proprietary database that you'll have to parse through to get the metadata back out. Or what if you have tags that you parsed using a web scraping tool that you want to import? Some DAM services don't easily allow this and don't let you automate it (no API or access to the database),  and as such you may find yourself going through the process of either automating the input yourself or manually inputting each tag (yikes). What if you also have files from different data streams such as some parsed from online and some from offline? You would have to put it all into the DAM and forget about any different metadata those files might have. Forget about having a local copy you can look through as well in most cases. Many DAMs also don't support some file types.\n\nThere are also issues associated with functionality such as tagging. There is no universally accepted standard for what tags exist and what format they should be in. The closest I've found is the [Public Tag Repository](https://hydrusnetwork.github.io/hydrus/PTR.html) or [Danbooru's Tags (NSFW)](https://danbooru.donmai.us/tags). Note that the PTR is probably the closest as I cannot find a way to have access to Danbooru's tag database. Its database is also a nightmare with around 64 tables in their database and everything in SQL which requires a migration to change the schema of.\n\nAs such, if you want true flexibility you have to find a way to separate the steps and be able to interchange the solutions you use for each. For collection, you should be able to use any method and scrapers that you want. For storage, files need to be stored in a universally accepted way along with their metadata that is stored either in an associated file or a database. Lastly, the management software needs to be completely separate, meaning you can switch DAMs as you please simply through importing and exporting your data. If you make a change to a file in a DAM service, it needs to be reflected in your storage solution.\n\nNote that there are solutions that try to cover all three steps, such as [Hydrus Network](https://github.com/hydrusnetwork/hydrus) which is a robust solution that acts as a DAM and also as a downloader with users being able to make custom downloaders. However, I've found myself using different downloaders for unsupported sites and struggling to find a way to automate the importing of tags. It also gets difficult when the biggest community made downloaders (e.g. for Danbooru) do not parse everything you want. It also does not support all of the functionalities that someone may want such as easily seeing file children/parents/siblings.\n\nThe only real solution I can think of for this is to store files in a universal file system (simple hierarchical file system such as exFAT) and to store metadata associated with each file's hash in a database that can be flexibly updated to reflect data stored or created in DAM services (exporting files). This means JSON or similar is likely the best option. This solution would also require custom importers and exporters to be made for each DAM service to allow full flexibility. The exporter would need to be able to sync with the universal database. Creating this kind of solution would be difficult and I would like to avoid this if possible. Not to mention if your DAM uses machine learning and likely uses vector databases which would be kinda hard to integrate into JSON.\n\nMy question is if there any tools or standards that accomplish this without needing to create this on my own. Are there existing open source self hosted services that meet this kind of flexibility? Is there an existing standard on what file data there is?\n\nAny help is appreciated. Please feel free to recommend DAMs as I am also looking for better services. [Hydrus Network](https://github.com/hydrusnetwork/hydrus) is currently my overall choice. If you want to look at criteria that some others have for robust DAMs, [this](https://softwarerecs.stackexchange.com/questions/47756/digital-asset-management-for-photography) is a good post.\n\n**TLDR**: Are there any open source &amp; self hosted Digital Asset Management services that allow for true flexibility (i.e. switching DAM services or for storing different kinds of metadata)? Are there any standards to know how to flexibly store files like I've talked about?", "author_fullname": "t2_hokshzbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted File Data Storage Solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lsh46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702957968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have many thousands of files that I am looking to manage, and I am looking for a service to help me manage them.&lt;/p&gt;\n\n&lt;p&gt;In order to help clarify what I am asking for, I&amp;#39;ll explain the problem in more detail. There are three steps associated with adding to this collection:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Collection&lt;/strong&gt;: This involves the act of collecting the files, which could include downloading them, creating them, or finding them offline.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: How are the files stored? What data is stored alongside them? Note that self hosted data is a required option.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Management&lt;/strong&gt;: Once the files and associated data are stored, how can you manage them? A self hosted service would be ideal.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There exist many solutions for the Storage &amp;amp; Management steps, including OS built-in tools such as Windows File Explorer. These solutions are usually called &lt;em&gt;Digital Asset Management&lt;/em&gt; (DAM) Services.&lt;/p&gt;\n\n&lt;p&gt;There also of course exist many separate solutions for the Collection step, such as web scraping tools like &lt;a href=\"https://github.com/mikf/gallery-dl\"&gt;Gallery-DL&lt;/a&gt; or &lt;a href=\"https://github.com/yt-dlp/yt-dlp\"&gt;yt-dlp&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, as many of you probably have encountered, it can be difficult to find solutions that work together well. Even if you do find one that works, it often heavily limits your flexibility.&lt;/p&gt;\n\n&lt;p&gt;For example, say you want to incorporate tags as metadata associated with files for querying purposes. Many DAM services allow this functionality, but what happens if you suddenly want to switch DAM services? It may become remarkably difficult if the tags are stored in a confusing proprietary database that you&amp;#39;ll have to parse through to get the metadata back out. Or what if you have tags that you parsed using a web scraping tool that you want to import? Some DAM services don&amp;#39;t easily allow this and don&amp;#39;t let you automate it (no API or access to the database),  and as such you may find yourself going through the process of either automating the input yourself or manually inputting each tag (yikes). What if you also have files from different data streams such as some parsed from online and some from offline? You would have to put it all into the DAM and forget about any different metadata those files might have. Forget about having a local copy you can look through as well in most cases. Many DAMs also don&amp;#39;t support some file types.&lt;/p&gt;\n\n&lt;p&gt;There are also issues associated with functionality such as tagging. There is no universally accepted standard for what tags exist and what format they should be in. The closest I&amp;#39;ve found is the &lt;a href=\"https://hydrusnetwork.github.io/hydrus/PTR.html\"&gt;Public Tag Repository&lt;/a&gt; or &lt;a href=\"https://danbooru.donmai.us/tags\"&gt;Danbooru&amp;#39;s Tags (NSFW)&lt;/a&gt;. Note that the PTR is probably the closest as I cannot find a way to have access to Danbooru&amp;#39;s tag database. Its database is also a nightmare with around 64 tables in their database and everything in SQL which requires a migration to change the schema of.&lt;/p&gt;\n\n&lt;p&gt;As such, if you want true flexibility you have to find a way to separate the steps and be able to interchange the solutions you use for each. For collection, you should be able to use any method and scrapers that you want. For storage, files need to be stored in a universally accepted way along with their metadata that is stored either in an associated file or a database. Lastly, the management software needs to be completely separate, meaning you can switch DAMs as you please simply through importing and exporting your data. If you make a change to a file in a DAM service, it needs to be reflected in your storage solution.&lt;/p&gt;\n\n&lt;p&gt;Note that there are solutions that try to cover all three steps, such as &lt;a href=\"https://github.com/hydrusnetwork/hydrus\"&gt;Hydrus Network&lt;/a&gt; which is a robust solution that acts as a DAM and also as a downloader with users being able to make custom downloaders. However, I&amp;#39;ve found myself using different downloaders for unsupported sites and struggling to find a way to automate the importing of tags. It also gets difficult when the biggest community made downloaders (e.g. for Danbooru) do not parse everything you want. It also does not support all of the functionalities that someone may want such as easily seeing file children/parents/siblings.&lt;/p&gt;\n\n&lt;p&gt;The only real solution I can think of for this is to store files in a universal file system (simple hierarchical file system such as exFAT) and to store metadata associated with each file&amp;#39;s hash in a database that can be flexibly updated to reflect data stored or created in DAM services (exporting files). This means JSON or similar is likely the best option. This solution would also require custom importers and exporters to be made for each DAM service to allow full flexibility. The exporter would need to be able to sync with the universal database. Creating this kind of solution would be difficult and I would like to avoid this if possible. Not to mention if your DAM uses machine learning and likely uses vector databases which would be kinda hard to integrate into JSON.&lt;/p&gt;\n\n&lt;p&gt;My question is if there any tools or standards that accomplish this without needing to create this on my own. Are there existing open source self hosted services that meet this kind of flexibility? Is there an existing standard on what file data there is?&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated. Please feel free to recommend DAMs as I am also looking for better services. &lt;a href=\"https://github.com/hydrusnetwork/hydrus\"&gt;Hydrus Network&lt;/a&gt; is currently my overall choice. If you want to look at criteria that some others have for robust DAMs, &lt;a href=\"https://softwarerecs.stackexchange.com/questions/47756/digital-asset-management-for-photography\"&gt;this&lt;/a&gt; is a good post.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: Are there any open source &amp;amp; self hosted Digital Asset Management services that allow for true flexibility (i.e. switching DAM services or for storing different kinds of metadata)? Are there any standards to know how to flexibly store files like I&amp;#39;ve talked about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?auto=webp&amp;s=e78fa80304b5763bf37ca051e074d40874a13fa0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1181317028bb06cfcedc7db9abfc8d9e4c36576d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=657a4e222f279cd70b47740c49056ff80ba58e87", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fac1fcccba27ea310251950037cd6105485ab509", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=687e01e79c42e341989a31ac6fda4fedf9ba2bd6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c50a8dbad55659e2332d488e5e0ad672e8972a9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8peLjdxRhf3qeObeax7LnJxvKOJUPdZmqDHPwLrNPsE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e18be8f18cda2b3ce39832f7af86937eddd46417", "width": 1080, "height": 540}], "variants": {}, "id": "NWU29wfBXVE-3lY-1uWtRELB8zJVlEUbK8C7H2XBik8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lsh46", "is_robot_indexable": true, "report_reasons": null, "author": "Estavenz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lsh46/selfhosted_file_data_storage_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lsh46/selfhosted_file_data_storage_solution/", "subreddit_subscribers": 719249, "created_utc": 1702957968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello peeps, got a quick query as someone who knows little to nothing about storage and just needs something to put all my shit onto and free some space on my laptop, mainly large YouTube video files lol \n\nI'm currently looking at two options, the Seagate One Touch line or the Western Digital My Passports. The Seagate being a slightly better option (5TB for \u00a3125) with the Western Digital being 4TB for \u00a3108\n\nI've heard some pretty iffy stuff about Western Digital, like they're basically unusable as a running drive (which sounds like I'll need it to be if I'm editing clips saved to the drive in an editor) and that some people have had catastrophic data loss. So any advice on which is more reliable would be great\n\nMost likely it'll just sit at my desk but in the case I do need to travel with it, would I be better off with an SSD or HDD? \n\n Many thanks", "author_fullname": "t2_37lr9qp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on portable storage - SSD or HDD Seagate/WD portable drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lr7d4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702954106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello peeps, got a quick query as someone who knows little to nothing about storage and just needs something to put all my shit onto and free some space on my laptop, mainly large YouTube video files lol &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at two options, the Seagate One Touch line or the Western Digital My Passports. The Seagate being a slightly better option (5TB for \u00a3125) with the Western Digital being 4TB for \u00a3108&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard some pretty iffy stuff about Western Digital, like they&amp;#39;re basically unusable as a running drive (which sounds like I&amp;#39;ll need it to be if I&amp;#39;m editing clips saved to the drive in an editor) and that some people have had catastrophic data loss. So any advice on which is more reliable would be great&lt;/p&gt;\n\n&lt;p&gt;Most likely it&amp;#39;ll just sit at my desk but in the case I do need to travel with it, would I be better off with an SSD or HDD? &lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lr7d4", "is_robot_indexable": true, "report_reasons": null, "author": "RipCurl69Reddit", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lr7d4/advice_on_portable_storage_ssd_or_hdd_seagatewd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lr7d4/advice_on_portable_storage_ssd_or_hdd_seagatewd/", "subreddit_subscribers": 719249, "created_utc": 1702954106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for the gound zero explanation of how to connect SSDs and HDDs into this [W680D4U-2L2T/G5](https://www.asrockrack.com/general/productdetail.asp?Model=W680D4U-2L2T%2FG5#Specifications) motherboard to see if it would be a reasonable alternative to popular ASUS Pro WS W680-ACE. I don't really understand OCuLink and I'm having a lot of trouble finding accessible explanations. \n\n The OCuLink ports on the board are labeled:\n\n* A: OCuLink (PCIe4.0 x4) \\[CPU\\] (shares lane with PCIe 4.0x4 slot)\n* B: OCuLink (PCIe4.0 x4 or 4 SATA 6Gb/s) \\[PCH\\]\n* C/D:  2 OCuLink (PCIe4.0 x4) \\[PCH\\] \n\nFirst of all, is there a chart of the SFF/oculink/slimsas connectors [similar to this one for USB](https://res.cloudinary.com/rspoc/image/upload/f_auto/q_auto/v1543497710/L8950515-01.jpg)? How do I tell if an oculink port or cable is 4i or 8i?\n\nok back to the motherboard. The HDD QVL lists only 2.5\" U.3 and M.2 2280 drives as being officially validated. I guess that means that I would need either an oculink/u.3 backplane or a oculink to u.3 cable like this one  [PCIe Gen 4 OCulink (SFF-8611) to U.3 (SFF-8639) Cable 150cm (microsatacables.com)](https://www.microsatacables.com/pcie-gen-4-oculink-sff-8611-to-u-3-sff-8639-cable-150cm) to connect a single drive, with no driver board in between?\n\nI would be fine paying SATA drive prices and connecting SATA3 SSDs and HDDs to this board - preferably even with something like the IcyDock [MB998IP-B](https://global.icydock.com/product_169.html) (2x miniSAS ports on back) or [MB998SP-B](https://global.icydock.com/product_167.html) (8x sata ports on back). Do I need something like an HBA, or can I just get a cable like this:  [Supermicro CBL-SAST-0933 50cm OCuLink SFF-8611 (x4) to 4 SATA Cable](https://store.supermicro.com/us_en/supermicro-50cm-oculink-to-4-sata-cable-cbl-sast-0933.html)? In either case, would I be able to use *any* of the OCuLink ports on the motherboard, or *only* the port B, which indicates that it also does SATA? \n\nCan I get this  [Mini SAS SFF-8643 To SFF-8611 Oculink Cable (microsatacables.com)](https://www.microsatacables.com/mini-sas-sff-8643-to-sff-8611-oculink-cable-rml42-0501)  cable, plug it into one of the *other* OCuLink ports (i.e., A, C, or D) and then use SATA SSDs in the ICYDock MB998IP-B?\n\nThe motherboard has just one m.2 slot. if I want to add another, do I have to use something like this card  [Innocard Oculink (SFf-8612) to M.2 NVMe SSD Adapter with Oculink (SFF-8611) to Mini SAS HD (SFF-8643) Cable - Newegg.com](https://www.newegg.com/p/0Y3-00M7-000D1) ? Same question as before, does it matter which port I plug it into?\n\nif I wanted all four OCuLink ports to split into 4 SATA ports for a total of 16, is that possible? I don't need any hardware raid because I'll be using ZFS. ", "author_fullname": "t2_4yuut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5 How do I plug drives into this (OCuLink) motherboard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lqnsv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702952505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for the gound zero explanation of how to connect SSDs and HDDs into this &lt;a href=\"https://www.asrockrack.com/general/productdetail.asp?Model=W680D4U-2L2T%2FG5#Specifications\"&gt;W680D4U-2L2T/G5&lt;/a&gt; motherboard to see if it would be a reasonable alternative to popular ASUS Pro WS W680-ACE. I don&amp;#39;t really understand OCuLink and I&amp;#39;m having a lot of trouble finding accessible explanations. &lt;/p&gt;\n\n&lt;p&gt;The OCuLink ports on the board are labeled:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A: OCuLink (PCIe4.0 x4) [CPU] (shares lane with PCIe 4.0x4 slot)&lt;/li&gt;\n&lt;li&gt;B: OCuLink (PCIe4.0 x4 or 4 SATA 6Gb/s) [PCH]&lt;/li&gt;\n&lt;li&gt;C/D:  2 OCuLink (PCIe4.0 x4) [PCH] &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;First of all, is there a chart of the SFF/oculink/slimsas connectors &lt;a href=\"https://res.cloudinary.com/rspoc/image/upload/f_auto/q_auto/v1543497710/L8950515-01.jpg\"&gt;similar to this one for USB&lt;/a&gt;? How do I tell if an oculink port or cable is 4i or 8i?&lt;/p&gt;\n\n&lt;p&gt;ok back to the motherboard. The HDD QVL lists only 2.5&amp;quot; U.3 and M.2 2280 drives as being officially validated. I guess that means that I would need either an oculink/u.3 backplane or a oculink to u.3 cable like this one  &lt;a href=\"https://www.microsatacables.com/pcie-gen-4-oculink-sff-8611-to-u-3-sff-8639-cable-150cm\"&gt;PCIe Gen 4 OCulink (SFF-8611) to U.3 (SFF-8639) Cable 150cm (microsatacables.com)&lt;/a&gt; to connect a single drive, with no driver board in between?&lt;/p&gt;\n\n&lt;p&gt;I would be fine paying SATA drive prices and connecting SATA3 SSDs and HDDs to this board - preferably even with something like the IcyDock &lt;a href=\"https://global.icydock.com/product_169.html\"&gt;MB998IP-B&lt;/a&gt; (2x miniSAS ports on back) or &lt;a href=\"https://global.icydock.com/product_167.html\"&gt;MB998SP-B&lt;/a&gt; (8x sata ports on back). Do I need something like an HBA, or can I just get a cable like this:  &lt;a href=\"https://store.supermicro.com/us_en/supermicro-50cm-oculink-to-4-sata-cable-cbl-sast-0933.html\"&gt;Supermicro CBL-SAST-0933 50cm OCuLink SFF-8611 (x4) to 4 SATA Cable&lt;/a&gt;? In either case, would I be able to use &lt;em&gt;any&lt;/em&gt; of the OCuLink ports on the motherboard, or &lt;em&gt;only&lt;/em&gt; the port B, which indicates that it also does SATA? &lt;/p&gt;\n\n&lt;p&gt;Can I get this  &lt;a href=\"https://www.microsatacables.com/mini-sas-sff-8643-to-sff-8611-oculink-cable-rml42-0501\"&gt;Mini SAS SFF-8643 To SFF-8611 Oculink Cable (microsatacables.com)&lt;/a&gt;  cable, plug it into one of the &lt;em&gt;other&lt;/em&gt; OCuLink ports (i.e., A, C, or D) and then use SATA SSDs in the ICYDock MB998IP-B?&lt;/p&gt;\n\n&lt;p&gt;The motherboard has just one m.2 slot. if I want to add another, do I have to use something like this card  &lt;a href=\"https://www.newegg.com/p/0Y3-00M7-000D1\"&gt;Innocard Oculink (SFf-8612) to M.2 NVMe SSD Adapter with Oculink (SFF-8611) to Mini SAS HD (SFF-8643) Cable - Newegg.com&lt;/a&gt; ? Same question as before, does it matter which port I plug it into?&lt;/p&gt;\n\n&lt;p&gt;if I wanted all four OCuLink ports to split into 4 SATA ports for a total of 16, is that possible? I don&amp;#39;t need any hardware raid because I&amp;#39;ll be using ZFS. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?auto=webp&amp;s=65133492208d5e8509f8773645ec2598e42be07a", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=68f9434593a55a693236fd99a8f452d87b1b6db3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf3aad54f7e608f89e8c34ed39b063e6f2cdc660", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=32ae02d9f965d3fc8a1a3ac91376dd2e5ebf419d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=998d32a6e91106d6f611bb897553f51fdc948235", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f533ff689dcd15a2614f6c83e1da102978c9b491", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/VzLVFNp_HXSWOVMm2qQjJtQ-KoZCvI_jbQO2nFL34PA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cac3f026c8eec1c08d578ae314ce273496ecaed", "width": 1080, "height": 1080}], "variants": {}, "id": "g5RkO4dPvHrIZnKb9kkutHhjfDx6G0hDMUJOSMJizqI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lqnsv", "is_robot_indexable": true, "report_reasons": null, "author": "verticalfuzz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lqnsv/eli5_how_do_i_plug_drives_into_this_oculink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lqnsv/eli5_how_do_i_plug_drives_into_this_oculink/", "subreddit_subscribers": 719249, "created_utc": 1702952505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I apologize in advance if this question is very basic, but I haven't purchased a new SSD in about 5 years and it looks like the SSD landscape has changed somewhat since then. I'm looking for a 1TB or 2TB M.2 SSD (depending on what the deals are) for usage in a general daily use laptop (web browsing, videos, music, light photo editting etc) and was wondering who makes reliable SSDs nowadays. In the past, I had bad luck with non vertically integrated SSD brands so I stuck with Samsung and Crucial drives. In my mind, I thought that overall SSD reliablity by brand was along these lines:\n\nTier 1: Samsung, Crucial\n\nTier 2: Intel (apparently they became Solidigm nowadays?)\n\nTier 3: everyone else\n\nIs this still roughly accurate? Are the cheaper non Samsung, Crucial, Solidigm SSDs reliable nowadays? I see that TEAMGROUP SSDs seem to be cheap and well reviewed on Amazon, but I'm not really one to trust Amazon reviews. Is QLC a problem for my usage scenario?\n\nThanks for any insights!", "author_fullname": "t2_8licsklb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD Reliability Tiers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m713p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703006107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize in advance if this question is very basic, but I haven&amp;#39;t purchased a new SSD in about 5 years and it looks like the SSD landscape has changed somewhat since then. I&amp;#39;m looking for a 1TB or 2TB M.2 SSD (depending on what the deals are) for usage in a general daily use laptop (web browsing, videos, music, light photo editting etc) and was wondering who makes reliable SSDs nowadays. In the past, I had bad luck with non vertically integrated SSD brands so I stuck with Samsung and Crucial drives. In my mind, I thought that overall SSD reliablity by brand was along these lines:&lt;/p&gt;\n\n&lt;p&gt;Tier 1: Samsung, Crucial&lt;/p&gt;\n\n&lt;p&gt;Tier 2: Intel (apparently they became Solidigm nowadays?)&lt;/p&gt;\n\n&lt;p&gt;Tier 3: everyone else&lt;/p&gt;\n\n&lt;p&gt;Is this still roughly accurate? Are the cheaper non Samsung, Crucial, Solidigm SSDs reliable nowadays? I see that TEAMGROUP SSDs seem to be cheap and well reviewed on Amazon, but I&amp;#39;m not really one to trust Amazon reviews. Is QLC a problem for my usage scenario?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m713p", "is_robot_indexable": true, "report_reasons": null, "author": "reos3", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m713p/ssd_reliability_tiers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m713p/ssd_reliability_tiers/", "subreddit_subscribers": 719249, "created_utc": 1703006107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've debated about getting a NAS or DAS for a while. All my drives are in my PC and it lives under my desk. It's all backed up manually and it works. I'm very reluctant to change this.\n\nBut it's noisy.\n\nIf I get a NAS/DAS and use it in JBOD, a bit of poking around online suggests the drive will be wiped. Is this really correct? For RAID, understandable, but for JBOD?\n\nAnd secondly, from people's experience with NAS/DAS, do the drives spin down and stay spun down. The ones in my PC spin down but not for long and is one of the reasons for the noise.", "author_fullname": "t2_183x1jsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Two questions regarding NAS/DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18m15i9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702990241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve debated about getting a NAS or DAS for a while. All my drives are in my PC and it lives under my desk. It&amp;#39;s all backed up manually and it works. I&amp;#39;m very reluctant to change this.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s noisy.&lt;/p&gt;\n\n&lt;p&gt;If I get a NAS/DAS and use it in JBOD, a bit of poking around online suggests the drive will be wiped. Is this really correct? For RAID, understandable, but for JBOD?&lt;/p&gt;\n\n&lt;p&gt;And secondly, from people&amp;#39;s experience with NAS/DAS, do the drives spin down and stay spun down. The ones in my PC spin down but not for long and is one of the reasons for the noise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18m15i9", "is_robot_indexable": true, "report_reasons": null, "author": "i_enjoy_silence", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18m15i9/two_questions_regarding_nasdas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18m15i9/two_questions_regarding_nasdas/", "subreddit_subscribers": 719249, "created_utc": 1702990241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone here working in IT and cybersecurity fields?\n\nWhat do you do with all network logs? How do you store them and for what purpose?", "author_fullname": "t2_550qnqr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cybersecurity and logs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lx2b3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702974414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here working in IT and cybersecurity fields?&lt;/p&gt;\n\n&lt;p&gt;What do you do with all network logs? How do you store them and for what purpose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18lx2b3", "is_robot_indexable": true, "report_reasons": null, "author": "masterphd2020", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lx2b3/cybersecurity_and_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lx2b3/cybersecurity_and_logs/", "subreddit_subscribers": 719249, "created_utc": 1702974414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. I am trying to think of a solution for migrating away from Windows because I'm finally no longer locked into their ecosystem. Right now I'm running a hardware raid solution that has 160tb usable and 130 used. I want to get away from Windows but currently the filesystem for the array is GPT with NTFS. I don't really have a good reason to swap out the drives anytime soon so I was hoping to just backup the data. Is there some solution, maybe an in person option in the Amsterdam area where I could pay to backup the files for a few days? Or is there an alternative I haven't considered? \n\nI had considered something along the lines of shrinking the partiton size, making a new partition in the empty space, copying the data over, then rinse and repeate. But I was considering using zfs with an hba in the new setup instead of a hardware raid card, so I couldn't do that stepwise. But maybe it makes more sense to try this solution in the short term until I need to upgrade again?", "author_fullname": "t2_15kbxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to change file systems without loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lutuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702965589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I am trying to think of a solution for migrating away from Windows because I&amp;#39;m finally no longer locked into their ecosystem. Right now I&amp;#39;m running a hardware raid solution that has 160tb usable and 130 used. I want to get away from Windows but currently the filesystem for the array is GPT with NTFS. I don&amp;#39;t really have a good reason to swap out the drives anytime soon so I was hoping to just backup the data. Is there some solution, maybe an in person option in the Amsterdam area where I could pay to backup the files for a few days? Or is there an alternative I haven&amp;#39;t considered? &lt;/p&gt;\n\n&lt;p&gt;I had considered something along the lines of shrinking the partiton size, making a new partition in the empty space, copying the data over, then rinse and repeate. But I was considering using zfs with an hba in the new setup instead of a hardware raid card, so I couldn&amp;#39;t do that stepwise. But maybe it makes more sense to try this solution in the short term until I need to upgrade again?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lutuc", "is_robot_indexable": true, "report_reasons": null, "author": "ShrodingersElephant", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lutuc/best_way_to_change_file_systems_without_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lutuc/best_way_to_change_file_systems_without_loss/", "subreddit_subscribers": 719249, "created_utc": 1702965589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few TBs of video files that I would like to share with my children. I want to give them both a hard drive with this video content and wanted to know if there was a program that I could put on the HD that, when accessing it either through their TV or computer, has a \"Netflix-style\" interface that would allow them to surf through the content. My thought was that no matter what the HD was plugged into, there would be a self-contained way to easily look through them.\n\nOr is there a better option? I know I can set up a media server that they could access, but my work schedule doesn't allow much extra time to maintain one (besides the fact I have no experience setting up/using one.) ", "author_fullname": "t2_4dezst1g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to organize video files on a hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lpjhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702949272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few TBs of video files that I would like to share with my children. I want to give them both a hard drive with this video content and wanted to know if there was a program that I could put on the HD that, when accessing it either through their TV or computer, has a &amp;quot;Netflix-style&amp;quot; interface that would allow them to surf through the content. My thought was that no matter what the HD was plugged into, there would be a self-contained way to easily look through them.&lt;/p&gt;\n\n&lt;p&gt;Or is there a better option? I know I can set up a media server that they could access, but my work schedule doesn&amp;#39;t allow much extra time to maintain one (besides the fact I have no experience setting up/using one.) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lpjhv", "is_robot_indexable": true, "report_reasons": null, "author": "OldWolfDaddy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lpjhv/software_to_organize_video_files_on_a_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lpjhv/software_to_organize_video_files_on_a_hard_drive/", "subreddit_subscribers": 719249, "created_utc": 1702949272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm running Ubuntu on my homelab server, with a Dell JBOD compatible with SAS drives.  A few months ago I picked up a good deal on a 14 TB IBM E050 drive, and it has worked great. However, I'm trying to set up Scrutiny to monitor all of my drives, and I can't seem to pull any SMART data for this IBM drive.\n\nI have a few other SAS drives and all of them are reading SMART data just fine. smartctl -i  shows that this drive is SMART capable and has SMART enabled.  Trying to run smartctl -t short -C on it shows an error for \"unsupported field in scsi command\".\n\nI suspect there's some extra flags and options for smartmontools that this specific drive may need, but I'm not having much luck finding what it would be. My question isn't specific to Scrutiny as I think the root problem is getting my smartctl flags set up correctly (these can then be customized in Scrutiny).  Months ago I found a post somewhere about this issue specific to IBM drives that talked about the right arguments to use, but now I can't find it. \n\nDoes anyone have experience with SMART monitoring their IBM SAS drives?", "author_fullname": "t2_yumg8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM E050 SAS Drive SMART Data In Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lmnse", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702941360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running Ubuntu on my homelab server, with a Dell JBOD compatible with SAS drives.  A few months ago I picked up a good deal on a 14 TB IBM E050 drive, and it has worked great. However, I&amp;#39;m trying to set up Scrutiny to monitor all of my drives, and I can&amp;#39;t seem to pull any SMART data for this IBM drive.&lt;/p&gt;\n\n&lt;p&gt;I have a few other SAS drives and all of them are reading SMART data just fine. smartctl -i  shows that this drive is SMART capable and has SMART enabled.  Trying to run smartctl -t short -C on it shows an error for &amp;quot;unsupported field in scsi command&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I suspect there&amp;#39;s some extra flags and options for smartmontools that this specific drive may need, but I&amp;#39;m not having much luck finding what it would be. My question isn&amp;#39;t specific to Scrutiny as I think the root problem is getting my smartctl flags set up correctly (these can then be customized in Scrutiny).  Months ago I found a post somewhere about this issue specific to IBM drives that talked about the right arguments to use, but now I can&amp;#39;t find it. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience with SMART monitoring their IBM SAS drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lmnse", "is_robot_indexable": true, "report_reasons": null, "author": "Majoraslayer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lmnse/ibm_e050_sas_drive_smart_data_in_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lmnse/ibm_e050_sas_drive_smart_data_in_linux/", "subreddit_subscribers": 719249, "created_utc": 1702941360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to download every slide from these two presentations as full size images.\n\n[https://www.flynndini.com/the-shadow-king](https://www.flynndini.com/the-shadow-king)\n\nSo far, every technique I have seen online does not work. I do not want to go and download every image manually one by one from its unique link, and I do not want to screenshot every slide either, I want to scrape the entire thing as its original images. Is there any way I can do this?", "author_fullname": "t2_b8qqcytr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download an embedded Google Slide presentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18lm3tk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702939958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to download every slide from these two presentations as full size images.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.flynndini.com/the-shadow-king\"&gt;https://www.flynndini.com/the-shadow-king&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So far, every technique I have seen online does not work. I do not want to go and download every image manually one by one from its unique link, and I do not want to screenshot every slide either, I want to scrape the entire thing as its original images. Is there any way I can do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18lm3tk", "is_robot_indexable": true, "report_reasons": null, "author": "doodlebuuggg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18lm3tk/how_to_download_an_embedded_google_slide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18lm3tk/how_to_download_an_embedded_google_slide/", "subreddit_subscribers": 719249, "created_utc": 1702939958.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}