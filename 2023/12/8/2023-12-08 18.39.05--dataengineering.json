{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My dad is 65 and was laid off about 6 months ago. He has been working in data engineering for over 40 years. He has about 5-15 interviews a week but cannot land a job. Are his skills just outdated in this field? He doesn\u2019t know AWS or cloud and he cannot develop software, he moves data. He says he is an expert in Azure. I\u2019m at a loss on how to help him. His age is working against him and the longer he goes without a job the more hopeless I feel.\n\nETA: Do these types of jobs care about misdemeanors? He has one from 2019 that may also be working against him", "author_fullname": "t2_qhrlh8cu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is AWS/cloud super necessary nowadays?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d288d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701986952.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701974393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad is 65 and was laid off about 6 months ago. He has been working in data engineering for over 40 years. He has about 5-15 interviews a week but cannot land a job. Are his skills just outdated in this field? He doesn\u2019t know AWS or cloud and he cannot develop software, he moves data. He says he is an expert in Azure. I\u2019m at a loss on how to help him. His age is working against him and the longer he goes without a job the more hopeless I feel.&lt;/p&gt;\n\n&lt;p&gt;ETA: Do these types of jobs care about misdemeanors? He has one from 2019 that may also be working against him&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18d288d", "is_robot_indexable": true, "report_reasons": null, "author": "butyoutolerateit5", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d288d/is_awscloud_super_necessary_nowadays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d288d/is_awscloud_super_necessary_nowadays/", "subreddit_subscribers": 144644, "created_utc": 1701974393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI work as a mix of being a data engineer/data analyst and I recently got more into API integration. I was just wondering, if there are any best practices on how.to access data from an API and integrate it into a dwh.\n\nFrom what I found so far on the web, it seems to be either:\nAuthentifcate, Store the json object raw, flatten in the dwh VS. Authentifcate, flatten the json and then store it.\nOn this part I am quite clear and I think it depends on the usecase? However, I am am unsure about the actual way of implementing it, for example in python for a given endpoint:\n\nPy Request (or similar), filter json, write to df, df to SQL/CSV, repeat for pagination.\nAlso where would on put unit tests? During the actual part of accessing the data?\n\nThank you in advance, any tips are welcome.", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice for API data integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dichi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702023901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I work as a mix of being a data engineer/data analyst and I recently got more into API integration. I was just wondering, if there are any best practices on how.to access data from an API and integrate it into a dwh.&lt;/p&gt;\n\n&lt;p&gt;From what I found so far on the web, it seems to be either:\nAuthentifcate, Store the json object raw, flatten in the dwh VS. Authentifcate, flatten the json and then store it.\nOn this part I am quite clear and I think it depends on the usecase? However, I am am unsure about the actual way of implementing it, for example in python for a given endpoint:&lt;/p&gt;\n\n&lt;p&gt;Py Request (or similar), filter json, write to df, df to SQL/CSV, repeat for pagination.\nAlso where would on put unit tests? During the actual part of accessing the data?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance, any tips are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18dichi", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dichi/best_practice_for_api_data_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dichi/best_practice_for_api_data_integration/", "subreddit_subscribers": 144644, "created_utc": 1702023901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've spent a decent amount of time indexing and formatting a lot of machine learning datasets that include images, audio, video, and natural language processing datasets.\n\nI know what's worked well for me in the past in the context of deep learning / machine learning projects, so wanted to propose a simple format that might help us standardize a format for the data with a little more structure. Wouldn't say it is ground breaking, but I feel like could be a good practice.\n\nCurious what this sub thinks or people are actually doing.\n\n[https://blog.oxen.ai/suds-a-guide-to-structuring-unstructured-data/](https://blog.oxen.ai/suds-a-guide-to-structuring-unstructured-data/)\n\nFeedback welcome.", "author_fullname": "t2_90isk4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does everyone store &amp; format unstructured data? ie: images, video, audio, text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18da6yz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701995750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent a decent amount of time indexing and formatting a lot of machine learning datasets that include images, audio, video, and natural language processing datasets.&lt;/p&gt;\n\n&lt;p&gt;I know what&amp;#39;s worked well for me in the past in the context of deep learning / machine learning projects, so wanted to propose a simple format that might help us standardize a format for the data with a little more structure. Wouldn&amp;#39;t say it is ground breaking, but I feel like could be a good practice.&lt;/p&gt;\n\n&lt;p&gt;Curious what this sub thinks or people are actually doing.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.oxen.ai/suds-a-guide-to-structuring-unstructured-data/\"&gt;https://blog.oxen.ai/suds-a-guide-to-structuring-unstructured-data/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feedback welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?auto=webp&amp;s=c943497c778ac2f5e79b9c113170761fe4d2c50c", "width": 1200, "height": 491}, "resolutions": [{"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01a48fc0b679ce69a2336e21564659d2342292a2", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8bb1f1a19a7a6046805ac1c70d92865e08c2d70", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a38f8a031a480face37093a7bef69986f8571af", "width": 320, "height": 130}, {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=309cb9ee732c11b7cc9fb6dea3fd14bd36c887ab", "width": 640, "height": 261}, {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f56f0f1ae55753b60764b2c6182e052bdadb841", "width": 960, "height": 392}, {"url": "https://external-preview.redd.it/XeTZ8ji1IEoEe95mwGST5K-LSA_tnd3_AoH9utpbSy4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4207420c0f1788b55a039463dc01d525bd68ac6f", "width": 1080, "height": 441}], "variants": {}, "id": "_gIuBWYP_0TWrDiVxl5DOnSU1XwCl5oooHzEojxCCKA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18da6yz", "is_robot_indexable": true, "report_reasons": null, "author": "FallMindless3563", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18da6yz/how_does_everyone_store_format_unstructured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18da6yz/how_does_everyone_store_format_unstructured_data/", "subreddit_subscribers": 144644, "created_utc": 1701995750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you\u2019ll employing data contracts in your data pipelines? I\u2019ve seen a lot of system diagrams and articles on it but want to see if theres someone who has implemented data contracts, how they are doing it, and maybe willing to share some of their experience.", "author_fullname": "t2_5cjr5v2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Contracts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dmdx8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702040644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you\u2019ll employing data contracts in your data pipelines? I\u2019ve seen a lot of system diagrams and articles on it but want to see if theres someone who has implemented data contracts, how they are doing it, and maybe willing to share some of their experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18dmdx8", "is_robot_indexable": true, "report_reasons": null, "author": "captut", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dmdx8/data_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dmdx8/data_contracts/", "subreddit_subscribers": 144644, "created_utc": 1702040644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m tasked with modernizing an existing on-prem sql server dw (tabular cube) to cloud dw. Primary drivers are the typical ones including aging hardware and performance issues.\n\nThe data sources are mainly on premise SQL servers, but a number of sources are brought in via API.\n\nThe data is simple as is the end user requirements. Think typical sales and labour reporting. The foot print is small too\u2026 500gb in total (which includes all history going back 20 years). The dw is currently built using Kimball approach.\n\nThere is some desire to eventually use ai and ml to do more advanced analytics, and I think there\u2019s a ton of value going this direction.\n\nI\u2019ve built a POC using fivetran to load raw data into a snowflake db instance and I\u2019ve built views that act similarly to the cubes facts and dimensions using a kimball style approach with clustered indexes on the fields I join. I\u2019ve got users testing out sigma, tableau and PowerBI.\n\nSome questions:\n\n1. Am I oversimplifying this?\n2. Should I be using materialized tables vs views?\n3. What is best practice for dw design in terms of the relational data?\n4. Anything else I\u2019m missing?", "author_fullname": "t2_nuco2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to a cloud dw", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dc5i2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702001773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m tasked with modernizing an existing on-prem sql server dw (tabular cube) to cloud dw. Primary drivers are the typical ones including aging hardware and performance issues.&lt;/p&gt;\n\n&lt;p&gt;The data sources are mainly on premise SQL servers, but a number of sources are brought in via API.&lt;/p&gt;\n\n&lt;p&gt;The data is simple as is the end user requirements. Think typical sales and labour reporting. The foot print is small too\u2026 500gb in total (which includes all history going back 20 years). The dw is currently built using Kimball approach.&lt;/p&gt;\n\n&lt;p&gt;There is some desire to eventually use ai and ml to do more advanced analytics, and I think there\u2019s a ton of value going this direction.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve built a POC using fivetran to load raw data into a snowflake db instance and I\u2019ve built views that act similarly to the cubes facts and dimensions using a kimball style approach with clustered indexes on the fields I join. I\u2019ve got users testing out sigma, tableau and PowerBI.&lt;/p&gt;\n\n&lt;p&gt;Some questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Am I oversimplifying this?&lt;/li&gt;\n&lt;li&gt;Should I be using materialized tables vs views?&lt;/li&gt;\n&lt;li&gt;What is best practice for dw design in terms of the relational data?&lt;/li&gt;\n&lt;li&gt;Anything else I\u2019m missing?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18dc5i2", "is_robot_indexable": true, "report_reasons": null, "author": "2000gt", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dc5i2/moving_to_a_cloud_dw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dc5i2/moving_to_a_cloud_dw/", "subreddit_subscribers": 144644, "created_utc": 1702001773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m teaching a data warehousing course at a state university this next year as an adjunct professor. I work full time as a data engineer. \n\nWe are currently having students build a relational database on an on prem SQL Server that the university hosts as a quick refresher of what they learned in the previous class. For the rest of the class, they use Snowflake and build a kimball style data warehouse with a different dataset. I would love to use the same dataset and somehow ETL the relational database into Snowflake. With limited time in the course and already covering lots of material, i don\u2019t want to spend a ton of time moving the data in a complicated way. Anybody have any ideas for a free ETL tool that can do this? I just want to extract and load and it would be a one time load.\n\nThoughts I\u2019ve already had: Stitch (14 day free trial), talend (outdated but free).", "author_fullname": "t2_bdrvjr4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehousing Class ETL Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dg713", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702015131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m teaching a data warehousing course at a state university this next year as an adjunct professor. I work full time as a data engineer. &lt;/p&gt;\n\n&lt;p&gt;We are currently having students build a relational database on an on prem SQL Server that the university hosts as a quick refresher of what they learned in the previous class. For the rest of the class, they use Snowflake and build a kimball style data warehouse with a different dataset. I would love to use the same dataset and somehow ETL the relational database into Snowflake. With limited time in the course and already covering lots of material, i don\u2019t want to spend a ton of time moving the data in a complicated way. Anybody have any ideas for a free ETL tool that can do this? I just want to extract and load and it would be a one time load.&lt;/p&gt;\n\n&lt;p&gt;Thoughts I\u2019ve already had: Stitch (14 day free trial), talend (outdated but free).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18dg713", "is_robot_indexable": true, "report_reasons": null, "author": "WarthogSwimming8862", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dg713/data_warehousing_class_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dg713/data_warehousing_class_etl_tool/", "subreddit_subscribers": 144644, "created_utc": 1702015131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey, I am in outsourcing company and I was deployed in the Data Engineering Devision in a big tech. Since I didn't have CS degree and this is my first engineering job. I am assigned to a Data Operation Unit. My main task is to transfer CSV files to other devices or tableau. Sometimes I change format excel files to CSV and make sure everything transferred correctly. I barely use Tableau and I rarely write any codes. My team member is writing codes with Spark and write some codes on Jupyter Notebook.  My other task is to check if there are some errors in Airflow and if there are some, my responsibility is to mention and tell that in slack and notify errors to my team.  \n\nI am curious if this is normal for anyone to experience like this. Maybe in the future, they said I might able to touch codes in airflows but I don't exactly know when that happens. \n\nThese being said, I am learning quite lot. I am learning AWS (KES, S3 and EFS), shell commands, crontab, GoogleSpreadsheet, airflows and basic Tableau navigation.. I am really interested in what you guys think and do you think this is a good deal and what kinda career can I purse after this?  Thanks", "author_fullname": "t2_4xluce6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need your guys opinion...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d93dl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701994387.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701992510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey, I am in outsourcing company and I was deployed in the Data Engineering Devision in a big tech. Since I didn&amp;#39;t have CS degree and this is my first engineering job. I am assigned to a Data Operation Unit. My main task is to transfer CSV files to other devices or tableau. Sometimes I change format excel files to CSV and make sure everything transferred correctly. I barely use Tableau and I rarely write any codes. My team member is writing codes with Spark and write some codes on Jupyter Notebook.  My other task is to check if there are some errors in Airflow and if there are some, my responsibility is to mention and tell that in slack and notify errors to my team.  &lt;/p&gt;\n\n&lt;p&gt;I am curious if this is normal for anyone to experience like this. Maybe in the future, they said I might able to touch codes in airflows but I don&amp;#39;t exactly know when that happens. &lt;/p&gt;\n\n&lt;p&gt;These being said, I am learning quite lot. I am learning AWS (KES, S3 and EFS), shell commands, crontab, GoogleSpreadsheet, airflows and basic Tableau navigation.. I am really interested in what you guys think and do you think this is a good deal and what kinda career can I purse after this?  Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18d93dl", "is_robot_indexable": true, "report_reasons": null, "author": "lastsamurai0414", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d93dl/i_need_your_guys_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d93dl/i_need_your_guys_opinion/", "subreddit_subscribers": 144644, "created_utc": 1701992510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey , wondering who has used Snowflake\u2019s Snowpipe feature? Can you vouch for it, or have you had issues?\n\nWe have an extensive glue job and step functions setup for simply copying CSV\u2019s to S3 to Snowflake, but it causes grief, and unnecessary complexity in the debugging process when source CSV\u2019s change etc, causing IT incidents. \n\nWondering if Snowpipe can help by getting the CSV\u2019s directly and how simple it is to implement?\n\nWould love to hear your thoughts on the tool and if it\u2019s been helpful for you at all.", "author_fullname": "t2_jkvzr8r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with Snowpipe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dgo8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702016943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey , wondering who has used Snowflake\u2019s Snowpipe feature? Can you vouch for it, or have you had issues?&lt;/p&gt;\n\n&lt;p&gt;We have an extensive glue job and step functions setup for simply copying CSV\u2019s to S3 to Snowflake, but it causes grief, and unnecessary complexity in the debugging process when source CSV\u2019s change etc, causing IT incidents. &lt;/p&gt;\n\n&lt;p&gt;Wondering if Snowpipe can help by getting the CSV\u2019s directly and how simple it is to implement?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your thoughts on the tool and if it\u2019s been helpful for you at all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18dgo8q", "is_robot_indexable": true, "report_reasons": null, "author": "pbower2049", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/", "subreddit_subscribers": 144644, "created_utc": 1702016943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, everyone! Data analyst-researcher here. \n\nI have the opportunity to create a data engineering mini-project that would greatly benefit me in my current position and is an excellent chance to learn more about this field. I would be delighted to gain some experience in this aspect.\n\nHowever, I need your help to come up with a plan on how to execute this and which (preferably free) tools to use.\n\nThe issue? At work, we perform certain, so-called, measurements twice a year for several years now. Essentially, it's monitoring, and the same variables are tracked. Measurements are conducted on samples of about 10,000 people across several countries.\n\nThis data is stored in a bunch of Excel files (raw data), and some aggregations and analytics are done manually (yeah, I know). Clearly, I would like to put all of this into a data engineering context and potentially speed up and simplify the entire process. It doesn't need to have an \"input\" for new data; I would work only with the existing data for practice.\n\nI would appreciate your help in figuring out how to conceptualize the whole thing:\n\n* Based on my modest knowledge, it would be good to convert all these Excel files into, for example, an SQL database. Am I right? There is already an assigned ID for each entity in the dataset, so I can track respondents over time. Still, I understand that it wouldn't hurt to assign an \"ID\" to each timestamp/measurement, making the main table essentially a \"merge\" of all existing Excel sheets?\n* Then, once the main database is created, I would like to design an ETL process and pipeline. Here, data transformation (formatting, loading) would be beneficial. I understand that Airflow could be useful for this purpose? I'm just not sure about the concept; would ETL extract data from the (initial) database and where would it store the transformed data and in what format? JSON response?\n* In the end, I understand that at least ad-hoc analytics would be useful (e.g., pandas scripts) that would perform specific aggregations and similar tasks, and matplotlib/seaborn for visualization.\n\nI hope this isn't too confusing. I would really appreciate guidance on the technical side and suggestions for tools I can use. I'm already working with Python and would love to take this opportunity to make my job easier and learn something new. Thank you very much!", "author_fullname": "t2_eom50v9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need guidance with my first data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dm0ls", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702039396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone! Data analyst-researcher here. &lt;/p&gt;\n\n&lt;p&gt;I have the opportunity to create a data engineering mini-project that would greatly benefit me in my current position and is an excellent chance to learn more about this field. I would be delighted to gain some experience in this aspect.&lt;/p&gt;\n\n&lt;p&gt;However, I need your help to come up with a plan on how to execute this and which (preferably free) tools to use.&lt;/p&gt;\n\n&lt;p&gt;The issue? At work, we perform certain, so-called, measurements twice a year for several years now. Essentially, it&amp;#39;s monitoring, and the same variables are tracked. Measurements are conducted on samples of about 10,000 people across several countries.&lt;/p&gt;\n\n&lt;p&gt;This data is stored in a bunch of Excel files (raw data), and some aggregations and analytics are done manually (yeah, I know). Clearly, I would like to put all of this into a data engineering context and potentially speed up and simplify the entire process. It doesn&amp;#39;t need to have an &amp;quot;input&amp;quot; for new data; I would work only with the existing data for practice.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate your help in figuring out how to conceptualize the whole thing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Based on my modest knowledge, it would be good to convert all these Excel files into, for example, an SQL database. Am I right? There is already an assigned ID for each entity in the dataset, so I can track respondents over time. Still, I understand that it wouldn&amp;#39;t hurt to assign an &amp;quot;ID&amp;quot; to each timestamp/measurement, making the main table essentially a &amp;quot;merge&amp;quot; of all existing Excel sheets?&lt;/li&gt;\n&lt;li&gt;Then, once the main database is created, I would like to design an ETL process and pipeline. Here, data transformation (formatting, loading) would be beneficial. I understand that Airflow could be useful for this purpose? I&amp;#39;m just not sure about the concept; would ETL extract data from the (initial) database and where would it store the transformed data and in what format? JSON response?&lt;/li&gt;\n&lt;li&gt;In the end, I understand that at least ad-hoc analytics would be useful (e.g., pandas scripts) that would perform specific aggregations and similar tasks, and matplotlib/seaborn for visualization.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I hope this isn&amp;#39;t too confusing. I would really appreciate guidance on the technical side and suggestions for tools I can use. I&amp;#39;m already working with Python and would love to take this opportunity to make my job easier and learn something new. Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18dm0ls", "is_robot_indexable": true, "report_reasons": null, "author": "g4nymede_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dm0ls/need_guidance_with_my_first_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dm0ls/need_guidance_with_my_first_data_engineering/", "subreddit_subscribers": 144644, "created_utc": 1702039396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi \n\nI would like to know in what feature store technology are you using ? And what technology to calculate the features ? Especially when we want to use the features in real time (streaming) inference with low latency. Mostly aggregation features in windows\n\nDoes anyone have an experience with materialized view for aggregation and what are the pros in using it and not doing the calculation outside of the store.", "author_fullname": "t2_j15inhpup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature store for real time inference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dmyjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702042543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;/p&gt;\n\n&lt;p&gt;I would like to know in what feature store technology are you using ? And what technology to calculate the features ? Especially when we want to use the features in real time (streaming) inference with low latency. Mostly aggregation features in windows&lt;/p&gt;\n\n&lt;p&gt;Does anyone have an experience with materialized view for aggregation and what are the pros in using it and not doing the calculation outside of the store.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18dmyjr", "is_robot_indexable": true, "report_reasons": null, "author": "springRock88", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dmyjr/feature_store_for_real_time_inference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dmyjr/feature_store_for_real_time_inference/", "subreddit_subscribers": 144644, "created_utc": 1702042543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, a brief blurb about my background:\n\nAmerican born, but built my career in data across East Asia, getting a late start after switching out of academia/education (I was just working to travel essentially, in my early and mid twenties). I began in the data field about 7 years ago, as an intern, then a data scientist, then a data engineer, then senior, then manager of a team. I gained a ton of knowledge and skills, but my background is highly heterogenous, and I'm a slow thinker and get distracted if someone is staring at me as I try to think through a problem, and so tend to fail live coding sessions (though my on-the-job work more than speaks for itself, with complex systems built, end to end pipelines inclusive of CICD, governance for data sets and resource consumption, strong spark, server, network, and cloud engineering knowledge, but no certifications to \"prove\" it). \n\nI applied for two sure fit positions but got declined for both, the first due to the live coding session (I was sleep deprived due to taking it at like 5am due to time zone differences, that didn't help), then second due perhaps being a manager currently, and getting interviewed by someone at my current organizational level who thought maybe I'm too senior for the kind of grunt work role.\n\nIs it entirely pointless to apply if I can't live code for the life of me, or if I don't have an in in a company, even if I have years of experience at this point and pretty vast knowledge? Or, is applying for IC or senior engineer roles a serious res flag for someone managing a small department of engineers (~20 people plus vendors)?", "author_fullname": "t2_ejt24ok7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice in job hunting in the USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d67f5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701984687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, a brief blurb about my background:&lt;/p&gt;\n\n&lt;p&gt;American born, but built my career in data across East Asia, getting a late start after switching out of academia/education (I was just working to travel essentially, in my early and mid twenties). I began in the data field about 7 years ago, as an intern, then a data scientist, then a data engineer, then senior, then manager of a team. I gained a ton of knowledge and skills, but my background is highly heterogenous, and I&amp;#39;m a slow thinker and get distracted if someone is staring at me as I try to think through a problem, and so tend to fail live coding sessions (though my on-the-job work more than speaks for itself, with complex systems built, end to end pipelines inclusive of CICD, governance for data sets and resource consumption, strong spark, server, network, and cloud engineering knowledge, but no certifications to &amp;quot;prove&amp;quot; it). &lt;/p&gt;\n\n&lt;p&gt;I applied for two sure fit positions but got declined for both, the first due to the live coding session (I was sleep deprived due to taking it at like 5am due to time zone differences, that didn&amp;#39;t help), then second due perhaps being a manager currently, and getting interviewed by someone at my current organizational level who thought maybe I&amp;#39;m too senior for the kind of grunt work role.&lt;/p&gt;\n\n&lt;p&gt;Is it entirely pointless to apply if I can&amp;#39;t live code for the life of me, or if I don&amp;#39;t have an in in a company, even if I have years of experience at this point and pretty vast knowledge? Or, is applying for IC or senior engineer roles a serious res flag for someone managing a small department of engineers (~20 people plus vendors)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18d67f5", "is_robot_indexable": true, "report_reasons": null, "author": "suterebaiiiii", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d67f5/advice_in_job_hunting_in_the_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d67f5/advice_in_job_hunting_in_the_usa/", "subreddit_subscribers": 144644, "created_utc": 1701984687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good evening everyone, I am new to DE amd I would like to know if there's anybook or material I can read to understand how to turn complicated jsons into a dataframe", "author_fullname": "t2_35f1rdk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Api injestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dqs2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702053493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening everyone, I am new to DE amd I would like to know if there&amp;#39;s anybook or material I can read to understand how to turn complicated jsons into a dataframe&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18dqs2z", "is_robot_indexable": true, "report_reasons": null, "author": "Rogie_88", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dqs2z/api_injestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dqs2z/api_injestion/", "subreddit_subscribers": 144644, "created_utc": 1702053493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n(this is my first post on this community!) \n\nI am new in DE and i just working in my final project to 'show it to the world. I know that I probably have flaws in my reasoning or data modeling principles, but I would appreciate anyone who can spare a few minutes to help me.\n\nMy (big) issue is (i am using dbt tool):\n\n1. My fact table \"fct\\_orders\" has a row per product\\_id per order\\_id and most of the sales were made in 2021-02-01, represented by the column \"created\\_at\"::timestamp.\n2. I have a table \"products\" with the columns: product\\_id, name, price\".\n3. I know the price of a product can change, so i want to implement a SCD2 snapshot to track changes in price of the table \"products\".\n4. My goal: display a column with the correct price of a product\\_id in my table \"fct\\_orders\". My plan was to LEFT JOIN the snapshot with the fact table using the following join conditions:\n   1. **\"left join snapshot\\_products f on f.product\\_id = a.product\\_id  AND a.created\\_at BETWEEN f.dbt\\_valid\\_from AND f.dbt\\_valid\\_to** \"\n5. Problem: the columns that the snapshot creates, specially \"dbt\\_valit\\_from\" has a date of 2023-11-11, so i can't use the approach i thougth. So there is a  dbt\\_Valid\\_From date discrepancy with the sales. What approach should i do? \n\nFinal details:\n\n1. i am using the snapshot strategy type \"timestamp\".\n2. there are some way to \"edit\" the column \"dbt\\_valid\\_from\" to start in 2021-01-01 (for example) or it is a wrong think to do?\n\nThanks for your time and patience reading all the post.", "author_fullname": "t2_9fw6zygj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using dbt Snapshot scd2 to allow correct product_price in fact table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dq4aq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702051702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;(this is my first post on this community!) &lt;/p&gt;\n\n&lt;p&gt;I am new in DE and i just working in my final project to &amp;#39;show it to the world. I know that I probably have flaws in my reasoning or data modeling principles, but I would appreciate anyone who can spare a few minutes to help me.&lt;/p&gt;\n\n&lt;p&gt;My (big) issue is (i am using dbt tool):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My fact table &amp;quot;fct_orders&amp;quot; has a row per product_id per order_id and most of the sales were made in 2021-02-01, represented by the column &amp;quot;created_at&amp;quot;::timestamp.&lt;/li&gt;\n&lt;li&gt;I have a table &amp;quot;products&amp;quot; with the columns: product_id, name, price&amp;quot;.&lt;/li&gt;\n&lt;li&gt;I know the price of a product can change, so i want to implement a SCD2 snapshot to track changes in price of the table &amp;quot;products&amp;quot;.&lt;/li&gt;\n&lt;li&gt;My goal: display a column with the correct price of a product_id in my table &amp;quot;fct_orders&amp;quot;. My plan was to LEFT JOIN the snapshot with the fact table using the following join conditions:\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;&amp;quot;left join snapshot_products f on f.product_id = a.product_id  AND a.created_at BETWEEN f.dbt_valid_from AND f.dbt_valid_to&lt;/strong&gt; &amp;quot;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Problem: the columns that the snapshot creates, specially &amp;quot;dbt_valit_from&amp;quot; has a date of 2023-11-11, so i can&amp;#39;t use the approach i thougth. So there is a  dbt_Valid_From date discrepancy with the sales. What approach should i do? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Final details:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;i am using the snapshot strategy type &amp;quot;timestamp&amp;quot;.&lt;/li&gt;\n&lt;li&gt;there are some way to &amp;quot;edit&amp;quot; the column &amp;quot;dbt_valid_from&amp;quot; to start in 2021-01-01 (for example) or it is a wrong think to do?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for your time and patience reading all the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18dq4aq", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful_Place_9816", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dq4aq/using_dbt_snapshot_scd2_to_allow_correct_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dq4aq/using_dbt_snapshot_scd2_to_allow_correct_product/", "subreddit_subscribers": 144644, "created_utc": 1702051702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I have created some data catalog tables in Glue using Terraform but I am now looking for advice on how to maintain them ? Is it a good practice to manage Glue tables using IaC ? If not, what would you advice ? ", "author_fullname": "t2_i9ozc53a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to maintain Glue catalog from source code ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18dibu7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702023820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I have created some data catalog tables in Glue using Terraform but I am now looking for advice on how to maintain them ? Is it a good practice to manage Glue tables using IaC ? If not, what would you advice ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18dibu7", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Evidence2331", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18dibu7/how_to_maintain_glue_catalog_from_source_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18dibu7/how_to_maintain_glue_catalog_from_source_code/", "subreddit_subscribers": 144644, "created_utc": 1702023820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have been working with data for 2.5 years, including 6 months as a Data Engineer trainee and 2 years as a Junior Data Engineer. Although I haven't completed my college degree yet (with another 2 years to go), I am actively seeking local/global remote opportunities in this field. I am based in Brazil but possess advanced English language skills.\n\nI'm curious to know whether it's too early for me to explore such opportunities or if there is a chance for me to secure a global remote position. Any tips or advice for my future career would be greatly appreciated.\n\nCurrently, my work revolves around Python, Pyspark, AWS, SQL, DataStudio(Looker), and Power BI. While my portfolio may not be strong, I'm struggling to come up with project ideas to enhance it. Any suggestions on potential projects to kickstart this improvement process would be valuable.", "author_fullname": "t2_8fsha4lla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with exploring Data Jobs, Seeking Tips and Project Ideas!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d2vf4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701976004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been working with data for 2.5 years, including 6 months as a Data Engineer trainee and 2 years as a Junior Data Engineer. Although I haven&amp;#39;t completed my college degree yet (with another 2 years to go), I am actively seeking local/global remote opportunities in this field. I am based in Brazil but possess advanced English language skills.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to know whether it&amp;#39;s too early for me to explore such opportunities or if there is a chance for me to secure a global remote position. Any tips or advice for my future career would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Currently, my work revolves around Python, Pyspark, AWS, SQL, DataStudio(Looker), and Power BI. While my portfolio may not be strong, I&amp;#39;m struggling to come up with project ideas to enhance it. Any suggestions on potential projects to kickstart this improvement process would be valuable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18d2vf4", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Resident-4200", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d2vf4/i_need_help_with_exploring_data_jobs_seeking_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d2vf4/i_need_help_with_exploring_data_jobs_seeking_tips/", "subreddit_subscribers": 144644, "created_utc": 1701976004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I will give you a background. We are agency and we are integrating Customer Data Platforms like Bloomreach etc. It has its own API on fronend and backend, but when we send documentation and everything we need to integrate project, DEVs on our client side dont know much about it and often they made a solution which is bad - sending bad data to our platform, incorrect types etc and it is real-time, so we cannot change that later.\n\nI want to code tracking by myself, but to make a tracking solution - sending events like cart\\_update, view\\_item etc. Client is happy with this idea, but i dont know how to start and what to do. I think I need to make our new application that will send that, but I dont know how to because all the logic is in code maintained by their DEVS and i willl not be able to change their code.", "author_fullname": "t2_31exp9bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New service for our clients - behavior tracking solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d3ijh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701977713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I will give you a background. We are agency and we are integrating Customer Data Platforms like Bloomreach etc. It has its own API on fronend and backend, but when we send documentation and everything we need to integrate project, DEVs on our client side dont know much about it and often they made a solution which is bad - sending bad data to our platform, incorrect types etc and it is real-time, so we cannot change that later.&lt;/p&gt;\n\n&lt;p&gt;I want to code tracking by myself, but to make a tracking solution - sending events like cart_update, view_item etc. Client is happy with this idea, but i dont know how to start and what to do. I think I need to make our new application that will send that, but I dont know how to because all the logic is in code maintained by their DEVS and i willl not be able to change their code.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18d3ijh", "is_robot_indexable": true, "report_reasons": null, "author": "Sonny-Orkidea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d3ijh/new_service_for_our_clients_behavior_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d3ijh/new_service_for_our_clients_behavior_tracking/", "subreddit_subscribers": 144644, "created_utc": 1701977713.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}