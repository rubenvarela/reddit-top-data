{"kind": "Listing", "data": {"after": "t3_18cqm5q", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep in mind the following when reading about anything tech online lol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_18cj54r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 128, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 128, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eRXOuuSq1JEToL8zZWwv0lwd6L5Mho_KW8RYyxS4xtI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701910021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ny2e7tayrr4c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ny2e7tayrr4c1.png?auto=webp&amp;s=acd89637bc12f77bc45643bc9468ffcc522b7bd6", "width": 556, "height": 286}, "resolutions": [{"url": "https://preview.redd.it/ny2e7tayrr4c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2b2a26f02900a6bec00b8be205667984500da88", "width": 108, "height": 55}, {"url": "https://preview.redd.it/ny2e7tayrr4c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=72611ebfeaf3783ba613b19a91b61052ef6d7ccd", "width": 216, "height": 111}, {"url": "https://preview.redd.it/ny2e7tayrr4c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7a3f2e231d43f3dc47734ffa293a1ddc9a0e4d69", "width": 320, "height": 164}], "variants": {}, "id": "-XEOfbD2MMIbyaGeSeB-AOzP5CCIQXaIvlaPStCbY7E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "18cj54r", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cj54r/keep_in_mind_the_following_when_reading_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ny2e7tayrr4c1.png", "subreddit_subscribers": 144473, "created_utc": 1701910021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fun project: I have created an ETL pipeline that pulls sales from an Adidas xlsx file containing 2020-2021 sales data..I have also created visualizations in PowerBI. One showing all sales data and another Cali sales data, feel free to critique.. \nI am attempting to strengthen my Python skills along with my visualization. Eventually I will make these a bit more complicated. I\u2019m currently trying to make sure I understand all that I am doing before moving on.  Full code is on my GitHub! https://github.com/bfraz33", "author_fullname": "t2_8txv38ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Adidas Sales data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0692atnhzs4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/0692atnhzs4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d6ce00d63c41dced775803103e62e875c155816"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/0692atnhzs4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b776e73a267abf1bdcdb0b8f94842ec9d40e6ab8"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/0692atnhzs4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ad5ed96adc040dfbea93d767309e988b618ffd8"}, {"y": 300, "x": 640, "u": "https://preview.redd.it/0692atnhzs4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1d358052a1c664b1811f87cec4c3dd5d3b19894"}], "s": {"y": 302, "x": 644, "u": "https://preview.redd.it/0692atnhzs4c1.jpg?width=644&amp;format=pjpg&amp;auto=webp&amp;s=7431b05052f59de7df5f8400177d094f4ab87748"}, "id": "0692atnhzs4c1"}, "qh97ctnhzs4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/qh97ctnhzs4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=284f0ec46415067b65bb6b89f661de5f43d2bb20"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/qh97ctnhzs4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40606e54250853fa87e7dd35a73021a5fb0495ce"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/qh97ctnhzs4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2bcc5fbfd991cb059c53c307d7982e370bbdb93f"}], "s": {"y": 1246, "x": 543, "u": "https://preview.redd.it/qh97ctnhzs4c1.jpg?width=543&amp;format=pjpg&amp;auto=webp&amp;s=d269c43252ce4ee96176914f94a80a59cdb67d44"}, "id": "qh97ctnhzs4c1"}, "nrdi9tnhzs4c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/nrdi9tnhzs4c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddb49ff86ae9d483a6f1665549053934997bf00b"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/nrdi9tnhzs4c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3bff4ba961a79f4a4489a0630a3351266637c949"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/nrdi9tnhzs4c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=310ffbde99a92a7a2d6bddf31cc3204c16f23666"}, {"y": 302, "x": 640, "u": "https://preview.redd.it/nrdi9tnhzs4c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc6a4129dee2043227564dd5144d8b0608dc3d68"}], "s": {"y": 302, "x": 640, "u": "https://preview.redd.it/nrdi9tnhzs4c1.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=32c08ac1859f92814b4f2881025c0a35a0bde41f"}, "id": "nrdi9tnhzs4c1"}}, "name": "t3_18cnsae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 54, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "qh97ctnhzs4c1", "id": 370537590}, {"media_id": "0692atnhzs4c1", "id": 370537591}, {"media_id": "nrdi9tnhzs4c1", "id": 370537592}]}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/mpJFuVF45UyKb0Pt6enPoXwi6k75IzWSUEDMizUPdP4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701924552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fun project: I have created an ETL pipeline that pulls sales from an Adidas xlsx file containing 2020-2021 sales data..I have also created visualizations in PowerBI. One showing all sales data and another Cali sales data, feel free to critique.. \nI am attempting to strengthen my Python skills along with my visualization. Eventually I will make these a bit more complicated. I\u2019m currently trying to make sure I understand all that I am doing before moving on.  Full code is on my GitHub! &lt;a href=\"https://github.com/bfraz33\"&gt;https://github.com/bfraz33&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18cnsae", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18cnsae", "is_robot_indexable": true, "report_reasons": null, "author": "Fraiz24", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cnsae/adidas_sales_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18cnsae", "subreddit_subscribers": 144473, "created_utc": 1701924552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This post was getting interesting answers, but OP deleted it. Starting this thread so we can re-start this conversation and save the contributions by multiple community members. (Including mine, that I will repeat below)\n\n/r/dataengineering/comments/18bwe2f/how_do_streaming_aggregation_pipelines_work/\n\nThe question was:\n\nLet's assume we are building a data pipeline for Uber Eats where we keep getting orders. We want a dashboard which shows each restaurant owner\n\n- How many orders?\n- What are the Top 3 ordered dishes (with order count)?\n- What\u2019s the total sale amount?\n\nThere are 3 buttons on the UI which allow the users (restaurant owners) to see these numbers for different time periods:\n\n- Last 1 hour\n- Last 24 hours (= 1 day)\n- Last 168 hours (= 24h * 7 = 1 week)\n\nThe dashboard should get new data every 5 minutes. How do you collect, store and serve data?\n\nMy Solution:We have a Kafka topic which gets all the order events. We have a Flink job with 5 min window which aggregates the data.\n\n\nI am not sure how to go ahead from here. Like how do I store the data efficiently so that it can answer the question from all time periods and the kind of db to use, how to partition etc.", "author_fullname": "t2_3kxbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Streaming Aggregation Pipelines work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ciwxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "#46d160", "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701909585.0, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701909334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post was getting interesting answers, but OP deleted it. Starting this thread so we can re-start this conversation and save the contributions by multiple community members. (Including mine, that I will repeat below)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/r/dataengineering/comments/18bwe2f/how_do_streaming_aggregation_pipelines_work/\"&gt;/r/dataengineering/comments/18bwe2f/how_do_streaming_aggregation_pipelines_work/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The question was:&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we are building a data pipeline for Uber Eats where we keep getting orders. We want a dashboard which shows each restaurant owner&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How many orders?&lt;/li&gt;\n&lt;li&gt;What are the Top 3 ordered dishes (with order count)?&lt;/li&gt;\n&lt;li&gt;What\u2019s the total sale amount?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There are 3 buttons on the UI which allow the users (restaurant owners) to see these numbers for different time periods:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Last 1 hour&lt;/li&gt;\n&lt;li&gt;Last 24 hours (= 1 day)&lt;/li&gt;\n&lt;li&gt;Last 168 hours (= 24h * 7 = 1 week)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The dashboard should get new data every 5 minutes. How do you collect, store and serve data?&lt;/p&gt;\n\n&lt;p&gt;My Solution:We have a Kafka topic which gets all the order events. We have a Flink job with 5 min window which aggregates the data.&lt;/p&gt;\n\n&lt;p&gt;I am not sure how to go ahead from here. Like how do I store the data efficiently so that it can answer the question from all time periods and the kind of db to use, how to partition etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "honorary mod | Snowflake", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ciwxo", "is_robot_indexable": true, "report_reasons": null, "author": "fhoffa", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/18ciwxo/how_do_streaming_aggregation_pipelines_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ciwxo/how_do_streaming_aggregation_pipelines_work/", "subreddit_subscribers": 144473, "created_utc": 1701909334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there\n\nI've embarked on a unique trajectory to write a book in the open. The book lives on [dedp.online](https://www.dedp.online/), you can also find it on [dataengineeringdesignpatterns.com](https://www.dataengineeringdesignpatterns.com), but I like shorter :).\n\nTo be clear, this is just the beginning. But as I'd like to make it a great book, I'd like to strive for feedback early on, so I decided to share it with you. The latest changes are documented in the changelog.\n\nThe online book is entirely free to read.\n\n## What does the book contain as of now?\n\nYou might wonder if it's worth delving into the book in its current, unfinished form. Well, it depends.There's already a wealth of content. However, the much-anticipated design patterns are still in the works. Suppose that's what you're most excited about. In that case, you'll find the beginnings of exploring the patterns of `Caching` and `Ad-hoc Querying` in the first Convergent Evolution chapter, covering \"BI vs. Semantic Layer vs. Modern OLAP vs. Data Virtualization\".\n\n## The Content\n\nAs of now, the book offers:\n\n* The outline of the book: What it is all about (to keep you excited \ud83d\ude09)\n* Introduction to the Field of Data Engineering with the history and state of DE and challenges along the data engineering lifecycle.\n* Introduction to Data Engineering Design Patterns (DEDP) with the critical starting point with Convergent Evolution and what it is.\n* An overview of some of the patterns and design patterns that forked from the Convergent Evolutions\n* The first is an analysis of four terms that form a Convergent Evolution and their patterns.\n\n## Bonus\n\nIn addition, I've enriched my second brain with sixty new terms, creating a valuable resource for anyone in data engineering. Explore this at [Second Brain](https://brain.ssp.sh/).\n\n## Seeking your early feedback\n\nYour critiques, suggestions, and questions are very welcome. This book has just started, but it may spark some thoughts, ideas, and terms you heard repeatedly. This feedback I'd super appreciate featuring it in my book.\n\nI am looking forward to your honest and constructive feedback. Things will change and hopefully improve.\n\nThanks.", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Living Book on Data Engineering Design Patterns - Feedback Welcome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cxamc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701960835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve embarked on a unique trajectory to write a book in the open. The book lives on &lt;a href=\"https://www.dedp.online/\"&gt;dedp.online&lt;/a&gt;, you can also find it on &lt;a href=\"https://www.dataengineeringdesignpatterns.com\"&gt;dataengineeringdesignpatterns.com&lt;/a&gt;, but I like shorter :).&lt;/p&gt;\n\n&lt;p&gt;To be clear, this is just the beginning. But as I&amp;#39;d like to make it a great book, I&amp;#39;d like to strive for feedback early on, so I decided to share it with you. The latest changes are documented in the changelog.&lt;/p&gt;\n\n&lt;p&gt;The online book is entirely free to read.&lt;/p&gt;\n\n&lt;h2&gt;What does the book contain as of now?&lt;/h2&gt;\n\n&lt;p&gt;You might wonder if it&amp;#39;s worth delving into the book in its current, unfinished form. Well, it depends.There&amp;#39;s already a wealth of content. However, the much-anticipated design patterns are still in the works. Suppose that&amp;#39;s what you&amp;#39;re most excited about. In that case, you&amp;#39;ll find the beginnings of exploring the patterns of &lt;code&gt;Caching&lt;/code&gt; and &lt;code&gt;Ad-hoc Querying&lt;/code&gt; in the first Convergent Evolution chapter, covering &amp;quot;BI vs. Semantic Layer vs. Modern OLAP vs. Data Virtualization&amp;quot;.&lt;/p&gt;\n\n&lt;h2&gt;The Content&lt;/h2&gt;\n\n&lt;p&gt;As of now, the book offers:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The outline of the book: What it is all about (to keep you excited \ud83d\ude09)&lt;/li&gt;\n&lt;li&gt;Introduction to the Field of Data Engineering with the history and state of DE and challenges along the data engineering lifecycle.&lt;/li&gt;\n&lt;li&gt;Introduction to Data Engineering Design Patterns (DEDP) with the critical starting point with Convergent Evolution and what it is.&lt;/li&gt;\n&lt;li&gt;An overview of some of the patterns and design patterns that forked from the Convergent Evolutions&lt;/li&gt;\n&lt;li&gt;The first is an analysis of four terms that form a Convergent Evolution and their patterns.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Bonus&lt;/h2&gt;\n\n&lt;p&gt;In addition, I&amp;#39;ve enriched my second brain with sixty new terms, creating a valuable resource for anyone in data engineering. Explore this at &lt;a href=\"https://brain.ssp.sh/\"&gt;Second Brain&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2&gt;Seeking your early feedback&lt;/h2&gt;\n\n&lt;p&gt;Your critiques, suggestions, and questions are very welcome. This book has just started, but it may spark some thoughts, ideas, and terms you heard repeatedly. This feedback I&amp;#39;d super appreciate featuring it in my book.&lt;/p&gt;\n\n&lt;p&gt;I am looking forward to your honest and constructive feedback. Things will change and hopefully improve.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?auto=webp&amp;s=8999b2b201ee737220ac1d188d5c323e6f76a3dc", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=96ed6244af0fdd5c5e9cd44bf4f7f472614a3379", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e699f7eee5a3caa3f37e3d341b901c0bd8886390", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebc5b7e6692bd5cce07aa3c4564c3438b4ddc45a", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4160381e4dc35539638f45b8c74163695d37770", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/nX11obwAu8YGj6KvhTJsdq9QhuxPp929ZK3jmqLqaUo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=984840a34173c717d34e4f3860408391f0502dc2", "width": 960, "height": 960}], "variants": {}, "id": "ZxGWGXDif7U8OZj2xEZ9uinreNiBy6Z4EtOatirwLwk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18cxamc", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18cxamc/living_book_on_data_engineering_design_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cxamc/living_book_on_data_engineering_design_patterns/", "subreddit_subscribers": 144473, "created_utc": 1701960835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you all instill more trust in data quality / etl pipelines in your end users?  This is a commonly occuring example of what I mean.\n\nA senior manager will be using our BI tool (Looker) to explore data, and see a 50% drop in customer usage of a specific feature in our product. In turn, they email me and say the data can't possibly be right, something's broken in the etl, can you look? We have set up pretty robust error handling, monitoring and alerting for all of our pipelines, so 99% of the time, the issue isn't in the etl layer. Either the data is correct and there actually was a 50% drop in usage for that feature, or the upstream modeling in the BI tool is defined incorrectly.  \n\nEither way, it takes time to debug the crappy BI modeling, or chase down business reasons for why that drop in feature usage occured (like deprecating that product feature in a new release, prod eng developing a new feature that does the same thing but better, etc).\n\nSo how do you all handle a general mistrust of the etl pipelines specifically, and the quality / integrity of data in general? TIA", "author_fullname": "t2_peqq109ch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My biggest issue in data engineering is end users trusting the integrity of the data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cgeoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701902417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you all instill more trust in data quality / etl pipelines in your end users?  This is a commonly occuring example of what I mean.&lt;/p&gt;\n\n&lt;p&gt;A senior manager will be using our BI tool (Looker) to explore data, and see a 50% drop in customer usage of a specific feature in our product. In turn, they email me and say the data can&amp;#39;t possibly be right, something&amp;#39;s broken in the etl, can you look? We have set up pretty robust error handling, monitoring and alerting for all of our pipelines, so 99% of the time, the issue isn&amp;#39;t in the etl layer. Either the data is correct and there actually was a 50% drop in usage for that feature, or the upstream modeling in the BI tool is defined incorrectly.  &lt;/p&gt;\n\n&lt;p&gt;Either way, it takes time to debug the crappy BI modeling, or chase down business reasons for why that drop in feature usage occured (like deprecating that product feature in a new release, prod eng developing a new feature that does the same thing but better, etc).&lt;/p&gt;\n\n&lt;p&gt;So how do you all handle a general mistrust of the etl pipelines specifically, and the quality / integrity of data in general? TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18cgeoh", "is_robot_indexable": true, "report_reasons": null, "author": "No-Support4478", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cgeoh/my_biggest_issue_in_data_engineering_is_end_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cgeoh/my_biggest_issue_in_data_engineering_is_end_users/", "subreddit_subscribers": 144473, "created_utc": 1701902417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello \ud83e\udd17\n\nLately I've been really interested in the topic of virtual data warehouses (what I understand are 'lake houses' - virtual data models built on top of a data lake).\n\nI'm looking for a solid reference (like Kimball on Dimensional Modeling) to know more about this.\n\nI am specifically interested in the practical part : best practices, examples of scripts, detailed use cases with a lot of explaination, implementation frameworks, how to manage SCD, snapshoting, etc \n\nDo you know what would be a good reference?\n\nThank you !", "author_fullname": "t2_rz2xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a good book on virtual DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cfxqv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701901141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello \ud83e\udd17&lt;/p&gt;\n\n&lt;p&gt;Lately I&amp;#39;ve been really interested in the topic of virtual data warehouses (what I understand are &amp;#39;lake houses&amp;#39; - virtual data models built on top of a data lake).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a solid reference (like Kimball on Dimensional Modeling) to know more about this.&lt;/p&gt;\n\n&lt;p&gt;I am specifically interested in the practical part : best practices, examples of scripts, detailed use cases with a lot of explaination, implementation frameworks, how to manage SCD, snapshoting, etc &lt;/p&gt;\n\n&lt;p&gt;Do you know what would be a good reference?&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18cfxqv", "is_robot_indexable": true, "report_reasons": null, "author": "Ownards", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cfxqv/looking_for_a_good_book_on_virtual_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cfxqv/looking_for_a_good_book_on_virtual_dwh/", "subreddit_subscribers": 144473, "created_utc": 1701901141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My dad is 65 and was laid off about 6 months ago. He has been working in data engineering for over 40 years. He has about 5-15 interviews a week but cannot land a job. Are his skills just outdated in this field? He doesn\u2019t know AWS or cloud and he cannot develop software, he moves data. He says he is an expert in Azure. I\u2019m at a loss on how to help him. His age is working against him and the longer he goes without a job the more hopeless I feel.\n\nETA: Do these types of jobs care about misdemeanors? He has one from 2019 that may also be working against him", "author_fullname": "t2_qhrlh8cu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is AWS/cloud super necessary nowadays?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d288d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701986952.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701974393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad is 65 and was laid off about 6 months ago. He has been working in data engineering for over 40 years. He has about 5-15 interviews a week but cannot land a job. Are his skills just outdated in this field? He doesn\u2019t know AWS or cloud and he cannot develop software, he moves data. He says he is an expert in Azure. I\u2019m at a loss on how to help him. His age is working against him and the longer he goes without a job the more hopeless I feel.&lt;/p&gt;\n\n&lt;p&gt;ETA: Do these types of jobs care about misdemeanors? He has one from 2019 that may also be working against him&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18d288d", "is_robot_indexable": true, "report_reasons": null, "author": "butyoutolerateit5", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d288d/is_awscloud_super_necessary_nowadays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d288d/is_awscloud_super_necessary_nowadays/", "subreddit_subscribers": 144473, "created_utc": 1701974393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bxjjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started With PyFlink on Kubernetes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18cz7r2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bhX9PYCJCqpsJj2lh-PZgF2Gq5bdY8Oz5muM3t0qN-A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701966114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decodable.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decodable.co/blog/getting-started-with-pyflink-on-kubernetes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?auto=webp&amp;s=831389fa48a24495f60e6f68edd63d48ad8f517f", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80e15bb4ef364f9bcd5852161edb07ba9e6ba065", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=32c209dab3bd3e2f97d047e2652683792b4059d2", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b0dd9e2160c381e9ba497f84e8f5ecfe64caf56", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4ee0cdf0c6b83418250a39d1a01e1c1ed77851b", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/pU_0dlJ8oH0FWaQsTgztQ6T7uOccZw-K1RDvyoDqfGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d151a97f053c94523341036babb61028053e444", "width": 960, "height": 960}], "variants": {}, "id": "1OkrA8L99fPhROo50RLnWcieIM4ToyQ19H7HTlAu8s8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18cz7r2", "is_robot_indexable": true, "report_reasons": null, "author": "gunnarmorling", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cz7r2/getting_started_with_pyflink_on_kubernetes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decodable.co/blog/getting-started-with-pyflink-on-kubernetes", "subreddit_subscribers": 144473, "created_utc": 1701966114.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've been setting up DAGs for my company for a while now using mostly Dagster, Pandas, BigQuery and DBT. It's been working OK but I keep feeling like the by far most common bug/timesink I encounter are debugging pandas type conversions before it enters into BQ. Great fun.\n\nThe problem I have right now is that I'm working with integer data that can be null in the API, but when I start working with pandas it automatically casts this to floats and things start getting a bit funky. Integer ID's suddenly have an extra .0 after it, or rows that where empty suddenly contain zeros or something. \n\nWhat am I missing? What do you guys like working with? Or is pandas a good solution and there are ways to improve the workflow? Thanks!", "author_fullname": "t2_t1xeu37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I use instead of Pandas for data ingestion/cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cxnsk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701961848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been setting up DAGs for my company for a while now using mostly Dagster, Pandas, BigQuery and DBT. It&amp;#39;s been working OK but I keep feeling like the by far most common bug/timesink I encounter are debugging pandas type conversions before it enters into BQ. Great fun.&lt;/p&gt;\n\n&lt;p&gt;The problem I have right now is that I&amp;#39;m working with integer data that can be null in the API, but when I start working with pandas it automatically casts this to floats and things start getting a bit funky. Integer ID&amp;#39;s suddenly have an extra .0 after it, or rows that where empty suddenly contain zeros or something. &lt;/p&gt;\n\n&lt;p&gt;What am I missing? What do you guys like working with? Or is pandas a good solution and there are ways to improve the workflow? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18cxnsk", "is_robot_indexable": true, "report_reasons": null, "author": "Fox_News_Shill", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cxnsk/what_should_i_use_instead_of_pandas_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cxnsk/what_should_i_use_instead_of_pandas_for_data/", "subreddit_subscribers": 144473, "created_utc": 1701961848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Has anyone been successfully placed as a Data Engineering manager in the past 4 to 5 months ? I see positions open for a long time. I am located in the Chicago region. My background includes initial 12 years in Data Engineering and the past 3 years in project management related to Data Engineering and Web development projects. I receive calls when I apply for full-time DE Manager positions, but either they go on hold, or I am informed that the position is canceled. Additionally, I believe I need my profile and interview techniques evaluated. I have heard a lot about Interview Quickstart, but it is terribly expensive, around 10k USD. Are there any other recommendations that can help me prepare for a DE Manager role or, in the future, a DE Director role? ", "author_fullname": "t2_a55amval", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prepare and apply for Data Engineering manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cl6pd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701916209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone been successfully placed as a Data Engineering manager in the past 4 to 5 months ? I see positions open for a long time. I am located in the Chicago region. My background includes initial 12 years in Data Engineering and the past 3 years in project management related to Data Engineering and Web development projects. I receive calls when I apply for full-time DE Manager positions, but either they go on hold, or I am informed that the position is canceled. Additionally, I believe I need my profile and interview techniques evaluated. I have heard a lot about Interview Quickstart, but it is terribly expensive, around 10k USD. Are there any other recommendations that can help me prepare for a DE Manager role or, in the future, a DE Director role? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18cl6pd", "is_robot_indexable": true, "report_reasons": null, "author": "No-Competition729", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cl6pd/prepare_and_apply_for_data_engineering_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cl6pd/prepare_and_apply_for_data_engineering_manager/", "subreddit_subscribers": 144473, "created_utc": 1701916209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Background**\n\nMy enterprise is undergoing a massive modernization where we are moving our 14+ databases from 2 On Prem servers and SAS to Azure Synapse pipelines and delta+serverless /dedicated pools for ( bronze/silver/gold data layers).\n\nEarly on, it was decided that all of the 20/30 databases would be orchestrated by 1 synapse workspace, 1 storage account and 1 dedicated pool.\n\nWe built 3 environments ( dev, uat, prod) and 3 CI/CD pipelines ( workspace, serverless, dedicated SQL) using YAML ( and PowerShell for serverless) to build and release to the respective environments using AzureDevOps.\n\n**Problem**\n\nThe architecture has had great success so far. However, now that the lift and shift is really picking up momentum, we have 12+ devs working collaboratively on different projects, with the codes going to the same code base. Our release cycle changed from once a week to on demand due to the high number of requests.\n\nNow the Development managers are asking that we allow partial deployments of the code, as UAT cycles dont perfectly overlap and they dont want code for certain projects getting stuck in UAT for longer than it needs to, because one of the UAT projects is not ready to go to prod. They are asking for partial deployments.\n\n**My perspective**\n\nI have strongly opposed this, and explained that this isnt possible without manual script executions and live env changes (in technical terms). \n\n**Questions**\n\n* Has anyone gone through this kind of request?\n*  Is there actually a way to run partial deployments that I'm not aware of?\n*  How do we explain this in business terms? \n* What alternatives can be provided to help the dev teams deliver without breaking the CI/CD validation benefits ?", "author_fullname": "t2_f8hvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partial Deployments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d13h9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701971227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My enterprise is undergoing a massive modernization where we are moving our 14+ databases from 2 On Prem servers and SAS to Azure Synapse pipelines and delta+serverless /dedicated pools for ( bronze/silver/gold data layers).&lt;/p&gt;\n\n&lt;p&gt;Early on, it was decided that all of the 20/30 databases would be orchestrated by 1 synapse workspace, 1 storage account and 1 dedicated pool.&lt;/p&gt;\n\n&lt;p&gt;We built 3 environments ( dev, uat, prod) and 3 CI/CD pipelines ( workspace, serverless, dedicated SQL) using YAML ( and PowerShell for serverless) to build and release to the respective environments using AzureDevOps.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The architecture has had great success so far. However, now that the lift and shift is really picking up momentum, we have 12+ devs working collaboratively on different projects, with the codes going to the same code base. Our release cycle changed from once a week to on demand due to the high number of requests.&lt;/p&gt;\n\n&lt;p&gt;Now the Development managers are asking that we allow partial deployments of the code, as UAT cycles dont perfectly overlap and they dont want code for certain projects getting stuck in UAT for longer than it needs to, because one of the UAT projects is not ready to go to prod. They are asking for partial deployments.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My perspective&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have strongly opposed this, and explained that this isnt possible without manual script executions and live env changes (in technical terms). &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Has anyone gone through this kind of request?&lt;/li&gt;\n&lt;li&gt; Is there actually a way to run partial deployments that I&amp;#39;m not aware of?&lt;/li&gt;\n&lt;li&gt; How do we explain this in business terms? &lt;/li&gt;\n&lt;li&gt;What alternatives can be provided to help the dev teams deliver without breaking the CI/CD validation benefits ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18d13h9", "is_robot_indexable": true, "report_reasons": null, "author": "Mefsha5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d13h9/partial_deployments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d13h9/partial_deployments/", "subreddit_subscribers": 144473, "created_utc": 1701971227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been messing around with Meltano recently and have been quite impressed. The yaml file structure sells it for me and baking in DBT directly into the same repo is pretty slick as well.\n\nOne thing that is bugging the heck out of me is the lack of a clean way to load assets from Meltano to be orchestrated by Dagster. The online help I have found has been outdated or bug ridden. I know Meltano suggests using Airflow but I want to avoid using Airflow as much as possible.\n\nAnyone have recommendations for a repo they have found similar to the above?", "author_fullname": "t2_d56f4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demo Meltano/DBT/Dagster Repo or Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cyfc8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701963959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been messing around with Meltano recently and have been quite impressed. The yaml file structure sells it for me and baking in DBT directly into the same repo is pretty slick as well.&lt;/p&gt;\n\n&lt;p&gt;One thing that is bugging the heck out of me is the lack of a clean way to load assets from Meltano to be orchestrated by Dagster. The online help I have found has been outdated or bug ridden. I know Meltano suggests using Airflow but I want to avoid using Airflow as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Anyone have recommendations for a repo they have found similar to the above?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18cyfc8", "is_robot_indexable": true, "report_reasons": null, "author": "mowmail", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cyfc8/demo_meltanodbtdagster_repo_or_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cyfc8/demo_meltanodbtdagster_repo_or_project/", "subreddit_subscribers": 144473, "created_utc": 1701963959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need help finding tools for managing data in a weather/climate research setting. I am looking for a dashboard/management database that lets me track/manage my datasets, assign post-processing scripts to them, attach relevant model configuration files. My overall data size varies from several GB to ~100Tb. Most of the data are coming from m I work for a university so something that runs locally on linux is ideal. I am pretty motivated to get something like this implemented if push comes to shove on using a cloud service.  \n\n\n  \nCurrently I just use folders names to manage the data, but when one is generating lots of data using weather and climate models, it's easy to lose track of things. I am happy to answer questions if more information is needed. Thank you!", "author_fullname": "t2_bf1rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data management/workflow for weather/climate/geospatial?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cglbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701902917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need help finding tools for managing data in a weather/climate research setting. I am looking for a dashboard/management database that lets me track/manage my datasets, assign post-processing scripts to them, attach relevant model configuration files. My overall data size varies from several GB to ~100Tb. Most of the data are coming from m I work for a university so something that runs locally on linux is ideal. I am pretty motivated to get something like this implemented if push comes to shove on using a cloud service.  &lt;/p&gt;\n\n&lt;p&gt;Currently I just use folders names to manage the data, but when one is generating lots of data using weather and climate models, it&amp;#39;s easy to lose track of things. I am happy to answer questions if more information is needed. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18cglbu", "is_robot_indexable": true, "report_reasons": null, "author": "gbromley", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cglbu/data_managementworkflow_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cglbu/data_managementworkflow_for/", "subreddit_subscribers": 144473, "created_utc": 1701902917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, a brief blurb about my background:\n\nAmerican born, but built my career in data across East Asia, getting a late start after switching out of academia/education (I was just working to travel essentially, in my early and mid twenties). I began in the data field about 7 years ago, as an intern, then a data scientist, then a data engineer, then senior, then manager of a team. I gained a ton of knowledge and skills, but my background is highly heterogenous, and I'm a slow thinker and get distracted if someone is staring at me as I try to think through a problem, and so tend to fail live coding sessions (though my on-the-job work more than speaks for itself, with complex systems built, end to end pipelines inclusive of CICD, governance for data sets and resource consumption, strong spark, server, network, and cloud engineering knowledge, but no certifications to \"prove\" it). \n\nI applied for two sure fit positions but got declined for both, the first due to the live coding session (I was sleep deprived due to taking it at like 5am due to time zone differences, that didn't help), then second due perhaps being a manager currently, and getting interviewed by someone at my current organizational level who thought maybe I'm too senior for the kind of grunt work role.\n\nIs it entirely pointless to apply if I can't live code for the life of me, or if I don't have an in in a company, even if I have years of experience at this point and pretty vast knowledge? Or, is applying for IC or senior engineer roles a serious res flag for someone managing a small department of engineers (~20 people plus vendors)?", "author_fullname": "t2_ejt24ok7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice in job hunting in the USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18d67f5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701984687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, a brief blurb about my background:&lt;/p&gt;\n\n&lt;p&gt;American born, but built my career in data across East Asia, getting a late start after switching out of academia/education (I was just working to travel essentially, in my early and mid twenties). I began in the data field about 7 years ago, as an intern, then a data scientist, then a data engineer, then senior, then manager of a team. I gained a ton of knowledge and skills, but my background is highly heterogenous, and I&amp;#39;m a slow thinker and get distracted if someone is staring at me as I try to think through a problem, and so tend to fail live coding sessions (though my on-the-job work more than speaks for itself, with complex systems built, end to end pipelines inclusive of CICD, governance for data sets and resource consumption, strong spark, server, network, and cloud engineering knowledge, but no certifications to &amp;quot;prove&amp;quot; it). &lt;/p&gt;\n\n&lt;p&gt;I applied for two sure fit positions but got declined for both, the first due to the live coding session (I was sleep deprived due to taking it at like 5am due to time zone differences, that didn&amp;#39;t help), then second due perhaps being a manager currently, and getting interviewed by someone at my current organizational level who thought maybe I&amp;#39;m too senior for the kind of grunt work role.&lt;/p&gt;\n\n&lt;p&gt;Is it entirely pointless to apply if I can&amp;#39;t live code for the life of me, or if I don&amp;#39;t have an in in a company, even if I have years of experience at this point and pretty vast knowledge? Or, is applying for IC or senior engineer roles a serious res flag for someone managing a small department of engineers (~20 people plus vendors)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18d67f5", "is_robot_indexable": true, "report_reasons": null, "author": "suterebaiiiii", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d67f5/advice_in_job_hunting_in_the_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d67f5/advice_in_job_hunting_in_the_usa/", "subreddit_subscribers": 144473, "created_utc": 1701984687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have been working with data for 2.5 years, including 6 months as a Data Engineer trainee and 2 years as a Junior Data Engineer. Although I haven't completed my college degree yet (with another 2 years to go), I am actively seeking local/global remote opportunities in this field. I am based in Brazil but possess advanced English language skills.\n\nI'm curious to know whether it's too early for me to explore such opportunities or if there is a chance for me to secure a global remote position. Any tips or advice for my future career would be greatly appreciated.\n\nCurrently, my work revolves around Python, Pyspark, AWS, SQL, DataStudio(Looker), and Power BI. While my portfolio may not be strong, I'm struggling to come up with project ideas to enhance it. Any suggestions on potential projects to kickstart this improvement process would be valuable.", "author_fullname": "t2_8fsha4lla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with exploring Data Jobs, Seeking Tips and Project Ideas!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d2vf4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701976004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been working with data for 2.5 years, including 6 months as a Data Engineer trainee and 2 years as a Junior Data Engineer. Although I haven&amp;#39;t completed my college degree yet (with another 2 years to go), I am actively seeking local/global remote opportunities in this field. I am based in Brazil but possess advanced English language skills.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to know whether it&amp;#39;s too early for me to explore such opportunities or if there is a chance for me to secure a global remote position. Any tips or advice for my future career would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Currently, my work revolves around Python, Pyspark, AWS, SQL, DataStudio(Looker), and Power BI. While my portfolio may not be strong, I&amp;#39;m struggling to come up with project ideas to enhance it. Any suggestions on potential projects to kickstart this improvement process would be valuable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18d2vf4", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Resident-4200", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d2vf4/i_need_help_with_exploring_data_jobs_seeking_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d2vf4/i_need_help_with_exploring_data_jobs_seeking_tips/", "subreddit_subscribers": 144473, "created_utc": 1701976004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you all handle non standard features  in your pipelines? I am doing a mix of if else statements, config files and parameters stored in db. Still everything seems overwhelming.", "author_fullname": "t2_l5b7eg3m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non standard things in your pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d0u5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701970519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you all handle non standard features  in your pipelines? I am doing a mix of if else statements, config files and parameters stored in db. Still everything seems overwhelming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18d0u5s", "is_robot_indexable": true, "report_reasons": null, "author": "BetResponsible4418", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d0u5s/non_standard_things_in_your_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d0u5s/non_standard_things_in_your_pipeline/", "subreddit_subscribers": 144473, "created_utc": 1701970519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to be able to cross-reference events from different audit subsystems with alerts from different security solutions (e.g. endpoint protection controls like EDR or network protection controls like IPS), and am wondering if DuckDB + dbt would be a good combination of tools to use for this purpose.\n\nI'd like to be able to perform event correlation either online or offline, and if possible, don't want to spin up a database server so test results can be broadly shared through whatever channels make sense to the end user (e.g. a local directory, SMB, S3, OneDrive, etc.)\n\nOriginally, I was thinking of doing this in Redis, or using Trino, but, then I discovered DuckDB, and, I like it.\n\nIf I were to use DuckDB + dbt to perform event correlation, how could I actually trigger the data pipelines?\n\nI'm thinking of using something like inotify locally, and something like AWS Lambda, S3, and SNS in AWS, but, maybe there's a better option?\n\nI like the idea of using SeaweedFS as an intermediate layer with object write [notifications](https://github.com/seaweedfs/seaweedfs/tree/master/weed/notification) going to SQS, RabbitMQ, or a local file, which could also allow me to observe the changes to different files through a metric collection layer like Prometheus and Grafana.\n\nWhen it comes to orchestration, Dagster seems cool, but, I'm not sure if it'd work locally, in an airgapped environment, etc. (I'm working with ransomware, worms, etc.).\n\nThe pipeline is basically:\n\n* Stream events from different audit sources into a sensor written in Go\n* Normalize the events within the sensor (e.g. translate events from Windows Event Log into process start/stop events)\n* Write events to a directory\n* Stream alerts from different alert sources using serverless functions written in Python\n* Write alerts to a directory\n* Create a materialized view that contains a list of all processes forming a given process tree\n* Cross-reference alerts with any process in the process tree to determine which processes produced alerts\n\nIt's necessary to reconstruct the process tree so I can identify alerts related to the descendants of a given child process (e.g. a command that detonates ransomware).", "author_fullname": "t2_lwr1wvz8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB + dbt for a serverless event correlation pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cymev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701965532.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701964515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to be able to cross-reference events from different audit subsystems with alerts from different security solutions (e.g. endpoint protection controls like EDR or network protection controls like IPS), and am wondering if DuckDB + dbt would be a good combination of tools to use for this purpose.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to perform event correlation either online or offline, and if possible, don&amp;#39;t want to spin up a database server so test results can be broadly shared through whatever channels make sense to the end user (e.g. a local directory, SMB, S3, OneDrive, etc.)&lt;/p&gt;\n\n&lt;p&gt;Originally, I was thinking of doing this in Redis, or using Trino, but, then I discovered DuckDB, and, I like it.&lt;/p&gt;\n\n&lt;p&gt;If I were to use DuckDB + dbt to perform event correlation, how could I actually trigger the data pipelines?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of using something like inotify locally, and something like AWS Lambda, S3, and SNS in AWS, but, maybe there&amp;#39;s a better option?&lt;/p&gt;\n\n&lt;p&gt;I like the idea of using SeaweedFS as an intermediate layer with object write &lt;a href=\"https://github.com/seaweedfs/seaweedfs/tree/master/weed/notification\"&gt;notifications&lt;/a&gt; going to SQS, RabbitMQ, or a local file, which could also allow me to observe the changes to different files through a metric collection layer like Prometheus and Grafana.&lt;/p&gt;\n\n&lt;p&gt;When it comes to orchestration, Dagster seems cool, but, I&amp;#39;m not sure if it&amp;#39;d work locally, in an airgapped environment, etc. (I&amp;#39;m working with ransomware, worms, etc.).&lt;/p&gt;\n\n&lt;p&gt;The pipeline is basically:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stream events from different audit sources into a sensor written in Go&lt;/li&gt;\n&lt;li&gt;Normalize the events within the sensor (e.g. translate events from Windows Event Log into process start/stop events)&lt;/li&gt;\n&lt;li&gt;Write events to a directory&lt;/li&gt;\n&lt;li&gt;Stream alerts from different alert sources using serverless functions written in Python&lt;/li&gt;\n&lt;li&gt;Write alerts to a directory&lt;/li&gt;\n&lt;li&gt;Create a materialized view that contains a list of all processes forming a given process tree&lt;/li&gt;\n&lt;li&gt;Cross-reference alerts with any process in the process tree to determine which processes produced alerts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It&amp;#39;s necessary to reconstruct the process tree so I can identify alerts related to the descendants of a given child process (e.g. a command that detonates ransomware).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lbat6Ay_WjUPuejj9f72QN-qLCNXvIl2Om2nGp4wC8I.jpg?auto=webp&amp;s=406f3edc1cce3e62958688e31cec3561632ea19a", "width": 437, "height": 437}, "resolutions": [{"url": "https://external-preview.redd.it/Lbat6Ay_WjUPuejj9f72QN-qLCNXvIl2Om2nGp4wC8I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=239fcbfe6466fb3698553bdbb13e1103ac7f3f74", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Lbat6Ay_WjUPuejj9f72QN-qLCNXvIl2Om2nGp4wC8I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=436cab45737d55008f173999f33f928c46311c19", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Lbat6Ay_WjUPuejj9f72QN-qLCNXvIl2Om2nGp4wC8I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7698b035832dcb22b485c2a0dc32213e0680efa5", "width": 320, "height": 320}], "variants": {}, "id": "FQeVW-uG_jVwW31yLJzth5utdtMXvjEul4hfAofUbgw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18cymev", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Importance-1605", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cymev/duckdb_dbt_for_a_serverless_event_correlation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cymev/duckdb_dbt_for_a_serverless_event_correlation/", "subreddit_subscribers": 144473, "created_utc": 1701964515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i noticed a lot of companies invent role names that have close requirements as data engineer", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What job keywords or names that you saw on LinkedIn and they are basically data engineering related?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cvv43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701956585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i noticed a lot of companies invent role names that have close requirements as data engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18cvv43", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cvv43/what_job_keywords_or_names_that_you_saw_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cvv43/what_job_keywords_or_names_that_you_saw_on/", "subreddit_subscribers": 144473, "created_utc": 1701956585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context \nIn the entirety of my experience I've always found that organisation of data in warehouse using schema(dataset in BQ) was done using schema name same as a business usecase, or team ownership, or the most generic name for schema that became ambiguous immediately the next day. The commonality across all the schemas were that they did not age well with time; Business usecase grew bigger or shaped up into something new, teams folded or have multiple sub categories, etc. In all, the schema space seemed like an encyclopedia of historical decisions which have now turned into 'domain knowledge'. \n\nQuestion \nMy controversial view is when naming a schema we should only use vocabulary that can hold true for the lifetime of the tables, because it is impossible to keep updating the schema name as per relevance. Rather offload any meaningful grouping ex : team / business usecase to tags. I'm currently have this once in a life time opportunity to define the schema space in my org and I am tempted to keep it flat - single schema for all structured data. Looking for some feedback from the group on this controversial decision.  \n\n\nExtra Information \nI've put the guard rail that only production spark jobs and applications can write to the schema above. I intend to double down on good cataloging practices on these tables - make data that matters trust worthy. \n\nFor all adhoc analysis purposes I am providing a 'playground' with no rules on data organisation. We intend to control cost here by ensuring short retention on playground.\n\nUpdate: one obvious challenge might be in using same bucket for entire warehouse. I'm discounting that as a problem for the sake of the discussion. IMO this can be handled in my org as we have control over table creation centrally.", "author_fullname": "t2_ug6a7t7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use of schemas in modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cuxto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701954158.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701953521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context \nIn the entirety of my experience I&amp;#39;ve always found that organisation of data in warehouse using schema(dataset in BQ) was done using schema name same as a business usecase, or team ownership, or the most generic name for schema that became ambiguous immediately the next day. The commonality across all the schemas were that they did not age well with time; Business usecase grew bigger or shaped up into something new, teams folded or have multiple sub categories, etc. In all, the schema space seemed like an encyclopedia of historical decisions which have now turned into &amp;#39;domain knowledge&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;Question \nMy controversial view is when naming a schema we should only use vocabulary that can hold true for the lifetime of the tables, because it is impossible to keep updating the schema name as per relevance. Rather offload any meaningful grouping ex : team / business usecase to tags. I&amp;#39;m currently have this once in a life time opportunity to define the schema space in my org and I am tempted to keep it flat - single schema for all structured data. Looking for some feedback from the group on this controversial decision.  &lt;/p&gt;\n\n&lt;p&gt;Extra Information \nI&amp;#39;ve put the guard rail that only production spark jobs and applications can write to the schema above. I intend to double down on good cataloging practices on these tables - make data that matters trust worthy. &lt;/p&gt;\n\n&lt;p&gt;For all adhoc analysis purposes I am providing a &amp;#39;playground&amp;#39; with no rules on data organisation. We intend to control cost here by ensuring short retention on playground.&lt;/p&gt;\n\n&lt;p&gt;Update: one obvious challenge might be in using same bucket for entire warehouse. I&amp;#39;m discounting that as a problem for the sake of the discussion. IMO this can be handled in my org as we have control over table creation centrally.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18cuxto", "is_robot_indexable": true, "report_reasons": null, "author": "that-pipe-dream", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cuxto/use_of_schemas_in_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cuxto/use_of_schemas_in_modeling/", "subreddit_subscribers": 144473, "created_utc": 1701953521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm new to data engineering. I have seen some jobs openings titled \"Data Engineer - AEP\". AEP is Adobe Experience Platform, something which I have no idea about. If there's an AEP Data Engineer here, can they provide a brief explanation about the job role?", "author_fullname": "t2_9daynfsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an AEP data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18crrbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701940492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m new to data engineering. I have seen some jobs openings titled &amp;quot;Data Engineer - AEP&amp;quot;. AEP is Adobe Experience Platform, something which I have no idea about. If there&amp;#39;s an AEP Data Engineer here, can they provide a brief explanation about the job role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18crrbp", "is_robot_indexable": true, "report_reasons": null, "author": "Captcodr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18crrbp/whats_an_aep_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18crrbp/whats_an_aep_data_engineer/", "subreddit_subscribers": 144473, "created_utc": 1701940492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a Quant Finance background and currently work for a large US Bank, and I have only begun learning about data engineering concepts (through airflow and the orchestration of my team's financial models and data).\n\nRecently, a junior executive approached me asking how we can retain and access our analytics at the customer level (rather than sub-portfolio). He believes this would make us better at managing our balance sheet, and I agree with him. \n\nIn this particular space that's approximately 5 million customers. I've estimated that storing our modeled results at this precision would result in 15-20 terabytes of tabular data per year. \n\nAs a large US Bank, we are well acquainted with Microsoft, but what are my options for cloud storage?What should I recommend? I imagine using technology like Apache Spark to operate over the large data, querying information and running ML algorithms. \n\nWhat kind of pricing should I tell the junior executive to expect? \n\nAll advice is welcome and appreciated.", "author_fullname": "t2_2ngngbnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud Storage Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18clmri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701917595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Quant Finance background and currently work for a large US Bank, and I have only begun learning about data engineering concepts (through airflow and the orchestration of my team&amp;#39;s financial models and data).&lt;/p&gt;\n\n&lt;p&gt;Recently, a junior executive approached me asking how we can retain and access our analytics at the customer level (rather than sub-portfolio). He believes this would make us better at managing our balance sheet, and I agree with him. &lt;/p&gt;\n\n&lt;p&gt;In this particular space that&amp;#39;s approximately 5 million customers. I&amp;#39;ve estimated that storing our modeled results at this precision would result in 15-20 terabytes of tabular data per year. &lt;/p&gt;\n\n&lt;p&gt;As a large US Bank, we are well acquainted with Microsoft, but what are my options for cloud storage?What should I recommend? I imagine using technology like Apache Spark to operate over the large data, querying information and running ML algorithms. &lt;/p&gt;\n\n&lt;p&gt;What kind of pricing should I tell the junior executive to expect? &lt;/p&gt;\n\n&lt;p&gt;All advice is welcome and appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18clmri", "is_robot_indexable": true, "report_reasons": null, "author": "mderst", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18clmri/cloud_storage_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18clmri/cloud_storage_options/", "subreddit_subscribers": 144473, "created_utc": 1701917595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote CPU/ memory intensive code which is using Python Processpool executor for parallel processing which running fine in local machine but when I dockerize it and running on Aws batch through ECR it\u2019s working for few iterations and then throw process pool broken error. I don\u2019t understand this behavior I replaced Processpool with Threadpool executor and it\u2019s working fine in Aws batch but slower compare to Processpool executor. \n\nI monitored compute environment and it\u2019s not even using half of the assigned memory when running Processpool executor. \n\nMay be someone shed some light on this behavior, any other things I may check or change ?", "author_fullname": "t2_a0ixumwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processpool executor in Aws batch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ckfxn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701913981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote CPU/ memory intensive code which is using Python Processpool executor for parallel processing which running fine in local machine but when I dockerize it and running on Aws batch through ECR it\u2019s working for few iterations and then throw process pool broken error. I don\u2019t understand this behavior I replaced Processpool with Threadpool executor and it\u2019s working fine in Aws batch but slower compare to Processpool executor. &lt;/p&gt;\n\n&lt;p&gt;I monitored compute environment and it\u2019s not even using half of the assigned memory when running Processpool executor. &lt;/p&gt;\n\n&lt;p&gt;May be someone shed some light on this behavior, any other things I may check or change ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ckfxn", "is_robot_indexable": true, "report_reasons": null, "author": "ExcitingAd7292", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ckfxn/processpool_executor_in_aws_batch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ckfxn/processpool_executor_in_aws_batch/", "subreddit_subscribers": 144473, "created_utc": 1701913981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nLooking for some book recommendatinos to learn more about CI/Cd both in theory and technical applications. I've been finding alot of videos but im more of reader type of guy.", "author_fullname": "t2_6o6sl8n7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Recommendations for Ci/CD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ciotd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701908669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Looking for some book recommendatinos to learn more about CI/Cd both in theory and technical applications. I&amp;#39;ve been finding alot of videos but im more of reader type of guy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ciotd", "is_robot_indexable": true, "report_reasons": null, "author": "Tasty_Fold3012", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ciotd/book_recommendations_for_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ciotd/book_recommendations_for_cicd/", "subreddit_subscribers": 144473, "created_utc": 1701908669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I will give you a background. We are agency and we are integrating Customer Data Platforms like Bloomreach etc. It has its own API on fronend and backend, but when we send documentation and everything we need to integrate project, DEVs on our client side dont know much about it and often they made a solution which is bad - sending bad data to our platform, incorrect types etc and it is real-time, so we cannot change that later.\n\nI want to code tracking by myself, but to make a tracking solution - sending events like cart\\_update, view\\_item etc. Client is happy with this idea, but i dont know how to start and what to do. I think I need to make our new application that will send that, but I dont know how to because all the logic is in code maintained by their DEVS and i willl not be able to change their code.", "author_fullname": "t2_31exp9bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New service for our clients - behavior tracking solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18d3ijh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701977713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I will give you a background. We are agency and we are integrating Customer Data Platforms like Bloomreach etc. It has its own API on fronend and backend, but when we send documentation and everything we need to integrate project, DEVs on our client side dont know much about it and often they made a solution which is bad - sending bad data to our platform, incorrect types etc and it is real-time, so we cannot change that later.&lt;/p&gt;\n\n&lt;p&gt;I want to code tracking by myself, but to make a tracking solution - sending events like cart_update, view_item etc. Client is happy with this idea, but i dont know how to start and what to do. I think I need to make our new application that will send that, but I dont know how to because all the logic is in code maintained by their DEVS and i willl not be able to change their code.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18d3ijh", "is_robot_indexable": true, "report_reasons": null, "author": "Sonny-Orkidea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18d3ijh/new_service_for_our_clients_behavior_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18d3ijh/new_service_for_our_clients_behavior_tracking/", "subreddit_subscribers": 144473, "created_utc": 1701977713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nGuess what? Charles Smart just dropped some AI wisdom, and we're spilling the beans on the juicy bits right here. \ud83e\uddd0\n\nCharles took us on a trip from traditional data governance to the cool new kid on the block \u2013 Unified Intelligence Governance. Why? 'Cause AI is like the rockstar crashing the data party, and we need a hipper way to manage it. \ud83c\udfb8\n\n**Old vs. New - Six Pillars Showdown**: Remember the OG data governance pillars? Well, AI threw a curveball, making data quality checks feel like counting jellybeans in a jar at the county fair. \ud83d\ude05\n\n**AI's Got Jokes Too**: Turns out, AI is a bit of a prankster \u2013 billions of data points, model black boxes, and algorithmic bias \u2013 it's like trying to keep up with the Kardashians, but with less drama and more code. \ud83e\udd37\u200d\u2642\ufe0f\n\n**EU AI Act \u2013 The Rulebook with Swagger**: The EU's AI Act is like the Gandalf of regulations \u2013 \"You shall not pass without transparency, human oversight, and some serious risk assessments.\" \ud83e\uddd9\u200d\u2642\ufe0f\u2728\n\n**Unified Intelligence Governance \u2013 Less Drama, More Action**: Chuck's proposing a new framework \u2013 think of it as the Avengers of data and AI governance. It's got everything from continuous data quality validation to algorithmic audits \u2013 the whole squad is here! \ud83d\udcbc\ud83e\udd16\n\n**Why You Should Care?**: Well, apart from being the coolest kid at the data party, it's about responsible AI, compliance, and building trust. It's the data version of 'keeping it real.' \ud83c\udf10\ud83d\udc99\n\nSo, let's chat! What's your take on AI's sense of humor? Join the casual data hangout and share your thoughts. Oh, and don't forget to check out Charles Smart's laid-back take on AI governance \u2013 \n\nView full article HERE!!!\n\n[https://www.factspan.com/blogs/data-and-ai-governance-evolving-traditional-data-governance-in-the-age-of-artificial-intelligence/](https://www.factspan.com/blogs/data-and-ai-governance-evolving-traditional-data-governance-in-the-age-of-artificial-intelligence/)\n\n&amp;#x200B;\n\n\\#ChillDataVibes", "author_fullname": "t2_nzr0ocai3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Community Chronicles: AI Governance Unveiled in the Most Casual Data Hangout Ever!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18cqm5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701935310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;Guess what? Charles Smart just dropped some AI wisdom, and we&amp;#39;re spilling the beans on the juicy bits right here. \ud83e\uddd0&lt;/p&gt;\n\n&lt;p&gt;Charles took us on a trip from traditional data governance to the cool new kid on the block \u2013 Unified Intelligence Governance. Why? &amp;#39;Cause AI is like the rockstar crashing the data party, and we need a hipper way to manage it. \ud83c\udfb8&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Old vs. New - Six Pillars Showdown&lt;/strong&gt;: Remember the OG data governance pillars? Well, AI threw a curveball, making data quality checks feel like counting jellybeans in a jar at the county fair. \ud83d\ude05&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;AI&amp;#39;s Got Jokes Too&lt;/strong&gt;: Turns out, AI is a bit of a prankster \u2013 billions of data points, model black boxes, and algorithmic bias \u2013 it&amp;#39;s like trying to keep up with the Kardashians, but with less drama and more code. \ud83e\udd37\u200d\u2642\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EU AI Act \u2013 The Rulebook with Swagger&lt;/strong&gt;: The EU&amp;#39;s AI Act is like the Gandalf of regulations \u2013 &amp;quot;You shall not pass without transparency, human oversight, and some serious risk assessments.&amp;quot; \ud83e\uddd9\u200d\u2642\ufe0f\u2728&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Unified Intelligence Governance \u2013 Less Drama, More Action&lt;/strong&gt;: Chuck&amp;#39;s proposing a new framework \u2013 think of it as the Avengers of data and AI governance. It&amp;#39;s got everything from continuous data quality validation to algorithmic audits \u2013 the whole squad is here! \ud83d\udcbc\ud83e\udd16&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why You Should Care?&lt;/strong&gt;: Well, apart from being the coolest kid at the data party, it&amp;#39;s about responsible AI, compliance, and building trust. It&amp;#39;s the data version of &amp;#39;keeping it real.&amp;#39; \ud83c\udf10\ud83d\udc99&lt;/p&gt;\n\n&lt;p&gt;So, let&amp;#39;s chat! What&amp;#39;s your take on AI&amp;#39;s sense of humor? Join the casual data hangout and share your thoughts. Oh, and don&amp;#39;t forget to check out Charles Smart&amp;#39;s laid-back take on AI governance \u2013 &lt;/p&gt;\n\n&lt;p&gt;View full article HERE!!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.factspan.com/blogs/data-and-ai-governance-evolving-traditional-data-governance-in-the-age-of-artificial-intelligence/\"&gt;https://www.factspan.com/blogs/data-and-ai-governance-evolving-traditional-data-governance-in-the-age-of-artificial-intelligence/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;#ChillDataVibes&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?auto=webp&amp;s=1fdcad45a9bb35268ae361b06d7021100453d562", "width": 1280, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bdf51097101853b3783ec051b5dc5f4e43f00a2", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc660d0abf2a23fc9887a62caaa41807b7d3bfef", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=729a6ca07f7dc39ebd5f56c92df1bae535a5a4a4", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36faa19219d4780ed018c64af3602640549e73c1", "width": 640, "height": 314}, {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97209bdac9497721fcb353d998d3426bc1095475", "width": 960, "height": 471}, {"url": "https://external-preview.redd.it/zCAOc1YPuJSvsRIZ7gEJXY4qUc1NEZta06Cmi-RnXYk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d6fec7bff62dedf0f7790381d0faf82c01b6138", "width": 1080, "height": 529}], "variants": {}, "id": "Xk74nxwB9GpqIzHwnNf20ONibUiUhfqe14pPD6OYTno"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18cqm5q", "is_robot_indexable": true, "report_reasons": null, "author": "KeyBid5470", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18cqm5q/data_engineering_community_chronicles_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18cqm5q/data_engineering_community_chronicles_ai/", "subreddit_subscribers": 144473, "created_utc": 1701935310.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}