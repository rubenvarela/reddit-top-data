{"kind": "Listing", "data": {"after": "t3_18tqk5x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been part of a forum for nearly 20 years. It was fairly active 2002 until 2015ish and since then activity has dropped off quite a bit. I just found out that the last remaining moderator (and the guy who pays the bills and owns the forum) passed away. From what I gather, the bills have been paid until April 2024 so not much time is left.\n\nWhat would be the best way to archive the site? Basically make it so I can access it in its entirety offline? It's a standard forum (with some sections for members only) and has an image section as well. I've searched around and can't find a definitive best suggestion.\n\nI would like to spend the next few years slowly going through all the old posts and pictures, turning them into something like an ebook for myself and possibly distribute copies to the members I'm still in contact with.\n\nThanks everyone for your time.\n\n**Edit:** not sure what the infrastructure/software looks like but it says \"Powered by Invision Community\" at the very bottom.", "author_fullname": "t2_7ly38fl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Owner/only moderator of a forum suddenly passed away. How to archive as a member?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18trmtr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703869283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been part of a forum for nearly 20 years. It was fairly active 2002 until 2015ish and since then activity has dropped off quite a bit. I just found out that the last remaining moderator (and the guy who pays the bills and owns the forum) passed away. From what I gather, the bills have been paid until April 2024 so not much time is left.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to archive the site? Basically make it so I can access it in its entirety offline? It&amp;#39;s a standard forum (with some sections for members only) and has an image section as well. I&amp;#39;ve searched around and can&amp;#39;t find a definitive best suggestion.&lt;/p&gt;\n\n&lt;p&gt;I would like to spend the next few years slowly going through all the old posts and pictures, turning them into something like an ebook for myself and possibly distribute copies to the members I&amp;#39;m still in contact with.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone for your time.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; not sure what the infrastructure/software looks like but it says &amp;quot;Powered by Invision Community&amp;quot; at the very bottom.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18trmtr", "is_robot_indexable": true, "report_reasons": null, "author": "landboisteve", "discussion_type": null, "num_comments": 20, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18trmtr/owneronly_moderator_of_a_forum_suddenly_passed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18trmtr/owneronly_moderator_of_a_forum_suddenly_passed/", "subreddit_subscribers": 721689, "created_utc": 1703868933.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello data hoarders, I expect the vast majority of you know the game Roblox  at this point (if you don't, it's essentially a game creation platform),  so I'll cut right to the chase.\n\nIf  you believe that you may still have a hard drive from around the year  2006 and have at the very least installed the game, please attempt to  locate the drive (as soon as you are able to) and search these 2  directories:\n\n**C:\\\\Program Files\\\\Roblox Corporation\\\\ROBLOX** contains the latest version installed.\n\n**C:\\\\Documents and Settings\\\\All Users\\\\Application Data\\\\ROBLOX** contains misc. data and cached stuff.\n\nFurther information can be found at this link: [https://robloxopolis.com/2006-roblox-bounty/](https://robloxopolis.com/2006-roblox-bounty/)\n\nEmail [robloxclientsearch@gmail.com](mailto:robloxclientsearch@gmail.com) if you found something substantial, or need further direct assistance.\n\nIf a **2006** version is recovered and preserved successfully, the person who found it will receive a **$500 USD** reward. If you have any suggestions on how else to spread the word, please let us know. Thank you for your time.", "author_fullname": "t2_kchsyxiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[BOUNTY] Does anyone here remember playing the online game \"Roblox\" from 2006? All versions from that time period are lost.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tasv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703814001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data hoarders, I expect the vast majority of you know the game Roblox  at this point (if you don&amp;#39;t, it&amp;#39;s essentially a game creation platform),  so I&amp;#39;ll cut right to the chase.&lt;/p&gt;\n\n&lt;p&gt;If  you believe that you may still have a hard drive from around the year  2006 and have at the very least installed the game, please attempt to  locate the drive (as soon as you are able to) and search these 2  directories:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;C:\\Program Files\\Roblox Corporation\\ROBLOX&lt;/strong&gt; contains the latest version installed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;C:\\Documents and Settings\\All Users\\Application Data\\ROBLOX&lt;/strong&gt; contains misc. data and cached stuff.&lt;/p&gt;\n\n&lt;p&gt;Further information can be found at this link: &lt;a href=\"https://robloxopolis.com/2006-roblox-bounty/\"&gt;https://robloxopolis.com/2006-roblox-bounty/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Email [&lt;a href=\"mailto:robloxclientsearch@gmail.com\"&gt;robloxclientsearch@gmail.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:robloxclientsearch@gmail.com\"&gt;robloxclientsearch@gmail.com&lt;/a&gt;) if you found something substantial, or need further direct assistance.&lt;/p&gt;\n\n&lt;p&gt;If a &lt;strong&gt;2006&lt;/strong&gt; version is recovered and preserved successfully, the person who found it will receive a &lt;strong&gt;$500 USD&lt;/strong&gt; reward. If you have any suggestions on how else to spread the word, please let us know. Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?auto=webp&amp;s=dbc8a1ccb7b91ec89be8d87e3dd1733fef5ab7e5", "width": 2000, "height": 973}, "resolutions": [{"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b3ce14d36f9ba44bb0625fbb7a46d990f72a4c1", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c140fd2860e409a0fcc84529ed68c417ff49e6a6", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c73694c68bd733161d119bf19443d0bcd682cde", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=96aaacb63479838128c6ff67e74ee42e09dcc49a", "width": 640, "height": 311}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5129cbfaf7dbe436978ee57d16566dbe15fa96af", "width": 960, "height": 467}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=415a1f9eb2b6f773e85a5a178505b2821e51db30", "width": 1080, "height": 525}], "variants": {}, "id": "ARnKGFIp06IW4MIg5BVdgwa5NZPj9IbzfcEZDI2EzIo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tasv5", "is_robot_indexable": true, "report_reasons": null, "author": "Loud_Negotiation4843", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tasv5/bounty_does_anyone_here_remember_playing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tasv5/bounty_does_anyone_here_remember_playing_the/", "subreddit_subscribers": 721689, "created_utc": 1703814001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, are there cases when corruption in an image / video file doesn't cause any visual artifacts?", "author_fullname": "t2_5ufxabnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible that data corruption / bit rot in a file may not cause any noticeable symptoms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpycu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703864532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, are there cases when corruption in an image / video file doesn&amp;#39;t cause any visual artifacts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpycu", "is_robot_indexable": true, "report_reasons": null, "author": "user1-reddit", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpycu/is_it_possible_that_data_corruption_bit_rot_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpycu/is_it_possible_that_data_corruption_bit_rot_in_a/", "subreddit_subscribers": 721689, "created_utc": 1703864532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's like the inverse of file compression, but you add some error correction code into it to improve resilience when archiving files. It would be great if it's battle proven and open source? Or at least open standard for easier retrieval after many years?", "author_fullname": "t2_bjeo1gwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a file format that can withstand some bit rot.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tra4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s like the inverse of file compression, but you add some error correction code into it to improve resilience when archiving files. It would be great if it&amp;#39;s battle proven and open source? Or at least open standard for easier retrieval after many years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tra4s", "is_robot_indexable": true, "report_reasons": null, "author": "--dany--", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tra4s/is_there_a_file_format_that_can_withstand_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tra4s/is_there_a_file_format_that_can_withstand_some/", "subreddit_subscribers": 721689, "created_utc": 1703868023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I don't know if this has been posted earlier, and I've got limited technical knowledge when it comes to this stuff, but I really want to help save some of this information for posterity and I don't know how to go about it.\n\n\nAny tip would be greatly appreciated!", "author_fullname": "t2_kjh71cjt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CGSociety is closing up soon, decades of valuable data/information/discussion/artwork is going to be lost, what can I do to save a mirror of the site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tlukv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703852162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I don&amp;#39;t know if this has been posted earlier, and I&amp;#39;ve got limited technical knowledge when it comes to this stuff, but I really want to help save some of this information for posterity and I don&amp;#39;t know how to go about it.&lt;/p&gt;\n\n&lt;p&gt;Any tip would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tlukv", "is_robot_indexable": true, "report_reasons": null, "author": "randomfuckingpotato", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/", "subreddit_subscribers": 721689, "created_utc": 1703852162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The name of the game to me is unironically power to weight (and capacity).\n\n\nI live on the go, currently have all my data in my laptop 4TB and an offsite 2.5\" 5TB hard drive.\n\n\nI guess I should set design goals and work from there? Is there a more proffessional way to do this? e.g...\n\n\nIn interest of brevity I'm for now only focusing on power but just being MINDFUL that I will have to account for these other factors.\n\n\nPriority 1 reliability+security\n\n\nPri 2+3 idle then activ power consumption - this is the difficulty\n\n\nPri 4 capacity\n\n\nPri 5 size+weight\n\n\nPri 6 usability\n\n\nPri 7 cost\n\n\nPri 8 ease of use&amp;setup - I am willing to solder, make my own PCBs, scripts, whatever BUUUUT most of all it needs to get done - improvement is better than a dream.\n\n\nTarget power excl. drives ~= 5w avg/day given arm based processor, phone running linux maybe?\n\nTarget power 20TB initially ~= 10-20w avg\n\nWhat happens when I run out of power (like system shuts off because battery ran out or I wanted to keep laptop powered)? etc...\n\n\n...\nI obviously need to incrementally develop this but what do I even start with? Buy a phone and a way to wire it to a 2.5\" drive and see what I can do? Advice would be greatly appreciated.", "author_fullname": "t2_4s2j111y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low mass, low power data hoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tmi3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703854669.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703854446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The name of the game to me is unironically power to weight (and capacity).&lt;/p&gt;\n\n&lt;p&gt;I live on the go, currently have all my data in my laptop 4TB and an offsite 2.5&amp;quot; 5TB hard drive.&lt;/p&gt;\n\n&lt;p&gt;I guess I should set design goals and work from there? Is there a more proffessional way to do this? e.g...&lt;/p&gt;\n\n&lt;p&gt;In interest of brevity I&amp;#39;m for now only focusing on power but just being MINDFUL that I will have to account for these other factors.&lt;/p&gt;\n\n&lt;p&gt;Priority 1 reliability+security&lt;/p&gt;\n\n&lt;p&gt;Pri 2+3 idle then activ power consumption - this is the difficulty&lt;/p&gt;\n\n&lt;p&gt;Pri 4 capacity&lt;/p&gt;\n\n&lt;p&gt;Pri 5 size+weight&lt;/p&gt;\n\n&lt;p&gt;Pri 6 usability&lt;/p&gt;\n\n&lt;p&gt;Pri 7 cost&lt;/p&gt;\n\n&lt;p&gt;Pri 8 ease of use&amp;amp;setup - I am willing to solder, make my own PCBs, scripts, whatever BUUUUT most of all it needs to get done - improvement is better than a dream.&lt;/p&gt;\n\n&lt;p&gt;Target power excl. drives ~= 5w avg/day given arm based processor, phone running linux maybe?&lt;/p&gt;\n\n&lt;p&gt;Target power 20TB initially ~= 10-20w avg&lt;/p&gt;\n\n&lt;p&gt;What happens when I run out of power (like system shuts off because battery ran out or I wanted to keep laptop powered)? etc...&lt;/p&gt;\n\n&lt;p&gt;...\nI obviously need to incrementally develop this but what do I even start with? Buy a phone and a way to wire it to a 2.5&amp;quot; drive and see what I can do? Advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "4TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tmi3c", "is_robot_indexable": true, "report_reasons": null, "author": "VoiceofRedditMkI", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18tmi3c/low_mass_low_power_data_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tmi3c/low_mass_low_power_data_hoarding/", "subreddit_subscribers": 721689, "created_utc": 1703854446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wondering if it is possible to backup a collection from archive.org that contains sub-collections so that files from sub-collections are put into their own sub-directories. Any idea how to accomplish this? As far as I know the ia app would put sub-collections in the same directory as all other other files.\n\n\nCollection that contains sub-collections: https://archive.org/details/softwarelibrary\nia app: https://archive.org/developers/internetarchive/cli.html", "author_fullname": "t2_bljn4qq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive: Backup of collections and sub-collections in separate folders possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tmv67", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703855638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if it is possible to backup a collection from archive.org that contains sub-collections so that files from sub-collections are put into their own sub-directories. Any idea how to accomplish this? As far as I know the ia app would put sub-collections in the same directory as all other other files.&lt;/p&gt;\n\n&lt;p&gt;Collection that contains sub-collections: &lt;a href=\"https://archive.org/details/softwarelibrary\"&gt;https://archive.org/details/softwarelibrary&lt;/a&gt;\nia app: &lt;a href=\"https://archive.org/developers/internetarchive/cli.html\"&gt;https://archive.org/developers/internetarchive/cli.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tmv67", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Analysis_1431", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tmv67/internet_archive_backup_of_collections_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tmv67/internet_archive_backup_of_collections_and/", "subreddit_subscribers": 721689, "created_utc": 1703855638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hardware isn't my strong suit (yet!)  and I'm pressed for time these days so while I'm tempted to follow a youtube video on building my own, I've been tempted by  the Synology 4-Bay DiskStation DS923+ with a pair of either :\n\nSeagate ST6000VN0033 Iron Wolf Multimedia Server Storage 6TB Internal Hard Drive 3.5\" - SATA\n\nor\n\nSeagate IronWolf 8TB NAS Internal Hard Drive HDD \u2013 3.5 Inch SATA 6Gb/s 7200 RPM 256MB Cache for RAID Network Attached Storage \u2013(ST8000VNZ04/N004)\n\nLater I'll add more to the other slots but I figure 1 for storage 1 for redundancy to start will be the way to go.  \n\n\n  \nMy main computer is pretty capable but I've read that without a dedicated GPU the DS923+ is going to struggle transcoding videos if say, I'm trying to watch on my phone while away from home or if I give friends access to the server from their location.   \n\n\nWould this be a mistake or a good entry point? ", "author_fullname": "t2_w03bzp59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "considering first NAS for use primarily as a personal movie server but later as a homelab... DS923+ or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tqnro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703866371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hardware isn&amp;#39;t my strong suit (yet!)  and I&amp;#39;m pressed for time these days so while I&amp;#39;m tempted to follow a youtube video on building my own, I&amp;#39;ve been tempted by  the Synology 4-Bay DiskStation DS923+ with a pair of either :&lt;/p&gt;\n\n&lt;p&gt;Seagate ST6000VN0033 Iron Wolf Multimedia Server Storage 6TB Internal Hard Drive 3.5&amp;quot; - SATA&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Seagate IronWolf 8TB NAS Internal Hard Drive HDD \u2013 3.5 Inch SATA 6Gb/s 7200 RPM 256MB Cache for RAID Network Attached Storage \u2013(ST8000VNZ04/N004)&lt;/p&gt;\n\n&lt;p&gt;Later I&amp;#39;ll add more to the other slots but I figure 1 for storage 1 for redundancy to start will be the way to go.  &lt;/p&gt;\n\n&lt;p&gt;My main computer is pretty capable but I&amp;#39;ve read that without a dedicated GPU the DS923+ is going to struggle transcoding videos if say, I&amp;#39;m trying to watch on my phone while away from home or if I give friends access to the server from their location.   &lt;/p&gt;\n\n&lt;p&gt;Would this be a mistake or a good entry point? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tqnro", "is_robot_indexable": true, "report_reasons": null, "author": "overflowingpothos", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tqnro/considering_first_nas_for_use_primarily_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tqnro/considering_first_nas_for_use_primarily_as_a/", "subreddit_subscribers": 721689, "created_utc": 1703866371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. Does anybody has an archive of liveleak's combat footage and war related videos? I just wandering, cause lots of vids had vanished with the website's shot down. I just managed to archive ruffly 600 items from their server back in 2015-16.", "author_fullname": "t2_p0f47tbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any long time archivists of liveleak?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpns6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703863764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. Does anybody has an archive of liveleak&amp;#39;s combat footage and war related videos? I just wandering, cause lots of vids had vanished with the website&amp;#39;s shot down. I just managed to archive ruffly 600 items from their server back in 2015-16.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpns6", "is_robot_indexable": true, "report_reasons": null, "author": "Ablackshado", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpns6/are_there_any_long_time_archivists_of_liveleak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpns6/are_there_any_long_time_archivists_of_liveleak/", "subreddit_subscribers": 721689, "created_utc": 1703863764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nhope I found the write place to ask. I use syncthing for syncing different folders. I am looking for a software, preferable opensource like syncthing, which makes backups of folders. Not huge in size. Preferable it can zip them to versions and store up to x versions. I would need it for synology, android and  windows.\n\n&amp;#x200B;\n\nFor example: Backup of different \"User\" folders of various programs (filebot, yuzu etc.). \n\nBackup of different Android \"User\" folders (emulator programs etc.)\n\n&amp;#x200B;\n\nHappy for any input!", "author_fullname": "t2_6ir04j5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Folder\" Backup Software, best case same program for Android, Synology and Windows (like syncthing for syncing folders)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpf7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703863120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;hope I found the write place to ask. I use syncthing for syncing different folders. I am looking for a software, preferable opensource like syncthing, which makes backups of folders. Not huge in size. Preferable it can zip them to versions and store up to x versions. I would need it for synology, android and  windows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example: Backup of different &amp;quot;User&amp;quot; folders of various programs (filebot, yuzu etc.). &lt;/p&gt;\n\n&lt;p&gt;Backup of different Android &amp;quot;User&amp;quot; folders (emulator programs etc.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Happy for any input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpf7r", "is_robot_indexable": true, "report_reasons": null, "author": "---in10se---", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpf7r/folder_backup_software_best_case_same_program_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpf7r/folder_backup_software_best_case_same_program_for/", "subreddit_subscribers": 721689, "created_utc": 1703863120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I plan to buy Synology and even though I did some research it's really hard to get all the answers I need.\n\n\\- DS923+ or DS423+ or DS1522+? I basically want to centralize my data, so it is accessible on all home devices. Maybe occasionally stream some video. Putting app on docker is a nice to have. Is the difference in the last model just the additional slot? Is it worth it?\n\n\\- Does it matter whether I buy NAS HDDs or plain HDDs for my use case? I am maybe not understanding this right, but I don't think my discs will run more than they would in a plain PC. I don't plan to have any 24/7 service on there.\n\n\\- I decided that 4x 4TB discs in raid10 is what I want to go for, can I use additional SSDs for cache in this configuration or am I misunderstanding this concept completely? Do I need specific SSDs for caching to work or can it be any.\n\n\\- Is there anything else I need to know/buy that is obviously missing in my plan?\n\nThanks!", "author_fullname": "t2_1iwe8qib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time NAS, what to put in Synology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18tyl98", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703886985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan to buy Synology and even though I did some research it&amp;#39;s really hard to get all the answers I need.&lt;/p&gt;\n\n&lt;p&gt;- DS923+ or DS423+ or DS1522+? I basically want to centralize my data, so it is accessible on all home devices. Maybe occasionally stream some video. Putting app on docker is a nice to have. Is the difference in the last model just the additional slot? Is it worth it?&lt;/p&gt;\n\n&lt;p&gt;- Does it matter whether I buy NAS HDDs or plain HDDs for my use case? I am maybe not understanding this right, but I don&amp;#39;t think my discs will run more than they would in a plain PC. I don&amp;#39;t plan to have any 24/7 service on there.&lt;/p&gt;\n\n&lt;p&gt;- I decided that 4x 4TB discs in raid10 is what I want to go for, can I use additional SSDs for cache in this configuration or am I misunderstanding this concept completely? Do I need specific SSDs for caching to work or can it be any.&lt;/p&gt;\n\n&lt;p&gt;- Is there anything else I need to know/buy that is obviously missing in my plan?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tyl98", "is_robot_indexable": true, "report_reasons": null, "author": "BoyOnTheSun", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tyl98/first_time_nas_what_to_put_in_synology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tyl98/first_time_nas_what_to_put_in_synology/", "subreddit_subscribers": 721689, "created_utc": 1703886985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have 7tb of SSD over a few drives. Boot drive, games drive, a full drive a family photos that are very important, and the rest is for video editing. I also have an 8tb mechanical drive where I store finished videos and raw, unedited video files. Believe it or not, I'm running out of space again.\n\nShould I get a NAS? I like the idea of my files always being available when Im on my computer, and not having to dig out the cables/power for an external drive - and I dont really wanna put another heat source (another mechanical drive) in my already over crowded system. NAS are kinda pricey, and probably wouldn't use it to RAID either. \n\nSo.. is there another solution, since Im not really looking to RAID, and I don't really know that I need it to be available online like a NAS does. I just need readily available storage, like a lot of it. ", "author_fullname": "t2_t1n26nlx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I keep running out of space.. what is my best option? External drives? NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18txs8f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703884830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have 7tb of SSD over a few drives. Boot drive, games drive, a full drive a family photos that are very important, and the rest is for video editing. I also have an 8tb mechanical drive where I store finished videos and raw, unedited video files. Believe it or not, I&amp;#39;m running out of space again.&lt;/p&gt;\n\n&lt;p&gt;Should I get a NAS? I like the idea of my files always being available when Im on my computer, and not having to dig out the cables/power for an external drive - and I dont really wanna put another heat source (another mechanical drive) in my already over crowded system. NAS are kinda pricey, and probably wouldn&amp;#39;t use it to RAID either. &lt;/p&gt;\n\n&lt;p&gt;So.. is there another solution, since Im not really looking to RAID, and I don&amp;#39;t really know that I need it to be available online like a NAS does. I just need readily available storage, like a lot of it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18txs8f", "is_robot_indexable": true, "report_reasons": null, "author": "CountingStars29", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18txs8f/i_keep_running_out_of_space_what_is_my_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18txs8f/i_keep_running_out_of_space_what_is_my_best/", "subreddit_subscribers": 721689, "created_utc": 1703884830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Specifically with regard to data integrity/bit-rot/etc, is there any reason to use RAR5's Recovery Volumes **and** PAR2?\n\ni.e. I create 5 RAR5 Recovery Volumes AND THEN enough PAR2 data to recover, at minimum, 5 of those RAR files.\n\n\\-VS-\n\nCreating 10 RAR5 Recovery Volumes in the first place...\n\n*(Assume 5 RAR5 Recovery Volumes plus PAR2 data is approximately equivalent to 10 RAR5 Recovery Volumes).*\n\nI initially thought I should do both (5 x RAR5 + PAR2)... however, if I am missing 6 RAR files, the outer PAR2 wrapper can't recover the inner RAR5 archive and everything goes in the bit bucket in the sky.\n\nAlternatively, 10 RAR5 Recovery Volumes handles 6 missing RAR files without an issue (obviously).\n\nNow, I'm leaning towards the latter but am wondering if I'm failing to think of a good reason to use BOTH, again, assuming each scheme results in basically the same amount of extraneous recovery data.\n\n(I completely understand I could create 10 RAR5 Recovery Volumes AND additional PAR2 recovery data, but this would increase the extraneous recovery data size.  And if I'm ok with that, why not create more RAR5 Recovery Volumes?)", "author_fullname": "t2_fnk2wyny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAR5: Recovery Volumes WITH PAR2?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18txdoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703884420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703883768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Specifically with regard to data integrity/bit-rot/etc, is there any reason to use RAR5&amp;#39;s Recovery Volumes &lt;strong&gt;and&lt;/strong&gt; PAR2?&lt;/p&gt;\n\n&lt;p&gt;i.e. I create 5 RAR5 Recovery Volumes AND THEN enough PAR2 data to recover, at minimum, 5 of those RAR files.&lt;/p&gt;\n\n&lt;p&gt;-VS-&lt;/p&gt;\n\n&lt;p&gt;Creating 10 RAR5 Recovery Volumes in the first place...&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(Assume 5 RAR5 Recovery Volumes plus PAR2 data is approximately equivalent to 10 RAR5 Recovery Volumes).&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I initially thought I should do both (5 x RAR5 + PAR2)... however, if I am missing 6 RAR files, the outer PAR2 wrapper can&amp;#39;t recover the inner RAR5 archive and everything goes in the bit bucket in the sky.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, 10 RAR5 Recovery Volumes handles 6 missing RAR files without an issue (obviously).&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m leaning towards the latter but am wondering if I&amp;#39;m failing to think of a good reason to use BOTH, again, assuming each scheme results in basically the same amount of extraneous recovery data.&lt;/p&gt;\n\n&lt;p&gt;(I completely understand I could create 10 RAR5 Recovery Volumes AND additional PAR2 recovery data, but this would increase the extraneous recovery data size.  And if I&amp;#39;m ok with that, why not create more RAR5 Recovery Volumes?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18txdoh", "is_robot_indexable": true, "report_reasons": null, "author": "4ppl3c0r3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18txdoh/rar5_recovery_volumes_with_par2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18txdoh/rar5_recovery_volumes_with_par2/", "subreddit_subscribers": 721689, "created_utc": 1703883768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I am trying to build a low-power storage array. I have picked some hardware together that I think will work, but I would like some confirmation or suggestions on how to do this better.\n\nThe hardware I picked is as follows:\n\n* Inter-Tech 2U-2412, 2U rack case with SAS/SATA 12G backplane with 12 3.5\" bays. This case requires 3 SFF-8087 connectors to the backplane.\n* LSI MegaRAID SAS 9341-8i\n* Intel RES2SV240 SAS expander\n* Gigabyte B550\n* 64 GB DDR4 RAM (non-ECC)\n* AMD Ryzen 3 4300G\n* 300W PSU\n\nI would like to build a low-power server that can run one or two VMs on the side. I would like to use TrueNAS with a ZFS software RAID. The RAID card has to be able to run in HBA/IT mode for this, as far as I understand.\n\nMy questions about this are?\n\n1. Will this selection of hardware work together nicely or are there severe bottlenecks?\n2. Are there any better hardware recommendations for a low-power budget storage array?\n3. How do I power the drives connected to the backplane? I have very limited experience with server grade hardware.\n\nI am generally a bit of a noob when it comes to storage that is a bit beyond the regular pc build, so I would like as much advice you can give me :)", "author_fullname": "t2_nrgq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will my build work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18tx5e8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703883176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am trying to build a low-power storage array. I have picked some hardware together that I think will work, but I would like some confirmation or suggestions on how to do this better.&lt;/p&gt;\n\n&lt;p&gt;The hardware I picked is as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inter-Tech 2U-2412, 2U rack case with SAS/SATA 12G backplane with 12 3.5&amp;quot; bays. This case requires 3 SFF-8087 connectors to the backplane.&lt;/li&gt;\n&lt;li&gt;LSI MegaRAID SAS 9341-8i&lt;/li&gt;\n&lt;li&gt;Intel RES2SV240 SAS expander&lt;/li&gt;\n&lt;li&gt;Gigabyte B550&lt;/li&gt;\n&lt;li&gt;64 GB DDR4 RAM (non-ECC)&lt;/li&gt;\n&lt;li&gt;AMD Ryzen 3 4300G&lt;/li&gt;\n&lt;li&gt;300W PSU&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would like to build a low-power server that can run one or two VMs on the side. I would like to use TrueNAS with a ZFS software RAID. The RAID card has to be able to run in HBA/IT mode for this, as far as I understand.&lt;/p&gt;\n\n&lt;p&gt;My questions about this are?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Will this selection of hardware work together nicely or are there severe bottlenecks?&lt;/li&gt;\n&lt;li&gt;Are there any better hardware recommendations for a low-power budget storage array?&lt;/li&gt;\n&lt;li&gt;How do I power the drives connected to the backplane? I have very limited experience with server grade hardware.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am generally a bit of a noob when it comes to storage that is a bit beyond the regular pc build, so I would like as much advice you can give me :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tx5e8", "is_robot_indexable": true, "report_reasons": null, "author": "EyeGaming2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tx5e8/will_my_build_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tx5e8/will_my_build_work/", "subreddit_subscribers": 721689, "created_utc": 1703883176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Simple Storage Space in Windows 11 with 24TB made up of:\n\n* 16TB HDD\n* 8TB HDD\n\nI have filled the Storage Space with 16TB worth of data. \n\n* 8TB worth of data is on the 8TB disk\n* 8TB worth of data is on the 16TB disk\n\nI assumed that since I have 8TB of remaining space on the 16TB drive, I could continue adding data into the pool and it would just be stored on that drive. However, when I try to add more, it says my disk is full. It seems like it is still trying to split the data across the two drives.\n\nIs there anything I can do? Is there a way to move some data from the filled drive to the bigger one? Thank you.", "author_fullname": "t2_qzchcllil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows Storage Space - Moving Data From one Drive To Another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tw99h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703880868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Simple Storage Space in Windows 11 with 24TB made up of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;16TB HDD&lt;/li&gt;\n&lt;li&gt;8TB HDD&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have filled the Storage Space with 16TB worth of data. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;8TB worth of data is on the 8TB disk&lt;/li&gt;\n&lt;li&gt;8TB worth of data is on the 16TB disk&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I assumed that since I have 8TB of remaining space on the 16TB drive, I could continue adding data into the pool and it would just be stored on that drive. However, when I try to add more, it says my disk is full. It seems like it is still trying to split the data across the two drives.&lt;/p&gt;\n\n&lt;p&gt;Is there anything I can do? Is there a way to move some data from the filled drive to the bigger one? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tw99h", "is_robot_indexable": true, "report_reasons": null, "author": "Character_Field7964", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tw99h/windows_storage_space_moving_data_from_one_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tw99h/windows_storage_space_moving_data_from_one_drive/", "subreddit_subscribers": 721689, "created_utc": 1703880868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Samsung is $248 and the black version of the SanDisk is $199 on Amazon.\n\nI've read previous threads about heating problems, data loss and failures of Sandisk SSDs.\n\nBut both listings on Amazon have over 10k reviews and there are similar number of complaints about failures, overheating, firmware updating problems for both products.\n\nAny recent experiences with these brands, particularly the 4 TB versions which are relatively new?\n\nThinking of booting from it on my old iMac -- the internal drive is dying -- until I upgrade my computer.\n\nI actually bought one of the Samsung T7 Shield 4 TB a few months back.  I use it only to store my photos and videos and have used only about 450 GB.  It's been solid for me but not really stressing it like booting the OS from it.", "author_fullname": "t2_pc6088pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung T7 Shield 4 TB vs. SanDisk Extreme 4 TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ttje3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703873850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Samsung is $248 and the black version of the SanDisk is $199 on Amazon.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read previous threads about heating problems, data loss and failures of Sandisk SSDs.&lt;/p&gt;\n\n&lt;p&gt;But both listings on Amazon have over 10k reviews and there are similar number of complaints about failures, overheating, firmware updating problems for both products.&lt;/p&gt;\n\n&lt;p&gt;Any recent experiences with these brands, particularly the 4 TB versions which are relatively new?&lt;/p&gt;\n\n&lt;p&gt;Thinking of booting from it on my old iMac -- the internal drive is dying -- until I upgrade my computer.&lt;/p&gt;\n\n&lt;p&gt;I actually bought one of the Samsung T7 Shield 4 TB a few months back.  I use it only to store my photos and videos and have used only about 450 GB.  It&amp;#39;s been solid for me but not really stressing it like booting the OS from it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ttje3", "is_robot_indexable": true, "report_reasons": null, "author": "Frappant11", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ttje3/samsung_t7_shield_4_tb_vs_sandisk_extreme_4_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ttje3/samsung_t7_shield_4_tb_vs_sandisk_extreme_4_tb/", "subreddit_subscribers": 721689, "created_utc": 1703873850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got 3 terabytes of data on dropbox.  \nThis data consists of text files, email backups, notes, images, all my photos, work divided in hundreds of folders - in other words, it's not 3tb of 10 videos, its 3TB of north of ONE MILLION files. It's a lot. \n\nAt first DP worked well, but as time passed, i noticed major issues. Organizing things means having to get a very fast 3TB drive and manually do everything locally. Their web interface is dreadful if you're in my situation.\n\nSo, im looking for options. I tried AWS buckets and a bucket explorer, but it's not as convenient as i thought it would be. \n\nI imagine I'm just one of many in that situation - stuck with DP and paying through the nose for storage. Thank you.", "author_fullname": "t2_w3r2eeev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice needed: I'm ecosystem-locked in with dropbox - how do I get out of it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18to8vg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703859847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got 3 terabytes of data on dropbox.&lt;br/&gt;\nThis data consists of text files, email backups, notes, images, all my photos, work divided in hundreds of folders - in other words, it&amp;#39;s not 3tb of 10 videos, its 3TB of north of ONE MILLION files. It&amp;#39;s a lot. &lt;/p&gt;\n\n&lt;p&gt;At first DP worked well, but as time passed, i noticed major issues. Organizing things means having to get a very fast 3TB drive and manually do everything locally. Their web interface is dreadful if you&amp;#39;re in my situation.&lt;/p&gt;\n\n&lt;p&gt;So, im looking for options. I tried AWS buckets and a bucket explorer, but it&amp;#39;s not as convenient as i thought it would be. &lt;/p&gt;\n\n&lt;p&gt;I imagine I&amp;#39;m just one of many in that situation - stuck with DP and paying through the nose for storage. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18to8vg", "is_robot_indexable": true, "report_reasons": null, "author": "RadioSailor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18to8vg/advice_needed_im_ecosystemlocked_in_with_dropbox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18to8vg/advice_needed_im_ecosystemlocked_in_with_dropbox/", "subreddit_subscribers": 721689, "created_utc": 1703859847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got a decent deal on Fujitsu Fi-7260 (roughly $150) and seller said the ADF has 78400 on it's counter. Is that a lot for such scanner? Should I be worried about jamming or other issues (mainly on the mechanical part)?\n\nI've been searching for a quite while now and this machine seemed like a reasonable option for archiving family photos (given the price). However, also read a post where there was a side by side comparison with Fujitsu ix500 and the image quality was much better on ix500 - red tint on Fi-7160 and less detail in darker spots. Would Epson FastFoto FF680 be any better in regard of image quality?\n\nI will be scanning around 3000 photos and I do prioritize the time, so ADF is a must! (I don't have negatives, prints are my only option).\n\nThanks for any input!", "author_fullname": "t2_2wl4v5lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fujitsu Fi-7260/Fi-7160 lifespan of ADF for scanning family photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tk5z5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703845803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got a decent deal on Fujitsu Fi-7260 (roughly $150) and seller said the ADF has 78400 on it&amp;#39;s counter. Is that a lot for such scanner? Should I be worried about jamming or other issues (mainly on the mechanical part)?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching for a quite while now and this machine seemed like a reasonable option for archiving family photos (given the price). However, also read a post where there was a side by side comparison with Fujitsu ix500 and the image quality was much better on ix500 - red tint on Fi-7160 and less detail in darker spots. Would Epson FastFoto FF680 be any better in regard of image quality?&lt;/p&gt;\n\n&lt;p&gt;I will be scanning around 3000 photos and I do prioritize the time, so ADF is a must! (I don&amp;#39;t have negatives, prints are my only option).&lt;/p&gt;\n\n&lt;p&gt;Thanks for any input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tk5z5", "is_robot_indexable": true, "report_reasons": null, "author": "Voky0077", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tk5z5/fujitsu_fi7260fi7160_lifespan_of_adf_for_scanning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tk5z5/fujitsu_fi7260fi7160_lifespan_of_adf_for_scanning/", "subreddit_subscribers": 721689, "created_utc": 1703845803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a flexible solution to encrypt files **and** filenames before uploading them to the cloud.\n\nI looked at Cryptomator and Duplicacy, however, I cannot really work out the pros and cons of each. Is anybody here with experience with both tools?", "author_fullname": "t2_i66m1lt1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cryptomator vs Duplicacy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18t5yj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703801092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a flexible solution to encrypt files &lt;strong&gt;and&lt;/strong&gt; filenames before uploading them to the cloud.&lt;/p&gt;\n\n&lt;p&gt;I looked at Cryptomator and Duplicacy, however, I cannot really work out the pros and cons of each. Is anybody here with experience with both tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18t5yj4", "is_robot_indexable": true, "report_reasons": null, "author": "South-Beautiful-5135", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18t5yj4/cryptomator_vs_duplicacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18t5yj4/cryptomator_vs_duplicacy/", "subreddit_subscribers": 721689, "created_utc": 1703801092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't care about privacy because I will encrypt everything. I'm looking for a free cloud storage service that gives above 100 GB of storage with a decent upload and download speed.\n\nLikewise, I tried Terabox, but its download speed is awful. And Degoo doesn't support files above 256 MB.", "author_fullname": "t2_ojb3oyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some cloud storage services that give free storage above 100 GB with decent upload and download speed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18tynll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free Cloud Storage Recommendation", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703887157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t care about privacy because I will encrypt everything. I&amp;#39;m looking for a free cloud storage service that gives above 100 GB of storage with a decent upload and download speed.&lt;/p&gt;\n\n&lt;p&gt;Likewise, I tried Terabox, but its download speed is awful. And Degoo doesn&amp;#39;t support files above 256 MB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18tynll", "is_robot_indexable": true, "report_reasons": null, "author": "Rachid90", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tynll/what_are_some_cloud_storage_services_that_give/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tynll/what_are_some_cloud_storage_services_that_give/", "subreddit_subscribers": 721689, "created_utc": 1703887157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basic info about my setup: \nI have an Unraid server and a workstation PC with 3 NVMe drives and one large HDD, namely WD HC560 20TB.\nUnraid is kind of a cold storage solution for me. NVMes in my PC are more like hot storage, while the WD drive is somewhere in between - stuff that is backed up and needed occasionally but important enough that I want to get it relatively quickly, even if my Unraid server is down or fails.\nHowever, there are two problems with that solution.\n1. Noise and vibration. That particular HDD is quite loud. I could live with that if it wasn't for the vibrations. My case (Fractal zmeshify 2 XL) is just terrible in that area. I keep tweaking the setup, adding dampers, rubber spacers, re-fitting parts, but in the end there is always something that starts resonating. Sometimes to a point, when it really makes me furious from the frustration.\n2. Drive activity. I keep my PC on for long time, sometimes 14+hrs/day. I know HC560 is an enterprise drive and is perfectly fit for constant workload, but in my case it's actually idle for most of the time. But it won't go idle because Windows keeps doing stuff with it, just enough to make it do hundreds of head parkings a day. I'm already at 18000 cycles and the drive is just a few months old. I've read it can handle 1 million cycles and that is not what worries me. It's, again, the noise. Also, noise when after just a brief period of inactivity, Windows starts indexing or defragging it. \n\nSo, I know I have two choices. USB enclosure or small NAS. I need it to be robust, sleek and being able to handle a drive like that, with encryption.\n\nCan you recommend any specific products?", "author_fullname": "t2_9ws2pmbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best solution for an external HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tvu7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703879809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basic info about my setup: \nI have an Unraid server and a workstation PC with 3 NVMe drives and one large HDD, namely WD HC560 20TB.\nUnraid is kind of a cold storage solution for me. NVMes in my PC are more like hot storage, while the WD drive is somewhere in between - stuff that is backed up and needed occasionally but important enough that I want to get it relatively quickly, even if my Unraid server is down or fails.\nHowever, there are two problems with that solution.\n1. Noise and vibration. That particular HDD is quite loud. I could live with that if it wasn&amp;#39;t for the vibrations. My case (Fractal zmeshify 2 XL) is just terrible in that area. I keep tweaking the setup, adding dampers, rubber spacers, re-fitting parts, but in the end there is always something that starts resonating. Sometimes to a point, when it really makes me furious from the frustration.\n2. Drive activity. I keep my PC on for long time, sometimes 14+hrs/day. I know HC560 is an enterprise drive and is perfectly fit for constant workload, but in my case it&amp;#39;s actually idle for most of the time. But it won&amp;#39;t go idle because Windows keeps doing stuff with it, just enough to make it do hundreds of head parkings a day. I&amp;#39;m already at 18000 cycles and the drive is just a few months old. I&amp;#39;ve read it can handle 1 million cycles and that is not what worries me. It&amp;#39;s, again, the noise. Also, noise when after just a brief period of inactivity, Windows starts indexing or defragging it. &lt;/p&gt;\n\n&lt;p&gt;So, I know I have two choices. USB enclosure or small NAS. I need it to be robust, sleek and being able to handle a drive like that, with encryption.&lt;/p&gt;\n\n&lt;p&gt;Can you recommend any specific products?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "200TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tvu7f", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Meet842", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18tvu7f/best_solution_for_an_external_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tvu7f/best_solution_for_an_external_hdd/", "subreddit_subscribers": 721689, "created_utc": 1703879809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a followup to [this older post of mine](https://www.reddit.com/r/DataHoarder/comments/17ec8s3/researching_what_to_use_for_purely_local_linux/). I have been using rsnapshot, and it works well. The problem though is that it takes a _long_ time to run, because I have so many files.\n\nI further researched btrfs and btrbk, and I think I'll go that route for internal backups. Here's my plan:\n\nInternally, I'd set up the main data drive and the backup data drive to both use btrfs. Using btrfs snapshots and btrbk, I'll do atomic incremental backups. This should be much more efficient than running rsnapshot, because the files do not need to be scanned. And, by using a snapshot version history, I can roll back to older snapshots if necessary.\n\nIn addition, I have two external drives. One is at home, the other is in a safe deposit box somewhere else. Ideally, these drives would use different filesystems; for example, one would use XFS, the other ext4. Both filesystems would sit on top of dm-integrity. That way, I do not rely on just one filesystem (btrfs), and dm-integrity provides integrity checks that btrfs has but other filesystems don't. For the external drive backups, I would use rsnapshot. File scans would be necessary, but here, it is okay, since I'd update the external drive backups perhaps once every two weeks or so. When doing the external backup, I would only back up the newest state on the backup drives. That is, the btrfs snapshots would not be copied. That is sort of okay, since those are btrfs specific, so they can't be efficiently copied over to non-btrfs filesystems. And, rsnapshot itself does its own snapshots on the external drive.\n\nHow does this sound? Any pitfalls you can see here? Any recommendations, suggestions  etc.?", "author_fullname": "t2_v3szwqll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I could use your opinion on improving a setup for automated backups.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tuoek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703876783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a followup to &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/17ec8s3/researching_what_to_use_for_purely_local_linux/\"&gt;this older post of mine&lt;/a&gt;. I have been using rsnapshot, and it works well. The problem though is that it takes a &lt;em&gt;long&lt;/em&gt; time to run, because I have so many files.&lt;/p&gt;\n\n&lt;p&gt;I further researched btrfs and btrbk, and I think I&amp;#39;ll go that route for internal backups. Here&amp;#39;s my plan:&lt;/p&gt;\n\n&lt;p&gt;Internally, I&amp;#39;d set up the main data drive and the backup data drive to both use btrfs. Using btrfs snapshots and btrbk, I&amp;#39;ll do atomic incremental backups. This should be much more efficient than running rsnapshot, because the files do not need to be scanned. And, by using a snapshot version history, I can roll back to older snapshots if necessary.&lt;/p&gt;\n\n&lt;p&gt;In addition, I have two external drives. One is at home, the other is in a safe deposit box somewhere else. Ideally, these drives would use different filesystems; for example, one would use XFS, the other ext4. Both filesystems would sit on top of dm-integrity. That way, I do not rely on just one filesystem (btrfs), and dm-integrity provides integrity checks that btrfs has but other filesystems don&amp;#39;t. For the external drive backups, I would use rsnapshot. File scans would be necessary, but here, it is okay, since I&amp;#39;d update the external drive backups perhaps once every two weeks or so. When doing the external backup, I would only back up the newest state on the backup drives. That is, the btrfs snapshots would not be copied. That is sort of okay, since those are btrfs specific, so they can&amp;#39;t be efficiently copied over to non-btrfs filesystems. And, rsnapshot itself does its own snapshots on the external drive.&lt;/p&gt;\n\n&lt;p&gt;How does this sound? Any pitfalls you can see here? Any recommendations, suggestions  etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tuoek", "is_robot_indexable": true, "report_reasons": null, "author": "FourDimensionalTaco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tuoek/i_could_use_your_opinion_on_improving_a_setup_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tuoek/i_could_use_your_opinion_on_improving_a_setup_for/", "subreddit_subscribers": 721689, "created_utc": 1703876783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking for :\n\n* a 2 TB SSD external drive to backup my laptop on a weekly basis\n* a 2 TB HDD (which I'll leave at my parents' house) to backup every \\~ 6 months.\n\nThough it's probably a very simple thing compared to the concerns of most people on this sub, I figured you'd be the ones to ask.\n\nMy main concerns are reliability and speed (esp. for the SSD one), as the faster the backup, the more inclined I'll be to do it regularly.\n\nI'm running Fedora on a 2015 XPS 13 (which only has USB 3.0 ports), and will be backing up using rsync.\n\nI've read that using a NVME drive in an enclosure was the recommended move (see e.g. [the top comment on a post from this sub](https://www.reddit.com/r/DataHoarder/comments/169s3ol/i_need_help_choosing_an_external_hard_drive/)), and that ORICO seemed to be generally recommended for enclosures. I've also read the complete opposite regarding ORICO ([here for instance](https://www.reddit.com/r/buildapcsales/comments/102kphz/enclosure_orico_m2_nvme_sata_ssd_enclosure/)), saying that their chips tended to suck, so I'm completely lost.\n\n**Should I :**\n\n1. **Go with an internal drive + a case?**\n2. **If so, which case + drive pair would you recommend :**\n\n* **for a 2 TB SSD with a M.2 form factor, fast enough to quickly backup \\~ 1TB weekly?**\n* **for a reliable 2 TB HDD?**\n\nNB :\n\n* I don't mind if the drive speeds exceed that of my USB 3.0 ports, some futureproofness is good if I ever end up upgrading my laptop.\n* The M.2 form factor for the SSD is important for me, as I tend to take my backup disk with me when I leave my apartment without my laptop for extended periods of time (in case of a break-in).\n\nThanks in advance for your help!", "author_fullname": "t2_1476qp88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an external drive : should I go (internal + case)? Any good case manufacturer to recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18trog0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703869054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a 2 TB SSD external drive to backup my laptop on a weekly basis&lt;/li&gt;\n&lt;li&gt;a 2 TB HDD (which I&amp;#39;ll leave at my parents&amp;#39; house) to backup every ~ 6 months.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Though it&amp;#39;s probably a very simple thing compared to the concerns of most people on this sub, I figured you&amp;#39;d be the ones to ask.&lt;/p&gt;\n\n&lt;p&gt;My main concerns are reliability and speed (esp. for the SSD one), as the faster the backup, the more inclined I&amp;#39;ll be to do it regularly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m running Fedora on a 2015 XPS 13 (which only has USB 3.0 ports), and will be backing up using rsync.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read that using a NVME drive in an enclosure was the recommended move (see e.g. &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/169s3ol/i_need_help_choosing_an_external_hard_drive/\"&gt;the top comment on a post from this sub&lt;/a&gt;), and that ORICO seemed to be generally recommended for enclosures. I&amp;#39;ve also read the complete opposite regarding ORICO (&lt;a href=\"https://www.reddit.com/r/buildapcsales/comments/102kphz/enclosure_orico_m2_nvme_sata_ssd_enclosure/\"&gt;here for instance&lt;/a&gt;), saying that their chips tended to suck, so I&amp;#39;m completely lost.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Should I :&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Go with an internal drive + a case?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;If so, which case + drive pair would you recommend :&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;for a 2 TB SSD with a M.2 form factor, fast enough to quickly backup ~ 1TB weekly?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;for a reliable 2 TB HDD?&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;NB :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I don&amp;#39;t mind if the drive speeds exceed that of my USB 3.0 ports, some futureproofness is good if I ever end up upgrading my laptop.&lt;/li&gt;\n&lt;li&gt;The M.2 form factor for the SSD is important for me, as I tend to take my backup disk with me when I leave my apartment without my laptop for extended periods of time (in case of a break-in).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18trog0", "is_robot_indexable": true, "report_reasons": null, "author": "loevelo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18trog0/looking_for_an_external_drive_should_i_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18trog0/looking_for_an_external_drive_should_i_go/", "subreddit_subscribers": 721689, "created_utc": 1703869054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I'm looking to see if I could get some suggestions or recommendations on an upgrade path for my NAS in my current home environment. I'm also unsure if this is the best place to ask, so please let me know if this question doesn't fit the sub.\n\nMy setup isn't too sophisticated at the moment. I had purchased a QNAP TS-453A back in February of 2017 and have it loaded with four WD Red 8TB (WD80EFZX-68UW8N0) configured in RAID 5. It is solely dedicated to storage and nothing else; with the bulk of it used for media archive. It has proved a shockingly reliable little device. I have a headless Intel NUC6i7KYK that is dedicated to running a majority of the backend services my home network uses.\n\nIn the next year I'd like to expand my NAS storage and initially I had planned on simply purchasing replacement Exos X18's and go through the drive swap process but upon further thought, I figured I'd like to purchase an additional NAS and use my current one as a backup solution. I'm not particularly locked in to staying with QNAP and so any recommendations would be welcome. Admittedly, I have been looking at the TS-932PX-4G as I'm interested in adding in SSD caching to the array.\n\nAt any rate, thanks for any help or suggestions you may be able to provide! Or, if you can point me to a more appropriate subreddit for this sort of question, I would also greatly appreciate it.", "author_fullname": "t2_omti3ihjf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrade Path for my TS-453A Environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tre6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m looking to see if I could get some suggestions or recommendations on an upgrade path for my NAS in my current home environment. I&amp;#39;m also unsure if this is the best place to ask, so please let me know if this question doesn&amp;#39;t fit the sub.&lt;/p&gt;\n\n&lt;p&gt;My setup isn&amp;#39;t too sophisticated at the moment. I had purchased a QNAP TS-453A back in February of 2017 and have it loaded with four WD Red 8TB (WD80EFZX-68UW8N0) configured in RAID 5. It is solely dedicated to storage and nothing else; with the bulk of it used for media archive. It has proved a shockingly reliable little device. I have a headless Intel NUC6i7KYK that is dedicated to running a majority of the backend services my home network uses.&lt;/p&gt;\n\n&lt;p&gt;In the next year I&amp;#39;d like to expand my NAS storage and initially I had planned on simply purchasing replacement Exos X18&amp;#39;s and go through the drive swap process but upon further thought, I figured I&amp;#39;d like to purchase an additional NAS and use my current one as a backup solution. I&amp;#39;m not particularly locked in to staying with QNAP and so any recommendations would be welcome. Admittedly, I have been looking at the TS-932PX-4G as I&amp;#39;m interested in adding in SSD caching to the array.&lt;/p&gt;\n\n&lt;p&gt;At any rate, thanks for any help or suggestions you may be able to provide! Or, if you can point me to a more appropriate subreddit for this sort of question, I would also greatly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tre6u", "is_robot_indexable": true, "report_reasons": null, "author": "mriormro", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tre6u/upgrade_path_for_my_ts453a_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tre6u/upgrade_path_for_my_ts453a_environment/", "subreddit_subscribers": 721689, "created_utc": 1703868307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I built a scanner box\u2014plastic storage box with a side opening, lined with white paper, and hole for lens in the top, and set camera to shoot photo every 6 seconds to allow me to reach into box and switch item to be photographed. I photographed hundreds if pieces of kids artwork. \n\nI would like automate the cropping. I tried in Photoshop (File - Automate - Crop and Straighten Photos)  but it opens multiple image files (eg, the artwork, the green tape, the white space, etc.) in Photoshop for me to save manually.\n\n**Is there a way in Photoshop (or another tool) to crop what it knows to be the biggest/most probable thing, save just that piece, and close it? Or if that is not possible, then autosave everything and I will later delete the bits and pieces in Windows Explorer?**\n\nI duplicated all the JPGs into a new folder for this process in case there is an accident.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca", "author_fullname": "t2_7jhiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to auto crop in Photoshop and save only the largest image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cq0bp200b99c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbb56ec87aaafe2360552fcbb1172df9e5093092"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1144785d2fead755a40988e8e048f8df862d22e6"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddb10a6a2ad395002e1702dcf560659fe3f64e82"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8487169ade92baa8d5bd6addf6d9119c9740f70c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87e4d8ae35a6eca6e555840115a477e97f008400"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3a655a035ef062ecf308cfe75b4a10811c14faac"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca"}, "id": "cq0bp200b99c1"}}, "name": "t3_18tqk5x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YMWOQUsCtWAL6k5NUMRd7_7hL7sHHN9cN_WPy-0uZPU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703866102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built a scanner box\u2014plastic storage box with a side opening, lined with white paper, and hole for lens in the top, and set camera to shoot photo every 6 seconds to allow me to reach into box and switch item to be photographed. I photographed hundreds if pieces of kids artwork. &lt;/p&gt;\n\n&lt;p&gt;I would like automate the cropping. I tried in Photoshop (File - Automate - Crop and Straighten Photos)  but it opens multiple image files (eg, the artwork, the green tape, the white space, etc.) in Photoshop for me to save manually.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is there a way in Photoshop (or another tool) to crop what it knows to be the biggest/most probable thing, save just that piece, and close it? Or if that is not possible, then autosave everything and I will later delete the bits and pieces in Windows Explorer?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I duplicated all the JPGs into a new folder for this process in case there is an accident.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca\"&gt;https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tqk5x", "is_robot_indexable": true, "report_reasons": null, "author": "ThumperStrauss", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tqk5x/how_to_auto_crop_in_photoshop_and_save_only_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tqk5x/how_to_auto_crop_in_photoshop_and_save_only_the/", "subreddit_subscribers": 721689, "created_utc": 1703866102.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}