{"kind": "Listing", "data": {"after": "t3_18tv3l5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been part of a forum for nearly 20 years. It was fairly active 2002 until 2015ish and since then activity has dropped off quite a bit. I just found out that the last remaining moderator (and the guy who pays the bills and owns the forum) passed away. From what I gather, the bills have been paid until April 2024 so not much time is left.\n\nWhat would be the best way to archive the site? Basically make it so I can access it in its entirety offline? It's a standard forum (with some sections for members only) and has an image section as well. I've searched around and can't find a definitive best suggestion.\n\nI would like to spend the next few years slowly going through all the old posts and pictures, turning them into something like an ebook for myself and possibly distribute copies to the members I'm still in contact with.\n\nThanks everyone for your time.\n\n**Edit:** not sure what the infrastructure/software looks like but it says \"Powered by Invision Community\" at the very bottom.", "author_fullname": "t2_7ly38fl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Owner/only moderator of a forum suddenly passed away. How to archive as a member?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18trmtr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703869283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been part of a forum for nearly 20 years. It was fairly active 2002 until 2015ish and since then activity has dropped off quite a bit. I just found out that the last remaining moderator (and the guy who pays the bills and owns the forum) passed away. From what I gather, the bills have been paid until April 2024 so not much time is left.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to archive the site? Basically make it so I can access it in its entirety offline? It&amp;#39;s a standard forum (with some sections for members only) and has an image section as well. I&amp;#39;ve searched around and can&amp;#39;t find a definitive best suggestion.&lt;/p&gt;\n\n&lt;p&gt;I would like to spend the next few years slowly going through all the old posts and pictures, turning them into something like an ebook for myself and possibly distribute copies to the members I&amp;#39;m still in contact with.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone for your time.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; not sure what the infrastructure/software looks like but it says &amp;quot;Powered by Invision Community&amp;quot; at the very bottom.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18trmtr", "is_robot_indexable": true, "report_reasons": null, "author": "landboisteve", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18trmtr/owneronly_moderator_of_a_forum_suddenly_passed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18trmtr/owneronly_moderator_of_a_forum_suddenly_passed/", "subreddit_subscribers": 721682, "created_utc": 1703868933.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello data hoarders, I expect the vast majority of you know the game Roblox  at this point (if you don't, it's essentially a game creation platform),  so I'll cut right to the chase.\n\nIf  you believe that you may still have a hard drive from around the year  2006 and have at the very least installed the game, please attempt to  locate the drive (as soon as you are able to) and search these 2  directories:\n\n**C:\\\\Program Files\\\\Roblox Corporation\\\\ROBLOX** contains the latest version installed.\n\n**C:\\\\Documents and Settings\\\\All Users\\\\Application Data\\\\ROBLOX** contains misc. data and cached stuff.\n\nFurther information can be found at this link: [https://robloxopolis.com/2006-roblox-bounty/](https://robloxopolis.com/2006-roblox-bounty/)\n\nEmail [robloxclientsearch@gmail.com](mailto:robloxclientsearch@gmail.com) if you found something substantial, or need further direct assistance.\n\nIf a **2006** version is recovered and preserved successfully, the person who found it will receive a **$500 USD** reward. If you have any suggestions on how else to spread the word, please let us know. Thank you for your time.", "author_fullname": "t2_kchsyxiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[BOUNTY] Does anyone here remember playing the online game \"Roblox\" from 2006? All versions from that time period are lost.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tasv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1703814001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data hoarders, I expect the vast majority of you know the game Roblox  at this point (if you don&amp;#39;t, it&amp;#39;s essentially a game creation platform),  so I&amp;#39;ll cut right to the chase.&lt;/p&gt;\n\n&lt;p&gt;If  you believe that you may still have a hard drive from around the year  2006 and have at the very least installed the game, please attempt to  locate the drive (as soon as you are able to) and search these 2  directories:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;C:\\Program Files\\Roblox Corporation\\ROBLOX&lt;/strong&gt; contains the latest version installed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;C:\\Documents and Settings\\All Users\\Application Data\\ROBLOX&lt;/strong&gt; contains misc. data and cached stuff.&lt;/p&gt;\n\n&lt;p&gt;Further information can be found at this link: &lt;a href=\"https://robloxopolis.com/2006-roblox-bounty/\"&gt;https://robloxopolis.com/2006-roblox-bounty/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Email [&lt;a href=\"mailto:robloxclientsearch@gmail.com\"&gt;robloxclientsearch@gmail.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:robloxclientsearch@gmail.com\"&gt;robloxclientsearch@gmail.com&lt;/a&gt;) if you found something substantial, or need further direct assistance.&lt;/p&gt;\n\n&lt;p&gt;If a &lt;strong&gt;2006&lt;/strong&gt; version is recovered and preserved successfully, the person who found it will receive a &lt;strong&gt;$500 USD&lt;/strong&gt; reward. If you have any suggestions on how else to spread the word, please let us know. Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?auto=webp&amp;s=dbc8a1ccb7b91ec89be8d87e3dd1733fef5ab7e5", "width": 2000, "height": 973}, "resolutions": [{"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b3ce14d36f9ba44bb0625fbb7a46d990f72a4c1", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c140fd2860e409a0fcc84529ed68c417ff49e6a6", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c73694c68bd733161d119bf19443d0bcd682cde", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=96aaacb63479838128c6ff67e74ee42e09dcc49a", "width": 640, "height": 311}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5129cbfaf7dbe436978ee57d16566dbe15fa96af", "width": 960, "height": 467}, {"url": "https://external-preview.redd.it/lWg-IrL2ds_mudfeK5u3i18JQt6TfK6FeCXTY9BEd_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=415a1f9eb2b6f773e85a5a178505b2821e51db30", "width": 1080, "height": 525}], "variants": {}, "id": "ARnKGFIp06IW4MIg5BVdgwa5NZPj9IbzfcEZDI2EzIo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tasv5", "is_robot_indexable": true, "report_reasons": null, "author": "Loud_Negotiation4843", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tasv5/bounty_does_anyone_here_remember_playing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tasv5/bounty_does_anyone_here_remember_playing_the/", "subreddit_subscribers": 721682, "created_utc": 1703814001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, are there cases when corruption in an image / video file doesn't cause any visual artifacts?", "author_fullname": "t2_5ufxabnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible that data corruption / bit rot in a file may not cause any noticeable symptoms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpycu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703864532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, are there cases when corruption in an image / video file doesn&amp;#39;t cause any visual artifacts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpycu", "is_robot_indexable": true, "report_reasons": null, "author": "user1-reddit", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpycu/is_it_possible_that_data_corruption_bit_rot_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpycu/is_it_possible_that_data_corruption_bit_rot_in_a/", "subreddit_subscribers": 721682, "created_utc": 1703864532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I don't know if this has been posted earlier, and I've got limited technical knowledge when it comes to this stuff, but I really want to help save some of this information for posterity and I don't know how to go about it.\n\n\nAny tip would be greatly appreciated!", "author_fullname": "t2_kjh71cjt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CGSociety is closing up soon, decades of valuable data/information/discussion/artwork is going to be lost, what can I do to save a mirror of the site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tlukv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703852162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I don&amp;#39;t know if this has been posted earlier, and I&amp;#39;ve got limited technical knowledge when it comes to this stuff, but I really want to help save some of this information for posterity and I don&amp;#39;t know how to go about it.&lt;/p&gt;\n\n&lt;p&gt;Any tip would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tlukv", "is_robot_indexable": true, "report_reasons": null, "author": "randomfuckingpotato", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/", "subreddit_subscribers": 721682, "created_utc": 1703852162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's like the inverse of file compression, but you add some error correction code into it to improve resilience when archiving files. It would be great if it's battle proven and open source? Or at least open standard for easier retrieval after many years?", "author_fullname": "t2_bjeo1gwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a file format that can withstand some bit rot.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tra4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s like the inverse of file compression, but you add some error correction code into it to improve resilience when archiving files. It would be great if it&amp;#39;s battle proven and open source? Or at least open standard for easier retrieval after many years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tra4s", "is_robot_indexable": true, "report_reasons": null, "author": "--dany--", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tra4s/is_there_a_file_format_that_can_withstand_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tra4s/is_there_a_file_format_that_can_withstand_some/", "subreddit_subscribers": 721682, "created_utc": 1703868023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The name of the game to me is unironically power to weight (and capacity).\n\n\nI live on the go, currently have all my data in my laptop 4TB and an offsite 2.5\" 5TB hard drive.\n\n\nI guess I should set design goals and work from there? Is there a more proffessional way to do this? e.g...\n\n\nIn interest of brevity I'm for now only focusing on power but just being MINDFUL that I will have to account for these other factors.\n\n\nPriority 1 reliability+security\n\n\nPri 2+3 idle then activ power consumption - this is the difficulty\n\n\nPri 4 capacity\n\n\nPri 5 size+weight\n\n\nPri 6 usability\n\n\nPri 7 cost\n\n\nPri 8 ease of use&amp;setup - I am willing to solder, make my own PCBs, scripts, whatever BUUUUT most of all it needs to get done - improvement is better than a dream.\n\n\nTarget power excl. drives ~= 5w avg/day given arm based processor, phone running linux maybe?\n\nTarget power 20TB initially ~= 10-20w avg\n\nWhat happens when I run out of power (like system shuts off because battery ran out or I wanted to keep laptop powered)? etc...\n\n\n...\nI obviously need to incrementally develop this but what do I even start with? Buy a phone and a way to wire it to a 2.5\" drive and see what I can do? Advice would be greatly appreciated.", "author_fullname": "t2_4s2j111y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low mass, low power data hoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tmi3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703854669.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703854446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The name of the game to me is unironically power to weight (and capacity).&lt;/p&gt;\n\n&lt;p&gt;I live on the go, currently have all my data in my laptop 4TB and an offsite 2.5&amp;quot; 5TB hard drive.&lt;/p&gt;\n\n&lt;p&gt;I guess I should set design goals and work from there? Is there a more proffessional way to do this? e.g...&lt;/p&gt;\n\n&lt;p&gt;In interest of brevity I&amp;#39;m for now only focusing on power but just being MINDFUL that I will have to account for these other factors.&lt;/p&gt;\n\n&lt;p&gt;Priority 1 reliability+security&lt;/p&gt;\n\n&lt;p&gt;Pri 2+3 idle then activ power consumption - this is the difficulty&lt;/p&gt;\n\n&lt;p&gt;Pri 4 capacity&lt;/p&gt;\n\n&lt;p&gt;Pri 5 size+weight&lt;/p&gt;\n\n&lt;p&gt;Pri 6 usability&lt;/p&gt;\n\n&lt;p&gt;Pri 7 cost&lt;/p&gt;\n\n&lt;p&gt;Pri 8 ease of use&amp;amp;setup - I am willing to solder, make my own PCBs, scripts, whatever BUUUUT most of all it needs to get done - improvement is better than a dream.&lt;/p&gt;\n\n&lt;p&gt;Target power excl. drives ~= 5w avg/day given arm based processor, phone running linux maybe?&lt;/p&gt;\n\n&lt;p&gt;Target power 20TB initially ~= 10-20w avg&lt;/p&gt;\n\n&lt;p&gt;What happens when I run out of power (like system shuts off because battery ran out or I wanted to keep laptop powered)? etc...&lt;/p&gt;\n\n&lt;p&gt;...\nI obviously need to incrementally develop this but what do I even start with? Buy a phone and a way to wire it to a 2.5&amp;quot; drive and see what I can do? Advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "4TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tmi3c", "is_robot_indexable": true, "report_reasons": null, "author": "VoiceofRedditMkI", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18tmi3c/low_mass_low_power_data_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tmi3c/low_mass_low_power_data_hoarding/", "subreddit_subscribers": 721682, "created_utc": 1703854446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wondering if it is possible to backup a collection from archive.org that contains sub-collections so that files from sub-collections are put into their own sub-directories. Any idea how to accomplish this? As far as I know the ia app would put sub-collections in the same directory as all other other files.\n\n\nCollection that contains sub-collections: https://archive.org/details/softwarelibrary\nia app: https://archive.org/developers/internetarchive/cli.html", "author_fullname": "t2_bljn4qq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive: Backup of collections and sub-collections in separate folders possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tmv67", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703855638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if it is possible to backup a collection from archive.org that contains sub-collections so that files from sub-collections are put into their own sub-directories. Any idea how to accomplish this? As far as I know the ia app would put sub-collections in the same directory as all other other files.&lt;/p&gt;\n\n&lt;p&gt;Collection that contains sub-collections: &lt;a href=\"https://archive.org/details/softwarelibrary\"&gt;https://archive.org/details/softwarelibrary&lt;/a&gt;\nia app: &lt;a href=\"https://archive.org/developers/internetarchive/cli.html\"&gt;https://archive.org/developers/internetarchive/cli.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tmv67", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Analysis_1431", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tmv67/internet_archive_backup_of_collections_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tmv67/internet_archive_backup_of_collections_and/", "subreddit_subscribers": 721682, "created_utc": 1703855638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. Does anybody has an archive of liveleak's combat footage and war related videos? I just wandering, cause lots of vids had vanished with the website's shot down. I just managed to archive ruffly 600 items from their server back in 2015-16.", "author_fullname": "t2_p0f47tbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any long time archivists of liveleak?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpns6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703863764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. Does anybody has an archive of liveleak&amp;#39;s combat footage and war related videos? I just wandering, cause lots of vids had vanished with the website&amp;#39;s shot down. I just managed to archive ruffly 600 items from their server back in 2015-16.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpns6", "is_robot_indexable": true, "report_reasons": null, "author": "Ablackshado", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpns6/are_there_any_long_time_archivists_of_liveleak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpns6/are_there_any_long_time_archivists_of_liveleak/", "subreddit_subscribers": 721682, "created_utc": 1703863764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nhope I found the write place to ask. I use syncthing for syncing different folders. I am looking for a software, preferable opensource like syncthing, which makes backups of folders. Not huge in size. Preferable it can zip them to versions and store up to x versions. I would need it for synology, android and  windows.\n\n&amp;#x200B;\n\nFor example: Backup of different \"User\" folders of various programs (filebot, yuzu etc.). \n\nBackup of different Android \"User\" folders (emulator programs etc.)\n\n&amp;#x200B;\n\nHappy for any input!", "author_fullname": "t2_6ir04j5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Folder\" Backup Software, best case same program for Android, Synology and Windows (like syncthing for syncing folders)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tpf7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703863120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;hope I found the write place to ask. I use syncthing for syncing different folders. I am looking for a software, preferable opensource like syncthing, which makes backups of folders. Not huge in size. Preferable it can zip them to versions and store up to x versions. I would need it for synology, android and  windows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example: Backup of different &amp;quot;User&amp;quot; folders of various programs (filebot, yuzu etc.). &lt;/p&gt;\n\n&lt;p&gt;Backup of different Android &amp;quot;User&amp;quot; folders (emulator programs etc.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Happy for any input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tpf7r", "is_robot_indexable": true, "report_reasons": null, "author": "---in10se---", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tpf7r/folder_backup_software_best_case_same_program_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tpf7r/folder_backup_software_best_case_same_program_for/", "subreddit_subscribers": 721682, "created_utc": 1703863120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Specifically with regard to data integrity/bit-rot/etc, is there any reason to use RAR5's Recovery Volumes **and** PAR2?\n\ni.e. I create 5 RAR5 Recovery Volumes AND THEN enough PAR2 data to recover, at minimum, 5 of those RAR files.\n\n\\-VS-\n\nCreating 10 RAR5 Recovery Volumes in the first place...\n\n*(Assume 5 RAR5 Recovery Volumes plus PAR2 data is approximately equivalent to 10 RAR5 Recovery Volumes).*\n\nI initially thought I should do both (5 x RAR5 + PAR2)... however, if I am missing 6 RAR files, the outer PAR2 wrapper can't recover the inner RAR5 archive and everything goes in the bit bucket in the sky.\n\nAlternatively, 10 RAR5 Recovery Volumes handles 6 missing RAR files without an issue (obviously).\n\nNow, I'm leaning towards the latter but am wondering if I'm failing to think of a good reason to use BOTH, again, assuming each scheme results in basically the same amount of extraneous recovery data.\n\n(I completely understand I could create 10 RAR5 Recovery Volumes AND additional PAR2 recovery data, but this would increase the extraneous recovery data size.  And if I'm ok with that, why not create more RAR5 Recovery Volumes?)", "author_fullname": "t2_fnk2wyny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAR5: Recovery Volumes WITH PAR2?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18txdoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703884420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703883768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Specifically with regard to data integrity/bit-rot/etc, is there any reason to use RAR5&amp;#39;s Recovery Volumes &lt;strong&gt;and&lt;/strong&gt; PAR2?&lt;/p&gt;\n\n&lt;p&gt;i.e. I create 5 RAR5 Recovery Volumes AND THEN enough PAR2 data to recover, at minimum, 5 of those RAR files.&lt;/p&gt;\n\n&lt;p&gt;-VS-&lt;/p&gt;\n\n&lt;p&gt;Creating 10 RAR5 Recovery Volumes in the first place...&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(Assume 5 RAR5 Recovery Volumes plus PAR2 data is approximately equivalent to 10 RAR5 Recovery Volumes).&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I initially thought I should do both (5 x RAR5 + PAR2)... however, if I am missing 6 RAR files, the outer PAR2 wrapper can&amp;#39;t recover the inner RAR5 archive and everything goes in the bit bucket in the sky.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, 10 RAR5 Recovery Volumes handles 6 missing RAR files without an issue (obviously).&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m leaning towards the latter but am wondering if I&amp;#39;m failing to think of a good reason to use BOTH, again, assuming each scheme results in basically the same amount of extraneous recovery data.&lt;/p&gt;\n\n&lt;p&gt;(I completely understand I could create 10 RAR5 Recovery Volumes AND additional PAR2 recovery data, but this would increase the extraneous recovery data size.  And if I&amp;#39;m ok with that, why not create more RAR5 Recovery Volumes?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18txdoh", "is_robot_indexable": true, "report_reasons": null, "author": "4ppl3c0r3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18txdoh/rar5_recovery_volumes_with_par2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18txdoh/rar5_recovery_volumes_with_par2/", "subreddit_subscribers": 721682, "created_utc": 1703883768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I am trying to build a low-power storage array. I have picked some hardware together that I think will work, but I would like some confirmation or suggestions on how to do this better.\n\nThe hardware I picked is as follows:\n\n* Inter-Tech 2U-2412, 2U rack case with SAS/SATA 12G backplane with 12 3.5\" bays. This case requires 3 SFF-8087 connectors to the backplane.\n* LSI MegaRAID SAS 9341-8i\n* Intel RES2SV240 SAS expander\n* Gigabyte B550\n* 64 GB DDR4 RAM (non-ECC)\n* AMD Ryzen 3 4300G\n* 300W PSU\n\nI would like to build a low-power server that can run one or two VMs on the side. I would like to use TrueNAS with a ZFS software RAID. The RAID card has to be able to run in HBA/IT mode for this, as far as I understand.\n\nMy questions about this are?\n\n1. Will this selection of hardware work together nicely or are there severe bottlenecks?\n2. Are there any better hardware recommendations for a low-power budget storage array?\n3. How do I power the drives connected to the backplane? I have very limited experience with server grade hardware.\n\nI am generally a bit of a noob when it comes to storage that is a bit beyond the regular pc build, so I would like as much advice you can give me :)", "author_fullname": "t2_nrgq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will my build work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18tx5e8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703883176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am trying to build a low-power storage array. I have picked some hardware together that I think will work, but I would like some confirmation or suggestions on how to do this better.&lt;/p&gt;\n\n&lt;p&gt;The hardware I picked is as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inter-Tech 2U-2412, 2U rack case with SAS/SATA 12G backplane with 12 3.5&amp;quot; bays. This case requires 3 SFF-8087 connectors to the backplane.&lt;/li&gt;\n&lt;li&gt;LSI MegaRAID SAS 9341-8i&lt;/li&gt;\n&lt;li&gt;Intel RES2SV240 SAS expander&lt;/li&gt;\n&lt;li&gt;Gigabyte B550&lt;/li&gt;\n&lt;li&gt;64 GB DDR4 RAM (non-ECC)&lt;/li&gt;\n&lt;li&gt;AMD Ryzen 3 4300G&lt;/li&gt;\n&lt;li&gt;300W PSU&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would like to build a low-power server that can run one or two VMs on the side. I would like to use TrueNAS with a ZFS software RAID. The RAID card has to be able to run in HBA/IT mode for this, as far as I understand.&lt;/p&gt;\n\n&lt;p&gt;My questions about this are?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Will this selection of hardware work together nicely or are there severe bottlenecks?&lt;/li&gt;\n&lt;li&gt;Are there any better hardware recommendations for a low-power budget storage array?&lt;/li&gt;\n&lt;li&gt;How do I power the drives connected to the backplane? I have very limited experience with server grade hardware.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am generally a bit of a noob when it comes to storage that is a bit beyond the regular pc build, so I would like as much advice you can give me :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tx5e8", "is_robot_indexable": true, "report_reasons": null, "author": "EyeGaming2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tx5e8/will_my_build_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tx5e8/will_my_build_work/", "subreddit_subscribers": 721682, "created_utc": 1703883176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Samsung is $248 and the black version of the SanDisk is $199 on Amazon.\n\nI've read previous threads about heating problems, data loss and failures of Sandisk SSDs.\n\nBut both listings on Amazon have over 10k reviews and there are similar number of complaints about failures, overheating, firmware updating problems for both products.\n\nAny recent experiences with these brands, particularly the 4 TB versions which are relatively new?\n\nThinking of booting from it on my old iMac -- the internal drive is dying -- until I upgrade my computer.\n\nI actually bought one of the Samsung T7 Shield 4 TB a few months back.  I use it only to store my photos and videos and have used only about 450 GB.  It's been solid for me but not really stressing it like booting the OS from it.", "author_fullname": "t2_pc6088pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung T7 Shield 4 TB vs. SanDisk Extreme 4 TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ttje3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703873850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Samsung is $248 and the black version of the SanDisk is $199 on Amazon.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read previous threads about heating problems, data loss and failures of Sandisk SSDs.&lt;/p&gt;\n\n&lt;p&gt;But both listings on Amazon have over 10k reviews and there are similar number of complaints about failures, overheating, firmware updating problems for both products.&lt;/p&gt;\n\n&lt;p&gt;Any recent experiences with these brands, particularly the 4 TB versions which are relatively new?&lt;/p&gt;\n\n&lt;p&gt;Thinking of booting from it on my old iMac -- the internal drive is dying -- until I upgrade my computer.&lt;/p&gt;\n\n&lt;p&gt;I actually bought one of the Samsung T7 Shield 4 TB a few months back.  I use it only to store my photos and videos and have used only about 450 GB.  It&amp;#39;s been solid for me but not really stressing it like booting the OS from it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ttje3", "is_robot_indexable": true, "report_reasons": null, "author": "Frappant11", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ttje3/samsung_t7_shield_4_tb_vs_sandisk_extreme_4_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ttje3/samsung_t7_shield_4_tb_vs_sandisk_extreme_4_tb/", "subreddit_subscribers": 721682, "created_utc": 1703873850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hardware isn't my strong suit (yet!)  and I'm pressed for time these days so while I'm tempted to follow a youtube video on building my own, I've been tempted by  the Synology 4-Bay DiskStation DS923+ with a pair of either :\n\nSeagate ST6000VN0033 Iron Wolf Multimedia Server Storage 6TB Internal Hard Drive 3.5\" - SATA\n\nor\n\nSeagate IronWolf 8TB NAS Internal Hard Drive HDD \u2013 3.5 Inch SATA 6Gb/s 7200 RPM 256MB Cache for RAID Network Attached Storage \u2013(ST8000VNZ04/N004)\n\nLater I'll add more to the other slots but I figure 1 for storage 1 for redundancy to start will be the way to go.  \n\n\n  \nMy main computer is pretty capable but I've read that without a dedicated GPU the DS923+ is going to struggle transcoding videos if say, I'm trying to watch on my phone while away from home or if I give friends access to the server from their location.   \n\n\nWould this be a mistake or a good entry point? ", "author_fullname": "t2_w03bzp59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "considering first NAS for use primarily as a personal movie server but later as a homelab... DS923+ or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tqnro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703866371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hardware isn&amp;#39;t my strong suit (yet!)  and I&amp;#39;m pressed for time these days so while I&amp;#39;m tempted to follow a youtube video on building my own, I&amp;#39;ve been tempted by  the Synology 4-Bay DiskStation DS923+ with a pair of either :&lt;/p&gt;\n\n&lt;p&gt;Seagate ST6000VN0033 Iron Wolf Multimedia Server Storage 6TB Internal Hard Drive 3.5&amp;quot; - SATA&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Seagate IronWolf 8TB NAS Internal Hard Drive HDD \u2013 3.5 Inch SATA 6Gb/s 7200 RPM 256MB Cache for RAID Network Attached Storage \u2013(ST8000VNZ04/N004)&lt;/p&gt;\n\n&lt;p&gt;Later I&amp;#39;ll add more to the other slots but I figure 1 for storage 1 for redundancy to start will be the way to go.  &lt;/p&gt;\n\n&lt;p&gt;My main computer is pretty capable but I&amp;#39;ve read that without a dedicated GPU the DS923+ is going to struggle transcoding videos if say, I&amp;#39;m trying to watch on my phone while away from home or if I give friends access to the server from their location.   &lt;/p&gt;\n\n&lt;p&gt;Would this be a mistake or a good entry point? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tqnro", "is_robot_indexable": true, "report_reasons": null, "author": "overflowingpothos", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tqnro/considering_first_nas_for_use_primarily_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tqnro/considering_first_nas_for_use_primarily_as_a/", "subreddit_subscribers": 721682, "created_utc": 1703866371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a flexible solution to encrypt files **and** filenames before uploading them to the cloud.\n\nI looked at Cryptomator and Duplicacy, however, I cannot really work out the pros and cons of each. Is anybody here with experience with both tools?", "author_fullname": "t2_i66m1lt1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cryptomator vs Duplicacy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18t5yj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703801092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a flexible solution to encrypt files &lt;strong&gt;and&lt;/strong&gt; filenames before uploading them to the cloud.&lt;/p&gt;\n\n&lt;p&gt;I looked at Cryptomator and Duplicacy, however, I cannot really work out the pros and cons of each. Is anybody here with experience with both tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18t5yj4", "is_robot_indexable": true, "report_reasons": null, "author": "South-Beautiful-5135", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18t5yj4/cryptomator_vs_duplicacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18t5yj4/cryptomator_vs_duplicacy/", "subreddit_subscribers": 721682, "created_utc": 1703801092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basic info about my setup: \nI have an Unraid server and a workstation PC with 3 NVMe drives and one large HDD, namely WD HC560 20TB.\nUnraid is kind of a cold storage solution for me. NVMes in my PC are more like hot storage, while the WD drive is somewhere in between - stuff that is backed up and needed occasionally but important enough that I want to get it relatively quickly, even if my Unraid server is down or fails.\nHowever, there are two problems with that solution.\n1. Noise and vibration. That particular HDD is quite loud. I could live with that if it wasn't for the vibrations. My case (Fractal zmeshify 2 XL) is just terrible in that area. I keep tweaking the setup, adding dampers, rubber spacers, re-fitting parts, but in the end there is always something that starts resonating. Sometimes to a point, when it really makes me furious from the frustration.\n2. Drive activity. I keep my PC on for long time, sometimes 14+hrs/day. I know HC560 is an enterprise drive and is perfectly fit for constant workload, but in my case it's actually idle for most of the time. But it won't go idle because Windows keeps doing stuff with it, just enough to make it do hundreds of head parkings a day. I'm already at 18000 cycles and the drive is just a few months old. I've read it can handle 1 million cycles and that is not what worries me. It's, again, the noise. Also, noise when after just a brief period of inactivity, Windows starts indexing or defragging it. \n\nSo, I know I have two choices. USB enclosure or small NAS. I need it to be robust, sleek and being able to handle a drive like that, with encryption.\n\nCan you recommend any specific products?", "author_fullname": "t2_9ws2pmbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best solution for an external HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18tvu7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703879809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basic info about my setup: \nI have an Unraid server and a workstation PC with 3 NVMe drives and one large HDD, namely WD HC560 20TB.\nUnraid is kind of a cold storage solution for me. NVMes in my PC are more like hot storage, while the WD drive is somewhere in between - stuff that is backed up and needed occasionally but important enough that I want to get it relatively quickly, even if my Unraid server is down or fails.\nHowever, there are two problems with that solution.\n1. Noise and vibration. That particular HDD is quite loud. I could live with that if it wasn&amp;#39;t for the vibrations. My case (Fractal zmeshify 2 XL) is just terrible in that area. I keep tweaking the setup, adding dampers, rubber spacers, re-fitting parts, but in the end there is always something that starts resonating. Sometimes to a point, when it really makes me furious from the frustration.\n2. Drive activity. I keep my PC on for long time, sometimes 14+hrs/day. I know HC560 is an enterprise drive and is perfectly fit for constant workload, but in my case it&amp;#39;s actually idle for most of the time. But it won&amp;#39;t go idle because Windows keeps doing stuff with it, just enough to make it do hundreds of head parkings a day. I&amp;#39;m already at 18000 cycles and the drive is just a few months old. I&amp;#39;ve read it can handle 1 million cycles and that is not what worries me. It&amp;#39;s, again, the noise. Also, noise when after just a brief period of inactivity, Windows starts indexing or defragging it. &lt;/p&gt;\n\n&lt;p&gt;So, I know I have two choices. USB enclosure or small NAS. I need it to be robust, sleek and being able to handle a drive like that, with encryption.&lt;/p&gt;\n\n&lt;p&gt;Can you recommend any specific products?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "200TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tvu7f", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Meet842", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18tvu7f/best_solution_for_an_external_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tvu7f/best_solution_for_an_external_hdd/", "subreddit_subscribers": 721682, "created_utc": 1703879809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a followup to [this older post of mine](https://www.reddit.com/r/DataHoarder/comments/17ec8s3/researching_what_to_use_for_purely_local_linux/). I have been using rsnapshot, and it works well. The problem though is that it takes a _long_ time to run, because I have so many files.\n\nI further researched btrfs and btrbk, and I think I'll go that route for internal backups. Here's my plan:\n\nInternally, I'd set up the main data drive and the backup data drive to both use btrfs. Using btrfs snapshots and btrbk, I'll do atomic incremental backups. This should be much more efficient than running rsnapshot, because the files do not need to be scanned. And, by using a snapshot version history, I can roll back to older snapshots if necessary.\n\nIn addition, I have two external drives. One is at home, the other is in a safe deposit box somewhere else. Ideally, these drives would use different filesystems; for example, one would use XFS, the other ext4. Both filesystems would sit on top of dm-integrity. That way, I do not rely on just one filesystem (btrfs), and dm-integrity provides integrity checks that btrfs has but other filesystems don't. For the external drive backups, I would use rsnapshot. File scans would be necessary, but here, it is okay, since I'd update the external drive backups perhaps once every two weeks or so. When doing the external backup, I would only back up the newest state on the backup drives. That is, the btrfs snapshots would not be copied. That is sort of okay, since those are btrfs specific, so they can't be efficiently copied over to non-btrfs filesystems. And, rsnapshot itself does its own snapshots on the external drive.\n\nHow does this sound? Any pitfalls you can see here? Any recommendations, suggestions  etc.?", "author_fullname": "t2_v3szwqll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I could use your opinion on improving a setup for automated backups.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tuoek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703876783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a followup to &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/17ec8s3/researching_what_to_use_for_purely_local_linux/\"&gt;this older post of mine&lt;/a&gt;. I have been using rsnapshot, and it works well. The problem though is that it takes a &lt;em&gt;long&lt;/em&gt; time to run, because I have so many files.&lt;/p&gt;\n\n&lt;p&gt;I further researched btrfs and btrbk, and I think I&amp;#39;ll go that route for internal backups. Here&amp;#39;s my plan:&lt;/p&gt;\n\n&lt;p&gt;Internally, I&amp;#39;d set up the main data drive and the backup data drive to both use btrfs. Using btrfs snapshots and btrbk, I&amp;#39;ll do atomic incremental backups. This should be much more efficient than running rsnapshot, because the files do not need to be scanned. And, by using a snapshot version history, I can roll back to older snapshots if necessary.&lt;/p&gt;\n\n&lt;p&gt;In addition, I have two external drives. One is at home, the other is in a safe deposit box somewhere else. Ideally, these drives would use different filesystems; for example, one would use XFS, the other ext4. Both filesystems would sit on top of dm-integrity. That way, I do not rely on just one filesystem (btrfs), and dm-integrity provides integrity checks that btrfs has but other filesystems don&amp;#39;t. For the external drive backups, I would use rsnapshot. File scans would be necessary, but here, it is okay, since I&amp;#39;d update the external drive backups perhaps once every two weeks or so. When doing the external backup, I would only back up the newest state on the backup drives. That is, the btrfs snapshots would not be copied. That is sort of okay, since those are btrfs specific, so they can&amp;#39;t be efficiently copied over to non-btrfs filesystems. And, rsnapshot itself does its own snapshots on the external drive.&lt;/p&gt;\n\n&lt;p&gt;How does this sound? Any pitfalls you can see here? Any recommendations, suggestions  etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tuoek", "is_robot_indexable": true, "report_reasons": null, "author": "FourDimensionalTaco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tuoek/i_could_use_your_opinion_on_improving_a_setup_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tuoek/i_could_use_your_opinion_on_improving_a_setup_for/", "subreddit_subscribers": 721682, "created_utc": 1703876783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking for :\n\n* a 2 TB SSD external drive to backup my laptop on a weekly basis\n* a 2 TB HDD (which I'll leave at my parents' house) to backup every \\~ 6 months.\n\nThough it's probably a very simple thing compared to the concerns of most people on this sub, I figured you'd be the ones to ask.\n\nMy main concerns are reliability and speed (esp. for the SSD one), as the faster the backup, the more inclined I'll be to do it regularly.\n\nI'm running Fedora on a 2015 XPS 13 (which only has USB 3.0 ports), and will be backing up using rsync.\n\nI've read that using a NVME drive in an enclosure was the recommended move (see e.g. [the top comment on a post from this sub](https://www.reddit.com/r/DataHoarder/comments/169s3ol/i_need_help_choosing_an_external_hard_drive/)), and that ORICO seemed to be generally recommended for enclosures. I've also read the complete opposite regarding ORICO ([here for instance](https://www.reddit.com/r/buildapcsales/comments/102kphz/enclosure_orico_m2_nvme_sata_ssd_enclosure/)), saying that their chips tended to suck, so I'm completely lost.\n\n**Should I :**\n\n1. **Go with an internal drive + a case?**\n2. **If so, which case + drive pair would you recommend :**\n\n* **for a 2 TB SSD with a M.2 form factor, fast enough to quickly backup \\~ 1TB weekly?**\n* **for a reliable 2 TB HDD?**\n\nNB :\n\n* I don't mind if the drive speeds exceed that of my USB 3.0 ports, some futureproofness is good if I ever end up upgrading my laptop.\n* The M.2 form factor for the SSD is important for me, as I tend to take my backup disk with me when I leave my apartment without my laptop for extended periods of time (in case of a break-in).\n\nThanks in advance for your help!", "author_fullname": "t2_1476qp88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an external drive : should I go (internal + case)? Any good case manufacturer to recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18trog0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703869054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a 2 TB SSD external drive to backup my laptop on a weekly basis&lt;/li&gt;\n&lt;li&gt;a 2 TB HDD (which I&amp;#39;ll leave at my parents&amp;#39; house) to backup every ~ 6 months.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Though it&amp;#39;s probably a very simple thing compared to the concerns of most people on this sub, I figured you&amp;#39;d be the ones to ask.&lt;/p&gt;\n\n&lt;p&gt;My main concerns are reliability and speed (esp. for the SSD one), as the faster the backup, the more inclined I&amp;#39;ll be to do it regularly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m running Fedora on a 2015 XPS 13 (which only has USB 3.0 ports), and will be backing up using rsync.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read that using a NVME drive in an enclosure was the recommended move (see e.g. &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/169s3ol/i_need_help_choosing_an_external_hard_drive/\"&gt;the top comment on a post from this sub&lt;/a&gt;), and that ORICO seemed to be generally recommended for enclosures. I&amp;#39;ve also read the complete opposite regarding ORICO (&lt;a href=\"https://www.reddit.com/r/buildapcsales/comments/102kphz/enclosure_orico_m2_nvme_sata_ssd_enclosure/\"&gt;here for instance&lt;/a&gt;), saying that their chips tended to suck, so I&amp;#39;m completely lost.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Should I :&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Go with an internal drive + a case?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;If so, which case + drive pair would you recommend :&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;for a 2 TB SSD with a M.2 form factor, fast enough to quickly backup ~ 1TB weekly?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;for a reliable 2 TB HDD?&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;NB :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I don&amp;#39;t mind if the drive speeds exceed that of my USB 3.0 ports, some futureproofness is good if I ever end up upgrading my laptop.&lt;/li&gt;\n&lt;li&gt;The M.2 form factor for the SSD is important for me, as I tend to take my backup disk with me when I leave my apartment without my laptop for extended periods of time (in case of a break-in).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18trog0", "is_robot_indexable": true, "report_reasons": null, "author": "loevelo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18trog0/looking_for_an_external_drive_should_i_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18trog0/looking_for_an_external_drive_should_i_go/", "subreddit_subscribers": 721682, "created_utc": 1703869054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I'm looking to see if I could get some suggestions or recommendations on an upgrade path for my NAS in my current home environment. I'm also unsure if this is the best place to ask, so please let me know if this question doesn't fit the sub.\n\nMy setup isn't too sophisticated at the moment. I had purchased a QNAP TS-453A back in February of 2017 and have it loaded with four WD Red 8TB (WD80EFZX-68UW8N0) configured in RAID 5. It is solely dedicated to storage and nothing else; with the bulk of it used for media archive. It has proved a shockingly reliable little device. I have a headless Intel NUC6i7KYK that is dedicated to running a majority of the backend services my home network uses.\n\nIn the next year I'd like to expand my NAS storage and initially I had planned on simply purchasing replacement Exos X18's and go through the drive swap process but upon further thought, I figured I'd like to purchase an additional NAS and use my current one as a backup solution. I'm not particularly locked in to staying with QNAP and so any recommendations would be welcome. Admittedly, I have been looking at the TS-932PX-4G as I'm interested in adding in SSD caching to the array.\n\nAt any rate, thanks for any help or suggestions you may be able to provide! Or, if you can point me to a more appropriate subreddit for this sort of question, I would also greatly appreciate it.", "author_fullname": "t2_omti3ihjf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrade Path for my TS-453A Environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tre6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703868307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m looking to see if I could get some suggestions or recommendations on an upgrade path for my NAS in my current home environment. I&amp;#39;m also unsure if this is the best place to ask, so please let me know if this question doesn&amp;#39;t fit the sub.&lt;/p&gt;\n\n&lt;p&gt;My setup isn&amp;#39;t too sophisticated at the moment. I had purchased a QNAP TS-453A back in February of 2017 and have it loaded with four WD Red 8TB (WD80EFZX-68UW8N0) configured in RAID 5. It is solely dedicated to storage and nothing else; with the bulk of it used for media archive. It has proved a shockingly reliable little device. I have a headless Intel NUC6i7KYK that is dedicated to running a majority of the backend services my home network uses.&lt;/p&gt;\n\n&lt;p&gt;In the next year I&amp;#39;d like to expand my NAS storage and initially I had planned on simply purchasing replacement Exos X18&amp;#39;s and go through the drive swap process but upon further thought, I figured I&amp;#39;d like to purchase an additional NAS and use my current one as a backup solution. I&amp;#39;m not particularly locked in to staying with QNAP and so any recommendations would be welcome. Admittedly, I have been looking at the TS-932PX-4G as I&amp;#39;m interested in adding in SSD caching to the array.&lt;/p&gt;\n\n&lt;p&gt;At any rate, thanks for any help or suggestions you may be able to provide! Or, if you can point me to a more appropriate subreddit for this sort of question, I would also greatly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tre6u", "is_robot_indexable": true, "report_reasons": null, "author": "mriormro", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tre6u/upgrade_path_for_my_ts453a_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tre6u/upgrade_path_for_my_ts453a_environment/", "subreddit_subscribers": 721682, "created_utc": 1703868307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I built a scanner box\u2014plastic storage box with a side opening, lined with white paper, and hole for lens in the top, and set camera to shoot photo every 6 seconds to allow me to reach into box and switch item to be photographed. I photographed hundreds if pieces of kids artwork. \n\nI would like automate the cropping. I tried in Photoshop (File - Automate - Crop and Straighten Photos)  but it opens multiple image files (eg, the artwork, the green tape, the white space, etc.) in Photoshop for me to save manually.\n\n**Is there a way in Photoshop (or another tool) to crop what it knows to be the biggest/most probable thing, save just that piece, and close it? Or if that is not possible, then autosave everything and I will later delete the bits and pieces in Windows Explorer?**\n\nI duplicated all the JPGs into a new folder for this process in case there is an accident.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca", "author_fullname": "t2_7jhiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to auto crop in Photoshop and save only the largest image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cq0bp200b99c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbb56ec87aaafe2360552fcbb1172df9e5093092"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1144785d2fead755a40988e8e048f8df862d22e6"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddb10a6a2ad395002e1702dcf560659fe3f64e82"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8487169ade92baa8d5bd6addf6d9119c9740f70c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87e4d8ae35a6eca6e555840115a477e97f008400"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3a655a035ef062ecf308cfe75b4a10811c14faac"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca"}, "id": "cq0bp200b99c1"}}, "name": "t3_18tqk5x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YMWOQUsCtWAL6k5NUMRd7_7hL7sHHN9cN_WPy-0uZPU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703866102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built a scanner box\u2014plastic storage box with a side opening, lined with white paper, and hole for lens in the top, and set camera to shoot photo every 6 seconds to allow me to reach into box and switch item to be photographed. I photographed hundreds if pieces of kids artwork. &lt;/p&gt;\n\n&lt;p&gt;I would like automate the cropping. I tried in Photoshop (File - Automate - Crop and Straighten Photos)  but it opens multiple image files (eg, the artwork, the green tape, the white space, etc.) in Photoshop for me to save manually.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is there a way in Photoshop (or another tool) to crop what it knows to be the biggest/most probable thing, save just that piece, and close it? Or if that is not possible, then autosave everything and I will later delete the bits and pieces in Windows Explorer?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I duplicated all the JPGs into a new folder for this process in case there is an accident.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca\"&gt;https://preview.redd.it/cq0bp200b99c1.jpg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f78756f19be92e1c7e993ca36b1b6abb2beaffca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tqk5x", "is_robot_indexable": true, "report_reasons": null, "author": "ThumperStrauss", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tqk5x/how_to_auto_crop_in_photoshop_and_save_only_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tqk5x/how_to_auto_crop_in_photoshop_and_save_only_the/", "subreddit_subscribers": 721682, "created_utc": 1703866102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys today I'm writing this post to ask to you guys who are the pro data hoarders teachers.\n\nTo summarize my situation in short, I want a big combined storage.\n\nI just recieved 4 seagate exos series 16TB drives (so I'll be able to get a combined 64TB)\n\nbut I don't know what's the best option for me to combine my drives now.\n\n&amp;#x200B;\n\nafter googling for a while I found 5 options\n\nraid 0\n\nwindows stripped volume \n\nwindows spanned volume\n\nwindows storage space\n\nwindows drive pool\n\n&amp;#x200B;\n\nbut I did not want to use the raid 0 because few years ago by my own mistake, I've lost all my datas. \n\n(yep stupidily I've made a raid 0 with windows drive c and after a forceful windows update, my pc refused to boot anymore xD )\n\n&amp;#x200B;\n\nand with the same reason I don't want to use the windows stripped volume &amp; spanned volume\n\nbecause that's just the software raid 0 powered by Microsoft Windows.\n\n&amp;#x200B;\n\nSo \"Windows Storage Space\" and \"Windows Drive Pool\" are the options left now.\n\nAfter some researches, I've seen people suggesting to use the windows drive pool for several\n\nreasons, but these reasons were not clear to me so I decided to write here the questions to clearify the informations. \n\n&amp;#x200B;\n\nSo here are my questions\n\n1. I know that in raid 0, stripped volume and spanned volume systems, failing 1 drive results all data loss but I see lot of people using more than 10 drives in drive pool system. According to my understanding, adding more and more drives should increase the risk of losing all datas but people are just doing it. So I'm assuming that even 1 drive fails, not all datas are lost in drive pool system. Is it true ? If it is, I see why people are suggesting this option because it's the only option that doesn't make the whole data loss when 1 drive dies. So when a drive in pool dies it only dies with it's containing datas only ? \n\n&amp;#x200B;\n\n2.   I am using windows 10 atm and I will not use something else than windows 10 and 11.\n\nLet's pretend that I've made a drive pool of 4x 16TB = 64TB\n\nand here comes 3 scenarios.\n\nScenarios A : I upgrade my windows to 11, would my drive pool be recognized in windows 11 ?\n\nScenarios B : I clean-reinstall my windows 10 with a USB, would my drive pool be recognized again ?\n\nScenarios C : I remove my exact 4 drives in pool from my PC and connect them to my friend's PC with windows 10 or 11. would my drive pool be recognized ?\n\n&amp;#x200B;\n\n3. Let's pretend that I've made a drive pool of 4x 16TB = 64TB\n\nand after few years I realize that I have few spaces left in pool and decide to buy 4 more 16TB drives\n\nand add them in pool. so I'll get 128TB in pool but I want to know if my previous datas will remain.\n\nIn other word, I want to know if adding new drives in pool results force format and deletes the all datas and makes an empty drive. \n\n&amp;#x200B;\n\nso that's everything what I wanted to know. Please let me say thank you for reading my post and sorry for my poor english. Any additional tips or recommendations are always welcome !\n\n(I forgot to mention that I don't mind the speed, for the speedy stuff I am using the NVMEs, I' am seeking for stability here)", "author_fullname": "t2_15ywve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about managing the Drive Pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tkp06", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703847896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys today I&amp;#39;m writing this post to ask to you guys who are the pro data hoarders teachers.&lt;/p&gt;\n\n&lt;p&gt;To summarize my situation in short, I want a big combined storage.&lt;/p&gt;\n\n&lt;p&gt;I just recieved 4 seagate exos series 16TB drives (so I&amp;#39;ll be able to get a combined 64TB)&lt;/p&gt;\n\n&lt;p&gt;but I don&amp;#39;t know what&amp;#39;s the best option for me to combine my drives now.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;after googling for a while I found 5 options&lt;/p&gt;\n\n&lt;p&gt;raid 0&lt;/p&gt;\n\n&lt;p&gt;windows stripped volume &lt;/p&gt;\n\n&lt;p&gt;windows spanned volume&lt;/p&gt;\n\n&lt;p&gt;windows storage space&lt;/p&gt;\n\n&lt;p&gt;windows drive pool&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;but I did not want to use the raid 0 because few years ago by my own mistake, I&amp;#39;ve lost all my datas. &lt;/p&gt;\n\n&lt;p&gt;(yep stupidily I&amp;#39;ve made a raid 0 with windows drive c and after a forceful windows update, my pc refused to boot anymore xD )&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;and with the same reason I don&amp;#39;t want to use the windows stripped volume &amp;amp; spanned volume&lt;/p&gt;\n\n&lt;p&gt;because that&amp;#39;s just the software raid 0 powered by Microsoft Windows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So &amp;quot;Windows Storage Space&amp;quot; and &amp;quot;Windows Drive Pool&amp;quot; are the options left now.&lt;/p&gt;\n\n&lt;p&gt;After some researches, I&amp;#39;ve seen people suggesting to use the windows drive pool for several&lt;/p&gt;\n\n&lt;p&gt;reasons, but these reasons were not clear to me so I decided to write here the questions to clearify the informations. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So here are my questions&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I know that in raid 0, stripped volume and spanned volume systems, failing 1 drive results all data loss but I see lot of people using more than 10 drives in drive pool system. According to my understanding, adding more and more drives should increase the risk of losing all datas but people are just doing it. So I&amp;#39;m assuming that even 1 drive fails, not all datas are lost in drive pool system. Is it true ? If it is, I see why people are suggesting this option because it&amp;#39;s the only option that doesn&amp;#39;t make the whole data loss when 1 drive dies. So when a drive in pool dies it only dies with it&amp;#39;s containing datas only ? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;  I am using windows 10 atm and I will not use something else than windows 10 and 11.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Let&amp;#39;s pretend that I&amp;#39;ve made a drive pool of 4x 16TB = 64TB&lt;/p&gt;\n\n&lt;p&gt;and here comes 3 scenarios.&lt;/p&gt;\n\n&lt;p&gt;Scenarios A : I upgrade my windows to 11, would my drive pool be recognized in windows 11 ?&lt;/p&gt;\n\n&lt;p&gt;Scenarios B : I clean-reinstall my windows 10 with a USB, would my drive pool be recognized again ?&lt;/p&gt;\n\n&lt;p&gt;Scenarios C : I remove my exact 4 drives in pool from my PC and connect them to my friend&amp;#39;s PC with windows 10 or 11. would my drive pool be recognized ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Let&amp;#39;s pretend that I&amp;#39;ve made a drive pool of 4x 16TB = 64TB&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;and after few years I realize that I have few spaces left in pool and decide to buy 4 more 16TB drives&lt;/p&gt;\n\n&lt;p&gt;and add them in pool. so I&amp;#39;ll get 128TB in pool but I want to know if my previous datas will remain.&lt;/p&gt;\n\n&lt;p&gt;In other word, I want to know if adding new drives in pool results force format and deletes the all datas and makes an empty drive. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;so that&amp;#39;s everything what I wanted to know. Please let me say thank you for reading my post and sorry for my poor english. Any additional tips or recommendations are always welcome !&lt;/p&gt;\n\n&lt;p&gt;(I forgot to mention that I don&amp;#39;t mind the speed, for the speedy stuff I am using the NVMEs, I&amp;#39; am seeking for stability here)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tkp06", "is_robot_indexable": true, "report_reasons": null, "author": "Synchel", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tkp06/question_about_managing_the_drive_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tkp06/question_about_managing_the_drive_pool/", "subreddit_subscribers": 721682, "created_utc": 1703847896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I own an Intel NUC (8i7BEH) and I'm trying to evaluate any possibility of expanding storage on it without using USB or without purchasing an expensive Thunderbolt enclosure.\n\n&gt;  PCI Express Revision : Gen3\n\n&gt; PCI Express Configurations : M.2 slot with PCIe X4 lanes\n\n\nAre things like this at all reliable? And what speeds could they possibly even support?\n\n\n[https://www.silverstonetek.com/en/product/info/expansion-cards/ECS07/](https://www.silverstonetek.com/en/product/info/expansion-cards/ECS07/)", "author_fullname": "t2_d22msnuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M.2 to Sata expansion Intel NUC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18td0wi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1703820631.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703820402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I own an Intel NUC (8i7BEH) and I&amp;#39;m trying to evaluate any possibility of expanding storage on it without using USB or without purchasing an expensive Thunderbolt enclosure.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;PCI Express Revision : Gen3&lt;/p&gt;\n\n&lt;p&gt;PCI Express Configurations : M.2 slot with PCIe X4 lanes&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Are things like this at all reliable? And what speeds could they possibly even support?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.silverstonetek.com/en/product/info/expansion-cards/ECS07/\"&gt;https://www.silverstonetek.com/en/product/info/expansion-cards/ECS07/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18td0wi", "is_robot_indexable": true, "report_reasons": null, "author": "TryNotToShootYoself", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18td0wi/m2_to_sata_expansion_intel_nuc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18td0wi/m2_to_sata_expansion_intel_nuc/", "subreddit_subscribers": 721682, "created_utc": 1703820402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, just after some advice please.\n\nI have scrutiny installed on Pop! OS.\n\nIn the scrutiny settings/device status-thresholds, i have it set to 'Both'. This drive shows a failed status.\n\n&amp;#x200B;\n\n[Error ID 188 - command timeout](https://preview.redd.it/pk8zgugrj59c1.png?width=583&amp;format=png&amp;auto=webp&amp;s=edc0ec72becfc34d0e7a3726a8bc1cf137aa50dc)\n\nWhen i have device status-thresholds set to SMART, the same drive shows a passed status.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/gocgty7ck59c1.png?width=583&amp;format=png&amp;auto=webp&amp;s=fc2266528c20a666e69cb174cc2e3073576472be\n\nWhat setting should i go off? Scrutiny or SMART?\n\nAny help &amp;/or advice would be much appreciated.\n\nThank you", "author_fullname": "t2_4qkas1dl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scrutiny output vs SMART output", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gocgty7ck59c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/gocgty7ck59c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f450977eae37a1ca844cb09e12e8768e0d2f3792"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/gocgty7ck59c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79b733f25eaefd5e8943a4a1a0b97ac4411ba92c"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/gocgty7ck59c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb49df4cbbc3d949a27777960f6885c5e2acfc0a"}], "s": {"y": 385, "x": 583, "u": "https://preview.redd.it/gocgty7ck59c1.png?width=583&amp;format=png&amp;auto=webp&amp;s=fc2266528c20a666e69cb174cc2e3073576472be"}, "id": "gocgty7ck59c1"}, "pk8zgugrj59c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/pk8zgugrj59c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=94b70ba8571e6d2117f8f8626b68839703d6fab7"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/pk8zgugrj59c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eef7969942188c1567f05250d0e3940426833c00"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/pk8zgugrj59c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a4c5fc8be72fc7c966ad90f22dfd88acafb8b45"}], "s": {"y": 385, "x": 583, "u": "https://preview.redd.it/pk8zgugrj59c1.png?width=583&amp;format=png&amp;auto=webp&amp;s=edc0ec72becfc34d0e7a3726a8bc1cf137aa50dc"}, "id": "pk8zgugrj59c1"}}, "name": "t3_18td0ix", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BRimv0MRrHhXeSKuCqkrqvKmztHJ7xwi0EmGYLCa4vA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703820373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just after some advice please.&lt;/p&gt;\n\n&lt;p&gt;I have scrutiny installed on Pop! OS.&lt;/p&gt;\n\n&lt;p&gt;In the scrutiny settings/device status-thresholds, i have it set to &amp;#39;Both&amp;#39;. This drive shows a failed status.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pk8zgugrj59c1.png?width=583&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=edc0ec72becfc34d0e7a3726a8bc1cf137aa50dc\"&gt;Error ID 188 - command timeout&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;When i have device status-thresholds set to SMART, the same drive shows a passed status.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gocgty7ck59c1.png?width=583&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fc2266528c20a666e69cb174cc2e3073576472be\"&gt;https://preview.redd.it/gocgty7ck59c1.png?width=583&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fc2266528c20a666e69cb174cc2e3073576472be&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What setting should i go off? Scrutiny or SMART?&lt;/p&gt;\n\n&lt;p&gt;Any help &amp;amp;/or advice would be much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18td0ix", "is_robot_indexable": true, "report_reasons": null, "author": "DamageInc72", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18td0ix/scrutiny_output_vs_smart_output/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18td0ix/scrutiny_output_vs_smart_output/", "subreddit_subscribers": 721682, "created_utc": 1703820373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Mac owner using a Promise Technology 32TB Pegasus2 R8 Thunderbolt 2 RAID Storage Array (7200 rpm).  Since 2015 it has worked flawlessly.\n\nI'm currently using a 2023 Mac mini.  M2, 24GB memory, OS 13.3.\n\nToday I noticed the Promise was painfully slow... investigated further and it started giving me \"Bad Sector found on physical disk\" alerts and the external light on one drive turned amber.  It would still show up in my Finder but if I selected the Promise I would just get the beach ball of death.\n\nI decided to plug it into my old iMac and the Promise seems just fine there.  Using the Promise utility it confirms that there was a bad sector on one of the disks, but I can still use it as normal, and all the external lights are blue (normal). I'm currently backing up the really important files.\n\nWhy do you think that it seems fine with my old Mac?  Do I have to go through the hassle of replacing that one drive or is there something I can do to my Mac mini?\n\nThoughts appreciated.  Thanks.", "author_fullname": "t2_28opqlfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Please: Strange Promise Pegasus 2 Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18t7qlz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703805608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mac owner using a Promise Technology 32TB Pegasus2 R8 Thunderbolt 2 RAID Storage Array (7200 rpm).  Since 2015 it has worked flawlessly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using a 2023 Mac mini.  M2, 24GB memory, OS 13.3.&lt;/p&gt;\n\n&lt;p&gt;Today I noticed the Promise was painfully slow... investigated further and it started giving me &amp;quot;Bad Sector found on physical disk&amp;quot; alerts and the external light on one drive turned amber.  It would still show up in my Finder but if I selected the Promise I would just get the beach ball of death.&lt;/p&gt;\n\n&lt;p&gt;I decided to plug it into my old iMac and the Promise seems just fine there.  Using the Promise utility it confirms that there was a bad sector on one of the disks, but I can still use it as normal, and all the external lights are blue (normal). I&amp;#39;m currently backing up the really important files.&lt;/p&gt;\n\n&lt;p&gt;Why do you think that it seems fine with my old Mac?  Do I have to go through the hassle of replacing that one drive or is there something I can do to my Mac mini?&lt;/p&gt;\n\n&lt;p&gt;Thoughts appreciated.  Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18t7qlz", "is_robot_indexable": true, "report_reasons": null, "author": "WalkerHaines", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18t7qlz/advice_please_strange_promise_pegasus_2_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18t7qlz/advice_please_strange_promise_pegasus_2_problem/", "subreddit_subscribers": 721682, "created_utc": 1703805608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I enjoy hfy stories and have spotted a few authors that I like. Unfortunately I'm from the middle of nowhere and can't get internet at home. I can't sit outside the library for hours on my laptop. I download youtube videos that way to watch at home but every utility I have found for reddit is for images and video, not text. Does anyone know of a utility to dl all text posts with replies from a reddit profile?", "author_fullname": "t2_nbcguzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Save hfy for later.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18t6enr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703802208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I enjoy hfy stories and have spotted a few authors that I like. Unfortunately I&amp;#39;m from the middle of nowhere and can&amp;#39;t get internet at home. I can&amp;#39;t sit outside the library for hours on my laptop. I download youtube videos that way to watch at home but every utility I have found for reddit is for images and video, not text. Does anyone know of a utility to dl all text posts with replies from a reddit profile?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18t6enr", "is_robot_indexable": true, "report_reasons": null, "author": "DonktheDestroyer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18t6enr/save_hfy_for_later/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18t6enr/save_hfy_for_later/", "subreddit_subscribers": 721682, "created_utc": 1703802208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Apologies if this is the wrong place to ask\n\nWhere is the best place to buy large capacity hard drives in the UK? I'm running out of bytes and I've heard Amazon is a minefield and the store I used to go to doesn't sell hard drives anymore", "author_fullname": "t2_nrlr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to buy large capacity hard drives in the UK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18tv3l5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1703877877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is the wrong place to ask&lt;/p&gt;\n\n&lt;p&gt;Where is the best place to buy large capacity hard drives in the UK? I&amp;#39;m running out of bytes and I&amp;#39;ve heard Amazon is a minefield and the store I used to go to doesn&amp;#39;t sell hard drives anymore&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18tv3l5", "is_robot_indexable": true, "report_reasons": null, "author": "angry_pidgeon", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18tv3l5/where_to_buy_large_capacity_hard_drives_in_the_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18tv3l5/where_to_buy_large_capacity_hard_drives_in_the_uk/", "subreddit_subscribers": 721682, "created_utc": 1703877877.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}