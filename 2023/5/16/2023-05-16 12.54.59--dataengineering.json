{"kind": "Listing", "data": {"after": "t3_13if1m0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fairly self explanatory. It\u2019s not very fast, no nice REPL for prototyping, large ETL seem to end up being a big mess of SQL in different models. I find developing using the tool extremely boring. Errors aren\u2019t caught when run, dbt expectations is less expressive than if you just wrote your own assertions etc, etc. As far as I can tell the only benefit relative to a tool like DBR which also optimises DAGs is DDL statement automation. Could someone please tell me what I\u2019m missing here.", "author_fullname": "t2_f1galyad", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there something wrong with me, I hate dbt, what am I missing ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ip8e5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684195740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fairly self explanatory. It\u2019s not very fast, no nice REPL for prototyping, large ETL seem to end up being a big mess of SQL in different models. I find developing using the tool extremely boring. Errors aren\u2019t caught when run, dbt expectations is less expressive than if you just wrote your own assertions etc, etc. As far as I can tell the only benefit relative to a tool like DBR which also optimises DAGs is DDL statement automation. Could someone please tell me what I\u2019m missing here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ip8e5", "is_robot_indexable": true, "report_reasons": null, "author": "PeruseAndSnooze", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ip8e5/is_there_something_wrong_with_me_i_hate_dbt_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ip8e5/is_there_something_wrong_with_me_i_hate_dbt_what/", "subreddit_subscribers": 105716, "created_utc": 1684195740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A month ago I wrote [this](https://www.reddit.com/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/?utm_source=share&amp;utm_medium=web2x&amp;context=3) post and how I was put on a PIP by my company.\n\nWell, a month later today, I've been let go. \n\nI was randomly pulled into a meeting with HR and they explained letting me go. Throughout this month I really tried my best to achieve every single point they mentioned. What I find strange is how, in every meeting, they're always finding new reasons for my poor performance which aren't being relayed back to me. During the meeting I didn't bother explaining, arguing, or trying to convince them that I tried my best. I gracefully took it on board and said farewell. \n\nSo, what would you advise that I do next?\n\nEdit: from UK.", "author_fullname": "t2_81mnb4wb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've just been let go as a junior. What would you recommend be the next steps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13i85tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684162655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684156890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A month ago I wrote &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;this&lt;/a&gt; post and how I was put on a PIP by my company.&lt;/p&gt;\n\n&lt;p&gt;Well, a month later today, I&amp;#39;ve been let go. &lt;/p&gt;\n\n&lt;p&gt;I was randomly pulled into a meeting with HR and they explained letting me go. Throughout this month I really tried my best to achieve every single point they mentioned. What I find strange is how, in every meeting, they&amp;#39;re always finding new reasons for my poor performance which aren&amp;#39;t being relayed back to me. During the meeting I didn&amp;#39;t bother explaining, arguing, or trying to convince them that I tried my best. I gracefully took it on board and said farewell. &lt;/p&gt;\n\n&lt;p&gt;So, what would you advise that I do next?&lt;/p&gt;\n\n&lt;p&gt;Edit: from UK.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13i85tz", "is_robot_indexable": true, "report_reasons": null, "author": "Taurusamazing92", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13i85tz/ive_just_been_let_go_as_a_junior_what_would_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13i85tz/ive_just_been_let_go_as_a_junior_what_would_you/", "subreddit_subscribers": 105716, "created_utc": 1684156890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1 - Every project should be classified as a major or minor one. Here are some examples of major ones:\n\n* a pipeline that extracts data from unknown external API, joins with existing data from data warehouse and produces some output tables.\n* a pipeline that consumes more than 1TB of data in the first try, regardless of complexity.\n* a pipeline that joins existing data from data warehouse with some new data from a just purchased company's data warehouse in the same cloud.\n\nFor every major project, the team should follow the following steps:\n\n* a brainstorm session, led by a senior/lead/manager (depending on the complexity), that produces a specification of requirements.\n* The lead engineer then refines the specification so that it includes all permission requests and business requirements translated into technical terms.\n* Permission requests are then given to lead/manager so that team can fast track them. There should be one such JIRA ticket for one project, unless more than one people are required to request permissions.\n* Technical requirements are then divided by the team, preferably no more than 3 engineers, and written into JIRA tickets.\n\nThere are so many projects that I have worked on that no one bothers to do a thorough analysis so that junior engineers have to scramble to ask permissions left and right while managers/lead should do that. It wastes so much time and brings so much frustration.\n\n&amp;#x200B;\n\n2 - Every major project should produce full documentations in ONE PLACE.\n\n* The specification\n* Each engineer should submit documentation (can be in the format of code comments) too\n* Lead eventually gather them together and form a unified doc\n* Most important, stakeholders should be tagged, and each engineer should be tagged too so that people can figure out the ownership quickly\n\nOK I get it. No one wants to write documentation. But please, don't use 4 platforms for documentation! And don't let other people guess the owner by looking at Git Blame! Ownership should always go to the engineer who leads the project, or the manager if the said engineer leaves.\n\nEvery documentation should contain a WHY, a HOW and a WHAT and a WHAT IF section. Yes we will probably spend more time writing docs than developing stuffs but I think that's what things should be.\n\n&amp;#x200B;\n\n3 - Full evaluation is needed for new tools/frameworks/language.\n\n* Does the new toy satisfy all of our requirements? And if not how long it takes to develop?\n* Does the new toy satisfy even the core requirements? And if not we should not migrate.\n* Does the new toy add significant value? If not then it's going to be someone else's resume project and I don't like it.\n* How much cost if we want to run the same thing on two tools for a while? For sure you cannot migrate in one shot.", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some workflow I really want to inject into our team if I'm the lead/manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13if51s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684173189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;1 - Every project should be classified as a major or minor one. Here are some examples of major ones:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a pipeline that extracts data from unknown external API, joins with existing data from data warehouse and produces some output tables.&lt;/li&gt;\n&lt;li&gt;a pipeline that consumes more than 1TB of data in the first try, regardless of complexity.&lt;/li&gt;\n&lt;li&gt;a pipeline that joins existing data from data warehouse with some new data from a just purchased company&amp;#39;s data warehouse in the same cloud.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For every major project, the team should follow the following steps:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a brainstorm session, led by a senior/lead/manager (depending on the complexity), that produces a specification of requirements.&lt;/li&gt;\n&lt;li&gt;The lead engineer then refines the specification so that it includes all permission requests and business requirements translated into technical terms.&lt;/li&gt;\n&lt;li&gt;Permission requests are then given to lead/manager so that team can fast track them. There should be one such JIRA ticket for one project, unless more than one people are required to request permissions.&lt;/li&gt;\n&lt;li&gt;Technical requirements are then divided by the team, preferably no more than 3 engineers, and written into JIRA tickets.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There are so many projects that I have worked on that no one bothers to do a thorough analysis so that junior engineers have to scramble to ask permissions left and right while managers/lead should do that. It wastes so much time and brings so much frustration.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2 - Every major project should produce full documentations in ONE PLACE.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The specification&lt;/li&gt;\n&lt;li&gt;Each engineer should submit documentation (can be in the format of code comments) too&lt;/li&gt;\n&lt;li&gt;Lead eventually gather them together and form a unified doc&lt;/li&gt;\n&lt;li&gt;Most important, stakeholders should be tagged, and each engineer should be tagged too so that people can figure out the ownership quickly&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;OK I get it. No one wants to write documentation. But please, don&amp;#39;t use 4 platforms for documentation! And don&amp;#39;t let other people guess the owner by looking at Git Blame! Ownership should always go to the engineer who leads the project, or the manager if the said engineer leaves.&lt;/p&gt;\n\n&lt;p&gt;Every documentation should contain a WHY, a HOW and a WHAT and a WHAT IF section. Yes we will probably spend more time writing docs than developing stuffs but I think that&amp;#39;s what things should be.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3 - Full evaluation is needed for new tools/frameworks/language.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Does the new toy satisfy all of our requirements? And if not how long it takes to develop?&lt;/li&gt;\n&lt;li&gt;Does the new toy satisfy even the core requirements? And if not we should not migrate.&lt;/li&gt;\n&lt;li&gt;Does the new toy add significant value? If not then it&amp;#39;s going to be someone else&amp;#39;s resume project and I don&amp;#39;t like it.&lt;/li&gt;\n&lt;li&gt;How much cost if we want to run the same thing on two tools for a while? For sure you cannot migrate in one shot.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13if51s", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13if51s/some_workflow_i_really_want_to_inject_into_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13if51s/some_workflow_i_really_want_to_inject_into_our/", "subreddit_subscribers": 105716, "created_utc": 1684173189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently seen a few posts asking about working with data in the context of a startup, including a few about setting up a stack and doing data modelling.\n\nAs luck would have it, I've been writing some reflections on those subjects. I'm shortly going to be moving on from my current org (which I joined when it was very early stage) and wanted to record some thoughts before I leave and memory fades...\n\nAnyway, I have finally published a series of three articles on our engineering blog! I've entitled it 'data modelling for startups', and you can find each article here:\n- [Part I](https://medium.com/apolitical-engineering/data-modelling-for-startups-part-i-f566af2a88ca)\n- [Part II](https://medium.com/apolitical-engineering/data-modelling-for-startups-part-ii-1b1fa58700e4)\n- [Part III](https://medium.com/apolitical-engineering/data-modelling-for-startups-part-iii-aca31e0f4176)\n\nI hope some of you find these interesting or useful. In any case I would really appreciate any thoughts/feedback from the hivemind!", "author_fullname": "t2_7920orfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling for startups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ig4tr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684175402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently seen a few posts asking about working with data in the context of a startup, including a few about setting up a stack and doing data modelling.&lt;/p&gt;\n\n&lt;p&gt;As luck would have it, I&amp;#39;ve been writing some reflections on those subjects. I&amp;#39;m shortly going to be moving on from my current org (which I joined when it was very early stage) and wanted to record some thoughts before I leave and memory fades...&lt;/p&gt;\n\n&lt;p&gt;Anyway, I have finally published a series of three articles on our engineering blog! I&amp;#39;ve entitled it &amp;#39;data modelling for startups&amp;#39;, and you can find each article here:\n- &lt;a href=\"https://medium.com/apolitical-engineering/data-modelling-for-startups-part-i-f566af2a88ca\"&gt;Part I&lt;/a&gt;\n- &lt;a href=\"https://medium.com/apolitical-engineering/data-modelling-for-startups-part-ii-1b1fa58700e4\"&gt;Part II&lt;/a&gt;\n- &lt;a href=\"https://medium.com/apolitical-engineering/data-modelling-for-startups-part-iii-aca31e0f4176\"&gt;Part III&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope some of you find these interesting or useful. In any case I would really appreciate any thoughts/feedback from the hivemind!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?auto=webp&amp;v=enabled&amp;s=1b76a0cd507dc3c5899786dbd2f8c075577d282e", "width": 1008, "height": 777}, "resolutions": [{"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e508e4b9868bf5c72a3e9ab5003896f3461b19b3", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a15cfe3ac73643cc988628ba0703db3555a037a7", "width": 216, "height": 166}, {"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c27903ffdf784e7b529a262252249e490792bb97", "width": 320, "height": 246}, {"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358194f8b5af1811be5e87fea8169116a923ec14", "width": 640, "height": 493}, {"url": "https://external-preview.redd.it/iJzM2LyYQv30f7PaW9_dIKpq2Sqh1f98OCenmWGwM-g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4bc9ad11ec62fff87ae2f09144ad9542e002ef5", "width": 960, "height": 740}], "variants": {}, "id": "rvDHp4zy54kMDypCos4omdQ12whW9NbR3sOYI2zRP5A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13ig4tr", "is_robot_indexable": true, "report_reasons": null, "author": "PaddyAlton", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ig4tr/data_modelling_for_startups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ig4tr/data_modelling_for_startups/", "subreddit_subscribers": 105716, "created_utc": 1684175402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,  can anyone point me to some good resources for learning Databricks/Spark. I\u2019m open to paid or free courses.\n\nI\u2019m potentially looking into taking the Databricks Certified Data Engineer Professional Exam as well.\n\nAny resources for a good hands of way of learning through projects would be appreciated.\n\nThank you.", "author_fullname": "t2_89q105yt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13i8u4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684158443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,  can anyone point me to some good resources for learning Databricks/Spark. I\u2019m open to paid or free courses.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m potentially looking into taking the Databricks Certified Data Engineer Professional Exam as well.&lt;/p&gt;\n\n&lt;p&gt;Any resources for a good hands of way of learning through projects would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13i8u4y", "is_robot_indexable": true, "report_reasons": null, "author": "Technical_Rutabaga67", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13i8u4y/databricks_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13i8u4y/databricks_learning/", "subreddit_subscribers": 105716, "created_utc": 1684158443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst in the finance domain and have worked on EDA, dashboard building and some tree models. I have started to feel that Analytics is not for me. I don't enjoy it. I like when I have been asked to work on tasks which require me to write codes (like automating an excel report to Rmarkdown report, data preparation for analysis and writing calculated fields in Tableau). I think i feel this way because I can visualise the output that way and then can sit for hours to achieve that. However analytics is something different. There is no fixed output and on the top of it you need to have a strong domain understanding to do the analysis. I feel DE might be for me. I am confused because I changed my role to data analytics 2 years back and now I am again thinking of changing the role. \n\nSo my question is to all the people who moved to DE, what were your reasons?\nAlso, suggest me if I am thinking the right way.\n\nThank you so much for your valuable inputs.", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why you decided to move from Analytics (Data Scientist/Data Analyst) to a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13iwokt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684217061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst in the finance domain and have worked on EDA, dashboard building and some tree models. I have started to feel that Analytics is not for me. I don&amp;#39;t enjoy it. I like when I have been asked to work on tasks which require me to write codes (like automating an excel report to Rmarkdown report, data preparation for analysis and writing calculated fields in Tableau). I think i feel this way because I can visualise the output that way and then can sit for hours to achieve that. However analytics is something different. There is no fixed output and on the top of it you need to have a strong domain understanding to do the analysis. I feel DE might be for me. I am confused because I changed my role to data analytics 2 years back and now I am again thinking of changing the role. &lt;/p&gt;\n\n&lt;p&gt;So my question is to all the people who moved to DE, what were your reasons?\nAlso, suggest me if I am thinking the right way.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much for your valuable inputs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13iwokt", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13iwokt/why_you_decided_to_move_from_analytics_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13iwokt/why_you_decided_to_move_from_analytics_data/", "subreddit_subscribers": 105716, "created_utc": 1684217061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Months? Years? Decades? Never?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When did Data Engineering start \"clicking\" for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13in62c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684190679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Months? Years? Decades? Never?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13in62c", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13in62c/when_did_data_engineering_start_clicking_for_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13in62c/when_did_data_engineering_start_clicking_for_you/", "subreddit_subscribers": 105716, "created_utc": 1684190679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fuypuqcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Version Control Data Pipelines Using the Medallion Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": true, "name": "t3_13j2kyc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4fL9huhf2PyrPEJRPEpphtB3u7qvfR3hbr_w3Ey3Nhw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684236738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/version-control-data-pipelines-medallion-architecture/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?auto=webp&amp;v=enabled&amp;s=0798ce0b32b898304ff3f7ada66636c1e5ddd062", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8deaf3521f5ad2ac56520c6d1fd827175bd8ff1c", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae6983711b568f74bbaa0db43d3e6871a6a455a6", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=372e4fecde84db7d9f5acf12715619be3c31fa8d", "width": 320, "height": 274}], "variants": {}, "id": "_bkpW0AXYJ9FWCIiGSYjujhYfz_Us5R6mF_dVLAssLE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13j2kyc", "is_robot_indexable": true, "report_reasons": null, "author": "towtoo893", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2kyc/version_control_data_pipelines_using_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/version-control-data-pipelines-medallion-architecture/", "subreddit_subscribers": 105716, "created_utc": 1684236738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team likes to maintain 3 environments: DEV, QA, and PRD. Each environment has a database for the raw data which is just a daily or ad-hoc clone from PRD. There is then another database for dbt transformations called &lt;env&gt;_INFOMART.\n\nCloning down is always a headache since running something like\n\n```\nCREATE OR REPLACE DATABASE QA_RAW\nCLONE PRD_RAW\n```\n\nwiill update the data, but all of the permissions will be blown away and needs to be created from scratch each time.\n\nWe currently follow a similar approach to this: https://link.medium.com/d22IMBHSPzb, but honestly why does it have to be this hard? Why can't we just use a COPY GRANTS option like we can for tables?\n\nI really want to know if I'm missing something simple or what others are doing to alleviate this issue. What I advocate for our team is to stop cloning down and just give our dbt roles read from PRD and writes to their own environment.\n\nThoughts?", "author_fullname": "t2_1o8t8mmj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is SnowFlake Database Cloning so Difficult (or what am I missing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13irr55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684202413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team likes to maintain 3 environments: DEV, QA, and PRD. Each environment has a database for the raw data which is just a daily or ad-hoc clone from PRD. There is then another database for dbt transformations called &amp;lt;env&amp;gt;_INFOMART.&lt;/p&gt;\n\n&lt;p&gt;Cloning down is always a headache since running something like&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\nCREATE OR REPLACE DATABASE QA_RAW\nCLONE PRD_RAW\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;wiill update the data, but all of the permissions will be blown away and needs to be created from scratch each time.&lt;/p&gt;\n\n&lt;p&gt;We currently follow a similar approach to this: &lt;a href=\"https://link.medium.com/d22IMBHSPzb\"&gt;https://link.medium.com/d22IMBHSPzb&lt;/a&gt;, but honestly why does it have to be this hard? Why can&amp;#39;t we just use a COPY GRANTS option like we can for tables?&lt;/p&gt;\n\n&lt;p&gt;I really want to know if I&amp;#39;m missing something simple or what others are doing to alleviate this issue. What I advocate for our team is to stop cloning down and just give our dbt roles read from PRD and writes to their own environment.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ku7iZLAG0L-40ijpPMEMWvyHRYyigKHY-tzRLZv03L8.jpg?auto=webp&amp;v=enabled&amp;s=88e0e889787dd5842b9261866d8c10c5bf439105", "width": 854, "height": 258}, "resolutions": [{"url": "https://external-preview.redd.it/ku7iZLAG0L-40ijpPMEMWvyHRYyigKHY-tzRLZv03L8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71d757c2c7a64ca29661f84194c86c9f8ec8fb3f", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/ku7iZLAG0L-40ijpPMEMWvyHRYyigKHY-tzRLZv03L8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28fc48c56f984f8e8570c9b478eb047db8a7e424", "width": 216, "height": 65}, {"url": "https://external-preview.redd.it/ku7iZLAG0L-40ijpPMEMWvyHRYyigKHY-tzRLZv03L8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adcda17583f3637a5c993f82ec36bea15c8e9849", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/ku7iZLAG0L-40ijpPMEMWvyHRYyigKHY-tzRLZv03L8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1db13567170bebb2f42eb723ffbc484a66d82d9", "width": 640, "height": 193}], "variants": {}, "id": "7zmP8J5snV8R_jPvWvc26_1YMGYiSPzqoO95lVPCr8E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13irr55", "is_robot_indexable": true, "report_reasons": null, "author": "TheBoldTilde", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13irr55/why_is_snowflake_database_cloning_so_difficult_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13irr55/why_is_snowflake_database_cloning_so_difficult_or/", "subreddit_subscribers": 105716, "created_utc": 1684202413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4qttbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Taipy: Graph-Based Data Pipelines in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "name": "t3_13ian40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ApXMcocvxMEvl7RE4rPe9e8PoqEqmOsijFznKpFwRno.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684162511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wz18xm89e00b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wz18xm89e00b1.png?auto=webp&amp;v=enabled&amp;s=c68315c27616bb869ed67366fd658fd3e3c54633", "width": 1842, "height": 717}, "resolutions": [{"url": "https://preview.redd.it/wz18xm89e00b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7262fa90f6d473c3fb4647039a741d64bfed3db9", "width": 108, "height": 42}, {"url": "https://preview.redd.it/wz18xm89e00b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=556d0a1a853bb8ddb3f8dced0d57bb1c6d961e09", "width": 216, "height": 84}, {"url": "https://preview.redd.it/wz18xm89e00b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=257be62926e1f70d2803de366a65f0f057915969", "width": 320, "height": 124}, {"url": "https://preview.redd.it/wz18xm89e00b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53fe3261a259b09a8d093e97e1f30ee1bb65cb2d", "width": 640, "height": 249}, {"url": "https://preview.redd.it/wz18xm89e00b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2025a5c4da2b21acda0b40004fe73021bb91cb6", "width": 960, "height": 373}, {"url": "https://preview.redd.it/wz18xm89e00b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ae5204fbadb8311d6bff28cfec181feaafd4a90", "width": 1080, "height": 420}], "variants": {}, "id": "2YKET0ktJYSbCbTKFn3GDFy_E9eydZrArIYLZFDZL5I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13ian40", "is_robot_indexable": true, "report_reasons": null, "author": "Alyx1337", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ian40/taipy_graphbased_data_pipelines_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wz18xm89e00b1.png", "subreddit_subscribers": 105716, "created_utc": 1684162511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have two data sets with the following data:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kkadd9ldd10b1.png?width=319&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aacec49928b640fd7ab4fcf83f96bc4dd396e063\n\n&amp;#x200B;\n\n \n\nGiven the interchange\\_rate value in the source file, I need to get the closest match of rebate\\_rate from the lookup table. In the image you can see that the transaction\\_id 2 has the highest interchange\\_rate and therefore, I need to get the highest rebate\\_rate; transaction\\_id 1 is the lowest interchange\\_rate and therefore get the lowest rebate\\_rate.\n\nThe red column I did manually using Excel just to show it as an example, but that's the expected output.\n\nMy initial idea is to loop through the rows in the source file, and for each line search for the closest match in the lookup table. But I'm not a very experienced PySpark developer. I'm looking for help to write code to accomplish this task.\n\n&amp;#x200B;\n\nCan anyone point me a direction? Thanks!", "author_fullname": "t2_3p0fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark: How to loop trough rows and search for value in another dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "media_metadata": {"kkadd9ldd10b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/kkadd9ldd10b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=805c7a3c2a43df213c2e823716b532b11a66851e"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/kkadd9ldd10b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f9400bc476cd09a2551d3dc9a2ed9e549916b4"}], "s": {"y": 254, "x": 319, "u": "https://preview.redd.it/kkadd9ldd10b1.png?width=319&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aacec49928b640fd7ab4fcf83f96bc4dd396e063"}, "id": "kkadd9ldd10b1"}}, "name": "t3_13ifo4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TUe9JJNge5zAu8KTV6E-eoe41iI13l_sHeNUCiCP6XA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684174364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two data sets with the following data:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kkadd9ldd10b1.png?width=319&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=aacec49928b640fd7ab4fcf83f96bc4dd396e063\"&gt;https://preview.redd.it/kkadd9ldd10b1.png?width=319&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=aacec49928b640fd7ab4fcf83f96bc4dd396e063&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Given the interchange_rate value in the source file, I need to get the closest match of rebate_rate from the lookup table. In the image you can see that the transaction_id 2 has the highest interchange_rate and therefore, I need to get the highest rebate_rate; transaction_id 1 is the lowest interchange_rate and therefore get the lowest rebate_rate.&lt;/p&gt;\n\n&lt;p&gt;The red column I did manually using Excel just to show it as an example, but that&amp;#39;s the expected output.&lt;/p&gt;\n\n&lt;p&gt;My initial idea is to loop through the rows in the source file, and for each line search for the closest match in the lookup table. But I&amp;#39;m not a very experienced PySpark developer. I&amp;#39;m looking for help to write code to accomplish this task.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can anyone point me a direction? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ifo4e", "is_robot_indexable": true, "report_reasons": null, "author": "Croves", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ifo4e/pyspark_how_to_loop_trough_rows_and_search_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ifo4e/pyspark_how_to_loop_trough_rows_and_search_for/", "subreddit_subscribers": 105716, "created_utc": 1684174364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Heya guys, I've got 10+ years as postgres admin, but always base installed on \\*NIX systems (and using IBM Netezza or Pivotal Greenplum forks), and historically had 1PB under management with a larger team. I'm now moving onto smaller projects built on AWS for cloud experience, but having troubles with finding good resources for performance monitoring. I know that Cloudwatch is available for what I would consider to be OS-level metrics (and would replace my custom nagios checks written for  \\*NIX deployments), but what about query-level? \n\nI'm used to enabling query history in Netezza/Greenplum, and grep on logs if I'm looking for something specific, and well versed in using EXPLAIN plans to tune queries. I've also used ELK stack (with custom code hooks) to track performance of db functions over time. I'm used to 24-hr rolling logs with 30-day to 90-day retention, and having some sort of gui (gp command center) or command-line tools (nz nzsqa) to track in-progress sql. I've not found anything similar for RDS, nor does it seem that Cloudwatch is able to handle query-level performance metrics.\n\nI've not found anything in the AWS online training, cloudguru, Manning or O'Reilly for best practices for these types of tasks. Anyone got any reference material they could link for best practices on how to handle query performance tracking?", "author_fullname": "t2_4j735omc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS RDS (Postgres) Administration Resources - Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13iqckl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684198595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya guys, I&amp;#39;ve got 10+ years as postgres admin, but always base installed on *NIX systems (and using IBM Netezza or Pivotal Greenplum forks), and historically had 1PB under management with a larger team. I&amp;#39;m now moving onto smaller projects built on AWS for cloud experience, but having troubles with finding good resources for performance monitoring. I know that Cloudwatch is available for what I would consider to be OS-level metrics (and would replace my custom nagios checks written for  *NIX deployments), but what about query-level? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m used to enabling query history in Netezza/Greenplum, and grep on logs if I&amp;#39;m looking for something specific, and well versed in using EXPLAIN plans to tune queries. I&amp;#39;ve also used ELK stack (with custom code hooks) to track performance of db functions over time. I&amp;#39;m used to 24-hr rolling logs with 30-day to 90-day retention, and having some sort of gui (gp command center) or command-line tools (nz nzsqa) to track in-progress sql. I&amp;#39;ve not found anything similar for RDS, nor does it seem that Cloudwatch is able to handle query-level performance metrics.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve not found anything in the AWS online training, cloudguru, Manning or O&amp;#39;Reilly for best practices for these types of tasks. Anyone got any reference material they could link for best practices on how to handle query performance tracking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13iqckl", "is_robot_indexable": true, "report_reasons": null, "author": "pandgea", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13iqckl/aws_rds_postgres_administration_resources_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13iqckl/aws_rds_postgres_administration_resources_question/", "subreddit_subscribers": 105716, "created_utc": 1684198595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for an on-site advanced SQL training in the Netherlands, preferably Amsterdam, for a team of 10 people. We use Snowflake and dbt but any SQL training would work, I've been searching for weeks and am very frustrated. Can anyone recommend a trainer / organization that can help?", "author_fullname": "t2_7ox4fv4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL query and performance optimization training in the Netherlands recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13i9kiq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684160079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for an on-site advanced SQL training in the Netherlands, preferably Amsterdam, for a team of 10 people. We use Snowflake and dbt but any SQL training would work, I&amp;#39;ve been searching for weeks and am very frustrated. Can anyone recommend a trainer / organization that can help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13i9kiq", "is_robot_indexable": true, "report_reasons": null, "author": "inhaltsloss", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13i9kiq/sql_query_and_performance_optimization_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13i9kiq/sql_query_and_performance_optimization_training/", "subreddit_subscribers": 105716, "created_utc": 1684160079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i would like to know which one is better for storing financial datasets, since i have 4TB CSV files in total. Im planning to transform the csv files into parquet or feather format so it could be way cheaper to store the data in AWS and run deep learning models. Any tips? Btw, i come from a financial background, so I\u2019m starting to learn about data. Thanks guys", "author_fullname": "t2_6bq784p6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet VS Feather", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j0f2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684230008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i would like to know which one is better for storing financial datasets, since i have 4TB CSV files in total. Im planning to transform the csv files into parquet or feather format so it could be way cheaper to store the data in AWS and run deep learning models. Any tips? Btw, i come from a financial background, so I\u2019m starting to learn about data. Thanks guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j0f2d", "is_robot_indexable": true, "report_reasons": null, "author": "pussydestroyerSPY", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j0f2d/parquet_vs_feather/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j0f2d/parquet_vs_feather/", "subreddit_subscribers": 105716, "created_utc": 1684230008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is probably simple but I don't get it.\n\nSuppose you're building a new data warehouse using both:\n\n* Data lake using medallion architecture -- e.g., raw, bronze, silver, gold\n* Dedicated data warehouse (e.g. Azure Dedicated SQL Pool)\n\nQuestion:\n\nDoes the dedicated data warehouse house all four layers? (raw, bronze, silver, gold).  Or is it just the gold layer?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie data lake/dedicated DW question: Does a physical, dedicated DW contain just the gold layer, or other layers as well?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13iih5p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684180404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is probably simple but I don&amp;#39;t get it.&lt;/p&gt;\n\n&lt;p&gt;Suppose you&amp;#39;re building a new data warehouse using both:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data lake using medallion architecture -- e.g., raw, bronze, silver, gold&lt;/li&gt;\n&lt;li&gt;Dedicated data warehouse (e.g. Azure Dedicated SQL Pool)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;Does the dedicated data warehouse house all four layers? (raw, bronze, silver, gold).  Or is it just the gold layer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13iih5p", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13iih5p/newbie_data_lakededicated_dw_question_does_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13iih5p/newbie_data_lakededicated_dw_question_does_a/", "subreddit_subscribers": 105716, "created_utc": 1684180404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering because it seems the interview process at my company changed to be much more difficult for engineers at my level.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would anyone else not pass the interview process at their current company if they interviewed today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13j3493", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684238298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering because it seems the interview process at my company changed to be much more difficult for engineers at my level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j3493", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j3493/would_anyone_else_not_pass_the_interview_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j3493/would_anyone_else_not_pass_the_interview_process/", "subreddit_subscribers": 105716, "created_utc": 1684238298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am new to data engineering concepts and need help on where to start with and any kind of learning pathways would really help.", "author_fullname": "t2_46torsuw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13j2vy1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684237658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am new to data engineering concepts and need help on where to start with and any kind of learning pathways would really help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j2vy1", "is_robot_indexable": true, "report_reasons": null, "author": "koderv", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2vy1/new_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j2vy1/new_to_data_engineering/", "subreddit_subscribers": 105716, "created_utc": 1684237658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I started my current job at a salary of 21k. Disappointing but all I has was 3 months of Microsoft certifications for az900, db900 and db203. \n\nI've been at this job for 8 months, which I've been mostly SSMS and SSIS based (data migration using T-SQL mostly, loading data using SSIS integration in VS into dynamics  and a bit of problem solving for current data ). \n\nMy initial passion was more azure based using synapse creating pipelines for datalakes/warehousong and engineering for analytics/ ML. \n\nI've barely managed to use these cloud technologies at all (mostly blob storage/data lake and ive had a brief look at some pipelines) but I have recieved interest from companies but worry about my lack of cloud experience. \n\nI've been offered 2nd interviews for a 39k and 30k job. Both say they like my skill set and are interested but I half feel like an imposter... \nI tend to learn best on the job as what would probably take me 6 months to learn on my own, I can learn in 1 month given guidance. \n\nMy Q is do I have nothing to worry about or am I lowballing myself or am I missing something?", "author_fullname": "t2_6o5h731v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm receiving good job opportunities, 7 months as a junior but worry about my actual experience in Azure.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13j2osy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684237078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I started my current job at a salary of 21k. Disappointing but all I has was 3 months of Microsoft certifications for az900, db900 and db203. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been at this job for 8 months, which I&amp;#39;ve been mostly SSMS and SSIS based (data migration using T-SQL mostly, loading data using SSIS integration in VS into dynamics  and a bit of problem solving for current data ). &lt;/p&gt;\n\n&lt;p&gt;My initial passion was more azure based using synapse creating pipelines for datalakes/warehousong and engineering for analytics/ ML. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve barely managed to use these cloud technologies at all (mostly blob storage/data lake and ive had a brief look at some pipelines) but I have recieved interest from companies but worry about my lack of cloud experience. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been offered 2nd interviews for a 39k and 30k job. Both say they like my skill set and are interested but I half feel like an imposter... \nI tend to learn best on the job as what would probably take me 6 months to learn on my own, I can learn in 1 month given guidance. &lt;/p&gt;\n\n&lt;p&gt;My Q is do I have nothing to worry about or am I lowballing myself or am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j2osy", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous6156", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2osy/im_receiving_good_job_opportunities_7_months_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j2osy/im_receiving_good_job_opportunities_7_months_as_a/", "subreddit_subscribers": 105716, "created_utc": 1684237078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I\u2019ve been trying to emulate the behavior of a dynamic window,  as Flink does not support dynamic window sizes. My operator inherits from KeyedProcessFunction, and I\u2019m only using KeyedStates to manipulate the window\\_size. I\u2019m clearing the KeyedStates when my bucket(window) is complete, to reset the bucket size.\n\nMy concern is, as Flink does not support dynamic windows, is this approach going against Flink Architecture?  Like will it break checkpointing mechanism in distributed systems? It's been noted that I\u2019m only using KeyedStates for maintaining or implementing the dynamic window.", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamic Windowing in Apache Flink", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13j2j00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684236589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019ve been trying to emulate the behavior of a dynamic window,  as Flink does not support dynamic window sizes. My operator inherits from KeyedProcessFunction, and I\u2019m only using KeyedStates to manipulate the window_size. I\u2019m clearing the KeyedStates when my bucket(window) is complete, to reset the bucket size.&lt;/p&gt;\n\n&lt;p&gt;My concern is, as Flink does not support dynamic windows, is this approach going against Flink Architecture?  Like will it break checkpointing mechanism in distributed systems? It&amp;#39;s been noted that I\u2019m only using KeyedStates for maintaining or implementing the dynamic window.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j2j00", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2j00/dynamic_windowing_in_apache_flink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j2j00/dynamic_windowing_in_apache_flink/", "subreddit_subscribers": 105716, "created_utc": 1684236589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Kestra, a Declarative Orchestration Alternative to Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 39, "top_awarded_type": null, "hide_score": true, "name": "t3_13j2c79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EWZ2vBZGK0DemPEM-wVbeHgEh730S5kDAD3Pz478AYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684236014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.devgenius.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.devgenius.io/introduction-to-kestra-a-declarative-orchestration-alternative-to-apache-airflow-10eaac05143d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?auto=webp&amp;v=enabled&amp;s=8f9ebe39b4b1002e65750c49d3ee6b7a9bbe3305", "width": 1200, "height": 337}, "resolutions": [{"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67597e808aa102d6452eb105e0fc7fbe7f24094c", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ac0677271bb054ed12cac6e30e70cc3e0bff259", "width": 216, "height": 60}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1a039af4ef88b0f0b62a54c1a3ec507462a2cb2", "width": 320, "height": 89}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72b6c84574eecc20175bb7b31c4c78f687660c83", "width": 640, "height": 179}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3712f8b3a1f958da94344dafc6a67db37afd2753", "width": 960, "height": 269}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6dee55c17679a7491698ecf8edff5d6acfcdaad", "width": 1080, "height": 303}], "variants": {}, "id": "FJAaQpsUIhM9-ETXbiwIyUjoau521Tql_4jveeqBNjY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13j2c79", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2c79/introduction_to_kestra_a_declarative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.devgenius.io/introduction-to-kestra-a-declarative-orchestration-alternative-to-apache-airflow-10eaac05143d", "subreddit_subscribers": 105716, "created_utc": 1684236014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, has anyone used AZCopy  to migrate data from one system to another in their project ?\nIf they have used ,can you please explain the advantages it has over the copy activity present in ADF/Synapse ?", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AZCopy over Copy activity in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j1ifs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684233488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, has anyone used AZCopy  to migrate data from one system to another in their project ?\nIf they have used ,can you please explain the advantages it has over the copy activity present in ADF/Synapse ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j1ifs", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j1ifs/using_azcopy_over_copy_activity_in_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j1ifs/using_azcopy_over_copy_activity_in_azure_data/", "subreddit_subscribers": 105716, "created_utc": 1684233488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi can some experienced data engineers answer this question for me?", "author_fullname": "t2_18whiiyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is Informatica as a tool when it comes to ETL/Data Engineering. Need honest answers please.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j1eju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684233147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi can some experienced data engineers answer this question for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j1eju", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Radio582", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j1eju/how_is_informatica_as_a_tool_when_it_comes_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j1eju/how_is_informatica_as_a_tool_when_it_comes_to/", "subreddit_subscribers": 105716, "created_utc": 1684233147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \n\nI'm looking for a solution to visualise and explore a very complex data lineage graph. The system that I want to visualise runs hundreds of interdependent calculation processes that are structured into overarching modules to enrich a limited number of tables with calculated results so most lineages would refer from a table to itself. Due to the nature of the database structure &amp; the way processes are stored, I cannot use tools like Datahub to extract lineage information. However, for each process I can identify what data it reads, what it writes and what other processes it feeds with results so I have all the components to build the graph. Typical graph libraries though (graphviz eg) will not suffice as they'd show everything at once and then the result is basically unusable. What I would like to achieve is:\n\n\\- showing module level data IO and dependencies, allowing a \"drill down\" from the module into it's sub processes\n\n\\- for each process show data IO &amp; dependencies towards other processes\n\n\\- apply tags to processes so that parts of the lineage graph can be dynamically hidden \n\n\\- feed the entire structure of module/process hierarchies, dependencies &amp; data IO into a system to render the lineage graph \n\n&amp;#x200B;\n\nAny ideas for a graph library / application or data lineage application that could achieve this would be more than welcome.", "author_fullname": "t2_o7nz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lineage / Graph visualisation expertise required", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13iyk2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684223630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a solution to visualise and explore a very complex data lineage graph. The system that I want to visualise runs hundreds of interdependent calculation processes that are structured into overarching modules to enrich a limited number of tables with calculated results so most lineages would refer from a table to itself. Due to the nature of the database structure &amp;amp; the way processes are stored, I cannot use tools like Datahub to extract lineage information. However, for each process I can identify what data it reads, what it writes and what other processes it feeds with results so I have all the components to build the graph. Typical graph libraries though (graphviz eg) will not suffice as they&amp;#39;d show everything at once and then the result is basically unusable. What I would like to achieve is:&lt;/p&gt;\n\n&lt;p&gt;- showing module level data IO and dependencies, allowing a &amp;quot;drill down&amp;quot; from the module into it&amp;#39;s sub processes&lt;/p&gt;\n\n&lt;p&gt;- for each process show data IO &amp;amp; dependencies towards other processes&lt;/p&gt;\n\n&lt;p&gt;- apply tags to processes so that parts of the lineage graph can be dynamically hidden &lt;/p&gt;\n\n&lt;p&gt;- feed the entire structure of module/process hierarchies, dependencies &amp;amp; data IO into a system to render the lineage graph &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any ideas for a graph library / application or data lineage application that could achieve this would be more than welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13iyk2z", "is_robot_indexable": true, "report_reasons": null, "author": "Roboright", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13iyk2z/data_lineage_graph_visualisation_expertise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13iyk2z/data_lineage_graph_visualisation_expertise/", "subreddit_subscribers": 105716, "created_utc": 1684223630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do I query Redshift Datashare Table using dbeaver?", "author_fullname": "t2_rwyd6ycy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query Redshift Datashare Table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13iwrpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684217354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I query Redshift Datashare Table using dbeaver?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13iwrpv", "is_robot_indexable": true, "report_reasons": null, "author": "mystery_lily_1008", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13iwrpv/query_redshift_datashare_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13iwrpv/query_redshift_datashare_table/", "subreddit_subscribers": 105716, "created_utc": 1684217354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am getting an opportunity to work in abinitio.\nIs it a dead tool with no scope?", "author_fullname": "t2_vn1meuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is abinitio a dead tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13if1m0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684172973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting an opportunity to work in abinitio.\nIs it a dead tool with no scope?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13if1m0", "is_robot_indexable": true, "report_reasons": null, "author": "jojobaoil68", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13if1m0/is_abinitio_a_dead_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13if1m0/is_abinitio_a_dead_tool/", "subreddit_subscribers": 105716, "created_utc": 1684172973.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}