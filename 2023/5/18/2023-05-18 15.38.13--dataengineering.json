{"kind": "Listing", "data": {"after": "t3_13ky7yx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Describe your experience &amp; position and tell us about something you learned the hard way. I'll go first...\n\nDE with 2 YOE. Background was non-technical. I design and implement pipelines to serve analytics.  \n\n\n**Story**: We believed a service provider (service desk and software maintenance) was fudging numbers in various ways to make their service look better than it was. We had access to their service desk ticket data, and the business logic behind whether or not a ticket met the service target / SLA.\n\nOur data analyst is almost done with his report for leadership on the matter. Asks me to add a calculated field to the materialized view that I provide him so he can finish up and send it out that day. I define a new CTE, left join it to the existing data, and define the new field. Briefly manually scroll through the new column and it looks good. Recreate the view and tell him to refresh on his end. He runs his calculation and starts finishing up his report.\n\nLater on, he hits me up on Teams with the dreaded \"something looks off\". Long story short, I did not de-duplicate the CTE I created, and the join resulted in some entries having many duplicate records, making his numbers inaccurate. Disaster averted thanks to him catching this.  \n\n\n**Lesson**: You need metadata capture and observability at every. single. step. in your pipelines, including the view layer.\n\nI could have caught this manually if I had taken 5 extra seconds, but it's just better engineering to implement CDC or trigger function + metadata table, then put together a little metadata &amp; lineage dashboard.  \n\nSo...what have you learned the hard way?", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What have you learned the hard way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9fvu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684346986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Describe your experience &amp;amp; position and tell us about something you learned the hard way. I&amp;#39;ll go first...&lt;/p&gt;\n\n&lt;p&gt;DE with 2 YOE. Background was non-technical. I design and implement pipelines to serve analytics.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Story&lt;/strong&gt;: We believed a service provider (service desk and software maintenance) was fudging numbers in various ways to make their service look better than it was. We had access to their service desk ticket data, and the business logic behind whether or not a ticket met the service target / SLA.&lt;/p&gt;\n\n&lt;p&gt;Our data analyst is almost done with his report for leadership on the matter. Asks me to add a calculated field to the materialized view that I provide him so he can finish up and send it out that day. I define a new CTE, left join it to the existing data, and define the new field. Briefly manually scroll through the new column and it looks good. Recreate the view and tell him to refresh on his end. He runs his calculation and starts finishing up his report.&lt;/p&gt;\n\n&lt;p&gt;Later on, he hits me up on Teams with the dreaded &amp;quot;something looks off&amp;quot;. Long story short, I did not de-duplicate the CTE I created, and the join resulted in some entries having many duplicate records, making his numbers inaccurate. Disaster averted thanks to him catching this.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Lesson&lt;/strong&gt;: You need metadata capture and observability at every. single. step. in your pipelines, including the view layer.&lt;/p&gt;\n\n&lt;p&gt;I could have caught this manually if I had taken 5 extra seconds, but it&amp;#39;s just better engineering to implement CDC or trigger function + metadata table, then put together a little metadata &amp;amp; lineage dashboard.  &lt;/p&gt;\n\n&lt;p&gt;So...what have you learned the hard way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k9fvu", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k9fvu/what_have_you_learned_the_hard_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k9fvu/what_have_you_learned_the_hard_way/", "subreddit_subscribers": 106055, "created_utc": 1684346986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To all the Dagster experts out there. I am joining a team that is using Dagster which I have never used before. \nWhat is the best way to learn Dagster? I am planning on going through their quick start hello world project they have. \n\nThanks!", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a team using Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13khzgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684366619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all the Dagster experts out there. I am joining a team that is using Dagster which I have never used before. \nWhat is the best way to learn Dagster? I am planning on going through their quick start hello world project they have. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13khzgg", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13khzgg/joining_a_team_using_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13khzgg/joining_a_team_using_dagster/", "subreddit_subscribers": 106055, "created_utc": 1684366619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems the biggest setback to expanding usage of data at my company is data silos that exist simply because people are not aware of what is available and so they recreate it in another location with a different naming convention. Are there any tools that give people a standard library of locations/queries they can use to find specific information?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys deal with data silos and lack of data awareness at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kih8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684367896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems the biggest setback to expanding usage of data at my company is data silos that exist simply because people are not aware of what is available and so they recreate it in another location with a different naming convention. Are there any tools that give people a standard library of locations/queries they can use to find specific information?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kih8h", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kih8h/how_do_you_guys_deal_with_data_silos_and_lack_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kih8h/how_do_you_guys_deal_with_data_silos_and_lack_of/", "subreddit_subscribers": 106055, "created_utc": 1684367896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s obviously very easy to find DE jobs under DE titles, but for people who are interested in working in data-intensive software engineering instead, how can one differentiate data vs. non data swe roles on sites like linkedin, indeed, etc", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find data engineering jobs under software engineering titles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9udf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684347903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s obviously very easy to find DE jobs under DE titles, but for people who are interested in working in data-intensive software engineering instead, how can one differentiate data vs. non data swe roles on sites like linkedin, indeed, etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13k9udf", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k9udf/how_to_find_data_engineering_jobs_under_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k9udf/how_to_find_data_engineering_jobs_under_software/", "subreddit_subscribers": 106055, "created_utc": 1684347903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company will soon be starting a new iteration of their data strategy journey. As many of you know, this will be a long process as we work out our data architecture, data governance, and integration strategies. As many of you ALSO know, management will almost certainly not be patient while we navigate these things and will want incremental (if not some near immediate) value out of our proposed solution.   \n\n\nMy question is, do any of you have tips on how to appease the stakeholders and show value without 1) losing focus on the main goal and 2) incurring an obscene amount of technical debt along the way?", "author_fullname": "t2_33b8fuxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips on how to navigate the inevitable, \"But we want value now\" pressure from management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k62dg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684339619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company will soon be starting a new iteration of their data strategy journey. As many of you know, this will be a long process as we work out our data architecture, data governance, and integration strategies. As many of you ALSO know, management will almost certainly not be patient while we navigate these things and will want incremental (if not some near immediate) value out of our proposed solution.   &lt;/p&gt;\n\n&lt;p&gt;My question is, do any of you have tips on how to appease the stakeholders and show value without 1) losing focus on the main goal and 2) incurring an obscene amount of technical debt along the way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k62dg", "is_robot_indexable": true, "report_reasons": null, "author": "FawkesFoundation", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k62dg/any_tips_on_how_to_navigate_the_inevitable_but_we/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k62dg/any_tips_on_how_to_navigate_the_inevitable_but_we/", "subreddit_subscribers": 106055, "created_utc": 1684339619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m guessing it\u2019s along the lines of\n\n1. add constraints do pk/fk\n\n&amp;\n\n2. find open source erd generator \n\n\nI have read a few blogs but do not speak directly to dbt projects fueling the creation and/or are not free?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a good way of developing an ERD based off a dbt project; programmatically/automated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k4yu2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684337244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m guessing it\u2019s along the lines of&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;add constraints do pk/fk&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;amp;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;find open source erd generator &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I have read a few blogs but do not speak directly to dbt projects fueling the creation and/or are not free?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13k4yu2", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k4yu2/anyone_have_a_good_way_of_developing_an_erd_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k4yu2/anyone_have_a_good_way_of_developing_an_erd_based/", "subreddit_subscribers": 106055, "created_utc": 1684337244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using this tool to manage their data pipelines? Pros and Cons? I love how it templates a lot of your code to help keep standards within your team.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MageAI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kpkn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684387922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using this tool to manage their data pipelines? Pros and Cons? I love how it templates a lot of your code to help keep standards within your team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kpkn2", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kpkn2/mageai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kpkn2/mageai/", "subreddit_subscribers": 106055, "created_utc": 1684387922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Also anyone develop in a Docker container?", "author_fullname": "t2_h2t9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your dev environment set up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kngt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684382230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684381336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Also anyone develop in a Docker container?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kngt8", "is_robot_indexable": true, "report_reasons": null, "author": "jackielarson", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kngt8/whats_your_dev_environment_set_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kngt8/whats_your_dev_environment_set_up/", "subreddit_subscribers": 106055, "created_utc": 1684381336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!  \nWith the Airbyte team, we\u2019ve been working on improving the way we could create new ELT connectors without code or local dev. The result of all this effort is what we\u2019re releasing today: a [no-code connector builder](https://airbyte.com/blog/launching-the-no-code-connector-builder-build-custom-connectors-in-minutes). \n\nThe best to showcase it is through a [preview video](https://www.youtube.com/watch?v=mE655VHbP-c&amp;t=1s). It handles authentication, pagination, rate limiting, schema handling, transformation, response decoding...actually everything except which data to pull and how. \n\nToday, the connector builder is best suited for synchronous HTTP API connectors. We\u2019ve published a [compatibility guide](https://docs.airbyte.com/connector-development/connector-builder-ui/connector-builder-compatibility) which can help you identify if a specific API is a fit for the connector builder. As we support more components, we expect that the vast majority of API connector needs will be supported. \n\nIt's available on both Airbyte Open Source and Cloud. Would love to hear any thoughts about it!", "author_fullname": "t2_11542k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build custom ELT connectors in no-code within 10 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l14gz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684421273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nWith the Airbyte team, we\u2019ve been working on improving the way we could create new ELT connectors without code or local dev. The result of all this effort is what we\u2019re releasing today: a &lt;a href=\"https://airbyte.com/blog/launching-the-no-code-connector-builder-build-custom-connectors-in-minutes\"&gt;no-code connector builder&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;The best to showcase it is through a &lt;a href=\"https://www.youtube.com/watch?v=mE655VHbP-c&amp;amp;t=1s\"&gt;preview video&lt;/a&gt;. It handles authentication, pagination, rate limiting, schema handling, transformation, response decoding...actually everything except which data to pull and how. &lt;/p&gt;\n\n&lt;p&gt;Today, the connector builder is best suited for synchronous HTTP API connectors. We\u2019ve published a &lt;a href=\"https://docs.airbyte.com/connector-development/connector-builder-ui/connector-builder-compatibility\"&gt;compatibility guide&lt;/a&gt; which can help you identify if a specific API is a fit for the connector builder. As we support more components, we expect that the vast majority of API connector needs will be supported. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s available on both Airbyte Open Source and Cloud. Would love to hear any thoughts about it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?auto=webp&amp;v=enabled&amp;s=9c2945921f4e5c125ef7d238c07dc222e1230e78", "width": 2540, "height": 1520}, "resolutions": [{"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54e541316d1ed494addc5d466490378cf5d03f01", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b76e10f87478fda7e0c9be6d51a668b6e15d84ef", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36140bd3271d840a6a9a373dd1d6e649a0e257ea", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ac2d6eb335fd72c2bafe02cc9a1c76a8950db27", "width": 640, "height": 382}, {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=165ab484c889faa593b5793e00cea3ae6e9bef6b", "width": 960, "height": 574}, {"url": "https://external-preview.redd.it/7ucWdhu4kHQDEPlfvmvtS6yMEsOW8dDdD0aoz2xtKr8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=715b6bde02091a80842ba69d05d6fbf924544b1b", "width": 1080, "height": 646}], "variants": {}, "id": "jmicj4_d8sgUJOPdtrWjbgYEZ9UUx9_p_57uZdHd6W8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13l14gz", "is_robot_indexable": true, "report_reasons": null, "author": "jeanlaf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l14gz/build_custom_elt_connectors_in_nocode_within_10/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l14gz/build_custom_elt_connectors_in_nocode_within_10/", "subreddit_subscribers": 106055, "created_utc": 1684421273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks - dropping by with some information on an upcoming Community-led webinar that may be of interest to you. Next week, on **May 23 at 11 AM PT, Ella Runciman (data engineer @ 1Password) will be hosting a webinar for The OA Club on best practices are 3rd party data enrichment**. \n\n*Disclaimer: I work for the company who pays the bills on The OA Club, but Ella is not employed by us and this webinar is not about our product. No sales folks will contact you because you registered.*    \n\n\nShe'll be covering: \n\n* An overview of data enrichment\n* The types of data enrichment\n* How data enrichment has evolved over the years (and its business value)\n* Hands-on examples of how to implement data enrichment in your organization   \n\n\nIf you're interested, you can RSVP [here](https://hubs.la/Q01QfD6t0).", "author_fullname": "t2_bxqhxdv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Webinar] Data Enrichment - How to create and utilize 3rd party data in your data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k8q64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684345396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks - dropping by with some information on an upcoming Community-led webinar that may be of interest to you. Next week, on &lt;strong&gt;May 23 at 11 AM PT, Ella Runciman (data engineer @ 1Password) will be hosting a webinar for The OA Club on best practices are 3rd party data enrichment&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Disclaimer: I work for the company who pays the bills on The OA Club, but Ella is not employed by us and this webinar is not about our product. No sales folks will contact you because you registered.&lt;/em&gt;    &lt;/p&gt;\n\n&lt;p&gt;She&amp;#39;ll be covering: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An overview of data enrichment&lt;/li&gt;\n&lt;li&gt;The types of data enrichment&lt;/li&gt;\n&lt;li&gt;How data enrichment has evolved over the years (and its business value)&lt;/li&gt;\n&lt;li&gt;Hands-on examples of how to implement data enrichment in your organization&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, you can RSVP &lt;a href=\"https://hubs.la/Q01QfD6t0\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?auto=webp&amp;v=enabled&amp;s=ff77a7ca78366999356715449640e3cf43575f7a", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02e09782c2615730f0dbff0342b929e14e9adaa5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c577e02eb2c2d1ae1284bc82eb6e835333be0bd5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=306c2379070f538c5831074c4a05332e60686f81", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9506993d67699fac3b0c17f9ccdd252c40b43aa7", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a45254c519e1d8aef113136e48d605ef0e65892", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad474a257dee7d744fe2b93fbd0672d36f50a4d8", "width": 1080, "height": 565}], "variants": {}, "id": "Te6WuNcXcZV9ln1yMDvGLXXHj_JaM-Cp7bcwaH8BUWg"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "award_43c43a35-15c5-4f73-91ef-fe538426435a", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=86ea90c91e68c8416d6535a03a0de560844da977", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=80e4a5323c68ea1f3a927f679f921fd66f198958", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e895b89e2b8384d6cfd3a0545b8c48025065103d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=ef1c7b73aa1d536a2aaeda16ab3134119ca5bb9d", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=b55a46a50135f11519922e4fb2ee9b6d04918b34", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Prayers up for the blessed. Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Bless Up (Pro)", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=86ea90c91e68c8416d6535a03a0de560844da977", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=80e4a5323c68ea1f3a927f679f921fd66f198958", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e895b89e2b8384d6cfd3a0545b8c48025065103d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=ef1c7b73aa1d536a2aaeda16ab3134119ca5bb9d", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=b55a46a50135f11519922e4fb2ee9b6d04918b34", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k8q64", "is_robot_indexable": true, "report_reasons": null, "author": "alliewritestech", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k8q64/webinar_data_enrichment_how_to_create_and_utilize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k8q64/webinar_data_enrichment_how_to_create_and_utilize/", "subreddit_subscribers": 106055, "created_utc": 1684345396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any tool I would give input data (database, parquet, whatever) to and it would insert it into the target relational database while handling all the logic such as upserts, primary key lookups, udpdates of children tables (e. g. M:N relationships tables) etc? Or do I really have to write my own giant custom ETL framework to solve this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool with automatic merge logic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k705a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684341620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any tool I would give input data (database, parquet, whatever) to and it would insert it into the target relational database while handling all the logic such as upserts, primary key lookups, udpdates of children tables (e. g. M:N relationships tables) etc? Or do I really have to write my own giant custom ETL framework to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k705a", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k705a/etl_tool_with_automatic_merge_logic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k705a/etl_tool_with_automatic_merge_logic/", "subreddit_subscribers": 106055, "created_utc": 1684341620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mean are those papers just blahblahblah or they contain a very much practical information which will help me become a better data engineer and make me more marketable and valuable?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will exploring research papers from google, meta or microsoft make me a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l0o5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684420122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean are those papers just blahblahblah or they contain a very much practical information which will help me become a better data engineer and make me more marketable and valuable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l0o5d", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l0o5d/will_exploring_research_papers_from_google_meta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l0o5d/will_exploring_research_papers_from_google_meta/", "subreddit_subscribers": 106055, "created_utc": 1684420122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, we are a data team consisting of three people and we are considering using dbt Cloud. Actually the team plan would be enough for us, but only two jobs can run at the same time in the tariff?! That seems (ridiculously) little.\nAnd the Enterprise plan would cost many times more.\n\nSomehow the tariff structure for dbt Cloud seems strange to me. The Teams plan is too limited to use it seriously and the Enterprise plan is way too expensive (and can only run 5 jobs in parallel).\n\nWhat would be a good way to use DBT core for a team that has little experience with cloud infrastructure? We do use Azure data factory for copying the on prem data to snowflake, but nothing more.", "author_fullname": "t2_2ishbuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Core + Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13kzqnm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684417765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, we are a data team consisting of three people and we are considering using dbt Cloud. Actually the team plan would be enough for us, but only two jobs can run at the same time in the tariff?! That seems (ridiculously) little.\nAnd the Enterprise plan would cost many times more.&lt;/p&gt;\n\n&lt;p&gt;Somehow the tariff structure for dbt Cloud seems strange to me. The Teams plan is too limited to use it seriously and the Enterprise plan is way too expensive (and can only run 5 jobs in parallel).&lt;/p&gt;\n\n&lt;p&gt;What would be a good way to use DBT core for a team that has little experience with cloud infrastructure? We do use Azure data factory for copying the on prem data to snowflake, but nothing more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kzqnm", "is_robot_indexable": true, "report_reasons": null, "author": "youderkB", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kzqnm/dbt_core_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kzqnm/dbt_core_azure_data_factory/", "subreddit_subscribers": 106055, "created_utc": 1684417765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any real time challenges that you faced while working with Amazon Redshift ? Any suggestions before deploying the service ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges that you want to highlight with Amazon Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kya4b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684414151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any real time challenges that you faced while working with Amazon Redshift ? Any suggestions before deploying the service ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kya4b", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kya4b/challenges_that_you_want_to_highlight_with_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kya4b/challenges_that_you_want_to_highlight_with_amazon/", "subreddit_subscribers": 106055, "created_utc": 1684414151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI have been recently asked to find a way to replace multiple Excel files with something more robust but providing similar adventages.\n\nProblem: Managers receive an Excel template, they fill in the data and some simple visuals are refreshed as they make adjustments. The template contains data they filled in in the previous years so they can model it based on history.\n\nI would like to avoid creating a tool like this myself and I don't feel like any dashboarding tools could help here. Also, something like notebooks might be too technical for the users.\n\nIs there any product you could recommend I can take a look at?", "author_fullname": "t2_5aibl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tool for interactive data modelling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kvmqf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684407610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I have been recently asked to find a way to replace multiple Excel files with something more robust but providing similar adventages.&lt;/p&gt;\n\n&lt;p&gt;Problem: Managers receive an Excel template, they fill in the data and some simple visuals are refreshed as they make adjustments. The template contains data they filled in in the previous years so they can model it based on history.&lt;/p&gt;\n\n&lt;p&gt;I would like to avoid creating a tool like this myself and I don&amp;#39;t feel like any dashboarding tools could help here. Also, something like notebooks might be too technical for the users.&lt;/p&gt;\n\n&lt;p&gt;Is there any product you could recommend I can take a look at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kvmqf", "is_robot_indexable": true, "report_reasons": null, "author": "mictom9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kvmqf/any_tool_for_interactive_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kvmqf/any_tool_for_interactive_data_modelling/", "subreddit_subscribers": 106055, "created_utc": 1684407610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throw everything here.", "author_fullname": "t2_7zhhkqm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the biggest foolishness you have seen or heard a colleague do at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kshpl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684397826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throw everything here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kshpl", "is_robot_indexable": true, "report_reasons": null, "author": "rafa4maniac", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kshpl/what_is_the_biggest_foolishness_you_have_seen_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kshpl/what_is_the_biggest_foolishness_you_have_seen_or/", "subreddit_subscribers": 106055, "created_utc": 1684397826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All!   \n\n\nI have Iceberg tables on AWS S3, they were created by Trino and the metadata is stored on Hive Metastore, but we want to make it consumable via AWS Athena too, and Athena can only use the Glue Catalog.   \n\n\nIs there an easy way to make the same metadata available on Glue Catalog? Maybe a Crawler or writing a Glue Job....  \n\n\nI could not find if the Glue crawler can read an existing Icerbeg Table. And we don't  want to recreate the table or duplicate the data.", "author_fullname": "t2_ijp90vxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue/Athena reading Iceberg Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l19hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684421624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All!   &lt;/p&gt;\n\n&lt;p&gt;I have Iceberg tables on AWS S3, they were created by Trino and the metadata is stored on Hive Metastore, but we want to make it consumable via AWS Athena too, and Athena can only use the Glue Catalog.   &lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to make the same metadata available on Glue Catalog? Maybe a Crawler or writing a Glue Job....  &lt;/p&gt;\n\n&lt;p&gt;I could not find if the Glue crawler can read an existing Icerbeg Table. And we don&amp;#39;t  want to recreate the table or duplicate the data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13l19hr", "is_robot_indexable": true, "report_reasons": null, "author": "CzarSantos98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l19hr/aws_glueathena_reading_iceberg_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l19hr/aws_glueathena_reading_iceberg_tables/", "subreddit_subscribers": 106055, "created_utc": 1684421624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Synapse Dedicated Pools (fka Azure SQL Data Warehouse) as far as I can tell - are on the way out. \n\n  * No major updates in 3 years\n  * I hear - can expect ~3 years of support, then migration to Serverless SQL pools\n\nFirst, correct me if my premise is off. But if it's correct:\n\nWhy? \n\nI have a mental picture of someone at MS starting a meeting with \"Datawarehouses are commoditized - cheap to build, maintain, and well understood. How can we change that?\"\n\nBut... presumably there's a more forward-looking reason.  \n\n(I'm coming from a place of ignorance - not a data engineer. Have only worked with Azure SQL and on-prem SQL Server before, and am currently learning Synapse Serverless which...oh, flat files, yeah OK, but the actual relational version is on the way out?  Huh. Thus the Q.)", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are Synapse Dedicated Pools on the way out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l14cn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684421264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Synapse Dedicated Pools (fka Azure SQL Data Warehouse) as far as I can tell - are on the way out. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No major updates in 3 years&lt;/li&gt;\n&lt;li&gt;I hear - can expect ~3 years of support, then migration to Serverless SQL pools&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;First, correct me if my premise is off. But if it&amp;#39;s correct:&lt;/p&gt;\n\n&lt;p&gt;Why? &lt;/p&gt;\n\n&lt;p&gt;I have a mental picture of someone at MS starting a meeting with &amp;quot;Datawarehouses are commoditized - cheap to build, maintain, and well understood. How can we change that?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;But... presumably there&amp;#39;s a more forward-looking reason.  &lt;/p&gt;\n\n&lt;p&gt;(I&amp;#39;m coming from a place of ignorance - not a data engineer. Have only worked with Azure SQL and on-prem SQL Server before, and am currently learning Synapse Serverless which...oh, flat files, yeah OK, but the actual relational version is on the way out?  Huh. Thus the Q.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l14cn", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l14cn/why_are_synapse_dedicated_pools_on_the_way_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l14cn/why_are_synapse_dedicated_pools_on_the_way_out/", "subreddit_subscribers": 106055, "created_utc": 1684421264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggest, what is the most absurd projects or task that you have handled in your DE career? \n\nMine was back when I was working in a local IT consulting. We have created pipelines and dashboards for this one client, but somehow they also want a PDF version of these dashboards to be sent to chat groups and DMs of their employees on different level and region (they use Telegram). Because our BI viz tool doesn't have the capabilities to do that, the consultant and DE lead that handled that client proposed an idea to recreate those dashboards one by one in excel using python scripts, export the excel files into PDF, and finally creating a chat bot to send this PDF to various chat groups and DMs.\n\nThe development phase was not a pleasant experience either. We didn't have a git repository and CI/CD pipeline, so all of code was stored in Dropbox and the 'deployment' was done by sending the scripts to a VM via SFTP and ran it via cronjob.", "author_fullname": "t2_1q71lc7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most ridiculous project/task/request that you have handled as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l0fcc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684419497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggest, what is the most absurd projects or task that you have handled in your DE career? &lt;/p&gt;\n\n&lt;p&gt;Mine was back when I was working in a local IT consulting. We have created pipelines and dashboards for this one client, but somehow they also want a PDF version of these dashboards to be sent to chat groups and DMs of their employees on different level and region (they use Telegram). Because our BI viz tool doesn&amp;#39;t have the capabilities to do that, the consultant and DE lead that handled that client proposed an idea to recreate those dashboards one by one in excel using python scripts, export the excel files into PDF, and finally creating a chat bot to send this PDF to various chat groups and DMs.&lt;/p&gt;\n\n&lt;p&gt;The development phase was not a pleasant experience either. We didn&amp;#39;t have a git repository and CI/CD pipeline, so all of code was stored in Dropbox and the &amp;#39;deployment&amp;#39; was done by sending the scripts to a VM via SFTP and ran it via cronjob.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l0fcc", "is_robot_indexable": true, "report_reasons": null, "author": "srodinger18", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l0fcc/what_is_the_most_ridiculous_projecttaskrequest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l0fcc/what_is_the_most_ridiculous_projecttaskrequest/", "subreddit_subscribers": 106055, "created_utc": 1684419497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any interesting data engineering projects written in Go? Im especialy interested in query engines. \nI know Rust has some (like Data Fusion or Pola-rs), but I havent heard much about Go. Is it not suitable for the job? \nIt looked to me like Go could replace Java in DE tooling, but Im not sure now.", "author_fullname": "t2_31py9i9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Tools in Go", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l0bpi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684419239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any interesting data engineering projects written in Go? Im especialy interested in query engines. \nI know Rust has some (like Data Fusion or Pola-rs), but I havent heard much about Go. Is it not suitable for the job? \nIt looked to me like Go could replace Java in DE tooling, but Im not sure now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l0bpi", "is_robot_indexable": true, "report_reasons": null, "author": "nvimvd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l0bpi/data_engineering_tools_in_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l0bpi/data_engineering_tools_in_go/", "subreddit_subscribers": 106055, "created_utc": 1684419239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10v76s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Engineering Guide to Data Quality - A Data Contract Perspective", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 123, "top_awarded_type": null, "hide_score": true, "name": "t3_13l0abl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8zaTannhHxrgo-aY9o5wJSSLvn1cNgJVqG_yPwRnhGs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684419136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringweekly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeringweekly.com/p/an-engineering-guide-to-data-quality", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JCzezKSW2c0c8ym2MFya6lIqJN301UC_41_ciqD9IFo.jpg?auto=webp&amp;v=enabled&amp;s=af4c96e7c7782751d3c66d8ea77e15dd6267d7e2", "width": 679, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JCzezKSW2c0c8ym2MFya6lIqJN301UC_41_ciqD9IFo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e5a54938183bdd1fbb49859404660719d9322a6d", "width": 108, "height": 95}, {"url": "https://external-preview.redd.it/JCzezKSW2c0c8ym2MFya6lIqJN301UC_41_ciqD9IFo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ffd24a6818de739433d1877ed07fb5de6e6d9fd", "width": 216, "height": 190}, {"url": "https://external-preview.redd.it/JCzezKSW2c0c8ym2MFya6lIqJN301UC_41_ciqD9IFo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9ba70f14f9aa67d81dcd8f122a175a7895cef56", "width": 320, "height": 282}, {"url": "https://external-preview.redd.it/JCzezKSW2c0c8ym2MFya6lIqJN301UC_41_ciqD9IFo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bae8709d83bd8cbbcfea472b9cbdf3ca7fc73c5d", "width": 640, "height": 565}], "variants": {}, "id": "HYFqac5NTOEhIoEAeeUAe0rRtWFrritCkgWjLFIcNO4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13l0abl", "is_robot_indexable": true, "report_reasons": null, "author": "vananth22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l0abl/an_engineering_guide_to_data_quality_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeringweekly.com/p/an-engineering-guide-to-data-quality", "subreddit_subscribers": 106055, "created_utc": 1684419136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that for a normal dimensional model the fact table contains 1 or more FKs to the dimensions, but we're creating a factless fact table for our person data.  We want our users to be able to report on things like, how many persons have an address in this county, how many have more than one phone number, etc.  To accomplish this I plan on having my fact table have each Person Id appear once, then each of my dimension tables will have the Person Id appearing 1 or more times.  \n\nI'd have to create a measure to count *distinct* Person Id because joining to any of the dimension tables would create duplicates, e.g., if a person had duplicate addresses or phone numbers, etc.\n\nCan anyone see any problems with this approach?", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensional Data Model Question for Person", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l080h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684418978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that for a normal dimensional model the fact table contains 1 or more FKs to the dimensions, but we&amp;#39;re creating a factless fact table for our person data.  We want our users to be able to report on things like, how many persons have an address in this county, how many have more than one phone number, etc.  To accomplish this I plan on having my fact table have each Person Id appear once, then each of my dimension tables will have the Person Id appearing 1 or more times.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d have to create a measure to count &lt;em&gt;distinct&lt;/em&gt; Person Id because joining to any of the dimension tables would create duplicates, e.g., if a person had duplicate addresses or phone numbers, etc.&lt;/p&gt;\n\n&lt;p&gt;Can anyone see any problems with this approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13l080h", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l080h/dimensional_data_model_question_for_person/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l080h/dimensional_data_model_question_for_person/", "subreddit_subscribers": 106055, "created_utc": 1684418978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys !\n\nI will be facing the task of an enterprise data migration from legacy systems to new ones that are currently in development.\n\nThe migration is about moving all business data from an SQL server and an IBM db2 databases to a new one powered by PostGres through a Django app. \n\nHere I am talking about mid size business with data approximately a few hundreds millions rows.\n\nI have experience with various databases but mostly on the client side, I develop in SQL and Python for various tasks but mainly reporting automation and data extraction, this will be the first task I will be managing a data migration.\n\nI am currently reading Practical data migrations from Johnny Morris and even though I find it quite interesting and giving a few good advices I would like some advices from other people who also had to do this job.\n\nWe are a team of two (both mastering Python/SQL and ETL tools such as Talend) and my plan is to cut the data in as much small pieces as required (for example one for customers one for contracts\u2026.) and proceed to a mapping from the legacy sources to the new ones (the fact that the new one is being written on Django gives us a very different  database structure). Once this mapping is done I would like to clean properly prepare the data according to the business rules and requirements.\nThen I want to load the data cut by cut and test help with assistance of business actors.\n\nHow would you guys do that or have done it ? \nWould you have any advices, any pitfalls to avoid or tools to recommend ? \nDo you think that the database is an ORM one such as Django would make one want to take a different data loading approach ?\n\nThis challenge makes me a bit stressed out but I think with the right methodology and proper time it would be all right \n\nThanks in advance !", "author_fullname": "t2_gunst0dz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advices for data migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13l00s1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684418477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys !&lt;/p&gt;\n\n&lt;p&gt;I will be facing the task of an enterprise data migration from legacy systems to new ones that are currently in development.&lt;/p&gt;\n\n&lt;p&gt;The migration is about moving all business data from an SQL server and an IBM db2 databases to a new one powered by PostGres through a Django app. &lt;/p&gt;\n\n&lt;p&gt;Here I am talking about mid size business with data approximately a few hundreds millions rows.&lt;/p&gt;\n\n&lt;p&gt;I have experience with various databases but mostly on the client side, I develop in SQL and Python for various tasks but mainly reporting automation and data extraction, this will be the first task I will be managing a data migration.&lt;/p&gt;\n\n&lt;p&gt;I am currently reading Practical data migrations from Johnny Morris and even though I find it quite interesting and giving a few good advices I would like some advices from other people who also had to do this job.&lt;/p&gt;\n\n&lt;p&gt;We are a team of two (both mastering Python/SQL and ETL tools such as Talend) and my plan is to cut the data in as much small pieces as required (for example one for customers one for contracts\u2026.) and proceed to a mapping from the legacy sources to the new ones (the fact that the new one is being written on Django gives us a very different  database structure). Once this mapping is done I would like to clean properly prepare the data according to the business rules and requirements.\nThen I want to load the data cut by cut and test help with assistance of business actors.&lt;/p&gt;\n\n&lt;p&gt;How would you guys do that or have done it ? \nWould you have any advices, any pitfalls to avoid or tools to recommend ? \nDo you think that the database is an ORM one such as Django would make one want to take a different data loading approach ?&lt;/p&gt;\n\n&lt;p&gt;This challenge makes me a bit stressed out but I think with the right methodology and proper time it would be all right &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13l00s1", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Smile8316", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l00s1/need_advices_for_data_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l00s1/need_advices_for_data_migration/", "subreddit_subscribers": 106055, "created_utc": 1684418477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I used to use [psql](https://www.postgresql.org/docs/current/app-psql.html#:%7E:text=psql%20is%20a%20terminal%2Dbased,and%20see%20the%20query%20results.) to connect to an aws redshift instance, and I would like to know if I can do the same with bigquery ?\n\nAt first sight, it seems like not because, unlike redshift, bigquery is not built on top of postgresql or something similar to it (it is built upon dremel). Is this understanding correct ?", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "psql and bigquery make a couple ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kytsj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684415466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to use &lt;a href=\"https://www.postgresql.org/docs/current/app-psql.html#:%7E:text=psql%20is%20a%20terminal%2Dbased,and%20see%20the%20query%20results.\"&gt;psql&lt;/a&gt; to connect to an aws redshift instance, and I would like to know if I can do the same with bigquery ?&lt;/p&gt;\n\n&lt;p&gt;At first sight, it seems like not because, unlike redshift, bigquery is not built on top of postgresql or something similar to it (it is built upon dremel). Is this understanding correct ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kytsj", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kytsj/psql_and_bigquery_make_a_couple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kytsj/psql_and_bigquery_make_a_couple/", "subreddit_subscribers": 106055, "created_utc": 1684415466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I live in an area that's heavy with biotech and biotech-adjacent companies (pharma, health-tech, etc) and am considering a jump into that industry. I've been in consulting for a few years but have never had a project in the industry, so I'd love to hear what it's generally like - what are the problems you're typically facing? Are your teams given free reign and autonomy? Are pay and wlb pretty good?\n\nI'm just afraid that I'll get bored and the company I join will plateau not challenge me enough. Happy to also message/dm privately", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work in biotech or a biotech-adjacent company? Would love to hear what it's like in that industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ky7yx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684414006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I live in an area that&amp;#39;s heavy with biotech and biotech-adjacent companies (pharma, health-tech, etc) and am considering a jump into that industry. I&amp;#39;ve been in consulting for a few years but have never had a project in the industry, so I&amp;#39;d love to hear what it&amp;#39;s generally like - what are the problems you&amp;#39;re typically facing? Are your teams given free reign and autonomy? Are pay and wlb pretty good?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just afraid that I&amp;#39;ll get bored and the company I join will plateau not challenge me enough. Happy to also message/dm privately&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13ky7yx", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ky7yx/anyone_work_in_biotech_or_a_biotechadjacent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ky7yx/anyone_work_in_biotech_or_a_biotechadjacent/", "subreddit_subscribers": 106055, "created_utc": 1684414006.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}