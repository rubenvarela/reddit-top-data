{"kind": "Listing", "data": {"after": "t3_13k9t1l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_90dih85se", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google accounts with youtube videos will not be deleted", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_13k50k0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 902, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 902, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/krjA1ekSDDoIcvI7_EYN6XPvUVNvjidTDJSQIft2d8k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684337351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3c1z79npbg0b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3c1z79npbg0b1.jpg?auto=webp&amp;v=enabled&amp;s=7c532cadce6a2d63bd4eda504cfb511b81e3a23a", "width": 828, "height": 455}, "resolutions": [{"url": "https://preview.redd.it/3c1z79npbg0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9427ac4d47c9c42170bc36943a23ab37d1be97fd", "width": 108, "height": 59}, {"url": "https://preview.redd.it/3c1z79npbg0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8c346ff36bc56ef79f0993bb416973351aa3da2", "width": 216, "height": 118}, {"url": "https://preview.redd.it/3c1z79npbg0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c3e19d7afe55b430bd744c5775d1f4a2e2b7e15", "width": 320, "height": 175}, {"url": "https://preview.redd.it/3c1z79npbg0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c63f973e219cfd07523850891d55a3ad0912d82", "width": 640, "height": 351}], "variants": {}, "id": "VbRqmlVi4pLAZnqa1Zr0Tf0Rvm34lBCNIHzOndPqkZc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k50k0", "is_robot_indexable": true, "report_reasons": null, "author": "LightningFanGirl", "discussion_type": null, "num_comments": 128, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3c1z79npbg0b1.jpg", "subreddit_subscribers": 683209, "created_utc": 1684337351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uw14ew4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZipCloud.com will Shut Down the Free 1GB Tier and delete all Data on Jun, 16 2023!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 31, "top_awarded_type": null, "hide_score": false, "name": "t3_13jy6d9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 148, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 148, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tnVoX1ahaOzhx6wnxIZwEk24xuKyvPrUJtuHCnP-Dco.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684320428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2nm6qafgfd0b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?auto=webp&amp;v=enabled&amp;s=dc0fc9a0eff660fa991fe4dde49ed9accbd9f592", "width": 1590, "height": 363}, "resolutions": [{"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98b866096a89677fbefd6c08b66dcbf79106e70d", "width": 108, "height": 24}, {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e2fc11b58785ef1a0ebb3794a327160c93576a9", "width": 216, "height": 49}, {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=103b5eb35758720c6fa1a5cd57283742c0b128bb", "width": 320, "height": 73}, {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c11048d8ad006be5326c91afbb47df609eb9ef4c", "width": 640, "height": 146}, {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1ed50fdc0aff5c4f21e0d0b34167c9f09b0a080", "width": 960, "height": 219}, {"url": "https://preview.redd.it/2nm6qafgfd0b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=075eed3fc24ef1b4c794a80a9b51b578d242aa83", "width": 1080, "height": 246}], "variants": {}, "id": "v_A97UdSLGAFYWxWpKA5tc5zHhlVfuvY3ZaaR83lbkI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13jy6d9", "is_robot_indexable": true, "report_reasons": null, "author": "JasonTheHasher", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13jy6d9/zipcloudcom_will_shut_down_the_free_1gb_tier_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2nm6qafgfd0b1.png", "subreddit_subscribers": 683209, "created_utc": 1684320428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let's get a megathread going now before we're flooded with more of these posts. Google says YouTube videos will NOT be deleted. Source: [https://www.reddit.com/r/DataHoarder/comments/13k50k0/google\\_accounts\\_with\\_youtube\\_videos\\_will\\_not\\_be/](https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/)  \n\n\nOriginal article:\n\n[https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts](https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts)  \n\n\nSome existing threads i'll leave open:\n\n&amp;#x200B;\n\nYouTube videos won't be deleted: [https://www.reddit.com/r/DataHoarder/comments/13k50k0/google\\_accounts\\_with\\_youtube\\_videos\\_will\\_not\\_be/](https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/)  \n\n\nExisting discussion on article:  \n[https://www.reddit.com/r/DataHoarder/comments/13j8a44/google\\_might\\_delete\\_your\\_gmail\\_account\\_if\\_you/](https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/)  \n\n\n  \nYouTube purge talk:\n\n[https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential\\_youtube\\_great\\_purge\\_due\\_2\\_years/](https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/)", "author_fullname": "t2_6htgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MEGATHREAD: Google inactive accounts purge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kci86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684353909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s get a megathread going now before we&amp;#39;re flooded with more of these posts. Google says YouTube videos will NOT be deleted. Source: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Original article:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts\"&gt;https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Some existing threads i&amp;#39;ll leave open:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;YouTube videos won&amp;#39;t be deleted: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Existing discussion on article:&lt;br/&gt;\n&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;YouTube purge talk:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?auto=webp&amp;v=enabled&amp;s=ef105f64542a55b86cedf362844f61f02ff12132", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00692dc796ac9f398ebfb27b6a1efad476407721", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b8bafa196ab25281f16fd5b4758f1ed676c76ad", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee0575312104de6014b8bb82209789f3b4a59c39", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f82f908f2f5a6265ccc7fb7138450e0b82db52", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ec64b7f2ed40aa38aa9e4d15fed443499e2a56e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb2a10bb708b34c2908bd2bf4af45c67418e6425", "width": 1080, "height": 565}], "variants": {}, "id": "lF5NRpw2f-9zN7vCx5FWogja3x4KVzpShDhCeZxmUxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "VHS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": "moderator", "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "13kci86", "is_robot_indexable": true, "report_reasons": null, "author": "nicholasserra", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13kci86/megathread_google_inactive_accounts_purge/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/13kci86/megathread_google_inactive_accounts_purge/", "subreddit_subscribers": 683209, "created_utc": 1684353909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With google announcing their deletion wave, starting in December, everybody is paying attention to youtube content. This is important but I don't want to worry about tunnel vision. Are there risks of losing tech support comments, blogs, etc? What other things are endangered?", "author_fullname": "t2_uh5my0gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Besides youtube, what other google account-connected content is at risk of vanishing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kajpz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684349489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With google announcing their deletion wave, starting in December, everybody is paying attention to youtube content. This is important but I don&amp;#39;t want to worry about tunnel vision. Are there risks of losing tech support comments, blogs, etc? What other things are endangered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13kajpz", "is_robot_indexable": true, "report_reasons": null, "author": "Warriohuma", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kajpz/besides_youtube_what_other_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kajpz/besides_youtube_what_other_google/", "subreddit_subscribers": 683209, "created_utc": 1684349489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_6eu3gcyt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Costco DEAL - Samsung T7 SSD 2TB Touch (orig: $190; sale: $129)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4psxzb728g0b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e8c378d516aa2ec40d3a4f102339b5d4e5db730"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7dd537892bae8af23476a1de55f2a6c05e76b1c"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a60774494abe44106c82c413087e1f076bb566d9"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd1e4a3f4f1dde971fbc97177e4d756dd3cfe9bb"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc3923fcb016d91b0a84179d468f27691e9489c"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dacb6d762568b48c1ab0ec4021d729e15a4c2fc"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3e0f8ad7c078b8579ce2e900a9533ffa94f47538"}, "id": "4psxzb728g0b1"}, "iqh6lc728g0b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 174, "x": 108, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6168fb88ed2ddb640ead62ea6a8bf33ffa6c2c64"}, {"y": 348, "x": 216, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bb4437ad265ad0c74665e28382969e1babed029"}, {"y": 516, "x": 320, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ac729c7f456f44d7d21447b5af475a057b85681"}, {"y": 1032, "x": 640, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1780fc3aea739a349469819012c2502240b4cde5"}, {"y": 1548, "x": 960, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23a074868b9805fc5b049f2e0c6075da21214c93"}, {"y": 1742, "x": 1080, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec37562f062990fc70ef306c4fdc20716fc0c7b4"}], "s": {"y": 3520, "x": 2182, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=2182&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=13b39bdd8c7525dc8c4fc72a6cdbea1314495e76"}, "id": "iqh6lc728g0b1"}}, "name": "t3_13kclm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 7, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "4psxzb728g0b1", "id": 276400260}, {"media_id": "iqh6lc728g0b1", "id": 276400261}]}, "link_flair_text": "News", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K5qlwwJBwCkKdQa6YI9G2zuo3d_e0cmmnkhPSd0ssJM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684354124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13kclm2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kclm2", "is_robot_indexable": true, "report_reasons": null, "author": "pharm2tech", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kclm2/costco_deal_samsung_t7_ssd_2tb_touch_orig_190/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13kclm2", "subreddit_subscribers": 683209, "created_utc": 1684354124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With the news that Google will be deleting accounts with over two years inactivity, including associated YouTube channels, we are likely about to witness one of the biggest content purges *ever*. As much as we would like to, I think it is clearly far beyond the community's capabilities to archive everything due to the gigantic scale of what is hosted on YouTube; however if we can identify some priority targets some kind of collective effort might be possible to at least save those. \n\nI think it makes sense to focus on videos that are historically significant, unique and/or irreplacable, but I don't have any concrete proposals for how to determine that. Maybe we could start with creating a collective database with links of \"at risk\" channels, a colour code for what type of content it is, and a comment box for additional explanation if needed? That way, people with an interest in specific types of content can pool resources to focus on archiving material that's of interest to them. Channel links can be fed into yt-dlp.\n\nIf there are other ideas or suggestions I am all ears.", "author_fullname": "t2_bz4eq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We need a community archiving effort for YouTube channels. What's most crucial to protect and how do we get organised?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k2vv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684332641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the news that Google will be deleting accounts with over two years inactivity, including associated YouTube channels, we are likely about to witness one of the biggest content purges &lt;em&gt;ever&lt;/em&gt;. As much as we would like to, I think it is clearly far beyond the community&amp;#39;s capabilities to archive everything due to the gigantic scale of what is hosted on YouTube; however if we can identify some priority targets some kind of collective effort might be possible to at least save those. &lt;/p&gt;\n\n&lt;p&gt;I think it makes sense to focus on videos that are historically significant, unique and/or irreplacable, but I don&amp;#39;t have any concrete proposals for how to determine that. Maybe we could start with creating a collective database with links of &amp;quot;at risk&amp;quot; channels, a colour code for what type of content it is, and a comment box for additional explanation if needed? That way, people with an interest in specific types of content can pool resources to focus on archiving material that&amp;#39;s of interest to them. Channel links can be fed into yt-dlp.&lt;/p&gt;\n\n&lt;p&gt;If there are other ideas or suggestions I am all ears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13k2vv5", "is_robot_indexable": true, "report_reasons": null, "author": "CaptainTelos", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k2vv5/we_need_a_community_archiving_effort_for_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k2vv5/we_need_a_community_archiving_effort_for_youtube/", "subreddit_subscribers": 683209, "created_utc": 1684332641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nI record dash cam/driving videos daily and I want to be able to save 1 years worth of videos at a time and at the end of the year I want to be able to delete everything and start over.\n\nThis will give me the ability to have a years worth of videos to work with- some I will upload, some I wont- but at the end of the year I will delete everything.\n\nI will be uploaded 100gb per day.\n\nWhats my best option for this scenario?", "author_fullname": "t2_12t9fb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best option for storing 40tb?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jr0ew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684296756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I record dash cam/driving videos daily and I want to be able to save 1 years worth of videos at a time and at the end of the year I want to be able to delete everything and start over.&lt;/p&gt;\n\n&lt;p&gt;This will give me the ability to have a years worth of videos to work with- some I will upload, some I wont- but at the end of the year I will delete everything.&lt;/p&gt;\n\n&lt;p&gt;I will be uploaded 100gb per day.&lt;/p&gt;\n\n&lt;p&gt;Whats my best option for this scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13jr0ew", "is_robot_indexable": true, "report_reasons": null, "author": "wuntuuthree", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13jr0ew/best_option_for_storing_40tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13jr0ew/best_option_for_storing_40tb/", "subreddit_subscribers": 683209, "created_utc": 1684296756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am not talking about simply downloading them to your PC, I'm talking about flat out creating mirrors in sites like archive.org.\nI know about tubeup, but it only works for individual videos and inputting an entire channel will just flood the IA with countless entries and make it harder to find things.\n\n\"Why not do it manually?\"\nI HAVE been trying to do it manually for the last 2 years but the process is becoming increasingly tedious for the following reasons:\n\n1. I have very little free space on my hard drives. My biggest external hard drives are the size of 2TB which is very small for these purposes. Not to mention a ton of space is already occupied by personal stuff. This means I can only download content from a handful of channels at a time then delete it once I upload it to IA.\n\n2. IA's upload speeds are insanely unreliable. One week I can upload several gigabytes in less than an hour, the next week I'll wait several hours just to upload something the size of 500MB.\n\n3. I always feel compelled to archive the contents of a creator's accounts in other platforms aside from YT itself such as soundcloud or deviantart for example. Obviously if a hypothetical YT archiver exists it probably won't work for other platforms but even automating just the YT channel will reduce a lot of tedium.\n\nI constantly find new channels that I want to preserve. My backlog keeps increasing. The more my backlog grows the more burnt out I feel. The more burnt out I feel the more I procrastinate. In the end the result is that I haven't archived a channel in MONTHS. \nAnd now with Google's announcement there's a sudden sense of urgency that I don't know if I can handle. I don't think I'll be able to accomplish that on my own without some kind of automation.\n\nPlease, any help would be greatly appreciated", "author_fullname": "t2_5f5hhwap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In light of recent news is there a way to automatically archive YT channels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k1ut1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684330478.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684330293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not talking about simply downloading them to your PC, I&amp;#39;m talking about flat out creating mirrors in sites like archive.org.\nI know about tubeup, but it only works for individual videos and inputting an entire channel will just flood the IA with countless entries and make it harder to find things.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Why not do it manually?&amp;quot;\nI HAVE been trying to do it manually for the last 2 years but the process is becoming increasingly tedious for the following reasons:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I have very little free space on my hard drives. My biggest external hard drives are the size of 2TB which is very small for these purposes. Not to mention a ton of space is already occupied by personal stuff. This means I can only download content from a handful of channels at a time then delete it once I upload it to IA.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;IA&amp;#39;s upload speeds are insanely unreliable. One week I can upload several gigabytes in less than an hour, the next week I&amp;#39;ll wait several hours just to upload something the size of 500MB.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I always feel compelled to archive the contents of a creator&amp;#39;s accounts in other platforms aside from YT itself such as soundcloud or deviantart for example. Obviously if a hypothetical YT archiver exists it probably won&amp;#39;t work for other platforms but even automating just the YT channel will reduce a lot of tedium.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I constantly find new channels that I want to preserve. My backlog keeps increasing. The more my backlog grows the more burnt out I feel. The more burnt out I feel the more I procrastinate. In the end the result is that I haven&amp;#39;t archived a channel in MONTHS. \nAnd now with Google&amp;#39;s announcement there&amp;#39;s a sudden sense of urgency that I don&amp;#39;t know if I can handle. I don&amp;#39;t think I&amp;#39;ll be able to accomplish that on my own without some kind of automation.&lt;/p&gt;\n\n&lt;p&gt;Please, any help would be greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k1ut1", "is_robot_indexable": true, "report_reasons": null, "author": "anxiousarchiver", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k1ut1/in_light_of_recent_news_is_there_a_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k1ut1/in_light_of_recent_news_is_there_a_way_to/", "subreddit_subscribers": 683209, "created_utc": 1684330293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, this question, is not just about DataHoarding, but also about legal base of making materials available later.\n\nRight now I am supporting it, so there is no need to make it free for all, BUT everybody DIES and a lot of other stuff can happen any moment, so:\n\nI want that any code I release within certain project will become Public domain (or maybe be licensed under just free MIT attribution license) after 10 years from publication.\n\nSo is there licenses that already have such time conditions?\n\nOr how to properly formulate such conditions so, users can be sure that any code that is 10 years old is Public domain and he can do whatever he wants with it?\n\nI already tried to ask this question in r/legaladvice [what\\_is\\_best\\_way\\_to\\_release\\_something\\_in\\_public](https://www.reddit.com/r/legaladvice/comments/13ifs3y/what_is_best_way_to_release_something_in_public/), but with no luck.\n\nI'll be glad for any comments or advices, even if they may seem somewhat unrelated.", "author_fullname": "t2_qbksl235", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is best way to release something in Public domain (or make available under some free license like MIT) after 10 years starting from date of publication?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kf629", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684359980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, this question, is not just about DataHoarding, but also about legal base of making materials available later.&lt;/p&gt;\n\n&lt;p&gt;Right now I am supporting it, so there is no need to make it free for all, BUT everybody DIES and a lot of other stuff can happen any moment, so:&lt;/p&gt;\n\n&lt;p&gt;I want that any code I release within certain project will become Public domain (or maybe be licensed under just free MIT attribution license) after 10 years from publication.&lt;/p&gt;\n\n&lt;p&gt;So is there licenses that already have such time conditions?&lt;/p&gt;\n\n&lt;p&gt;Or how to properly formulate such conditions so, users can be sure that any code that is 10 years old is Public domain and he can do whatever he wants with it?&lt;/p&gt;\n\n&lt;p&gt;I already tried to ask this question in &lt;a href=\"/r/legaladvice\"&gt;r/legaladvice&lt;/a&gt; &lt;a href=\"https://www.reddit.com/r/legaladvice/comments/13ifs3y/what_is_best_way_to_release_something_in_public/\"&gt;what_is_best_way_to_release_something_in_public&lt;/a&gt;, but with no luck.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be glad for any comments or advices, even if they may seem somewhat unrelated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kf629", "is_robot_indexable": true, "report_reasons": null, "author": "atomknack", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kf629/what_is_best_way_to_release_something_in_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kf629/what_is_best_way_to_release_something_in_public/", "subreddit_subscribers": 683209, "created_utc": 1684359980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have 55 TB of data stored in Google Drive. After paying for four additional accounts, they increased the total storage to 25 TB. However, when I requested more storage, they only gave me 50 TB, which wasn't enough. They denied my subsequent request, so I decided to cancel my other four accounts. I'm not willing to pay $100 USD per month for only 50 TB.\n\nI reached out to Dropbox support, and after speaking with their chatbox, they said they would call me. However, I haven't received any updates from them. I've read comments suggesting that their support is useless. They charge $90 USD per month per \"unlimited storage\" but If I can't even get a call for their service, I can't imagine getting a response if something goes wrong.\n\nIn the meantime, I'm testing Backblaze B2. I received an email from a sales manager, but I noticed that there is no web-based GUI like Google Drive. Most of the third-party software with GUIs are paid and quite expensive. I understand that there are costs associated with storing and downloading content.\n\nQuestions:\n\n* Are there any free alternatives to manage files in B2? Such as renaming, deleting files, or moving them to folders?\n* I'm not sure if my files will be deleted. I have movies, series, ROMs, games, and files that I've collected over the years, like old issues of Mad Magazines, which I don't expect to read again. I'm concerned about whether these files will be deleted if I don't access them. I also don't plan to watch all the movies every year.\n* Considering my current data size of 55 TB and uploading 300 GB monthly, as well as watching 30 movies monthly via Kodi, how much do you think I will have to pay monthly?\n* How much are you currently paying for your storage, do you have any retention policy set?\n\nI have only 55 days to resolve this issue with Google Drive, I'm in state of panic.\n\nThanks and regards.", "author_fullname": "t2_2w8hbc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive alternative? BackBlaze B2 maybe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jvab7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684310598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have 55 TB of data stored in Google Drive. After paying for four additional accounts, they increased the total storage to 25 TB. However, when I requested more storage, they only gave me 50 TB, which wasn&amp;#39;t enough. They denied my subsequent request, so I decided to cancel my other four accounts. I&amp;#39;m not willing to pay $100 USD per month for only 50 TB.&lt;/p&gt;\n\n&lt;p&gt;I reached out to Dropbox support, and after speaking with their chatbox, they said they would call me. However, I haven&amp;#39;t received any updates from them. I&amp;#39;ve read comments suggesting that their support is useless. They charge $90 USD per month per &amp;quot;unlimited storage&amp;quot; but If I can&amp;#39;t even get a call for their service, I can&amp;#39;t imagine getting a response if something goes wrong.&lt;/p&gt;\n\n&lt;p&gt;In the meantime, I&amp;#39;m testing Backblaze B2. I received an email from a sales manager, but I noticed that there is no web-based GUI like Google Drive. Most of the third-party software with GUIs are paid and quite expensive. I understand that there are costs associated with storing and downloading content.&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are there any free alternatives to manage files in B2? Such as renaming, deleting files, or moving them to folders?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m not sure if my files will be deleted. I have movies, series, ROMs, games, and files that I&amp;#39;ve collected over the years, like old issues of Mad Magazines, which I don&amp;#39;t expect to read again. I&amp;#39;m concerned about whether these files will be deleted if I don&amp;#39;t access them. I also don&amp;#39;t plan to watch all the movies every year.&lt;/li&gt;\n&lt;li&gt;Considering my current data size of 55 TB and uploading 300 GB monthly, as well as watching 30 movies monthly via Kodi, how much do you think I will have to pay monthly?&lt;/li&gt;\n&lt;li&gt;How much are you currently paying for your storage, do you have any retention policy set?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have only 55 days to resolve this issue with Google Drive, I&amp;#39;m in state of panic.&lt;/p&gt;\n\n&lt;p&gt;Thanks and regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13jvab7", "is_robot_indexable": true, "report_reasons": null, "author": "ElBuenEloy", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13jvab7/google_drive_alternative_backblaze_b2_maybe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13jvab7/google_drive_alternative_backblaze_b2_maybe/", "subreddit_subscribers": 683209, "created_utc": 1684310598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 20 TB seagate internal hard drive I am accessing by using a hard drive enclosure. I have a Macbook and am trying to format the drive as Apple File System (APFS). I am wondering if there are benefits to partitioning if my only goal is to dump files on it? In other words, are there benefits from a recovery perspective if it failed one day? Thanks", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I am using a 20 TB hard drive just for storage, are there any benefits to partitioning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ka1q8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684348356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 20 TB seagate internal hard drive I am accessing by using a hard drive enclosure. I have a Macbook and am trying to format the drive as Apple File System (APFS). I am wondering if there are benefits to partitioning if my only goal is to dump files on it? In other words, are there benefits from a recovery perspective if it failed one day? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ka1q8", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ka1q8/if_i_am_using_a_20_tb_hard_drive_just_for_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ka1q8/if_i_am_using_a_20_tb_hard_drive_just_for_storage/", "subreddit_subscribers": 683209, "created_utc": 1684348356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nI have an ubuntu desktop that lost some files (I think I ran an rsync command in the wrong direction? Not sure what happened honestly) and I'm trying to restore from a backup I made last week. Is there a best way to diff two massive directories to find what files may or may not be missing from the current desktop and backup?\n\nI'm essentially trying to diff two /home directories. I ran a diff between both of them and piped the output to a output.txt which became this massive text file full of difficult to interpret info. Working on refining my diff parameters but I think it will have similar results regardless.\n\nI also tried meld but I think my machine was having trouble recursing and finding the files because it kept freezing. Might try and run it on a beefier machine later in the week.\n\nRegardless... is there a better way to do this? Feels like I might be missing an obvious solution for comparing two directories here.\n\nThanks in advance!", "author_fullname": "t2_cufnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest method for diffing two large directories when restoring backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k2d8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684331492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have an ubuntu desktop that lost some files (I think I ran an rsync command in the wrong direction? Not sure what happened honestly) and I&amp;#39;m trying to restore from a backup I made last week. Is there a best way to diff two massive directories to find what files may or may not be missing from the current desktop and backup?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m essentially trying to diff two /home directories. I ran a diff between both of them and piped the output to a output.txt which became this massive text file full of difficult to interpret info. Working on refining my diff parameters but I think it will have similar results regardless.&lt;/p&gt;\n\n&lt;p&gt;I also tried meld but I think my machine was having trouble recursing and finding the files because it kept freezing. Might try and run it on a beefier machine later in the week.&lt;/p&gt;\n\n&lt;p&gt;Regardless... is there a better way to do this? Feels like I might be missing an obvious solution for comparing two directories here.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k2d8o", "is_robot_indexable": true, "report_reasons": null, "author": "freddiefin", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k2d8o/easiest_method_for_diffing_two_large_directories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k2d8o/easiest_method_for_diffing_two_large_directories/", "subreddit_subscribers": 683209, "created_utc": 1684331492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have these two imgur images I uploaded anonymously a month ago, nothing too important, and definitely not even a thousandth of the amount of images I've posted onto imgur anonymously in my lifetime, but anyways I've been having problems accessing imgur for this entire month now, with the site either not loading at all and showing me error 429 or just simply not loading images. Apparently the people in this [post](https://www.reddit.com/r/techsupport/comments/13h9ui5/problems_opening_imgur_posts/) (one of the very few posts talking about this) are saying it's because of the massive amounts of data hoarders archiving images from imgur effectively causing some kind of DDOS attack onto its servers but others are saying it's because I'm using a VPN (or a combination of both, ie. imgur is restricting further image queries only to the most trustworthy IPs to reduce server strain)\n\nAnyways here are my two images:\n\n* [https://i.imgur.com/t5jmGEv.png](https://i.imgur.com/t5jmGEv.png)\n* [https://i.imgur.com/11T1hFQ.png](https://i.imgur.com/11T1hFQ.png)\n\nIn the future will there be a tool where I can just input in any old imgur image ID and retrieve the image data from it (almost like an imgur mirror site)? And by any I mean *any,* so not just the very popular ones found from reddit and a few random unpopular images here and there. I have treasure troves worth of information including imgur links from my childhood that I haven't been able to access yet, but when I do get to access them I want to be able to view all the imgur images like they still existed in imgur's servers, despite them not being posted elsewhere on the internet other than a single private location (by treasure troves I mean old discord dms, or emailed image dumps, the likes) Some of them probably contain old account information that could be used to further uncover the rabbithole of my childhood on the internet and without these images lots of things would be forever lost... I was practically raised on the internet in the 2010s era and I have participated in so many things I'm practically embedded in every facet on the internet. Besides my childhood to the internet some images probably contain clues to unlocking the secrets of my childhood outside of the internet, like playground pictures, and the likes.", "author_fullname": "t2_as6q6x6ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help me access these two imgur images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jsgr6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684301199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have these two imgur images I uploaded anonymously a month ago, nothing too important, and definitely not even a thousandth of the amount of images I&amp;#39;ve posted onto imgur anonymously in my lifetime, but anyways I&amp;#39;ve been having problems accessing imgur for this entire month now, with the site either not loading at all and showing me error 429 or just simply not loading images. Apparently the people in this &lt;a href=\"https://www.reddit.com/r/techsupport/comments/13h9ui5/problems_opening_imgur_posts/\"&gt;post&lt;/a&gt; (one of the very few posts talking about this) are saying it&amp;#39;s because of the massive amounts of data hoarders archiving images from imgur effectively causing some kind of DDOS attack onto its servers but others are saying it&amp;#39;s because I&amp;#39;m using a VPN (or a combination of both, ie. imgur is restricting further image queries only to the most trustworthy IPs to reduce server strain)&lt;/p&gt;\n\n&lt;p&gt;Anyways here are my two images:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://i.imgur.com/t5jmGEv.png\"&gt;https://i.imgur.com/t5jmGEv.png&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://i.imgur.com/11T1hFQ.png\"&gt;https://i.imgur.com/11T1hFQ.png&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In the future will there be a tool where I can just input in any old imgur image ID and retrieve the image data from it (almost like an imgur mirror site)? And by any I mean &lt;em&gt;any,&lt;/em&gt; so not just the very popular ones found from reddit and a few random unpopular images here and there. I have treasure troves worth of information including imgur links from my childhood that I haven&amp;#39;t been able to access yet, but when I do get to access them I want to be able to view all the imgur images like they still existed in imgur&amp;#39;s servers, despite them not being posted elsewhere on the internet other than a single private location (by treasure troves I mean old discord dms, or emailed image dumps, the likes) Some of them probably contain old account information that could be used to further uncover the rabbithole of my childhood on the internet and without these images lots of things would be forever lost... I was practically raised on the internet in the 2010s era and I have participated in so many things I&amp;#39;m practically embedded in every facet on the internet. Besides my childhood to the internet some images probably contain clues to unlocking the secrets of my childhood outside of the internet, like playground pictures, and the likes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LQitdy2-SxAnyj4xaFNaPTk_Ga0epCbZYuguarr5G34.png?auto=webp&amp;v=enabled&amp;s=97fb91a6d29556421a3a7900374fd2e36b28fa95", "width": 885, "height": 332}, "resolutions": [{"url": "https://external-preview.redd.it/LQitdy2-SxAnyj4xaFNaPTk_Ga0epCbZYuguarr5G34.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f40e3ac068ac7871831c04e89a8215a2b443fe97", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/LQitdy2-SxAnyj4xaFNaPTk_Ga0epCbZYuguarr5G34.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=888adf8f79639173c9e557ec02342db26140b5c1", "width": 216, "height": 81}, {"url": "https://external-preview.redd.it/LQitdy2-SxAnyj4xaFNaPTk_Ga0epCbZYuguarr5G34.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=864daae48bbba4d0fd671783e4aabfe5bba8d764", "width": 320, "height": 120}, {"url": "https://external-preview.redd.it/LQitdy2-SxAnyj4xaFNaPTk_Ga0epCbZYuguarr5G34.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d51b555e822bb65a196127ce42c7390ba156db3", "width": 640, "height": 240}], "variants": {}, "id": "EzSdy3FxugaM07Q8nfgyd2LMZl7bYXmFfyJhcR1vTQ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13jsgr6", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic_Essay9033", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13jsgr6/can_anyone_help_me_access_these_two_imgur_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13jsgr6/can_anyone_help_me_access_these_two_imgur_images/", "subreddit_subscribers": 683209, "created_utc": 1684301199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using traditional hdd's for my file storage. Currently, I only have 14TB split between  5 drives and have been thinking about creating my own dedicated file server.\n\nIs the new standard for file servers ssd based? Kinda looking for a solution for long-term storage, but I'm kind of lost. Would appreciate some help lol.", "author_fullname": "t2_16de20zp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Long term Storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjgwq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using traditional hdd&amp;#39;s for my file storage. Currently, I only have 14TB split between  5 drives and have been thinking about creating my own dedicated file server.&lt;/p&gt;\n\n&lt;p&gt;Is the new standard for file servers ssd based? Kinda looking for a solution for long-term storage, but I&amp;#39;m kind of lost. Would appreciate some help lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kjgwq", "is_robot_indexable": true, "report_reasons": null, "author": "HeartDessire", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjgwq/long_term_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjgwq/long_term_storage/", "subreddit_subscribers": 683209, "created_utc": 1684370453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks.  I am moving soon, and wish to bring some of my hard drives with me through the airport.  I have exactly 100 hard drives, and need to move them with me preferably the day of the move.  I took out my suitcase, and 45 drives will fit in there, making it 50-60 pounds.  I am allowed two carry ons (backpack + suitcase), and two (up to) 50 pound totes (cannot have a single 100 pound or 60/40, 70/30, etc.).  I do not trust putting the drives in the totes due to the possibility of them getting banged around in transportation, and I have also had some very valuable stuff stolen out of my totes when they go through SeaTac (Comic Books to be more exact).  This leaves me with either shipping them up via Large Flat Rate Boxes, or putting the remaining drives (26 3.5, the rest 2.5 inch) in my backpack, though these would need to fit under the seat in front of me, so I am skeptical that would work.\n\n&amp;#x200B;\n\nMy concern is how to move them up with me without getting banged around (even with padding).  All drives are in ESD Bags.  My second concern is whether or not I will have issues at Airport security.  I once went through FAI with around 200 bouncy balls (from my childhood), and that held us up for an hour and almost made us miss our flight because they took each ball and put them in it's own bin to scan individually.  Should I tell the person ahead of time that my suitcase is nothing but hard drives in ESD Bags?  Are they vulnerable to the XRay?  Will security think its weird that I am traveling with an entire suitcase full of Hard Drives and confiscate them?  I simply wish to know these things ahead of time so I am able to take the preventative steps to avoid any fiasco.\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_3zr5fswte", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airport Concern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kbgje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684351563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks.  I am moving soon, and wish to bring some of my hard drives with me through the airport.  I have exactly 100 hard drives, and need to move them with me preferably the day of the move.  I took out my suitcase, and 45 drives will fit in there, making it 50-60 pounds.  I am allowed two carry ons (backpack + suitcase), and two (up to) 50 pound totes (cannot have a single 100 pound or 60/40, 70/30, etc.).  I do not trust putting the drives in the totes due to the possibility of them getting banged around in transportation, and I have also had some very valuable stuff stolen out of my totes when they go through SeaTac (Comic Books to be more exact).  This leaves me with either shipping them up via Large Flat Rate Boxes, or putting the remaining drives (26 3.5, the rest 2.5 inch) in my backpack, though these would need to fit under the seat in front of me, so I am skeptical that would work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My concern is how to move them up with me without getting banged around (even with padding).  All drives are in ESD Bags.  My second concern is whether or not I will have issues at Airport security.  I once went through FAI with around 200 bouncy balls (from my childhood), and that held us up for an hour and almost made us miss our flight because they took each ball and put them in it&amp;#39;s own bin to scan individually.  Should I tell the person ahead of time that my suitcase is nothing but hard drives in ESD Bags?  Are they vulnerable to the XRay?  Will security think its weird that I am traveling with an entire suitcase full of Hard Drives and confiscate them?  I simply wish to know these things ahead of time so I am able to take the preventative steps to avoid any fiasco.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kbgje", "is_robot_indexable": true, "report_reasons": null, "author": "Wise-Bird2450", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kbgje/airport_concern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kbgje/airport_concern/", "subreddit_subscribers": 683209, "created_utc": 1684351563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Another discussions made me think of this.  \nIs there a full fledged application capable of storing locally conversations (or more interactions) from a multitude of commercial services (facebook, discord, instagram, reddit, twitter etc) ? From some of these you can download and backup your data. But I'd like to have a single application that makes the data more easelly searchable and managable into a single GUI.", "author_fullname": "t2_59x3196w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to store multiple commercial services locally", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k782o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684342109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Another discussions made me think of this.&lt;br/&gt;\nIs there a full fledged application capable of storing locally conversations (or more interactions) from a multitude of commercial services (facebook, discord, instagram, reddit, twitter etc) ? From some of these you can download and backup your data. But I&amp;#39;d like to have a single application that makes the data more easelly searchable and managable into a single GUI.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k782o", "is_robot_indexable": true, "report_reasons": null, "author": "sweetsweetgaga", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k782o/software_to_store_multiple_commercial_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k782o/software_to_store_multiple_commercial_services/", "subreddit_subscribers": 683209, "created_utc": 1684342109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey y'all! I have some questions about the best way to download and display Instagram posts. I'm trying to create Instagram content plans for specific accounts/influencers, sort of like a custom blog post with posts in their niche included and analyzed as examples. Currently I embed the posts on a notion page but notion embeds are a bit janky and I'd like to host these pages on my own site if possible. \n\n&amp;#x200B;\n\nMy viable options right now look like embedding, downloading the content (reels, photos, and ideally descriptions), or using the native instagram guide feature. They all have some issues. \n\n&amp;#x200B;\n\nIt seems like there's a lot of experts on downloading Instagram content on here, is assisted content downloading a real banning concern or is it mostly in extreme cases? I wouldn't be downloading more than 10-20 posts a day if that. Does anyone have experience using a python script or anything else to redisplay this content data in another program/site? \n\n&amp;#x200B;\n\nDownload content \n\n\\-Downloading programs can get account banned if used too much \n\n\\-Labor intensive compared to embedding (more actions required)\n\n\\-Hosting actual content can slow down site \n\n&amp;#x200B;\n\nEmbed: \n\n\\-Can break as instagram/hosting site updates \n\n\\-Asks to sign into instagram \n\n\\-Sometimes makes user view on instagram instead of on page \n\n\\-Users can delete posts or turn off embedding \n\n&amp;#x200B;\n\nInstagram Guide \n\n\\-Guides can't be private or shared with just one person, workarounds like having a separate private account for each client are too clunky \n\n\\-More labor intensive to duplicate between clients, have to do everything from scratch  \n\n\\-Seamlessly incorporates native Insta content", "author_fullname": "t2_12bbxegs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about downloading Instagram content and some alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjkh9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all! I have some questions about the best way to download and display Instagram posts. I&amp;#39;m trying to create Instagram content plans for specific accounts/influencers, sort of like a custom blog post with posts in their niche included and analyzed as examples. Currently I embed the posts on a notion page but notion embeds are a bit janky and I&amp;#39;d like to host these pages on my own site if possible. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My viable options right now look like embedding, downloading the content (reels, photos, and ideally descriptions), or using the native instagram guide feature. They all have some issues. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It seems like there&amp;#39;s a lot of experts on downloading Instagram content on here, is assisted content downloading a real banning concern or is it mostly in extreme cases? I wouldn&amp;#39;t be downloading more than 10-20 posts a day if that. Does anyone have experience using a python script or anything else to redisplay this content data in another program/site? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Download content &lt;/p&gt;\n\n&lt;p&gt;-Downloading programs can get account banned if used too much &lt;/p&gt;\n\n&lt;p&gt;-Labor intensive compared to embedding (more actions required)&lt;/p&gt;\n\n&lt;p&gt;-Hosting actual content can slow down site &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Embed: &lt;/p&gt;\n\n&lt;p&gt;-Can break as instagram/hosting site updates &lt;/p&gt;\n\n&lt;p&gt;-Asks to sign into instagram &lt;/p&gt;\n\n&lt;p&gt;-Sometimes makes user view on instagram instead of on page &lt;/p&gt;\n\n&lt;p&gt;-Users can delete posts or turn off embedding &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Instagram Guide &lt;/p&gt;\n\n&lt;p&gt;-Guides can&amp;#39;t be private or shared with just one person, workarounds like having a separate private account for each client are too clunky &lt;/p&gt;\n\n&lt;p&gt;-More labor intensive to duplicate between clients, have to do everything from scratch  &lt;/p&gt;\n\n&lt;p&gt;-Seamlessly incorporates native Insta content&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kjkh9", "is_robot_indexable": true, "report_reasons": null, "author": "ThePeefers", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjkh9/questions_about_downloading_instagram_content_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjkh9/questions_about_downloading_instagram_content_and/", "subreddit_subscribers": 683209, "created_utc": 1684370711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 20TB hard drive mounted on a a Sabrent Docking Station and it is connected to my outlet through a cheap surge protector. I am wondering if I need to use a better surge protector into the outlet, as sometimes I can feel \"humming\" electricity on my Macbook when its connected to the surge protector.", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a good surge protector necessary for internal hard drives mounted on a docking station?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kji7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 20TB hard drive mounted on a a Sabrent Docking Station and it is connected to my outlet through a cheap surge protector. I am wondering if I need to use a better surge protector into the outlet, as sometimes I can feel &amp;quot;humming&amp;quot; electricity on my Macbook when its connected to the surge protector.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kji7v", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kji7v/is_a_good_surge_protector_necessary_for_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kji7v/is_a_good_surge_protector_necessary_for_internal/", "subreddit_subscribers": 683209, "created_utc": 1684370547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im moving to Dropbox later in the week, and I'm wanting to transfer over my files on my Gdrive account. With TB's to move, what would be the best way to do this? I do have rclone on my own personal server, but that would take quite awhile", "author_fullname": "t2_5pbat", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring files from Gdrive to Dropbox", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjh2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im moving to Dropbox later in the week, and I&amp;#39;m wanting to transfer over my files on my Gdrive account. With TB&amp;#39;s to move, what would be the best way to do this? I do have rclone on my own personal server, but that would take quite awhile&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kjh2f", "is_robot_indexable": true, "report_reasons": null, "author": "ligerzeronz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjh2f/transferring_files_from_gdrive_to_dropbox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjh2f/transferring_files_from_gdrive_to_dropbox/", "subreddit_subscribers": 683209, "created_utc": 1684370464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Asking for a friend.", "author_fullname": "t2_ru18w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much information can the human brain store in terms of data size?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kfsl4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684361386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Asking for a friend.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kfsl4", "is_robot_indexable": true, "report_reasons": null, "author": "McKnighty9", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kfsl4/how_much_information_can_the_human_brain_store_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kfsl4/how_much_information_can_the_human_brain_store_in/", "subreddit_subscribers": 683209, "created_utc": 1684361386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\n\nSetting up my first home storage server. And im looking for some advice.\n\n\nI have 4 18tb drives in 1 server. I want 2 of them to be mirrored and the other 2 to be pooled without striping.\n\n\nWhat would be the best setup for this software wise? Is this even possible? I have experience with linux/bash", "author_fullname": "t2_4mjy3g6kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 drives, 2 mirrored, 2 pooled?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ke144", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684357423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Setting up my first home storage server. And im looking for some advice.&lt;/p&gt;\n\n&lt;p&gt;I have 4 18tb drives in 1 server. I want 2 of them to be mirrored and the other 2 to be pooled without striping.&lt;/p&gt;\n\n&lt;p&gt;What would be the best setup for this software wise? Is this even possible? I have experience with linux/bash&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ke144", "is_robot_indexable": true, "report_reasons": null, "author": "LrrrRuler", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ke144/4_drives_2_mirrored_2_pooled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ke144/4_drives_2_mirrored_2_pooled/", "subreddit_subscribers": 683209, "created_utc": 1684357423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have changed all of the filenames but not the contents of the files in my movie collection for Radarr.\n\n I am wondering the best method for copying the updated filenames to my backup HDD (my backup drive still has the old filenames but the same exact files) without actually recopying all that data (+/- 20TB)", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to copy updated filenames but not the actual files to backup drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kd3kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684355261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have changed all of the filenames but not the contents of the files in my movie collection for Radarr.&lt;/p&gt;\n\n&lt;p&gt;I am wondering the best method for copying the updated filenames to my backup HDD (my backup drive still has the old filenames but the same exact files) without actually recopying all that data (+/- 20TB)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kd3kr", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kd3kr/how_to_copy_updated_filenames_but_not_the_actual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kd3kr/how_to_copy_updated_filenames_but_not_the_actual/", "subreddit_subscribers": 683209, "created_utc": 1684355261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm having a very strange case of filesystem corruption that's possibly not hardware-related.\n\nAfter years of usage, I had a 4TB NTFS Evo 860 that had some strange file corruption (jpg files had \"no header\" error when trying to open, but chkdsk didn't find an issue, files had exact same bit size). I used it via a USB3 SATA adapter seemed to work fine when attached straight with SATA. Out of caution I changed both the adapter cable AND I also got a new 870 SSD instead.\n\nNow after 2 weeks file corruption starts on the new drive as well. Unaccessible directories -&gt; chkdsk's \"free space marked as allocated in the bitmap for index\", orphaned file, errors in MFT's BITMAP attribute.\n\nBoth drives have good SMART values. According to Samsung Magician they have the latest firmware.\nWhat could be the issue? Could this be somehow the motherboard controller's fault? How could I debug this?", "author_fullname": "t2_4a8ri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's wrong with these Evo SSDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kcds0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684353641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having a very strange case of filesystem corruption that&amp;#39;s possibly not hardware-related.&lt;/p&gt;\n\n&lt;p&gt;After years of usage, I had a 4TB NTFS Evo 860 that had some strange file corruption (jpg files had &amp;quot;no header&amp;quot; error when trying to open, but chkdsk didn&amp;#39;t find an issue, files had exact same bit size). I used it via a USB3 SATA adapter seemed to work fine when attached straight with SATA. Out of caution I changed both the adapter cable AND I also got a new 870 SSD instead.&lt;/p&gt;\n\n&lt;p&gt;Now after 2 weeks file corruption starts on the new drive as well. Unaccessible directories -&amp;gt; chkdsk&amp;#39;s &amp;quot;free space marked as allocated in the bitmap for index&amp;quot;, orphaned file, errors in MFT&amp;#39;s BITMAP attribute.&lt;/p&gt;\n\n&lt;p&gt;Both drives have good SMART values. According to Samsung Magician they have the latest firmware.\nWhat could be the issue? Could this be somehow the motherboard controller&amp;#39;s fault? How could I debug this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kcds0", "is_robot_indexable": true, "report_reasons": null, "author": "poisonborz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kcds0/whats_wrong_with_these_evo_ssds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kcds0/whats_wrong_with_these_evo_ssds/", "subreddit_subscribers": 683209, "created_utc": 1684353641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had/have an Onn brand flash drive from Walmart. The tip of it snapped off inside my computer, I extracted it with tweezers. I thought it was done for. I thought the connector snapped off of the motherboard or something. With all hope gone, I decided to take apart the rest of my flash drive, just to know the extent of the damage. And then I learned there are two kinds of flash drive.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe\n\nI thought I had the one on the right, but I actually have the one on the left. Inside my flash drive was nothing. Nothing but enough plastic to slide the UDP, where all the actual data is stored, in and out of the computer. My UDP is still intact. But it's come free of the USB connector. At about a millimeter thick, it can't stay in my computer on its own.\n\nHas this ever happened to you? Have you ever had a loose UDP and you needed a way to get the data off of it or make it compatible with a computer? What do I do here?", "author_fullname": "t2_129mom3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I salvage the data from my UDP flash drive? I thought it was broken, but now I don't think it is.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fg0j0oubsf0b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf546708b842ce35bd8253627f40c60211399c9d"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a5c8b27badae32d2420d8d45dd39c24e28d5c7d"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b06374e26e64a22bb0c4d25cff9f7adf995ec079"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88584f2e236c6e8cad15a70760576a4d306b390f"}], "s": {"y": 533, "x": 800, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe"}, "id": "fg0j0oubsf0b1"}}, "name": "t3_13kaccl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WJFUXlO22f0p0bhiGRa1FVMdousGflAZVli-enCWNKc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684349031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had/have an Onn brand flash drive from Walmart. The tip of it snapped off inside my computer, I extracted it with tweezers. I thought it was done for. I thought the connector snapped off of the motherboard or something. With all hope gone, I decided to take apart the rest of my flash drive, just to know the extent of the damage. And then I learned there are two kinds of flash drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe\"&gt;https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I thought I had the one on the right, but I actually have the one on the left. Inside my flash drive was nothing. Nothing but enough plastic to slide the UDP, where all the actual data is stored, in and out of the computer. My UDP is still intact. But it&amp;#39;s come free of the USB connector. At about a millimeter thick, it can&amp;#39;t stay in my computer on its own.&lt;/p&gt;\n\n&lt;p&gt;Has this ever happened to you? Have you ever had a loose UDP and you needed a way to get the data off of it or make it compatible with a computer? What do I do here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kaccl", "is_robot_indexable": true, "report_reasons": null, "author": "FrothySolutions", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kaccl/how_can_i_salvage_the_data_from_my_udp_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kaccl/how_can_i_salvage_the_data_from_my_udp_flash/", "subreddit_subscribers": 683209, "created_utc": 1684349031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI've been looking around this and other reddit pages on best storage solutions for backing up my collection of game ROMs and PC game install files. However, I have some specific needs/questions that I could used guidance on:\n\n* I would like to be regularly copy game ROMs and install files to and from the storage solution with minimal risk of data loss or other technical issues; what storage medium would work for that? What would be the long-term consequences to the storage device? The goal is to keep a copy on the storage unit, and to copy from it to my main PC drive or other device for game play.\n* I would prefer an external storage solution to keep it separate from my PC, would that make sense given my use scenario or would the USB connection be a hindrance?\n* What process is best for copying individual or large sets or ROMs within the drive and to and from drives? My concern is that in the past I had read that simple Windows copy/paste functions were best for small, individual files but could cause date issues in aggregate. Is that the case with Windows 10 or am I safe to rely on basic copy/paste when adding files to my storage device or taking them off of it?\n* How often should I be ready to replace drives before data degradation becomes a risk, or is that not an issue in a realistic time frame with today's tech?\n\nMy storage needs aren't that large, about 2 TB for the foreseeable future. My budget is not super high, about $100-200. I have a basic understanding of archiving rules (3-2-1) and an understanding of storage tech (HDD vs SDD, etc) and get the sense that NAS might be the best option in the future, though I am unsure if I have the funds for that currently (though if I am wrong on that front I would be happy to pursue it instead should it meet my needs). Thank you for any advice!", "author_fullname": "t2_b3be2u61s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External storage options and process for game back ups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9t1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684347815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking around this and other reddit pages on best storage solutions for backing up my collection of game ROMs and PC game install files. However, I have some specific needs/questions that I could used guidance on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I would like to be regularly copy game ROMs and install files to and from the storage solution with minimal risk of data loss or other technical issues; what storage medium would work for that? What would be the long-term consequences to the storage device? The goal is to keep a copy on the storage unit, and to copy from it to my main PC drive or other device for game play.&lt;/li&gt;\n&lt;li&gt;I would prefer an external storage solution to keep it separate from my PC, would that make sense given my use scenario or would the USB connection be a hindrance?&lt;/li&gt;\n&lt;li&gt;What process is best for copying individual or large sets or ROMs within the drive and to and from drives? My concern is that in the past I had read that simple Windows copy/paste functions were best for small, individual files but could cause date issues in aggregate. Is that the case with Windows 10 or am I safe to rely on basic copy/paste when adding files to my storage device or taking them off of it?&lt;/li&gt;\n&lt;li&gt;How often should I be ready to replace drives before data degradation becomes a risk, or is that not an issue in a realistic time frame with today&amp;#39;s tech?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My storage needs aren&amp;#39;t that large, about 2 TB for the foreseeable future. My budget is not super high, about $100-200. I have a basic understanding of archiving rules (3-2-1) and an understanding of storage tech (HDD vs SDD, etc) and get the sense that NAS might be the best option in the future, though I am unsure if I have the funds for that currently (though if I am wrong on that front I would be happy to pursue it instead should it meet my needs). Thank you for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k9t1l", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonComet0079", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k9t1l/external_storage_options_and_process_for_game/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k9t1l/external_storage_options_and_process_for_game/", "subreddit_subscribers": 683209, "created_utc": 1684347815.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}