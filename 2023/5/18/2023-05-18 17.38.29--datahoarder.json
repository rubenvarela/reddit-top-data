{"kind": "Listing", "data": {"after": "t3_13k9t1l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_57o7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox: After four years of SMR storage, here's what we love\u2014and what comes next", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_13kqy64", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 177, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 177, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3bdhj-XDo3ZX3GZvoJoeB0S1SiC8J4QHjV6TfmP5d7k.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684392618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dropbox.tech", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dropbox.tech/infrastructure/four-years-of-smr-storage-what-we-love-and-whats-next", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?auto=webp&amp;v=enabled&amp;s=b21c2418753b5628f18962d82d3d9a626e76eebc", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85709443795963dfeab8995e54970230fd8eefb1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93c9d1523dd8f7432ed9eafd3c450696a44216db", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ba255c083eef77e0397f347c9d995542f19a05a", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23dcfc3cbf1fb0264f6085b55da28d3de3139329", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f7754ae0c9bc1e9d66cc67b1545e633656f1c66", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/w9o049_q2hhPwD3Ivxgom2MmZy0DHK4rEqwwqhZoXb8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b541b658216c00c466fe1af6ffcb5a89dc44cbf3", "width": 1080, "height": 565}], "variants": {}, "id": "Fu1Qer5s91j2J3UBkhCf3H59eCu9Ane8MkOnvbEvgxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "152 TB ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13kqy64", "is_robot_indexable": true, "report_reasons": null, "author": "callcifer", "discussion_type": null, "num_comments": 48, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13kqy64/dropbox_after_four_years_of_smr_storage_heres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dropbox.tech/infrastructure/four-years-of-smr-storage-what-we-love-and-whats-next", "subreddit_subscribers": 683337, "created_utc": 1684392618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let's get a megathread going now before we're flooded with more of these posts. Google says YouTube videos will NOT be deleted. Source: [https://www.reddit.com/r/DataHoarder/comments/13k50k0/google\\_accounts\\_with\\_youtube\\_videos\\_will\\_not\\_be/](https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/)  \n\n\nOriginal article:\n\n[https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts](https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts)  \n\n\nSome existing threads i'll leave open:\n\n&amp;#x200B;\n\nYouTube videos won't be deleted: [https://www.reddit.com/r/DataHoarder/comments/13k50k0/google\\_accounts\\_with\\_youtube\\_videos\\_will\\_not\\_be/](https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/)  \n\n\nExisting discussion on article:  \n[https://www.reddit.com/r/DataHoarder/comments/13j8a44/google\\_might\\_delete\\_your\\_gmail\\_account\\_if\\_you/](https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/)  \n\n\n  \nYouTube purge talk:\n\n[https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential\\_youtube\\_great\\_purge\\_due\\_2\\_years/](https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/)", "author_fullname": "t2_6htgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MEGATHREAD: Google inactive accounts purge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kci86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684353909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s get a megathread going now before we&amp;#39;re flooded with more of these posts. Google says YouTube videos will NOT be deleted. Source: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Original article:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts\"&gt;https://www.theverge.com/2023/5/16/23725438/google-gmail-deleting-inactive-accounts&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Some existing threads i&amp;#39;ll leave open:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;YouTube videos won&amp;#39;t be deleted: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13k50k0/google_accounts_with_youtube_videos_will_not_be/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Existing discussion on article:&lt;br/&gt;\n&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13j8a44/google_might_delete_your_gmail_account_if_you/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;YouTube purge talk:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13jn5ey/potential_youtube_great_purge_due_2_years/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?auto=webp&amp;v=enabled&amp;s=ef105f64542a55b86cedf362844f61f02ff12132", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00692dc796ac9f398ebfb27b6a1efad476407721", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b8bafa196ab25281f16fd5b4758f1ed676c76ad", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee0575312104de6014b8bb82209789f3b4a59c39", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f82f908f2f5a6265ccc7fb7138450e0b82db52", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ec64b7f2ed40aa38aa9e4d15fed443499e2a56e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/BhrR31ZMAN3AsR2uevYnch7Sl4edlTs2OsEbWGs1zGM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb2a10bb708b34c2908bd2bf4af45c67418e6425", "width": 1080, "height": 565}], "variants": {}, "id": "lF5NRpw2f-9zN7vCx5FWogja3x4KVzpShDhCeZxmUxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "VHS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": "moderator", "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "13kci86", "is_robot_indexable": true, "report_reasons": null, "author": "nicholasserra", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13kci86/megathread_google_inactive_accounts_purge/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/13kci86/megathread_google_inactive_accounts_purge/", "subreddit_subscribers": 683337, "created_utc": 1684353909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Well was about time until last week it would show unlimited in drive. That was even after the forced migrations and everything \n\n&amp;#x200B;\n\n1 user - no limit would be shown in GDrive.\n\n&amp;#x200B;\n\nJust recieved an email that I was over quota - being limited to 2TB now if I check my GDrive.\n\n&amp;#x200B;\n\n(had 3TB)\n\n&amp;#x200B;\n\nWell, good bye Google!", "author_fullname": "t2_5gi1u304", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google enforcing storage limit on old GSuite unlimited Accounts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kr75h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684393430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Well was about time until last week it would show unlimited in drive. That was even after the forced migrations and everything &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1 user - no limit would be shown in GDrive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just recieved an email that I was over quota - being limited to 2TB now if I check my GDrive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(had 3TB)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Well, good bye Google!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kr75h", "is_robot_indexable": true, "report_reasons": null, "author": "Goose-Difficult", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kr75h/google_enforcing_storage_limit_on_old_gsuite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kr75h/google_enforcing_storage_limit_on_old_gsuite/", "subreddit_subscribers": 683337, "created_utc": 1684393430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With google announcing their deletion wave, starting in December, everybody is paying attention to youtube content. This is important but I don't want to worry about tunnel vision. Are there risks of losing tech support comments, blogs, etc? What other things are endangered?", "author_fullname": "t2_uh5my0gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Besides youtube, what other google account-connected content is at risk of vanishing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kajpz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684349489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With google announcing their deletion wave, starting in December, everybody is paying attention to youtube content. This is important but I don&amp;#39;t want to worry about tunnel vision. Are there risks of losing tech support comments, blogs, etc? What other things are endangered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13kajpz", "is_robot_indexable": true, "report_reasons": null, "author": "Warriohuma", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kajpz/besides_youtube_what_other_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kajpz/besides_youtube_what_other_google/", "subreddit_subscribers": 683337, "created_utc": 1684349489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can the DataHoarder community help out? Either with backing it up or with technical knowledge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kyvm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_aa96f", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "CombatFootage", "selftext": "[removed]", "author_fullname": "t2_i3rjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This sub has great historical value - is there any backup or contingency plan in case reddit corporate purges these communities?", "link_flair_richtext": [{"e": "text", "t": "Question  (Text)"}], "subreddit_name_prefixed": "r/CombatFootage", "hidden": false, "pwls": null, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kvenz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2756, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question  (Text)", "can_mod_post": false, "score": 2756, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684407008.0, "link_flair_type": "richtext", "wls": null, "removed_by_category": "moderator", "banned_by": null, "author_flair_type": "text", "domain": "self.CombatFootage", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_69c94eb4-d6a3-48e7-9cf2-0f39fed8b87c", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=12f18f484af14d4a593c0eeca2ddf0104fcafbea", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=a86cd430c009186819c61a9f12cc6010529da93a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5acf096034215626ed92aba3219a3e02a5270013", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=8ae29304ad7bd8f005a2a6baf2268dc4e721f59a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d258ce2dd4a244a34f9a37bcf05ecc0a7dbd9e8f", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Listen, get educated, and get involved.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Ally", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=12f18f484af14d4a593c0eeca2ddf0104fcafbea", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=a86cd430c009186819c61a9f12cc6010529da93a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5acf096034215626ed92aba3219a3e02a5270013", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=8ae29304ad7bd8f005a2a6baf2268dc4e721f59a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d258ce2dd4a244a34f9a37bcf05ecc0a7dbd9e8f", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "d27d0b3a-7586-11ea-9f14-0ea8329ba511", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2v0c6", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#008b29", "id": "13kvenz", "is_robot_indexable": false, "report_reasons": null, "author": "Prophet_60091_", "discussion_type": null, "num_comments": 224, "send_replies": false, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/CombatFootage/comments/13kvenz/this_sub_has_great_historical_value_is_there_any/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/CombatFootage/comments/13kvenz/this_sub_has_great_historical_value_is_there_any/", "subreddit_subscribers": 1408267, "created_utc": 1684407008.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1684415598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.CombatFootage", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/CombatFootage/comments/13kvenz/this_sub_has_great_historical_value_is_there_any/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kyvm4", "is_robot_indexable": true, "report_reasons": null, "author": "GoodGuyLafarge", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13kvenz", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kyvm4/can_the_datahoarder_community_help_out_either/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/CombatFootage/comments/13kvenz/this_sub_has_great_historical_value_is_there_any/", "subreddit_subscribers": 683337, "created_utc": 1684415598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, this question, is not just about DataHoarding, but also about legal base of making materials available later.\n\nRight now I am supporting it, so there is no need to make it free for all, BUT everybody DIES and a lot of other stuff can happen any moment, so:\n\nI want that any code I release within certain project will become Public domain (or maybe be licensed under just free MIT attribution license) after 10 years from publication.\n\nSo is there licenses that already have such time conditions?\n\nOr how to properly formulate such conditions so, users can be sure that any code that is 10 years old is Public domain and he can do whatever he wants with it?\n\nI already tried to ask this question in r/legaladvice [what\\_is\\_best\\_way\\_to\\_release\\_something\\_in\\_public](https://www.reddit.com/r/legaladvice/comments/13ifs3y/what_is_best_way_to_release_something_in_public/), but with no luck.\n\nI'll be glad for any comments or advices, even if they may seem somewhat unrelated.", "author_fullname": "t2_qbksl235", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is best way to release something in Public domain (or make available under some free license like MIT) after 10 years starting from date of publication?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kf629", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684359980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, this question, is not just about DataHoarding, but also about legal base of making materials available later.&lt;/p&gt;\n\n&lt;p&gt;Right now I am supporting it, so there is no need to make it free for all, BUT everybody DIES and a lot of other stuff can happen any moment, so:&lt;/p&gt;\n\n&lt;p&gt;I want that any code I release within certain project will become Public domain (or maybe be licensed under just free MIT attribution license) after 10 years from publication.&lt;/p&gt;\n\n&lt;p&gt;So is there licenses that already have such time conditions?&lt;/p&gt;\n\n&lt;p&gt;Or how to properly formulate such conditions so, users can be sure that any code that is 10 years old is Public domain and he can do whatever he wants with it?&lt;/p&gt;\n\n&lt;p&gt;I already tried to ask this question in &lt;a href=\"/r/legaladvice\"&gt;r/legaladvice&lt;/a&gt; &lt;a href=\"https://www.reddit.com/r/legaladvice/comments/13ifs3y/what_is_best_way_to_release_something_in_public/\"&gt;what_is_best_way_to_release_something_in_public&lt;/a&gt;, but with no luck.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be glad for any comments or advices, even if they may seem somewhat unrelated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kf629", "is_robot_indexable": true, "report_reasons": null, "author": "atomknack", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kf629/what_is_best_way_to_release_something_in_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kf629/what_is_best_way_to_release_something_in_public/", "subreddit_subscribers": 683337, "created_utc": 1684359980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_6eu3gcyt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Costco DEAL - Samsung T7 SSD 2TB Touch (orig: $190; sale: $129)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4psxzb728g0b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e8c378d516aa2ec40d3a4f102339b5d4e5db730"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7dd537892bae8af23476a1de55f2a6c05e76b1c"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a60774494abe44106c82c413087e1f076bb566d9"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd1e4a3f4f1dde971fbc97177e4d756dd3cfe9bb"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc3923fcb016d91b0a84179d468f27691e9489c"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dacb6d762568b48c1ab0ec4021d729e15a4c2fc"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/4psxzb728g0b1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3e0f8ad7c078b8579ce2e900a9533ffa94f47538"}, "id": "4psxzb728g0b1"}, "iqh6lc728g0b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 174, "x": 108, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6168fb88ed2ddb640ead62ea6a8bf33ffa6c2c64"}, {"y": 348, "x": 216, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bb4437ad265ad0c74665e28382969e1babed029"}, {"y": 516, "x": 320, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ac729c7f456f44d7d21447b5af475a057b85681"}, {"y": 1032, "x": 640, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1780fc3aea739a349469819012c2502240b4cde5"}, {"y": 1548, "x": 960, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23a074868b9805fc5b049f2e0c6075da21214c93"}, {"y": 1742, "x": 1080, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec37562f062990fc70ef306c4fdc20716fc0c7b4"}], "s": {"y": 3520, "x": 2182, "u": "https://preview.redd.it/iqh6lc728g0b1.jpg?width=2182&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=13b39bdd8c7525dc8c4fc72a6cdbea1314495e76"}, "id": "iqh6lc728g0b1"}}, "name": "t3_13kclm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "4psxzb728g0b1", "id": 276400260}, {"media_id": "iqh6lc728g0b1", "id": 276400261}]}, "link_flair_text": "News", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K5qlwwJBwCkKdQa6YI9G2zuo3d_e0cmmnkhPSd0ssJM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684354124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13kclm2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kclm2", "is_robot_indexable": true, "report_reasons": null, "author": "pharm2tech", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kclm2/costco_deal_samsung_t7_ssd_2tb_touch_orig_190/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13kclm2", "subreddit_subscribers": 683337, "created_utc": 1684354124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nJust got the dreaded email for my Google Workspace Enterprise Standard account that I've been using for almost 3 years now with about 30TB in drive.\n\nI recently set up my NAS of 54TB so atleast I won't lose my data immediately and was using Google Drive as a cloud backup solution. I was paying $15/mo for this, incredible deal!\n\nI use rclone to encrypt my files and every week, it checks for any changes between my local &amp; backup and syncs the backup accordingly. \n\nMy question, is what do I move to now? Dropbox will cost about $72-75/mo and they can change their policy for unlimited storage similar to google at any time.  \nOr Hetzner server auction will cost me about $80/mo but I'll have more control over it, albeit still under Hetzner.\n\nBackblaze becomes too expensive at around $150/ mo ($5\\*30TB).  \nWhat are you switching too or already using for as a cloud backup that maybe i cheaper? Spending $80/mo on cloud storage for a backup just seems a lot :(", "author_fullname": "t2_cxhmpy2s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive alternative for cloud backup; 30TB +1TB/year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ksggt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684397711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Just got the dreaded email for my Google Workspace Enterprise Standard account that I&amp;#39;ve been using for almost 3 years now with about 30TB in drive.&lt;/p&gt;\n\n&lt;p&gt;I recently set up my NAS of 54TB so atleast I won&amp;#39;t lose my data immediately and was using Google Drive as a cloud backup solution. I was paying $15/mo for this, incredible deal!&lt;/p&gt;\n\n&lt;p&gt;I use rclone to encrypt my files and every week, it checks for any changes between my local &amp;amp; backup and syncs the backup accordingly. &lt;/p&gt;\n\n&lt;p&gt;My question, is what do I move to now? Dropbox will cost about $72-75/mo and they can change their policy for unlimited storage similar to google at any time.&lt;br/&gt;\nOr Hetzner server auction will cost me about $80/mo but I&amp;#39;ll have more control over it, albeit still under Hetzner.&lt;/p&gt;\n\n&lt;p&gt;Backblaze becomes too expensive at around $150/ mo ($5*30TB).&lt;br/&gt;\nWhat are you switching too or already using for as a cloud backup that maybe i cheaper? Spending $80/mo on cloud storage for a backup just seems a lot :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ksggt", "is_robot_indexable": true, "report_reasons": null, "author": "seriouslyfun95", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13ksggt/google_drive_alternative_for_cloud_backup_30tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ksggt/google_drive_alternative_for_cloud_backup_30tb/", "subreddit_subscribers": 683337, "created_utc": 1684397711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example when you add 5 Mb file to 50 Gb rar archive, there will be 50 Gb written to disk again. It's very slow and inefficient. Does all archive formats has this limitation?", "author_fullname": "t2_pkh7uvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to add file to an exisiting archive without fully overwriting it on disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kv4n8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684406227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example when you add 5 Mb file to 50 Gb rar archive, there will be 50 Gb written to disk again. It&amp;#39;s very slow and inefficient. Does all archive formats has this limitation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kv4n8", "is_robot_indexable": true, "report_reasons": null, "author": "Animus_777", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kv4n8/is_it_possible_to_add_file_to_an_exisiting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kv4n8/is_it_possible_to_add_file_to_an_exisiting/", "subreddit_subscribers": 683337, "created_utc": 1684406227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 20TB hard drive mounted on a a Sabrent Docking Station and it is connected to my outlet through a cheap surge protector. I am wondering if I need to use a better surge protector into the outlet, as sometimes I can feel \"humming\" electricity on my Macbook when its connected to the surge protector.", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a good surge protector necessary for internal hard drives mounted on a docking station?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kji7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 20TB hard drive mounted on a a Sabrent Docking Station and it is connected to my outlet through a cheap surge protector. I am wondering if I need to use a better surge protector into the outlet, as sometimes I can feel &amp;quot;humming&amp;quot; electricity on my Macbook when its connected to the surge protector.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kji7v", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kji7v/is_a_good_surge_protector_necessary_for_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kji7v/is_a_good_surge_protector_necessary_for_internal/", "subreddit_subscribers": 683337, "created_utc": 1684370547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey y'all! I have some questions about the best way to download and display Instagram posts. I'm trying to create Instagram content plans for specific accounts/influencers, sort of like a custom blog post with posts in their niche included and analyzed as examples. Currently I embed the posts on a notion page but notion embeds are a bit janky and I'd like to host these pages on my own site if possible. \n\n&amp;#x200B;\n\nMy viable options right now look like embedding, downloading the content (reels, photos, and ideally descriptions), or using the native instagram guide feature. They all have some issues. \n\n&amp;#x200B;\n\nIt seems like there's a lot of experts on downloading Instagram content on here, is assisted content downloading a real banning concern or is it mostly in extreme cases? I wouldn't be downloading more than 10-20 posts a day if that. Does anyone have experience using a python script or anything else to redisplay this content data in another program/site? \n\n&amp;#x200B;\n\nDownload content \n\n\\-Downloading programs can get account banned if used too much \n\n\\-Labor intensive compared to embedding (more actions required)\n\n\\-Hosting actual content can slow down site \n\n&amp;#x200B;\n\nEmbed: \n\n\\-Can break as instagram/hosting site updates \n\n\\-Asks to sign into instagram \n\n\\-Sometimes makes user view on instagram instead of on page \n\n\\-Users can delete posts or turn off embedding \n\n&amp;#x200B;\n\nInstagram Guide \n\n\\-Guides can't be private or shared with just one person, workarounds like having a separate private account for each client are too clunky \n\n\\-More labor intensive to duplicate between clients, have to do everything from scratch  \n\n\\-Seamlessly incorporates native Insta content", "author_fullname": "t2_12bbxegs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about downloading Instagram content and some alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjkh9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all! I have some questions about the best way to download and display Instagram posts. I&amp;#39;m trying to create Instagram content plans for specific accounts/influencers, sort of like a custom blog post with posts in their niche included and analyzed as examples. Currently I embed the posts on a notion page but notion embeds are a bit janky and I&amp;#39;d like to host these pages on my own site if possible. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My viable options right now look like embedding, downloading the content (reels, photos, and ideally descriptions), or using the native instagram guide feature. They all have some issues. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It seems like there&amp;#39;s a lot of experts on downloading Instagram content on here, is assisted content downloading a real banning concern or is it mostly in extreme cases? I wouldn&amp;#39;t be downloading more than 10-20 posts a day if that. Does anyone have experience using a python script or anything else to redisplay this content data in another program/site? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Download content &lt;/p&gt;\n\n&lt;p&gt;-Downloading programs can get account banned if used too much &lt;/p&gt;\n\n&lt;p&gt;-Labor intensive compared to embedding (more actions required)&lt;/p&gt;\n\n&lt;p&gt;-Hosting actual content can slow down site &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Embed: &lt;/p&gt;\n\n&lt;p&gt;-Can break as instagram/hosting site updates &lt;/p&gt;\n\n&lt;p&gt;-Asks to sign into instagram &lt;/p&gt;\n\n&lt;p&gt;-Sometimes makes user view on instagram instead of on page &lt;/p&gt;\n\n&lt;p&gt;-Users can delete posts or turn off embedding &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Instagram Guide &lt;/p&gt;\n\n&lt;p&gt;-Guides can&amp;#39;t be private or shared with just one person, workarounds like having a separate private account for each client are too clunky &lt;/p&gt;\n\n&lt;p&gt;-More labor intensive to duplicate between clients, have to do everything from scratch  &lt;/p&gt;\n\n&lt;p&gt;-Seamlessly incorporates native Insta content&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kjkh9", "is_robot_indexable": true, "report_reasons": null, "author": "ThePeefers", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjkh9/questions_about_downloading_instagram_content_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjkh9/questions_about_downloading_instagram_content_and/", "subreddit_subscribers": 683337, "created_utc": 1684370711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using traditional hdd's for my file storage. Currently, I only have 14TB split between  5 drives and have been thinking about creating my own dedicated file server.\n\nIs the new standard for file servers ssd based? Kinda looking for a solution for long-term storage, but I'm kind of lost. Would appreciate some help lol.", "author_fullname": "t2_16de20zp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Long term Storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjgwq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using traditional hdd&amp;#39;s for my file storage. Currently, I only have 14TB split between  5 drives and have been thinking about creating my own dedicated file server.&lt;/p&gt;\n\n&lt;p&gt;Is the new standard for file servers ssd based? Kinda looking for a solution for long-term storage, but I&amp;#39;m kind of lost. Would appreciate some help lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kjgwq", "is_robot_indexable": true, "report_reasons": null, "author": "HeartDessire", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjgwq/long_term_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjgwq/long_term_storage/", "subreddit_subscribers": 683337, "created_utc": 1684370453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks.  I am moving soon, and wish to bring some of my hard drives with me through the airport.  I have exactly 100 hard drives, and need to move them with me preferably the day of the move.  I took out my suitcase, and 45 drives will fit in there, making it 50-60 pounds.  I am allowed two carry ons (backpack + suitcase), and two (up to) 50 pound totes (cannot have a single 100 pound or 60/40, 70/30, etc.).  I do not trust putting the drives in the totes due to the possibility of them getting banged around in transportation, and I have also had some very valuable stuff stolen out of my totes when they go through SeaTac (Comic Books to be more exact).  This leaves me with either shipping them up via Large Flat Rate Boxes, or putting the remaining drives (26 3.5, the rest 2.5 inch) in my backpack, though these would need to fit under the seat in front of me, so I am skeptical that would work.\n\n&amp;#x200B;\n\nMy concern is how to move them up with me without getting banged around (even with padding).  All drives are in ESD Bags.  My second concern is whether or not I will have issues at Airport security.  I once went through FAI with around 200 bouncy balls (from my childhood), and that held us up for an hour and almost made us miss our flight because they took each ball and put them in it's own bin to scan individually.  Should I tell the person ahead of time that my suitcase is nothing but hard drives in ESD Bags?  Are they vulnerable to the XRay?  Will security think its weird that I am traveling with an entire suitcase full of Hard Drives and confiscate them?  I simply wish to know these things ahead of time so I am able to take the preventative steps to avoid any fiasco.\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_3zr5fswte", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airport Concern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kbgje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684351563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks.  I am moving soon, and wish to bring some of my hard drives with me through the airport.  I have exactly 100 hard drives, and need to move them with me preferably the day of the move.  I took out my suitcase, and 45 drives will fit in there, making it 50-60 pounds.  I am allowed two carry ons (backpack + suitcase), and two (up to) 50 pound totes (cannot have a single 100 pound or 60/40, 70/30, etc.).  I do not trust putting the drives in the totes due to the possibility of them getting banged around in transportation, and I have also had some very valuable stuff stolen out of my totes when they go through SeaTac (Comic Books to be more exact).  This leaves me with either shipping them up via Large Flat Rate Boxes, or putting the remaining drives (26 3.5, the rest 2.5 inch) in my backpack, though these would need to fit under the seat in front of me, so I am skeptical that would work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My concern is how to move them up with me without getting banged around (even with padding).  All drives are in ESD Bags.  My second concern is whether or not I will have issues at Airport security.  I once went through FAI with around 200 bouncy balls (from my childhood), and that held us up for an hour and almost made us miss our flight because they took each ball and put them in it&amp;#39;s own bin to scan individually.  Should I tell the person ahead of time that my suitcase is nothing but hard drives in ESD Bags?  Are they vulnerable to the XRay?  Will security think its weird that I am traveling with an entire suitcase full of Hard Drives and confiscate them?  I simply wish to know these things ahead of time so I am able to take the preventative steps to avoid any fiasco.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kbgje", "is_robot_indexable": true, "report_reasons": null, "author": "Wise-Bird2450", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kbgje/airport_concern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kbgje/airport_concern/", "subreddit_subscribers": 683337, "created_utc": 1684351563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of using rclone alongside IDrive e2, and was wondering if anyone here had any experience with it?\n\n**Question:**  Are you able to view (obviously non encrypted) media from the IDrive e2 website? For example, when you press on the bucket, then can you see the images and videos with their thumbnails? Or do things just appear as their file name with no picture. I want to be able to browse photos and stuff using the rclone browser GUI.\n\nAny thoughts/recommendations/warnings about IDrive e2? I was thinking of choosing it because of the cheap price and no egress charge.\n\nThanks!", "author_fullname": "t2_heaw12g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of IDrive e2?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l0yr4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684420866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of using rclone alongside IDrive e2, and was wondering if anyone here had any experience with it?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;  Are you able to view (obviously non encrypted) media from the IDrive e2 website? For example, when you press on the bucket, then can you see the images and videos with their thumbnails? Or do things just appear as their file name with no picture. I want to be able to browse photos and stuff using the rclone browser GUI.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts/recommendations/warnings about IDrive e2? I was thinking of choosing it because of the cheap price and no egress charge.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13l0yr4", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway52075", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13l0yr4/what_do_you_think_of_idrive_e2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13l0yr4/what_do_you_think_of_idrive_e2/", "subreddit_subscribers": 683337, "created_utc": 1684420866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there!For the longest time, I have wanted to get myself a NAS to be able to work more reliably with large amounts of media material on multiple devices (my main Windows workstation and my Macbook M1 pro 14\") and to archive larger projects for future use. I was originally planning on getting myself a Synology NAS, but after reading some concerns of the extensive proprietary hardware and limitations, and just the overall cost, I opted to build myself a NAS computer instead. Because of this, I also began considering making it quite powerful for multiple use-cases and to be reliable for the long-term.\n\nI have added different notes of use-cases, and would like to hear some opinions if this is optimal, if there are specs I should change, or if a pre-built NAS is a safer bet overall. I am prepared for the maintenance such a NAS would require, but believe that the benefits will outweigh it overall, and cause I love to troubleshoot a lot.\n\n**Main use-case:**\n\n* To archive and work with large amounts media material on different devices (Windows and MacOS). (Certain major projects will be backed up on external drives for safekeeping just in case)\n* Able to access remotely in case of remote work.\n* Able to share files and request files from clients.\n\nSecondary use-cases (Not necessary):\n\n* Host simple game servers (Minecraft, Project Zomboid, etc.)\n* Use as an office hub (Nextcloud, OnlyOffice, etc.)\n* Potential rendering station(?)\n\n&amp;#x200B;\n\n**These are the specs:**\n\n* Fractal Node 304\n* 2x Noctua NF-A9x14 HS-PWM\n* Noctua NF-A14 PWM\n* Noctua NH-D15S (?) or alternative from Noctua.\n* Gigabyte B550I AORUS PRO AX\n* Ryzen 7 5700G\n* 2x 32 GB DDR4-3600 ram\n* Corsair SFX SF750 PSU\n* TP-Link TX401 10 Gigabit PCI Express Network Adapter\n* Samsung 980 PRO SSD, 1TB\n* 4x Seagate Ironwolf 12 TB (for a total of 48 TB of storage without RAID)\n\nReasoning and wishes with these specs:\n\n* The Fractal Node 304 is a small case that would fit in my tiny office space and would fit in on of the Kallax shelf slots next to my desk.\n* The Ryzen 7 5700G offers an alright inbuilt GPU which will suffice for most productivity task, as I won't be doing anything graphically intensive, and can avoid the purchase of an separate GPU.\n* 64 GB ram might be overkill, but I would like to be on the safe side for the long-term and for it to be able to handle multiple tasks (such as constant file transferring and game server hosting).\n* Samsung 980 Pro SSD for the TrueNAS Core OS.\n* I decided to opt for the Ironwolf non-Pro disks as I've read that the Pro tend to be noisier and because the cost would be lower and more economical.\n* To setup a RAID6 configuration with the HDD's for redundancy.\n\nEdit: Simple corrections, formatting fixes and added the adapter for faster GBit networking.", "author_fullname": "t2_1rl7h47h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Planning my first NAS for media production, is this a good build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l23mx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684425039.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684423639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!For the longest time, I have wanted to get myself a NAS to be able to work more reliably with large amounts of media material on multiple devices (my main Windows workstation and my Macbook M1 pro 14&amp;quot;) and to archive larger projects for future use. I was originally planning on getting myself a Synology NAS, but after reading some concerns of the extensive proprietary hardware and limitations, and just the overall cost, I opted to build myself a NAS computer instead. Because of this, I also began considering making it quite powerful for multiple use-cases and to be reliable for the long-term.&lt;/p&gt;\n\n&lt;p&gt;I have added different notes of use-cases, and would like to hear some opinions if this is optimal, if there are specs I should change, or if a pre-built NAS is a safer bet overall. I am prepared for the maintenance such a NAS would require, but believe that the benefits will outweigh it overall, and cause I love to troubleshoot a lot.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Main use-case:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;To archive and work with large amounts media material on different devices (Windows and MacOS). (Certain major projects will be backed up on external drives for safekeeping just in case)&lt;/li&gt;\n&lt;li&gt;Able to access remotely in case of remote work.&lt;/li&gt;\n&lt;li&gt;Able to share files and request files from clients.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Secondary use-cases (Not necessary):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Host simple game servers (Minecraft, Project Zomboid, etc.)&lt;/li&gt;\n&lt;li&gt;Use as an office hub (Nextcloud, OnlyOffice, etc.)&lt;/li&gt;\n&lt;li&gt;Potential rendering station(?)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;These are the specs:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fractal Node 304&lt;/li&gt;\n&lt;li&gt;2x Noctua NF-A9x14 HS-PWM&lt;/li&gt;\n&lt;li&gt;Noctua NF-A14 PWM&lt;/li&gt;\n&lt;li&gt;Noctua NH-D15S (?) or alternative from Noctua.&lt;/li&gt;\n&lt;li&gt;Gigabyte B550I AORUS PRO AX&lt;/li&gt;\n&lt;li&gt;Ryzen 7 5700G&lt;/li&gt;\n&lt;li&gt;2x 32 GB DDR4-3600 ram&lt;/li&gt;\n&lt;li&gt;Corsair SFX SF750 PSU&lt;/li&gt;\n&lt;li&gt;TP-Link TX401 10 Gigabit PCI Express Network Adapter&lt;/li&gt;\n&lt;li&gt;Samsung 980 PRO SSD, 1TB&lt;/li&gt;\n&lt;li&gt;4x Seagate Ironwolf 12 TB (for a total of 48 TB of storage without RAID)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Reasoning and wishes with these specs:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The Fractal Node 304 is a small case that would fit in my tiny office space and would fit in on of the Kallax shelf slots next to my desk.&lt;/li&gt;\n&lt;li&gt;The Ryzen 7 5700G offers an alright inbuilt GPU which will suffice for most productivity task, as I won&amp;#39;t be doing anything graphically intensive, and can avoid the purchase of an separate GPU.&lt;/li&gt;\n&lt;li&gt;64 GB ram might be overkill, but I would like to be on the safe side for the long-term and for it to be able to handle multiple tasks (such as constant file transferring and game server hosting).&lt;/li&gt;\n&lt;li&gt;Samsung 980 Pro SSD for the TrueNAS Core OS.&lt;/li&gt;\n&lt;li&gt;I decided to opt for the Ironwolf non-Pro disks as I&amp;#39;ve read that the Pro tend to be noisier and because the cost would be lower and more economical.&lt;/li&gt;\n&lt;li&gt;To setup a RAID6 configuration with the HDD&amp;#39;s for redundancy.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Edit: Simple corrections, formatting fixes and added the adapter for faster GBit networking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13l23mx", "is_robot_indexable": true, "report_reasons": null, "author": "restalot", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13l23mx/planning_my_first_nas_for_media_production_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13l23mx/planning_my_first_nas_for_media_production_is/", "subreddit_subscribers": 683337, "created_utc": 1684423639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Greetings, cartoon hoarder here. As the title says. I need some help downloading from [france.tv](https://france.tv) and [npo3.nl](https://npo3.nl). I've tried it with yt-dlp but to no success, and also tried with IDM but it keeps giving me a http/1.1 403 forbidden error. The shows I'm trying to get are [this](https://www.france.tv/france-5/ernest-et-celestine) and [this](https://www.npo3.nl/woezel-pip/KN_1658875). Trying to find help for non-English sites is hard, so I hope I can finally get some help here. Thanks.", "author_fullname": "t2_16625pqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help downloading from france.tv and npo3.nl", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l1fwv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684422064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, cartoon hoarder here. As the title says. I need some help downloading from &lt;a href=\"https://france.tv\"&gt;france.tv&lt;/a&gt; and &lt;a href=\"https://npo3.nl\"&gt;npo3.nl&lt;/a&gt;. I&amp;#39;ve tried it with yt-dlp but to no success, and also tried with IDM but it keeps giving me a http/1.1 403 forbidden error. The shows I&amp;#39;m trying to get are &lt;a href=\"https://www.france.tv/france-5/ernest-et-celestine\"&gt;this&lt;/a&gt; and &lt;a href=\"https://www.npo3.nl/woezel-pip/KN_1658875\"&gt;this&lt;/a&gt;. Trying to find help for non-English sites is hard, so I hope I can finally get some help here. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?auto=webp&amp;v=enabled&amp;s=a61f1ce1969e23eaff4d2db816bf0bbe9f66663e", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a6de21343bb6e87eb3ea9f4971b8bf996001f52", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f4d89eb39d9635e6ee46190109ff9a8b0915a52", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80cb56d02a0dc28fddb84307eea2313e6bac25d1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c45113cb2bfaac1982d6a29b14b713ea72dd7d3", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=204cbee0c5e27b081eb5bbd480f63c9ff3f357a3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/g7kQbQgpmsnZ4p2Ih9ioEHOldr7e3ctcjawSTbMZiXM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1690f03a7345709c9382a1d4f1848cabf9df50d2", "width": 1080, "height": 567}], "variants": {}, "id": "to0TvSPMreVZ6awlrK8K4uHG6qFp3UG19hyOlIEk02Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13l1fwv", "is_robot_indexable": true, "report_reasons": null, "author": "aussiecuno", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13l1fwv/help_downloading_from_francetv_and_npo3nl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13l1fwv/help_downloading_from_francetv_and_npo3nl/", "subreddit_subscribers": 683337, "created_utc": 1684422064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NASA uses laser system to perform fastest data transfer ever in space | The laser-based system transferred 3.6 terabytes in six minutes, which is roughly equivalent to one million songs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13ksfb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_hswvjukr", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CIuoQpDQsr5ZjtjdzJEKz_ZeqDXCUL_Tqeh1PMcom8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "space", "selftext": "", "author_fullname": "t2_2uwit82z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NASA uses laser system to perform fastest data transfer ever in space | The laser-based system transferred 3.6 terabytes in six minutes, which is roughly equivalent to one million songs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/space", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13k1s6j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3362, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3362, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/CIuoQpDQsr5ZjtjdzJEKz_ZeqDXCUL_Tqeh1PMcom8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1684330122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interestingengineering.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://interestingengineering.com/innovation/nasa-uses-laser-system-to-perform-fastest-data-transfer-ever-in-space", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?auto=webp&amp;v=enabled&amp;s=bff6baa2b9f3ce4cceaa41256683bd4e4253cdcc", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e141770b1ca0ec3ca770aa281150a118e53d7901", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a114f17437c89f1d521dfefa32fe2f4ebb27730", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=987df446a16feeb11f9612e9cdb22f3371d0f49b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e378b795597acad9f159c60b22b417b93a5ef362", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bba123626971a4f51c1b06e6fb1dd340820c5c70", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2eca261c8360e6bed317905f69affdbe9cb28c0b", "width": 1080, "height": 607}], "variants": {}, "id": "jMXXyhaYDbbbiGPVPyAAEPe0cxfRHo_QQSbNgD5xTNk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh87", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13k1s6j", "is_robot_indexable": true, "report_reasons": null, "author": "chrisdh79", "discussion_type": null, "num_comments": 300, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/space/comments/13k1s6j/nasa_uses_laser_system_to_perform_fastest_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://interestingengineering.com/innovation/nasa-uses-laser-system-to-perform-fastest-data-transfer-ever-in-space", "subreddit_subscribers": 23278152, "created_utc": 1684330122.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1684397594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interestingengineering.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://interestingengineering.com/innovation/nasa-uses-laser-system-to-perform-fastest-data-transfer-ever-in-space", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?auto=webp&amp;v=enabled&amp;s=bff6baa2b9f3ce4cceaa41256683bd4e4253cdcc", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e141770b1ca0ec3ca770aa281150a118e53d7901", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a114f17437c89f1d521dfefa32fe2f4ebb27730", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=987df446a16feeb11f9612e9cdb22f3371d0f49b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e378b795597acad9f159c60b22b417b93a5ef362", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bba123626971a4f51c1b06e6fb1dd340820c5c70", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/VksGQ8_Ldg4eeJSDhi3RAhlN6EgcfEHxyOWGb2xKbGM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2eca261c8360e6bed317905f69affdbe9cb28c0b", "width": 1080, "height": 607}], "variants": {}, "id": "jMXXyhaYDbbbiGPVPyAAEPe0cxfRHo_QQSbNgD5xTNk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ksfb4", "is_robot_indexable": true, "report_reasons": null, "author": "tjwalkr3", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13k1s6j", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ksfb4/nasa_uses_laser_system_to_perform_fastest_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://interestingengineering.com/innovation/nasa-uses-laser-system-to-perform-fastest-data-transfer-ever-in-space", "subreddit_subscribers": 683337, "created_utc": 1684397594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have tried czkawka, antidupl, and visipics based on posts from this forum.\n\nHowever, none of these can detect these images which are *very certainly* downscaled thumbnails.\n\nThis is a folder that android phones make, and I was a dummy and copied both the thumbnails and the originals.  I now have thousands of thumbnail duplicates.  We're talking a 306x408 image vs an original at 2448x3246.   Maybe its a settings thing? but I haven't had much luck playing with the settings on these tools.", "author_fullname": "t2_p4eu0tpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Duplicate photo finder that works on downscaled images (thumbnails)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjwoq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684371619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tried czkawka, antidupl, and visipics based on posts from this forum.&lt;/p&gt;\n\n&lt;p&gt;However, none of these can detect these images which are &lt;em&gt;very certainly&lt;/em&gt; downscaled thumbnails.&lt;/p&gt;\n\n&lt;p&gt;This is a folder that android phones make, and I was a dummy and copied both the thumbnails and the originals.  I now have thousands of thumbnail duplicates.  We&amp;#39;re talking a 306x408 image vs an original at 2448x3246.   Maybe its a settings thing? but I haven&amp;#39;t had much luck playing with the settings on these tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13kjwoq", "is_robot_indexable": true, "report_reasons": null, "author": "pdxstolemyvan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kjwoq/duplicate_photo_finder_that_works_on_downscaled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kjwoq/duplicate_photo_finder_that_works_on_downscaled/", "subreddit_subscribers": 683337, "created_utc": 1684371619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have changed all of the filenames but not the contents of the files in my movie collection for Radarr.\n\n I am wondering the best method for copying the updated filenames to my backup HDD (my backup drive still has the old filenames but the same exact files) without actually recopying all that data (+/- 20TB)", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to copy updated filenames but not the actual files to backup drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kd3kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684355261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have changed all of the filenames but not the contents of the files in my movie collection for Radarr.&lt;/p&gt;\n\n&lt;p&gt;I am wondering the best method for copying the updated filenames to my backup HDD (my backup drive still has the old filenames but the same exact files) without actually recopying all that data (+/- 20TB)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kd3kr", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kd3kr/how_to_copy_updated_filenames_but_not_the_actual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kd3kr/how_to_copy_updated_filenames_but_not_the_actual/", "subreddit_subscribers": 683337, "created_utc": 1684355261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had/have an Onn brand flash drive from Walmart. The tip of it snapped off inside my computer, I extracted it with tweezers. I thought it was done for. I thought the connector snapped off of the motherboard or something. With all hope gone, I decided to take apart the rest of my flash drive, just to know the extent of the damage. And then I learned there are two kinds of flash drive.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe\n\nI thought I had the one on the right, but I actually have the one on the left. Inside my flash drive was nothing. Nothing but enough plastic to slide the UDP, where all the actual data is stored, in and out of the computer. My UDP is still intact. But it's come free of the USB connector. At about a millimeter thick, it can't stay in my computer on its own.\n\nHas this ever happened to you? Have you ever had a loose UDP and you needed a way to get the data off of it or make it compatible with a computer? What do I do here?", "author_fullname": "t2_129mom3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I salvage the data from my UDP flash drive? I thought it was broken, but now I don't think it is.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fg0j0oubsf0b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf546708b842ce35bd8253627f40c60211399c9d"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a5c8b27badae32d2420d8d45dd39c24e28d5c7d"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b06374e26e64a22bb0c4d25cff9f7adf995ec079"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88584f2e236c6e8cad15a70760576a4d306b390f"}], "s": {"y": 533, "x": 800, "u": "https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe"}, "id": "fg0j0oubsf0b1"}}, "name": "t3_13kaccl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WJFUXlO22f0p0bhiGRa1FVMdousGflAZVli-enCWNKc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684349031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had/have an Onn brand flash drive from Walmart. The tip of it snapped off inside my computer, I extracted it with tweezers. I thought it was done for. I thought the connector snapped off of the motherboard or something. With all hope gone, I decided to take apart the rest of my flash drive, just to know the extent of the damage. And then I learned there are two kinds of flash drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe\"&gt;https://preview.redd.it/fg0j0oubsf0b1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=366f7b5d9fb17c07f65af04e56185183187e2ebe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I thought I had the one on the right, but I actually have the one on the left. Inside my flash drive was nothing. Nothing but enough plastic to slide the UDP, where all the actual data is stored, in and out of the computer. My UDP is still intact. But it&amp;#39;s come free of the USB connector. At about a millimeter thick, it can&amp;#39;t stay in my computer on its own.&lt;/p&gt;\n\n&lt;p&gt;Has this ever happened to you? Have you ever had a loose UDP and you needed a way to get the data off of it or make it compatible with a computer? What do I do here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kaccl", "is_robot_indexable": true, "report_reasons": null, "author": "FrothySolutions", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kaccl/how_can_i_salvage_the_data_from_my_udp_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kaccl/how_can_i_salvage_the_data_from_my_udp_flash/", "subreddit_subscribers": 683337, "created_utc": 1684349031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 20 TB seagate internal hard drive I am accessing by using a hard drive enclosure. I have a Macbook and am trying to format the drive as Apple File System (APFS). I am wondering if there are benefits to partitioning if my only goal is to dump files on it? In other words, are there benefits from a recovery perspective if it failed one day? Thanks", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I am using a 20 TB hard drive just for storage, are there any benefits to partitioning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ka1q8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684348356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 20 TB seagate internal hard drive I am accessing by using a hard drive enclosure. I have a Macbook and am trying to format the drive as Apple File System (APFS). I am wondering if there are benefits to partitioning if my only goal is to dump files on it? In other words, are there benefits from a recovery perspective if it failed one day? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ka1q8", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ka1q8/if_i_am_using_a_20_tb_hard_drive_just_for_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ka1q8/if_i_am_using_a_20_tb_hard_drive_just_for_storage/", "subreddit_subscribers": 683337, "created_utc": 1684348356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am the type of person to over analyze everything. I can't help it, so I embrace it. But I'm hoping for some outside thoughts/perspectives.\n\nI've used both rclone and Syncovery and love both. I've contributed $ to both. I hope both stay in development. Both have their pros/cons. \n\nI use rclone on all my servers. I was using Syncovery on my Windows 10 daily driver to backup my 2 TB of data to Backblaze B2 using ZIP encryption. It's all photos and important documents. \n\nI've moved my daily driver from Windows 10 to Linux (Debian Bookworm + KDE Plasma).\n\nI can keep using Syncovery but am contemplating if I should move to rclone for backing up the data from my daily driver. \n\nI use encryption with both. With Syncovery there is a GUI that I can use, and it has built in job scheduler and email notification. With rclone I use cron + script I wrote that does the backing up and emailing (using mail).\n\nI only have \\~2 TB of data and it grows very slowly. I'll probably add 1-2 gigs a year.\n\nI'm just curious what others think.\n\nI really like/want ease of use/configuring, which Syncovery wins at, but rclone is so popular and also does a very good job once you create/configure the scripts.\n\nI've spent too much time thinking about this. I just need someone to tell me what to do. Heh.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me with my analysis paralysis for backing up my data (photos and documents): rclone + crypt vs. Syncovery + ZIP + encryption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kyl8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684414888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the type of person to over analyze everything. I can&amp;#39;t help it, so I embrace it. But I&amp;#39;m hoping for some outside thoughts/perspectives.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used both rclone and Syncovery and love both. I&amp;#39;ve contributed $ to both. I hope both stay in development. Both have their pros/cons. &lt;/p&gt;\n\n&lt;p&gt;I use rclone on all my servers. I was using Syncovery on my Windows 10 daily driver to backup my 2 TB of data to Backblaze B2 using ZIP encryption. It&amp;#39;s all photos and important documents. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved my daily driver from Windows 10 to Linux (Debian Bookworm + KDE Plasma).&lt;/p&gt;\n\n&lt;p&gt;I can keep using Syncovery but am contemplating if I should move to rclone for backing up the data from my daily driver. &lt;/p&gt;\n\n&lt;p&gt;I use encryption with both. With Syncovery there is a GUI that I can use, and it has built in job scheduler and email notification. With rclone I use cron + script I wrote that does the backing up and emailing (using mail).&lt;/p&gt;\n\n&lt;p&gt;I only have ~2 TB of data and it grows very slowly. I&amp;#39;ll probably add 1-2 gigs a year.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just curious what others think.&lt;/p&gt;\n\n&lt;p&gt;I really like/want ease of use/configuring, which Syncovery wins at, but rclone is so popular and also does a very good job once you create/configure the scripts.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve spent too much time thinking about this. I just need someone to tell me what to do. Heh.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13kyl8c", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13kyl8c/help_me_with_my_analysis_paralysis_for_backing_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13kyl8c/help_me_with_my_analysis_paralysis_for_backing_up/", "subreddit_subscribers": 683337, "created_utc": 1684414888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "To head off the inevitable \"RAID is not a backup\" comments, yes I am aware. This will be on a separate machine with different credentials and have read only access to the primary machine. In the short term it will be LAN only, long term it will be offsite connected via VPN. As far as I can tell ZFS's built in tools can do basically everything a backup program can and I'm wondering if I'm missing some critical feature.\n\n1. ZFS Snapshots are incremental so they don't take up much space, can be scripted to have a retention policy, and the snapshot directory can be hidden from non-root users (if the root gets compromised I'm assuming everything is fucked anyway).\n\n2. Since the source is ZFS anyway, I can do ZFS send / recieve or just use rsync on a cron job to handle automatic scheduling. Or it could be a manual process if this turns out to be an offline / cold backup \n\n4. Pools / datasets can be encrypted like a backup repository's encryption if required, but I don't care about that in this instance. It's an option if needed though.\n\n5. I guess ZFS doesn't have a pretty GUI or WebUI but that's not really necessary either. \n\n6. Built in RAID so you don't need a separate RAID / drive pooling mechanism to back sources larger than the individual backup drives.\n\n7. No fragile database / repository layouts. I've never had a ZFS snapshot fail to recover a file without ZFS complaining to hell and back about corrupted data. But I've had a few backup repositories bork itself and lose things silently.\n\nEdit : Yes, I test my backups. Luckily that's how I found out shit was being borked and I didn't have to find out the hard way.\n\n\nThe only thing I can think of is sub-disk level parity. Much like winrar's recovery record, you can add a small bit of extra data (say, 2%) to your backup to help against minor corruption. ZFS needs a whole disk's worth of capacity unless you do some funky stuff like partitioning a drive and RAID'ing that. Won't save you from an actual drive failure but would protect against bitrot or something along those lines.\n\nPAR2 should be able to handle it, except it's not in \"real time\" and currently there's no way to skip files that have a valid par2 file. So I'd be calculating every par2 file every time a backup runs.\n\nAnother small issue with ZFS in my case is I'm a lot more comfortable with a windows environment which doesn't support ZFS. If / when this becomes an offsite machine it will be running TrueNAS, but in the short term I don't have a dedicated linux / freebsd machine to run it off of.\n\nTechnically there's a ZFS port for windows, but the last I heard it BSOD'd people's machines left and right so that's not exactly an option. But I can get around windows compatibility fairly easily since my machines have Hyper-V, meaning I can pass physical disks larger than 2TB through and run the backup.\n\nAm I missing something?", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS vs Backup Programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ks9m2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684398570.0, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684397053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To head off the inevitable &amp;quot;RAID is not a backup&amp;quot; comments, yes I am aware. This will be on a separate machine with different credentials and have read only access to the primary machine. In the short term it will be LAN only, long term it will be offsite connected via VPN. As far as I can tell ZFS&amp;#39;s built in tools can do basically everything a backup program can and I&amp;#39;m wondering if I&amp;#39;m missing some critical feature.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;ZFS Snapshots are incremental so they don&amp;#39;t take up much space, can be scripted to have a retention policy, and the snapshot directory can be hidden from non-root users (if the root gets compromised I&amp;#39;m assuming everything is fucked anyway).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Since the source is ZFS anyway, I can do ZFS send / recieve or just use rsync on a cron job to handle automatic scheduling. Or it could be a manual process if this turns out to be an offline / cold backup &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Pools / datasets can be encrypted like a backup repository&amp;#39;s encryption if required, but I don&amp;#39;t care about that in this instance. It&amp;#39;s an option if needed though.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I guess ZFS doesn&amp;#39;t have a pretty GUI or WebUI but that&amp;#39;s not really necessary either. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Built in RAID so you don&amp;#39;t need a separate RAID / drive pooling mechanism to back sources larger than the individual backup drives.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;No fragile database / repository layouts. I&amp;#39;ve never had a ZFS snapshot fail to recover a file without ZFS complaining to hell and back about corrupted data. But I&amp;#39;ve had a few backup repositories bork itself and lose things silently.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Edit : Yes, I test my backups. Luckily that&amp;#39;s how I found out shit was being borked and I didn&amp;#39;t have to find out the hard way.&lt;/p&gt;\n\n&lt;p&gt;The only thing I can think of is sub-disk level parity. Much like winrar&amp;#39;s recovery record, you can add a small bit of extra data (say, 2%) to your backup to help against minor corruption. ZFS needs a whole disk&amp;#39;s worth of capacity unless you do some funky stuff like partitioning a drive and RAID&amp;#39;ing that. Won&amp;#39;t save you from an actual drive failure but would protect against bitrot or something along those lines.&lt;/p&gt;\n\n&lt;p&gt;PAR2 should be able to handle it, except it&amp;#39;s not in &amp;quot;real time&amp;quot; and currently there&amp;#39;s no way to skip files that have a valid par2 file. So I&amp;#39;d be calculating every par2 file every time a backup runs.&lt;/p&gt;\n\n&lt;p&gt;Another small issue with ZFS in my case is I&amp;#39;m a lot more comfortable with a windows environment which doesn&amp;#39;t support ZFS. If / when this becomes an offsite machine it will be running TrueNAS, but in the short term I don&amp;#39;t have a dedicated linux / freebsd machine to run it off of.&lt;/p&gt;\n\n&lt;p&gt;Technically there&amp;#39;s a ZFS port for windows, but the last I heard it BSOD&amp;#39;d people&amp;#39;s machines left and right so that&amp;#39;s not exactly an option. But I can get around windows compatibility fairly easily since my machines have Hyper-V, meaning I can pass physical disks larger than 2TB through and run the backup.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB / Hyper-V", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ks9m2", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13ks9m2/zfs_vs_backup_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ks9m2/zfs_vs_backup_programs/", "subreddit_subscribers": 683337, "created_utc": 1684397053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\n\nSetting up my first home storage server. And im looking for some advice.\n\n\nI have 4 18tb drives in 1 server. I want 2 of them to be mirrored and the other 2 to be pooled without striping.\n\n\nWhat would be the best setup for this software wise? Is this even possible? I have experience with linux/bash", "author_fullname": "t2_4mjy3g6kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 drives, 2 mirrored, 2 pooled?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ke144", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684357423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Setting up my first home storage server. And im looking for some advice.&lt;/p&gt;\n\n&lt;p&gt;I have 4 18tb drives in 1 server. I want 2 of them to be mirrored and the other 2 to be pooled without striping.&lt;/p&gt;\n\n&lt;p&gt;What would be the best setup for this software wise? Is this even possible? I have experience with linux/bash&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ke144", "is_robot_indexable": true, "report_reasons": null, "author": "LrrrRuler", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ke144/4_drives_2_mirrored_2_pooled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ke144/4_drives_2_mirrored_2_pooled/", "subreddit_subscribers": 683337, "created_utc": 1684357423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI've been looking around this and other reddit pages on best storage solutions for backing up my collection of game ROMs and PC game install files. However, I have some specific needs/questions that I could used guidance on:\n\n* I would like to be regularly copy game ROMs and install files to and from the storage solution with minimal risk of data loss or other technical issues; what storage medium would work for that? What would be the long-term consequences to the storage device? The goal is to keep a copy on the storage unit, and to copy from it to my main PC drive or other device for game play.\n* I would prefer an external storage solution to keep it separate from my PC, would that make sense given my use scenario or would the USB connection be a hindrance?\n* What process is best for copying individual or large sets or ROMs within the drive and to and from drives? My concern is that in the past I had read that simple Windows copy/paste functions were best for small, individual files but could cause date issues in aggregate. Is that the case with Windows 10 or am I safe to rely on basic copy/paste when adding files to my storage device or taking them off of it?\n* How often should I be ready to replace drives before data degradation becomes a risk, or is that not an issue in a realistic time frame with today's tech?\n\nMy storage needs aren't that large, about 2 TB for the foreseeable future. My budget is not super high, about $100-200. I have a basic understanding of archiving rules (3-2-1) and an understanding of storage tech (HDD vs SDD, etc) and get the sense that NAS might be the best option in the future, though I am unsure if I have the funds for that currently (though if I am wrong on that front I would be happy to pursue it instead should it meet my needs). Thank you for any advice!", "author_fullname": "t2_b3be2u61s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External storage options and process for game back ups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9t1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684347815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking around this and other reddit pages on best storage solutions for backing up my collection of game ROMs and PC game install files. However, I have some specific needs/questions that I could used guidance on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I would like to be regularly copy game ROMs and install files to and from the storage solution with minimal risk of data loss or other technical issues; what storage medium would work for that? What would be the long-term consequences to the storage device? The goal is to keep a copy on the storage unit, and to copy from it to my main PC drive or other device for game play.&lt;/li&gt;\n&lt;li&gt;I would prefer an external storage solution to keep it separate from my PC, would that make sense given my use scenario or would the USB connection be a hindrance?&lt;/li&gt;\n&lt;li&gt;What process is best for copying individual or large sets or ROMs within the drive and to and from drives? My concern is that in the past I had read that simple Windows copy/paste functions were best for small, individual files but could cause date issues in aggregate. Is that the case with Windows 10 or am I safe to rely on basic copy/paste when adding files to my storage device or taking them off of it?&lt;/li&gt;\n&lt;li&gt;How often should I be ready to replace drives before data degradation becomes a risk, or is that not an issue in a realistic time frame with today&amp;#39;s tech?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My storage needs aren&amp;#39;t that large, about 2 TB for the foreseeable future. My budget is not super high, about $100-200. I have a basic understanding of archiving rules (3-2-1) and an understanding of storage tech (HDD vs SDD, etc) and get the sense that NAS might be the best option in the future, though I am unsure if I have the funds for that currently (though if I am wrong on that front I would be happy to pursue it instead should it meet my needs). Thank you for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13k9t1l", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonComet0079", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13k9t1l/external_storage_options_and_process_for_game/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13k9t1l/external_storage_options_and_process_for_game/", "subreddit_subscribers": 683337, "created_utc": 1684347815.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}