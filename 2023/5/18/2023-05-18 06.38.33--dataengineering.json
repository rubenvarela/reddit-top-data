{"kind": "Listing", "data": {"after": "t3_13k56q9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came across some jobs that have the same descirption as DE but have different titles (exp ETL developper). I was wondering what are the rest of the possibilities.", "author_fullname": "t2_um2qwii8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the other names for data engineering jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jzt1u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684325101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across some jobs that have the same descirption as DE but have different titles (exp ETL developper). I was wondering what are the rest of the possibilities.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jzt1u", "is_robot_indexable": true, "report_reasons": null, "author": "NoChemical1223", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jzt1u/what_are_the_other_names_for_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jzt1u/what_are_the_other_names_for_data_engineering_jobs/", "subreddit_subscribers": 105992, "created_utc": 1684325101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Describe your experience &amp; position and tell us about something you learned the hard way. I'll go first...\n\nDE with 2 YOE. Background was non-technical. I design and implement pipelines to serve analytics.  \n\n\n**Story**: We believed a service provider (service desk and software maintenance) was fudging numbers in various ways to make their service look better than it was. We had access to their service desk ticket data, and the business logic behind whether or not a ticket met the service target / SLA.\n\nOur data analyst is almost done with his report for leadership on the matter. Asks me to add a calculated field to the materialized view that I provide him so he can finish up and send it out that day. I define a new CTE, left join it to the existing data, and define the new field. Briefly manually scroll through the new column and it looks good. Recreate the view and tell him to refresh on his end. He runs his calculation and starts finishing up his report.\n\nLater on, he hits me up on Teams with the dreaded \"something looks off\". Long story short, I did not de-duplicate the CTE I created, and the join resulted in some entries having many duplicate records, making his numbers inaccurate. Disaster averted thanks to him catching this.  \n\n\n**Lesson**: You need metadata capture and observability at every. single. step. in your pipelines, including the view layer.\n\nI could have caught this manually if I had taken 5 extra seconds, but it's just better engineering to implement CDC or trigger function + metadata table, then put together a little metadata &amp; lineage dashboard.  \n\nSo...what have you learned the hard way?", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What have you learned the hard way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9fvu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684346986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Describe your experience &amp;amp; position and tell us about something you learned the hard way. I&amp;#39;ll go first...&lt;/p&gt;\n\n&lt;p&gt;DE with 2 YOE. Background was non-technical. I design and implement pipelines to serve analytics.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Story&lt;/strong&gt;: We believed a service provider (service desk and software maintenance) was fudging numbers in various ways to make their service look better than it was. We had access to their service desk ticket data, and the business logic behind whether or not a ticket met the service target / SLA.&lt;/p&gt;\n\n&lt;p&gt;Our data analyst is almost done with his report for leadership on the matter. Asks me to add a calculated field to the materialized view that I provide him so he can finish up and send it out that day. I define a new CTE, left join it to the existing data, and define the new field. Briefly manually scroll through the new column and it looks good. Recreate the view and tell him to refresh on his end. He runs his calculation and starts finishing up his report.&lt;/p&gt;\n\n&lt;p&gt;Later on, he hits me up on Teams with the dreaded &amp;quot;something looks off&amp;quot;. Long story short, I did not de-duplicate the CTE I created, and the join resulted in some entries having many duplicate records, making his numbers inaccurate. Disaster averted thanks to him catching this.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Lesson&lt;/strong&gt;: You need metadata capture and observability at every. single. step. in your pipelines, including the view layer.&lt;/p&gt;\n\n&lt;p&gt;I could have caught this manually if I had taken 5 extra seconds, but it&amp;#39;s just better engineering to implement CDC or trigger function + metadata table, then put together a little metadata &amp;amp; lineage dashboard.  &lt;/p&gt;\n\n&lt;p&gt;So...what have you learned the hard way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k9fvu", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k9fvu/what_have_you_learned_the_hard_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k9fvu/what_have_you_learned_the_hard_way/", "subreddit_subscribers": 105992, "created_utc": 1684346986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering job market currently saturated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jx5k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684317119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jx5k6", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "subreddit_subscribers": 105992, "created_utc": 1684317119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Following up from my [last post](https://www.reddit.com/r/dataengineering/comments/135mhee/im_a_one_man_data_team_pretty_much_how_can_i_be/), I was able to talk to my boss and get a data warehouse (BigQuery) set up and rolling. Now, I am going to use Prefect to start orchestrating my Python files that perform ETL.\n\nThis is going to make life a lot easier!\n\nThere were a lot of great tips and advice in that thread so thank you.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Good Ending: I was Able to Secure a Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k2dqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684331523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Following up from my &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/135mhee/im_a_one_man_data_team_pretty_much_how_can_i_be/\"&gt;last post&lt;/a&gt;, I was able to talk to my boss and get a data warehouse (BigQuery) set up and rolling. Now, I am going to use Prefect to start orchestrating my Python files that perform ETL.&lt;/p&gt;\n\n&lt;p&gt;This is going to make life a lot easier!&lt;/p&gt;\n\n&lt;p&gt;There were a lot of great tips and advice in that thread so thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k2dqp", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k2dqp/the_good_ending_i_was_able_to_secure_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k2dqp/the_good_ending_i_was_able_to_secure_a_data/", "subreddit_subscribers": 105992, "created_utc": 1684331523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The Snowflake community is rife with information dumps on how to optimize expensive queries. We know because we combed through a ton of them. What we present here are three tactical ways in which we\u2019ve done this at [Toplyne](https://www.toplyne.io/).\n\n[https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01](https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01)  \n\n\nhashnode: [https://toplyne.hashnode.dev/cooking-with-snowflake](https://toplyne.hashnode.dev/cooking-with-snowflake)", "author_fullname": "t2_11mmk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cooking with Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k0u4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684327794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Snowflake community is rife with information dumps on how to optimize expensive queries. We know because we combed through a ton of them. What we present here are three tactical ways in which we\u2019ve done this at &lt;a href=\"https://www.toplyne.io/\"&gt;Toplyne&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01\"&gt;https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;hashnode: &lt;a href=\"https://toplyne.hashnode.dev/cooking-with-snowflake\"&gt;https://toplyne.hashnode.dev/cooking-with-snowflake&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?auto=webp&amp;v=enabled&amp;s=51be4efb76e306644bb1ac106ce7329c56cb85b1", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ed30cabb11f40a64afa20fba4137d94dd3e4caa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5a2b05b006fe97d319ba40b75c7a2fabedc85e0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b993ec3bda0ae5f64a8c916c91b303dcddc4e49e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7209521a9de64ba328aa9f3785879d8b9c34589", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21ea0c1e63c2454ac26dc3426e1f518a72189886", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abaa2e32064a30ff80aa0fc9a08a9a6001708d88", "width": 1080, "height": 607}], "variants": {}, "id": "mWF3LAbLbxtgk91lqNheYK4vTh9LkvNn5DurUSJd_v8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13k0u4u", "is_robot_indexable": true, "report_reasons": null, "author": "Pbd1194", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k0u4u/cooking_with_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k0u4u/cooking_with_snowflake/", "subreddit_subscribers": 105992, "created_utc": 1684327794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI am working on building an ELT warehouse using Databricks as the warehouse and dbt as the transformation tool . This is our first time implementing a DWH on Databricks. What are the things I should be watchful about ?. Is it required to use unity catalog for this implementation. Looking for your valuable expertise. Also, is databricks meant to be used as a DWH or it should be used only as a compute engine.", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinion on implementing a full data warehouse using Databricks as the warehouse and DBT as the transformation tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k34gq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684333180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am working on building an ELT warehouse using Databricks as the warehouse and dbt as the transformation tool . This is our first time implementing a DWH on Databricks. What are the things I should be watchful about ?. Is it required to use unity catalog for this implementation. Looking for your valuable expertise. Also, is databricks meant to be used as a DWH or it should be used only as a compute engine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13k34gq", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k34gq/opinion_on_implementing_a_full_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k34gq/opinion_on_implementing_a_full_data_warehouse/", "subreddit_subscribers": 105992, "created_utc": 1684333180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To all the Dagster experts out there. I am joining a team that is using Dagster which I have never used before. \nWhat is the best way to learn Dagster? I am planning on going through their quick start hello world project they have. \n\nThanks!", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a team using Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13khzgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684366619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all the Dagster experts out there. I am joining a team that is using Dagster which I have never used before. \nWhat is the best way to learn Dagster? I am planning on going through their quick start hello world project they have. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13khzgg", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13khzgg/joining_a_team_using_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13khzgg/joining_a_team_using_dagster/", "subreddit_subscribers": 105992, "created_utc": 1684366619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s obviously very easy to find DE jobs under DE titles, but for people who are interested in working in data-intensive software engineering instead, how can one differentiate data vs. non data swe roles on sites like linkedin, indeed, etc", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find data engineering jobs under software engineering titles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k9udf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684347903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s obviously very easy to find DE jobs under DE titles, but for people who are interested in working in data-intensive software engineering instead, how can one differentiate data vs. non data swe roles on sites like linkedin, indeed, etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13k9udf", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k9udf/how_to_find_data_engineering_jobs_under_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k9udf/how_to_find_data_engineering_jobs_under_software/", "subreddit_subscribers": 105992, "created_utc": 1684347903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company will soon be starting a new iteration of their data strategy journey. As many of you know, this will be a long process as we work out our data architecture, data governance, and integration strategies. As many of you ALSO know, management will almost certainly not be patient while we navigate these things and will want incremental (if not some near immediate) value out of our proposed solution.   \n\n\nMy question is, do any of you have tips on how to appease the stakeholders and show value without 1) losing focus on the main goal and 2) incurring an obscene amount of technical debt along the way?", "author_fullname": "t2_33b8fuxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips on how to navigate the inevitable, \"But we want value now\" pressure from management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k62dg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684339619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company will soon be starting a new iteration of their data strategy journey. As many of you know, this will be a long process as we work out our data architecture, data governance, and integration strategies. As many of you ALSO know, management will almost certainly not be patient while we navigate these things and will want incremental (if not some near immediate) value out of our proposed solution.   &lt;/p&gt;\n\n&lt;p&gt;My question is, do any of you have tips on how to appease the stakeholders and show value without 1) losing focus on the main goal and 2) incurring an obscene amount of technical debt along the way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k62dg", "is_robot_indexable": true, "report_reasons": null, "author": "FawkesFoundation", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k62dg/any_tips_on_how_to_navigate_the_inevitable_but_we/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k62dg/any_tips_on_how_to_navigate_the_inevitable_but_we/", "subreddit_subscribers": 105992, "created_utc": 1684339619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m guessing it\u2019s along the lines of\n\n1. add constraints do pk/fk\n\n&amp;\n\n2. find open source erd generator \n\n\nI have read a few blogs but do not speak directly to dbt projects fueling the creation and/or are not free?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a good way of developing an ERD based off a dbt project; programmatically/automated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k4yu2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684337244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m guessing it\u2019s along the lines of&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;add constraints do pk/fk&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;amp;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;find open source erd generator &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I have read a few blogs but do not speak directly to dbt projects fueling the creation and/or are not free?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13k4yu2", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k4yu2/anyone_have_a_good_way_of_developing_an_erd_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k4yu2/anyone_have_a_good_way_of_developing_an_erd_based/", "subreddit_subscribers": 105992, "created_utc": 1684337244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Gpu, cuda (rapids.ai of nvidia) and vectorization (velox of meta) are something I am really interested in. But I am not sure if those are relevant to DE or MLE.", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are CUDA/GPU programming skills sought after among MLE or DE employers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k3pbl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684334503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gpu, cuda (rapids.ai of nvidia) and vectorization (velox of meta) are something I am really interested in. But I am not sure if those are relevant to DE or MLE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13k3pbl", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k3pbl/are_cudagpu_programming_skills_sought_after_among/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k3pbl/are_cudagpu_programming_skills_sought_after_among/", "subreddit_subscribers": 105992, "created_utc": 1684334503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gej5riou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All you need is data and functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jtjso", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684304683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mckayla.blog", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jtjso", "is_robot_indexable": true, "report_reasons": null, "author": "gemconbet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jtjso/all_you_need_is_data_and_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "subreddit_subscribers": 105992, "created_utc": 1684304683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems the biggest setback to expanding usage of data at my company is data silos that exist simply because people are not aware of what is available and so they recreate it in another location with a different naming convention. Are there any tools that give people a standard library of locations/queries they can use to find specific information?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys deal with data silos and lack of data awareness at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kih8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684367896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems the biggest setback to expanding usage of data at my company is data silos that exist simply because people are not aware of what is available and so they recreate it in another location with a different naming convention. Are there any tools that give people a standard library of locations/queries they can use to find specific information?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kih8h", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kih8h/how_do_you_guys_deal_with_data_silos_and_lack_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kih8h/how_do_you_guys_deal_with_data_silos_and_lack_of/", "subreddit_subscribers": 105992, "created_utc": 1684367896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When it comes to storing clickstream events in any warehouse or say hive external tables or the likes, what is the approach you are following? Single table for all clickstream events. OR one table per event.\n\nWhat does the community think of its pros and cons?", "author_fullname": "t2_e5czp0ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single table vs multiple table for clickstream events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jxsq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684319223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When it comes to storing clickstream events in any warehouse or say hive external tables or the likes, what is the approach you are following? Single table for all clickstream events. OR one table per event.&lt;/p&gt;\n\n&lt;p&gt;What does the community think of its pros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jxsq0", "is_robot_indexable": true, "report_reasons": null, "author": "jaisukku", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jxsq0/single_table_vs_multiple_table_for_clickstream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jxsq0/single_table_vs_multiple_table_for_clickstream/", "subreddit_subscribers": 105992, "created_utc": 1684319223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks - dropping by with some information on an upcoming Community-led webinar that may be of interest to you. Next week, on **May 23 at 11 AM PT, Ella Runciman (data engineer @ 1Password) will be hosting a webinar for The OA Club on best practices are 3rd party data enrichment**. \n\n*Disclaimer: I work for the company who pays the bills on The OA Club, but Ella is not employed by us and this webinar is not about our product. No sales folks will contact you because you registered.*    \n\n\nShe'll be covering: \n\n* An overview of data enrichment\n* The types of data enrichment\n* How data enrichment has evolved over the years (and its business value)\n* Hands-on examples of how to implement data enrichment in your organization   \n\n\nIf you're interested, you can RSVP [here](https://hubs.la/Q01QfD6t0).", "author_fullname": "t2_bxqhxdv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Webinar] Data Enrichment - How to create and utilize 3rd party data in your data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k8q64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684345396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks - dropping by with some information on an upcoming Community-led webinar that may be of interest to you. Next week, on &lt;strong&gt;May 23 at 11 AM PT, Ella Runciman (data engineer @ 1Password) will be hosting a webinar for The OA Club on best practices are 3rd party data enrichment&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Disclaimer: I work for the company who pays the bills on The OA Club, but Ella is not employed by us and this webinar is not about our product. No sales folks will contact you because you registered.&lt;/em&gt;    &lt;/p&gt;\n\n&lt;p&gt;She&amp;#39;ll be covering: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An overview of data enrichment&lt;/li&gt;\n&lt;li&gt;The types of data enrichment&lt;/li&gt;\n&lt;li&gt;How data enrichment has evolved over the years (and its business value)&lt;/li&gt;\n&lt;li&gt;Hands-on examples of how to implement data enrichment in your organization&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, you can RSVP &lt;a href=\"https://hubs.la/Q01QfD6t0\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?auto=webp&amp;v=enabled&amp;s=ff77a7ca78366999356715449640e3cf43575f7a", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02e09782c2615730f0dbff0342b929e14e9adaa5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c577e02eb2c2d1ae1284bc82eb6e835333be0bd5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=306c2379070f538c5831074c4a05332e60686f81", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9506993d67699fac3b0c17f9ccdd252c40b43aa7", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a45254c519e1d8aef113136e48d605ef0e65892", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/sSr1LYPS8NsqoUBhQBGbYXPB6MwCPtoROByCfIzZnO4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad474a257dee7d744fe2b93fbd0672d36f50a4d8", "width": 1080, "height": 565}], "variants": {}, "id": "Te6WuNcXcZV9ln1yMDvGLXXHj_JaM-Cp7bcwaH8BUWg"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "award_43c43a35-15c5-4f73-91ef-fe538426435a", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=86ea90c91e68c8416d6535a03a0de560844da977", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=80e4a5323c68ea1f3a927f679f921fd66f198958", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e895b89e2b8384d6cfd3a0545b8c48025065103d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=ef1c7b73aa1d536a2aaeda16ab3134119ca5bb9d", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=b55a46a50135f11519922e4fb2ee9b6d04918b34", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Prayers up for the blessed. Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Bless Up (Pro)", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=86ea90c91e68c8416d6535a03a0de560844da977", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=80e4a5323c68ea1f3a927f679f921fd66f198958", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e895b89e2b8384d6cfd3a0545b8c48025065103d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=ef1c7b73aa1d536a2aaeda16ab3134119ca5bb9d", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=b55a46a50135f11519922e4fb2ee9b6d04918b34", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k8q64", "is_robot_indexable": true, "report_reasons": null, "author": "alliewritestech", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k8q64/webinar_data_enrichment_how_to_create_and_utilize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k8q64/webinar_data_enrichment_how_to_create_and_utilize/", "subreddit_subscribers": 105992, "created_utc": 1684345396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Also anyone develop in a Docker container?", "author_fullname": "t2_h2t9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your dev environment set up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kngt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684382230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684381336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Also anyone develop in a Docker container?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kngt8", "is_robot_indexable": true, "report_reasons": null, "author": "jackielarson", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kngt8/whats_your_dev_environment_set_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kngt8/whats_your_dev_environment_set_up/", "subreddit_subscribers": 105992, "created_utc": 1684381336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any tool I would give input data (database, parquet, whatever) to and it would insert it into the target relational database while handling all the logic such as upserts, primary key lookups, udpdates of children tables (e. g. M:N relationships tables) etc? Or do I really have to write my own giant custom ETL framework to solve this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool with automatic merge logic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k705a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684341620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any tool I would give input data (database, parquet, whatever) to and it would insert it into the target relational database while handling all the logic such as upserts, primary key lookups, udpdates of children tables (e. g. M:N relationships tables) etc? Or do I really have to write my own giant custom ETL framework to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k705a", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k705a/etl_tool_with_automatic_merge_logic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k705a/etl_tool_with_automatic_merge_logic/", "subreddit_subscribers": 105992, "created_utc": 1684341620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,  \nfor a few years, we have been using Redash as our internal SQL-based data analysis and dashboards. But since it has not been maintained for some time, we are looking for a replacement.  \n\n\nWhich tools do you use and do you have some recommendations?  \nPreferably open source but any recommendation will be great.", "author_fullname": "t2_yu7cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a great replacement for Redash?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k0tfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684327742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nfor a few years, we have been using Redash as our internal SQL-based data analysis and dashboards. But since it has not been maintained for some time, we are looking for a replacement.  &lt;/p&gt;\n\n&lt;p&gt;Which tools do you use and do you have some recommendations?&lt;br/&gt;\nPreferably open source but any recommendation will be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k0tfn", "is_robot_indexable": true, "report_reasons": null, "author": "UserPobro", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k0tfn/what_would_be_a_great_replacement_for_redash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k0tfn/what_would_be_a_great_replacement_for_redash/", "subreddit_subscribers": 105992, "created_utc": 1684327742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using this tool to manage their data pipelines? Pros and Cons? I love how it templates a lot of your code to help keep standards within your team.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MageAI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13kpkn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684387922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using this tool to manage their data pipelines? Pros and Cons? I love how it templates a lot of your code to help keep standards within your team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13kpkn2", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kpkn2/mageai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kpkn2/mageai/", "subreddit_subscribers": 105992, "created_utc": 1684387922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m sorry if this isn\u2019t posted the right way or in the right sub, please delete and direct me to the correct one.\n\nThe team uses dbt and supports pipelines in place for Epic Clarity  and patient level (hospital line items). Hiring manager has mentioned he feels I have a strong background and would like to place me in one of the open DE roles on his team (1 DE now, and then a Sr. DE, and DE opening soon). \n\nWhat are some solid questions to ask the team about workflow and expectations that would let me get a good idea of what my role would be expected to produce? I\u2019m currently a Business Analyst working with sql &amp; Tableau, background in healthcare analytics (basically a data analytics and relational database management focused program)", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meeting members of the hiring team tomorrow during 3rd round interview for healthcare DE Operations role looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kj9y1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684369940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m sorry if this isn\u2019t posted the right way or in the right sub, please delete and direct me to the correct one.&lt;/p&gt;\n\n&lt;p&gt;The team uses dbt and supports pipelines in place for Epic Clarity  and patient level (hospital line items). Hiring manager has mentioned he feels I have a strong background and would like to place me in one of the open DE roles on his team (1 DE now, and then a Sr. DE, and DE opening soon). &lt;/p&gt;\n\n&lt;p&gt;What are some solid questions to ask the team about workflow and expectations that would let me get a good idea of what my role would be expected to produce? I\u2019m currently a Business Analyst working with sql &amp;amp; Tableau, background in healthcare analytics (basically a data analytics and relational database management focused program)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13kj9y1", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kj9y1/meeting_members_of_the_hiring_team_tomorrow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kj9y1/meeting_members_of_the_hiring_team_tomorrow/", "subreddit_subscribers": 105992, "created_utc": 1684369940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hoping someone can help me make sure I'm not missing something.\n\n1. Ive got a series of python scripts that hit one our internal systems for data.\n\n2.  The api has a last modified property so each call, I store the datetime at the start of the job and the next run will pass that datetime as a parameter so the api only returns rows that have changed.\n\n3. For simplicity, I'm going to use github cicd to run the jobs every few hours.\n\nSo far so good however, as our stack may shift in the future and what I understand as general best practise, my initial plan was to write the api results to a csv or parquet file in azure blob storage with standard file name conventions. Then subsequently load these csv files into our warehouse (azure postgres). In my head, this means any schema drift, postgres issues etc don't break the actual data extract and everything becomes more modular = better...\n\nHaving been doing some databricks training recently, I think I had just assumed there would be a relatively simple solution like autoloader, which could watch the blob store and upon seeing a new file, load that into postgres but I think that was wishful thinking.\n\nIs there a good solution to do that or is it just going to be easier to write the api results direct into the postgres database? Is this one of the reasons you might pick something like Databricks over postgres for instance? \n\nFor reference, I'm planning on throwing dbt core over the top of postgres.\n\n-edit grammer", "author_fullname": "t2_t12o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python API extract to blob or Postgresql direct?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k7qhx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684343203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping someone can help me make sure I&amp;#39;m not missing something.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Ive got a series of python scripts that hit one our internal systems for data.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The api has a last modified property so each call, I store the datetime at the start of the job and the next run will pass that datetime as a parameter so the api only returns rows that have changed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;For simplicity, I&amp;#39;m going to use github cicd to run the jobs every few hours.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So far so good however, as our stack may shift in the future and what I understand as general best practise, my initial plan was to write the api results to a csv or parquet file in azure blob storage with standard file name conventions. Then subsequently load these csv files into our warehouse (azure postgres). In my head, this means any schema drift, postgres issues etc don&amp;#39;t break the actual data extract and everything becomes more modular = better...&lt;/p&gt;\n\n&lt;p&gt;Having been doing some databricks training recently, I think I had just assumed there would be a relatively simple solution like autoloader, which could watch the blob store and upon seeing a new file, load that into postgres but I think that was wishful thinking.&lt;/p&gt;\n\n&lt;p&gt;Is there a good solution to do that or is it just going to be easier to write the api results direct into the postgres database? Is this one of the reasons you might pick something like Databricks over postgres for instance? &lt;/p&gt;\n\n&lt;p&gt;For reference, I&amp;#39;m planning on throwing dbt core over the top of postgres.&lt;/p&gt;\n\n&lt;p&gt;-edit grammer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13k7qhx", "is_robot_indexable": true, "report_reasons": null, "author": "KingslyLear", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k7qhx/python_api_extract_to_blob_or_postgresql_direct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k7qhx/python_api_extract_to_blob_or_postgresql_direct/", "subreddit_subscribers": 105992, "created_utc": 1684343203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change Data Capture (CDC) for MongoDB with Debezium and Memphis.dev", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13k2hor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OGsl38heyjGzyy5gjSZlm5tCPO2uYAfuvnHu2yCqBbw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684331770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/memphis-dev/part-2-change-data-capture-cdc-for-mongodb-with-debezium-and-memphis-dev-b7aa1ed81a2c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?auto=webp&amp;v=enabled&amp;s=90372060be29c202938b1ed77bc2bb8589af14a1", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b17942fc3de8c97449711c40d335e1f3d1409f4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=442287e7c58525d1b87c9e85e799bf12556673b6", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aab772eb0ee1de7815aee4d882fb2a0a077da284", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56e86f21954bcd88c6bf28eba26cfb217a3f5e63", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=990eeccd85dbb9853b8788d8e4525d95211a3b4d", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/RI9WrmTq-83C7DOAIUa5Odtg8wlXR_aH3L-yy-O6YNE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0154fa2cf44e982e3e4c0192ac7efcfccbf1a132", "width": 1080, "height": 607}], "variants": {}, "id": "BAK38xkS16JLHUHa4pcZfmYDCfxZQtTfoid04itzh2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13k2hor", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k2hor/change_data_capture_cdc_for_mongodb_with_debezium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/memphis-dev/part-2-change-data-capture-cdc-for-mongodb-with-debezium-and-memphis-dev-b7aa1ed81a2c", "subreddit_subscribers": 105992, "created_utc": 1684331770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fbliz6iq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Odigos v0.1.5 - Managing OpenTelemetry using Kubernetes labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_13jxj4t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OjxmyylSJgKp_eD5b5u0T_N3oeyhvHV4E_zBc_uElWA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684318355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "keyval.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://keyval.dev/labels-support/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?auto=webp&amp;v=enabled&amp;s=b1d5de80ff3a04af7d94fa29a3516ded6a998837", "width": 738, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94c162a2de48c4b1592001f3a45f152e43c072ae", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fe5e5c1af29c946c85905c915eac85c564cf064", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49ec4e18c60620c1babef719f3af7c4fab5852a0", "width": 320, "height": 272}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd66c84c4bb9af2336479b1873cdee8944e000ff", "width": 640, "height": 544}], "variants": {}, "id": "X7VuIcpdDWamVcOA5XBSIKHnF-pkmVMowxsUlaKf8ts"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jxj4t", "is_robot_indexable": true, "report_reasons": null, "author": "Barakikia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jxj4t/odigos_v015_managing_opentelemetry_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://keyval.dev/labels-support/", "subreddit_subscribers": 105992, "created_utc": 1684318355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've always tackled learning new things by diving right in. With the stupid amount of new AI models, database types and options for interacting I can't help but feel like a kid in a candy store. \n\nI'm interested in The practicality of varying sources for purchasing ingredients, but first I need to get an idea of what pricing looks like over time, where, when and why lettuce is more expensive, referencing fuel prices and how they correlate, hell even looking at cartel violence and how it relates to avocados \ud83e\udd51. It's a butterfly effect that can actually be seen if you look at the right things at the same time.\n\nAny ideas? I've searched a lot but I'm getting a feeling that a lot of this stuff is kept close to the chest.", "author_fullname": "t2_2m8zmg33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data newb looking for example or real data from restaurants that show purchasing history from suppliers like SYSCO and other food providers over at least a couple of years.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13kjdpy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684370222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve always tackled learning new things by diving right in. With the stupid amount of new AI models, database types and options for interacting I can&amp;#39;t help but feel like a kid in a candy store. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in The practicality of varying sources for purchasing ingredients, but first I need to get an idea of what pricing looks like over time, where, when and why lettuce is more expensive, referencing fuel prices and how they correlate, hell even looking at cartel violence and how it relates to avocados \ud83e\udd51. It&amp;#39;s a butterfly effect that can actually be seen if you look at the right things at the same time.&lt;/p&gt;\n\n&lt;p&gt;Any ideas? I&amp;#39;ve searched a lot but I&amp;#39;m getting a feeling that a lot of this stuff is kept close to the chest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13kjdpy", "is_robot_indexable": true, "report_reasons": null, "author": "hellorobby", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13kjdpy/data_newb_looking_for_example_or_real_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13kjdpy/data_newb_looking_for_example_or_real_data_from/", "subreddit_subscribers": 105992, "created_utc": 1684370222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone please explain how to run benthos in Airflow? I can't find any guides online", "author_fullname": "t2_tthpf8ar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benthos in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13k56q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684337724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone please explain how to run benthos in Airflow? I can&amp;#39;t find any guides online&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13k56q9", "is_robot_indexable": true, "report_reasons": null, "author": "According_Aide_489", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k56q9/benthos_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k56q9/benthos_in_airflow/", "subreddit_subscribers": 105992, "created_utc": 1684337724.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}