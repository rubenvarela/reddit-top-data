{"kind": "Listing", "data": {"after": "t3_13whu1n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, today i've had a last round interview with my (hopefully) future manager. The job is a data science internship in a bank. The question was as follows:\n\n\"Let's say you have 250 variables which you can use to construct a model. However, you will have to explain why you chose these variables to your colleague, who is going to decide whether it goes into production or not. How many do you keep?\"\n\nAnd that's it! Nothing on the context, data, nature of the problem or even the aformentioned colleague. I believe it wasn't a question regarding my knowledge on data pre-processing and feature selection, because we have discussed these pretty intensively in the questions before. Nevertheless, I told him about these once more and said that it varies from case to case. In the end, he still asked for an estimate, so I said \"50 maximum, 20-25 optimally\", and argued that a model with more variables would probably be tough to interpret and that explaining that many to my colleague would probably take way too long.\n\nOverall, I've got a feeling I did pretty well in the interview. This question is the only thing I'm uncertain of. From what I heard and saw, this wasn't meant to reveal my way of thinking etc. He simply wanted to know the estimated value.\n\nWhat do you guys think was the purpose of this?\n\nWhat's the correct answer?\n\nDo you think I replied well?\n\nEDIT: I can see some of you say it was about data preprocessing/feature selection/dimensionality reduction. I'm no expert in ds interviews, but as i mentioned \nearlier I've already told him what i know about these topics. It seems weird to ask someone the same thing twice.", "author_fullname": "t2_25ix3tty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unusual interview question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vtrp8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 142, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 142, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685481356.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685461495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, today i&amp;#39;ve had a last round interview with my (hopefully) future manager. The job is a data science internship in a bank. The question was as follows:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Let&amp;#39;s say you have 250 variables which you can use to construct a model. However, you will have to explain why you chose these variables to your colleague, who is going to decide whether it goes into production or not. How many do you keep?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;And that&amp;#39;s it! Nothing on the context, data, nature of the problem or even the aformentioned colleague. I believe it wasn&amp;#39;t a question regarding my knowledge on data pre-processing and feature selection, because we have discussed these pretty intensively in the questions before. Nevertheless, I told him about these once more and said that it varies from case to case. In the end, he still asked for an estimate, so I said &amp;quot;50 maximum, 20-25 optimally&amp;quot;, and argued that a model with more variables would probably be tough to interpret and that explaining that many to my colleague would probably take way too long.&lt;/p&gt;\n\n&lt;p&gt;Overall, I&amp;#39;ve got a feeling I did pretty well in the interview. This question is the only thing I&amp;#39;m uncertain of. From what I heard and saw, this wasn&amp;#39;t meant to reveal my way of thinking etc. He simply wanted to know the estimated value.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think was the purpose of this?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the correct answer?&lt;/p&gt;\n\n&lt;p&gt;Do you think I replied well?&lt;/p&gt;\n\n&lt;p&gt;EDIT: I can see some of you say it was about data preprocessing/feature selection/dimensionality reduction. I&amp;#39;m no expert in ds interviews, but as i mentioned \nearlier I&amp;#39;ve already told him what i know about these topics. It seems weird to ask someone the same thing twice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vtrp8", "is_robot_indexable": true, "report_reasons": null, "author": "Woznyyyy", "discussion_type": null, "num_comments": 129, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vtrp8/unusual_interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vtrp8/unusual_interview_question/", "subreddit_subscribers": 913975, "created_utc": 1685461495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started working at a small analytics company, they haven't had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don't know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.", "author_fullname": "t2_3739kucg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would one write a data ETL pipeline in Javascript + SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w4yfp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685487592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working at a small analytics company, they haven&amp;#39;t had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don&amp;#39;t know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w4yfp", "is_robot_indexable": true, "report_reasons": null, "author": "Brown-Chemist99", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "subreddit_subscribers": 913975, "created_utc": 1685487592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm fairly new to working with this type of problem and am hoping to get some advice beyond what I was able to find from searching online.  I'm modeling on a large dataset using random forest. I get strong evaluation scores (R-squared of \\~0.85) on a preliminary run on the training set with no hyperparameter tuning, however, when I introduce cross-validation and hyperparameter tuning, I end up with something like 0.20 for my best model. \n\nMy guess is that this indicates overfitting, but are there any other issues that I may be concerned with? My understanding is that overfitting is much less common in random forest models-- with my dataset being pretty large, would this just indicate that the data are highly noisy? Is there a 'best approach' to assessing/solving this issue?\n\nThanks in advance for any advice more experienced members are able to give.", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High scoring training set, but low scoring with cross-validation. Is this from overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrlbs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685456341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new to working with this type of problem and am hoping to get some advice beyond what I was able to find from searching online.  I&amp;#39;m modeling on a large dataset using random forest. I get strong evaluation scores (R-squared of ~0.85) on a preliminary run on the training set with no hyperparameter tuning, however, when I introduce cross-validation and hyperparameter tuning, I end up with something like 0.20 for my best model. &lt;/p&gt;\n\n&lt;p&gt;My guess is that this indicates overfitting, but are there any other issues that I may be concerned with? My understanding is that overfitting is much less common in random forest models-- with my dataset being pretty large, would this just indicate that the data are highly noisy? Is there a &amp;#39;best approach&amp;#39; to assessing/solving this issue?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any advice more experienced members are able to give.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrlbs", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrlbs/high_scoring_training_set_but_low_scoring_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrlbs/high_scoring_training_set_but_low_scoring_with/", "subreddit_subscribers": 913975, "created_utc": 1685456341.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vle5v8ic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is DataOps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13vro8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is DataOps?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "author_name": "Polyseam", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/HNgpk9IUfK4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@polyseam"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13vro8l", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZV9tDN9N8Oy3pnxB22xIP11rQZvrVyX4a3uRkht-ZQU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685456536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/HNgpk9IUfK4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?auto=webp&amp;v=enabled&amp;s=558ed727ae34d44e61e800d5c68b6d4e3b06c9b5", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8987cee6ecdb05960e5deea7cec8c9c38efe0c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c5ce5990d7fd1f1cf4b4389b41bc453fc017fdb", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2be9fc510038f6f9ddb00aac3996a20d0ea37dc", "width": 320, "height": 240}], "variants": {}, "id": "YzEWw94GU1pBBr-CsbqyKbtLUvvhgd5ZFCQ5vQvUDYI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vro8l", "is_robot_indexable": true, "report_reasons": null, "author": "Polyseam", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vro8l/what_is_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/HNgpk9IUfK4", "subreddit_subscribers": 913975, "created_utc": 1685456536.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is DataOps?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "author_name": "Polyseam", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/HNgpk9IUfK4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@polyseam"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crops prediction with Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7srhy44w033b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/7srhy44w033b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02f3694cc239878ccf2a217aec626bb365be297"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/7srhy44w033b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c809c138766c4846e3956ee6e307f091cdbe5e62"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/7srhy44w033b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0914ed50006928f281a06956dd5c47453a937ef8"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/7srhy44w033b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96189182f829d41bb6d914ee482dfc4ee4e15ad6"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/7srhy44w033b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8779fcf97744747a8179cf975c729770e88266"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/7srhy44w033b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd037219cb6c71cdeb7f9024cf9db81157dba217"}], "s": {"y": 902, "x": 2500, "u": "https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c"}, "id": "7srhy44w033b1"}}, "name": "t3_13w3g3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2aTLJHuqZnjlHyX0Z1XFj9PDRRtHcyPFuhpMeYRg5xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c\"&gt;https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3g3h", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "subreddit_subscribers": 913975, "created_utc": 1685483880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There dataset is large enough. Very mild correlation.", "author_fullname": "t2_9y42hl3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a prediction model where there is negligible relation between the target variable and independent variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrk0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685456253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There dataset is large enough. Very mild correlation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrk0x", "is_robot_indexable": true, "report_reasons": null, "author": "ilovekungfuu", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrk0x/how_to_build_a_prediction_model_where_there_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrk0x/how_to_build_a_prediction_model_where_there_is/", "subreddit_subscribers": 913975, "created_utc": 1685456253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In past companies where I worked as a statistician (in the healthcare/insurance industry), the data prep and cleaning were handled by separate teams while I focused on modeling and literature research.\n\nIn my current position we have to do everything -- this doesn't seem terribly efficient.\n\nIs this \"jack of all trades/master of none\" job description standard among other data scientists?", "author_fullname": "t2_6cjiszgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better for data prep &amp; modelling to be separate positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vqd25", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685453335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In past companies where I worked as a statistician (in the healthcare/insurance industry), the data prep and cleaning were handled by separate teams while I focused on modeling and literature research.&lt;/p&gt;\n\n&lt;p&gt;In my current position we have to do everything -- this doesn&amp;#39;t seem terribly efficient.&lt;/p&gt;\n\n&lt;p&gt;Is this &amp;quot;jack of all trades/master of none&amp;quot; job description standard among other data scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vqd25", "is_robot_indexable": true, "report_reasons": null, "author": "RobertWF_47", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vqd25/better_for_data_prep_modelling_to_be_separate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vqd25/better_for_data_prep_modelling_to_be_separate/", "subreddit_subscribers": 913975, "created_utc": 1685453335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  \n\n\nThe ratings at my company are as follows  \n1 - Did not meet expectations  \n2 - Met some expectations  \n3 - Met expectations  \n4 - Exceeded expecations  \n5 - Went over and beyond expectations  \n\n\nThe reasons given for my rating were as follows:  \nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March '23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  \n\n\nWhile discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  \n\n\nOn a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  \n\n\nThe feedback from other stakeholders was mostly positive, citing things like I'm curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  \n\n\nDuring the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  \n\n\nIn our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  \n\n\nTLDR:\n\nTo summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager's dissatisfaction, as I believe this issue may arise again in my next review.  \nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. \n\nWhile I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don't want to quit without an other job lined up, given the situation of the current market. There's been no talk of a PIP, so I guess I'll be safe for the next 6 months. However, I'm not sure how much of a big difference I can make  \n\n\nAny suggestions would be greatly appreciated.", "author_fullname": "t2_7n4roggm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a bad performance review - Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vxim7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  &lt;/p&gt;\n\n&lt;p&gt;The ratings at my company are as follows&lt;br/&gt;\n1 - Did not meet expectations&lt;br/&gt;\n2 - Met some expectations&lt;br/&gt;\n3 - Met expectations&lt;br/&gt;\n4 - Exceeded expecations&lt;br/&gt;\n5 - Went over and beyond expectations  &lt;/p&gt;\n\n&lt;p&gt;The reasons given for my rating were as follows:&lt;br/&gt;\nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March &amp;#39;23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  &lt;/p&gt;\n\n&lt;p&gt;While discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  &lt;/p&gt;\n\n&lt;p&gt;On a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  &lt;/p&gt;\n\n&lt;p&gt;The feedback from other stakeholders was mostly positive, citing things like I&amp;#39;m curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  &lt;/p&gt;\n\n&lt;p&gt;During the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  &lt;/p&gt;\n\n&lt;p&gt;In our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  &lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;To summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager&amp;#39;s dissatisfaction, as I believe this issue may arise again in my next review.&lt;br/&gt;\nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. &lt;/p&gt;\n\n&lt;p&gt;While I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don&amp;#39;t want to quit without an other job lined up, given the situation of the current market. There&amp;#39;s been no talk of a PIP, so I guess I&amp;#39;ll be safe for the next 6 months. However, I&amp;#39;m not sure how much of a big difference I can make  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vxim7", "is_robot_indexable": true, "report_reasons": null, "author": "Public-Drag1602", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "subreddit_subscribers": 913975, "created_utc": 1685470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use synthetic because there are no donor brands", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are trying to perform A/B test on a campaign with very low to no control population, we are thinking about CTGAN to generate synthetic data but control data we have has 50 data points at max...how to generate control data or conduct a successful A/B test. P.S Synthetic control is not an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wcha5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685508131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use synthetic because there are no donor brands&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wcha5", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "subreddit_subscribers": 913975, "created_utc": 1685508131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7tpw2nbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing Jupyter Notebooks from localhost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13vyhdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K0s5acGmBFpLQath3rISaAgo6tS1oIHws2nuzNZT76s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685472425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pinggy.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?auto=webp&amp;v=enabled&amp;s=8879d7f15715c0622e0916aaedca8d2afb69f727", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=422f020c501c2ef89b12b705aea313e1c6aa151a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7f4914bd9db1d5ef86db25c39502d52bd1582f2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a10f495be6e4162572b9685897b8c12d60c8ab93", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ca00afdc443d902a1c8bb4d489402bd62c14172", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95c4a1af46b911cd76606123fb71db7243aca521", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c666b63be723ebba4c1c2cd10de2350390f1c66", "width": 1080, "height": 607}], "variants": {}, "id": "OGdm_ujqca1mKitGu5akhCopk6oU69W93sJmL_kNI38"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vyhdz", "is_robot_indexable": true, "report_reasons": null, "author": "bishakhghosh_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vyhdz/sharing_jupyter_notebooks_from_localhost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "subreddit_subscribers": 913975, "created_utc": 1685472425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I'm really keen on making a switch to a data science role. I know there's a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.\n\nWhat's the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you'd suggest? I'm all ears for your insights and personal experiences!\n\nThanks in advance", "author_fullname": "t2_oumsxias", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from ETL Developer to Data Science: Seeking Advice on Skill Development and Learning Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13weulc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685516229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I&amp;#39;m really keen on making a switch to a data science role. I know there&amp;#39;s a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you&amp;#39;d suggest? I&amp;#39;m all ears for your insights and personal experiences!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13weulc", "is_robot_indexable": true, "report_reasons": null, "author": "vidit_108", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "subreddit_subscribers": 913975, "created_utc": 1685516229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I'm using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I'm trying to go through some troubleshooting steps to see if I can improve things.\n\nWhen looking at histograms and box plots, I noticed that many of my numeric features and my target aren't normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?\n\nAny additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on handling skewed data in a random forest model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vujck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685465213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685463274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I&amp;#39;m using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I&amp;#39;m trying to go through some troubleshooting steps to see if I can improve things.&lt;/p&gt;\n\n&lt;p&gt;When looking at histograms and box plots, I noticed that many of my numeric features and my target aren&amp;#39;t normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?&lt;/p&gt;\n\n&lt;p&gt;Any additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vujck", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "subreddit_subscribers": 913975, "created_utc": 1685463274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nToday i got invited for an interview from airbnb. The hr told me this \n\n\"The objective of this evaluation round would be to understand your approach to data, detail orientation as well as aptitude for project management and planning. \"  \n\n\nIt is a data analysis internship. Any suggestion for what to study?", "author_fullname": "t2_5eyrbl3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to study for interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wh477", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685524553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Today i got invited for an interview from airbnb. The hr told me this &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The objective of this evaluation round would be to understand your approach to data, detail orientation as well as aptitude for project management and planning. &amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;It is a data analysis internship. Any suggestion for what to study?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wh477", "is_robot_indexable": true, "report_reasons": null, "author": "biagio98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wh477/what_to_study_for_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wh477/what_to_study_for_interview/", "subreddit_subscribers": 913975, "created_utc": 1685524553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. I'm trying to create a LSTM that that takes in various inputs such as opening price, interest rate, consumer sentiment index, and EPS to predict the closing price of a stock. However, the problem is that some of these variables are recorded on a monthly basis and quarterly basis and I'm sure of how to incorporate all these different kinds of data together. \n\nFor some more information regarding my model, the model will take 3 months worth of data to predict 7 days of the closing price of APPL stock. This is for a project. Thank you for all your help.", "author_fullname": "t2_bmhe3y7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incorporating Quarterly, Monthly, and Daily Data Together", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wasqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685503116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;m trying to create a LSTM that that takes in various inputs such as opening price, interest rate, consumer sentiment index, and EPS to predict the closing price of a stock. However, the problem is that some of these variables are recorded on a monthly basis and quarterly basis and I&amp;#39;m sure of how to incorporate all these different kinds of data together. &lt;/p&gt;\n\n&lt;p&gt;For some more information regarding my model, the model will take 3 months worth of data to predict 7 days of the closing price of APPL stock. This is for a project. Thank you for all your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wasqm", "is_robot_indexable": true, "report_reasons": null, "author": "Successful-Fee4220", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wasqm/incorporating_quarterly_monthly_and_daily_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wasqm/incorporating_quarterly_monthly_and_daily_data/", "subreddit_subscribers": 913975, "created_utc": 1685503116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).\n\nThe usual estimator is mean(Y)\\_{t} - mean(Y)\\_{c}. This is the same as fitting the model \n\nY = b\\_0 + b\\_t x Indicator.\n\nb\\_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. \n\nNow my question is why don't we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b\\_t without introducing bias. To me it seems like a no-brainer. Any catch here?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_dx4dz5s2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we use regression to estimate treatment effect in randomized experiment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vwdzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685467555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).&lt;/p&gt;\n\n&lt;p&gt;The usual estimator is mean(Y)_{t} - mean(Y)_{c}. This is the same as fitting the model &lt;/p&gt;\n\n&lt;p&gt;Y = b_0 + b_t x Indicator.&lt;/p&gt;\n\n&lt;p&gt;b_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. &lt;/p&gt;\n\n&lt;p&gt;Now my question is why don&amp;#39;t we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b_t without introducing bias. To me it seems like a no-brainer. Any catch here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vwdzd", "is_robot_indexable": true, "report_reasons": null, "author": "aggis_husky", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "subreddit_subscribers": 913975, "created_utc": 1685467555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just came up on the year mark for my first data scientist role and I\u2019m thinking about what to do about my career long-term.\n\nSome context: I work in finance in a data science team that\u2019s heavily focused on experimental design and causal inference. It\u2019s a bit of a weird role because my job is more around enforcing standards for experimental design and measurement, vetting and analyzing causal inference use cases and scoping work for novel methods in causal inference and measurement. I wrote virtually no sql in my job.\n\nThe good:\n- get some really good experience in designing good experiments and auditing the execution of the experimental design from end to end\n- soft skills development. Experimental designs need to be socialized which requires a lot of listening to precisely understand the business problem and communicating how the experimental design answers the business problem\n- freedom to explore and work on projects that use novel methods (likely won\u2019t go anywhere besides impressing my boss but good experience nonetheless)\n- great mentorship, my manager is a PhD statistician who has a ton of exp in experimental design and the director of the team is a PhD statistician as well so the value of the work we do is well understood and within the business\n- recognizable name brand on my resume \n- good pay for early career role in a non-tech industry\n\nThe bad:\n- no sql exposure, all the data comes from other analysts\n- no dashboard dev work\n- no opportunities for modeling in the predictive sense (we do use statistical modeling techniques but they\u2019re typically in service of causal inference work which is quite different than traditional modeling)\n- no coding best practices (no one uses git, we don\u2019t have a repo, just notebooks sent over email)\n- skill ceiling in experimental design. Our problems aren\u2019t as complicated and interesting as what\u2019s encountered in the tech industry\n\nIdeally I\u2019d like to have a long career in the field. I love experimental design (have a prior PhD in engineering and worked in my industry for a couple years before becoming a DS) and causal inference, it\u2019s a fun field. \n\nMy goals are to get a role in the tech industry and work on more interesting problems either within or adjacent to my sub field. I do some pro-bono consulting work for nonprofits on the side that give me more exposure to modeling but obviously the strength of this is limited relative to the strength of doing work problems in this.\n\nI\u2019m worried however that the negatives of my role and specializing is really going to limit my career growth and an not sure if I should spend time and find opportunities to shore these up. Would love to hear from others who have experience on what they think.", "author_fullname": "t2_9plbo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I specialize or look towards generalizing as an early career data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrgd6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685455994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just came up on the year mark for my first data scientist role and I\u2019m thinking about what to do about my career long-term.&lt;/p&gt;\n\n&lt;p&gt;Some context: I work in finance in a data science team that\u2019s heavily focused on experimental design and causal inference. It\u2019s a bit of a weird role because my job is more around enforcing standards for experimental design and measurement, vetting and analyzing causal inference use cases and scoping work for novel methods in causal inference and measurement. I wrote virtually no sql in my job.&lt;/p&gt;\n\n&lt;p&gt;The good:\n- get some really good experience in designing good experiments and auditing the execution of the experimental design from end to end\n- soft skills development. Experimental designs need to be socialized which requires a lot of listening to precisely understand the business problem and communicating how the experimental design answers the business problem\n- freedom to explore and work on projects that use novel methods (likely won\u2019t go anywhere besides impressing my boss but good experience nonetheless)\n- great mentorship, my manager is a PhD statistician who has a ton of exp in experimental design and the director of the team is a PhD statistician as well so the value of the work we do is well understood and within the business\n- recognizable name brand on my resume \n- good pay for early career role in a non-tech industry&lt;/p&gt;\n\n&lt;p&gt;The bad:\n- no sql exposure, all the data comes from other analysts\n- no dashboard dev work\n- no opportunities for modeling in the predictive sense (we do use statistical modeling techniques but they\u2019re typically in service of causal inference work which is quite different than traditional modeling)\n- no coding best practices (no one uses git, we don\u2019t have a repo, just notebooks sent over email)\n- skill ceiling in experimental design. Our problems aren\u2019t as complicated and interesting as what\u2019s encountered in the tech industry&lt;/p&gt;\n\n&lt;p&gt;Ideally I\u2019d like to have a long career in the field. I love experimental design (have a prior PhD in engineering and worked in my industry for a couple years before becoming a DS) and causal inference, it\u2019s a fun field. &lt;/p&gt;\n\n&lt;p&gt;My goals are to get a role in the tech industry and work on more interesting problems either within or adjacent to my sub field. I do some pro-bono consulting work for nonprofits on the side that give me more exposure to modeling but obviously the strength of this is limited relative to the strength of doing work problems in this.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried however that the negatives of my role and specializing is really going to limit my career growth and an not sure if I should spend time and find opportunities to shore these up. Would love to hear from others who have experience on what they think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrgd6", "is_robot_indexable": true, "report_reasons": null, "author": "ColickingSeahorse", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrgd6/should_i_specialize_or_look_towards_generalizing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrgd6/should_i_specialize_or_look_towards_generalizing/", "subreddit_subscribers": 913975, "created_utc": 1685455994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are data jobs (including analytics) safe from recession and improvement of A.I.? How can one improve their odds of staying ahead in the game? Apologies if this was already asked.\nThank you.", "author_fullname": "t2_14olq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recession and A.I.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wizv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685530886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are data jobs (including analytics) safe from recession and improvement of A.I.? How can one improve their odds of staying ahead in the game? Apologies if this was already asked.\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wizv5", "is_robot_indexable": true, "report_reasons": null, "author": "greytrain09", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wizv5/recession_and_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wizv5/recession_and_ai/", "subreddit_subscribers": 913975, "created_utc": 1685530886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI live in the UK. I have USA citizenship. \n\nI was accepted into a program here in the UK that provided me with a PgDip in Data while also providing a paid work placement. So when this program is finished I will have a PgDip in Data, and about 2 years of actual work experience. I was not like an intern getting coffee, I worked on real projects etc.\n\nI\u2019m looking to move back the the USA. PgDip is not really a degree that is generally offered in the USA. \n\n-Would having the PgDip be a detriment to any applications to USA jobs as it\u2019s not a well known sort of credential? \n\n-There is an option to get the full MSc but that would require a pretty substantial tuition payment, and writing a dissertation. This is my 2nd masters that I\u2019ve done back to back and the thought of having to write a dissertation again just\u2026.no. My first masters is a full MSc in an unrelated subject. \n\n-are there any certs or something smaller I can get to make any sort of application more competitive? \n\nThanks for any help!", "author_fullname": "t2_9c3vih4ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PgDip from UK in Data Science in USA and certs etc to be more competitive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wipp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685530005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I live in the UK. I have USA citizenship. &lt;/p&gt;\n\n&lt;p&gt;I was accepted into a program here in the UK that provided me with a PgDip in Data while also providing a paid work placement. So when this program is finished I will have a PgDip in Data, and about 2 years of actual work experience. I was not like an intern getting coffee, I worked on real projects etc.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to move back the the USA. PgDip is not really a degree that is generally offered in the USA. &lt;/p&gt;\n\n&lt;p&gt;-Would having the PgDip be a detriment to any applications to USA jobs as it\u2019s not a well known sort of credential? &lt;/p&gt;\n\n&lt;p&gt;-There is an option to get the full MSc but that would require a pretty substantial tuition payment, and writing a dissertation. This is my 2nd masters that I\u2019ve done back to back and the thought of having to write a dissertation again just\u2026.no. My first masters is a full MSc in an unrelated subject. &lt;/p&gt;\n\n&lt;p&gt;-are there any certs or something smaller I can get to make any sort of application more competitive? &lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wipp1", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Baby9379", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wipp1/pgdip_from_uk_in_data_science_in_usa_and_certs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wipp1/pgdip_from_uk_in_data_science_in_usa_and_certs/", "subreddit_subscribers": 913975, "created_utc": 1685530005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm looking for a jaw-dropping way to represent data in a map, something beyond plotly bubble maps. I'm looking for something flamboyant.\n\nThanks for your time.", "author_fullname": "t2_jyn7urgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best option to represent data in a map?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wipme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685529998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for a jaw-dropping way to represent data in a map, something beyond plotly bubble maps. I&amp;#39;m looking for something flamboyant.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wipme", "is_robot_indexable": true, "report_reasons": null, "author": "varmadd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wipme/best_option_to_represent_data_in_a_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wipme/best_option_to_represent_data_in_a_map/", "subreddit_subscribers": 913975, "created_utc": 1685529998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn't see much supplementary materials or articles on the internet explaining it.\n\nMaybe it's that simple and easy and I should probably leave this field, but that's for another time. I'll leave after understanding this paper. \n\nhere's the link if anyone is interested https://arxiv.org/pdf/1610.02136.pdf\n\n\nI understand PR Curves and ROC curves and softmax, but I just can't seem to follow what they are doing.\n\n-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. \n \n-For example, what does the value/score in even mean? I'm guessing value is the Area under the Curve, but what's the score? The base rate of the classes or something? https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\n\n-And I can't even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I'm guessing there is no need for thresholding? \n\n-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?\n\nWould really appreciate the help if possible. I think it's supposed to be a very easy paper which is discouraging but that's for another time....\n\nAnd sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it's a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.", "author_fullname": "t2_163jio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone read an old paper called \"Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13webkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685514278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn&amp;#39;t see much supplementary materials or articles on the internet explaining it.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s that simple and easy and I should probably leave this field, but that&amp;#39;s for another time. I&amp;#39;ll leave after understanding this paper. &lt;/p&gt;\n\n&lt;p&gt;here&amp;#39;s the link if anyone is interested &lt;a href=\"https://arxiv.org/pdf/1610.02136.pdf\"&gt;https://arxiv.org/pdf/1610.02136.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand PR Curves and ROC curves and softmax, but I just can&amp;#39;t seem to follow what they are doing.&lt;/p&gt;\n\n&lt;p&gt;-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. &lt;/p&gt;\n\n&lt;p&gt;-For example, what does the value/score in even mean? I&amp;#39;m guessing value is the Area under the Curve, but what&amp;#39;s the score? The base rate of the classes or something? &lt;a href=\"https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\"&gt;https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-And I can&amp;#39;t even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I&amp;#39;m guessing there is no need for thresholding? &lt;/p&gt;\n\n&lt;p&gt;-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate the help if possible. I think it&amp;#39;s supposed to be a very easy paper which is discouraging but that&amp;#39;s for another time....&lt;/p&gt;\n\n&lt;p&gt;And sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it&amp;#39;s a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13webkb", "is_robot_indexable": true, "report_reasons": null, "author": "THE_REAL_ODB", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "subreddit_subscribers": 913975, "created_utc": 1685514278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It's not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   \n\n\nNow I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I'm confused if I should target product manager or core data science (ML heavy) roles. \n\n  \nI am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I'm a German, currently working in the UAE.) \n\nI feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you", "author_fullname": "t2_o08dc9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Manager vs Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wdyhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685512939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It&amp;#39;s not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   &lt;/p&gt;\n\n&lt;p&gt;Now I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I&amp;#39;m confused if I should target product manager or core data science (ML heavy) roles. &lt;/p&gt;\n\n&lt;p&gt;I am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I&amp;#39;m a German, currently working in the UAE.) &lt;/p&gt;\n\n&lt;p&gt;I feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wdyhl", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Wonder-342", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "subreddit_subscribers": 913975, "created_utc": 1685512939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All\n\nIm working on a project where im looking to perform an lstm time series forecast for multiple different commodities at a time and ideally want to be able to run the model for one commodity and then run again for the second commodity and so on, appending the results to an array or df as it runs. All training data would ideally sit in a single spark dataframe and looped by a commidity id field.\n\nHowever, im limited to working within databricks and struggling to see how it is possible with only the udfs in pyspark available.\n\nHas anyone got any experience or advice for attempting something similar?", "author_fullname": "t2_8f2klb16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help creating a looping ML function in Pyspark (Databricks)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w3th3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685484760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;Im working on a project where im looking to perform an lstm time series forecast for multiple different commodities at a time and ideally want to be able to run the model for one commodity and then run again for the second commodity and so on, appending the results to an array or df as it runs. All training data would ideally sit in a single spark dataframe and looped by a commidity id field.&lt;/p&gt;\n\n&lt;p&gt;However, im limited to working within databricks and struggling to see how it is possible with only the udfs in pyspark available.&lt;/p&gt;\n\n&lt;p&gt;Has anyone got any experience or advice for attempting something similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3th3", "is_robot_indexable": true, "report_reasons": null, "author": "madlad183", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3th3/help_creating_a_looping_ml_function_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3th3/help_creating_a_looping_ml_function_in_pyspark/", "subreddit_subscribers": 913975, "created_utc": 1685484760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We get dozens and dozens of file patterns that are VERY consistent coming in that have to be cleaned up and reformatted to .csv files which we compare against the data in the database to see if it needs to be updated or if its outdated. Once its been cleaned we load it into the database and all is good, but we are repeating the same process over and over and I want ways to automate the pattern matching.\n\nThe challenge is that each of these formats are quite large but almost always one of about 11 different formats and I'm repeating the same cleaning steps each time. What is a DataScience step, tool, function or process to create a \\`pattern\\` or \\`map\\` that python can use to recognize \\`oh hey random\\_dirty\\_file\\_00n format matches clean\\_data\\_file\\_00n format &gt;90%\\` so lets reformat it.\n\nWe used something like this before years ago using MongoDB where they created a large script that compared the format and layout of a .csv, .txt, .tsv, .xml file that were 95% the same from customer exports, database exports, web scraping, data migrations or whatever. Isn't there a RL or SL 'thing' for this?\n\n\\`\\`\\`\n\n\"if this \\`dirty\\_data\\_pattern\\_001\\`:\n\nthen reformat to \\`clean\\_data\\_pattern\\_001\\`\"\n\n\\`\\`\\`\n\nMy notes just mention it was a mapping or formatting script but don't have access to that code from 7 years ago.\n\nPerhaps I'm overlooking or don't have the experience to know which but I've used\n\n1. Python regex\n2. MongoDB integrated with python\n3. Python \\`map()\\` function\n4. \\[Python NLTK functions\\]([https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/](https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/))\n5. Python scripts using \\`sklearn.preprocessing\\` like \\[[Jeremyjordan.me](https://Jeremyjordan.me)\\]([https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/](https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/)) using script like this works for words but not whole documents\n\nI hope this script below is formatted correctly but its close to what we use for individual word matching.\n\nEdit: for some reason I had to click inline code, then code block and the 'inserting spaces doesn't work' it only works when putting the code in \"triple marks and doing \\`code block\\` and doing \\`inline code\\`\" but it seems to be showing correctly now\n\n\\`\\`\\`\n\n    male_terms = [\"male\", \"m\", \"mal\", \"msle\", \"malr\", \"mail\", \"make\", \"cis male\", \"man\", \"maile\", \"male (cis)\", \"cis man\"]\n    \n    female_terms = [\"female\", \"f\", \"woman\", \"femake\", \"femaile\", \"femake\", \"cis female\", \"cis-female/femme\", \"female (cis)\", \"femail\", \"cis woman\"]\n    \n    def clean_gender(response):\n        if response.lower().rstrip() in male_terms:\n            return \"Male\"\n        elif response.lower().rstrip() in female_terms:\n            return \"Female\"\n        else:\n            return \"Other\"\n    \n    df['Gender'] = df[\"Gender\"].apply(lambda x: clean_gender(x))\n\n\\`\\`\\`", "author_fullname": "t2_cbz254uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the data science process or best practices for Reinforcement Learning RL or Supervised Learning SL method to map `dirty_data_pattern_001` to `clean_data_pattern_001` is this a tensor flow or map function?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vzawy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685474554.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685474214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We get dozens and dozens of file patterns that are VERY consistent coming in that have to be cleaned up and reformatted to .csv files which we compare against the data in the database to see if it needs to be updated or if its outdated. Once its been cleaned we load it into the database and all is good, but we are repeating the same process over and over and I want ways to automate the pattern matching.&lt;/p&gt;\n\n&lt;p&gt;The challenge is that each of these formats are quite large but almost always one of about 11 different formats and I&amp;#39;m repeating the same cleaning steps each time. What is a DataScience step, tool, function or process to create a `pattern` or `map` that python can use to recognize `oh hey random_dirty_file_00n format matches clean_data_file_00n format &amp;gt;90%` so lets reformat it.&lt;/p&gt;\n\n&lt;p&gt;We used something like this before years ago using MongoDB where they created a large script that compared the format and layout of a .csv, .txt, .tsv, .xml file that were 95% the same from customer exports, database exports, web scraping, data migrations or whatever. Isn&amp;#39;t there a RL or SL &amp;#39;thing&amp;#39; for this?&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;if this `dirty_data_pattern_001`:&lt;/p&gt;\n\n&lt;p&gt;then reformat to `clean_data_pattern_001`&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;My notes just mention it was a mapping or formatting script but don&amp;#39;t have access to that code from 7 years ago.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I&amp;#39;m overlooking or don&amp;#39;t have the experience to know which but I&amp;#39;ve used&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python regex&lt;/li&gt;\n&lt;li&gt;MongoDB integrated with python&lt;/li&gt;\n&lt;li&gt;Python `map()` function&lt;/li&gt;\n&lt;li&gt;[Python NLTK functions](&lt;a href=\"https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/\"&gt;https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/&lt;/a&gt;)&lt;/li&gt;\n&lt;li&gt;Python scripts using `sklearn.preprocessing` like [&lt;a href=\"https://Jeremyjordan.me\"&gt;Jeremyjordan.me&lt;/a&gt;](&lt;a href=\"https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/\"&gt;https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/&lt;/a&gt;) using script like this works for words but not whole documents&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I hope this script below is formatted correctly but its close to what we use for individual word matching.&lt;/p&gt;\n\n&lt;p&gt;Edit: for some reason I had to click inline code, then code block and the &amp;#39;inserting spaces doesn&amp;#39;t work&amp;#39; it only works when putting the code in &amp;quot;triple marks and doing `code block` and doing `inline code`&amp;quot; but it seems to be showing correctly now&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;male_terms = [&amp;quot;male&amp;quot;, &amp;quot;m&amp;quot;, &amp;quot;mal&amp;quot;, &amp;quot;msle&amp;quot;, &amp;quot;malr&amp;quot;, &amp;quot;mail&amp;quot;, &amp;quot;make&amp;quot;, &amp;quot;cis male&amp;quot;, &amp;quot;man&amp;quot;, &amp;quot;maile&amp;quot;, &amp;quot;male (cis)&amp;quot;, &amp;quot;cis man&amp;quot;]\n\nfemale_terms = [&amp;quot;female&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;woman&amp;quot;, &amp;quot;femake&amp;quot;, &amp;quot;femaile&amp;quot;, &amp;quot;femake&amp;quot;, &amp;quot;cis female&amp;quot;, &amp;quot;cis-female/femme&amp;quot;, &amp;quot;female (cis)&amp;quot;, &amp;quot;femail&amp;quot;, &amp;quot;cis woman&amp;quot;]\n\ndef clean_gender(response):\n    if response.lower().rstrip() in male_terms:\n        return &amp;quot;Male&amp;quot;\n    elif response.lower().rstrip() in female_terms:\n        return &amp;quot;Female&amp;quot;\n    else:\n        return &amp;quot;Other&amp;quot;\n\ndf[&amp;#39;Gender&amp;#39;] = df[&amp;quot;Gender&amp;quot;].apply(lambda x: clean_gender(x))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kVnBrWGTrbn8IcPl7jUrXtEdtv9OiF6cB5yvHuhS0DQ.jpg?auto=webp&amp;v=enabled&amp;s=3d1e12b29962c29b283f923a8285f732781426f8", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/kVnBrWGTrbn8IcPl7jUrXtEdtv9OiF6cB5yvHuhS0DQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82c07b6e523f5002d402aeb9b881bb14b774c110", "width": 108, "height": 108}], "variants": {}, "id": "LrwawBOrEFhMR9Nbh20vF8BGtS6Co_BAR39WQmpv-34"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vzawy", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Win_3457", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vzawy/what_is_the_data_science_process_or_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vzawy/what_is_the_data_science_process_or_best/", "subreddit_subscribers": 913975, "created_utc": 1685474214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in an ML/CV team and would like to learn more about how ML/CV/DS teams manage their projects within the team. we currently use Kanban, but it has been somewhat inefficient, as it focuses too much on the stages of a product and less on the research and development processes...\n\nHow does your team organize and manage the flow of projects?", "author_fullname": "t2_9s1yrp6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team/squad/tribe organize their projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vw57e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685466985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an ML/CV team and would like to learn more about how ML/CV/DS teams manage their projects within the team. we currently use Kanban, but it has been somewhat inefficient, as it focuses too much on the stages of a product and less on the research and development processes...&lt;/p&gt;\n\n&lt;p&gt;How does your team organize and manage the flow of projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vw57e", "is_robot_indexable": true, "report_reasons": null, "author": "ddponwheels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vw57e/how_does_your_teamsquadtribe_organize_their/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vw57e/how_does_your_teamsquadtribe_organize_their/", "subreddit_subscribers": 913975, "created_utc": 1685466985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a friend who without any knowledge of coding, but just for a degree in pharmacy has got a job as data analyst type, the company gave him trainings and so he is learning some of main softwares used in the field. Good and happy for him.\nMe, after that I learned some coding for a year with Python, SQL, and others with certification obviously linked on the CV, and studying physics (toward the end), seems I can't even get an internship, not paid, to get some real experience and form myself.\nJust one interview last month with a suspicious company with 0 reviews who wanted me to pay them for the internship.\n\nCan you tell me any real company that would hire me or give me some training at an entry level as data scientist or data analyst? Or is anyone offering a position?\nI'm an hardworker.", "author_fullname": "t2_bzblyfu4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datascience internship (remote)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13whu1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685527117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a friend who without any knowledge of coding, but just for a degree in pharmacy has got a job as data analyst type, the company gave him trainings and so he is learning some of main softwares used in the field. Good and happy for him.\nMe, after that I learned some coding for a year with Python, SQL, and others with certification obviously linked on the CV, and studying physics (toward the end), seems I can&amp;#39;t even get an internship, not paid, to get some real experience and form myself.\nJust one interview last month with a suspicious company with 0 reviews who wanted me to pay them for the internship.&lt;/p&gt;\n\n&lt;p&gt;Can you tell me any real company that would hire me or give me some training at an entry level as data scientist or data analyst? Or is anyone offering a position?\nI&amp;#39;m an hardworker.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13whu1n", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Hawk9942", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13whu1n/datascience_internship_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13whu1n/datascience_internship_remote/", "subreddit_subscribers": 913975, "created_utc": 1685527117.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}