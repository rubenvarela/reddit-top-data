{"kind": "Listing", "data": {"after": "t3_13wjt3v", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started working at a small analytics company, they haven't had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don't know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.", "author_fullname": "t2_3739kucg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would one write a data ETL pipeline in Javascript + SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w4yfp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685487592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working at a small analytics company, they haven&amp;#39;t had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don&amp;#39;t know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w4yfp", "is_robot_indexable": true, "report_reasons": null, "author": "Brown-Chemist99", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "subreddit_subscribers": 914219, "created_utc": 1685487592.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best editor for Python in your opinion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wkkdv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685535246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wkkdv", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 92, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "subreddit_subscribers": 914219, "created_utc": 1685535246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It's not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   \n\n\nNow I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I'm confused if I should target product manager or core data science (ML heavy) roles. \n\n  \nI am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I'm a German, currently working in the UAE.) \n\nI feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you", "author_fullname": "t2_o08dc9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Manager vs Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wdyhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685512939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It&amp;#39;s not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   &lt;/p&gt;\n\n&lt;p&gt;Now I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I&amp;#39;m confused if I should target product manager or core data science (ML heavy) roles. &lt;/p&gt;\n\n&lt;p&gt;I am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I&amp;#39;m a German, currently working in the UAE.) &lt;/p&gt;\n\n&lt;p&gt;I feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wdyhl", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Wonder-342", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "subreddit_subscribers": 914219, "created_utc": 1685512939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crops prediction with Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7srhy44w033b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/7srhy44w033b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02f3694cc239878ccf2a217aec626bb365be297"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/7srhy44w033b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c809c138766c4846e3956ee6e307f091cdbe5e62"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/7srhy44w033b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0914ed50006928f281a06956dd5c47453a937ef8"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/7srhy44w033b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96189182f829d41bb6d914ee482dfc4ee4e15ad6"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/7srhy44w033b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8779fcf97744747a8179cf975c729770e88266"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/7srhy44w033b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd037219cb6c71cdeb7f9024cf9db81157dba217"}], "s": {"y": 902, "x": 2500, "u": "https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c"}, "id": "7srhy44w033b1"}}, "name": "t3_13w3g3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2aTLJHuqZnjlHyX0Z1XFj9PDRRtHcyPFuhpMeYRg5xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c\"&gt;https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3g3h", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "subreddit_subscribers": 914219, "created_utc": 1685483880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use synthetic because there are no donor brands", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are trying to perform A/B test on a campaign with very low to no control population, we are thinking about CTGAN to generate synthetic data but control data we have has 50 data points at max...how to generate control data or conduct a successful A/B test. P.S Synthetic control is not an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wcha5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685508131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use synthetic because there are no donor brands&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wcha5", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "subreddit_subscribers": 914219, "created_utc": 1685508131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.\n\nThanks \ud83d\ude0a", "author_fullname": "t2_aakdy8le7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most difficult data to collect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wns57", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685543267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wns57", "is_robot_indexable": true, "report_reasons": null, "author": "TipAccomplished1946", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "subreddit_subscribers": 914219, "created_utc": 1685543267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I'm really keen on making a switch to a data science role. I know there's a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.\n\nWhat's the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you'd suggest? I'm all ears for your insights and personal experiences!\n\nThanks in advance", "author_fullname": "t2_oumsxias", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from ETL Developer to Data Science: Seeking Advice on Skill Development and Learning Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13weulc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685516229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I&amp;#39;m really keen on making a switch to a data science role. I know there&amp;#39;s a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you&amp;#39;d suggest? I&amp;#39;m all ears for your insights and personal experiences!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13weulc", "is_robot_indexable": true, "report_reasons": null, "author": "vidit_108", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "subreddit_subscribers": 914219, "created_utc": 1685516229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  \n\n\nThe ratings at my company are as follows  \n1 - Did not meet expectations  \n2 - Met some expectations  \n3 - Met expectations  \n4 - Exceeded expecations  \n5 - Went over and beyond expectations  \n\n\nThe reasons given for my rating were as follows:  \nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March '23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  \n\n\nWhile discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  \n\n\nOn a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  \n\n\nThe feedback from other stakeholders was mostly positive, citing things like I'm curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  \n\n\nDuring the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  \n\n\nIn our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  \n\n\nTLDR:\n\nTo summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager's dissatisfaction, as I believe this issue may arise again in my next review.  \nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. \n\nWhile I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don't want to quit without an other job lined up, given the situation of the current market. There's been no talk of a PIP, so I guess I'll be safe for the next 6 months. However, I'm not sure how much of a big difference I can make  \n\n\nAny suggestions would be greatly appreciated.", "author_fullname": "t2_7n4roggm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a bad performance review - Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vxim7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  &lt;/p&gt;\n\n&lt;p&gt;The ratings at my company are as follows&lt;br/&gt;\n1 - Did not meet expectations&lt;br/&gt;\n2 - Met some expectations&lt;br/&gt;\n3 - Met expectations&lt;br/&gt;\n4 - Exceeded expecations&lt;br/&gt;\n5 - Went over and beyond expectations  &lt;/p&gt;\n\n&lt;p&gt;The reasons given for my rating were as follows:&lt;br/&gt;\nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March &amp;#39;23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  &lt;/p&gt;\n\n&lt;p&gt;While discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  &lt;/p&gt;\n\n&lt;p&gt;On a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  &lt;/p&gt;\n\n&lt;p&gt;The feedback from other stakeholders was mostly positive, citing things like I&amp;#39;m curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  &lt;/p&gt;\n\n&lt;p&gt;During the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  &lt;/p&gt;\n\n&lt;p&gt;In our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  &lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;To summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager&amp;#39;s dissatisfaction, as I believe this issue may arise again in my next review.&lt;br/&gt;\nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. &lt;/p&gt;\n\n&lt;p&gt;While I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don&amp;#39;t want to quit without an other job lined up, given the situation of the current market. There&amp;#39;s been no talk of a PIP, so I guess I&amp;#39;ll be safe for the next 6 months. However, I&amp;#39;m not sure how much of a big difference I can make  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vxim7", "is_robot_indexable": true, "report_reasons": null, "author": "Public-Drag1602", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "subreddit_subscribers": 914219, "created_utc": 1685470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7tpw2nbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing Jupyter Notebooks from localhost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13vyhdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K0s5acGmBFpLQath3rISaAgo6tS1oIHws2nuzNZT76s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685472425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pinggy.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?auto=webp&amp;v=enabled&amp;s=8879d7f15715c0622e0916aaedca8d2afb69f727", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=422f020c501c2ef89b12b705aea313e1c6aa151a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7f4914bd9db1d5ef86db25c39502d52bd1582f2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a10f495be6e4162572b9685897b8c12d60c8ab93", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ca00afdc443d902a1c8bb4d489402bd62c14172", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95c4a1af46b911cd76606123fb71db7243aca521", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c666b63be723ebba4c1c2cd10de2350390f1c66", "width": 1080, "height": 607}], "variants": {}, "id": "OGdm_ujqca1mKitGu5akhCopk6oU69W93sJmL_kNI38"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vyhdz", "is_robot_indexable": true, "report_reasons": null, "author": "bishakhghosh_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vyhdz/sharing_jupyter_notebooks_from_localhost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "subreddit_subscribers": 914219, "created_utc": 1685472425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For example I want to use the time series of the temperature in Orlando to predict the temperature in Miami.  What are the ways I can use the Orlando daily high temperature time series to predict the current day's high temperature or forecast tomorrow's high temperature in Miami?", "author_fullname": "t2_2uajbxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the easiest ways to use one time series to predict or forecast a different time series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13woa0w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685545090.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685544489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example I want to use the time series of the temperature in Orlando to predict the temperature in Miami.  What are the ways I can use the Orlando daily high temperature time series to predict the current day&amp;#39;s high temperature or forecast tomorrow&amp;#39;s high temperature in Miami?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13woa0w", "is_robot_indexable": true, "report_reasons": null, "author": "penpapermouse", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13woa0w/what_are_the_easiest_ways_to_use_one_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13woa0w/what_are_the_easiest_ways_to_use_one_time_series/", "subreddit_subscribers": 914219, "created_utc": 1685544489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn't see much supplementary materials or articles on the internet explaining it.\n\nMaybe it's that simple and easy and I should probably leave this field, but that's for another time. I'll leave after understanding this paper. \n\nhere's the link if anyone is interested https://arxiv.org/pdf/1610.02136.pdf\n\n\nI understand PR Curves and ROC curves and softmax, but I just can't seem to follow what they are doing.\n\n-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. \n \n-For example, what does the value/score in even mean? I'm guessing value is the Area under the Curve, but what's the score? The base rate of the classes or something? https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\n\n-And I can't even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I'm guessing there is no need for thresholding? \n\n-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?\n\nWould really appreciate the help if possible. I think it's supposed to be a very easy paper which is discouraging but that's for another time....\n\nAnd sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it's a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.", "author_fullname": "t2_163jio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone read an old paper called \"Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13webkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685514278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn&amp;#39;t see much supplementary materials or articles on the internet explaining it.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s that simple and easy and I should probably leave this field, but that&amp;#39;s for another time. I&amp;#39;ll leave after understanding this paper. &lt;/p&gt;\n\n&lt;p&gt;here&amp;#39;s the link if anyone is interested &lt;a href=\"https://arxiv.org/pdf/1610.02136.pdf\"&gt;https://arxiv.org/pdf/1610.02136.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand PR Curves and ROC curves and softmax, but I just can&amp;#39;t seem to follow what they are doing.&lt;/p&gt;\n\n&lt;p&gt;-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. &lt;/p&gt;\n\n&lt;p&gt;-For example, what does the value/score in even mean? I&amp;#39;m guessing value is the Area under the Curve, but what&amp;#39;s the score? The base rate of the classes or something? &lt;a href=\"https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\"&gt;https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-And I can&amp;#39;t even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I&amp;#39;m guessing there is no need for thresholding? &lt;/p&gt;\n\n&lt;p&gt;-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate the help if possible. I think it&amp;#39;s supposed to be a very easy paper which is discouraging but that&amp;#39;s for another time....&lt;/p&gt;\n\n&lt;p&gt;And sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it&amp;#39;s a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13webkb", "is_robot_indexable": true, "report_reasons": null, "author": "THE_REAL_ODB", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "subreddit_subscribers": 914219, "created_utc": 1685514278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).\n\nThe usual estimator is mean(Y)\\_{t} - mean(Y)\\_{c}. This is the same as fitting the model \n\nY = b\\_0 + b\\_t x Indicator.\n\nb\\_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. \n\nNow my question is why don't we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b\\_t without introducing bias. To me it seems like a no-brainer. Any catch here?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_dx4dz5s2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we use regression to estimate treatment effect in randomized experiment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vwdzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685467555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).&lt;/p&gt;\n\n&lt;p&gt;The usual estimator is mean(Y)_{t} - mean(Y)_{c}. This is the same as fitting the model &lt;/p&gt;\n\n&lt;p&gt;Y = b_0 + b_t x Indicator.&lt;/p&gt;\n\n&lt;p&gt;b_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. &lt;/p&gt;\n\n&lt;p&gt;Now my question is why don&amp;#39;t we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b_t without introducing bias. To me it seems like a no-brainer. Any catch here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vwdzd", "is_robot_indexable": true, "report_reasons": null, "author": "aggis_husky", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "subreddit_subscribers": 914219, "created_utc": 1685467555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All. I\u2019m wondering what is the possible way to feed huge text to LLM so I could query it with custom questions and it will use the context of the entire document for each question or query?\n\nUnfortunately, all articles that I\u2019ve recently come across described the workflow on enhancing ChatGPT with custom text via the reduced summary of the document and prompting it for each query to keep the context. It does not look an option for me since the text is huge and I want to keep the details of the original document so the LLM can use it while building the answer.\n\nSo, I support the solution is to take some general-purpose LLM and fine-tune it (retrain) with my text to enhance the model? \nAny other solutions for the problem? Which LLM to use for that (any lightweight one that does not require huge resources to host it)?\n\nThanks!", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Augmenting LLM with my data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wrgiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685551707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I\u2019m wondering what is the possible way to feed huge text to LLM so I could query it with custom questions and it will use the context of the entire document for each question or query?&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, all articles that I\u2019ve recently come across described the workflow on enhancing ChatGPT with custom text via the reduced summary of the document and prompting it for each query to keep the context. It does not look an option for me since the text is huge and I want to keep the details of the original document so the LLM can use it while building the answer.&lt;/p&gt;\n\n&lt;p&gt;So, I support the solution is to take some general-purpose LLM and fine-tune it (retrain) with my text to enhance the model? \nAny other solutions for the problem? Which LLM to use for that (any lightweight one that does not require huge resources to host it)?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wrgiv", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wrgiv/augmenting_llm_with_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wrgiv/augmenting_llm_with_my_data/", "subreddit_subscribers": 914219, "created_utc": 1685551707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work on a data engineering team and love what I do and just graduated with a masters in data analytics which included several machine learning courses (done part time while I was still working full time). \nWe have a weekly data team training where someone in the department will present on a topic of their choice and the person coordinating has been asking me to present on a data science topic now that I finished my degree. \nWhat are a couple suggestions for quick but still interesting concepts that are easy to explain in a half hour session?\nThanks!", "author_fullname": "t2_bfa6tlx6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to Give Lessons On", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wrfym", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685551673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on a data engineering team and love what I do and just graduated with a masters in data analytics which included several machine learning courses (done part time while I was still working full time). \nWe have a weekly data team training where someone in the department will present on a topic of their choice and the person coordinating has been asking me to present on a data science topic now that I finished my degree. \nWhat are a couple suggestions for quick but still interesting concepts that are easy to explain in a half hour session?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wrfym", "is_robot_indexable": true, "report_reasons": null, "author": "Lost_Source824", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wrfym/what_to_give_lessons_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wrfym/what_to_give_lessons_on/", "subreddit_subscribers": 914219, "created_utc": 1685551673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I made the switch from fisheries management (population stats background) to data science last year after I got into a data science master's program, and happily finished my first year with a 4.0, I applied to many places and only got one interview who happened to not put up the correct job description and wanted someone with much more experience. I want to make it in data science, what kind of personal project would you recommend I do over the summer to prove that I actually know how to do things, I feel like I'm being brushed off because when I was applying for internships I only had officially completed one semester and was almost done with the second semester, and the only things in my portfolio were homework assignment and exam assignments. I would prefer to do it in Python since all of my background is in R I have almost nothing to show for my python work and a lot of jobs are asking for python not R.", "author_fullname": "t2_nypxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failed to get an internship how do I improve for next time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wqsnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685550199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made the switch from fisheries management (population stats background) to data science last year after I got into a data science master&amp;#39;s program, and happily finished my first year with a 4.0, I applied to many places and only got one interview who happened to not put up the correct job description and wanted someone with much more experience. I want to make it in data science, what kind of personal project would you recommend I do over the summer to prove that I actually know how to do things, I feel like I&amp;#39;m being brushed off because when I was applying for internships I only had officially completed one semester and was almost done with the second semester, and the only things in my portfolio were homework assignment and exam assignments. I would prefer to do it in Python since all of my background is in R I have almost nothing to show for my python work and a lot of jobs are asking for python not R.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqsnq", "is_robot_indexable": true, "report_reasons": null, "author": "Talonsoldat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqsnq/failed_to_get_an_internship_how_do_i_improve_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqsnq/failed_to_get_an_internship_how_do_i_improve_for/", "subreddit_subscribers": 914219, "created_utc": 1685550199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What do you do if you have 1-4 observations on a hundred separate occasions (it is basically event starts and has 7 steps with an exponentialish increase and then it ends and there are a few other features that influence it at each time period), what type of models can you use? \n\nMy instinct is to just line it up as a regression problem and put the observations as features, but I've been wondering if there is a better way to do it (I know there is a lot of research into arma/arima, can you use it for separate instances and combine it with other factors at each time step).\n\nI also feel like there might be some manufacturing optimisation model, but I haven't seen a practical suggestion", "author_fullname": "t2_23bi1gsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with a bunch of small time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wqqtv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685550083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you do if you have 1-4 observations on a hundred separate occasions (it is basically event starts and has 7 steps with an exponentialish increase and then it ends and there are a few other features that influence it at each time period), what type of models can you use? &lt;/p&gt;\n\n&lt;p&gt;My instinct is to just line it up as a regression problem and put the observations as features, but I&amp;#39;ve been wondering if there is a better way to do it (I know there is a lot of research into arma/arima, can you use it for separate instances and combine it with other factors at each time step).&lt;/p&gt;\n\n&lt;p&gt;I also feel like there might be some manufacturing optimisation model, but I haven&amp;#39;t seen a practical suggestion&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqqtv", "is_robot_indexable": true, "report_reasons": null, "author": "Alienbushman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqqtv/what_do_you_do_with_a_bunch_of_small_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqqtv/what_do_you_do_with_a_bunch_of_small_time_series/", "subreddit_subscribers": 914219, "created_utc": 1685550083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9792cqxim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone published a library in python? if yes then how did you do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wqiyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685549596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqiyb", "is_robot_indexable": true, "report_reasons": null, "author": "Dipanshuz1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqiyb/has_anyone_published_a_library_in_python_if_yes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqiyb/has_anyone_published_a_library_in_python_if_yes/", "subreddit_subscribers": 914219, "created_utc": 1685549596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I use conda and want to have my code available in my environment \n\nWe currently have custom modules we implement and make them available with \"pip install -e .\" Inside of the env. \n\nAre there any tools to better manage dependencies?", "author_fullname": "t2_og7kb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best environment management tool, conda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wqchd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685549189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I use conda and want to have my code available in my environment &lt;/p&gt;\n\n&lt;p&gt;We currently have custom modules we implement and make them available with &amp;quot;pip install -e .&amp;quot; Inside of the env. &lt;/p&gt;\n\n&lt;p&gt;Are there any tools to better manage dependencies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqchd", "is_robot_indexable": true, "report_reasons": null, "author": "siddartha08", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqchd/best_environment_management_tool_conda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqchd/best_environment_management_tool_conda/", "subreddit_subscribers": 914219, "created_utc": 1685549189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello guys,\n\nWe wanted to ask for a community\u2019s opinion. \n\nAs data professionals ourselves, we understand the challenges of extracting insights from data. That's why we've incorporated ChatGPT into our analytics platform to facilitate comprehension of complex data for end users, in a decipherable form.\n\nChatGPT reveals insights, trends, patterns and recommendations within the specific domain of expertise in one click. We\u2019ve developed a  prompt generator , which helps the AI in comprehending the underlying conditions of the chart and furnishing it with the relevant raw data, all under-the-hood.  \n \n\n[DoubleCloud AI-Insights](https://i.redd.it/sau2cyvh783b1.gif)\n\nThis feature works best with complex charts where multiple factors need to be comprehended. It can discover non-obvious anomalies, patterns or correlations to provide a deeper understanding of data. Think of it as a digital business analyst, who can leverage data-driven insights for improved decision-making.\n\nAlso sharing some discoveries we made while developing the feature, which you may find useful: \n\n* Precision in the prompt phrasing plays a crucial role in driving the accuracy of the response. clear specifications, such as the preferred language, answer length, and contextual information regarding the data, can have a significant impact on the outcome. Role playing or simulating a specialist can also guide the model to provide more detailed responses within a particular knowledge domain.\n* ChatGPT excels in parsing and working with tabular data, including CSV. We chose this format to transmit raw data to the model due to its compactness, accuracy, and readability. The model can even conceptualize the way the data from such a table could be represented using different chart types and can explain the data using these visualizations.\n* It's worth noting that ChatGPT seems to struggle with large values and fractional numbers with numerous decimal points. To overcome this, we rounded numbers to a maximum of 2-3 decimal places. This practice not only improves accuracy but also reduces the number of tokens used.\n\nIf you wanna try the feature we have a free trial: [https://double.cloud/services/doublecloud-visualization/](https://double.cloud/services/doublecloud-visualization/), no credit card is required, and without any GPT-4 API Key.", "author_fullname": "t2_a4qx2du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of using GPT-4 to automatically extract insights from data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"sau2cyvh783b1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9cae36446674144be5813c5b27f95f57c7e20ce8"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=97cec2c316e25e319624c2cc2be0e618297e5ab0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=5f9f63a5e487da9197f00e84997274db753abeb8"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=cf87e2e348e1e4143f51343948b2bfe2c8e0a19d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9a1d8ea866b4e289569741a7430a9a460e2f97a9"}], "s": {"y": 576, "gif": "https://i.redd.it/sau2cyvh783b1.gif", "mp4": "https://preview.redd.it/sau2cyvh783b1.gif?format=mp4&amp;v=enabled&amp;s=8c2da20ce72021363a6d75913be9114fdcd5af97", "x": 1024}, "id": "sau2cyvh783b1"}}, "name": "t3_13wpsrg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2OZZ896u-uAHMjsoUi0jbtsxCfEDa_9SlUDUW838QuY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685547976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;We wanted to ask for a community\u2019s opinion. &lt;/p&gt;\n\n&lt;p&gt;As data professionals ourselves, we understand the challenges of extracting insights from data. That&amp;#39;s why we&amp;#39;ve incorporated ChatGPT into our analytics platform to facilitate comprehension of complex data for end users, in a decipherable form.&lt;/p&gt;\n\n&lt;p&gt;ChatGPT reveals insights, trends, patterns and recommendations within the specific domain of expertise in one click. We\u2019ve developed a  prompt generator , which helps the AI in comprehending the underlying conditions of the chart and furnishing it with the relevant raw data, all under-the-hood.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/sau2cyvh783b1.gif\"&gt;DoubleCloud AI-Insights&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This feature works best with complex charts where multiple factors need to be comprehended. It can discover non-obvious anomalies, patterns or correlations to provide a deeper understanding of data. Think of it as a digital business analyst, who can leverage data-driven insights for improved decision-making.&lt;/p&gt;\n\n&lt;p&gt;Also sharing some discoveries we made while developing the feature, which you may find useful: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Precision in the prompt phrasing plays a crucial role in driving the accuracy of the response. clear specifications, such as the preferred language, answer length, and contextual information regarding the data, can have a significant impact on the outcome. Role playing or simulating a specialist can also guide the model to provide more detailed responses within a particular knowledge domain.&lt;/li&gt;\n&lt;li&gt;ChatGPT excels in parsing and working with tabular data, including CSV. We chose this format to transmit raw data to the model due to its compactness, accuracy, and readability. The model can even conceptualize the way the data from such a table could be represented using different chart types and can explain the data using these visualizations.&lt;/li&gt;\n&lt;li&gt;It&amp;#39;s worth noting that ChatGPT seems to struggle with large values and fractional numbers with numerous decimal points. To overcome this, we rounded numbers to a maximum of 2-3 decimal places. This practice not only improves accuracy but also reduces the number of tokens used.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you wanna try the feature we have a free trial: &lt;a href=\"https://double.cloud/services/doublecloud-visualization/\"&gt;https://double.cloud/services/doublecloud-visualization/&lt;/a&gt;, no credit card is required, and without any GPT-4 API Key.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wpsrg", "is_robot_indexable": true, "report_reasons": null, "author": "deepanigi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wpsrg/what_do_you_think_of_using_gpt4_to_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wpsrg/what_do_you_think_of_using_gpt4_to_automatically/", "subreddit_subscribers": 914219, "created_utc": 1685547976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anybody suggest me an app vaible in android to execute phython programs ?", "author_fullname": "t2_un9jycm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mobile app to run phython program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wp0h1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685546170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody suggest me an app vaible in android to execute phython programs ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wp0h1", "is_robot_indexable": true, "report_reasons": null, "author": "Cold_Match2401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wp0h1/mobile_app_to_run_phython_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wp0h1/mobile_app_to_run_phython_program/", "subreddit_subscribers": 914219, "created_utc": 1685546170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How are you supposed to randomize your groups in scenarios when certain groups can't be split up for a test? For example we may want to test conversion on local TV ad campaigns but can't randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?", "author_fullname": "t2_dayu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AB Test Randomization with Fixed Groups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wossp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685545671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you supposed to randomize your groups in scenarios when certain groups can&amp;#39;t be split up for a test? For example we may want to test conversion on local TV ad campaigns but can&amp;#39;t randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wossp", "is_robot_indexable": true, "report_reasons": null, "author": "TryWforWumbo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "subreddit_subscribers": 914219, "created_utc": 1685545671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Next week I will complete the final \"in person\" assesment for my level 4 data analyst qualification. It consists of a presentation and then questioning from an external examiner on my course projects for circa 2 hours. I'm struggling with what to expect and would appreciate hearing experiences of anyone who has completed this.\n\nTo prepare thus far,  I have focused on the \"ksb\"s but would love some practise questions and/or a better grasp whether I should be focusing deeply on my code or more high level. Much appreciated!!", "author_fullname": "t2_leovmrlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level 4 Data Analyst Apprenticeship Assessment (UK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wm5xa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685539277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Next week I will complete the final &amp;quot;in person&amp;quot; assesment for my level 4 data analyst qualification. It consists of a presentation and then questioning from an external examiner on my course projects for circa 2 hours. I&amp;#39;m struggling with what to expect and would appreciate hearing experiences of anyone who has completed this.&lt;/p&gt;\n\n&lt;p&gt;To prepare thus far,  I have focused on the &amp;quot;ksb&amp;quot;s but would love some practise questions and/or a better grasp whether I should be focusing deeply on my code or more high level. Much appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wm5xa", "is_robot_indexable": true, "report_reasons": null, "author": "Separate-Egg-9599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wm5xa/level_4_data_analyst_apprenticeship_assessment_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wm5xa/level_4_data_analyst_apprenticeship_assessment_uk/", "subreddit_subscribers": 914219, "created_utc": 1685539277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am back testing a ML model  for classification.\nI need to back test it for specific period say between Jan 2023 and May 2023.\nI have the dates for class 1 but not for the class 0( obviously)\n\nHow can we back test this model for specific period.\nNeed your suggestion and ideas.", "author_fullname": "t2_3v6pyvi2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back testing model to check threshold and accuracy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wl1nn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685536475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am back testing a ML model  for classification.\nI need to back test it for specific period say between Jan 2023 and May 2023.\nI have the dates for class 1 but not for the class 0( obviously)&lt;/p&gt;\n\n&lt;p&gt;How can we back test this model for specific period.\nNeed your suggestion and ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wl1nn", "is_robot_indexable": true, "report_reasons": null, "author": "bubdi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wl1nn/back_testing_model_to_check_threshold_and_accuracy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wl1nn/back_testing_model_to_check_threshold_and_accuracy/", "subreddit_subscribers": 914219, "created_utc": 1685536475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ll be 23 when I begin the program with no prior experience, I just feel if I do a 2 years masters I\u2019ll be done at 25 with on experience in the labour market. I don\u2019t know guys, which is better I guess the pace of a 2 years master will be breathable. Location is Canada", "author_fullname": "t2_9ple7b7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters for 1 year vs masters for 2 years in statistics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wkw87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685536087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll be 23 when I begin the program with no prior experience, I just feel if I do a 2 years masters I\u2019ll be done at 25 with on experience in the labour market. I don\u2019t know guys, which is better I guess the pace of a 2 years master will be breathable. Location is Canada&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wkw87", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Ad_7053", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wkw87/masters_for_1_year_vs_masters_for_2_years_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wkw87/masters_for_1_year_vs_masters_for_2_years_in/", "subreddit_subscribers": 914219, "created_utc": 1685536087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9de03cxq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leading Data Science Events/ Summits in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 31, "top_awarded_type": null, "hide_score": false, "name": "t3_13wjt3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wJOXx2UnsMMvPT1hxgv-_sFjMgZqeXFljkLU6koQzYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685533204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datasciencecertifications.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datasciencecertifications.com/events", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?auto=webp&amp;v=enabled&amp;s=f61767c37724cc0b4240c0d2731559e32fd91c88", "width": 395, "height": 90}, "resolutions": [{"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4132cd92c5a841253bf488d30f12ef0be690f6fd", "width": 108, "height": 24}, {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=912e4185fc9fec1551687db3399679432cab2bdf", "width": 216, "height": 49}, {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a90aea8c5e70483bcf4f06c16924f861c42065fc", "width": 320, "height": 72}], "variants": {}, "id": "PKTwTdcu4YRmcmCdPjLwc-2a2R9Hk9V9yprRQ05Lrnk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wjt3v", "is_robot_indexable": true, "report_reasons": null, "author": "Palaksharma22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wjt3v/leading_data_science_events_summits_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datasciencecertifications.com/events", "subreddit_subscribers": 914219, "created_utc": 1685533204.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}