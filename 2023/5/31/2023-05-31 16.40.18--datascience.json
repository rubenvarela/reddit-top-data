{"kind": "Listing", "data": {"after": "t3_13wasqm", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started working at a small analytics company, they haven't had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don't know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.", "author_fullname": "t2_3739kucg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would one write a data ETL pipeline in Javascript + SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w4yfp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685487592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working at a small analytics company, they haven&amp;#39;t had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don&amp;#39;t know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w4yfp", "is_robot_indexable": true, "report_reasons": null, "author": "Brown-Chemist99", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "subreddit_subscribers": 914178, "created_utc": 1685487592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best editor for Python in your opinion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wkkdv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685535246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wkkdv", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "subreddit_subscribers": 914178, "created_utc": 1685535246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crops prediction with Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7srhy44w033b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/7srhy44w033b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02f3694cc239878ccf2a217aec626bb365be297"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/7srhy44w033b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c809c138766c4846e3956ee6e307f091cdbe5e62"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/7srhy44w033b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0914ed50006928f281a06956dd5c47453a937ef8"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/7srhy44w033b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96189182f829d41bb6d914ee482dfc4ee4e15ad6"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/7srhy44w033b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8779fcf97744747a8179cf975c729770e88266"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/7srhy44w033b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd037219cb6c71cdeb7f9024cf9db81157dba217"}], "s": {"y": 902, "x": 2500, "u": "https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c"}, "id": "7srhy44w033b1"}}, "name": "t3_13w3g3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2aTLJHuqZnjlHyX0Z1XFj9PDRRtHcyPFuhpMeYRg5xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c\"&gt;https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3g3h", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "subreddit_subscribers": 914178, "created_utc": 1685483880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It's not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   \n\n\nNow I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I'm confused if I should target product manager or core data science (ML heavy) roles. \n\n  \nI am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I'm a German, currently working in the UAE.) \n\nI feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you", "author_fullname": "t2_o08dc9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Manager vs Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wdyhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685512939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It&amp;#39;s not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   &lt;/p&gt;\n\n&lt;p&gt;Now I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I&amp;#39;m confused if I should target product manager or core data science (ML heavy) roles. &lt;/p&gt;\n\n&lt;p&gt;I am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I&amp;#39;m a German, currently working in the UAE.) &lt;/p&gt;\n\n&lt;p&gt;I feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wdyhl", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Wonder-342", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "subreddit_subscribers": 914178, "created_utc": 1685512939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use synthetic because there are no donor brands", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are trying to perform A/B test on a campaign with very low to no control population, we are thinking about CTGAN to generate synthetic data but control data we have has 50 data points at max...how to generate control data or conduct a successful A/B test. P.S Synthetic control is not an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wcha5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685508131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use synthetic because there are no donor brands&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wcha5", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "subreddit_subscribers": 914178, "created_utc": 1685508131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  \n\n\nThe ratings at my company are as follows  \n1 - Did not meet expectations  \n2 - Met some expectations  \n3 - Met expectations  \n4 - Exceeded expecations  \n5 - Went over and beyond expectations  \n\n\nThe reasons given for my rating were as follows:  \nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March '23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  \n\n\nWhile discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  \n\n\nOn a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  \n\n\nThe feedback from other stakeholders was mostly positive, citing things like I'm curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  \n\n\nDuring the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  \n\n\nIn our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  \n\n\nTLDR:\n\nTo summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager's dissatisfaction, as I believe this issue may arise again in my next review.  \nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. \n\nWhile I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don't want to quit without an other job lined up, given the situation of the current market. There's been no talk of a PIP, so I guess I'll be safe for the next 6 months. However, I'm not sure how much of a big difference I can make  \n\n\nAny suggestions would be greatly appreciated.", "author_fullname": "t2_7n4roggm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a bad performance review - Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vxim7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  &lt;/p&gt;\n\n&lt;p&gt;The ratings at my company are as follows&lt;br/&gt;\n1 - Did not meet expectations&lt;br/&gt;\n2 - Met some expectations&lt;br/&gt;\n3 - Met expectations&lt;br/&gt;\n4 - Exceeded expecations&lt;br/&gt;\n5 - Went over and beyond expectations  &lt;/p&gt;\n\n&lt;p&gt;The reasons given for my rating were as follows:&lt;br/&gt;\nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March &amp;#39;23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  &lt;/p&gt;\n\n&lt;p&gt;While discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  &lt;/p&gt;\n\n&lt;p&gt;On a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  &lt;/p&gt;\n\n&lt;p&gt;The feedback from other stakeholders was mostly positive, citing things like I&amp;#39;m curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  &lt;/p&gt;\n\n&lt;p&gt;During the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  &lt;/p&gt;\n\n&lt;p&gt;In our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  &lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;To summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager&amp;#39;s dissatisfaction, as I believe this issue may arise again in my next review.&lt;br/&gt;\nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. &lt;/p&gt;\n\n&lt;p&gt;While I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don&amp;#39;t want to quit without an other job lined up, given the situation of the current market. There&amp;#39;s been no talk of a PIP, so I guess I&amp;#39;ll be safe for the next 6 months. However, I&amp;#39;m not sure how much of a big difference I can make  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vxim7", "is_robot_indexable": true, "report_reasons": null, "author": "Public-Drag1602", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "subreddit_subscribers": 914178, "created_utc": 1685470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I'm really keen on making a switch to a data science role. I know there's a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.\n\nWhat's the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you'd suggest? I'm all ears for your insights and personal experiences!\n\nThanks in advance", "author_fullname": "t2_oumsxias", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from ETL Developer to Data Science: Seeking Advice on Skill Development and Learning Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13weulc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685516229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I&amp;#39;m really keen on making a switch to a data science role. I know there&amp;#39;s a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you&amp;#39;d suggest? I&amp;#39;m all ears for your insights and personal experiences!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13weulc", "is_robot_indexable": true, "report_reasons": null, "author": "vidit_108", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "subreddit_subscribers": 914178, "created_utc": 1685516229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7tpw2nbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing Jupyter Notebooks from localhost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13vyhdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K0s5acGmBFpLQath3rISaAgo6tS1oIHws2nuzNZT76s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685472425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pinggy.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?auto=webp&amp;v=enabled&amp;s=8879d7f15715c0622e0916aaedca8d2afb69f727", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=422f020c501c2ef89b12b705aea313e1c6aa151a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7f4914bd9db1d5ef86db25c39502d52bd1582f2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a10f495be6e4162572b9685897b8c12d60c8ab93", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ca00afdc443d902a1c8bb4d489402bd62c14172", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95c4a1af46b911cd76606123fb71db7243aca521", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c666b63be723ebba4c1c2cd10de2350390f1c66", "width": 1080, "height": 607}], "variants": {}, "id": "OGdm_ujqca1mKitGu5akhCopk6oU69W93sJmL_kNI38"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vyhdz", "is_robot_indexable": true, "report_reasons": null, "author": "bishakhghosh_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vyhdz/sharing_jupyter_notebooks_from_localhost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "subreddit_subscribers": 914178, "created_utc": 1685472425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello guys,\n\nWe wanted to ask for a community\u2019s opinion. \n\nAs data professionals ourselves, we understand the challenges of extracting insights from data. That's why we've incorporated ChatGPT into our analytics platform to facilitate comprehension of complex data for end users, in a decipherable form.\n\nChatGPT reveals insights, trends, patterns and recommendations within the specific domain of expertise in one click. We\u2019ve developed a  prompt generator , which helps the AI in comprehending the underlying conditions of the chart and furnishing it with the relevant raw data, all under-the-hood.  \n \n\n[DoubleCloud AI-Insights](https://i.redd.it/sau2cyvh783b1.gif)\n\nThis feature works best with complex charts where multiple factors need to be comprehended. It can discover non-obvious anomalies, patterns or correlations to provide a deeper understanding of data. Think of it as a digital business analyst, who can leverage data-driven insights for improved decision-making.\n\nAlso sharing some discoveries we made while developing the feature, which you may find useful: \n\n* Precision in the prompt phrasing plays a crucial role in driving the accuracy of the response. clear specifications, such as the preferred language, answer length, and contextual information regarding the data, can have a significant impact on the outcome. Role playing or simulating a specialist can also guide the model to provide more detailed responses within a particular knowledge domain.\n* ChatGPT excels in parsing and working with tabular data, including CSV. We chose this format to transmit raw data to the model due to its compactness, accuracy, and readability. The model can even conceptualize the way the data from such a table could be represented using different chart types and can explain the data using these visualizations.\n* It's worth noting that ChatGPT seems to struggle with large values and fractional numbers with numerous decimal points. To overcome this, we rounded numbers to a maximum of 2-3 decimal places. This practice not only improves accuracy but also reduces the number of tokens used.\n\nIf you wanna try the feature we have a free trial: [https://double.cloud/services/doublecloud-visualization/](https://double.cloud/services/doublecloud-visualization/), no credit card is required, and without any GPT-4 API Key.", "author_fullname": "t2_a4qx2du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of using GPT-4 to automatically extract insights from data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"sau2cyvh783b1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9cae36446674144be5813c5b27f95f57c7e20ce8"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=97cec2c316e25e319624c2cc2be0e618297e5ab0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=5f9f63a5e487da9197f00e84997274db753abeb8"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=cf87e2e348e1e4143f51343948b2bfe2c8e0a19d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/sau2cyvh783b1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9a1d8ea866b4e289569741a7430a9a460e2f97a9"}], "s": {"y": 576, "gif": "https://i.redd.it/sau2cyvh783b1.gif", "mp4": "https://preview.redd.it/sau2cyvh783b1.gif?format=mp4&amp;v=enabled&amp;s=8c2da20ce72021363a6d75913be9114fdcd5af97", "x": 1024}, "id": "sau2cyvh783b1"}}, "name": "t3_13wpsrg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2OZZ896u-uAHMjsoUi0jbtsxCfEDa_9SlUDUW838QuY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685547976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;We wanted to ask for a community\u2019s opinion. &lt;/p&gt;\n\n&lt;p&gt;As data professionals ourselves, we understand the challenges of extracting insights from data. That&amp;#39;s why we&amp;#39;ve incorporated ChatGPT into our analytics platform to facilitate comprehension of complex data for end users, in a decipherable form.&lt;/p&gt;\n\n&lt;p&gt;ChatGPT reveals insights, trends, patterns and recommendations within the specific domain of expertise in one click. We\u2019ve developed a  prompt generator , which helps the AI in comprehending the underlying conditions of the chart and furnishing it with the relevant raw data, all under-the-hood.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/sau2cyvh783b1.gif\"&gt;DoubleCloud AI-Insights&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This feature works best with complex charts where multiple factors need to be comprehended. It can discover non-obvious anomalies, patterns or correlations to provide a deeper understanding of data. Think of it as a digital business analyst, who can leverage data-driven insights for improved decision-making.&lt;/p&gt;\n\n&lt;p&gt;Also sharing some discoveries we made while developing the feature, which you may find useful: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Precision in the prompt phrasing plays a crucial role in driving the accuracy of the response. clear specifications, such as the preferred language, answer length, and contextual information regarding the data, can have a significant impact on the outcome. Role playing or simulating a specialist can also guide the model to provide more detailed responses within a particular knowledge domain.&lt;/li&gt;\n&lt;li&gt;ChatGPT excels in parsing and working with tabular data, including CSV. We chose this format to transmit raw data to the model due to its compactness, accuracy, and readability. The model can even conceptualize the way the data from such a table could be represented using different chart types and can explain the data using these visualizations.&lt;/li&gt;\n&lt;li&gt;It&amp;#39;s worth noting that ChatGPT seems to struggle with large values and fractional numbers with numerous decimal points. To overcome this, we rounded numbers to a maximum of 2-3 decimal places. This practice not only improves accuracy but also reduces the number of tokens used.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you wanna try the feature we have a free trial: &lt;a href=\"https://double.cloud/services/doublecloud-visualization/\"&gt;https://double.cloud/services/doublecloud-visualization/&lt;/a&gt;, no credit card is required, and without any GPT-4 API Key.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wpsrg", "is_robot_indexable": true, "report_reasons": null, "author": "deepanigi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wpsrg/what_do_you_think_of_using_gpt4_to_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wpsrg/what_do_you_think_of_using_gpt4_to_automatically/", "subreddit_subscribers": 914178, "created_utc": 1685547976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I'm using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I'm trying to go through some troubleshooting steps to see if I can improve things.\n\nWhen looking at histograms and box plots, I noticed that many of my numeric features and my target aren't normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?\n\nAny additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on handling skewed data in a random forest model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vujck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685465213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685463274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I&amp;#39;m using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I&amp;#39;m trying to go through some troubleshooting steps to see if I can improve things.&lt;/p&gt;\n\n&lt;p&gt;When looking at histograms and box plots, I noticed that many of my numeric features and my target aren&amp;#39;t normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?&lt;/p&gt;\n\n&lt;p&gt;Any additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vujck", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "subreddit_subscribers": 914178, "created_utc": 1685463274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For example I want to use the time series of the temperature in Orlando to predict the temperature in Miami.  What are the ways I can use the Orlando daily high temperature time series to predict the current day's high temperature or forecast tomorrow's high temperature in Miami?", "author_fullname": "t2_2uajbxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the easiest ways to use one time series to predict or forecast a different time series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13woa0w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685545090.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685544489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example I want to use the time series of the temperature in Orlando to predict the temperature in Miami.  What are the ways I can use the Orlando daily high temperature time series to predict the current day&amp;#39;s high temperature or forecast tomorrow&amp;#39;s high temperature in Miami?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13woa0w", "is_robot_indexable": true, "report_reasons": null, "author": "penpapermouse", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13woa0w/what_are_the_easiest_ways_to_use_one_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13woa0w/what_are_the_easiest_ways_to_use_one_time_series/", "subreddit_subscribers": 914178, "created_utc": 1685544489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.\n\nThanks \ud83d\ude0a", "author_fullname": "t2_aakdy8le7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most difficult data to collect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wns57", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685543267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wns57", "is_robot_indexable": true, "report_reasons": null, "author": "TipAccomplished1946", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "subreddit_subscribers": 914178, "created_utc": 1685543267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Next week I will complete the final \"in person\" assesment for my level 4 data analyst qualification. It consists of a presentation and then questioning from an external examiner on my course projects for circa 2 hours. I'm struggling with what to expect and would appreciate hearing experiences of anyone who has completed this.\n\nTo prepare thus far,  I have focused on the \"ksb\"s but would love some practise questions and/or a better grasp whether I should be focusing deeply on my code or more high level. Much appreciated!!", "author_fullname": "t2_leovmrlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level 4 Data Analyst Apprenticeship Assessment (UK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wm5xa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685539277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Next week I will complete the final &amp;quot;in person&amp;quot; assesment for my level 4 data analyst qualification. It consists of a presentation and then questioning from an external examiner on my course projects for circa 2 hours. I&amp;#39;m struggling with what to expect and would appreciate hearing experiences of anyone who has completed this.&lt;/p&gt;\n\n&lt;p&gt;To prepare thus far,  I have focused on the &amp;quot;ksb&amp;quot;s but would love some practise questions and/or a better grasp whether I should be focusing deeply on my code or more high level. Much appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wm5xa", "is_robot_indexable": true, "report_reasons": null, "author": "Separate-Egg-9599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wm5xa/level_4_data_analyst_apprenticeship_assessment_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wm5xa/level_4_data_analyst_apprenticeship_assessment_uk/", "subreddit_subscribers": 914178, "created_utc": 1685539277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn't see much supplementary materials or articles on the internet explaining it.\n\nMaybe it's that simple and easy and I should probably leave this field, but that's for another time. I'll leave after understanding this paper. \n\nhere's the link if anyone is interested https://arxiv.org/pdf/1610.02136.pdf\n\n\nI understand PR Curves and ROC curves and softmax, but I just can't seem to follow what they are doing.\n\n-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. \n \n-For example, what does the value/score in even mean? I'm guessing value is the Area under the Curve, but what's the score? The base rate of the classes or something? https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\n\n-And I can't even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I'm guessing there is no need for thresholding? \n\n-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?\n\nWould really appreciate the help if possible. I think it's supposed to be a very easy paper which is discouraging but that's for another time....\n\nAnd sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it's a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.", "author_fullname": "t2_163jio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone read an old paper called \"Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13webkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685514278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn&amp;#39;t see much supplementary materials or articles on the internet explaining it.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s that simple and easy and I should probably leave this field, but that&amp;#39;s for another time. I&amp;#39;ll leave after understanding this paper. &lt;/p&gt;\n\n&lt;p&gt;here&amp;#39;s the link if anyone is interested &lt;a href=\"https://arxiv.org/pdf/1610.02136.pdf\"&gt;https://arxiv.org/pdf/1610.02136.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand PR Curves and ROC curves and softmax, but I just can&amp;#39;t seem to follow what they are doing.&lt;/p&gt;\n\n&lt;p&gt;-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. &lt;/p&gt;\n\n&lt;p&gt;-For example, what does the value/score in even mean? I&amp;#39;m guessing value is the Area under the Curve, but what&amp;#39;s the score? The base rate of the classes or something? &lt;a href=\"https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\"&gt;https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-And I can&amp;#39;t even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I&amp;#39;m guessing there is no need for thresholding? &lt;/p&gt;\n\n&lt;p&gt;-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate the help if possible. I think it&amp;#39;s supposed to be a very easy paper which is discouraging but that&amp;#39;s for another time....&lt;/p&gt;\n\n&lt;p&gt;And sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it&amp;#39;s a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13webkb", "is_robot_indexable": true, "report_reasons": null, "author": "THE_REAL_ODB", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "subreddit_subscribers": 914178, "created_utc": 1685514278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).\n\nThe usual estimator is mean(Y)\\_{t} - mean(Y)\\_{c}. This is the same as fitting the model \n\nY = b\\_0 + b\\_t x Indicator.\n\nb\\_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. \n\nNow my question is why don't we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b\\_t without introducing bias. To me it seems like a no-brainer. Any catch here?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_dx4dz5s2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we use regression to estimate treatment effect in randomized experiment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vwdzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685467555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).&lt;/p&gt;\n\n&lt;p&gt;The usual estimator is mean(Y)_{t} - mean(Y)_{c}. This is the same as fitting the model &lt;/p&gt;\n\n&lt;p&gt;Y = b_0 + b_t x Indicator.&lt;/p&gt;\n\n&lt;p&gt;b_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. &lt;/p&gt;\n\n&lt;p&gt;Now my question is why don&amp;#39;t we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b_t without introducing bias. To me it seems like a no-brainer. Any catch here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vwdzd", "is_robot_indexable": true, "report_reasons": null, "author": "aggis_husky", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "subreddit_subscribers": 914178, "created_utc": 1685467555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to get into data science but currently not sure if the way I am going about it is the best path. Ideally, I want to either be able to find a job after my current full-time internship is up (july of 2024) or go into grad school for my masters. I would have two years experience by the end of this internship.\n\nMy relevant undergraduate degree is in economics, which is technical is some regard but not something like CS or statistics. Currently a senior research assistant at an economic think tank. My work involves a lot of scripting and production of several indices. I use a lot of R, some python, some SQL, and a decent amount of Tableau. Additionally, we interact a lot with business clients and C-suite level executives and therefore I have a decent understanding of what stakeholder needs, and translating more technical concepts for a wider audience. For my personal project at work, I decided to try and build a model to predict salary using an extensive dataset of online job postings so I can have an actual project under my belt; however this is the first time I will be doing any modelling and am learning on the fly. At the moment, I am going through a python textbook (Head First Python) and a machine learning textbook (Hands-On Machine Learning) to assist in that regards.\n\nI am a little concerned that I lack the technical skills of entry level people in the field. For example, I did not take probability or linear algebra during university. I am however, following the MIT online  Linear Algebra class but I am not sure if employers or masters programs really consider that as legitimate. I plan on doing a probability class later this year when I have more time. I do have a solid understanding of statistics due to the economics degree, and completed a substantial senior thesis doing regression analysis on the economics of crime. I also lack computer science skills that a lot of others have (I see tons of posts around here with terms I have not heard of).\n\nAm I on the right path when it comes to entering the data science space? What other resources should I look into as well? By the end of my internship, should I be looking at grad school or trying to get a more entry level data science focused position? I think I would prefer finding another job versus grad school, just at a cost level, but will go to grad school if its a must/recommended. I think right now if I were to go into another job, it would probably have to be something along the lines of data analyst rather than ML related, too.\n\nAny advice would be greatly appreciated.", "author_fullname": "t2_zyhvl64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS career and learning advice for someone without a technical degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wpltt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685547535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to get into data science but currently not sure if the way I am going about it is the best path. Ideally, I want to either be able to find a job after my current full-time internship is up (july of 2024) or go into grad school for my masters. I would have two years experience by the end of this internship.&lt;/p&gt;\n\n&lt;p&gt;My relevant undergraduate degree is in economics, which is technical is some regard but not something like CS or statistics. Currently a senior research assistant at an economic think tank. My work involves a lot of scripting and production of several indices. I use a lot of R, some python, some SQL, and a decent amount of Tableau. Additionally, we interact a lot with business clients and C-suite level executives and therefore I have a decent understanding of what stakeholder needs, and translating more technical concepts for a wider audience. For my personal project at work, I decided to try and build a model to predict salary using an extensive dataset of online job postings so I can have an actual project under my belt; however this is the first time I will be doing any modelling and am learning on the fly. At the moment, I am going through a python textbook (Head First Python) and a machine learning textbook (Hands-On Machine Learning) to assist in that regards.&lt;/p&gt;\n\n&lt;p&gt;I am a little concerned that I lack the technical skills of entry level people in the field. For example, I did not take probability or linear algebra during university. I am however, following the MIT online  Linear Algebra class but I am not sure if employers or masters programs really consider that as legitimate. I plan on doing a probability class later this year when I have more time. I do have a solid understanding of statistics due to the economics degree, and completed a substantial senior thesis doing regression analysis on the economics of crime. I also lack computer science skills that a lot of others have (I see tons of posts around here with terms I have not heard of).&lt;/p&gt;\n\n&lt;p&gt;Am I on the right path when it comes to entering the data science space? What other resources should I look into as well? By the end of my internship, should I be looking at grad school or trying to get a more entry level data science focused position? I think I would prefer finding another job versus grad school, just at a cost level, but will go to grad school if its a must/recommended. I think right now if I were to go into another job, it would probably have to be something along the lines of data analyst rather than ML related, too.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wpltt", "is_robot_indexable": true, "report_reasons": null, "author": "Eliyatollah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wpltt/ds_career_and_learning_advice_for_someone_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wpltt/ds_career_and_learning_advice_for_someone_without/", "subreddit_subscribers": 914178, "created_utc": 1685547535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anybody suggest me an app vaible in android to execute phython programs ?", "author_fullname": "t2_un9jycm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mobile app to run phython program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wp0h1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685546170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody suggest me an app vaible in android to execute phython programs ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wp0h1", "is_robot_indexable": true, "report_reasons": null, "author": "Cold_Match2401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wp0h1/mobile_app_to_run_phython_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wp0h1/mobile_app_to_run_phython_program/", "subreddit_subscribers": 914178, "created_utc": 1685546170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How are you supposed to randomize your groups in scenarios when certain groups can't be split up for a test? For example we may want to test conversion on local TV ad campaigns but can't randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?", "author_fullname": "t2_dayu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AB Test Randomization with Fixed Groups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wossp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685545671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you supposed to randomize your groups in scenarios when certain groups can&amp;#39;t be split up for a test? For example we may want to test conversion on local TV ad campaigns but can&amp;#39;t randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wossp", "is_robot_indexable": true, "report_reasons": null, "author": "TryWforWumbo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "subreddit_subscribers": 914178, "created_utc": 1685545671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_m6kzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenAI\u2019s Sam Altman: No GPT-5 In Training As Of Yet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13wnbkv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EASoidy_f1eAZLpaoG57zE-E4gyHxLRe6E5NiUNIPSs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685542095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/inkwater-atlas/openais-sam-altman-no-gpt-5-in-training-as-of-yet-8ddf95b9b3d6", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?auto=webp&amp;v=enabled&amp;s=d28963286cd3255df665cc8a57858a580e38352b", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a94bfb0a6757261531a6334bf53bc0a87ca6344", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eca6e548d9d225f9943040e9f9316776d55ecc", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=222f3602a9520f7ac43e4f23be543a6851d84378", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=493adbae3aa1e88c003c0015c4034e789ed1d846", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5264174ef00a072c71ef0e309d6a8b89dbe43762", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3055ebe01fb6e531882f2e580bc54c0ae43876b", "width": 1080, "height": 720}], "variants": {}, "id": "N5lb3eq-yiwMylcDE1BYnr_U6EGw281aw2FNnsBweuc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wnbkv", "is_robot_indexable": true, "report_reasons": null, "author": "liquidocelotYT", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wnbkv/openais_sam_altman_no_gpt5_in_training_as_of_yet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/inkwater-atlas/openais-sam-altman-no-gpt-5-in-training-as-of-yet-8ddf95b9b3d6", "subreddit_subscribers": 914178, "created_utc": 1685542095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am back testing a ML model  for classification.\nI need to back test it for specific period say between Jan 2023 and May 2023.\nI have the dates for class 1 but not for the class 0( obviously)\n\nHow can we back test this model for specific period.\nNeed your suggestion and ideas.", "author_fullname": "t2_3v6pyvi2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back testing model to check threshold and accuracy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wl1nn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685536475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am back testing a ML model  for classification.\nI need to back test it for specific period say between Jan 2023 and May 2023.\nI have the dates for class 1 but not for the class 0( obviously)&lt;/p&gt;\n\n&lt;p&gt;How can we back test this model for specific period.\nNeed your suggestion and ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wl1nn", "is_robot_indexable": true, "report_reasons": null, "author": "bubdi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wl1nn/back_testing_model_to_check_threshold_and_accuracy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wl1nn/back_testing_model_to_check_threshold_and_accuracy/", "subreddit_subscribers": 914178, "created_utc": 1685536475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ll be 23 when I begin the program with no prior experience, I just feel if I do a 2 years masters I\u2019ll be done at 25 with on experience in the labour market. I don\u2019t know guys, which is better I guess the pace of a 2 years master will be breathable. Location is Canada", "author_fullname": "t2_9ple7b7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters for 1 year vs masters for 2 years in statistics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wkw87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685536087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll be 23 when I begin the program with no prior experience, I just feel if I do a 2 years masters I\u2019ll be done at 25 with on experience in the labour market. I don\u2019t know guys, which is better I guess the pace of a 2 years master will be breathable. Location is Canada&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wkw87", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Ad_7053", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wkw87/masters_for_1_year_vs_masters_for_2_years_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wkw87/masters_for_1_year_vs_masters_for_2_years_in/", "subreddit_subscribers": 914178, "created_utc": 1685536087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9de03cxq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leading Data Science Events/ Summits in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 31, "top_awarded_type": null, "hide_score": false, "name": "t3_13wjt3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wJOXx2UnsMMvPT1hxgv-_sFjMgZqeXFljkLU6koQzYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685533204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datasciencecertifications.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datasciencecertifications.com/events", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?auto=webp&amp;v=enabled&amp;s=f61767c37724cc0b4240c0d2731559e32fd91c88", "width": 395, "height": 90}, "resolutions": [{"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4132cd92c5a841253bf488d30f12ef0be690f6fd", "width": 108, "height": 24}, {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=912e4185fc9fec1551687db3399679432cab2bdf", "width": 216, "height": 49}, {"url": "https://external-preview.redd.it/ouIguqrAcqAYq8xPs6WL6zwHTJx3wQz2XnEEMjPx33o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a90aea8c5e70483bcf4f06c16924f861c42065fc", "width": 320, "height": 72}], "variants": {}, "id": "PKTwTdcu4YRmcmCdPjLwc-2a2R9Hk9V9yprRQ05Lrnk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wjt3v", "is_robot_indexable": true, "report_reasons": null, "author": "Palaksharma22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wjt3v/leading_data_science_events_summits_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datasciencecertifications.com/events", "subreddit_subscribers": 914178, "created_utc": 1685533204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm looking for a jaw-dropping way to represent data in a map, something beyond plotly bubble maps. I'm looking for something flamboyant.\n\nThanks for your time.", "author_fullname": "t2_jyn7urgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best option to represent data in a map?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wipme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685529998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for a jaw-dropping way to represent data in a map, something beyond plotly bubble maps. I&amp;#39;m looking for something flamboyant.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wipme", "is_robot_indexable": true, "report_reasons": null, "author": "varmadd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wipme/best_option_to_represent_data_in_a_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wipme/best_option_to_represent_data_in_a_map/", "subreddit_subscribers": 914178, "created_utc": 1685529998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nToday i got invited for an interview from airbnb. The hr told me this \n\n\"The objective of this evaluation round would be to understand your approach to data, detail orientation as well as aptitude for project management and planning. \"  \n\n\nIt is a data analysis internship. Any suggestion for what to study?", "author_fullname": "t2_5eyrbl3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to study for interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wh477", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685524553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Today i got invited for an interview from airbnb. The hr told me this &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The objective of this evaluation round would be to understand your approach to data, detail orientation as well as aptitude for project management and planning. &amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;It is a data analysis internship. Any suggestion for what to study?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wh477", "is_robot_indexable": true, "report_reasons": null, "author": "biagio98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wh477/what_to_study_for_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wh477/what_to_study_for_interview/", "subreddit_subscribers": 914178, "created_utc": 1685524553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. I'm trying to create a LSTM that that takes in various inputs such as opening price, interest rate, consumer sentiment index, and EPS to predict the closing price of a stock. However, the problem is that some of these variables are recorded on a monthly basis and quarterly basis and I'm sure of how to incorporate all these different kinds of data together. \n\nFor some more information regarding my model, the model will take 3 months worth of data to predict 7 days of the closing price of APPL stock. This is for a project. Thank you for all your help.", "author_fullname": "t2_bmhe3y7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incorporating Quarterly, Monthly, and Daily Data Together", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wasqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685503116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;m trying to create a LSTM that that takes in various inputs such as opening price, interest rate, consumer sentiment index, and EPS to predict the closing price of a stock. However, the problem is that some of these variables are recorded on a monthly basis and quarterly basis and I&amp;#39;m sure of how to incorporate all these different kinds of data together. &lt;/p&gt;\n\n&lt;p&gt;For some more information regarding my model, the model will take 3 months worth of data to predict 7 days of the closing price of APPL stock. This is for a project. Thank you for all your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wasqm", "is_robot_indexable": true, "report_reasons": null, "author": "Successful-Fee4220", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wasqm/incorporating_quarterly_monthly_and_daily_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wasqm/incorporating_quarterly_monthly_and_daily_data/", "subreddit_subscribers": 914178, "created_utc": 1685503116.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}