{"kind": "Listing", "data": {"after": "t3_13wqchd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started working at a small analytics company, they haven't had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don't know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.", "author_fullname": "t2_3739kucg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would one write a data ETL pipeline in Javascript + SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w4yfp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685487592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working at a small analytics company, they haven&amp;#39;t had a data scientist or engineer on the team in a while, and basically, everything is written in extremely disorganized Javascript code with SQL sprinkled in. The current workflow is someone manually running these scripts to generate flat files, which they send off to clients. I am working on automating the entire process, but I don&amp;#39;t know any Javascript and parsing this code is extremely painful. Why would one write data analytics code in this way? Any tips on how to navigate this situation efficiently would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w4yfp", "is_robot_indexable": true, "report_reasons": null, "author": "Brown-Chemist99", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w4yfp/why_would_one_write_a_data_etl_pipeline_in/", "subreddit_subscribers": 914354, "created_utc": 1685487592.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best editor for Python in your opinion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wkkdv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685535246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wkkdv", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 128, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wkkdv/which_is_the_best_editor_for_python_in_your/", "subreddit_subscribers": 914354, "created_utc": 1685535246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It's not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   \n\n\nNow I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I'm confused if I should target product manager or core data science (ML heavy) roles. \n\n  \nI am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I'm a German, currently working in the UAE.) \n\nI feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you", "author_fullname": "t2_o08dc9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Manager vs Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wdyhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685512939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;little background: I am currently a data scientist at a small market research company. I have been a data analyst for a couple of years and then transitioned into a data scientist. My current role includes building pipelines, extracting data, cleaning, analyzing (using pandas, numpy, matplotlib) and building small models. It&amp;#39;s not focused on ML. The work is impactful for the org (I know exactly how much revenue the product brings etc.).   &lt;/p&gt;\n\n&lt;p&gt;Now I am thinking to apply for new roles. Reason - less salary and also feel like upskilling. But I&amp;#39;m confused if I should target product manager or core data science (ML heavy) roles. &lt;/p&gt;\n\n&lt;p&gt;I am good with people, I manage tasks well, I am also good with generating insights, and can persevere to learn new skills. I want a career that is more futuristic (given AI threats), something that has more visibility and good promotions, and also that can help me move around the world. (I&amp;#39;m a German, currently working in the UAE.) &lt;/p&gt;\n\n&lt;p&gt;I feel data careers provide more hard skills that allow you to get more opportunities around the world. Can someone please give me some perspectives? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wdyhl", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Wonder-342", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wdyhl/product_manager_vs_data_scientist/", "subreddit_subscribers": 914354, "created_utc": 1685512939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crops prediction with Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7srhy44w033b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/7srhy44w033b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02f3694cc239878ccf2a217aec626bb365be297"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/7srhy44w033b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c809c138766c4846e3956ee6e307f091cdbe5e62"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/7srhy44w033b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0914ed50006928f281a06956dd5c47453a937ef8"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/7srhy44w033b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96189182f829d41bb6d914ee482dfc4ee4e15ad6"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/7srhy44w033b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8779fcf97744747a8179cf975c729770e88266"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/7srhy44w033b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd037219cb6c71cdeb7f9024cf9db81157dba217"}], "s": {"y": 902, "x": 2500, "u": "https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c"}, "id": "7srhy44w033b1"}}, "name": "t3_13w3g3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2aTLJHuqZnjlHyX0Z1XFj9PDRRtHcyPFuhpMeYRg5xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c\"&gt;https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3g3h", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "subreddit_subscribers": 914354, "created_utc": 1685483880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.\n\nThanks \ud83d\ude0a", "author_fullname": "t2_aakdy8le7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most difficult data to collect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wns57", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685543267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In your jobs what data do you find most challenging to collect and wrange? Particularly interested in already structured data, but would be glad to hear any thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wns57", "is_robot_indexable": true, "report_reasons": null, "author": "TipAccomplished1946", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wns57/most_difficult_data_to_collect/", "subreddit_subscribers": 914354, "created_utc": 1685543267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use synthetic because there are no donor brands", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are trying to perform A/B test on a campaign with very low to no control population, we are thinking about CTGAN to generate synthetic data but control data we have has 50 data points at max...how to generate control data or conduct a successful A/B test. P.S Synthetic control is not an option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wcha5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685508131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use synthetic because there are no donor brands&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wcha5", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wcha5/we_are_trying_to_perform_ab_test_on_a_campaign/", "subreddit_subscribers": 914354, "created_utc": 1685508131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I'm really keen on making a switch to a data science role. I know there's a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.\n\nWhat's the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you'd suggest? I'm all ears for your insights and personal experiences!\n\nThanks in advance", "author_fullname": "t2_oumsxias", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from ETL Developer to Data Science: Seeking Advice on Skill Development and Learning Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13weulc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685516229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as an ETL developer for a while, using Cloud Data Integration for building ETL pipelines and Cloud Data Warehouse for SQL querying. But now, I&amp;#39;m really keen on making a switch to a data science role. I know there&amp;#39;s a bunch of hard skills I need to pick up before I can land a job in this field. So, I wanted to jump in here and ask for some advice on the best way to go about it.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the recommended order or sequence of things I should learn and practice to build a solid profile that will impress potential employers? Any specific resources, courses, or projects you&amp;#39;d suggest? I&amp;#39;m all ears for your insights and personal experiences!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13weulc", "is_robot_indexable": true, "report_reasons": null, "author": "vidit_108", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13weulc/transitioning_from_etl_developer_to_data_science/", "subreddit_subscribers": 914354, "created_utc": 1685516229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_m6kzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenAI\u2019s Sam Altman: No GPT-5 In Training As Of Yet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13wnbkv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EASoidy_f1eAZLpaoG57zE-E4gyHxLRe6E5NiUNIPSs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685542095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/inkwater-atlas/openais-sam-altman-no-gpt-5-in-training-as-of-yet-8ddf95b9b3d6", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?auto=webp&amp;v=enabled&amp;s=d28963286cd3255df665cc8a57858a580e38352b", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a94bfb0a6757261531a6334bf53bc0a87ca6344", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eca6e548d9d225f9943040e9f9316776d55ecc", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=222f3602a9520f7ac43e4f23be543a6851d84378", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=493adbae3aa1e88c003c0015c4034e789ed1d846", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5264174ef00a072c71ef0e309d6a8b89dbe43762", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/8zCuhNYuZ4e6m_2NbxAywt77jG8JLrLN4hZv8SYByjI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3055ebe01fb6e531882f2e580bc54c0ae43876b", "width": 1080, "height": 720}], "variants": {}, "id": "N5lb3eq-yiwMylcDE1BYnr_U6EGw281aw2FNnsBweuc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wnbkv", "is_robot_indexable": true, "report_reasons": null, "author": "liquidocelotYT", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wnbkv/openais_sam_altman_no_gpt5_in_training_as_of_yet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/inkwater-atlas/openais-sam-altman-no-gpt-5-in-training-as-of-yet-8ddf95b9b3d6", "subreddit_subscribers": 914354, "created_utc": 1685542095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "perhaps the term outliers isnt appropriate here\n\nwhat i did is calculated the shap value for each feature, then :\n\n\\- i took the feature with highest importance\n\n\\- i took the index of each value with negative shap in this feature\n\n\\- i recreated dataset with removing these indexes\n\nsince a negative shap means a datapoint is contributing negatively to the model, i removed it\n\nmy f1score increased from 70% to 90 % ( the data was imbalanced )\n\nis this a good implementation of shap?\n\nbecause its mostly used for model interpretation but i used it for different purpose\n\nthanks for advice", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using shap values for removing outliers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13ww38i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685562625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;perhaps the term outliers isnt appropriate here&lt;/p&gt;\n\n&lt;p&gt;what i did is calculated the shap value for each feature, then :&lt;/p&gt;\n\n&lt;p&gt;- i took the feature with highest importance&lt;/p&gt;\n\n&lt;p&gt;- i took the index of each value with negative shap in this feature&lt;/p&gt;\n\n&lt;p&gt;- i recreated dataset with removing these indexes&lt;/p&gt;\n\n&lt;p&gt;since a negative shap means a datapoint is contributing negatively to the model, i removed it&lt;/p&gt;\n\n&lt;p&gt;my f1score increased from 70% to 90 % ( the data was imbalanced )&lt;/p&gt;\n\n&lt;p&gt;is this a good implementation of shap?&lt;/p&gt;\n\n&lt;p&gt;because its mostly used for model interpretation but i used it for different purpose&lt;/p&gt;\n\n&lt;p&gt;thanks for advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ww38i", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ww38i/using_shap_values_for_removing_outliers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ww38i/using_shap_values_for_removing_outliers/", "subreddit_subscribers": 914354, "created_utc": 1685562625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I\u2019m a data scientist at a company and I have yet to do any real data science. Our company has a long history of hiring outside agencies to complete DS work (and all types of work, to be frank). Since I came to the company, there is a cycle where I think of a project and propose it, leadership loves it, and then they have me start the work before abruptly hiring an agency to complete the project. They do this about a week or two after I start the work, before I\u2019ve presented any results, so it\u2019s not like I\u2019m moving \u201ctoo slow\u201d (and for reference, these agencies usually take months to deliver results).\n\nIt\u2019s very frustrating. I\u2019ve not gotten a chance to deliver on any of my ideas. I\u2019m basically an overpaid data analyst who comes up with good ideas for someone else to execute.\n\nAnyway, it\u2019s just happened again on a project that I was excited about and really got going on. My boss wants me to hand over the analysis I\u2019ve already done to an agency to complete. Usually the agency just starts from scratch, so this request is new. I personally feel it\u2019s wrong; if you want the agency to handle the project, then they should do the work, not using my hard work that I\u2019ll get no credit for.\n\nI\u2019m going to hand over my work because I don\u2019t really have a choice, my work is company property, but I\u2019m beyond irritated.", "author_fullname": "t2_7ci7himt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Boss wants me to pass along my work for project completion by someone else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wsull", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685554944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I\u2019m a data scientist at a company and I have yet to do any real data science. Our company has a long history of hiring outside agencies to complete DS work (and all types of work, to be frank). Since I came to the company, there is a cycle where I think of a project and propose it, leadership loves it, and then they have me start the work before abruptly hiring an agency to complete the project. They do this about a week or two after I start the work, before I\u2019ve presented any results, so it\u2019s not like I\u2019m moving \u201ctoo slow\u201d (and for reference, these agencies usually take months to deliver results).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s very frustrating. I\u2019ve not gotten a chance to deliver on any of my ideas. I\u2019m basically an overpaid data analyst who comes up with good ideas for someone else to execute.&lt;/p&gt;\n\n&lt;p&gt;Anyway, it\u2019s just happened again on a project that I was excited about and really got going on. My boss wants me to hand over the analysis I\u2019ve already done to an agency to complete. Usually the agency just starts from scratch, so this request is new. I personally feel it\u2019s wrong; if you want the agency to handle the project, then they should do the work, not using my hard work that I\u2019ll get no credit for.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to hand over my work because I don\u2019t really have a choice, my work is company property, but I\u2019m beyond irritated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wsull", "is_robot_indexable": true, "report_reasons": null, "author": "njtw-1122", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wsull/boss_wants_me_to_pass_along_my_work_for_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wsull/boss_wants_me_to_pass_along_my_work_for_project/", "subreddit_subscribers": 914354, "created_utc": 1685554944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How are you supposed to randomize your groups in scenarios when certain groups can't be split up for a test? For example we may want to test conversion on local TV ad campaigns but can't randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?", "author_fullname": "t2_dayu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AB Test Randomization with Fixed Groups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wossp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685545671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you supposed to randomize your groups in scenarios when certain groups can&amp;#39;t be split up for a test? For example we may want to test conversion on local TV ad campaigns but can&amp;#39;t randomly assign variations to different individual households within the same local network. Do we just randomize the locations? What if we only have access to a small number of locations and certain locations are already known to convert less often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wossp", "is_robot_indexable": true, "report_reasons": null, "author": "TryWforWumbo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wossp/ab_test_randomization_with_fixed_groups/", "subreddit_subscribers": 914354, "created_utc": 1685545671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn't see much supplementary materials or articles on the internet explaining it.\n\nMaybe it's that simple and easy and I should probably leave this field, but that's for another time. I'll leave after understanding this paper. \n\nhere's the link if anyone is interested https://arxiv.org/pdf/1610.02136.pdf\n\n\nI understand PR Curves and ROC curves and softmax, but I just can't seem to follow what they are doing.\n\n-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. \n \n-For example, what does the value/score in even mean? I'm guessing value is the Area under the Curve, but what's the score? The base rate of the classes or something? https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\n\n-And I can't even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I'm guessing there is no need for thresholding? \n\n-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?\n\nWould really appreciate the help if possible. I think it's supposed to be a very easy paper which is discouraging but that's for another time....\n\nAnd sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it's a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.", "author_fullname": "t2_163jio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone read an old paper called \"Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13webkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685514278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this may not be the appropriate sub for this kind of question, but I am lost and discouraged and could really use your help. For such a landmark paper on the field(OOD or out of distribution), I didn&amp;#39;t see much supplementary materials or articles on the internet explaining it.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s that simple and easy and I should probably leave this field, but that&amp;#39;s for another time. I&amp;#39;ll leave after understanding this paper. &lt;/p&gt;\n\n&lt;p&gt;here&amp;#39;s the link if anyone is interested &lt;a href=\"https://arxiv.org/pdf/1610.02136.pdf\"&gt;https://arxiv.org/pdf/1610.02136.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand PR Curves and ROC curves and softmax, but I just can&amp;#39;t seem to follow what they are doing.&lt;/p&gt;\n\n&lt;p&gt;-THe whole convoluted set up of why they have separate metrics for correctly classifying whether the classifier that gets the answer correct and another two separate metrics of distinguishing in distribution datasets and out-of-distribution datasets. &lt;/p&gt;\n\n&lt;p&gt;-For example, what does the value/score in even mean? I&amp;#39;m guessing value is the Area under the Curve, but what&amp;#39;s the score? The base rate of the classes or something? &lt;a href=\"https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png\"&gt;https://d3i71xaburhd42.cloudfront.net/6ff2a434578ff2746b9283e45abf296887f48a2d/4-Table2-1.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-And I can&amp;#39;t even seem to understand how they classify the out of distribution samples with just using the softmax without some sort of thresholding. Since the metric is Area under the PR curve and Area under the ROC curve across all imaginary thresholding so I&amp;#39;m guessing there is no need for thresholding? &lt;/p&gt;\n\n&lt;p&gt;-and why do they take the negative scores of the out-of-distribution(OOD) test samples softmax output to determine if it is OOD or not?&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate the help if possible. I think it&amp;#39;s supposed to be a very easy paper which is discouraging but that&amp;#39;s for another time....&lt;/p&gt;\n\n&lt;p&gt;And sorry about the long winded rant, you will not understand my rambling unless you read the paper. But it&amp;#39;s a short read and not math or tech heavy so It shouldnt take too much time. Would really appreciate the input of someone smarter than me. \nthanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13webkb", "is_robot_indexable": true, "report_reasons": null, "author": "THE_REAL_ODB", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13webkb/has_anyone_read_an_old_paper_called_baseline_for/", "subreddit_subscribers": 914354, "created_utc": 1685514278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have land prices value of a region \\~400 data points, but recorded in different years, and some of them might be increased by 2-3x factor. I want to build a Land price prediction model based on this. How to proceed?", "author_fullname": "t2_7qfjqq47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Land Price prediciton", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13ww6z5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685562869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have land prices value of a region ~400 data points, but recorded in different years, and some of them might be increased by 2-3x factor. I want to build a Land price prediction model based on this. How to proceed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ww6z5", "is_robot_indexable": true, "report_reasons": null, "author": "Anu_Rag9704", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ww6z5/land_price_prediciton/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ww6z5/land_price_prediciton/", "subreddit_subscribers": 914354, "created_utc": 1685562869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been informed that projects include, Markeing Mix Modeling and using machine learning. How should I prepare for this?", "author_fullname": "t2_47f0qg1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I be expected to know / expect to do in a data science internship for a marketing company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wvpz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685561753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been informed that projects include, Markeing Mix Modeling and using machine learning. How should I prepare for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wvpz0", "is_robot_indexable": true, "report_reasons": null, "author": "IcyTitle1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wvpz0/what_should_i_be_expected_to_know_expect_to_do_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wvpz0/what_should_i_be_expected_to_know_expect_to_do_in/", "subreddit_subscribers": 914354, "created_utc": 1685561753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say you'd like to analyze behavior of users of an e-commerce shop. There are millions of daily active users. Given the compute power at hand, you have two options (or may be more?). First is to  take a small time period, say a week, and base your analysis on this one week for all users. Second is to take a much longer period, say a year, but choosing a smaller number of users. I understand that there are pros and cons to each method. But I would like to know what are the things that you take into account when making a choice.", "author_fullname": "t2_4oockqg5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Subsampling: small time period or sparse sampling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wvlzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685561492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say you&amp;#39;d like to analyze behavior of users of an e-commerce shop. There are millions of daily active users. Given the compute power at hand, you have two options (or may be more?). First is to  take a small time period, say a week, and base your analysis on this one week for all users. Second is to take a much longer period, say a year, but choosing a smaller number of users. I understand that there are pros and cons to each method. But I would like to know what are the things that you take into account when making a choice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wvlzr", "is_robot_indexable": true, "report_reasons": null, "author": "furioncruz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wvlzr/subsampling_small_time_period_or_sparse_sampling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wvlzr/subsampling_small_time_period_or_sparse_sampling/", "subreddit_subscribers": 914354, "created_utc": 1685561492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_585lv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bayesian Methods in Modern Marketing Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_13wuzz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5QgiixYjmTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Bayesian Methods in Modern Marketing Analytics\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Bayesian Methods in Modern Marketing Analytics", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5QgiixYjmTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Bayesian Methods in Modern Marketing Analytics\"&gt;&lt;/iframe&gt;", "author_name": "PyMC Labs", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/5QgiixYjmTM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@PyMCLabs"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5QgiixYjmTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Bayesian Methods in Modern Marketing Analytics\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13wuzz0", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WlNSCLiWsdo12FpAl7ccnrHdAEvHqPJY5dYnqNqITlo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685560098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=5QgiixYjmTM", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tQ88koHdnRbLzD4i-yVFqX2CbHD7UpsEj2CEorX9DdU.jpg?auto=webp&amp;v=enabled&amp;s=74d301f14b554c35dc33e8af944a1a460e034331", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/tQ88koHdnRbLzD4i-yVFqX2CbHD7UpsEj2CEorX9DdU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19c00a5785215527f66f50c51a8673ae134946ad", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/tQ88koHdnRbLzD4i-yVFqX2CbHD7UpsEj2CEorX9DdU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a7dd8e1506bd58b51463c7773aac0f50711f858", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/tQ88koHdnRbLzD4i-yVFqX2CbHD7UpsEj2CEorX9DdU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e96f590aba5151c96207dd903ba68bbd8b41a77", "width": 320, "height": 240}], "variants": {}, "id": "KeRPWz1_FDq-fQQiUTF2qY2Cqy7xC-e9q6vDM4lWGMw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wuzz0", "is_robot_indexable": true, "report_reasons": null, "author": "Zuricho", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wuzz0/bayesian_methods_in_modern_marketing_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=5QgiixYjmTM", "subreddit_subscribers": 914354, "created_utc": 1685560098.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Bayesian Methods in Modern Marketing Analytics", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/5QgiixYjmTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Bayesian Methods in Modern Marketing Analytics\"&gt;&lt;/iframe&gt;", "author_name": "PyMC Labs", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/5QgiixYjmTM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@PyMCLabs"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nSo I understand that in RD, there are several tables that contain data about an object (Customers, Orders).\n\nWithin those tables, in order to easily identify say a customer or order, we use keys to uniquely identify a customer or order. Without using keys, if we used something as in DOB/Order Status to identify an object, we come across duplicates but they are different customers/orders.\n\nI am getting lost in the connection between the different tables in an RD.\n\n1.\u00a0Are connections between tables made through adding a foreign key in an existing table [(Example)](https://imgur.com/a/0nJa4L9). Or do you take at least 2 primary keys and add them to a brand new table [(Example)](https://imgur.com/a/br3iP1Q)? Or both?\n\n2. When you add a foreign key to an existing table, is the other corresponding information about that key also added or just the key. For example, if I add a Customer ID key as a foreign key to a Order table, does it only bring over the Customer ID, or its corresponding data such as Name, Billing Address, ETC?\n\nThank you!", "author_fullname": "t2_5l285b5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relational Database - Am I misunderstanding connections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13wudqk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685558639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;So I understand that in RD, there are several tables that contain data about an object (Customers, Orders).&lt;/p&gt;\n\n&lt;p&gt;Within those tables, in order to easily identify say a customer or order, we use keys to uniquely identify a customer or order. Without using keys, if we used something as in DOB/Order Status to identify an object, we come across duplicates but they are different customers/orders.&lt;/p&gt;\n\n&lt;p&gt;I am getting lost in the connection between the different tables in an RD.&lt;/p&gt;\n\n&lt;p&gt;1.\u00a0Are connections between tables made through adding a foreign key in an existing table &lt;a href=\"https://imgur.com/a/0nJa4L9\"&gt;(Example)&lt;/a&gt;. Or do you take at least 2 primary keys and add them to a brand new table &lt;a href=\"https://imgur.com/a/br3iP1Q\"&gt;(Example)&lt;/a&gt;? Or both?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;When you add a foreign key to an existing table, is the other corresponding information about that key also added or just the key. For example, if I add a Customer ID key as a foreign key to a Order table, does it only bring over the Customer ID, or its corresponding data such as Name, Billing Address, ETC?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/79oly1-JX2mHcnc7i8ofImEx_0Aim0Mow55u3iEX4ZA.jpg?auto=webp&amp;v=enabled&amp;s=40340782d497b529e2bc3ae3bcb120423d763dad", "width": 904, "height": 810}, "resolutions": [{"url": "https://external-preview.redd.it/79oly1-JX2mHcnc7i8ofImEx_0Aim0Mow55u3iEX4ZA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5181154da4481752821a99ba300ce7fddd9bb9a", "width": 108, "height": 96}, {"url": "https://external-preview.redd.it/79oly1-JX2mHcnc7i8ofImEx_0Aim0Mow55u3iEX4ZA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1360339d8665e96394b95ac51249d3cf68f852d6", "width": 216, "height": 193}, {"url": "https://external-preview.redd.it/79oly1-JX2mHcnc7i8ofImEx_0Aim0Mow55u3iEX4ZA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbcc917c025fe4cb2147300e5384a29e69adee90", "width": 320, "height": 286}, {"url": "https://external-preview.redd.it/79oly1-JX2mHcnc7i8ofImEx_0Aim0Mow55u3iEX4ZA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=211e1d017c9462889ebfffba7c7d527dbfbc6808", "width": 640, "height": 573}], "variants": {}, "id": "C2AXxjtJcinDVuQMDGo18WD5hvEHB2xW_714EcdnkHE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wudqk", "is_robot_indexable": true, "report_reasons": null, "author": "htxastrowrld", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wudqk/relational_database_am_i_misunderstanding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wudqk/relational_database_am_i_misunderstanding/", "subreddit_subscribers": 914354, "created_utc": 1685558639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m just finished my junior year and am now in my final summer before graduation- with no internship. \n\ni feel like I\u2019m doing nothing\u2026because I am and so I don\u2019t want to waste this summer just because I didn\u2019t get an internship. \n\nWhat should I do? I know some people do projects, but how do I do that? Where do I go and how do I start? \n\nI know there are also a lot of data science boot camps- which are the most helpful and which do employers like to see? (And preferably very cheap or free) \n\nAny other suggestions?", "author_fullname": "t2_vojufwj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No internship- what should I do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wtfis", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685556331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m just finished my junior year and am now in my final summer before graduation- with no internship. &lt;/p&gt;\n\n&lt;p&gt;i feel like I\u2019m doing nothing\u2026because I am and so I don\u2019t want to waste this summer just because I didn\u2019t get an internship. &lt;/p&gt;\n\n&lt;p&gt;What should I do? I know some people do projects, but how do I do that? Where do I go and how do I start? &lt;/p&gt;\n\n&lt;p&gt;I know there are also a lot of data science boot camps- which are the most helpful and which do employers like to see? (And preferably very cheap or free) &lt;/p&gt;\n\n&lt;p&gt;Any other suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wtfis", "is_robot_indexable": true, "report_reasons": null, "author": "comfy_cozy_35", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wtfis/no_internship_what_should_i_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wtfis/no_internship_what_should_i_do/", "subreddit_subscribers": 914354, "created_utc": 1685556331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI have been doing data science for a little while now with no particular area of focus. I have worked on projects like record linkage, predicting sales volume, service ticket volume, and manufacturing defects but never causal inference. I recently got asked at work if I could take on a causal inference project and I want to check with all of you if the idea is feasible assuming we have the data to do it. The ask is to use causal inference to try and determine how many new clients we obtained because of our new product or how important it was to the acquisition of those new clients even if we cannot definitively say how many signed up because of it. Is this the correct application of causal inference?", "author_fullname": "t2_zivdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Causal Inference Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wsll5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685554334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been doing data science for a little while now with no particular area of focus. I have worked on projects like record linkage, predicting sales volume, service ticket volume, and manufacturing defects but never causal inference. I recently got asked at work if I could take on a causal inference project and I want to check with all of you if the idea is feasible assuming we have the data to do it. The ask is to use causal inference to try and determine how many new clients we obtained because of our new product or how important it was to the acquisition of those new clients even if we cannot definitively say how many signed up because of it. Is this the correct application of causal inference?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wsll5", "is_robot_indexable": true, "report_reasons": null, "author": "Meclimax", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wsll5/first_causal_inference_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wsll5/first_causal_inference_project/", "subreddit_subscribers": 914354, "created_utc": 1685554334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All. I\u2019m wondering what is the possible way to feed huge text to LLM so I could query it with custom questions and it will use the context of the entire document for each question or query?\n\nUnfortunately, all articles that I\u2019ve recently come across described the workflow on enhancing ChatGPT with custom text via the reduced summary of the document and prompting it for each query to keep the context. It does not look an option for me since the text is huge and I want to keep the details of the original document so the LLM can use it while building the answer.\n\nSo, I support the solution is to take some general-purpose LLM and fine-tune it (retrain) with my text to enhance the model? \nAny other solutions for the problem? Which LLM to use for that (any lightweight one that does not require huge resources to host it)?\n\nThanks!", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Augmenting LLM with my data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wrgiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685551707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I\u2019m wondering what is the possible way to feed huge text to LLM so I could query it with custom questions and it will use the context of the entire document for each question or query?&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, all articles that I\u2019ve recently come across described the workflow on enhancing ChatGPT with custom text via the reduced summary of the document and prompting it for each query to keep the context. It does not look an option for me since the text is huge and I want to keep the details of the original document so the LLM can use it while building the answer.&lt;/p&gt;\n\n&lt;p&gt;So, I support the solution is to take some general-purpose LLM and fine-tune it (retrain) with my text to enhance the model? \nAny other solutions for the problem? Which LLM to use for that (any lightweight one that does not require huge resources to host it)?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wrgiv", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wrgiv/augmenting_llm_with_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wrgiv/augmenting_llm_with_my_data/", "subreddit_subscribers": 914354, "created_utc": 1685551707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work on a data engineering team and love what I do and just graduated with a masters in data analytics which included several machine learning courses (done part time while I was still working full time). \nWe have a weekly data team training where someone in the department will present on a topic of their choice and the person coordinating has been asking me to present on a data science topic now that I finished my degree. \nWhat are a couple suggestions for quick but still interesting concepts that are easy to explain in a half hour session?\nThanks!", "author_fullname": "t2_bfa6tlx6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to Give Lessons On", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wrfym", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685551673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on a data engineering team and love what I do and just graduated with a masters in data analytics which included several machine learning courses (done part time while I was still working full time). \nWe have a weekly data team training where someone in the department will present on a topic of their choice and the person coordinating has been asking me to present on a data science topic now that I finished my degree. \nWhat are a couple suggestions for quick but still interesting concepts that are easy to explain in a half hour session?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wrfym", "is_robot_indexable": true, "report_reasons": null, "author": "Lost_Source824", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wrfym/what_to_give_lessons_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wrfym/what_to_give_lessons_on/", "subreddit_subscribers": 914354, "created_utc": 1685551673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I made the switch from fisheries management (population stats background) to data science last year after I got into a data science master's program, and happily finished my first year with a 4.0, I applied to many places and only got one interview who happened to not put up the correct job description and wanted someone with much more experience. I want to make it in data science, what kind of personal project would you recommend I do over the summer to prove that I actually know how to do things, I feel like I'm being brushed off because when I was applying for internships I only had officially completed one semester and was almost done with the second semester, and the only things in my portfolio were homework assignment and exam assignments. I would prefer to do it in Python since all of my background is in R I have almost nothing to show for my python work and a lot of jobs are asking for python not R.", "author_fullname": "t2_nypxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failed to get an internship how do I improve for next time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wqsnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685550199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made the switch from fisheries management (population stats background) to data science last year after I got into a data science master&amp;#39;s program, and happily finished my first year with a 4.0, I applied to many places and only got one interview who happened to not put up the correct job description and wanted someone with much more experience. I want to make it in data science, what kind of personal project would you recommend I do over the summer to prove that I actually know how to do things, I feel like I&amp;#39;m being brushed off because when I was applying for internships I only had officially completed one semester and was almost done with the second semester, and the only things in my portfolio were homework assignment and exam assignments. I would prefer to do it in Python since all of my background is in R I have almost nothing to show for my python work and a lot of jobs are asking for python not R.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqsnq", "is_robot_indexable": true, "report_reasons": null, "author": "Talonsoldat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqsnq/failed_to_get_an_internship_how_do_i_improve_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqsnq/failed_to_get_an_internship_how_do_i_improve_for/", "subreddit_subscribers": 914354, "created_utc": 1685550199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What do you do if you have 1-4 observations on a hundred separate occasions (it is basically event starts and has 7 steps with an exponentialish increase and then it ends and there are a few other features that influence it at each time period), what type of models can you use? \n\nMy instinct is to just line it up as a regression problem and put the observations as features, but I've been wondering if there is a better way to do it (I know there is a lot of research into arma/arima, can you use it for separate instances and combine it with other factors at each time step).\n\nI also feel like there might be some manufacturing optimisation model, but I haven't seen a practical suggestion", "author_fullname": "t2_23bi1gsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with a bunch of small time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wqqtv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685550083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you do if you have 1-4 observations on a hundred separate occasions (it is basically event starts and has 7 steps with an exponentialish increase and then it ends and there are a few other features that influence it at each time period), what type of models can you use? &lt;/p&gt;\n\n&lt;p&gt;My instinct is to just line it up as a regression problem and put the observations as features, but I&amp;#39;ve been wondering if there is a better way to do it (I know there is a lot of research into arma/arima, can you use it for separate instances and combine it with other factors at each time step).&lt;/p&gt;\n\n&lt;p&gt;I also feel like there might be some manufacturing optimisation model, but I haven&amp;#39;t seen a practical suggestion&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqqtv", "is_robot_indexable": true, "report_reasons": null, "author": "Alienbushman", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqqtv/what_do_you_do_with_a_bunch_of_small_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqqtv/what_do_you_do_with_a_bunch_of_small_time_series/", "subreddit_subscribers": 914354, "created_utc": 1685550083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9792cqxim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone published a library in python? if yes then how did you do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wqiyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685549596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqiyb", "is_robot_indexable": true, "report_reasons": null, "author": "Dipanshuz1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqiyb/has_anyone_published_a_library_in_python_if_yes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqiyb/has_anyone_published_a_library_in_python_if_yes/", "subreddit_subscribers": 914354, "created_utc": 1685549596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I use conda and want to have my code available in my environment \n\nWe currently have custom modules we implement and make them available with \"pip install -e .\" Inside of the env. \n\nAre there any tools to better manage dependencies?", "author_fullname": "t2_og7kb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best environment management tool, conda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wqchd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685549189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I use conda and want to have my code available in my environment &lt;/p&gt;\n\n&lt;p&gt;We currently have custom modules we implement and make them available with &amp;quot;pip install -e .&amp;quot; Inside of the env. &lt;/p&gt;\n\n&lt;p&gt;Are there any tools to better manage dependencies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wqchd", "is_robot_indexable": true, "report_reasons": null, "author": "siddartha08", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wqchd/best_environment_management_tool_conda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wqchd/best_environment_management_tool_conda/", "subreddit_subscribers": 914354, "created_utc": 1685549189.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}