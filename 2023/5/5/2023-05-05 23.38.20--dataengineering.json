{"kind": "Listing", "data": {"after": "t3_138h91z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cmjwin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Welcome to JOIN hell", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_138cvct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 137, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 137, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xQyfG35IzBPm3Bd09roABVBCsjbUt9UyepYWOweaic0.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683267755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ho2lxe3nhyxa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?auto=webp&amp;v=enabled&amp;s=727f6990522a563a26475da3dc0a7669c84a9e52", "width": 888, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44da424e0a5535937cb47679c80bf90a830f68cc", "width": 108, "height": 60}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78b3a3100c6566d4b12744aedf12cee8cc0d639a", "width": 216, "height": 121}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fa61eebd7eeffc7a1332751490306b87cd16fe5", "width": 320, "height": 180}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d41d5629da0dd96094d8ecbb5a25532db426677", "width": 640, "height": 360}], "variants": {}, "id": "CEt7hgNYbUxB-mmCkT92tqRtwZYchEZ9UEL-sZLG5io"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "138cvct", "is_robot_indexable": true, "report_reasons": null, "author": "tiltaltti", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138cvct/welcome_to_join_hell/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ho2lxe3nhyxa1.jpg", "subreddit_subscribers": 104217, "created_utc": 1683267755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Asking this question to open up a general discussion about how do we bring the DE team under the spotlight. The work done by DE team is critical to support the dashboards/ ML Models but rarely do we see recognition for the DEs. \nWhat are some of the ways through which you are handling this at your org?", "author_fullname": "t2_bjfbzxo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do You Bring Your DE Team Out of The Shadows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138l4yc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683291889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Asking this question to open up a general discussion about how do we bring the DE team under the spotlight. The work done by DE team is critical to support the dashboards/ ML Models but rarely do we see recognition for the DEs. \nWhat are some of the ways through which you are handling this at your org?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138l4yc", "is_robot_indexable": true, "report_reasons": null, "author": "booyahtech", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/138l4yc/how_do_you_bring_your_de_team_out_of_the_shadows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138l4yc/how_do_you_bring_your_de_team_out_of_the_shadows/", "subreddit_subscribers": 104217, "created_utc": 1683291889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently became a Data Engineer. I have experience in SWE and ML and wanted to study something different but helpful to Data Engineering. Just curious if cyber security is something that is useful to the role? Or anything else you guys recommend", "author_fullname": "t2_h256mca5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How useful is cyber security?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386r86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683250725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently became a Data Engineer. I have experience in SWE and ML and wanted to study something different but helpful to Data Engineering. Just curious if cyber security is something that is useful to the role? Or anything else you guys recommend&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1386r86", "is_robot_indexable": true, "report_reasons": null, "author": "ElasticCode", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1386r86/how_useful_is_cyber_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1386r86/how_useful_is_cyber_security/", "subreddit_subscribers": 104217, "created_utc": 1683250725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I also posted another version of this in r/Biostatistics. I'm currently deciding my next path in my career and I'm not ashamed to admit I value stability and good work-life balance over a higher salary (especially coming from a high stress career). Should I get an MS Biostatistics to be a biostatistician or an MS Data Science centered on DE (currently accepted but deferred to decide) to be a data engineer? I only want to work 9 to 5 and would like t to make at least six figures after some experience. Not sure if anyone has knowledge on how both fields compare to one another.", "author_fullname": "t2_at4evmor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overall, does Data Engineering provide a good work-life balance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138n3s4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683295092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I also posted another version of this in &lt;a href=\"/r/Biostatistics\"&gt;r/Biostatistics&lt;/a&gt;. I&amp;#39;m currently deciding my next path in my career and I&amp;#39;m not ashamed to admit I value stability and good work-life balance over a higher salary (especially coming from a high stress career). Should I get an MS Biostatistics to be a biostatistician or an MS Data Science centered on DE (currently accepted but deferred to decide) to be a data engineer? I only want to work 9 to 5 and would like t to make at least six figures after some experience. Not sure if anyone has knowledge on how both fields compare to one another.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138n3s4", "is_robot_indexable": true, "report_reasons": null, "author": "CDRSkywalker1991", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138n3s4/overall_does_data_engineering_provide_a_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138n3s4/overall_does_data_engineering_provide_a_good/", "subreddit_subscribers": 104217, "created_utc": 1683295092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/dataengineering + freddie mercury", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_138o36n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/4qdoecu6t0ya1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/4qdoecu6t0ya1/DASH_96.mp4", "dash_url": "https://v.redd.it/4qdoecu6t0ya1/DASHPlaylist.mpd?a=1685921900%2CMDRhOWZkNjYyNjdmM2VhNDllY2Q0ZTYxMjU4NjI4ZDI5YmQ0ZDA2NjM2ZTIyNWU3ODk5ZTAzMTg2MmVhNWJjNw%3D%3D&amp;v=1&amp;f=sd", "duration": 68, "hls_url": "https://v.redd.it/4qdoecu6t0ya1/HLSPlaylist.m3u8?a=1685921900%2CM2I2ZmMyNjZhOTk1YWQxZjk2OTE0NTZiMGI2MTlhN2ViMjY2ZmJiNTVlMTk1NGE0MjU0ZDlhN2M5YjExZjhmYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Rv9bMTYvx4x4gfyv9b5lMh_m5ntetLZXW__jcCef_vM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683295961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/4qdoecu6t0ya1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=984f4b8bda0bf952f4760c95bc3c159ee7d15318", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4879f850c9a4d4a1b2261df030dc40ae8ffc68de", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3351d734d6f695bfce05448fe8eee20a120eb53e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6f84f63c2a915a1497b924e2dc1f09336dea4925", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d248f0d2453862ae97de522b6414835589fd4b1a", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=55352f9fdf6fc0dfef94dde1ddd69b3b53c6d4b6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/f1wuqKUWBJnZmyg5jdMMu3-FFXEr5p0Ikm2BjqN-O1c.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d7e98d94fc39f64664c205f63be5c1b9fc78d205", "width": 1080, "height": 607}], "variants": {}, "id": "bqQGH1qA15r8yfJjr66aclLOJK-rg4IMPKewzLhzCAA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "138o36n", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138o36n/rdataengineering_freddie_mercury/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/4qdoecu6t0ya1", "subreddit_subscribers": 104217, "created_utc": 1683295961.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/4qdoecu6t0ya1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/4qdoecu6t0ya1/DASH_96.mp4", "dash_url": "https://v.redd.it/4qdoecu6t0ya1/DASHPlaylist.mpd?a=1685921900%2CMDRhOWZkNjYyNjdmM2VhNDllY2Q0ZTYxMjU4NjI4ZDI5YmQ0ZDA2NjM2ZTIyNWU3ODk5ZTAzMTg2MmVhNWJjNw%3D%3D&amp;v=1&amp;f=sd", "duration": 68, "hls_url": "https://v.redd.it/4qdoecu6t0ya1/HLSPlaylist.m3u8?a=1685921900%2CM2I2ZmMyNjZhOTk1YWQxZjk2OTE0NTZiMGI2MTlhN2ViMjY2ZmJiNTVlMTk1NGE0MjU0ZDlhN2M5YjExZjhmYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently I've talked to a few (non-technical) stakeholders who are very excited about integrating tools that are some version of \"point generative AI at your warehouse\" ([Hex](https://app.hex.tech/), [Defog](https://defog.ai/)) for *end users.* So that a user could essentially just submit a questions to #databot and get an answer.\n\nI've watched some demos, read a bit of documentation and it just seems like the excitement is out of line with reality. Like, allowing any user to map their ambiguous text questions to explicit analytical code answers seems like an absolute nightmare. Just imagining the scenarios like \"person X and Y asked #databot how many unique users churned from the platform last week and got different answers, how come?\" makes my skin crawl. Seems like the only use case would be a really clean/standardized data model or maybe as a productivity tool for data teams...\n\nAm I missing something? Has anyone used one of these tools? Are they better than I'm giving them credit for?", "author_fullname": "t2_2gln0h10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about peoples experience with generative ai to facilitate data access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386w68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683251088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I&amp;#39;ve talked to a few (non-technical) stakeholders who are very excited about integrating tools that are some version of &amp;quot;point generative AI at your warehouse&amp;quot; (&lt;a href=\"https://app.hex.tech/\"&gt;Hex&lt;/a&gt;, &lt;a href=\"https://defog.ai/\"&gt;Defog&lt;/a&gt;) for &lt;em&gt;end users.&lt;/em&gt; So that a user could essentially just submit a questions to #databot and get an answer.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve watched some demos, read a bit of documentation and it just seems like the excitement is out of line with reality. Like, allowing any user to map their ambiguous text questions to explicit analytical code answers seems like an absolute nightmare. Just imagining the scenarios like &amp;quot;person X and Y asked #databot how many unique users churned from the platform last week and got different answers, how come?&amp;quot; makes my skin crawl. Seems like the only use case would be a really clean/standardized data model or maybe as a productivity tool for data teams...&lt;/p&gt;\n\n&lt;p&gt;Am I missing something? Has anyone used one of these tools? Are they better than I&amp;#39;m giving them credit for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1386w68", "is_robot_indexable": true, "report_reasons": null, "author": "poopybutbaby", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1386w68/curious_about_peoples_experience_with_generative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1386w68/curious_about_peoples_experience_with_generative/", "subreddit_subscribers": 104217, "created_utc": 1683251088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm going through the AWS Glue scripts of my company and I see the module \"awsglue\". What's inside it? I go in circles in their documentation and I search for it and I cannot find any details on it. I google \"awsglue documentation aws glue\" and find nothing. It's only when I look at the pip page do I see a link to the Github which lists the classes in it. \n\n&amp;#x200B;\n\nI see a \"DynamicFrame\" class in the Github page, so I go to the API reference in the documentation. Its  table of contents is massive and impossible to scroll through. I Ctrl-F \"DynamicFrame\". It doesn't exist. I search \"DynamicFrame\" in the search bar, and the documentation is put in some separate area called \"PySpark Extensions\" Why is this not in a central location?\n\n&amp;#x200B;\n\nSo now I want to find details on the \"Job\" class because its in the script im studying. Where do I go? There's no central documentation. I have no idea which section of the website to click to. I search \"Job\" in the search bar, and ofc, I can't find any details because the word \"Job\" is in EVERY SINGLE PAGE\n\n&amp;#x200B;\n\nLike, i've been having issues finding stuff on documentation my whole life so part of this is probably my fault but still ahhhh im frustrated", "author_fullname": "t2_i56iqon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or is the AWS Glue documentation kind of bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138vov9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683308114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going through the AWS Glue scripts of my company and I see the module &amp;quot;awsglue&amp;quot;. What&amp;#39;s inside it? I go in circles in their documentation and I search for it and I cannot find any details on it. I google &amp;quot;awsglue documentation aws glue&amp;quot; and find nothing. It&amp;#39;s only when I look at the pip page do I see a link to the Github which lists the classes in it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I see a &amp;quot;DynamicFrame&amp;quot; class in the Github page, so I go to the API reference in the documentation. Its  table of contents is massive and impossible to scroll through. I Ctrl-F &amp;quot;DynamicFrame&amp;quot;. It doesn&amp;#39;t exist. I search &amp;quot;DynamicFrame&amp;quot; in the search bar, and the documentation is put in some separate area called &amp;quot;PySpark Extensions&amp;quot; Why is this not in a central location?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So now I want to find details on the &amp;quot;Job&amp;quot; class because its in the script im studying. Where do I go? There&amp;#39;s no central documentation. I have no idea which section of the website to click to. I search &amp;quot;Job&amp;quot; in the search bar, and ofc, I can&amp;#39;t find any details because the word &amp;quot;Job&amp;quot; is in EVERY SINGLE PAGE&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Like, i&amp;#39;ve been having issues finding stuff on documentation my whole life so part of this is probably my fault but still ahhhh im frustrated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138vov9", "is_robot_indexable": true, "report_reasons": null, "author": "DoubleDual63", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138vov9/is_it_me_or_is_the_aws_glue_documentation_kind_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138vov9/is_it_me_or_is_the_aws_glue_documentation_kind_of/", "subreddit_subscribers": 104217, "created_utc": 1683308114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!!\n\nI'm looking to read about softwares (early/growth stage) in the DataOps space that allow Data Engineers to predict their monthly or quarterly spend on Data Warehousing tools like Snowflake, BigQuery, Redshift etc.\n\nI've come across Finout and YellowBrick that have similar offerings, but I was wondering in case anyone here uses any specific tools that I should  probably read about.", "author_fullname": "t2_uyy7iz4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any software that can help you predict the cost of your data warehousing tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1392aqm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683322799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to read about softwares (early/growth stage) in the DataOps space that allow Data Engineers to predict their monthly or quarterly spend on Data Warehousing tools like Snowflake, BigQuery, Redshift etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come across Finout and YellowBrick that have similar offerings, but I was wondering in case anyone here uses any specific tools that I should  probably read about.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1392aqm", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayugrad22", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1392aqm/any_software_that_can_help_you_predict_the_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1392aqm/any_software_that_can_help_you_predict_the_cost/", "subreddit_subscribers": 104217, "created_utc": 1683322799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have an analyst that made a lot of transformations through pandas in a notebook file on their laptop locally. Now they want to schedule it and we have an airflow instance up and running. What's the recommendation? Package the module up as a lambda (aws) or cloud function (GCP) to be called?", "author_fullname": "t2_9mgcm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you typically offload pandas compute when using Airflow to orchestrate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138zxpi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683317573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have an analyst that made a lot of transformations through pandas in a notebook file on their laptop locally. Now they want to schedule it and we have an airflow instance up and running. What&amp;#39;s the recommendation? Package the module up as a lambda (aws) or cloud function (GCP) to be called?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138zxpi", "is_robot_indexable": true, "report_reasons": null, "author": "tonguewin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138zxpi/where_do_you_typically_offload_pandas_compute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138zxpi/where_do_you_typically_offload_pandas_compute/", "subreddit_subscribers": 104217, "created_utc": 1683317573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Imagine a typical situation where one has a `sales` fact table and multiple dimensional tables such as `product` and `product_category`, with `product` having a many-to-one relation with `product_category`.\n\nYou extract this data from your transactional data store, so everything is in 3NF, and you set `product` and `product_category` to be SCD type 2.\n\nThen in your mart you want to create the table `product_with_category`.\n\nThe question is, what is the recommended approach / practice to join these 2 tables? I understand that the join must consider the validity period of both each `product` row and each `product_category` row, and return the intersection between the two, but I am not exactly sure how to handle this situation (e.g. should one use surrogate keys, is the data range sufficient, etc...).\n\nPlease let me know how you approach this!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are joins organized between 2+ dimensional tables with SCD type 2?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138igwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683285172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Imagine a typical situation where one has a &lt;code&gt;sales&lt;/code&gt; fact table and multiple dimensional tables such as &lt;code&gt;product&lt;/code&gt; and &lt;code&gt;product_category&lt;/code&gt;, with &lt;code&gt;product&lt;/code&gt; having a many-to-one relation with &lt;code&gt;product_category&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;You extract this data from your transactional data store, so everything is in 3NF, and you set &lt;code&gt;product&lt;/code&gt; and &lt;code&gt;product_category&lt;/code&gt; to be SCD type 2.&lt;/p&gt;\n\n&lt;p&gt;Then in your mart you want to create the table &lt;code&gt;product_with_category&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;The question is, what is the recommended approach / practice to join these 2 tables? I understand that the join must consider the validity period of both each &lt;code&gt;product&lt;/code&gt; row and each &lt;code&gt;product_category&lt;/code&gt; row, and return the intersection between the two, but I am not exactly sure how to handle this situation (e.g. should one use surrogate keys, is the data range sufficient, etc...).&lt;/p&gt;\n\n&lt;p&gt;Please let me know how you approach this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138igwm", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138igwm/how_are_joins_organized_between_2_dimensional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138igwm/how_are_joins_organized_between_2_dimensional/", "subreddit_subscribers": 104217, "created_utc": 1683285172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you had the choice and 6 months of free time, which data tool would you build/fix/rewrite and why?\n\nSerious responses only, please.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Data tool/product would you build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138734e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683251608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you had the choice and 6 months of free time, which data tool would you build/fix/rewrite and why?&lt;/p&gt;\n\n&lt;p&gt;Serious responses only, please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138734e", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138734e/what_data_toolproduct_would_you_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138734e/what_data_toolproduct_would_you_build/", "subreddit_subscribers": 104217, "created_utc": 1683251608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says... I can't think of a reason why CDC would ever not be the \"gold standard\" for any ELT data integration processes? I can understand that in some scenarios, CDC may not be possible, how would you have a proper EL process without CDC?\n\nThe only other patterns I can think of would be:\n\n1. You can schedule a full source database scan during off-hours and simply replace all of the tables in the destination, but this would be far too inefficient. Even worse, for global companies, there aren't really any \"off-hours\" that a job like this could run during. Even more, you would lose any ability to analyze the history of something with a changing state, for example: open orders on July 1st in 2019, or customers who had an address change. I don't see how you would handle SCDs with this full \"flush as replace\" pattern. Lastly, you can forget about low-latency analytics, I think that is obviously a true statement.\n2. Something better would be to ingest records that have a \"modified\\_at\" column where I could create an extractor to just extract records that have been modified since the last extraction, and then upsert those changes into my destination tables. I think it would be very wishful to think that every table has a column like this to begin with. I could also handle SCD's to flag an updates to a record as \"current\". Also, what if there are multiple state changes between extraction jobs? This pattern would only pick up the most recent state of a record, which could be bad. Finally, I suppose you can have more frequent \"micro-batches\" that issues a SELECT query to all tables every 5 minutes to get the newly modified records, but this seems quite inefficient.\n3. The only other option (I can think of) would be CDC. Every data mutation to a source table is considered an event that would create a message in a queue. Subscribers would get notified to persist the mutation into the target location. Every mutation is captured in the order that it occurred, so analysts could then analyze any data at any state at a given point of time.", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would you ever not use CDC for ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1393kdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683325698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says... I can&amp;#39;t think of a reason why CDC would ever not be the &amp;quot;gold standard&amp;quot; for any ELT data integration processes? I can understand that in some scenarios, CDC may not be possible, how would you have a proper EL process without CDC?&lt;/p&gt;\n\n&lt;p&gt;The only other patterns I can think of would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;You can schedule a full source database scan during off-hours and simply replace all of the tables in the destination, but this would be far too inefficient. Even worse, for global companies, there aren&amp;#39;t really any &amp;quot;off-hours&amp;quot; that a job like this could run during. Even more, you would lose any ability to analyze the history of something with a changing state, for example: open orders on July 1st in 2019, or customers who had an address change. I don&amp;#39;t see how you would handle SCDs with this full &amp;quot;flush as replace&amp;quot; pattern. Lastly, you can forget about low-latency analytics, I think that is obviously a true statement.&lt;/li&gt;\n&lt;li&gt;Something better would be to ingest records that have a &amp;quot;modified_at&amp;quot; column where I could create an extractor to just extract records that have been modified since the last extraction, and then upsert those changes into my destination tables. I think it would be very wishful to think that every table has a column like this to begin with. I could also handle SCD&amp;#39;s to flag an updates to a record as &amp;quot;current&amp;quot;. Also, what if there are multiple state changes between extraction jobs? This pattern would only pick up the most recent state of a record, which could be bad. Finally, I suppose you can have more frequent &amp;quot;micro-batches&amp;quot; that issues a SELECT query to all tables every 5 minutes to get the newly modified records, but this seems quite inefficient.&lt;/li&gt;\n&lt;li&gt;The only other option (I can think of) would be CDC. Every data mutation to a source table is considered an event that would create a message in a queue. Subscribers would get notified to persist the mutation into the target location. Every mutation is captured in the order that it occurred, so analysts could then analyze any data at any state at a given point of time.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1393kdj", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1393kdj/why_would_you_ever_not_use_cdc_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1393kdj/why_would_you_ever_not_use_cdc_for_elt/", "subreddit_subscribers": 104217, "created_utc": 1683325698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a lot of older oracle databases that have no primary keys or changed time stamps on the tables. Some are small enough that they could be pulled and the comparison can be done upstream. But we have larger 100 million row tables that it would put too much strain on the system during business hours.", "author_fullname": "t2_723xj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How have you handled source extraction from transactional databases that don\u2019t high water marks available?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138wcgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683309582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a lot of older oracle databases that have no primary keys or changed time stamps on the tables. Some are small enough that they could be pulled and the comparison can be done upstream. But we have larger 100 million row tables that it would put too much strain on the system during business hours.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138wcgg", "is_robot_indexable": true, "report_reasons": null, "author": "JustSittin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138wcgg/how_have_you_handled_source_extraction_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138wcgg/how_have_you_handled_source_extraction_from/", "subreddit_subscribers": 104217, "created_utc": 1683309582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a business graduate from college. Somehow i ended up getting a DE position. I\u2019m currently in my project for almost 2 years now, but still dont know what the hell im doing. I\u2019m given tasks, and maybe 2hrs of training before doing those. I\u2019m really lost and would like to improve on my skills. Here\u2019s a general idea of what im doing :\n\n- updating yaml files\n- hql\n- cdp\n- linux\n- hdfs\n- sql\n- a bit of talend( i just follow a guide )\n\nIs it a good idea to start sharpening my sql skills and start diving into python?? Thanks", "author_fullname": "t2_lcfxg0hw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m lost - need guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138lunh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683293533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a business graduate from college. Somehow i ended up getting a DE position. I\u2019m currently in my project for almost 2 years now, but still dont know what the hell im doing. I\u2019m given tasks, and maybe 2hrs of training before doing those. I\u2019m really lost and would like to improve on my skills. Here\u2019s a general idea of what im doing :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;updating yaml files&lt;/li&gt;\n&lt;li&gt;hql&lt;/li&gt;\n&lt;li&gt;cdp&lt;/li&gt;\n&lt;li&gt;linux&lt;/li&gt;\n&lt;li&gt;hdfs&lt;/li&gt;\n&lt;li&gt;sql&lt;/li&gt;\n&lt;li&gt;a bit of talend( i just follow a guide )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is it a good idea to start sharpening my sql skills and start diving into python?? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138lunh", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Loan-8060", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138lunh/im_lost_need_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138lunh/im_lost_need_guidance/", "subreddit_subscribers": 104217, "created_utc": 1683293533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adopting Apache arrow for ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_138f03f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hS_y8t94AP1dAs88_MpRIKqGmc0SctZ2BVv1nIIBYnc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683274621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arrow.apache.org", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arrow.apache.org/blog/2023/05/04/adopting-apache-arrow-at-cloudquery/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?auto=webp&amp;v=enabled&amp;s=90564d1040201ce8db134ebce49959eaeceae067", "width": 1800, "height": 936}, "resolutions": [{"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0feee992df675372bd136f2b9d218fac510db429", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8909c3aff2cc9b636ea2ff770f5e649114d1dd5", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f90141496369ee8286a3b47c5037956aab818c66", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f0ccbfcfc7f9e43ac2771261477e4906dbb9daa", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb23457cd1609a53963cdf4d5dff1513058e1f10", "width": 960, "height": 499}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ded3ac959f0c28f5943b8d80bb2853d346dab86", "width": 1080, "height": 561}], "variants": {}, "id": "tgQE8dETOzO_PokwPLeRbf3ODtZN7Y-KrsIZVY72CKM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "138f03f", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138f03f/adopting_apache_arrow_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arrow.apache.org/blog/2023/05/04/adopting-apache-arrow-at-cloudquery/", "subreddit_subscribers": 104217, "created_utc": 1683274621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "is there a way I can enable or add a macro command at model folder level that runs after each model materialization execution like I need to insert a record with dynamic runtime values into a custom audit log table like row count, time stamp etc\n\nHow do you guys capture custom process or audit log in dbt?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we add custom Audit logging in dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138eo3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683273523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is there a way I can enable or add a macro command at model folder level that runs after each model materialization execution like I need to insert a record with dynamic runtime values into a custom audit log table like row count, time stamp etc&lt;/p&gt;\n\n&lt;p&gt;How do you guys capture custom process or audit log in dbt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138eo3m", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138eo3m/how_can_we_add_custom_audit_logging_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138eo3m/how_can_we_add_custom_audit_logging_in_dbt/", "subreddit_subscribers": 104217, "created_utc": 1683273523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks\n\nCurrently in a DE junior role. But the role is not so interesting. Not big data tools that I'm getting assigned to work on. Thought of doing certifications but, gone through alot of posts here against that. Finally doing a project on pyspark and some BI reporting. I have basics or intermediate excercise exp. But all the job postings on LinkedIn or portals req exp atleast 2 years. \nNow I'm thinking of applying to python developer positions rather than DE ones. Or should I try data analyst roles ?? ( I want to work closely with business so that my doings are useful and impactful).", "author_fullname": "t2_8dll0cj72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Transition Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138aw5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683261733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks&lt;/p&gt;\n\n&lt;p&gt;Currently in a DE junior role. But the role is not so interesting. Not big data tools that I&amp;#39;m getting assigned to work on. Thought of doing certifications but, gone through alot of posts here against that. Finally doing a project on pyspark and some BI reporting. I have basics or intermediate excercise exp. But all the job postings on LinkedIn or portals req exp atleast 2 years. \nNow I&amp;#39;m thinking of applying to python developer positions rather than DE ones. Or should I try data analyst roles ?? ( I want to work closely with business so that my doings are useful and impactful).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "138aw5n", "is_robot_indexable": true, "report_reasons": null, "author": "Secret_While3350", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138aw5n/job_transition_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138aw5n/job_transition_help/", "subreddit_subscribers": 104217, "created_utc": 1683261733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working for a consultancy for 1.5 years as a DE, and it's been chaotic with three projects running simultaneously. \nI have to investigate where the data is, catalogue everything, create pipelines, code business rules... everything has to be done urgently. \n\nI'm just a few months away from being promoted and earning the Senior title  but I'm not sure if I want to be promoted. I would like to go somewhere else, negotiate a better salary as a mid-level professional. But at the same time, wouldn't the Senior title be useful in the future? \n\nThe best downside would be that I would become a Senior with Junior-level experience, which would mean being held accountable as a Senior and having even more tasks as a Junior behind the scenes. I don't know\u2026", "author_fullname": "t2_827bi0bz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need an outside perspective", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1391w1e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683321899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working for a consultancy for 1.5 years as a DE, and it&amp;#39;s been chaotic with three projects running simultaneously. \nI have to investigate where the data is, catalogue everything, create pipelines, code business rules... everything has to be done urgently. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just a few months away from being promoted and earning the Senior title  but I&amp;#39;m not sure if I want to be promoted. I would like to go somewhere else, negotiate a better salary as a mid-level professional. But at the same time, wouldn&amp;#39;t the Senior title be useful in the future? &lt;/p&gt;\n\n&lt;p&gt;The best downside would be that I would become a Senior with Junior-level experience, which would mean being held accountable as a Senior and having even more tasks as a Junior behind the scenes. I don&amp;#39;t know\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1391w1e", "is_robot_indexable": true, "report_reasons": null, "author": "Obvious_Mood_2190", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1391w1e/i_need_an_outside_perspective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1391w1e/i_need_an_outside_perspective/", "subreddit_subscribers": 104217, "created_utc": 1683321899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mastering Collaboration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13907si", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yhGWF19pEu9wcdLYCEr3-akO_GfDso641KW8mZcqUnw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683318203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/ZgYNyheUyzb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?auto=webp&amp;v=enabled&amp;s=663b93e3d4d2fe96109ce2f640446fa12fa136f0", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2bc6d61ad4d79e874a13983efc2efd85ce84121", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38a43e00ce712d13718bd9b23ae487ae5f0089b2", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f88f7f7266de11bb44d8b7c2d40eb507d307d92", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e553741e9f4ba9efd1953b9e231effc732ad1a9", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe1be054de83410f32c528daa0e44cb8cb5ef65b", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/0yTnMWxjNz2D14eF33Xsm3ULuR5zndCvyDYZEI3RdPE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4776c324055fcfbb940cc6e2d8a82f7f05bc2a68", "width": 1080, "height": 720}], "variants": {}, "id": "SdNt0f5axGYmxOdN6MdFFu-RkFsGdn56cEaH1ms91co"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13907si", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13907si/mastering_collaboration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/ZgYNyheUyzb", "subreddit_subscribers": 104217, "created_utc": 1683318203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm finishing a data science master's soon, and after working as an analyst and interacting with data engineers and data scientists, I think I am more drawn to data engineering.\n\nI am looking to complete a project to learn some new skills and bolster my resume. I'm looking for feedback on the project:\n\nDesired skills to learn: interacting with APIs, AWS, pipelines, containers\n\nGoal: \n\nBuild database of most upvoted comments for hottest Reddit posts and display the database on my personal website\n\nStrategy: \n\nExtract: For a specific subreddit, extract the most upvoted comment for each of the top 10 hottest posts from Reddit's API. \n\nLoad: Load the post title : comment combos into DynamoDB\n\nPipeline/container (still struggling with understanding this part): trigger the ETL code via AWS lambda once a week\nDisplay on website: TBD\n\nProgress: \n\nfinished the code for extracting most upvoted comments, researching how to push them into DynamoDB. \n\nI used the PRAW python reddit api wrapper. Is that cheating myself out of learning api's, or is the setup basically the same? Haven't worked with APIs at all before.\n\nWould really appreciate if anyone sees an obvious error in my approach, especially related to the pipeline/container part. \n\nTIA!", "author_fullname": "t2_j3ecksk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Feedback for Resume Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138xngn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683312860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683312441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m finishing a data science master&amp;#39;s soon, and after working as an analyst and interacting with data engineers and data scientists, I think I am more drawn to data engineering.&lt;/p&gt;\n\n&lt;p&gt;I am looking to complete a project to learn some new skills and bolster my resume. I&amp;#39;m looking for feedback on the project:&lt;/p&gt;\n\n&lt;p&gt;Desired skills to learn: interacting with APIs, AWS, pipelines, containers&lt;/p&gt;\n\n&lt;p&gt;Goal: &lt;/p&gt;\n\n&lt;p&gt;Build database of most upvoted comments for hottest Reddit posts and display the database on my personal website&lt;/p&gt;\n\n&lt;p&gt;Strategy: &lt;/p&gt;\n\n&lt;p&gt;Extract: For a specific subreddit, extract the most upvoted comment for each of the top 10 hottest posts from Reddit&amp;#39;s API. &lt;/p&gt;\n\n&lt;p&gt;Load: Load the post title : comment combos into DynamoDB&lt;/p&gt;\n\n&lt;p&gt;Pipeline/container (still struggling with understanding this part): trigger the ETL code via AWS lambda once a week\nDisplay on website: TBD&lt;/p&gt;\n\n&lt;p&gt;Progress: &lt;/p&gt;\n\n&lt;p&gt;finished the code for extracting most upvoted comments, researching how to push them into DynamoDB. &lt;/p&gt;\n\n&lt;p&gt;I used the PRAW python reddit api wrapper. Is that cheating myself out of learning api&amp;#39;s, or is the setup basically the same? Haven&amp;#39;t worked with APIs at all before.&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate if anyone sees an obvious error in my approach, especially related to the pipeline/container part. &lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138xngn", "is_robot_indexable": true, "report_reasons": null, "author": "SellGameRent", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138xngn/project_feedback_for_resume_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138xngn/project_feedback_for_resume_portfolio/", "subreddit_subscribers": 104217, "created_utc": 1683312441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't remember where I read this: deep-tech jobs are recession proof given how specialised and essential for the business they are. Is this true? What would you consider deep-tech when it comes to data engineering?", "author_fullname": "t2_6960i650", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is considered deep-tech in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138tnnk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683303738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t remember where I read this: deep-tech jobs are recession proof given how specialised and essential for the business they are. Is this true? What would you consider deep-tech when it comes to data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138tnnk", "is_robot_indexable": true, "report_reasons": null, "author": "TheBrownViking20", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138tnnk/what_is_considered_deeptech_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138tnnk/what_is_considered_deeptech_in_data_engineering/", "subreddit_subscribers": 104217, "created_utc": 1683303738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone suggest a good tutorial or course on Apache NiFi. We use NiFi in my current job, though I don't have to work on it, I'm needed to debug the flows once in a while.\nIf anyone could suggest a good learning resource it would be of great helps.\nThanks!", "author_fullname": "t2_k3zy67lu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache NiFi learning resources.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138s4rv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683300455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone suggest a good tutorial or course on Apache NiFi. We use NiFi in my current job, though I don&amp;#39;t have to work on it, I&amp;#39;m needed to debug the flows once in a while.\nIf anyone could suggest a good learning resource it would be of great helps.\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138s4rv", "is_robot_indexable": true, "report_reasons": null, "author": "i_wadkar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138s4rv/apache_nifi_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138s4rv/apache_nifi_learning_resources/", "subreddit_subscribers": 104217, "created_utc": 1683300455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently doing an adhoc evaluation on what to move our DE application towards. It seems to me that moving onto some kind of Spark solution will give us more control on the RDD level, but Snowpark looks like it could be easier to get up and running, with the potential drawback that it might not be as fast as Spark. I'm primarily focused on ease of development and ease of maintenance.\n\nAnyone have any thoughts or opinions on this? I'm slightly leaning towards Snowpark because most of the data we use is already in Snowflake, and it seems easier to setup compared to Glue/Databricks.", "author_fullname": "t2_78wsb0ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpark vs AWS Glue/Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138l2xo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683291764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently doing an adhoc evaluation on what to move our DE application towards. It seems to me that moving onto some kind of Spark solution will give us more control on the RDD level, but Snowpark looks like it could be easier to get up and running, with the potential drawback that it might not be as fast as Spark. I&amp;#39;m primarily focused on ease of development and ease of maintenance.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any thoughts or opinions on this? I&amp;#39;m slightly leaning towards Snowpark because most of the data we use is already in Snowflake, and it seems easier to setup compared to Glue/Databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138l2xo", "is_robot_indexable": true, "report_reasons": null, "author": "neuralscattered", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138l2xo/snowpark_vs_aws_gluedatabricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138l2xo/snowpark_vs_aws_gluedatabricks/", "subreddit_subscribers": 104217, "created_utc": 1683291764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just like most users of spark are pyspark, I thought flink would have quite a few users, even if pylink wasn't the trend, but I looked it up and found out that it wasn't.\n\nAccording to the community posts, there is a lack of support and performance for python. is that real?\n\nDoes anyone actually use pyflink at work?\n\nJava is terrible for me", "author_fullname": "t2_6pkq7jrch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is pyflink a bad choice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138juv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683288845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just like most users of spark are pyspark, I thought flink would have quite a few users, even if pylink wasn&amp;#39;t the trend, but I looked it up and found out that it wasn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;According to the community posts, there is a lack of support and performance for python. is that real?&lt;/p&gt;\n\n&lt;p&gt;Does anyone actually use pyflink at work?&lt;/p&gt;\n\n&lt;p&gt;Java is terrible for me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138juv8", "is_robot_indexable": true, "report_reasons": null, "author": "Hankaul", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138juv8/is_pyflink_a_bad_choice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138juv8/is_pyflink_a_bad_choice/", "subreddit_subscribers": 104217, "created_utc": 1683288845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Iam doing a POC on databricks and am very new to this.\n\nSo I wanted to pull data from IBM AS400 system on to Databricks.\n\n I believe it requires establishing a jdbc connection, but I couldn't find much details online.\n\nHas anyone worked on similar request?", "author_fullname": "t2_9fr6if3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AS400 to Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138h91z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683281631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Iam doing a POC on databricks and am very new to this.&lt;/p&gt;\n\n&lt;p&gt;So I wanted to pull data from IBM AS400 system on to Databricks.&lt;/p&gt;\n\n&lt;p&gt;I believe it requires establishing a jdbc connection, but I couldn&amp;#39;t find much details online.&lt;/p&gt;\n\n&lt;p&gt;Has anyone worked on similar request?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138h91z", "is_robot_indexable": true, "report_reasons": null, "author": "aj_here_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138h91z/as400_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138h91z/as400_to_databricks/", "subreddit_subscribers": 104217, "created_utc": 1683281631.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}