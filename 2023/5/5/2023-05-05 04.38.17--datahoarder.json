{"kind": "Listing", "data": {"after": "t3_137o5v1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1a927l58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze Drive Stats for Q1 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_137ph3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 244, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 244, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V8o7cXx1QEk8lEkn7a2F7atC7Yu4_vyb9x78iRqIlzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683213195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "backblaze.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.backblaze.com/blog/backblaze-drive-stats-for-q1-2023/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?auto=webp&amp;v=enabled&amp;s=7e0fbaa59bc74324c931fc919ce4ce4b6fc47713", "width": 1440, "height": 820}, "resolutions": [{"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b593ab5ad325fba3286ead5f7ec500d855b87080", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b195378190a30a40018bfbdff1ea752e274eedf8", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4daeb1ff1c2e8a4f02e3214dbbd3be9991e43041", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccbae6ca1eed6a581cb6cb40006908cc05b8f6e6", "width": 640, "height": 364}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17a17b35c344a41142aa16f52565d84a08b8df62", "width": 960, "height": 546}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91d94c5d5d95d67b5faca45296142c45adf1dfbc", "width": 1080, "height": 615}], "variants": {}, "id": "m0ieKlY8zlIxLzAoz0IgGYiLvyxDDRZuQnsTWWjU0PI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137ph3i", "is_robot_indexable": true, "report_reasons": null, "author": "g0rbe", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137ph3i/backblaze_drive_stats_for_q1_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.backblaze.com/blog/backblaze-drive-stats-for-q1-2023/", "subreddit_subscribers": 680829, "created_utc": 1683213195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I archive YouTube livestreams on my PC by using ytarchive (channel monitor function) running 24/7. But my PC is pretty high end and I don't necessarily want it running 24/7 just for this purpose. I was thinking of getting a cheap laptop just for running the livestream archiving program, but I heard laptops aren't great for 24/7 use (but they can be purchased for pretty cheap!) because of dust and fans being difficult to replace. Any suggestions from other data hoarders?", "author_fullname": "t2_14zhkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap computer for archiving livestreams: any experiences/suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137t6c9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683219540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I archive YouTube livestreams on my PC by using ytarchive (channel monitor function) running 24/7. But my PC is pretty high end and I don&amp;#39;t necessarily want it running 24/7 just for this purpose. I was thinking of getting a cheap laptop just for running the livestream archiving program, but I heard laptops aren&amp;#39;t great for 24/7 use (but they can be purchased for pretty cheap!) because of dust and fans being difficult to replace. Any suggestions from other data hoarders?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137t6c9", "is_robot_indexable": true, "report_reasons": null, "author": "fenrisulfr-pnw", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137t6c9/cheap_computer_for_archiving_livestreams_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137t6c9/cheap_computer_for_archiving_livestreams_any/", "subreddit_subscribers": 680829, "created_utc": 1683219540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was originally going to grab a 12TB Exos off of Server Part Deals, but after further research, these \"enterprise tier\" drives are apparently super noisy and vibrate a lot, even at idle, and I'm not looking to buy a NAS setup anytime soon. I only have so much money and I just want a cheap and quick fix for the time being.\n\nI want something with a lot of storage that I can stick directly into my PC and not be any nosier than my two old 1TB HDDs already are. For reference, my drives aren't any louder than my CPU cooler (Dark Rock Pro 4) or case fans when I'm idle, and aren't that much louder than them when writing either.\n\nI'm mainly going to be using this new drive to store unimportant videos and miscellaneous files, so it doesn't need to be fast. I'm hoping that I can get one at a good price ($100 - $150 range). Any ideas? Would a Barracuda be better in this instance with the slower RPM?\n\nUnfortunately, anything above 8TB seems to be exponentially more expensive on Amazon, but I can live with just 8TB for years to come. I mainly just want the extra storage for convenience as my +5 years of hoarding have only just started to max out my whopping 3TB total of drives.\n\nThanks in advance!", "author_fullname": "t2_1azvp51y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New and clueless buyer looking for a quiet HDD.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dqg4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683186900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was originally going to grab a 12TB Exos off of Server Part Deals, but after further research, these &amp;quot;enterprise tier&amp;quot; drives are apparently super noisy and vibrate a lot, even at idle, and I&amp;#39;m not looking to buy a NAS setup anytime soon. I only have so much money and I just want a cheap and quick fix for the time being.&lt;/p&gt;\n\n&lt;p&gt;I want something with a lot of storage that I can stick directly into my PC and not be any nosier than my two old 1TB HDDs already are. For reference, my drives aren&amp;#39;t any louder than my CPU cooler (Dark Rock Pro 4) or case fans when I&amp;#39;m idle, and aren&amp;#39;t that much louder than them when writing either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m mainly going to be using this new drive to store unimportant videos and miscellaneous files, so it doesn&amp;#39;t need to be fast. I&amp;#39;m hoping that I can get one at a good price ($100 - $150 range). Any ideas? Would a Barracuda be better in this instance with the slower RPM?&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, anything above 8TB seems to be exponentially more expensive on Amazon, but I can live with just 8TB for years to come. I mainly just want the extra storage for convenience as my +5 years of hoarding have only just started to max out my whopping 3TB total of drives.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137dqg4", "is_robot_indexable": true, "report_reasons": null, "author": "xYamax", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137dqg4/new_and_clueless_buyer_looking_for_a_quiet_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137dqg4/new_and_clueless_buyer_looking_for_a_quiet_hdd/", "subreddit_subscribers": 680829, "created_utc": 1683186900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\\- \"A what now?\"\n\nHear me out. I keep backup of my music archive on external HDD at work, but I need to sync them from time to time, to add new music. I have VPN access, but I don't want to use work network for that task. Now, I use Total Commander Synchronize Dirs, left is remote, right is local, I sync them, and when I get results of what needs to be copied from home to work, I just choose USB stick as destination, and it copies the files and folders, whole needed tree, there. At work I just copy paste.\n\n\\- \"There you are\", I hear, \"you have a working solution, what do you need?\"\n\nSometimes, I change the folder names or move folders to another genre folders. Or, just rename the folder. So if I just copy from source to destination, I'd have duplicates. There are more situations like that.\n\nWhat would help me is Robocopy with MIR option, to copy the difference, delete the extra data in destination, but to make some sort of batch file that could be executed and move difference files from local source to destination folder, and delete all extra files in destination that don't exist in source.\n\nAre you aware of tool like that?", "author_fullname": "t2_jign0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Offline synchronization tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137yvxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683232007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;- &amp;quot;A what now?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Hear me out. I keep backup of my music archive on external HDD at work, but I need to sync them from time to time, to add new music. I have VPN access, but I don&amp;#39;t want to use work network for that task. Now, I use Total Commander Synchronize Dirs, left is remote, right is local, I sync them, and when I get results of what needs to be copied from home to work, I just choose USB stick as destination, and it copies the files and folders, whole needed tree, there. At work I just copy paste.&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;There you are&amp;quot;, I hear, &amp;quot;you have a working solution, what do you need?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Sometimes, I change the folder names or move folders to another genre folders. Or, just rename the folder. So if I just copy from source to destination, I&amp;#39;d have duplicates. There are more situations like that.&lt;/p&gt;\n\n&lt;p&gt;What would help me is Robocopy with MIR option, to copy the difference, delete the extra data in destination, but to make some sort of batch file that could be executed and move difference files from local source to destination folder, and delete all extra files in destination that don&amp;#39;t exist in source.&lt;/p&gt;\n\n&lt;p&gt;Are you aware of tool like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137yvxj", "is_robot_indexable": true, "report_reasons": null, "author": "hlloyge", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137yvxj/offline_synchronization_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137yvxj/offline_synchronization_tool/", "subreddit_subscribers": 680829, "created_utc": 1683232007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi. I have an UnRAID NAS and for backups I have a 5-bay external drive enclosure (\\*) plugged into a separate Windows PC. I use FreeFile sync to periodically drag everything across the network and to the external hard drives.\n\nNow, I am intending long-term to build a backup NAS and then sync between the two, but for the time being I'm going to continue using this enclosure.\n\nMy question is this: rather than have my NAS shares backed up to individual disks on the 5-drive bay, is there any software for Windows that will allow me to reliably combine the drives into a JBOD (or similar) pool so I can backup everything to one disk instead of splitting it across 5? I used to use Drive Bender years ago but I don't know if there's a modern equivalent that will work with a bunch of external drives.\n\nIf there's backup solution I can implement by plugging the 5-drive bay into my UnRaid system itself I'd be keen to hear about it.\n\nThanks\n\n&amp;#x200B;\n\n* [https://www.amazon.com.au/ORICO-External-Enclosure-Support-Aluminum/dp/B08621Z2R6/ref=asc\\_df\\_B08621Z2R6?hvadid=80333197552957&amp;hvnetw=s&amp;hvqmt=e&amp;hvbmt=be&amp;hvdev=c&amp;hvlocint=&amp;hvlocphy=&amp;hvtargid=pla-4583932718159284&amp;th=1](https://www.amazon.com.au/ORICO-External-Enclosure-Support-Aluminum/dp/B08621Z2R6/ref=asc_df_B08621Z2R6?hvadid=80333197552957&amp;hvnetw=s&amp;hvqmt=e&amp;hvbmt=be&amp;hvdev=c&amp;hvlocint=&amp;hvlocphy=&amp;hvtargid=pla-4583932718159284&amp;th=1)", "author_fullname": "t2_qf82z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up to multiple external drives - pooling software?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1384tj6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683245603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have an UnRAID NAS and for backups I have a 5-bay external drive enclosure (*) plugged into a separate Windows PC. I use FreeFile sync to periodically drag everything across the network and to the external hard drives.&lt;/p&gt;\n\n&lt;p&gt;Now, I am intending long-term to build a backup NAS and then sync between the two, but for the time being I&amp;#39;m going to continue using this enclosure.&lt;/p&gt;\n\n&lt;p&gt;My question is this: rather than have my NAS shares backed up to individual disks on the 5-drive bay, is there any software for Windows that will allow me to reliably combine the drives into a JBOD (or similar) pool so I can backup everything to one disk instead of splitting it across 5? I used to use Drive Bender years ago but I don&amp;#39;t know if there&amp;#39;s a modern equivalent that will work with a bunch of external drives.&lt;/p&gt;\n\n&lt;p&gt;If there&amp;#39;s backup solution I can implement by plugging the 5-drive bay into my UnRaid system itself I&amp;#39;d be keen to hear about it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.com.au/ORICO-External-Enclosure-Support-Aluminum/dp/B08621Z2R6/ref=asc_df_B08621Z2R6?hvadid=80333197552957&amp;amp;hvnetw=s&amp;amp;hvqmt=e&amp;amp;hvbmt=be&amp;amp;hvdev=c&amp;amp;hvlocint=&amp;amp;hvlocphy=&amp;amp;hvtargid=pla-4583932718159284&amp;amp;th=1\"&gt;https://www.amazon.com.au/ORICO-External-Enclosure-Support-Aluminum/dp/B08621Z2R6/ref=asc_df_B08621Z2R6?hvadid=80333197552957&amp;amp;hvnetw=s&amp;amp;hvqmt=e&amp;amp;hvbmt=be&amp;amp;hvdev=c&amp;amp;hvlocint=&amp;amp;hvlocphy=&amp;amp;hvtargid=pla-4583932718159284&amp;amp;th=1&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1384tj6", "is_robot_indexable": true, "report_reasons": null, "author": "WhatAGoodDoggy", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1384tj6/backing_up_to_multiple_external_drives_pooling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1384tj6/backing_up_to_multiple_external_drives_pooling/", "subreddit_subscribers": 680829, "created_utc": 1683245603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 4 TB .tar file of all my research files from graduate school which currently sits on Google Drive. I need to transfer it from Google Drive to somewhere else as my storage is winding down. I do not need regular access to the research files and only need it somewhere as a backup for the future.\n\nIs there a cost effective way to have the 4 TB sent somewhere for cold storage? thanks", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a cost-effective way to store 4 TB in cold storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1388a9y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683254636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 4 TB .tar file of all my research files from graduate school which currently sits on Google Drive. I need to transfer it from Google Drive to somewhere else as my storage is winding down. I do not need regular access to the research files and only need it somewhere as a backup for the future.&lt;/p&gt;\n\n&lt;p&gt;Is there a cost effective way to have the 4 TB sent somewhere for cold storage? thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1388a9y", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1388a9y/what_is_a_costeffective_way_to_store_4_tb_in_cold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1388a9y/what_is_a_costeffective_way_to_store_4_tb_in_cold/", "subreddit_subscribers": 680829, "created_utc": 1683254636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey yall I did some searching around a bit and searched this sub a bit but I am looking for suggestions on where you'd recommend the best cloud provider for someone who's looking to backup a lot of personal data (around 35TB) without completely breaking the bank.\n\nFirst, I will say that I find it humorous that I am asking about storage on Reddit.. I personally work as a Storage architect and live in the world of on-prem storage, but have very little experience in cloud providers and what they offer. I do know the S3 API quite well as one of the technologies I support and design around is Ceph and it heavily supports S3...Anyways I love storage and if I don't stop now I will ramble way too much on this post.\n\nSo, I have built a really great Plex library for myself after ripping my entire DVD and blu-ray collection and have a really robust multi VDEV raidz2 array to host all of this along with stuff for my homelab.\n\nWhen I first started this project I used to think.. whatever, I don't need a backup.. I don't care that much about this data, its just for fun, so if I somehow lose data with my RAIDZ2 array then it must have been fate LOL... But as time has gone on and I have continued to add more and more rips into this server, I have started to care more and more and now I really want to make sure I don't lose this data.\n\n&amp;#x200B;\n\nSo... I have heard Backblaze offers a \"unlimited\" type package for personal... but I was just wondering if anyone has any experience with this, and would my use case actually fall under this type of deal or is there another provider that can offer 30-40TB backup at a low cost?\n\nThanks yall!", "author_fullname": "t2_4pwfwueb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud storage provider for personal with high storage limits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1385e34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683247087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey yall I did some searching around a bit and searched this sub a bit but I am looking for suggestions on where you&amp;#39;d recommend the best cloud provider for someone who&amp;#39;s looking to backup a lot of personal data (around 35TB) without completely breaking the bank.&lt;/p&gt;\n\n&lt;p&gt;First, I will say that I find it humorous that I am asking about storage on Reddit.. I personally work as a Storage architect and live in the world of on-prem storage, but have very little experience in cloud providers and what they offer. I do know the S3 API quite well as one of the technologies I support and design around is Ceph and it heavily supports S3...Anyways I love storage and if I don&amp;#39;t stop now I will ramble way too much on this post.&lt;/p&gt;\n\n&lt;p&gt;So, I have built a really great Plex library for myself after ripping my entire DVD and blu-ray collection and have a really robust multi VDEV raidz2 array to host all of this along with stuff for my homelab.&lt;/p&gt;\n\n&lt;p&gt;When I first started this project I used to think.. whatever, I don&amp;#39;t need a backup.. I don&amp;#39;t care that much about this data, its just for fun, so if I somehow lose data with my RAIDZ2 array then it must have been fate LOL... But as time has gone on and I have continued to add more and more rips into this server, I have started to care more and more and now I really want to make sure I don&amp;#39;t lose this data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So... I have heard Backblaze offers a &amp;quot;unlimited&amp;quot; type package for personal... but I was just wondering if anyone has any experience with this, and would my use case actually fall under this type of deal or is there another provider that can offer 30-40TB backup at a low cost?&lt;/p&gt;\n\n&lt;p&gt;Thanks yall!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1385e34", "is_robot_indexable": true, "report_reasons": null, "author": "DividedbyPi", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1385e34/cloud_storage_provider_for_personal_with_high/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1385e34/cloud_storage_provider_for_personal_with_high/", "subreddit_subscribers": 680829, "created_utc": 1683247087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "this is how OS identifies the bridge:\n\n\n\n    May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_GETMAXLUN set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\n    May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_PREVENT_ALLOW set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\n    May  4 15:37:58 NomadBSD kernel: ugen0.3: &lt;JMicron JMS567&gt; at usbus0\n    May  4 15:37:58 NomadBSD kernel: umass2 on uhub0\n    May  4 15:37:58 NomadBSD kernel: umass2: &lt;JMicron JMS567, class 0/0, rev 2.10/66.01, addr 2&gt; on usbus0\n    May  4 15:37:58 NomadBSD kernel: umass2:  SCSI over Bulk-Only; quirks = 0x8100\n    May  4 15:37:58 NomadBSD kernel: umass2:4:2: Attached to scbus4\n    May  4 15:37:58 NomadBSD kernel: da2 at umass-sim2 bus 2 scbus4 target 0 lun 0\n    May  4 15:37:58 NomadBSD kernel: da2: &lt;ST1000LM 024 HN-M101MBB 6601&gt; Fixed Direct Access SPC-4 SCSI device\n    May  4 15:37:58 NomadBSD kernel: da2: Serial Number DB9876543211545\n    May  4 15:37:58 NomadBSD kernel: da2: 40.000MB/s transfers\n    May  4 15:37:58 NomadBSD kernel: da2: 953869MB (1953525168 512 byte sectors)\n    May  4 15:37:58 NomadBSD kernel: da2: quirks=0x2&lt;NO_6_BYTE&gt;\n\n\n\nwhen issuing normal inquiry, smartctl says:\n\n\n    /dev/da2: Unknown USB bridge [0x7825:0xa2a4 (0x6601)]\n    Please specify device type with the -d option.\n\n\nthe only way to get anything from the drive is through:\n\n\n    root@NomadBSD:~ # smartctl -d sat,auto -a /dev/da2\n    smartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n    \n    === START OF INFORMATION SECTION ===\n    Vendor:               ST1000LM\n    Product:              024 HN-M101MBB\n    Revision:             6601\n    Compliance:           SPC-4\n    User Capacity:        1,000,204,886,016 bytes [1.00 TB]\n    &lt;snip&gt;\n\n\n\nunfortunately -A (get attributes) doesn't work - prints just the header... one would think that maybe specifying **usbjmicron** would be any better, but nada... it can't even open the device with this type (subparameters p and 0 don't work either):\n\n\n    root@NomadBSD:~ # smartctl -d usbjmicron -a /dev/da2\n    smartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n    \n    Smartctl open device: /dev/da2 [USB JMicron] failed: No device connected\n    \n\n\ni know that it is possible to get through this bridge - other programs are able to read SMART attributes (like CrystalDiskInfo or Victoria).\n\nis there *any* other way? maybe somebody has the same enclosure (bridge) and figured this out?", "author_fullname": "t2_14uv2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "get SMART attributes (via smartctl) through JMicron JMS567 USB bridge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137na7l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683211045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;this is how OS identifies the bridge:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_GETMAXLUN set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\nMay  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_PREVENT_ALLOW set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\nMay  4 15:37:58 NomadBSD kernel: ugen0.3: &amp;lt;JMicron JMS567&amp;gt; at usbus0\nMay  4 15:37:58 NomadBSD kernel: umass2 on uhub0\nMay  4 15:37:58 NomadBSD kernel: umass2: &amp;lt;JMicron JMS567, class 0/0, rev 2.10/66.01, addr 2&amp;gt; on usbus0\nMay  4 15:37:58 NomadBSD kernel: umass2:  SCSI over Bulk-Only; quirks = 0x8100\nMay  4 15:37:58 NomadBSD kernel: umass2:4:2: Attached to scbus4\nMay  4 15:37:58 NomadBSD kernel: da2 at umass-sim2 bus 2 scbus4 target 0 lun 0\nMay  4 15:37:58 NomadBSD kernel: da2: &amp;lt;ST1000LM 024 HN-M101MBB 6601&amp;gt; Fixed Direct Access SPC-4 SCSI device\nMay  4 15:37:58 NomadBSD kernel: da2: Serial Number DB9876543211545\nMay  4 15:37:58 NomadBSD kernel: da2: 40.000MB/s transfers\nMay  4 15:37:58 NomadBSD kernel: da2: 953869MB (1953525168 512 byte sectors)\nMay  4 15:37:58 NomadBSD kernel: da2: quirks=0x2&amp;lt;NO_6_BYTE&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;when issuing normal inquiry, smartctl says:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;/dev/da2: Unknown USB bridge [0x7825:0xa2a4 (0x6601)]\nPlease specify device type with the -d option.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;the only way to get anything from the drive is through:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root@NomadBSD:~ # smartctl -d sat,auto -a /dev/da2\nsmartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n\n=== START OF INFORMATION SECTION ===\nVendor:               ST1000LM\nProduct:              024 HN-M101MBB\nRevision:             6601\nCompliance:           SPC-4\nUser Capacity:        1,000,204,886,016 bytes [1.00 TB]\n&amp;lt;snip&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;unfortunately -A (get attributes) doesn&amp;#39;t work - prints just the header... one would think that maybe specifying &lt;strong&gt;usbjmicron&lt;/strong&gt; would be any better, but nada... it can&amp;#39;t even open the device with this type (subparameters p and 0 don&amp;#39;t work either):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root@NomadBSD:~ # smartctl -d usbjmicron -a /dev/da2\nsmartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n\nSmartctl open device: /dev/da2 [USB JMicron] failed: No device connected\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;i know that it is possible to get through this bridge - other programs are able to read SMART attributes (like CrystalDiskInfo or Victoria).&lt;/p&gt;\n\n&lt;p&gt;is there &lt;em&gt;any&lt;/em&gt; other way? maybe somebody has the same enclosure (bridge) and figured this out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137na7l", "is_robot_indexable": true, "report_reasons": null, "author": "paprok", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137na7l/get_smart_attributes_via_smartctl_through_jmicron/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137na7l/get_smart_attributes_via_smartctl_through_jmicron/", "subreddit_subscribers": 680829, "created_utc": 1683211045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Would this be a good idea? I was just going to use a cheap RCA to HDMI converter and a capture card but thought this would be more strait forward.", "author_fullname": "t2_dajs338x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Would this work for VHS digitizing with my PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"a1et2l1cnxxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59db3ffaeb3cb6663bd7ce5a24b1be7c2118757c"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbea6ece242b244b031a7d2bb6d81b8676d3bc07"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e4781b1497538678c1a1f0d1d6337e5f983ec7a"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f22f6172eb59ae857c9aea8aad1d875223abce5"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d668b0c7872343c05049e0d02830ccfc5f2b7f4b"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad307339b73984766f32cf977b6a423a4c8b1764"}], "s": {"y": 3120, "x": 1440, "u": "https://preview.redd.it/a1et2l1cnxxa1.png?width=1440&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d78f441dae85a72cb2dd4a4784470bb7c743509e"}, "id": "a1et2l1cnxxa1"}, "4xxdblrbnxxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42749dcbd398ce4456c690601cba8d227afa865b"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a30ffdc5488e83f09dd98b3f57a9a29d06eee23f"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab3f51accb33213df28cc3632ab53690adcfdc89"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=386cb0ad41abbace4f0fa349ece9a023486f9e8c"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e270fbf493238537a5d8993d41ddfd21c19bb04"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c41c8a56a8f73297cd3b5c7241759a93119bdeb2"}], "s": {"y": 3120, "x": 1440, "u": "https://preview.redd.it/4xxdblrbnxxa1.png?width=1440&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0c8e2117cdf560589d8ff64fe0f4d63ac27057e0"}, "id": "4xxdblrbnxxa1"}}, "name": "t3_1389fvj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "4xxdblrbnxxa1", "id": 271310533}, {"media_id": "a1et2l1cnxxa1", "id": 271310534}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HiihONk_oniMxXkdnzTgATCRGcCh6RzhZoq9_Iqy9Lk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683257532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would this be a good idea? I was just going to use a cheap RCA to HDMI converter and a capture card but thought this would be more strait forward.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1389fvj", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1389fvj", "is_robot_indexable": true, "report_reasons": null, "author": "AverageShitass", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1389fvj/would_this_work_for_vhs_digitizing_with_my_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1389fvj", "subreddit_subscribers": 680829, "created_utc": 1683257532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys, first time posting here. I have 4 14TB HDDs. I want to use them to hoard data like movies, songs, pics etc. It's mainly for backup including PC images. I don't want to buy a box just for them. My computer can handle these HDDs and I'd rather them be in my main desktop given my \"on the move\" situation. \n\n&amp;#x200B;\n\nI had actually set up the first RAID 1 pair through my Intel Motherboard. But then I thought about what would happen if I had to replace my mobo and/or if I upgrade my system to maybe an AMD one if they offered the best performance and I realized after googling that it can be tricky. And it seems most people discourage MB RAID. \n\n&amp;#x200B;\n\nMy question is, what route should I go? SInce these are 14TB drives, I want to mirror their data in pairs since losing 14TB of data is costly. So 2 RAID 1 arrays. I want to keep it as simple as possible and I want to be able to easily move the mirrored pairs to a new system should I encounter a motherboard issue OR do an upgrade.\n\n&amp;#x200B;\n\nAnother thing is that I have two different verisons of Windows 10 on my machine and in the future it might become dual booting Windows 10 and Windows 11 or doing a triple booting with Windows 10, 11 and a Linux image. THis is why I initially went with a motherboard approach. I figured it would be tricky to do Windows OS RAID when I have dual/tri booting system. \n\nShould I find a RAID card and if so, what do you recommend? If not what other routes should I go? I'm open to anythig that's not very expensive.", "author_fullname": "t2_5mp54o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2xRAID 1, Should Should I use Motherboard or Software or RAID card? Or something else", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386rfv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683250742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, first time posting here. I have 4 14TB HDDs. I want to use them to hoard data like movies, songs, pics etc. It&amp;#39;s mainly for backup including PC images. I don&amp;#39;t want to buy a box just for them. My computer can handle these HDDs and I&amp;#39;d rather them be in my main desktop given my &amp;quot;on the move&amp;quot; situation. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I had actually set up the first RAID 1 pair through my Intel Motherboard. But then I thought about what would happen if I had to replace my mobo and/or if I upgrade my system to maybe an AMD one if they offered the best performance and I realized after googling that it can be tricky. And it seems most people discourage MB RAID. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is, what route should I go? SInce these are 14TB drives, I want to mirror their data in pairs since losing 14TB of data is costly. So 2 RAID 1 arrays. I want to keep it as simple as possible and I want to be able to easily move the mirrored pairs to a new system should I encounter a motherboard issue OR do an upgrade.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Another thing is that I have two different verisons of Windows 10 on my machine and in the future it might become dual booting Windows 10 and Windows 11 or doing a triple booting with Windows 10, 11 and a Linux image. THis is why I initially went with a motherboard approach. I figured it would be tricky to do Windows OS RAID when I have dual/tri booting system. &lt;/p&gt;\n\n&lt;p&gt;Should I find a RAID card and if so, what do you recommend? If not what other routes should I go? I&amp;#39;m open to anythig that&amp;#39;s not very expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1386rfv", "is_robot_indexable": true, "report_reasons": null, "author": "chineke14", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1386rfv/2xraid_1_should_should_i_use_motherboard_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1386rfv/2xraid_1_should_should_i_use_motherboard_or/", "subreddit_subscribers": 680829, "created_utc": 1683250742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planning to build my own NAS system that runs mainly for Plex but also a little bit of something else.\n\nSince I'm going to put the system in my own room, I was planning to get the WD Red Plus with 8TB that runs at 5640RPM as it should technically be much quieter than those 7200RPM ones.\n\nHowever, as I was reading WD's specification about their drives, I learned that apparently the 12TB and above ones are all heliosealed and should be even quieter than the 8TB one according to their own documents.\n\nMeanwhile, I'm can still read from some places that the 12TB ones can still be quite annoying as you can hear high pitch noise from them.\n\nNow I'm just really confused and really need someone who actually owns both of them to give me their suggestions.\n\ntl;dr I'd like to know the quietest HDD with large capacity.", "author_fullname": "t2_k3g4b5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noise level 5640RPM air-sealed vs 7200RPM heliosealed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dxc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683187528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning to build my own NAS system that runs mainly for Plex but also a little bit of something else.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m going to put the system in my own room, I was planning to get the WD Red Plus with 8TB that runs at 5640RPM as it should technically be much quieter than those 7200RPM ones.&lt;/p&gt;\n\n&lt;p&gt;However, as I was reading WD&amp;#39;s specification about their drives, I learned that apparently the 12TB and above ones are all heliosealed and should be even quieter than the 8TB one according to their own documents.&lt;/p&gt;\n\n&lt;p&gt;Meanwhile, I&amp;#39;m can still read from some places that the 12TB ones can still be quite annoying as you can hear high pitch noise from them.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m just really confused and really need someone who actually owns both of them to give me their suggestions.&lt;/p&gt;\n\n&lt;p&gt;tl;dr I&amp;#39;d like to know the quietest HDD with large capacity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137dxc9", "is_robot_indexable": true, "report_reasons": null, "author": "Paul860913", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137dxc9/noise_level_5640rpm_airsealed_vs_7200rpm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137dxc9/noise_level_5640rpm_airsealed_vs_7200rpm/", "subreddit_subscribers": 680829, "created_utc": 1683187528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have got a 300 Mbps (\\~37 MB/s) symmetrical connection (same up and down speeds). During speedtest, I get those speeds. I have tested using Ookla, [Fast.com](https://Fast.com), Cloudflare Speedtest and I have got near 300 Mb/s up and down speeds. But when ever I try to upload a youtube video or file to GDrive, speeds are around 2-3 MB/s. When I upload to Onedrive speeds improve to 8-10 MB/s. But still can't saturate my connection. Also when I stream to Youtube, frames drop a lot and it lags a lot but my gameplay is very smooth. But when streaming to Twitch, this doesn't seem to be the case.", "author_fullname": "t2_5ov8p822", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uploads are very slow when uploading to Drive, YouTube and live streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1389yjb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683259000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have got a 300 Mbps (~37 MB/s) symmetrical connection (same up and down speeds). During speedtest, I get those speeds. I have tested using Ookla, &lt;a href=\"https://Fast.com\"&gt;Fast.com&lt;/a&gt;, Cloudflare Speedtest and I have got near 300 Mb/s up and down speeds. But when ever I try to upload a youtube video or file to GDrive, speeds are around 2-3 MB/s. When I upload to Onedrive speeds improve to 8-10 MB/s. But still can&amp;#39;t saturate my connection. Also when I stream to Youtube, frames drop a lot and it lags a lot but my gameplay is very smooth. But when streaming to Twitch, this doesn&amp;#39;t seem to be the case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1389yjb", "is_robot_indexable": true, "report_reasons": null, "author": "Xyncronix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1389yjb/uploads_are_very_slow_when_uploading_to_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1389yjb/uploads_are_very_slow_when_uploading_to_drive/", "subreddit_subscribers": 680829, "created_utc": 1683259000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a MacBook with USB-C/Thunderbolt connections and normally since most external hard drives are USB-3, I need to use a USB-C to USB-3 converter dongle. The currently drives I have are a Seagate Expansion External and a Seagate Exos internal mounted on a hard drive docking station converting SATA to USB-3.\n\nI am wondering what might be the fastest hard drive available for my MacBook and if there are additional converter options that can speed up what I have above. Thanks", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fastest External Hard Drive for MacBooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1389mf7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683258048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a MacBook with USB-C/Thunderbolt connections and normally since most external hard drives are USB-3, I need to use a USB-C to USB-3 converter dongle. The currently drives I have are a Seagate Expansion External and a Seagate Exos internal mounted on a hard drive docking station converting SATA to USB-3.&lt;/p&gt;\n\n&lt;p&gt;I am wondering what might be the fastest hard drive available for my MacBook and if there are additional converter options that can speed up what I have above. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1389mf7", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1389mf7/fastest_external_hard_drive_for_macbooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1389mf7/fastest_external_hard_drive_for_macbooks/", "subreddit_subscribers": 680829, "created_utc": 1683258048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So  recently I have bought a WD Red Plus 4TB to connect to my Orange Pi 5  (running armbian) with a AX-SC021 USB Alxum USB3.0 to SATA6G connector  to use as a home server HDD. Everything works just fine but I noticed  yesterday that it began making this noise every minute, or more precisely \\~63 seconds. I have tried `hdparm -S 0 /dev/sda` and ran some SMART tests but no luck there, nor any related error in the system log. Can someone help me identify what/why that noise is?  Many thanks!!!\n\nNoise audio: [www.whyp.it/tracks/94887/hdd?token=g1vm1](https://www.whyp.it/tracks/94887/hdd?token=g1vm1)", "author_fullname": "t2_g39ykrzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Noise Every Minute (63 seconds to be exact)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1388nwl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683255575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So  recently I have bought a WD Red Plus 4TB to connect to my Orange Pi 5  (running armbian) with a AX-SC021 USB Alxum USB3.0 to SATA6G connector  to use as a home server HDD. Everything works just fine but I noticed  yesterday that it began making this noise every minute, or more precisely ~63 seconds. I have tried &lt;code&gt;hdparm -S 0 /dev/sda&lt;/code&gt; and ran some SMART tests but no luck there, nor any related error in the system log. Can someone help me identify what/why that noise is?  Many thanks!!!&lt;/p&gt;\n\n&lt;p&gt;Noise audio: &lt;a href=\"https://www.whyp.it/tracks/94887/hdd?token=g1vm1\"&gt;www.whyp.it/tracks/94887/hdd?token=g1vm1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?auto=webp&amp;v=enabled&amp;s=b112a72684b15bef4db5d2a5587649e82c9a3ed8", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d40cd9b622d3be51bb510ef05d03cec28670219", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8c5b3e9c6aa05143cddf1846aea19c68743a560", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=418cd5bd8b1cbb3056c8a557e16a6c8143f91883", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6af2c5014cbfa841588917f950beca21c2796e11", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=387a4265b7f76d2c545b359e542792f7df89f44c", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/qzx7M7NalO6EsVsBJ_lA_DAkHDDP9CQNl68m6eGF-7g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=089e9e8d05c3dc54ad27a9ad015b24689a3d54f1", "width": 1080, "height": 564}], "variants": {}, "id": "WhUaEduY2rnlf0g05TXrTe9kWyllkLZGWuyRJaTvepc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1388nwl", "is_robot_indexable": true, "report_reasons": null, "author": "mikey_002", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1388nwl/hdd_noise_every_minute_63_seconds_to_be_exact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1388nwl/hdd_noise_every_minute_63_seconds_to_be_exact/", "subreddit_subscribers": 680829, "created_utc": 1683255575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The one on the left is an example from a website tutorial. My drive results are on the right, nothing listed for write and read totals? Any ideas?\n\n(Yes she's well traveled, a lot of usage)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/msysgueadxxa1.jpg?width=2542&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=83bb5c3dc3242d9469a5c95c6e6d790540054bd4", "author_fullname": "t2_bib2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD is Missing Total Host Read/Writes in CrystalDisk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 58, "top_awarded_type": null, "hide_score": false, "media_metadata": {"msysgueadxxa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34251d2c6e0b43e968920807293739300660e4a6"}, {"y": 90, "x": 216, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caa6d52db103c29ad8ef41786fd7521e66a57c33"}, {"y": 133, "x": 320, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53d1791cab023eb564c6238948b17d631a17b9be"}, {"y": 267, "x": 640, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca6027a31464029e739896e55a17bf756e8bbe30"}, {"y": 400, "x": 960, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d47c2fca31d0f2112ffcfe7591c12be2886dd785"}, {"y": 450, "x": 1080, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf1ecfce0580ef72fe6048a31bff9e457c1fce08"}], "s": {"y": 1061, "x": 2542, "u": "https://preview.redd.it/msysgueadxxa1.jpg?width=2542&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=83bb5c3dc3242d9469a5c95c6e6d790540054bd4"}, "id": "msysgueadxxa1"}}, "name": "t3_13885cj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZF4fsdnxkOsThbaiKkgD4Uon8FUM6euwF-PxVDrauSU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683254287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The one on the left is an example from a website tutorial. My drive results are on the right, nothing listed for write and read totals? Any ideas?&lt;/p&gt;\n\n&lt;p&gt;(Yes she&amp;#39;s well traveled, a lot of usage)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/msysgueadxxa1.jpg?width=2542&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83bb5c3dc3242d9469a5c95c6e6d790540054bd4\"&gt;https://preview.redd.it/msysgueadxxa1.jpg?width=2542&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83bb5c3dc3242d9469a5c95c6e6d790540054bd4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13885cj", "is_robot_indexable": true, "report_reasons": null, "author": "LeoWitt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13885cj/ssd_is_missing_total_host_readwrites_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13885cj/ssd_is_missing_total_host_readwrites_in/", "subreddit_subscribers": 680829, "created_utc": 1683254287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to download static.musictoday.com/store/bands/840/product_large/ without knowing the names of the files. I figured out a few of the naming conventions like PHAS###.jpg, but I\u2019d like to find more. Is there a way around this? Thanks!", "author_fullname": "t2_14sf4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with getting an image folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1387iqb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683252752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to download static.musictoday.com/store/bands/840/product_large/ without knowing the names of the files. I figured out a few of the naming conventions like PHAS###.jpg, but I\u2019d like to find more. Is there a way around this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1387iqb", "is_robot_indexable": true, "report_reasons": null, "author": "theblake1980", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1387iqb/help_with_getting_an_image_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1387iqb/help_with_getting_an_image_folder/", "subreddit_subscribers": 680829, "created_utc": 1683252752.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not so good using English so here's the summary  \n\\- seagate backup plus slim 1TB, 6 years old  \n\\- last plugged working normally with 100% health  \n\\- gonna do some backup, plugged in, external disk usage 100% without read/write  \n\\- laptop slowed down  \n\\- try do restart  \n\\- external hdd detected but without detail capacity  \n\\- disconnect hdd, reconnect, still the same  \n\\- trying other enclosure, still same  \n\\- connect hdd in bios, bios got freeze, disconnect the hdd, bios back to normal  \n\\- reconnect again in windows, and just let it be, few minutes, usb not recognize (error 43)  \n\\- try to format, bsod happen with \"Driver corrupted expool\"  \n\\- uninstall the driver, still not working  \n\\- there's no any beeping, hdd spin as usual with normal rattling without repeating pattern  \nSo.. what happen? Can i fix it? Can i get my data back? What failure? Bad sector, head stuck, scratched disk, driver fault, firmware fault or other? Help :(", "author_fullname": "t2_atb9kocp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with my not detected seagate external drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1387flm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683252520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not so good using English so here&amp;#39;s the summary&lt;br/&gt;\n- seagate backup plus slim 1TB, 6 years old&lt;br/&gt;\n- last plugged working normally with 100% health&lt;br/&gt;\n- gonna do some backup, plugged in, external disk usage 100% without read/write&lt;br/&gt;\n- laptop slowed down&lt;br/&gt;\n- try do restart&lt;br/&gt;\n- external hdd detected but without detail capacity&lt;br/&gt;\n- disconnect hdd, reconnect, still the same&lt;br/&gt;\n- trying other enclosure, still same&lt;br/&gt;\n- connect hdd in bios, bios got freeze, disconnect the hdd, bios back to normal&lt;br/&gt;\n- reconnect again in windows, and just let it be, few minutes, usb not recognize (error 43)&lt;br/&gt;\n- try to format, bsod happen with &amp;quot;Driver corrupted expool&amp;quot;&lt;br/&gt;\n- uninstall the driver, still not working&lt;br/&gt;\n- there&amp;#39;s no any beeping, hdd spin as usual with normal rattling without repeating pattern&lt;br/&gt;\nSo.. what happen? Can i fix it? Can i get my data back? What failure? Bad sector, head stuck, scratched disk, driver fault, firmware fault or other? Help :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1387flm", "is_robot_indexable": true, "report_reasons": null, "author": "Re_YZ", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1387flm/need_help_with_my_not_detected_seagate_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1387flm/need_help_with_my_not_detected_seagate_external/", "subreddit_subscribers": 680829, "created_utc": 1683252520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just made a new build to house my Exos HDDs and my case (Fractal Meshify 2) is only about 9 HDDs high but it obviously blocks some intake airflow despite proper mounting and a bit of space between them. \n\nFor those running HDDs in a tower, do you keep your fans running at a low RPM (as in idle RPM 300-500RPM) or do you have them spun up a bit at all times to cool the drives more since large file transfers don't really work the CPU and get my fan profile going much. from idle. \n\nWith 9x Seagate Exos in this build I'm seeing HDD temps 31C to 33C at pure idle with no activity. \n\nBut under transfer I see 43C to 46C no problem. \n\nThis is due to my fans really not spinning up to accommodate the file transfers like they do with CPU intensive tasks.\n\n\n\n\n\n.......spec if applicable.....\nFans 3x Noctua NFA14 intake\n1x Noctua NFA14 exhaust \nNoctua tower CPU cooler 2x120mm", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you with a wall of HDDs in a tower...fan speeds?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386orv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683250539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just made a new build to house my Exos HDDs and my case (Fractal Meshify 2) is only about 9 HDDs high but it obviously blocks some intake airflow despite proper mounting and a bit of space between them. &lt;/p&gt;\n\n&lt;p&gt;For those running HDDs in a tower, do you keep your fans running at a low RPM (as in idle RPM 300-500RPM) or do you have them spun up a bit at all times to cool the drives more since large file transfers don&amp;#39;t really work the CPU and get my fan profile going much. from idle. &lt;/p&gt;\n\n&lt;p&gt;With 9x Seagate Exos in this build I&amp;#39;m seeing HDD temps 31C to 33C at pure idle with no activity. &lt;/p&gt;\n\n&lt;p&gt;But under transfer I see 43C to 46C no problem. &lt;/p&gt;\n\n&lt;p&gt;This is due to my fans really not spinning up to accommodate the file transfers like they do with CPU intensive tasks.&lt;/p&gt;\n\n&lt;p&gt;.......spec if applicable.....\nFans 3x Noctua NFA14 intake\n1x Noctua NFA14 exhaust \nNoctua tower CPU cooler 2x120mm&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1386orv", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1386orv/for_those_of_you_with_a_wall_of_hdds_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1386orv/for_those_of_you_with_a_wall_of_hdds_in_a/", "subreddit_subscribers": 680829, "created_utc": 1683250539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I keep copies of data on two portable hard drives. (And plan on putting one in the cloud as well). I usually write to them frequently, but soon, I\u2019m going to be keeping them in cold storage for around 9 months. \n\nOne of these drives is HFS+, but the other is EXFAT, and I don\u2019t feel too secure with it because of EXFAT\u2019s reputation and no journaling. It\u2019s also noticeably more sluggish than the HFS drive. I\u2019m thinking of reformatting it to HFS+, but wanted to get some input before I decide. And since my other drive is HFS+, maybe putting APFS on this one would put less eggs in one basket, and possibly future proof my data just in case HFS becomes unsupported later on? Plus I heard that HFS+ can be prone to bit-rot (not sure how accurate that is), and having an APFS drive may protect against that. However, I am aware that APFS is not ideal for spinning HDDs.\n\nOne last thing to factor in, is that I use Mac, but in the future, I would like to use Linux. And I feel like having all Apple formatted drives would basically trap my data in the Apple ecosystem. But the only other option that seems to work with Linux would be Exfat, and it just doesn\u2019t seem reliable enough for cold storage\u2026\n\nAny advice would be appreciated!", "author_fullname": "t2_heaw12g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HFS+ for cold storage? Or something else...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13852m6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683246267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep copies of data on two portable hard drives. (And plan on putting one in the cloud as well). I usually write to them frequently, but soon, I\u2019m going to be keeping them in cold storage for around 9 months. &lt;/p&gt;\n\n&lt;p&gt;One of these drives is HFS+, but the other is EXFAT, and I don\u2019t feel too secure with it because of EXFAT\u2019s reputation and no journaling. It\u2019s also noticeably more sluggish than the HFS drive. I\u2019m thinking of reformatting it to HFS+, but wanted to get some input before I decide. And since my other drive is HFS+, maybe putting APFS on this one would put less eggs in one basket, and possibly future proof my data just in case HFS becomes unsupported later on? Plus I heard that HFS+ can be prone to bit-rot (not sure how accurate that is), and having an APFS drive may protect against that. However, I am aware that APFS is not ideal for spinning HDDs.&lt;/p&gt;\n\n&lt;p&gt;One last thing to factor in, is that I use Mac, but in the future, I would like to use Linux. And I feel like having all Apple formatted drives would basically trap my data in the Apple ecosystem. But the only other option that seems to work with Linux would be Exfat, and it just doesn\u2019t seem reliable enough for cold storage\u2026&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13852m6", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway52075", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13852m6/hfs_for_cold_storage_or_something_else/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13852m6/hfs_for_cold_storage_or_something_else/", "subreddit_subscribers": 680829, "created_utc": 1683246267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm a writer and photographer, so I have a whole archive of audio interviews, docs, and photos that I need to store, but also need regular access to. I need to be able to access my files quickly/semi-regularly since I often have to refer back to old files when I work on a new project or re-share photos with clients.\n\nMy current set-up: A 500GB MacBook Pro, a 2TB LaCie external drive, and 2TB of cloud storage on pCloud which also has a virtual drive on my Mac.\n\nThe problem: For redundancy's sake, I want my external drive to be identical to my cloud drive. pCloud doesn't work great for this because it needs the files to be moved manually, so every time I add something to my cloud drive I'd have to manually copy it onto my external drive to ensure that everything that's on one is on the other. However, I initially got pCloud *because* the virtual drive doesn't take up space on my laptop **and** is super easy to access/sort through.\n\nI know that there has to be a more efficient way around this issue, but I've had a hard time finding a solution when I've researched online. If there's a way for me to just plug in my hard drive and sync it a cloud service that I can also access easily, that would be ideal. Hoping someone here can advise on maybe a different cloud service or some other way around this issue. Thank you!", "author_fullname": "t2_k8q7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Hoarder: What's the Best Way to Sync My Files Across Multiple Drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1382o0d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683240407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a writer and photographer, so I have a whole archive of audio interviews, docs, and photos that I need to store, but also need regular access to. I need to be able to access my files quickly/semi-regularly since I often have to refer back to old files when I work on a new project or re-share photos with clients.&lt;/p&gt;\n\n&lt;p&gt;My current set-up: A 500GB MacBook Pro, a 2TB LaCie external drive, and 2TB of cloud storage on pCloud which also has a virtual drive on my Mac.&lt;/p&gt;\n\n&lt;p&gt;The problem: For redundancy&amp;#39;s sake, I want my external drive to be identical to my cloud drive. pCloud doesn&amp;#39;t work great for this because it needs the files to be moved manually, so every time I add something to my cloud drive I&amp;#39;d have to manually copy it onto my external drive to ensure that everything that&amp;#39;s on one is on the other. However, I initially got pCloud &lt;em&gt;because&lt;/em&gt; the virtual drive doesn&amp;#39;t take up space on my laptop &lt;strong&gt;and&lt;/strong&gt; is super easy to access/sort through.&lt;/p&gt;\n\n&lt;p&gt;I know that there has to be a more efficient way around this issue, but I&amp;#39;ve had a hard time finding a solution when I&amp;#39;ve researched online. If there&amp;#39;s a way for me to just plug in my hard drive and sync it a cloud service that I can also access easily, that would be ideal. Hoping someone here can advise on maybe a different cloud service or some other way around this issue. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1382o0d", "is_robot_indexable": true, "report_reasons": null, "author": "MissingPhonebooth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1382o0d/beginner_data_hoarder_whats_the_best_way_to_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1382o0d/beginner_data_hoarder_whats_the_best_way_to_sync/", "subreddit_subscribers": 680829, "created_utc": 1683240407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My main hobbby is astrophotography. I want to start hoarding all data of past projects. I currently have a 1 tb nvme os drive where i also store games. I also have a 2 tb nvme 4.0 working drive where i store current projects. The astrophotography software uses this drive to write and read a lot of data to so i can not use this as storage.\n\nSo when i am done with a project i want to store all of the data somewhere els. what would be the best option for this? with atleast a little bit of redundency in mind? I currently have 1 nvme slot unused in my motherboard and 4 sata ports unused. I also have place for sata ssds. and 2 3.5 hdd. I am also open to getting external storage.", "author_fullname": "t2_2hdciidi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help deciding what i need.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ybuy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683230773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My main hobbby is astrophotography. I want to start hoarding all data of past projects. I currently have a 1 tb nvme os drive where i also store games. I also have a 2 tb nvme 4.0 working drive where i store current projects. The astrophotography software uses this drive to write and read a lot of data to so i can not use this as storage.&lt;/p&gt;\n\n&lt;p&gt;So when i am done with a project i want to store all of the data somewhere els. what would be the best option for this? with atleast a little bit of redundency in mind? I currently have 1 nvme slot unused in my motherboard and 4 sata ports unused. I also have place for sata ssds. and 2 3.5 hdd. I am also open to getting external storage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137ybuy", "is_robot_indexable": true, "report_reasons": null, "author": "Timetoerist13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137ybuy/need_help_deciding_what_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137ybuy/need_help_deciding_what_i_need/", "subreddit_subscribers": 680829, "created_utc": 1683230773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know quite a few formats E.g mkv are not worth zipping as they are already compressed. \n\nDoes anyone know if the same applies to epub or other ebook formats?\n\nMy motivation is to pay less for cloud backups.", "author_fullname": "t2_d2ja9fnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does epub compress well?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137vuob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683225366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know quite a few formats E.g mkv are not worth zipping as they are already compressed. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know if the same applies to epub or other ebook formats?&lt;/p&gt;\n\n&lt;p&gt;My motivation is to pay less for cloud backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137vuob", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Warning-4186", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137vuob/does_epub_compress_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137vuob/does_epub_compress_well/", "subreddit_subscribers": 680829, "created_utc": 1683225366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from DS1513+ with DX513 to DS2422+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ucxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2elzat07", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "synology", "selftext": "I got one volume expanded over both units (yes I know..) both units are populated full and with mostly 10tb drives. The DS1513+ is runnning latest DSM 7.1.1-42962 Update 5\n\nThis has been running nicely.\n\nCan I just pop all 10 drives in the DS2422+ and voila?", "author_fullname": "t2_2elzat07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from DS1513+ with DX513 to DS2422+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/synology", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_134m4tm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "NAS hardware", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682946702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got one volume expanded over both units (yes I know..) both units are populated full and with mostly 10tb drives. The DS1513+ is runnning latest DSM 7.1.1-42962 Update 5&lt;/p&gt;\n\n&lt;p&gt;This has been running nicely.&lt;/p&gt;\n\n&lt;p&gt;Can I just pop all 10 drives in the DS2422+ and voila?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b45c7c8-4b25-11ed-a1f3-5a29a1a8c4d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4co", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "134m4tm", "is_robot_indexable": true, "report_reasons": null, "author": "sewzter", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "subreddit_subscribers": 122196, "created_utc": 1682946702.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1683222082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137ucxf", "is_robot_indexable": true, "report_reasons": null, "author": "sewzter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_134m4tm", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137ucxf/migrating_from_ds1513_with_dx513_to_ds2422/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "subreddit_subscribers": 680829, "created_utc": 1683222082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " So I\u2019ve got a bunch of DVDs and Blu-rays that I never take out of the case any more, I want to get them ripped and on to a service like Plex (or a different one if there\u2019s a better service, that\u2019s just the only one I know.) I\u2019m looking for advice on the best software to rip the movies, ideally with the menu and everything intact.  \n\n\nAlso, I don\u2019t even have a Blu-ray drive on my computer, so I\u2019m going to have buy one. If there\u2019s some hardware that\u2019s specifically designed for ripping movies that could be interesting.  \n\n\nI haven\u2019t ripped anything in like 10 years, so any advice you can give me would be greatly appreciated.", "author_fullname": "t2_7grcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help Porting DVD/Blu-ray Library to Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137rjbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683215971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve got a bunch of DVDs and Blu-rays that I never take out of the case any more, I want to get them ripped and on to a service like Plex (or a different one if there\u2019s a better service, that\u2019s just the only one I know.) I\u2019m looking for advice on the best software to rip the movies, ideally with the menu and everything intact.  &lt;/p&gt;\n\n&lt;p&gt;Also, I don\u2019t even have a Blu-ray drive on my computer, so I\u2019m going to have buy one. If there\u2019s some hardware that\u2019s specifically designed for ripping movies that could be interesting.  &lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t ripped anything in like 10 years, so any advice you can give me would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137rjbv", "is_robot_indexable": true, "report_reasons": null, "author": "Honbomb", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137rjbv/need_help_porting_dvdbluray_library_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137rjbv/need_help_porting_dvdbluray_library_to_cloud/", "subreddit_subscribers": 680829, "created_utc": 1683215971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got 102 2gb files to download for my Google Photos data export.  I'm using IDM to download, but figured out how to automate it so I don't have to click each individual link.  One issue seems to be that I can't get IDM/Google to play nice, as the downloads sometimes require my login/password, and for some reason Google isn't accepting the credentials submitted via IDM.\n\nI realize there's probably some necessary information I haven't provided, but am savvy enough to be able to get whatever info is needed.  Any help you folks can provide would be greatly appreciated :-)", "author_fullname": "t2_frcwun8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Download Manager and Google Photos Export", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137o5v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683211825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got 102 2gb files to download for my Google Photos data export.  I&amp;#39;m using IDM to download, but figured out how to automate it so I don&amp;#39;t have to click each individual link.  One issue seems to be that I can&amp;#39;t get IDM/Google to play nice, as the downloads sometimes require my login/password, and for some reason Google isn&amp;#39;t accepting the credentials submitted via IDM.&lt;/p&gt;\n\n&lt;p&gt;I realize there&amp;#39;s probably some necessary information I haven&amp;#39;t provided, but am savvy enough to be able to get whatever info is needed.  Any help you folks can provide would be greatly appreciated :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137o5v1", "is_robot_indexable": true, "report_reasons": null, "author": "Papapot1755", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137o5v1/internet_download_manager_and_google_photos_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137o5v1/internet_download_manager_and_google_photos_export/", "subreddit_subscribers": 680829, "created_utc": 1683211825.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}