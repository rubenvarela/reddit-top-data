{"kind": "Listing", "data": {"after": "t3_137i1gx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).\n\n\n\n\nEven ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of work can a data engineer do if they can't find employment as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ij6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683202929.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683201719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).&lt;/p&gt;\n\n&lt;p&gt;Even ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137ij6s", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "subreddit_subscribers": 104133, "created_utc": 1683201719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cmjwin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Welcome to JOIN hell", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_138cvct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 35, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xQyfG35IzBPm3Bd09roABVBCsjbUt9UyepYWOweaic0.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683267755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ho2lxe3nhyxa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?auto=webp&amp;v=enabled&amp;s=727f6990522a563a26475da3dc0a7669c84a9e52", "width": 888, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44da424e0a5535937cb47679c80bf90a830f68cc", "width": 108, "height": 60}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78b3a3100c6566d4b12744aedf12cee8cc0d639a", "width": 216, "height": 121}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fa61eebd7eeffc7a1332751490306b87cd16fe5", "width": 320, "height": 180}, {"url": "https://preview.redd.it/ho2lxe3nhyxa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d41d5629da0dd96094d8ecbb5a25532db426677", "width": 640, "height": 360}], "variants": {}, "id": "CEt7hgNYbUxB-mmCkT92tqRtwZYchEZ9UEL-sZLG5io"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "138cvct", "is_robot_indexable": true, "report_reasons": null, "author": "tiltaltti", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138cvct/welcome_to_join_hell/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ho2lxe3nhyxa1.jpg", "subreddit_subscribers": 104133, "created_utc": 1683267755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently became a Data Engineer. I have experience in SWE and ML and wanted to study something different but helpful to Data Engineering. Just curious if cyber security is something that is useful to the role? Or anything else you guys recommend", "author_fullname": "t2_h256mca5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How useful is cyber security?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386r86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683250725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently became a Data Engineer. I have experience in SWE and ML and wanted to study something different but helpful to Data Engineering. Just curious if cyber security is something that is useful to the role? Or anything else you guys recommend&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1386r86", "is_robot_indexable": true, "report_reasons": null, "author": "ElasticCode", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1386r86/how_useful_is_cyber_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1386r86/how_useful_is_cyber_security/", "subreddit_subscribers": 104133, "created_utc": 1683250725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently I've talked to a few (non-technical) stakeholders who are very excited about integrating tools that are some version of \"point generative AI at your warehouse\" ([Hex](https://app.hex.tech/), [Defog](https://defog.ai/)) for *end users.* So that a user could essentially just submit a questions to #databot and get an answer.\n\nI've watched some demos, read a bit of documentation and it just seems like the excitement is out of line with reality. Like, allowing any user to map their ambiguous text questions to explicit analytical code answers seems like an absolute nightmare. Just imagining the scenarios like \"person X and Y asked #databot how many unique users churned from the platform last week and got different answers, how come?\" makes my skin crawl. Seems like the only use case would be a really clean/standardized data model or maybe as a productivity tool for data teams...\n\nAm I missing something? Has anyone used one of these tools? Are they better than I'm giving them credit for?", "author_fullname": "t2_2gln0h10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about peoples experience with generative ai to facilitate data access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386w68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683251088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I&amp;#39;ve talked to a few (non-technical) stakeholders who are very excited about integrating tools that are some version of &amp;quot;point generative AI at your warehouse&amp;quot; (&lt;a href=\"https://app.hex.tech/\"&gt;Hex&lt;/a&gt;, &lt;a href=\"https://defog.ai/\"&gt;Defog&lt;/a&gt;) for &lt;em&gt;end users.&lt;/em&gt; So that a user could essentially just submit a questions to #databot and get an answer.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve watched some demos, read a bit of documentation and it just seems like the excitement is out of line with reality. Like, allowing any user to map their ambiguous text questions to explicit analytical code answers seems like an absolute nightmare. Just imagining the scenarios like &amp;quot;person X and Y asked #databot how many unique users churned from the platform last week and got different answers, how come?&amp;quot; makes my skin crawl. Seems like the only use case would be a really clean/standardized data model or maybe as a productivity tool for data teams...&lt;/p&gt;\n\n&lt;p&gt;Am I missing something? Has anyone used one of these tools? Are they better than I&amp;#39;m giving them credit for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1386w68", "is_robot_indexable": true, "report_reasons": null, "author": "poopybutbaby", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1386w68/curious_about_peoples_experience_with_generative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1386w68/curious_about_peoples_experience_with_generative/", "subreddit_subscribers": 104133, "created_utc": 1683251088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started as a data engineer 2 years ago after being an analyst. I learned DE fairly quickly and became the driving force on our DE team. The team though is mostly low code tools and non programming skills, outside of SQL. \n\nI want to take my career in more of a programming direction and learn more of the software engineering best practices. I already know python pretty well but I barely get to use it in production outside of personal stuff. \n\nAnyways I love my team members and the director is good but none of them are true data people. \nI am contemplating taking a job offer to join a team where I can learn and grow under what seems to be great leadership and smart people. \n\nMy only hesitation is I just finished implementing something and they are relying on me for a lot. \nWhat do people on here think?", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I making the wrong career decision?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1386847", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683249297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started as a data engineer 2 years ago after being an analyst. I learned DE fairly quickly and became the driving force on our DE team. The team though is mostly low code tools and non programming skills, outside of SQL. &lt;/p&gt;\n\n&lt;p&gt;I want to take my career in more of a programming direction and learn more of the software engineering best practices. I already know python pretty well but I barely get to use it in production outside of personal stuff. &lt;/p&gt;\n\n&lt;p&gt;Anyways I love my team members and the director is good but none of them are true data people. \nI am contemplating taking a job offer to join a team where I can learn and grow under what seems to be great leadership and smart people. &lt;/p&gt;\n\n&lt;p&gt;My only hesitation is I just finished implementing something and they are relying on me for a lot. \nWhat do people on here think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1386847", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1386847/am_i_making_the_wrong_career_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1386847/am_i_making_the_wrong_career_decision/", "subreddit_subscribers": 104133, "created_utc": 1683249297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Engineering as a field has lots of things to be done as a data engineer, how do you learn all that's required and be confident of it too, for eg: Databases(SQL, NoSQL), Cloud(AWS, Azure), ETL (Dbt, etc..), Python/Scala, Linux, DevOps/CI-CD tools(Git, Jenkins, etc..), Orchestration (airflow, Luigi).\n\nHow do you keep up with learning all these? Please reply if you are an experienced DE.", "author_fullname": "t2_60oji2x5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Know-how - To the Experienced Folks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137julp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683204986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Engineering as a field has lots of things to be done as a data engineer, how do you learn all that&amp;#39;s required and be confident of it too, for eg: Databases(SQL, NoSQL), Cloud(AWS, Azure), ETL (Dbt, etc..), Python/Scala, Linux, DevOps/CI-CD tools(Git, Jenkins, etc..), Orchestration (airflow, Luigi).&lt;/p&gt;\n\n&lt;p&gt;How do you keep up with learning all these? Please reply if you are an experienced DE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137julp", "is_robot_indexable": true, "report_reasons": null, "author": "rakash_ram", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137julp/data_engineering_knowhow_to_the_experienced_folks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137julp/data_engineering_knowhow_to_the_experienced_folks/", "subreddit_subscribers": 104133, "created_utc": 1683204986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently prepared for data engineering concepts and would like to ask what level of python or DSA questions are asked in data engineering interviews? I don't know DSA much but is it necessary to learn for Data engineering jobs and interviews?", "author_fullname": "t2_662jzicru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coding and DSA questions??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_138fqzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683277043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently prepared for data engineering concepts and would like to ask what level of python or DSA questions are asked in data engineering interviews? I don&amp;#39;t know DSA much but is it necessary to learn for Data engineering jobs and interviews?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "138fqzx", "is_robot_indexable": true, "report_reasons": null, "author": "singh_gagan92", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138fqzx/coding_and_dsa_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138fqzx/coding_and_dsa_questions/", "subreddit_subscribers": 104133, "created_utc": 1683277043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Debezium Server and Memphis.dev for Streaming Change Data Capture (CDC) Events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_137vjev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nGxV_SFTDRwjzMkdeNaHjht4vYOSQEEI79tcEYV65b0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683224682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/memphis-dev/memphis-dev-part-1-integrating-debezium-server-and-memphis-dev-3fc91d420024", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?auto=webp&amp;v=enabled&amp;s=aa39263086a498190df25bf165d1c370637896c2", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=889c396bb82dc6645be0e2c0bebd6250bd359bc3", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5537959c165e9c8006d5389a4b7190d13c163e2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b413efa5e0f47993f2722827d3c8975c4e0907e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=804123a23c0b37b4d534e570d50e2fdc6d410a4e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8c868d81ce4b0404f7537571c27a0d20cd50b86", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/HDwpvc3h3wBfl6DHPlbAlXq_Iz-JS4LhCUTj73xvvDs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e07f9e4d4232a55e1e7b720d30b53965355de0e", "width": 1080, "height": 607}], "variants": {}, "id": "WoQ75rnXOZVqrLe5eCJf8Mja9Xr42qa0l5kcLuwwsPk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137vjev", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137vjev/integrating_debezium_server_and_memphisdev_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/memphis-dev/memphis-dev-part-1-integrating-debezium-server-and-memphis-dev-3fc91d420024", "subreddit_subscribers": 104133, "created_utc": 1683224682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI have been reading a lot about data contracts and was hoping to implement them in the company I work for.\n\nBefore that, I had a few questions:\n\n\\- How many of you regularly use data contracts?\n\n\\- How do you create/represent them? Do you use Google's Protocol Buffers or Apache Avro or something different?\n\n\\- How do you enforce them? (This is the main question I'm struggling with - what's the least effort way or tool to enforce data contracts).\n\nThanks in advance!", "author_fullname": "t2_mytvjynu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data contracts - do you use them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137glbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683196175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been reading a lot about data contracts and was hoping to implement them in the company I work for.&lt;/p&gt;\n\n&lt;p&gt;Before that, I had a few questions:&lt;/p&gt;\n\n&lt;p&gt;- How many of you regularly use data contracts?&lt;/p&gt;\n\n&lt;p&gt;- How do you create/represent them? Do you use Google&amp;#39;s Protocol Buffers or Apache Avro or something different?&lt;/p&gt;\n\n&lt;p&gt;- How do you enforce them? (This is the main question I&amp;#39;m struggling with - what&amp;#39;s the least effort way or tool to enforce data contracts).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137glbo", "is_robot_indexable": true, "report_reasons": null, "author": "a-layerup", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "subreddit_subscribers": 104133, "created_utc": 1683196175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you had the choice and 6 months of free time, which data tool would you build/fix/rewrite and why?\n\nSerious responses only, please.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Data tool/product would you build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138734e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683251608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you had the choice and 6 months of free time, which data tool would you build/fix/rewrite and why?&lt;/p&gt;\n\n&lt;p&gt;Serious responses only, please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "138734e", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138734e/what_data_toolproduct_would_you_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138734e/what_data_toolproduct_would_you_build/", "subreddit_subscribers": 104133, "created_utc": 1683251608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to get the MySQL Developer certification\\* to enhance my resume. What are some good resources to help me prepare for it?\n\n\\*I know some people have no respect for certifications, but that's what I've decided to do. Therefore, if we could dispense with the arguments about the validity of certifications, it would be greatly appreciated.", "author_fullname": "t2_7s8rukjx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Courses/resources for Oracle's MySQL Developer certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1380f0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683235322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to get the MySQL Developer certification* to enhance my resume. What are some good resources to help me prepare for it?&lt;/p&gt;\n\n&lt;p&gt;*I know some people have no respect for certifications, but that&amp;#39;s what I&amp;#39;ve decided to do. Therefore, if we could dispense with the arguments about the validity of certifications, it would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1380f0c", "is_robot_indexable": true, "report_reasons": null, "author": "african_kid_1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1380f0c/coursesresources_for_oracles_mysql_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1380f0c/coursesresources_for_oracles_mysql_developer/", "subreddit_subscribers": 104133, "created_utc": 1683235322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this project, we will scrape data from the MotoGP website and perform data engineering tasks to clean and prepare the data for analysis. The data will include race results over the years. Once the data is cleaned and prepared, we will perform exploratory data analysis and visualization to gain insights into the data.  \n[GitHub-repo](https://github.com/Manny-97/DE-ZOOMCAMP-PROJECT)\n\nhttps://preview.redd.it/diqrdifj9vxa1.png?width=1249&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c77f41cc010dcd22de27542d635772be989a5bfd", "author_fullname": "t2_52y1it67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing MotoGP Racing Data Using a Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"diqrdifj9vxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5cf5a61f0887a26b3affaaafd64afd00cc631ac"}, {"y": 125, "x": 216, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7903e34771aecae8bd65e1b3980541cfca429da0"}, {"y": 185, "x": 320, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3443ec3708660fc80e785c44b5336598bf07760"}, {"y": 371, "x": 640, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c978d4b4db6fad85993cbde8b9aff7df12e3d52c"}, {"y": 557, "x": 960, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd3e08177dd9920d5f31d99afbc1ab29d326c108"}, {"y": 626, "x": 1080, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be5df53b43a6e963e00ae07b3a87558868d7b54c"}], "s": {"y": 725, "x": 1249, "u": "https://preview.redd.it/diqrdifj9vxa1.png?width=1249&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c77f41cc010dcd22de27542d635772be989a5bfd"}, "id": "diqrdifj9vxa1"}}, "name": "t3_137xegw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ymu7wC8_YmQKen0pTgFbOgscfSNH33qi5R9CBCiiWP4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683228758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this project, we will scrape data from the MotoGP website and perform data engineering tasks to clean and prepare the data for analysis. The data will include race results over the years. Once the data is cleaned and prepared, we will perform exploratory data analysis and visualization to gain insights into the data.&lt;br/&gt;\n&lt;a href=\"https://github.com/Manny-97/DE-ZOOMCAMP-PROJECT\"&gt;GitHub-repo&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/diqrdifj9vxa1.png?width=1249&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c77f41cc010dcd22de27542d635772be989a5bfd\"&gt;https://preview.redd.it/diqrdifj9vxa1.png?width=1249&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c77f41cc010dcd22de27542d635772be989a5bfd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?auto=webp&amp;v=enabled&amp;s=3d209c549f2dd36ebd7d50317d17c23ba037b1bd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=396b913e23f49f5f9e1d401510f388010acca411", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a07f9bb67965ab1545302b8ce831cea5f85c31d1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d80e1e547c6e8a7f2e49357fa9f5dd29727fa83", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6c7aad6fbaba61b431780973a530865af468b23", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=658961af6331f18a3bb2111f5393b4bda6861750", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/p_Uho6uNeM3k7MvP1VrdmZ0noNHidL-GsY70J4PLZZ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef7c1f50cd566d3091a551f424a4f2aa05bcb571", "width": 1080, "height": 540}], "variants": {}, "id": "LhzAVlQmrDsoloGcjB1ux5WOChaw81bdHvx8MCRSMWA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "137xegw", "is_robot_indexable": true, "report_reasons": null, "author": "Manny-97", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137xegw/analyzing_motogp_racing_data_using_a_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137xegw/analyzing_motogp_racing_data_using_a_data_pipeline/", "subreddit_subscribers": 104133, "created_utc": 1683228758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was scheduled an interview recently and the job position requires CI/CD experience as an add-on in data engineering.\n\nMy previous experience in data engineering is a bit vague because we were using self-built platforms and tooling to deploy our ETL jobs. \n\nThis is how we do: normally we would write code locally, run the code block by block on our ad-hoc query platform. If the code runs smooth and result is fine, we would deploy the code and testing the whole pipeline. The code is versioned. Which means the job can be iterated or reversed back to the previous version. \n\nFor a single ETL pipeline it can be tested or published( pushed as the prod version). but code reviews are not many because there\u2019s NO GIT REPO branches or merge requests.\nHowever we still take carefully in terms of code readability and efficiency but it\u2019s still pretty wild west.\n\nI\u2019m having the interview tomorrow and I don\u2019t really know what to say if they ask me if I have CI/CD experience. \n\nA few questions here:\n\nHow much difference does it have between our ways of deploying code and the normal ways?\n\nWhat can I mention in front of such question?\n\nWhat\u2019s the difference from CI/CD between data engineering and common software engineering?", "author_fullname": "t2_oorup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you practice CI/CD in your work? What\u2019s the difference from CI/CD in common software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137oibw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683212189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was scheduled an interview recently and the job position requires CI/CD experience as an add-on in data engineering.&lt;/p&gt;\n\n&lt;p&gt;My previous experience in data engineering is a bit vague because we were using self-built platforms and tooling to deploy our ETL jobs. &lt;/p&gt;\n\n&lt;p&gt;This is how we do: normally we would write code locally, run the code block by block on our ad-hoc query platform. If the code runs smooth and result is fine, we would deploy the code and testing the whole pipeline. The code is versioned. Which means the job can be iterated or reversed back to the previous version. &lt;/p&gt;\n\n&lt;p&gt;For a single ETL pipeline it can be tested or published( pushed as the prod version). but code reviews are not many because there\u2019s NO GIT REPO branches or merge requests.\nHowever we still take carefully in terms of code readability and efficiency but it\u2019s still pretty wild west.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having the interview tomorrow and I don\u2019t really know what to say if they ask me if I have CI/CD experience. &lt;/p&gt;\n\n&lt;p&gt;A few questions here:&lt;/p&gt;\n\n&lt;p&gt;How much difference does it have between our ways of deploying code and the normal ways?&lt;/p&gt;\n\n&lt;p&gt;What can I mention in front of such question?&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the difference from CI/CD between data engineering and common software engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137oibw", "is_robot_indexable": true, "report_reasons": null, "author": "GeForceKawaiiyo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137oibw/how_do_you_practice_cicd_in_your_work_whats_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137oibw/how_do_you_practice_cicd_in_your_work_whats_the/", "subreddit_subscribers": 104133, "created_utc": 1683212189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks\n\nCurrently in a DE junior role. But the role is not so interesting. Not big data tools that I'm getting assigned to work on. Thought of doing certifications but, gone through alot of posts here against that. Finally doing a project on pyspark and some BI reporting. I have basics or intermediate excercise exp. But all the job postings on LinkedIn or portals req exp atleast 2 years. \nNow I'm thinking of applying to python developer positions rather than DE ones. Or should I try data analyst roles ?? ( I want to work closely with business so that my doings are useful and impactful).", "author_fullname": "t2_8dll0cj72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Transition Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138aw5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683261733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks&lt;/p&gt;\n\n&lt;p&gt;Currently in a DE junior role. But the role is not so interesting. Not big data tools that I&amp;#39;m getting assigned to work on. Thought of doing certifications but, gone through alot of posts here against that. Finally doing a project on pyspark and some BI reporting. I have basics or intermediate excercise exp. But all the job postings on LinkedIn or portals req exp atleast 2 years. \nNow I&amp;#39;m thinking of applying to python developer positions rather than DE ones. Or should I try data analyst roles ?? ( I want to work closely with business so that my doings are useful and impactful).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "138aw5n", "is_robot_indexable": true, "report_reasons": null, "author": "Secret_While3350", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138aw5n/job_transition_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138aw5n/job_transition_help/", "subreddit_subscribers": 104133, "created_utc": 1683261733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a BA grad student, recently received an offer to work at an early stage startup as a summer intern. The startup is building a cloud tool for a retailer to validate POS transactions. My role is to write SQL queries for the validation purposes based on business requirements and build on the existing python code for APIs. Is this a good opportunity to take on if my goal is to become a data engineer after graduation?", "author_fullname": "t2_c9dcr4wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for intern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137r14a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683215728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683214819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a BA grad student, recently received an offer to work at an early stage startup as a summer intern. The startup is building a cloud tool for a retailer to validate POS transactions. My role is to write SQL queries for the validation purposes based on business requirements and build on the existing python code for APIs. Is this a good opportunity to take on if my goal is to become a data engineer after graduation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "137r14a", "is_robot_indexable": true, "report_reasons": null, "author": "sigapuranger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137r14a/advice_for_intern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137r14a/advice_for_intern/", "subreddit_subscribers": 104133, "created_utc": 1683214819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It may be a stupid, just newbee on dv\n\nWhy do we need Hub and Link tables since we can derived the same from Sat tables itself as we can include those columns from hub and link in Sat?", "author_fullname": "t2_khph1234", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data vault model question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137pnwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683238505.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683213368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It may be a stupid, just newbee on dv&lt;/p&gt;\n\n&lt;p&gt;Why do we need Hub and Link tables since we can derived the same from Sat tables itself as we can include those columns from hub and link in Sat?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137pnwq", "is_robot_indexable": true, "report_reasons": null, "author": "misc0007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137pnwq/data_vault_model_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137pnwq/data_vault_model_question/", "subreddit_subscribers": 104133, "created_utc": 1683213368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adopting Apache arrow for ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_138f03f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hS_y8t94AP1dAs88_MpRIKqGmc0SctZ2BVv1nIIBYnc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683274621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arrow.apache.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arrow.apache.org/blog/2023/05/04/adopting-apache-arrow-at-cloudquery/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?auto=webp&amp;v=enabled&amp;s=90564d1040201ce8db134ebce49959eaeceae067", "width": 1800, "height": 936}, "resolutions": [{"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0feee992df675372bd136f2b9d218fac510db429", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8909c3aff2cc9b636ea2ff770f5e649114d1dd5", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f90141496369ee8286a3b47c5037956aab818c66", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f0ccbfcfc7f9e43ac2771261477e4906dbb9daa", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb23457cd1609a53963cdf4d5dff1513058e1f10", "width": 960, "height": 499}, {"url": "https://external-preview.redd.it/DPNEFgnyFJBS9xtPmWwTk_vy1bqCV64FL8uvrzZSydM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ded3ac959f0c28f5943b8d80bb2853d346dab86", "width": 1080, "height": 561}], "variants": {}, "id": "tgQE8dETOzO_PokwPLeRbf3ODtZN7Y-KrsIZVY72CKM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "138f03f", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138f03f/adopting_apache_arrow_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arrow.apache.org/blog/2023/05/04/adopting-apache-arrow-at-cloudquery/", "subreddit_subscribers": 104133, "created_utc": 1683274621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "is there a way I can enable or add a macro command at model folder level that runs after each model materialization execution like I need to insert a record with dynamic runtime values into a custom audit log table like row count, time stamp etc\n\nHow do you guys capture custom process or audit log in dbt?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we add custom Audit logging in dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_138eo3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683273523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is there a way I can enable or add a macro command at model folder level that runs after each model materialization execution like I need to insert a record with dynamic runtime values into a custom audit log table like row count, time stamp etc&lt;/p&gt;\n\n&lt;p&gt;How do you guys capture custom process or audit log in dbt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "138eo3m", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/138eo3m/how_can_we_add_custom_audit_logging_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/138eo3m/how_can_we_add_custom_audit_logging_in_dbt/", "subreddit_subscribers": 104133, "created_utc": 1683273523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My coworker is interested in using the Telegraf Agent to receive data from messaging services like Google Pub/Sub and/or Kafka. I have suggested that there are better alternatives available. However, my coworker has chosen to ignore my concerns and plans to continue testing with their chosen agent.\n\nIn their proposed architecture, the system would be centralized on a virtual machine, with the amount of data growing exponentially as the number of clients increases.\n\nI believe this approach is not viable, and I have recommended more robust tools that would provide better preprocessing and transformation capabilities, such as Airflow, Flink, or Beam.\n\nIf we were to choose one of these three options (Airflow, Flink, or Beam), we would aim to implement a distributed/serverless solution. The question then arises: am I being overly pragmatic, or is their proposed architecture indeed bound to fail?\n\n*\\* edit: correction on \"Telegraf Agent\"* ", "author_fullname": "t2_76d1dys0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assessing the Viability of Telegraf Agent for Messaging Services Data Collection Instead of More Convenient Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1385ckx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683246970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My coworker is interested in using the Telegraf Agent to receive data from messaging services like Google Pub/Sub and/or Kafka. I have suggested that there are better alternatives available. However, my coworker has chosen to ignore my concerns and plans to continue testing with their chosen agent.&lt;/p&gt;\n\n&lt;p&gt;In their proposed architecture, the system would be centralized on a virtual machine, with the amount of data growing exponentially as the number of clients increases.&lt;/p&gt;\n\n&lt;p&gt;I believe this approach is not viable, and I have recommended more robust tools that would provide better preprocessing and transformation capabilities, such as Airflow, Flink, or Beam.&lt;/p&gt;\n\n&lt;p&gt;If we were to choose one of these three options (Airflow, Flink, or Beam), we would aim to implement a distributed/serverless solution. The question then arises: am I being overly pragmatic, or is their proposed architecture indeed bound to fail?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;\\&lt;/em&gt; edit: correction on &amp;quot;Telegraf Agent&amp;quot;* &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1385ckx", "is_robot_indexable": true, "report_reasons": null, "author": "Revolution_Little", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1385ckx/assessing_the_viability_of_telegraf_agent_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1385ckx/assessing_the_viability_of_telegraf_agent_for/", "subreddit_subscribers": 104133, "created_utc": 1683246970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tpg40t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enhance your Data Team's Productivity with dbt and Gitpod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_137x76x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KnQdxAGTHCgJjPMKopgJxH56B4fdfH2HuU0jlu0D7pc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683228319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "gitpod.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.gitpod.io/blog/dbt-in-gitpod", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?auto=webp&amp;v=enabled&amp;s=7810a41f81bc5c8c3d871a6fd72384f0affd6791", "width": 2208, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=509ddb5aa3fe17d51b6bca3892978e40e10d6430", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f589848d1f628b786bcb58c9e5093db3f6e37c5", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02f76d8ed5b3625cc323258ac664484a07151e00", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=073fd0b706631a0da4a48860aed1fcec43331759", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1a9b1eb1be176ba9cba0c59b376aab262e5301f", "width": 960, "height": 521}, {"url": "https://external-preview.redd.it/fF9N2cYeoJNLugIjH4oJ5IYEWbO2GTkjkrb9-9lT8WA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91802f0d4eb6a10188a5c3814c9119b004fafbd4", "width": 1080, "height": 586}], "variants": {}, "id": "FeNbUsGFsGeIs3zm6_B4_U6rui5XN3oCCtVvszdIRVY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137x76x", "is_robot_indexable": true, "report_reasons": null, "author": "kpkaiser", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137x76x/enhance_your_data_teams_productivity_with_dbt_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.gitpod.io/blog/dbt-in-gitpod", "subreddit_subscribers": 104133, "created_utc": 1683228319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has almost all the data in Dropbox as csv files, few in txt files. Now that we want to make data more visible. Here are some expectations:  \n\\- Can find files that have same or similar column names\n\n\\- Have the capability to store meta data, because we can now manually create meta data for each file\n\n\\- Can search files based on meta data.  \nAny recommendations? Or should we just migrate to better cloud storage?", "author_fullname": "t2_4rbx4z37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data discovery tool for csv files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137sj29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683218097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has almost all the data in Dropbox as csv files, few in txt files. Now that we want to make data more visible. Here are some expectations:&lt;br/&gt;\n- Can find files that have same or similar column names&lt;/p&gt;\n\n&lt;p&gt;- Have the capability to store meta data, because we can now manually create meta data for each file&lt;/p&gt;\n\n&lt;p&gt;- Can search files based on meta data.&lt;br/&gt;\nAny recommendations? Or should we just migrate to better cloud storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137sj29", "is_robot_indexable": true, "report_reasons": null, "author": "panday1995", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137sj29/data_discovery_tool_for_csv_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137sj29/data_discovery_tool_for_csv_files/", "subreddit_subscribers": 104133, "created_utc": 1683218097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Im parsing some XMLs and loading them into postgres and given the nature of the records it generates a lot of duplicates.\n\nI would like to know whats the most efficient tool for removing dups. The first thing that comes to mind its PySpark but im not sure. Wdyt?", "author_fullname": "t2_8k92uib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's PySpark an adecuate tool for deduplication?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137lk6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683208855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Im parsing some XMLs and loading them into postgres and given the nature of the records it generates a lot of duplicates.&lt;/p&gt;\n\n&lt;p&gt;I would like to know whats the most efficient tool for removing dups. The first thing that comes to mind its PySpark but im not sure. Wdyt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137lk6p", "is_robot_indexable": true, "report_reasons": null, "author": "DeUnaShabown", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137lk6p/its_pyspark_an_adecuate_tool_for_deduplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137lk6p/its_pyspark_an_adecuate_tool_for_deduplication/", "subreddit_subscribers": 104133, "created_utc": 1683208855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udca1 What are Slowly Changing Dimensions (SCD) \ud83d\udca1 SCD Types \ud83d\udca1 How to implement SCD Type 2 in VDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_137lajn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AkNTFhi0_jb7z3ll1fh1DFfoK0ujczHBIWl3ke6hLHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683208250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/how-to-keep-track-of-data-versions-using-versatile-data-kit-f1916f18737e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?auto=webp&amp;v=enabled&amp;s=62b1541d9f092e383be97e915acbc14ca00cde3e", "width": 1200, "height": 802}, "resolutions": [{"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67e4ee5233df2873f8d62400ae385c2f495f706e", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=057c3f8b98867d26953a38ed7cfaf9b4509343dd", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65446bd8634b72dbcaa55307180cb0acdeeb9044", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=552f9ea3195ff6499f90fbdb56bb968cd2370a6d", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74a953d497daca5ca4fcfe8b22fa41ec1333d403", "width": 960, "height": 641}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02a6d555c070b4ed0d1f8063e47546d1ab4cb8f6", "width": 1080, "height": 721}], "variants": {}, "id": "oVejV9TkbC0Iu-JH8IBRENViFvCDP1jk-8CZobweJVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137lajn", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137lajn/what_are_slowly_changing_dimensions_scd_scd_types/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/how-to-keep-track-of-data-versions-using-versatile-data-kit-f1916f18737e", "subreddit_subscribers": 104133, "created_utc": 1683208250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to load to redshift the csv files in s3 that the filename has date today using COPY COMMAND in stage 1. \n\nEveryday there is a new csv file and has date when it was created\n\nsample: \nsample_file_2023_05_04.csv\nsample_file_2023_05_03.csv\n\nEveryday there is a new file, we usually load all then filter but it\u2019s taking too long to load \n\nPs: we cannot delete old files", "author_fullname": "t2_al77qn57k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load data in redshift from s3 that only loads the csv file if it\u2019s the current date", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137kyjl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683220284.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683207506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to load to redshift the csv files in s3 that the filename has date today using COPY COMMAND in stage 1. &lt;/p&gt;\n\n&lt;p&gt;Everyday there is a new csv file and has date when it was created&lt;/p&gt;\n\n&lt;p&gt;sample: \nsample_file_2023_05_04.csv\nsample_file_2023_05_03.csv&lt;/p&gt;\n\n&lt;p&gt;Everyday there is a new file, we usually load all then filter but it\u2019s taking too long to load &lt;/p&gt;\n\n&lt;p&gt;Ps: we cannot delete old files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137kyjl", "is_robot_indexable": true, "report_reasons": null, "author": "eleanor1717", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137kyjl/load_data_in_redshift_from_s3_that_only_loads_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137kyjl/load_data_in_redshift_from_s3_that_only_loads_the/", "subreddit_subscribers": 104133, "created_utc": 1683207506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The vector database hype explained - the story of Victor Hector and Lecter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_137i1gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fdrtyazIWJ479hucWX56dknNQEK8GDYpxajsPp87-5I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683200374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "thdpth.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://thdpth.substack.com/p/the-vector-database-hype-explained", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?auto=webp&amp;v=enabled&amp;s=42a0117c34e9e5145582dce01f9c7f7504def609", "width": 1073, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e881cc60390fcacb4088f27d9333c08519358a9a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=191c6a7cc20abe56155ab48b8858f9379afa9b69", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0156be3a4820b6132713908b7606d9d6940fb1f9", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbbb65b969d955ed141bc1c7e3e1ae484bd55671", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=195c32edd5d04639a1a8fa7069423143c2a4d812", "width": 960, "height": 536}], "variants": {}, "id": "fHTmoHPt8ioLJD_NFTiTNE-s68s9_8Y53Hg8GSg3BHI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137i1gx", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137i1gx/the_vector_database_hype_explained_the_story_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://thdpth.substack.com/p/the-vector-database-hype-explained", "subreddit_subscribers": 104133, "created_utc": 1683200374.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}