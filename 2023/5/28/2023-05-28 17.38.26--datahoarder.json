{"kind": "Listing", "data": {"after": "t3_13tsun7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can't believe I've gone all these years without using --embed-metadata.  It seems like it should be mandatory for most data hoarders.\n\nWhat else am I missing out on?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TIL about yt-dlp's amazing --embed-metadata flag. What are some other essential settings for dedicated data hoarders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tnkn0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 441, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 441, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685236040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t believe I&amp;#39;ve gone all these years without using --embed-metadata.  It seems like it should be mandatory for most data hoarders.&lt;/p&gt;\n\n&lt;p&gt;What else am I missing out on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tnkn0", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 90, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tnkn0/til_about_ytdlps_amazing_embedmetadata_flag_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tnkn0/til_about_ytdlps_amazing_embedmetadata_flag_what/", "subreddit_subscribers": 684605, "created_utc": 1685236040.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I purchased four new WD Red Pro 16TB drives from a seemingly reputable company, and two don't work out of the box. I don't think they were shipped well, as there's no padding (see photos). My Synology system immediately recognised two of the drives and let me rebuild the RAID (DS918+ RAID6), but the other two wouldn't initialise, and one couldn't be seen at all. Both drives spun up but made a lovely buzzing noise! I'm 99% sure the two drives are mechanically damaged from poor transport packaging, but I wanted to hear what you all think.", "author_fullname": "t2_m22sb4ul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "WD Red Pro\u2019s Failed - out the box!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eotypdckch2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a563c6b643c8a514b71523dfe750c5df8979f68"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49bcac58810c7b5fdec888c75ec6d00bfed853f9"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99adada243e596c3103416cfac8778becb97d16d"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ac2afef984fe5a3556f908c8e2cdfe541e2af22"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7399ee687c333c82061a850c20d5d7218288a7c"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25329000bce2da9c6f6e5cdb8ec0457fb3d2077a"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c76c96ab458c6cecd6e8b2001429670031cd54b0"}, "id": "eotypdckch2b1"}, "ouoi1eckch2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4f68f838fde07fb1284c1c7113cb9ab5848f3d2"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=768936673c0f7ae6ccc92c986517ce39980f2eb5"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52d2bde334d09afb9901e5f0cac6deb1662e39ff"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1de33cd12514aba31cb745121e15334e31028b2a"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15fb3d57f7e79e46f5275aec609d3a6d7aa998d0"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=120686ea85f2b53840c786bc1a37e2c8abdbd3f8"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=70a3a11a487d92c616d368ca4c7fe2be70341f53"}, "id": "ouoi1eckch2b1"}}, "name": "t3_13ti61z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 142, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "ouoi1eckch2b1", "id": 280492863}, {"media_id": "eotypdckch2b1", "id": 280492864}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 142, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fSD5HaV0wdmDJfL6oU7Ao02CoenSABWSadEKJjvrY5E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685221442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased four new WD Red Pro 16TB drives from a seemingly reputable company, and two don&amp;#39;t work out of the box. I don&amp;#39;t think they were shipped well, as there&amp;#39;s no padding (see photos). My Synology system immediately recognised two of the drives and let me rebuild the RAID (DS918+ RAID6), but the other two wouldn&amp;#39;t initialise, and one couldn&amp;#39;t be seen at all. Both drives spun up but made a lovely buzzing noise! I&amp;#39;m 99% sure the two drives are mechanically damaged from poor transport packaging, but I wanted to hear what you all think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13ti61z", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13ti61z", "is_robot_indexable": true, "report_reasons": null, "author": "DrCuthbert", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ti61z/wd_red_pros_failed_out_the_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13ti61z", "subreddit_subscribers": 684605, "created_utc": 1685221442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\nMy father runs a Facebook page video-ing aircraft for his followers, he shoots in 4K 50fps and so he averages about 100-150GB per day/airshow (sometimes 200-250GB a weekend (if it\u2019s a 2 day airshow), most weekends through the summer). \n\nBecause of this, he has been slowly collecting various large (5, 8 &amp; 10tb) external hdd which he, over the years has filled up with the videos as well as the edits. So he just keeps buying more (he doesn\u2019t want to delete anything).\n\nI have said he needs to stop buying the cheapest couple TB USB hard drive and get a proper NAS. I also thought about a thunderbolt enclosure but I don\u2019t really want to rely on his Mac Studio for RAID.\n\nDoes anyone have any ideas as the best route to take? Ideally would like to be under \u00a31k. I have a couple of TrueNAS boxes but they can be a little janky at times (my fault usually lol), I\u2019m not sure of any other NAS OS\u2019s. \nThere are also the prebuilts, Terramaster etc but are these actually any good?\nOr is it just worth buying another external hard drive (perhaps 12-14TB) and investing in a backup solution (but that still leaves the primary data scattered around).\n\nHe is almost out of room again so I need to decide fairly quickly. Just looking for some tips/advice on what I could do?\n\nThank you!\n\nPs, as for backups. He doesn\u2019t have any\u2026 I may try and convince him to buy an LTO 5/6 drive (if I can find some reasonable priced ones) and some tapes in a few months. But idk. As far as I can tell, the cloud is too expensive\u2026", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with my fathers (15tb+) data storage problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tdpu0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 130, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 130, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685210188.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685209839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nMy father runs a Facebook page video-ing aircraft for his followers, he shoots in 4K 50fps and so he averages about 100-150GB per day/airshow (sometimes 200-250GB a weekend (if it\u2019s a 2 day airshow), most weekends through the summer). &lt;/p&gt;\n\n&lt;p&gt;Because of this, he has been slowly collecting various large (5, 8 &amp;amp; 10tb) external hdd which he, over the years has filled up with the videos as well as the edits. So he just keeps buying more (he doesn\u2019t want to delete anything).&lt;/p&gt;\n\n&lt;p&gt;I have said he needs to stop buying the cheapest couple TB USB hard drive and get a proper NAS. I also thought about a thunderbolt enclosure but I don\u2019t really want to rely on his Mac Studio for RAID.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any ideas as the best route to take? Ideally would like to be under \u00a31k. I have a couple of TrueNAS boxes but they can be a little janky at times (my fault usually lol), I\u2019m not sure of any other NAS OS\u2019s. \nThere are also the prebuilts, Terramaster etc but are these actually any good?\nOr is it just worth buying another external hard drive (perhaps 12-14TB) and investing in a backup solution (but that still leaves the primary data scattered around).&lt;/p&gt;\n\n&lt;p&gt;He is almost out of room again so I need to decide fairly quickly. Just looking for some tips/advice on what I could do?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;Ps, as for backups. He doesn\u2019t have any\u2026 I may try and convince him to buy an LTO 5/6 drive (if I can find some reasonable priced ones) and some tapes in a few months. But idk. As far as I can tell, the cloud is too expensive\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tdpu0", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tdpu0/dealing_with_my_fathers_15tb_data_storage_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tdpu0/dealing_with_my_fathers_15tb_data_storage_problems/", "subreddit_subscribers": 684605, "created_utc": 1685209839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_px8520be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Water Cooling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13tw0fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V59O1aA0yRlp4xFOlw2Eweyt6KrIP5PybnJbHs8MIUU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685265879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/r7zxouaxij2b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?auto=webp&amp;v=enabled&amp;s=6863844aa4e23060991fb7b80b8625aa11771ded", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83ba75e7289fe0a2d4c019a64b3e2d04076253d5", "width": 108, "height": 81}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ac4684a7a24589118983f8926e8092122dbc39c", "width": 216, "height": 162}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fcbb0ef4d6afc59e29bb57efaee239b7bf41998", "width": 320, "height": 240}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=817aecf1531f63ab8bd230e4636e0c9256490769", "width": 640, "height": 480}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0d78f7d14d4e77d115cb7c0ebb87eb8b97c9f3d", "width": 960, "height": 720}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccef78dd60ae062ea734afc51741cad4881d42e0", "width": 1080, "height": 810}], "variants": {}, "id": "AYYC22kjNQjhYNXtxeuUoaZODPdEXGbF_EFtVK7K5AA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tw0fb", "is_robot_indexable": true, "report_reasons": null, "author": "Thousand_Hands_4032", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tw0fb/hdd_water_cooling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/r7zxouaxij2b1.jpg", "subreddit_subscribers": 684605, "created_utc": 1685265879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My Toshiba 1TB Hard Drive has 1845 bad sectors. Im planning on buying a new one (probably a SSD this time), but I dont want the same thing to happen again. So what causes those Bad Sectors?", "author_fullname": "t2_yo96h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What causes Bad sectors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1su9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685284171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Toshiba 1TB Hard Drive has 1845 bad sectors. Im planning on buying a new one (probably a SSD this time), but I dont want the same thing to happen again. So what causes those Bad Sectors?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u1su9", "is_robot_indexable": true, "report_reasons": null, "author": "bigmactv", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u1su9/what_causes_bad_sectors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u1su9/what_causes_bad_sectors/", "subreddit_subscribers": 684605, "created_utc": 1685284171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After [my sandisks are no longer trustworthy](https://www.theverge.com/2023/5/22/23733267/sandisk-extreme-pro-failure-ssd-firmware) I'm looking into either getting a couple Samsung T7s or getting an external NVME enclosure with an 8TB m.2 ssd.\n\nI am worried about the reliability, however. I can find plenty of reviews all day of people who use them as storage drives, game console drives, etc. but it's hard to find much info about people who are transferring tons of data on/off at a time.\n\nI do video productions so a regular day could see 3-4tb of data transferring to a drive, then that drive being used as a primary for encoding footage/uploading/etc. I always practice double or more when possible backups but having my primary drive fail is still an annoyance that I don't want to deal with.\n\nAnyone in the same field/similar workflow that's got experience with a specific enclosure/brand of SSD?", "author_fullname": "t2_2f2tnu1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have real world practice transferring tbs of data on and off an external M.2 thunderbolt/usb4 ssd enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tkm30", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685227951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After &lt;a href=\"https://www.theverge.com/2023/5/22/23733267/sandisk-extreme-pro-failure-ssd-firmware\"&gt;my sandisks are no longer trustworthy&lt;/a&gt; I&amp;#39;m looking into either getting a couple Samsung T7s or getting an external NVME enclosure with an 8TB m.2 ssd.&lt;/p&gt;\n\n&lt;p&gt;I am worried about the reliability, however. I can find plenty of reviews all day of people who use them as storage drives, game console drives, etc. but it&amp;#39;s hard to find much info about people who are transferring tons of data on/off at a time.&lt;/p&gt;\n\n&lt;p&gt;I do video productions so a regular day could see 3-4tb of data transferring to a drive, then that drive being used as a primary for encoding footage/uploading/etc. I always practice double or more when possible backups but having my primary drive fail is still an annoyance that I don&amp;#39;t want to deal with.&lt;/p&gt;\n\n&lt;p&gt;Anyone in the same field/similar workflow that&amp;#39;s got experience with a specific enclosure/brand of SSD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?auto=webp&amp;v=enabled&amp;s=f1a80dc66c139e4c095e9b193dd24fdfb44acfbd", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af5a05c8d2309de8cf918831b6b269441e804a38", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b3f8c6eecff810f7c24ea1e326b39c91ed179d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06fcfa65dbbad3677411db727c25ed209e2d18f5", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=494c4bbe78d1745bc0fe6dbe47a0cee11efab8d4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=801063985f749f8669cf7a6def2faee6d23981af", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9a0e5dc37e20c826a0c3bcd984ac115250f885b", "width": 1080, "height": 565}], "variants": {}, "id": "XN6OaUWNpbs1WEk2cS4aWDJo0_5XTeC3P8kYKCCtrAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tkm30", "is_robot_indexable": true, "report_reasons": null, "author": "PresentFault", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tkm30/anyone_have_real_world_practice_transferring_tbs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tkm30/anyone_have_real_world_practice_transferring_tbs/", "subreddit_subscribers": 684605, "created_utc": 1685227951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have downloaded a lot of RBG's (you know what it is) own x265 10-bit 2160p encodes which contain HDR10 static metadata. The video is encoded at \\~8000 kbps and the audio is lossless. The files are encoded from blu-ray sources/remuxes. However, there are many titles that are originally mastered with Dolby Vision but the re-encoded files only HDR10, which is static instead of Dolby Vision's dynamic metadata. So I downloaded releases from a private tracker which have Dolby Vision metadata and are encoded at \\~6000 kbps so the file size is lesser but they have Dolby Vision metadata. They claim to be hybrid, containing Dolby Vision that is backwards compatible with HDR10 so the profile used is Profile 8. I used HDR10+ Parser (which can also parse Dolby Vision metadata) and extracted the DV metadata from the encodes of the private tracker. However, the extracted metadata .bin files are only 25-35 MB for a 2 hour movie. Is the size of the metadata really that small? I have seen that MEL is around 2 MB/s and FEL is 7-8 MB/s. So is this really DV? Is it possible to mux the hybrid DV+HDR metadata into the RBG encodes? The minimum and maximum light levels are exactly the same. Is it even worth it? I know about DoVi Tools but haven't experimented with it.", "author_fullname": "t2_jo575sf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Muxing Dolby Vision metadata into an HDR stream", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tgf1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685216894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have downloaded a lot of RBG&amp;#39;s (you know what it is) own x265 10-bit 2160p encodes which contain HDR10 static metadata. The video is encoded at ~8000 kbps and the audio is lossless. The files are encoded from blu-ray sources/remuxes. However, there are many titles that are originally mastered with Dolby Vision but the re-encoded files only HDR10, which is static instead of Dolby Vision&amp;#39;s dynamic metadata. So I downloaded releases from a private tracker which have Dolby Vision metadata and are encoded at ~6000 kbps so the file size is lesser but they have Dolby Vision metadata. They claim to be hybrid, containing Dolby Vision that is backwards compatible with HDR10 so the profile used is Profile 8. I used HDR10+ Parser (which can also parse Dolby Vision metadata) and extracted the DV metadata from the encodes of the private tracker. However, the extracted metadata .bin files are only 25-35 MB for a 2 hour movie. Is the size of the metadata really that small? I have seen that MEL is around 2 MB/s and FEL is 7-8 MB/s. So is this really DV? Is it possible to mux the hybrid DV+HDR metadata into the RBG encodes? The minimum and maximum light levels are exactly the same. Is it even worth it? I know about DoVi Tools but haven&amp;#39;t experimented with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tgf1l", "is_robot_indexable": true, "report_reasons": null, "author": "TheApolloZ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tgf1l/muxing_dolby_vision_metadata_into_an_hdr_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tgf1l/muxing_dolby_vision_metadata_into_an_hdr_stream/", "subreddit_subscribers": 684605, "created_utc": 1685216894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know any program/extensions that would allow me to save user's tweets to google sheets or docs automatically for free. Ever since the twitter API pricing got enacted most of my twitter feed are dead as well.\n\nI have tried using IFTTT but it's not longer free and I really dislike that it creates a new file on it's limit. I have also tried using Twint, but failed to get it working. \n\nRight now I just copy the tweets everyday onto a document. Any other options?\n\nThanks.", "author_fullname": "t2_cu30k7dl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive twitter user's tweets for free?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13u4ygx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685292250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know any program/extensions that would allow me to save user&amp;#39;s tweets to google sheets or docs automatically for free. Ever since the twitter API pricing got enacted most of my twitter feed are dead as well.&lt;/p&gt;\n\n&lt;p&gt;I have tried using IFTTT but it&amp;#39;s not longer free and I really dislike that it creates a new file on it&amp;#39;s limit. I have also tried using Twint, but failed to get it working. &lt;/p&gt;\n\n&lt;p&gt;Right now I just copy the tweets everyday onto a document. Any other options?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u4ygx", "is_robot_indexable": true, "report_reasons": null, "author": "purpblow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u4ygx/how_can_i_archive_twitter_users_tweets_for_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u4ygx/how_can_i_archive_twitter_users_tweets_for_free/", "subreddit_subscribers": 684605, "created_utc": 1685292250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! \n\n\nThere are a few websites that I want to download from, but every time I try to I always end up with this message:  \n\n&gt; The following parts of the text will be scrambled to prevent theft.\n\nSomewhere in the text, followed by a few paragraphs that are a bunch of scrambled letters. I've tried a lot of programs (like downloadthemall and various extensions that revolve around turning a website into an epub) and copy-pasting but that yields the same results and turning off Javascript results in a site error. The only one that seems to work is Save Page WE and viewing it with my browser, but I want to download a lot of pages and I'd have to do it one by one that way. \n\nI was wondering if anyone knew how to proceed or maybe have some thoughts on what's causing it and how to prevent? Thank you!\n\nEdit: I forgot to add, the website has a nifty little table of content which is what I\u2019d usually use to grab pages.\n\nEdit: here\u2019s the site since some people are asking: https://secondlifetranslations.com/", "author_fullname": "t2_bfjrfghm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would anyone know how to download from websites that scramble text when you try to download them or copy-paste the text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u0p8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685292365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685281127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;There are a few websites that I want to download from, but every time I try to I always end up with this message:  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The following parts of the text will be scrambled to prevent theft.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Somewhere in the text, followed by a few paragraphs that are a bunch of scrambled letters. I&amp;#39;ve tried a lot of programs (like downloadthemall and various extensions that revolve around turning a website into an epub) and copy-pasting but that yields the same results and turning off Javascript results in a site error. The only one that seems to work is Save Page WE and viewing it with my browser, but I want to download a lot of pages and I&amp;#39;d have to do it one by one that way. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone knew how to proceed or maybe have some thoughts on what&amp;#39;s causing it and how to prevent? Thank you!&lt;/p&gt;\n\n&lt;p&gt;Edit: I forgot to add, the website has a nifty little table of content which is what I\u2019d usually use to grab pages.&lt;/p&gt;\n\n&lt;p&gt;Edit: here\u2019s the site since some people are asking: &lt;a href=\"https://secondlifetranslations.com/\"&gt;https://secondlifetranslations.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?auto=webp&amp;v=enabled&amp;s=7cb8ba6651376b7901723183fc988c63a249b190", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc7c497e81a8681fdf980c39ea9abf2fe367f01c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=922eb64189e7f277b554c466ac7a1e82793f6451", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f72c94e898f27ef0fb1786e5e7681b70858275dc", "width": 320, "height": 320}], "variants": {}, "id": "Qxd1tNE-22kqYHWwWa7kt2V_JtyFNohMzaJSGZe99xM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u0p8v", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative-Buy-7315", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u0p8v/would_anyone_know_how_to_download_from_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u0p8v/would_anyone_know_how_to_download_from_websites/", "subreddit_subscribers": 684605, "created_utc": 1685281127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 150000+ emails currently saved up. There is some important stuff in them and a lot of spam. Some of the spam is interesting (like social notifications showing whole post conversations) and some is outright malicious or has attachments I should never open. The original file for one of them is in pst format, but I am not completely sure if I am going to lose anything by converting it in mbox or other formats. (readpst was able to throw away directly all attachments and rtf body attachments, even if I am not sure about what the second thing means, but it worked fine).\n\nThe filesize either way is obviously a non issue. However, I am scared about the safety of the whole thing for two reasons: I am not sure about potential threats that can come from some of the emails, and I want to be able to store these emails in some cloud backup service without anyone else having access to them in the worst realistic case scenario.\n\nThe first one could be solved by setting up a vm, not even giving it internet access after the initial setup so I don't have to worry about anything running in the background or emails trying to do weird stuff like checking if someone is trying to pull an image from some server. I dont think the html itself could he harmful. For accessing the actual emails I checked evolution and it was fine, I was having issues with some other programs. I didnt check thunderbird.\n\nThe second issue could be maybe solved by only storing password protected archives, making sure the password is good enough. But I don't know much about it and heard stories about it only working in certain situations, if you are using certain options and in some cases some of the data can still be accessed with some compression formats. \n\nBut I imagine this second question is more broad and doesnt just deal with this specific case. So, overall I'm not sure. How do you go about it?", "author_fullname": "t2_7b7hahqv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any email hoarders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tqout", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685246013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 150000+ emails currently saved up. There is some important stuff in them and a lot of spam. Some of the spam is interesting (like social notifications showing whole post conversations) and some is outright malicious or has attachments I should never open. The original file for one of them is in pst format, but I am not completely sure if I am going to lose anything by converting it in mbox or other formats. (readpst was able to throw away directly all attachments and rtf body attachments, even if I am not sure about what the second thing means, but it worked fine).&lt;/p&gt;\n\n&lt;p&gt;The filesize either way is obviously a non issue. However, I am scared about the safety of the whole thing for two reasons: I am not sure about potential threats that can come from some of the emails, and I want to be able to store these emails in some cloud backup service without anyone else having access to them in the worst realistic case scenario.&lt;/p&gt;\n\n&lt;p&gt;The first one could be solved by setting up a vm, not even giving it internet access after the initial setup so I don&amp;#39;t have to worry about anything running in the background or emails trying to do weird stuff like checking if someone is trying to pull an image from some server. I dont think the html itself could he harmful. For accessing the actual emails I checked evolution and it was fine, I was having issues with some other programs. I didnt check thunderbird.&lt;/p&gt;\n\n&lt;p&gt;The second issue could be maybe solved by only storing password protected archives, making sure the password is good enough. But I don&amp;#39;t know much about it and heard stories about it only working in certain situations, if you are using certain options and in some cases some of the data can still be accessed with some compression formats. &lt;/p&gt;\n\n&lt;p&gt;But I imagine this second question is more broad and doesnt just deal with this specific case. So, overall I&amp;#39;m not sure. How do you go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tqout", "is_robot_indexable": true, "report_reasons": null, "author": "GRINDSETuwu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tqout/any_email_hoarders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tqout/any_email_hoarders/", "subreddit_subscribers": 684605, "created_utc": 1685246013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nHello,\n\nI am looking for someone who have experience in regards of designing PCB SATA backplane\n\nAm hoping to create 12 SATA slot backplane via SATA-3 interface on PCB for my custom build NAS case. If anyone have a sample file or CAD design, would love to hear your input or guide me to right direction.\n\nAlso, what is the most popular PCB manufacturer and how much does it cost to make this board?\n\nI am new to this and would love to learn this process. It's a fun project.\n\nThank you sir/madam for reading this.", "author_fullname": "t2_7ehbae6um", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCB SATA Backplane Designer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tk8ud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685226966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am looking for someone who have experience in regards of designing PCB SATA backplane&lt;/p&gt;\n\n&lt;p&gt;Am hoping to create 12 SATA slot backplane via SATA-3 interface on PCB for my custom build NAS case. If anyone have a sample file or CAD design, would love to hear your input or guide me to right direction.&lt;/p&gt;\n\n&lt;p&gt;Also, what is the most popular PCB manufacturer and how much does it cost to make this board?&lt;/p&gt;\n\n&lt;p&gt;I am new to this and would love to learn this process. It&amp;#39;s a fun project.&lt;/p&gt;\n\n&lt;p&gt;Thank you sir/madam for reading this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tk8ud", "is_robot_indexable": true, "report_reasons": null, "author": "Cluster_NAS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tk8ud/pcb_sata_backplane_designer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tk8ud/pcb_sata_backplane_designer/", "subreddit_subscribers": 684605, "created_utc": 1685226966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sorry, noob question - I have a lot of videos saved in mp4 format, some of them are up to 20 GB big. I would like to downsize them a little to free up a few GB storage. Seeing as mp4 is already a compressed format, could Handbrake or VLC accomplish this or is it a waste of time and should I just buy a new HDD? Thanks a lot!", "author_fullname": "t2_bpl0kcwmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mp4 compression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tiyuu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685223532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry, noob question - I have a lot of videos saved in mp4 format, some of them are up to 20 GB big. I would like to downsize them a little to free up a few GB storage. Seeing as mp4 is already a compressed format, could Handbrake or VLC accomplish this or is it a waste of time and should I just buy a new HDD? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tiyuu", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult_Owl_3447", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tiyuu/mp4_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tiyuu/mp4_compression/", "subreddit_subscribers": 684605, "created_utc": 1685223532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planning on making a digital back up of my book collection and although google gives me some options i figured i'd check in here and maybe get some tips for doing it in mass or even just suggestion for the programs and/or hardware you guys have used. Any and all info appreciated!", "author_fullname": "t2_3wjwphc1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "digitizing a small library, suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ti9ac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685221670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning on making a digital back up of my book collection and although google gives me some options i figured i&amp;#39;d check in here and maybe get some tips for doing it in mass or even just suggestion for the programs and/or hardware you guys have used. Any and all info appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ti9ac", "is_robot_indexable": true, "report_reasons": null, "author": "Puddleofbooks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ti9ac/digitizing_a_small_library_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ti9ac/digitizing_a_small_library_suggestions/", "subreddit_subscribers": 684605, "created_utc": 1685221670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am running unRAID, if I want to run a 20 TB parity drive and 5 x 20 TB storage drives, would these drives make sense to get there: [Seagate Exos X20 20TB SATA HDD SATA 6Gb/s 7200 RPM (ST20000NM007D) (2 Pack) (Renewed)](https://www.amazon.com/Seagate-Exos-20TB-ST20000NM007D-Renewed/dp/B0BWGJ8W5D/ref=sr_1_4?crid=16NPLNTRC2A4P&amp;keywords=internal+hard+drive+20TB&amp;qid=1685208536&amp;sprefix=internal+hard+drive+20tb%2Caps%2C96&amp;sr=8-4)\n\n&amp;#x200B;\n\nNothing on the array is going to be mission-critical. Mostly a Plex server. I have a 6gpbs sync connection, so I can redownload stuff in a flash if I need it.\n\n&amp;#x200B;\n\nPlease let me know if this is the best bang for your buck way to get there. I am very open and appreciative of any suggestions or better routes anyone can offer.", "author_fullname": "t2_tslji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making the jump back to local storage. Best way to ~100TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tdavb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685208718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running unRAID, if I want to run a 20 TB parity drive and 5 x 20 TB storage drives, would these drives make sense to get there: &lt;a href=\"https://www.amazon.com/Seagate-Exos-20TB-ST20000NM007D-Renewed/dp/B0BWGJ8W5D/ref=sr_1_4?crid=16NPLNTRC2A4P&amp;amp;keywords=internal+hard+drive+20TB&amp;amp;qid=1685208536&amp;amp;sprefix=internal+hard+drive+20tb%2Caps%2C96&amp;amp;sr=8-4\"&gt;Seagate Exos X20 20TB SATA HDD SATA 6Gb/s 7200 RPM (ST20000NM007D) (2 Pack) (Renewed)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Nothing on the array is going to be mission-critical. Mostly a Plex server. I have a 6gpbs sync connection, so I can redownload stuff in a flash if I need it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please let me know if this is the best bang for your buck way to get there. I am very open and appreciative of any suggestions or better routes anyone can offer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tdavb", "is_robot_indexable": true, "report_reasons": null, "author": "veritas2884", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tdavb/making_the_jump_back_to_local_storage_best_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tdavb/making_the_jump_back_to_local_storage_best_way_to/", "subreddit_subscribers": 684605, "created_utc": 1685208718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There was a suggestion in the comments from [this](https://www.reddit.com/r/DataHoarder/comments/jocb05/incredibly_slow_download_speed_from_archiveorg/) post to try FDM in case if browser does not want to download the file at better speeds, but it's not my case. My download still resets at certain megabytes mark and WM does not continue the download for me. What had I done wrong to FDM settings or forgot to do?\n\n&amp;#x200B;\n\n[Example 1: Full installer of World of Tanks 0.8.5 \\(RU\\)](https://preview.redd.it/wnevb9vzql2b1.png?width=419&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=09227fd000da367b4010fb1dac00f86e92b8306f)\n\n[Example 2: Full installer of World of Tanks 0.8.8 \\(RU\\)](https://preview.redd.it/zala27x3rl2b1.png?width=419&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=adc2c89393e90810f5df59c92f6127c12c996a40)\n\nI'm aware of rule 8.3 of this subreddit telling I can't ask anyone to reupload the files for me, so I don't ask for such. I'm generally in 'cannot download' situation.\n\nThe download speed is about 1 MB/s on average, peaking up to 2 MB/s, my bandwidth is 100 Mbps, but I'm too far from Wayback Machine's servers (Russia, to be exact). I have tried using WireGuard VPN servers located in the US, but their download speed is barely 150 KB/s on average. We're done for?", "author_fullname": "t2_452npj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FDM doesn't really help downloading large files from Wayback Machine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wnevb9vzql2b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/wnevb9vzql2b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a9f1bf039931e07033ea32b88ac985e5ec2ab8b"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/wnevb9vzql2b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3630c91246c6760a9a54cec99d812d51356e110"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/wnevb9vzql2b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cea980df4487f639771ca77b8479261d565272ef"}], "s": {"y": 290, "x": 419, "u": "https://preview.redd.it/wnevb9vzql2b1.png?width=419&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=09227fd000da367b4010fb1dac00f86e92b8306f"}, "id": "wnevb9vzql2b1"}, "zala27x3rl2b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/zala27x3rl2b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9766754a5ab931d05e1383e4de7c6ad2ad9c025c"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/zala27x3rl2b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48a99a5ab3a9e828de5991c482650941feb85211"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/zala27x3rl2b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2807cd2feff47ae19b3452d416002746d6ffb060"}], "s": {"y": 290, "x": 419, "u": "https://preview.redd.it/zala27x3rl2b1.png?width=419&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=adc2c89393e90810f5df59c92f6127c12c996a40"}, "id": "zala27x3rl2b1"}}, "name": "t3_13tyog3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WLLP1zW3D3h9l7YZ8h3VNObF6fXbTmS_VMDiKNQ57Iw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685274988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There was a suggestion in the comments from &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/jocb05/incredibly_slow_download_speed_from_archiveorg/\"&gt;this&lt;/a&gt; post to try FDM in case if browser does not want to download the file at better speeds, but it&amp;#39;s not my case. My download still resets at certain megabytes mark and WM does not continue the download for me. What had I done wrong to FDM settings or forgot to do?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wnevb9vzql2b1.png?width=419&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=09227fd000da367b4010fb1dac00f86e92b8306f\"&gt;Example 1: Full installer of World of Tanks 0.8.5 (RU)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zala27x3rl2b1.png?width=419&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=adc2c89393e90810f5df59c92f6127c12c996a40\"&gt;Example 2: Full installer of World of Tanks 0.8.8 (RU)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of rule 8.3 of this subreddit telling I can&amp;#39;t ask anyone to reupload the files for me, so I don&amp;#39;t ask for such. I&amp;#39;m generally in &amp;#39;cannot download&amp;#39; situation.&lt;/p&gt;\n\n&lt;p&gt;The download speed is about 1 MB/s on average, peaking up to 2 MB/s, my bandwidth is 100 Mbps, but I&amp;#39;m too far from Wayback Machine&amp;#39;s servers (Russia, to be exact). I have tried using WireGuard VPN servers located in the US, but their download speed is barely 150 KB/s on average. We&amp;#39;re done for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tyog3", "is_robot_indexable": true, "report_reasons": null, "author": "SigmaTel71", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tyog3/fdm_doesnt_really_help_downloading_large_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tyog3/fdm_doesnt_really_help_downloading_large_files/", "subreddit_subscribers": 684605, "created_utc": 1685274988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellow DataHoarders!\n\nI've been pondering over a question for a while now and thought this would be the best place to get some expert opinions. I'm currently running a network setup with traditional 7200rpm SATA II storage drives, which I'm using with ZFS and iSCSI. My network hardware maxes out at 10Gbps for internal transfers, and I don't have any plans to transfer data over WAN.\n\nRecently, I've been hearing a lot about NVMe over Fabrics (NVMe-OF) and its potential for high performance over networks. However, most of the discussion revolves around SSD drives, and I'm using traditional HDDs.\n\nSo, my question to the community is this: Has anyone here used NVMe-OF with non-SSD drives over a network? If so, I'm curious to know if you noticed any performance enhancements when compared to other networking protocols, specifically iSCSI which I'm currently using.\n\nI understand that NVMe-OF is primarily designed to leverage the speed of SSDs, but I'm wondering if there might be any benefits to using it with traditional hard drives. Given that my network hardware can only handle up to 10Gbps, would NVMe-OF bring any noticeable improvements in speed or efficiency, or would the potential gains be negated by my current hardware limitations? Also, I wonder if it is could also reduce the amount required by ZFS when making the partitions available for my storage devices (I am using them as a Kubernetes cluster storage medium)\n\nAny insights, experiences, or thoughts on this would be highly appreciated. Thanks in advance for your help!", "author_fullname": "t2_9e3dgilt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NVMe-OF with Non-SSD Drives: Worth the Switch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tulf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685260383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow DataHoarders!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pondering over a question for a while now and thought this would be the best place to get some expert opinions. I&amp;#39;m currently running a network setup with traditional 7200rpm SATA II storage drives, which I&amp;#39;m using with ZFS and iSCSI. My network hardware maxes out at 10Gbps for internal transfers, and I don&amp;#39;t have any plans to transfer data over WAN.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve been hearing a lot about NVMe over Fabrics (NVMe-OF) and its potential for high performance over networks. However, most of the discussion revolves around SSD drives, and I&amp;#39;m using traditional HDDs.&lt;/p&gt;\n\n&lt;p&gt;So, my question to the community is this: Has anyone here used NVMe-OF with non-SSD drives over a network? If so, I&amp;#39;m curious to know if you noticed any performance enhancements when compared to other networking protocols, specifically iSCSI which I&amp;#39;m currently using.&lt;/p&gt;\n\n&lt;p&gt;I understand that NVMe-OF is primarily designed to leverage the speed of SSDs, but I&amp;#39;m wondering if there might be any benefits to using it with traditional hard drives. Given that my network hardware can only handle up to 10Gbps, would NVMe-OF bring any noticeable improvements in speed or efficiency, or would the potential gains be negated by my current hardware limitations? Also, I wonder if it is could also reduce the amount required by ZFS when making the partitions available for my storage devices (I am using them as a Kubernetes cluster storage medium)&lt;/p&gt;\n\n&lt;p&gt;Any insights, experiences, or thoughts on this would be highly appreciated. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tulf0", "is_robot_indexable": true, "report_reasons": null, "author": "tsyklon_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tulf0/nvmeof_with_nonssd_drives_worth_the_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tulf0/nvmeof_with_nonssd_drives_worth_the_switch/", "subreddit_subscribers": 684605, "created_utc": 1685260383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\\--So you bought some SAS drives on the cheap, and now you want to use them without spending a bunch of money on a big backplane or 1-off adapter. You need 1-2 free x4 PCIe slots, or just 1 slot if you go with a Noctua fan. You need to keep the SAS card actively cooled.\n\n&amp;#x200B;\n\nParts list:\n\n&amp;#x200B;\n\n5-bay enclosure (buy x2 for 8-10 drive support)\n\n[https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;ref=ppx\\_yo2ov\\_dt\\_b\\_product\\_details](https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details)\n\n\\^ $68(!) at time of post\n\n&amp;#x200B;\n\nNote - I leave the 5th bay open for drive swaps, they eventually die and you can just switch the cable.\n\n&amp;#x200B;\n\n2-port external (-8E) SAS HBA\n\n[https://www.ebay.com/sch/i.html?\\_from=R40&amp;\\_nkw=sas9200-8e+IT+mode&amp;\\_sacat=0&amp;LH\\_TitleDesc=0&amp;LH\\_PrefLoc=2&amp;\\_sop=15](https://www.ebay.com/sch/i.html?_from=R40&amp;_nkw=sas9200-8e+IT+mode&amp;_sacat=0&amp;LH_TitleDesc=0&amp;LH_PrefLoc=2&amp;_sop=15)\n\n\\^ \\~$19-40 on ebay\n\n&amp;#x200B;\n\nFan for the HBA, takes up a slot\n\n[https://www.amazon.com/gp/product/B000233ZMU/ref=ppx\\_yo\\_dt\\_b\\_search\\_asin\\_title?ie=UTF8&amp;psc=1](https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1)\n\n\\~$20\n\n&amp;#x200B;\n\nStandard PC power supply with 2x 4-pin Molex power \n\n[https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT](https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT)\n\n\\~$45-50, less if you already have one lying around\n\n&amp;#x200B;\n\nSAS cables (2-pack, good for 8 drives but you can also start with a single cable / 4 drives) \n\n[https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8](https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8)\n\n\\~$34\n\n&amp;#x200B;\n\n**Subtotal**, \\~$150 on the cheaper end. Certainly you should be able to do this for under $200, and you get SAS + SATA drive flexibility *and the ability to grow* in a desktop-sized space. UPS also strongly recommended, you can find them on AMZN for \\~$75 and up.\n\n&amp;#x200B;\n\n\\--How I know it works: Bought a cheap used 4TB SAS drive on ebay for $20 for proof-of-concept and threw it in the listed enclosure with a 4TB SATA NAS drive. The SAS has 512 sectors and SATA has 4k sectors, but it works with a ZFS mirror at ashift=12. \n\nYou can mix SAS and SATA drives in the same enclosure as long as you use a SAS HBA in IT mode. Don't try it with a motherboard SATA controller, those are sata-only connections.\n\n&amp;#x200B;\n\nREF: [https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx](https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx)\n\nRefer to \"4-8-drive-SAS-desktop\" sheet\n\n&amp;#x200B;\n\n**Bonus**: If you also buy the 5-bay external HDDRACK listed in the spreadsheet, you can re-use the same (existing) PC power supply. The enclosure uses 2x Molex and the rack uses 5x SATA.\n\n&amp;#x200B;\n\n/ you're welcome \ud83d\udc7b", "author_fullname": "t2_1vbtepb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HOWTO - Maybe the cheapest way to use 4-8 SAS drives on your desktop without buying an expensive 1-off adapter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tjcgi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685224566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;--So you bought some SAS drives on the cheap, and now you want to use them without spending a bunch of money on a big backplane or 1-off adapter. You need 1-2 free x4 PCIe slots, or just 1 slot if you go with a Noctua fan. You need to keep the SAS card actively cooled.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Parts list:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;5-bay enclosure (buy x2 for 8-10 drive support)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details\"&gt;https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;^ $68(!) at time of post&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note - I leave the 5th bay open for drive swaps, they eventually die and you can just switch the cable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2-port external (-8E) SAS HBA&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebay.com/sch/i.html?_from=R40&amp;amp;_nkw=sas9200-8e+IT+mode&amp;amp;_sacat=0&amp;amp;LH_TitleDesc=0&amp;amp;LH_PrefLoc=2&amp;amp;_sop=15\"&gt;https://www.ebay.com/sch/i.html?_from=R40&amp;amp;_nkw=sas9200-8e+IT+mode&amp;amp;_sacat=0&amp;amp;LH_TitleDesc=0&amp;amp;LH_PrefLoc=2&amp;amp;_sop=15&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;^ ~$19-40 on ebay&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Fan for the HBA, takes up a slot&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1\"&gt;https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$20&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Standard PC power supply with 2x 4-pin Molex power &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT\"&gt;https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$45-50, less if you already have one lying around&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SAS cables (2-pack, good for 8 drives but you can also start with a single cable / 4 drives) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8\"&gt;https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$34&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Subtotal&lt;/strong&gt;, ~$150 on the cheaper end. Certainly you should be able to do this for under $200, and you get SAS + SATA drive flexibility &lt;em&gt;and the ability to grow&lt;/em&gt; in a desktop-sized space. UPS also strongly recommended, you can find them on AMZN for ~$75 and up.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;--How I know it works: Bought a cheap used 4TB SAS drive on ebay for $20 for proof-of-concept and threw it in the listed enclosure with a 4TB SATA NAS drive. The SAS has 512 sectors and SATA has 4k sectors, but it works with a ZFS mirror at ashift=12. &lt;/p&gt;\n\n&lt;p&gt;You can mix SAS and SATA drives in the same enclosure as long as you use a SAS HBA in IT mode. Don&amp;#39;t try it with a motherboard SATA controller, those are sata-only connections.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;REF: &lt;a href=\"https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx\"&gt;https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Refer to &amp;quot;4-8-drive-SAS-desktop&amp;quot; sheet&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: If you also buy the 5-bay external HDDRACK listed in the spreadsheet, you can re-use the same (existing) PC power supply. The enclosure uses 2x Molex and the rack uses 5x SATA.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;/ you&amp;#39;re welcome \ud83d\udc7b&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB \ud83d\ude07 \ud83d\ude1c \ud83d\ude43", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tjcgi", "is_robot_indexable": true, "report_reasons": null, "author": "zfsbest", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/", "subreddit_subscribers": 684605, "created_utc": 1685224566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Maybe 6 years ago I bought a four base analogy NAS and 4*16 terabyte WD red drives. Other than a few Synology hiccups with NFS and permissions everything has been more or less fine.\n\nBut since I work in IT, I know that eventually everything dies.\n\nSo do you preemptively replace hardware after a good life?\n\nI ask because I have around 4-5TB terabytes of actual data stored. Of which I used to back up to Google drive at college but that is no more. I do back the data up on external discs maybe once a year when I remember. But those discs are stored in my house and if my house burns down then I lose everything.\n\nI was looking at how much it would cost via cloud services to that much data and it's quite expensive. Especially compared to something like backblaze personal. So with? Potentially replacing the hardware. I was thinking getting a Mac mini with a directly attached storage enclosure and mount the drives that way. This way I could just pay the $7 a month for backblaze", "author_fullname": "t2_a33jxmmgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you preventatively replace working hardware?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tikab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685222467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe 6 years ago I bought a four base analogy NAS and 4*16 terabyte WD red drives. Other than a few Synology hiccups with NFS and permissions everything has been more or less fine.&lt;/p&gt;\n\n&lt;p&gt;But since I work in IT, I know that eventually everything dies.&lt;/p&gt;\n\n&lt;p&gt;So do you preemptively replace hardware after a good life?&lt;/p&gt;\n\n&lt;p&gt;I ask because I have around 4-5TB terabytes of actual data stored. Of which I used to back up to Google drive at college but that is no more. I do back the data up on external discs maybe once a year when I remember. But those discs are stored in my house and if my house burns down then I lose everything.&lt;/p&gt;\n\n&lt;p&gt;I was looking at how much it would cost via cloud services to that much data and it&amp;#39;s quite expensive. Especially compared to something like backblaze personal. So with? Potentially replacing the hardware. I was thinking getting a Mac mini with a directly attached storage enclosure and mount the drives that way. This way I could just pay the $7 a month for backblaze&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tikab", "is_robot_indexable": true, "report_reasons": null, "author": "Overnightboat", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tikab/do_you_preventatively_replace_working_hardware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tikab/do_you_preventatively_replace_working_hardware/", "subreddit_subscribers": 684605, "created_utc": 1685222467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I downloaded the Wayback Machine extension and tried to archive a video, but it just archived everything but the video itself. I looked for guides online, but they were a bit complex.", "author_fullname": "t2_4djned55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy guide to archive YouTube videos on the Wayback Machine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tglbj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685217370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded the Wayback Machine extension and tried to archive a video, but it just archived everything but the video itself. I looked for guides online, but they were a bit complex.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tglbj", "is_robot_indexable": true, "report_reasons": null, "author": "RMS-108_Marasai", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tglbj/easy_guide_to_archive_youtube_videos_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tglbj/easy_guide_to_archive_youtube_videos_on_the/", "subreddit_subscribers": 684605, "created_utc": 1685217370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI'm looking for ways to download whole tiktok user accounts. I know of 4k Tokkit, but it doesn't seem to be able to download the photo slide posts. (There's  Qoob Clips but it's just the testing for 4k tokkit from what i read on 4kdownload's subreddit)\n\nI also know that using a mix of browser extension to grab all links + jdownloader2 works. But the extensions will not always manage to grab all links (an issue with tiktok itself not displaying the link (hovering the mouse on top of the video will only show the www tiktok com link bottom left of the browser). Also using this method makes it harder to update user accounts without redownloading already downloaded posts (keeping all the links in jdownloader would just be a mess, I it just slows down).\n\nDo you know of another way to pull all the links for the videos of a user ? (I think I saw something for that in my search for a solution, but it was from tiktok API, and I have no idea how API's work, not even sure it would return me a list on links). If I can at least grab the links, I'll try to make something my self to sort a list of links downloader/not downloaded.\n\nOr any other tools ? I'v read somepeople talk about yt-dlp, it won't directly download an user account, but if I give it a list of videos it would work, but I tested it on a post with photo slides, it just downloads as video (i'd prefer it as images in a folder).", "author_fullname": "t2_brjsodej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good Tiktok account downloader ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13u3hil", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685288650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for ways to download whole tiktok user accounts. I know of 4k Tokkit, but it doesn&amp;#39;t seem to be able to download the photo slide posts. (There&amp;#39;s  Qoob Clips but it&amp;#39;s just the testing for 4k tokkit from what i read on 4kdownload&amp;#39;s subreddit)&lt;/p&gt;\n\n&lt;p&gt;I also know that using a mix of browser extension to grab all links + jdownloader2 works. But the extensions will not always manage to grab all links (an issue with tiktok itself not displaying the link (hovering the mouse on top of the video will only show the www tiktok com link bottom left of the browser). Also using this method makes it harder to update user accounts without redownloading already downloaded posts (keeping all the links in jdownloader would just be a mess, I it just slows down).&lt;/p&gt;\n\n&lt;p&gt;Do you know of another way to pull all the links for the videos of a user ? (I think I saw something for that in my search for a solution, but it was from tiktok API, and I have no idea how API&amp;#39;s work, not even sure it would return me a list on links). If I can at least grab the links, I&amp;#39;ll try to make something my self to sort a list of links downloader/not downloaded.&lt;/p&gt;\n\n&lt;p&gt;Or any other tools ? I&amp;#39;v read somepeople talk about yt-dlp, it won&amp;#39;t directly download an user account, but if I give it a list of videos it would work, but I tested it on a post with photo slides, it just downloads as video (i&amp;#39;d prefer it as images in a folder).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u3hil", "is_robot_indexable": true, "report_reasons": null, "author": "bob36959", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u3hil/any_good_tiktok_account_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u3hil/any_good_tiktok_account_downloader/", "subreddit_subscribers": 684605, "created_utc": 1685288650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4ulrx5xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Txti, the page from motherfuckingwebsite.com, is shutting down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tx7ol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1685270192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=36102015", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Back to Hdd again", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tx7ol", "is_robot_indexable": true, "report_reasons": null, "author": "Merchant_Lawrence", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13tx7ol/txti_the_page_from_motherfuckingwebsitecom_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=36102015", "subreddit_subscribers": 684605, "created_utc": 1685270192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Transferring files from an internal HDD to an external HDD and the internal is reading 100% utilization but the transfer speed is barely able to stay above 10 MB/s, and sometimes dips to zero for a bit. The external drive I'm transferring to is reading about 5% utilization. The transfer speed just spiked to about 110 MB/s average, with the internal HDD reading around 75% utilization on average and the external picked up to about 40% on average. Noticed that accessing the drive can be slow at times as well, hangs up on stuff etc. The only drives that I've ever failed me in the past were Seagate, and this might be another one of them.\n\nCan't wait for SSDs to start getting cheaper with higher capacities, lol. I use a lot of storage because I do video production, can't afford a NAS setup yet.", "author_fullname": "t2_xp1zqcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my HDD failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twr28", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685268581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Transferring files from an internal HDD to an external HDD and the internal is reading 100% utilization but the transfer speed is barely able to stay above 10 MB/s, and sometimes dips to zero for a bit. The external drive I&amp;#39;m transferring to is reading about 5% utilization. The transfer speed just spiked to about 110 MB/s average, with the internal HDD reading around 75% utilization on average and the external picked up to about 40% on average. Noticed that accessing the drive can be slow at times as well, hangs up on stuff etc. The only drives that I&amp;#39;ve ever failed me in the past were Seagate, and this might be another one of them.&lt;/p&gt;\n\n&lt;p&gt;Can&amp;#39;t wait for SSDs to start getting cheaper with higher capacities, lol. I use a lot of storage because I do video production, can&amp;#39;t afford a NAS setup yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13twr28", "is_robot_indexable": true, "report_reasons": null, "author": "theseawoof", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13twr28/is_my_hdd_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13twr28/is_my_hdd_failing/", "subreddit_subscribers": 684605, "created_utc": 1685268581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've recently started to save old DVDs but I'm having a bit of trouble finding a proper way to get the encoding correct. The way that I'm currently doing it is save all the data with MakeMKV, then use HandBrake to convert the data into a singular MKV-file. It's that final step that I'm not sure how to properly do to ensure that I get the best quality. \n\nI guess this becomes more of a \"how to use HandBrake\" but I use:\n\n* Video &gt; Framerate: Same as source\n* Audio: All tracks\n* Subtitles All tracks\n* Dimensions: Allow upscaling\n\nThe rest I leave for defaults. Is \"same as source\" the best way to get a proper framerate or am I losing out on some other optimizations here? Should I apply some filters for better video quality, especially for older DVDs? Should I increase the audio bitrate from the default 160 or is that just increasing the file size without gaining any benefits in quality? I'd love to hear what you guys think.", "author_fullname": "t2_bjlgrfr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended encodings and other settings for digitizing your DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twqa0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685268501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently started to save old DVDs but I&amp;#39;m having a bit of trouble finding a proper way to get the encoding correct. The way that I&amp;#39;m currently doing it is save all the data with MakeMKV, then use HandBrake to convert the data into a singular MKV-file. It&amp;#39;s that final step that I&amp;#39;m not sure how to properly do to ensure that I get the best quality. &lt;/p&gt;\n\n&lt;p&gt;I guess this becomes more of a &amp;quot;how to use HandBrake&amp;quot; but I use:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Video &amp;gt; Framerate: Same as source&lt;/li&gt;\n&lt;li&gt;Audio: All tracks&lt;/li&gt;\n&lt;li&gt;Subtitles All tracks&lt;/li&gt;\n&lt;li&gt;Dimensions: Allow upscaling&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The rest I leave for defaults. Is &amp;quot;same as source&amp;quot; the best way to get a proper framerate or am I losing out on some other optimizations here? Should I apply some filters for better video quality, especially for older DVDs? Should I increase the audio bitrate from the default 160 or is that just increasing the file size without gaining any benefits in quality? I&amp;#39;d love to hear what you guys think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13twqa0", "is_robot_indexable": true, "report_reasons": null, "author": "ConstantConsumption", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13twqa0/recommended_encodings_and_other_settings_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13twqa0/recommended_encodings_and_other_settings_for/", "subreddit_subscribers": 684605, "created_utc": 1685268501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My requirements I think are simple. I have a 16TB mirror raid (I'm a n00b yes) of stuff and it currently gets backed up against 2 8TB drives in my garage on a proxmox backup server. \n\nI'd like to back that up on a tape and take it offsite and then have another tape at home and do a rotation. Problem is, tape drives seem to be expensive. \n\nCan anyone recommended a good backup tape drive solution which is cheap and fits all my data on one tape ? Or some other solution I haven't thought of ? Do I need to buy more hard drives and rotate spinning rust instead ?\n\nThanks", "author_fullname": "t2_7pvjhp35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap tape backup solutions for 16TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twg7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685267514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My requirements I think are simple. I have a 16TB mirror raid (I&amp;#39;m a n00b yes) of stuff and it currently gets backed up against 2 8TB drives in my garage on a proxmox backup server. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to back that up on a tape and take it offsite and then have another tape at home and do a rotation. Problem is, tape drives seem to be expensive. &lt;/p&gt;\n\n&lt;p&gt;Can anyone recommended a good backup tape drive solution which is cheap and fits all my data on one tape ? Or some other solution I haven&amp;#39;t thought of ? Do I need to buy more hard drives and rotate spinning rust instead ?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13twg7o", "is_robot_indexable": true, "report_reasons": null, "author": "givemejuice1229", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13twg7o/cheap_tape_backup_solutions_for_16tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13twg7o/cheap_tape_backup_solutions_for_16tb/", "subreddit_subscribers": 684605, "created_utc": 1685267514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I recently made a new Google account and I wanted to transfer my old account data such as YouTube, News, Chrome and etc. I tried to use Google takeout but, it doesn't directly send it to the new my account. Could anyone please help me?", "author_fullname": "t2_popy2nq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring old data from Google account to a new account.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "name": "t3_13tsun7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EMwhqy2Viv719nRYsPNRWtpdGDOh7G4tRSZGNqpmc4I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685253694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I recently made a new Google account and I wanted to transfer my old account data such as YouTube, News, Chrome and etc. I tried to use Google takeout but, it doesn&amp;#39;t directly send it to the new my account. Could anyone please help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/j23uhrpg0k2b1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?auto=webp&amp;v=enabled&amp;s=2d32759f4ef13c2f9e52eea584d28bb539ea0041", "width": 1372, "height": 1297}, "resolutions": [{"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7c46c520b64d46cabfdac96794d300ba5612e85", "width": 108, "height": 102}, {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02cea1efbd3f29b28bd2f66f9bf504858afe0c1f", "width": 216, "height": 204}, {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=540459fc124f3fa6f4658399d9c2f343fd1696aa", "width": 320, "height": 302}, {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46807616d15e0c94a37c7575ed989be2b351a3a5", "width": 640, "height": 605}, {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f359baeae3bc63de7bd93030087982facdd3dbe4", "width": 960, "height": 907}, {"url": "https://preview.redd.it/j23uhrpg0k2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31cdc61799281a7f325709aa1715535ba4d336c0", "width": 1080, "height": 1020}], "variants": {}, "id": "ptR5Psar-bowt5c1K65c4E1Ofjtks4THlo8SaQZLsDQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tsun7", "is_robot_indexable": true, "report_reasons": null, "author": "Shaunaghini", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tsun7/transferring_old_data_from_google_account_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/j23uhrpg0k2b1.jpg", "subreddit_subscribers": 684605, "created_utc": 1685253694.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}