{"kind": "Listing", "data": {"after": "t3_13theis", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can't believe I've gone all these years without using --embed-metadata.  It seems like it should be mandatory for most data hoarders.\n\nWhat else am I missing out on?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TIL about yt-dlp's amazing --embed-metadata flag. What are some other essential settings for dedicated data hoarders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tnkn0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 502, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 502, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685236040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t believe I&amp;#39;ve gone all these years without using --embed-metadata.  It seems like it should be mandatory for most data hoarders.&lt;/p&gt;\n\n&lt;p&gt;What else am I missing out on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tnkn0", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 114, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tnkn0/til_about_ytdlps_amazing_embedmetadata_flag_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tnkn0/til_about_ytdlps_amazing_embedmetadata_flag_what/", "subreddit_subscribers": 684616, "created_utc": 1685236040.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I purchased four new WD Red Pro 16TB drives from a seemingly reputable company, and two don't work out of the box. I don't think they were shipped well, as there's no padding (see photos). My Synology system immediately recognised two of the drives and let me rebuild the RAID (DS918+ RAID6), but the other two wouldn't initialise, and one couldn't be seen at all. Both drives spun up but made a lovely buzzing noise! I'm 99% sure the two drives are mechanically damaged from poor transport packaging, but I wanted to hear what you all think.", "author_fullname": "t2_m22sb4ul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "WD Red Pro\u2019s Failed - out the box!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eotypdckch2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a563c6b643c8a514b71523dfe750c5df8979f68"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49bcac58810c7b5fdec888c75ec6d00bfed853f9"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99adada243e596c3103416cfac8778becb97d16d"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ac2afef984fe5a3556f908c8e2cdfe541e2af22"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7399ee687c333c82061a850c20d5d7218288a7c"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25329000bce2da9c6f6e5cdb8ec0457fb3d2077a"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/eotypdckch2b1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c76c96ab458c6cecd6e8b2001429670031cd54b0"}, "id": "eotypdckch2b1"}, "ouoi1eckch2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4f68f838fde07fb1284c1c7113cb9ab5848f3d2"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=768936673c0f7ae6ccc92c986517ce39980f2eb5"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52d2bde334d09afb9901e5f0cac6deb1662e39ff"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1de33cd12514aba31cb745121e15334e31028b2a"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15fb3d57f7e79e46f5275aec609d3a6d7aa998d0"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=120686ea85f2b53840c786bc1a37e2c8abdbd3f8"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/ouoi1eckch2b1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=70a3a11a487d92c616d368ca4c7fe2be70341f53"}, "id": "ouoi1eckch2b1"}}, "name": "t3_13ti61z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 147, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "ouoi1eckch2b1", "id": 280492863}, {"media_id": "eotypdckch2b1", "id": 280492864}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 147, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fSD5HaV0wdmDJfL6oU7Ao02CoenSABWSadEKJjvrY5E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685221442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased four new WD Red Pro 16TB drives from a seemingly reputable company, and two don&amp;#39;t work out of the box. I don&amp;#39;t think they were shipped well, as there&amp;#39;s no padding (see photos). My Synology system immediately recognised two of the drives and let me rebuild the RAID (DS918+ RAID6), but the other two wouldn&amp;#39;t initialise, and one couldn&amp;#39;t be seen at all. Both drives spun up but made a lovely buzzing noise! I&amp;#39;m 99% sure the two drives are mechanically damaged from poor transport packaging, but I wanted to hear what you all think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13ti61z", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13ti61z", "is_robot_indexable": true, "report_reasons": null, "author": "DrCuthbert", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ti61z/wd_red_pros_failed_out_the_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13ti61z", "subreddit_subscribers": 684616, "created_utc": 1685221442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_px8520be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Water Cooling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13tw0fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 118, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 118, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V59O1aA0yRlp4xFOlw2Eweyt6KrIP5PybnJbHs8MIUU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685265879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/r7zxouaxij2b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?auto=webp&amp;v=enabled&amp;s=6863844aa4e23060991fb7b80b8625aa11771ded", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83ba75e7289fe0a2d4c019a64b3e2d04076253d5", "width": 108, "height": 81}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ac4684a7a24589118983f8926e8092122dbc39c", "width": 216, "height": 162}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fcbb0ef4d6afc59e29bb57efaee239b7bf41998", "width": 320, "height": 240}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=817aecf1531f63ab8bd230e4636e0c9256490769", "width": 640, "height": 480}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0d78f7d14d4e77d115cb7c0ebb87eb8b97c9f3d", "width": 960, "height": 720}, {"url": "https://preview.redd.it/r7zxouaxij2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccef78dd60ae062ea734afc51741cad4881d42e0", "width": 1080, "height": 810}], "variants": {}, "id": "AYYC22kjNQjhYNXtxeuUoaZODPdEXGbF_EFtVK7K5AA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tw0fb", "is_robot_indexable": true, "report_reasons": null, "author": "Thousand_Hands_4032", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tw0fb/hdd_water_cooling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/r7zxouaxij2b1.jpg", "subreddit_subscribers": 684616, "created_utc": 1685265879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My Toshiba 1TB Hard Drive has 1845 bad sectors. Im planning on buying a new one (probably a SSD this time), but I dont want the same thing to happen again. So what causes those Bad Sectors?", "author_fullname": "t2_yo96h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What causes Bad sectors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1su9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685284171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Toshiba 1TB Hard Drive has 1845 bad sectors. Im planning on buying a new one (probably a SSD this time), but I dont want the same thing to happen again. So what causes those Bad Sectors?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u1su9", "is_robot_indexable": true, "report_reasons": null, "author": "bigmactv", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u1su9/what_causes_bad_sectors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u1su9/what_causes_bad_sectors/", "subreddit_subscribers": 684616, "created_utc": 1685284171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently, an automotive forum for the Chevrolet Camaro known as Camaro6 (As well it\u2019s sister sites, Camaro5 and Corvette forums) was down for the last 5 days. As a novice DIY mechanic, not having the wealth of knowledge available to access was detrimental to those of us that seek answers that only people with our cars may have. \n\nThe forum owners seem to be completely disengaged with the sites as a whole, and after this recent week long downtime I figure it\u2019s only a matter of time before the knowledge contained in these forums are lost forever. \n\nThe site seems to be up for now, so I\u2019d like to ask for advice on how to best save the forum on Wayback machine, or another archive site.", "author_fullname": "t2_3zslcd55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best way to archive an entire forum?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u6qkf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685296646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, an automotive forum for the Chevrolet Camaro known as Camaro6 (As well it\u2019s sister sites, Camaro5 and Corvette forums) was down for the last 5 days. As a novice DIY mechanic, not having the wealth of knowledge available to access was detrimental to those of us that seek answers that only people with our cars may have. &lt;/p&gt;\n\n&lt;p&gt;The forum owners seem to be completely disengaged with the sites as a whole, and after this recent week long downtime I figure it\u2019s only a matter of time before the knowledge contained in these forums are lost forever. &lt;/p&gt;\n\n&lt;p&gt;The site seems to be up for now, so I\u2019d like to ask for advice on how to best save the forum on Wayback machine, or another archive site.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u6qkf", "is_robot_indexable": true, "report_reasons": null, "author": "TheSixSpeed", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u6qkf/whats_the_best_way_to_archive_an_entire_forum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u6qkf/whats_the_best_way_to_archive_an_entire_forum/", "subreddit_subscribers": 684616, "created_utc": 1685296646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I built a plex server last year and quickly expanded from a 10tb server to a 50 tb server before I remembered \"I should start backing this stuff up just in case\". So now I'm looking for a cost effective method to back up my data just in case, but I know I don't have the money to buy another 50tb of hard drives right now.", "author_fullname": "t2_3sipc6qf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backup data in cost effective way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u6ufj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685296907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built a plex server last year and quickly expanded from a 10tb server to a 50 tb server before I remembered &amp;quot;I should start backing this stuff up just in case&amp;quot;. So now I&amp;#39;m looking for a cost effective method to back up my data just in case, but I know I don&amp;#39;t have the money to buy another 50tb of hard drives right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u6ufj", "is_robot_indexable": true, "report_reasons": null, "author": "WxaithBrynger", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u6ufj/how_to_backup_data_in_cost_effective_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u6ufj/how_to_backup_data_in_cost_effective_way/", "subreddit_subscribers": 684616, "created_utc": 1685296907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After [my sandisks are no longer trustworthy](https://www.theverge.com/2023/5/22/23733267/sandisk-extreme-pro-failure-ssd-firmware) I'm looking into either getting a couple Samsung T7s or getting an external NVME enclosure with an 8TB m.2 ssd.\n\nI am worried about the reliability, however. I can find plenty of reviews all day of people who use them as storage drives, game console drives, etc. but it's hard to find much info about people who are transferring tons of data on/off at a time.\n\nI do video productions so a regular day could see 3-4tb of data transferring to a drive, then that drive being used as a primary for encoding footage/uploading/etc. I always practice double or more when possible backups but having my primary drive fail is still an annoyance that I don't want to deal with.\n\nAnyone in the same field/similar workflow that's got experience with a specific enclosure/brand of SSD?", "author_fullname": "t2_2f2tnu1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have real world practice transferring tbs of data on and off an external M.2 thunderbolt/usb4 ssd enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tkm30", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685227951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After &lt;a href=\"https://www.theverge.com/2023/5/22/23733267/sandisk-extreme-pro-failure-ssd-firmware\"&gt;my sandisks are no longer trustworthy&lt;/a&gt; I&amp;#39;m looking into either getting a couple Samsung T7s or getting an external NVME enclosure with an 8TB m.2 ssd.&lt;/p&gt;\n\n&lt;p&gt;I am worried about the reliability, however. I can find plenty of reviews all day of people who use them as storage drives, game console drives, etc. but it&amp;#39;s hard to find much info about people who are transferring tons of data on/off at a time.&lt;/p&gt;\n\n&lt;p&gt;I do video productions so a regular day could see 3-4tb of data transferring to a drive, then that drive being used as a primary for encoding footage/uploading/etc. I always practice double or more when possible backups but having my primary drive fail is still an annoyance that I don&amp;#39;t want to deal with.&lt;/p&gt;\n\n&lt;p&gt;Anyone in the same field/similar workflow that&amp;#39;s got experience with a specific enclosure/brand of SSD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?auto=webp&amp;v=enabled&amp;s=f1a80dc66c139e4c095e9b193dd24fdfb44acfbd", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af5a05c8d2309de8cf918831b6b269441e804a38", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b3f8c6eecff810f7c24ea1e326b39c91ed179d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06fcfa65dbbad3677411db727c25ed209e2d18f5", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=494c4bbe78d1745bc0fe6dbe47a0cee11efab8d4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=801063985f749f8669cf7a6def2faee6d23981af", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/_m34z133Cy7BEFuLX2X5kK5rk9EMRQVu7ofy2Yjn7cA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9a0e5dc37e20c826a0c3bcd984ac115250f885b", "width": 1080, "height": 565}], "variants": {}, "id": "XN6OaUWNpbs1WEk2cS4aWDJo0_5XTeC3P8kYKCCtrAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tkm30", "is_robot_indexable": true, "report_reasons": null, "author": "PresentFault", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tkm30/anyone_have_real_world_practice_transferring_tbs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tkm30/anyone_have_real_world_practice_transferring_tbs/", "subreddit_subscribers": 684616, "created_utc": 1685227951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " On  Win11 one of my main external storage drive is giving me some trouble with missing files and permissions. After a restart the icon was suddenly a white sheet of paper instead of the drive icon and the drive was not accessible - it was not asking me to format (just an error message saying access denied) and looked fine in drive manager. \n\n* I  noticed the permissions were weird - they were all blank and the owner  was unknown. I changed the permissions to be the same as my other drives  (owner: SYSTEM with full access for admin. added users, added everyone.  It scanned all the files and gave me a LOT of  \"Failed to  enumerate objects in the container. Access is denied\" errors like:  D\\\\found.000\\\\30000000-$boot, D\\\\found.000\\\\310000000-(foldername),  d\\\\found.000\\\\340000000file.chk..etc.... I clicked continue on a few but eventually had to cancel because there were too many.\n* after  the permissions change I could open the drive but I can only see a few  files and folders - almost everything is gone even though it says most  of the drive is full. All the files that were within the folders that  could not be enumerated in the previous step are not visible or  accessible.\n* I tried system restore from a week ago and it did not fix it.\n* I checked system event viewer and I see at the exact same time that the windows update finished\n\n&gt;Installation  Successful: Windows successfully installed the following update:  Security Intelligence Update for Microsoft Defender Antivirus -  KB2267602 (Version 1.389.2544.0)\n\nthat two errors popped up  from Ntfs (microsoft-windows-ntfs) and ntfs(ntfs):\n\n&gt;Volume  D: (\\\\Device\\\\HarddiskVolume14) needs to be taken offline to perform a  Full Chkdsk.  Please run \"CHKDSK /F\" locally via the command line, or  run \"REPAIR-VOLUME &lt;drive:&gt;\" locally or remotely via PowerShell.\n\nand\n\n&gt;A  corruption was discovered in the file system structure on volume D:.  The Master File Table (MFT) contains a corrupted file record.  The file  reference number is 0xb00000000000b.  The name of the file is  \"&lt;unable to determine file name&gt;\".\n\nBoth chkdsk f and r and Repair-Volume show no errors... chkdsk also shows 6378467 MB in 94646 files. So it sees all of the files there that I cant see or access. \n\nCrystalDiskInfo says the drive is healthy.\n\nThe drive shows there's only 1.19tb of 8tb free but only has about 1tb of files that I can actually view. (I have the option to view hidden files checked so they are not hidden)\n\nI did a scan with easus data recovery and it immediately showed all of the missing files in a found.000 folder. \n\n&amp;#x200B;\n\nAny ideas to get proper access back? or is it necessary to \"restore\" these files from the found.000 folder via data recovery software? \n\n&amp;#x200B;\n\nAnd yes I do have backups - but it's a long term updated backup not mirrored so it would be a pretty time consuming process to have to pull the specific \\~6tb of files to get things back to how they were so that my media/file server can reconnect seamlessly.", "author_fullname": "t2_2dzj3r6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File permission issues causing lost files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13u85gi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685300342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On  Win11 one of my main external storage drive is giving me some trouble with missing files and permissions. After a restart the icon was suddenly a white sheet of paper instead of the drive icon and the drive was not accessible - it was not asking me to format (just an error message saying access denied) and looked fine in drive manager. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I  noticed the permissions were weird - they were all blank and the owner  was unknown. I changed the permissions to be the same as my other drives  (owner: SYSTEM with full access for admin. added users, added everyone.  It scanned all the files and gave me a LOT of  &amp;quot;Failed to  enumerate objects in the container. Access is denied&amp;quot; errors like:  D\\found.000\\30000000-$boot, D\\found.000\\310000000-(foldername),  d\\found.000\\340000000file.chk..etc.... I clicked continue on a few but eventually had to cancel because there were too many.&lt;/li&gt;\n&lt;li&gt;after  the permissions change I could open the drive but I can only see a few  files and folders - almost everything is gone even though it says most  of the drive is full. All the files that were within the folders that  could not be enumerated in the previous step are not visible or  accessible.&lt;/li&gt;\n&lt;li&gt;I tried system restore from a week ago and it did not fix it.&lt;/li&gt;\n&lt;li&gt;I checked system event viewer and I see at the exact same time that the windows update finished&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Installation  Successful: Windows successfully installed the following update:  Security Intelligence Update for Microsoft Defender Antivirus -  KB2267602 (Version 1.389.2544.0)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;that two errors popped up  from Ntfs (microsoft-windows-ntfs) and ntfs(ntfs):&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Volume  D: (\\Device\\HarddiskVolume14) needs to be taken offline to perform a  Full Chkdsk.  Please run &amp;quot;CHKDSK /F&amp;quot; locally via the command line, or  run &amp;quot;REPAIR-VOLUME &amp;lt;drive:&amp;gt;&amp;quot; locally or remotely via PowerShell.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;A  corruption was discovered in the file system structure on volume D:.  The Master File Table (MFT) contains a corrupted file record.  The file  reference number is 0xb00000000000b.  The name of the file is  &amp;quot;&amp;lt;unable to determine file name&amp;gt;&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Both chkdsk f and r and Repair-Volume show no errors... chkdsk also shows 6378467 MB in 94646 files. So it sees all of the files there that I cant see or access. &lt;/p&gt;\n\n&lt;p&gt;CrystalDiskInfo says the drive is healthy.&lt;/p&gt;\n\n&lt;p&gt;The drive shows there&amp;#39;s only 1.19tb of 8tb free but only has about 1tb of files that I can actually view. (I have the option to view hidden files checked so they are not hidden)&lt;/p&gt;\n\n&lt;p&gt;I did a scan with easus data recovery and it immediately showed all of the missing files in a found.000 folder. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any ideas to get proper access back? or is it necessary to &amp;quot;restore&amp;quot; these files from the found.000 folder via data recovery software? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And yes I do have backups - but it&amp;#39;s a long term updated backup not mirrored so it would be a pretty time consuming process to have to pull the specific ~6tb of files to get things back to how they were so that my media/file server can reconnect seamlessly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u85gi", "is_robot_indexable": true, "report_reasons": null, "author": "smilesdavis8d", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u85gi/file_permission_issues_causing_lost_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u85gi/file_permission_issues_causing_lost_files/", "subreddit_subscribers": 684616, "created_utc": 1685300342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought the HP OMEN 17-ck1020nr 17.3\" Gaming Laptop with i7 12700, 3070ti, 16GB DDR5-4800, and 500GB SSD and want to upgrade the SSD to future proof the next 5-7 years. \n\nI have a second SSD slot and have never upgraded a laptop before. I was thinking given I enjoy photography/videography/gaming, that I should get a larger SSD and keep the 500GB SSD for now until a later time to upgrade comes. \n\nBefore I look for 4tb laptop SSDs, can any of you tell me if I should be considering a 2x2 setup instead? I don\u2019t know how easy it is to copy the main O/S drive over, but right now it does seem 2x2tb is close to the price of the 4tb SSDs. I know nothing beyond the large brands either, so any product recommendations are welcome! \n\nLooking for general advice here, if anyone also has any advice on if it\u2019s worthwhile to upgrade the RAM now versus later I\u2019m all ears too!! Thanks!", "author_fullname": "t2_4v5kn1zy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help upgrading gaming/photography laptop storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u7oft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685299099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought the HP OMEN 17-ck1020nr 17.3&amp;quot; Gaming Laptop with i7 12700, 3070ti, 16GB DDR5-4800, and 500GB SSD and want to upgrade the SSD to future proof the next 5-7 years. &lt;/p&gt;\n\n&lt;p&gt;I have a second SSD slot and have never upgraded a laptop before. I was thinking given I enjoy photography/videography/gaming, that I should get a larger SSD and keep the 500GB SSD for now until a later time to upgrade comes. &lt;/p&gt;\n\n&lt;p&gt;Before I look for 4tb laptop SSDs, can any of you tell me if I should be considering a 2x2 setup instead? I don\u2019t know how easy it is to copy the main O/S drive over, but right now it does seem 2x2tb is close to the price of the 4tb SSDs. I know nothing beyond the large brands either, so any product recommendations are welcome! &lt;/p&gt;\n\n&lt;p&gt;Looking for general advice here, if anyone also has any advice on if it\u2019s worthwhile to upgrade the RAM now versus later I\u2019m all ears too!! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u7oft", "is_robot_indexable": true, "report_reasons": null, "author": "bourbonexplorer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u7oft/help_upgrading_gamingphotography_laptop_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u7oft/help_upgrading_gamingphotography_laptop_storage/", "subreddit_subscribers": 684616, "created_utc": 1685299099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have used Picard and mp3tag to organize my 75k+ file library for my Plexamp manager.  They problem is that I have alot of duplicate flac/mp3 entries, so some albums are 2x files.  \n\nI am looking for a way I can dive into a library with a script, compare or convert any duplicates into mp3 (I am not a sound snob, I don't care about lossless), so I can have 1 entry per track.\n\nIs there a script/program (linux or windows) or an 'arr' that can help me clean all these extras up?", "author_fullname": "t2_np6lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch cleanup of music library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u6nki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685296428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have used Picard and mp3tag to organize my 75k+ file library for my Plexamp manager.  They problem is that I have alot of duplicate flac/mp3 entries, so some albums are 2x files.  &lt;/p&gt;\n\n&lt;p&gt;I am looking for a way I can dive into a library with a script, compare or convert any duplicates into mp3 (I am not a sound snob, I don&amp;#39;t care about lossless), so I can have 1 entry per track.&lt;/p&gt;\n\n&lt;p&gt;Is there a script/program (linux or windows) or an &amp;#39;arr&amp;#39; that can help me clean all these extras up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u6nki", "is_robot_indexable": true, "report_reasons": null, "author": "digitalamish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u6nki/batch_cleanup_of_music_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u6nki/batch_cleanup_of_music_library/", "subreddit_subscribers": 684616, "created_utc": 1685296428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "String distance based network for fuzzy matching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u6ir7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_hdmiw", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just started a data science internship, and my small team's first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). \n\nStandard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don't know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you're not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.\n\nMy idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. \n\nHas anyone tried this network-based fuzzy matching? Does it even sound promising? \n\n(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I'm encouraged to experiment for the sake of learning, even if it's a little less time efficient. We also have a VM to use over the summer for free.)", "author_fullname": "t2_hdmiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "String distance based network for fuzzy matching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u4sd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685293119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685291834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started a data science internship, and my small team&amp;#39;s first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). &lt;/p&gt;\n\n&lt;p&gt;Standard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don&amp;#39;t know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you&amp;#39;re not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.&lt;/p&gt;\n\n&lt;p&gt;My idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this network-based fuzzy matching? Does it even sound promising? &lt;/p&gt;\n\n&lt;p&gt;(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I&amp;#39;m encouraged to experiment for the sake of learning, even if it&amp;#39;s a little less time efficient. We also have a VM to use over the summer for free.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u4sd7", "is_robot_indexable": true, "report_reasons": null, "author": "ChiefWilliam", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "subreddit_subscribers": 911687, "created_utc": 1685291834.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1685296084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u6ir7", "is_robot_indexable": true, "report_reasons": null, "author": "ChiefWilliam", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13u4sd7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u6ir7/string_distance_based_network_for_fuzzy_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "subreddit_subscribers": 684616, "created_utc": 1685296084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 150000+ emails currently saved up. There is some important stuff in them and a lot of spam. Some of the spam is interesting (like social notifications showing whole post conversations) and some is outright malicious or has attachments I should never open. The original file for one of them is in pst format, but I am not completely sure if I am going to lose anything by converting it in mbox or other formats. (readpst was able to throw away directly all attachments and rtf body attachments, even if I am not sure about what the second thing means, but it worked fine).\n\nThe filesize either way is obviously a non issue. However, I am scared about the safety of the whole thing for two reasons: I am not sure about potential threats that can come from some of the emails, and I want to be able to store these emails in some cloud backup service without anyone else having access to them in the worst realistic case scenario.\n\nThe first one could be solved by setting up a vm, not even giving it internet access after the initial setup so I don't have to worry about anything running in the background or emails trying to do weird stuff like checking if someone is trying to pull an image from some server. I dont think the html itself could he harmful. For accessing the actual emails I checked evolution and it was fine, I was having issues with some other programs. I didnt check thunderbird.\n\nThe second issue could be maybe solved by only storing password protected archives, making sure the password is good enough. But I don't know much about it and heard stories about it only working in certain situations, if you are using certain options and in some cases some of the data can still be accessed with some compression formats. \n\nBut I imagine this second question is more broad and doesnt just deal with this specific case. So, overall I'm not sure. How do you go about it?", "author_fullname": "t2_7b7hahqv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any email hoarders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tqout", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685246013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 150000+ emails currently saved up. There is some important stuff in them and a lot of spam. Some of the spam is interesting (like social notifications showing whole post conversations) and some is outright malicious or has attachments I should never open. The original file for one of them is in pst format, but I am not completely sure if I am going to lose anything by converting it in mbox or other formats. (readpst was able to throw away directly all attachments and rtf body attachments, even if I am not sure about what the second thing means, but it worked fine).&lt;/p&gt;\n\n&lt;p&gt;The filesize either way is obviously a non issue. However, I am scared about the safety of the whole thing for two reasons: I am not sure about potential threats that can come from some of the emails, and I want to be able to store these emails in some cloud backup service without anyone else having access to them in the worst realistic case scenario.&lt;/p&gt;\n\n&lt;p&gt;The first one could be solved by setting up a vm, not even giving it internet access after the initial setup so I don&amp;#39;t have to worry about anything running in the background or emails trying to do weird stuff like checking if someone is trying to pull an image from some server. I dont think the html itself could he harmful. For accessing the actual emails I checked evolution and it was fine, I was having issues with some other programs. I didnt check thunderbird.&lt;/p&gt;\n\n&lt;p&gt;The second issue could be maybe solved by only storing password protected archives, making sure the password is good enough. But I don&amp;#39;t know much about it and heard stories about it only working in certain situations, if you are using certain options and in some cases some of the data can still be accessed with some compression formats. &lt;/p&gt;\n\n&lt;p&gt;But I imagine this second question is more broad and doesnt just deal with this specific case. So, overall I&amp;#39;m not sure. How do you go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tqout", "is_robot_indexable": true, "report_reasons": null, "author": "GRINDSETuwu", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tqout/any_email_hoarders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tqout/any_email_hoarders/", "subreddit_subscribers": 684616, "created_utc": 1685246013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nHello,\n\nI am looking for someone who have experience in regards of designing PCB SATA backplane\n\nAm hoping to create 12 SATA slot backplane via SATA-3 interface on PCB for my custom build NAS case. If anyone have a sample file or CAD design, would love to hear your input or guide me to right direction.\n\nAlso, what is the most popular PCB manufacturer and how much does it cost to make this board?\n\nI am new to this and would love to learn this process. It's a fun project.\n\nThank you sir/madam for reading this.", "author_fullname": "t2_7ehbae6um", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCB SATA Backplane Designer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tk8ud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685226966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am looking for someone who have experience in regards of designing PCB SATA backplane&lt;/p&gt;\n\n&lt;p&gt;Am hoping to create 12 SATA slot backplane via SATA-3 interface on PCB for my custom build NAS case. If anyone have a sample file or CAD design, would love to hear your input or guide me to right direction.&lt;/p&gt;\n\n&lt;p&gt;Also, what is the most popular PCB manufacturer and how much does it cost to make this board?&lt;/p&gt;\n\n&lt;p&gt;I am new to this and would love to learn this process. It&amp;#39;s a fun project.&lt;/p&gt;\n\n&lt;p&gt;Thank you sir/madam for reading this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tk8ud", "is_robot_indexable": true, "report_reasons": null, "author": "Cluster_NAS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tk8ud/pcb_sata_backplane_designer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tk8ud/pcb_sata_backplane_designer/", "subreddit_subscribers": 684616, "created_utc": 1685226966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\\--So you bought some SAS drives on the cheap, and now you want to use them without spending a bunch of money on a big backplane or 1-off adapter. You need 1-2 free x4 PCIe slots, or just 1 slot if you go with a Noctua fan. You need to keep the SAS card actively cooled.\n\n&amp;#x200B;\n\nParts list:\n\n&amp;#x200B;\n\n5-bay enclosure (buy x2 for 8-10 drive support)\n\n[https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;ref=ppx\\_yo2ov\\_dt\\_b\\_product\\_details](https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details)\n\n\\^ $68(!) at time of post\n\n&amp;#x200B;\n\nNote - I leave the 5th bay open for drive swaps, they eventually die and you can just switch the cable.\n\n&amp;#x200B;\n\n2-port external (-8E) SAS HBA\n\n[https://www.ebay.com/sch/i.html?\\_from=R40&amp;\\_nkw=sas9200-8e+IT+mode&amp;\\_sacat=0&amp;LH\\_TitleDesc=0&amp;LH\\_PrefLoc=2&amp;\\_sop=15](https://www.ebay.com/sch/i.html?_from=R40&amp;_nkw=sas9200-8e+IT+mode&amp;_sacat=0&amp;LH_TitleDesc=0&amp;LH_PrefLoc=2&amp;_sop=15)\n\n\\^ \\~$19-40 on ebay\n\n&amp;#x200B;\n\nFan for the HBA, takes up a slot\n\n[https://www.amazon.com/gp/product/B000233ZMU/ref=ppx\\_yo\\_dt\\_b\\_search\\_asin\\_title?ie=UTF8&amp;psc=1](https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1)\n\n\\~$20\n\n&amp;#x200B;\n\nStandard PC power supply with 2x 4-pin Molex power \n\n[https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT](https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT)\n\n\\~$45-50, less if you already have one lying around\n\n&amp;#x200B;\n\nSAS cables (2-pack, good for 8 drives but you can also start with a single cable / 4 drives) \n\n[https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8](https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8)\n\n\\~$34\n\n&amp;#x200B;\n\n**Subtotal**, \\~$150 on the cheaper end. Certainly you should be able to do this for under $200, and you get SAS + SATA drive flexibility *and the ability to grow* in a desktop-sized space. UPS also strongly recommended, you can find them on AMZN for \\~$75 and up.\n\n&amp;#x200B;\n\n\\--How I know it works: Bought a cheap used 4TB SAS drive on ebay for $20 for proof-of-concept and threw it in the listed enclosure with a 4TB SATA NAS drive. The SAS has 512 sectors and SATA has 4k sectors, but it works with a ZFS mirror at ashift=12. \n\nYou can mix SAS and SATA drives in the same enclosure as long as you use a SAS HBA in IT mode. Don't try it with a motherboard SATA controller, those are sata-only connections.\n\n&amp;#x200B;\n\nREF: [https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx](https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx)\n\nRefer to \"4-8-drive-SAS-desktop\" sheet\n\n&amp;#x200B;\n\n**Bonus**: If you also buy the 5-bay external HDDRACK listed in the spreadsheet, you can re-use the same (existing) PC power supply. The enclosure uses 2x Molex and the rack uses 5x SATA.\n\n&amp;#x200B;\n\n/ you're welcome \ud83d\udc7b", "author_fullname": "t2_1vbtepb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HOWTO - Maybe the cheapest way to use 4-8 SAS drives on your desktop without buying an expensive 1-off adapter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tjcgi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685224566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;--So you bought some SAS drives on the cheap, and now you want to use them without spending a bunch of money on a big backplane or 1-off adapter. You need 1-2 free x4 PCIe slots, or just 1 slot if you go with a Noctua fan. You need to keep the SAS card actively cooled.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Parts list:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;5-bay enclosure (buy x2 for 8-10 drive support)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details\"&gt;https://www.amazon.com/dp/B0BV142WM5?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;^ $68(!) at time of post&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note - I leave the 5th bay open for drive swaps, they eventually die and you can just switch the cable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2-port external (-8E) SAS HBA&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebay.com/sch/i.html?_from=R40&amp;amp;_nkw=sas9200-8e+IT+mode&amp;amp;_sacat=0&amp;amp;LH_TitleDesc=0&amp;amp;LH_PrefLoc=2&amp;amp;_sop=15\"&gt;https://www.ebay.com/sch/i.html?_from=R40&amp;amp;_nkw=sas9200-8e+IT+mode&amp;amp;_sacat=0&amp;amp;LH_TitleDesc=0&amp;amp;LH_PrefLoc=2&amp;amp;_sop=15&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;^ ~$19-40 on ebay&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Fan for the HBA, takes up a slot&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1\"&gt;https://www.amazon.com/gp/product/B000233ZMU/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$20&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Standard PC power supply with 2x 4-pin Molex power &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT\"&gt;https://www.amazon.com/ARESGAME-Supply-Certified-Modular-Warranty/dp/B0BDCKFJJT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$45-50, less if you already have one lying around&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SAS cables (2-pack, good for 8 drives but you can also start with a single cable / 4 drives) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8\"&gt;https://www.amazon.com/CableCreation-External-26pin-SFF-8088-Cable/dp/B07CL2V1B8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~$34&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Subtotal&lt;/strong&gt;, ~$150 on the cheaper end. Certainly you should be able to do this for under $200, and you get SAS + SATA drive flexibility &lt;em&gt;and the ability to grow&lt;/em&gt; in a desktop-sized space. UPS also strongly recommended, you can find them on AMZN for ~$75 and up.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;--How I know it works: Bought a cheap used 4TB SAS drive on ebay for $20 for proof-of-concept and threw it in the listed enclosure with a 4TB SATA NAS drive. The SAS has 512 sectors and SATA has 4k sectors, but it works with a ZFS mirror at ashift=12. &lt;/p&gt;\n\n&lt;p&gt;You can mix SAS and SATA drives in the same enclosure as long as you use a SAS HBA in IT mode. Don&amp;#39;t try it with a motherboard SATA controller, those are sata-only connections.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;REF: &lt;a href=\"https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx\"&gt;https://github.com/kneutron/ansitest/blob/master/ZFS/zfs-parts-list-60TB-backup-raidz1.xlsx&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Refer to &amp;quot;4-8-drive-SAS-desktop&amp;quot; sheet&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: If you also buy the 5-bay external HDDRACK listed in the spreadsheet, you can re-use the same (existing) PC power supply. The enclosure uses 2x Molex and the rack uses 5x SATA.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;/ you&amp;#39;re welcome \ud83d\udc7b&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB \ud83d\ude07 \ud83d\ude1c \ud83d\ude43", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tjcgi", "is_robot_indexable": true, "report_reasons": null, "author": "zfsbest", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/", "subreddit_subscribers": 684616, "created_utc": 1685224566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sorry, noob question - I have a lot of videos saved in mp4 format, some of them are up to 20 GB big. I would like to downsize them a little to free up a few GB storage. Seeing as mp4 is already a compressed format, could Handbrake or VLC accomplish this or is it a waste of time and should I just buy a new HDD? Thanks a lot!", "author_fullname": "t2_bpl0kcwmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mp4 compression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tiyuu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685223532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry, noob question - I have a lot of videos saved in mp4 format, some of them are up to 20 GB big. I would like to downsize them a little to free up a few GB storage. Seeing as mp4 is already a compressed format, could Handbrake or VLC accomplish this or is it a waste of time and should I just buy a new HDD? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tiyuu", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult_Owl_3447", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tiyuu/mp4_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tiyuu/mp4_compression/", "subreddit_subscribers": 684616, "created_utc": 1685223532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planning on making a digital back up of my book collection and although google gives me some options i figured i'd check in here and maybe get some tips for doing it in mass or even just suggestion for the programs and/or hardware you guys have used. Any and all info appreciated!", "author_fullname": "t2_3wjwphc1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "digitizing a small library, suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ti9ac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685221670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning on making a digital back up of my book collection and although google gives me some options i figured i&amp;#39;d check in here and maybe get some tips for doing it in mass or even just suggestion for the programs and/or hardware you guys have used. Any and all info appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ti9ac", "is_robot_indexable": true, "report_reasons": null, "author": "Puddleofbooks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ti9ac/digitizing_a_small_library_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ti9ac/digitizing_a_small_library_suggestions/", "subreddit_subscribers": 684616, "created_utc": 1685221670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hope this doesn't go against this subs policy but I'm willing to pay someone for an mp3 archive of  Joe Rogan's podcast. I've tried various torrents and telegram groups but it's quite tedious to get &gt;100 episodes.  There's the internet archive but it's strictly videos and the download speeds are atrocious.  Looking for 500 - 1000 episodes as audio files, starting after episode 500. \n\nI don't have a fortune to spend on this but name your price since I realize this isn't going to take 5 minutes.  For context I'm looking to transcribe them and try running some ML on them.", "author_fullname": "t2_eip0tip2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to buy a Joe Rogan export", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13u8x50", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685302321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this doesn&amp;#39;t go against this subs policy but I&amp;#39;m willing to pay someone for an mp3 archive of  Joe Rogan&amp;#39;s podcast. I&amp;#39;ve tried various torrents and telegram groups but it&amp;#39;s quite tedious to get &amp;gt;100 episodes.  There&amp;#39;s the internet archive but it&amp;#39;s strictly videos and the download speeds are atrocious.  Looking for 500 - 1000 episodes as audio files, starting after episode 500. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have a fortune to spend on this but name your price since I realize this isn&amp;#39;t going to take 5 minutes.  For context I&amp;#39;m looking to transcribe them and try running some ML on them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u8x50", "is_robot_indexable": true, "report_reasons": null, "author": "serjester4", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u8x50/looking_to_buy_a_joe_rogan_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u8x50/looking_to_buy_a_joe_rogan_export/", "subreddit_subscribers": 684616, "created_utc": 1685302321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! \n\n\nThere are a few websites that I want to download from, but every time I try to I always end up with this message:  \n\n&gt; The following parts of the text will be scrambled to prevent theft.\n\nSomewhere in the text, followed by a few paragraphs that are a bunch of scrambled letters. I've tried a lot of programs (like downloadthemall and various extensions that revolve around turning a website into an epub) and copy-pasting but that yields the same results and turning off Javascript results in a site error. The only one that seems to work is Save Page WE and viewing it with my browser, but I want to download a lot of pages and I'd have to do it one by one that way. \n\nI was wondering if anyone knew how to proceed or maybe have some thoughts on what's causing it and how to prevent? Thank you!\n\nEdit: I forgot to add, the website has a nifty little table of content which is what I\u2019d usually use to grab pages.\n\nEdit: here\u2019s the site since some people are asking: https://secondlifetranslations.com/", "author_fullname": "t2_bfjrfghm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would anyone know how to download from websites that scramble text when you try to download them or copy-paste the text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u0p8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685292365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685281127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;There are a few websites that I want to download from, but every time I try to I always end up with this message:  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The following parts of the text will be scrambled to prevent theft.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Somewhere in the text, followed by a few paragraphs that are a bunch of scrambled letters. I&amp;#39;ve tried a lot of programs (like downloadthemall and various extensions that revolve around turning a website into an epub) and copy-pasting but that yields the same results and turning off Javascript results in a site error. The only one that seems to work is Save Page WE and viewing it with my browser, but I want to download a lot of pages and I&amp;#39;d have to do it one by one that way. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone knew how to proceed or maybe have some thoughts on what&amp;#39;s causing it and how to prevent? Thank you!&lt;/p&gt;\n\n&lt;p&gt;Edit: I forgot to add, the website has a nifty little table of content which is what I\u2019d usually use to grab pages.&lt;/p&gt;\n\n&lt;p&gt;Edit: here\u2019s the site since some people are asking: &lt;a href=\"https://secondlifetranslations.com/\"&gt;https://secondlifetranslations.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?auto=webp&amp;v=enabled&amp;s=7cb8ba6651376b7901723183fc988c63a249b190", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc7c497e81a8681fdf980c39ea9abf2fe367f01c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=922eb64189e7f277b554c466ac7a1e82793f6451", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Qhwe1VfC8ekkzM7aZJTDrdiRfO9AMeKYWC7PKGVAb04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f72c94e898f27ef0fb1786e5e7681b70858275dc", "width": 320, "height": 320}], "variants": {}, "id": "Qxd1tNE-22kqYHWwWa7kt2V_JtyFNohMzaJSGZe99xM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13u0p8v", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative-Buy-7315", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13u0p8v/would_anyone_know_how_to_download_from_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13u0p8v/would_anyone_know_how_to_download_from_websites/", "subreddit_subscribers": 684616, "created_utc": 1685281127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellow DataHoarders!\n\nI've been pondering over a question for a while now and thought this would be the best place to get some expert opinions. I'm currently running a network setup with traditional 7200rpm SATA II storage drives, which I'm using with ZFS and iSCSI. My network hardware maxes out at 10Gbps for internal transfers, and I don't have any plans to transfer data over WAN.\n\nRecently, I've been hearing a lot about NVMe over Fabrics (NVMe-OF) and its potential for high performance over networks. However, most of the discussion revolves around SSD drives, and I'm using traditional HDDs.\n\nSo, my question to the community is this: Has anyone here used NVMe-OF with non-SSD drives over a network? If so, I'm curious to know if you noticed any performance enhancements when compared to other networking protocols, specifically iSCSI which I'm currently using.\n\nI understand that NVMe-OF is primarily designed to leverage the speed of SSDs, but I'm wondering if there might be any benefits to using it with traditional hard drives. Given that my network hardware can only handle up to 10Gbps, would NVMe-OF bring any noticeable improvements in speed or efficiency, or would the potential gains be negated by my current hardware limitations? Also, I wonder if it is could also reduce the amount required by ZFS when making the partitions available for my storage devices (I am using them as a Kubernetes cluster storage medium)\n\nAny insights, experiences, or thoughts on this would be highly appreciated. Thanks in advance for your help!", "author_fullname": "t2_9e3dgilt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NVMe-OF with Non-SSD Drives: Worth the Switch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tulf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685260383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow DataHoarders!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pondering over a question for a while now and thought this would be the best place to get some expert opinions. I&amp;#39;m currently running a network setup with traditional 7200rpm SATA II storage drives, which I&amp;#39;m using with ZFS and iSCSI. My network hardware maxes out at 10Gbps for internal transfers, and I don&amp;#39;t have any plans to transfer data over WAN.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve been hearing a lot about NVMe over Fabrics (NVMe-OF) and its potential for high performance over networks. However, most of the discussion revolves around SSD drives, and I&amp;#39;m using traditional HDDs.&lt;/p&gt;\n\n&lt;p&gt;So, my question to the community is this: Has anyone here used NVMe-OF with non-SSD drives over a network? If so, I&amp;#39;m curious to know if you noticed any performance enhancements when compared to other networking protocols, specifically iSCSI which I&amp;#39;m currently using.&lt;/p&gt;\n\n&lt;p&gt;I understand that NVMe-OF is primarily designed to leverage the speed of SSDs, but I&amp;#39;m wondering if there might be any benefits to using it with traditional hard drives. Given that my network hardware can only handle up to 10Gbps, would NVMe-OF bring any noticeable improvements in speed or efficiency, or would the potential gains be negated by my current hardware limitations? Also, I wonder if it is could also reduce the amount required by ZFS when making the partitions available for my storage devices (I am using them as a Kubernetes cluster storage medium)&lt;/p&gt;\n\n&lt;p&gt;Any insights, experiences, or thoughts on this would be highly appreciated. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tulf0", "is_robot_indexable": true, "report_reasons": null, "author": "tsyklon_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tulf0/nvmeof_with_nonssd_drives_worth_the_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tulf0/nvmeof_with_nonssd_drives_worth_the_switch/", "subreddit_subscribers": 684616, "created_utc": 1685260383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Maybe 6 years ago I bought a four base analogy NAS and 4*16 terabyte WD red drives. Other than a few Synology hiccups with NFS and permissions everything has been more or less fine.\n\nBut since I work in IT, I know that eventually everything dies.\n\nSo do you preemptively replace hardware after a good life?\n\nI ask because I have around 4-5TB terabytes of actual data stored. Of which I used to back up to Google drive at college but that is no more. I do back the data up on external discs maybe once a year when I remember. But those discs are stored in my house and if my house burns down then I lose everything.\n\nI was looking at how much it would cost via cloud services to that much data and it's quite expensive. Especially compared to something like backblaze personal. So with? Potentially replacing the hardware. I was thinking getting a Mac mini with a directly attached storage enclosure and mount the drives that way. This way I could just pay the $7 a month for backblaze", "author_fullname": "t2_a33jxmmgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you preventatively replace working hardware?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tikab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685222467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe 6 years ago I bought a four base analogy NAS and 4*16 terabyte WD red drives. Other than a few Synology hiccups with NFS and permissions everything has been more or less fine.&lt;/p&gt;\n\n&lt;p&gt;But since I work in IT, I know that eventually everything dies.&lt;/p&gt;\n\n&lt;p&gt;So do you preemptively replace hardware after a good life?&lt;/p&gt;\n\n&lt;p&gt;I ask because I have around 4-5TB terabytes of actual data stored. Of which I used to back up to Google drive at college but that is no more. I do back the data up on external discs maybe once a year when I remember. But those discs are stored in my house and if my house burns down then I lose everything.&lt;/p&gt;\n\n&lt;p&gt;I was looking at how much it would cost via cloud services to that much data and it&amp;#39;s quite expensive. Especially compared to something like backblaze personal. So with? Potentially replacing the hardware. I was thinking getting a Mac mini with a directly attached storage enclosure and mount the drives that way. This way I could just pay the $7 a month for backblaze&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tikab", "is_robot_indexable": true, "report_reasons": null, "author": "Overnightboat", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tikab/do_you_preventatively_replace_working_hardware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tikab/do_you_preventatively_replace_working_hardware/", "subreddit_subscribers": 684616, "created_utc": 1685222467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've recently started to save old DVDs but I'm having a bit of trouble finding a proper way to get the encoding correct. The way that I'm currently doing it is save all the data with MakeMKV, then use HandBrake to convert the data into a singular MKV-file. It's that final step that I'm not sure how to properly do to ensure that I get the best quality. \n\nI guess this becomes more of a \"how to use HandBrake\" but I use:\n\n* Video &gt; Framerate: Same as source\n* Audio: All tracks\n* Subtitles All tracks\n* Dimensions: Allow upscaling\n\nThe rest I leave for defaults. Is \"same as source\" the best way to get a proper framerate or am I losing out on some other optimizations here? Should I apply some filters for better video quality, especially for older DVDs? Should I increase the audio bitrate from the default 160 or is that just increasing the file size without gaining any benefits in quality? I'd love to hear what you guys think.", "author_fullname": "t2_bjlgrfr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended encodings and other settings for digitizing your DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twqa0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685268501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently started to save old DVDs but I&amp;#39;m having a bit of trouble finding a proper way to get the encoding correct. The way that I&amp;#39;m currently doing it is save all the data with MakeMKV, then use HandBrake to convert the data into a singular MKV-file. It&amp;#39;s that final step that I&amp;#39;m not sure how to properly do to ensure that I get the best quality. &lt;/p&gt;\n\n&lt;p&gt;I guess this becomes more of a &amp;quot;how to use HandBrake&amp;quot; but I use:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Video &amp;gt; Framerate: Same as source&lt;/li&gt;\n&lt;li&gt;Audio: All tracks&lt;/li&gt;\n&lt;li&gt;Subtitles All tracks&lt;/li&gt;\n&lt;li&gt;Dimensions: Allow upscaling&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The rest I leave for defaults. Is &amp;quot;same as source&amp;quot; the best way to get a proper framerate or am I losing out on some other optimizations here? Should I apply some filters for better video quality, especially for older DVDs? Should I increase the audio bitrate from the default 160 or is that just increasing the file size without gaining any benefits in quality? I&amp;#39;d love to hear what you guys think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13twqa0", "is_robot_indexable": true, "report_reasons": null, "author": "ConstantConsumption", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13twqa0/recommended_encodings_and_other_settings_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13twqa0/recommended_encodings_and_other_settings_for/", "subreddit_subscribers": 684616, "created_utc": 1685268501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My requirements I think are simple. I have a 16TB mirror raid (I'm a n00b yes) of stuff and it currently gets backed up against 2 8TB drives in my garage on a proxmox backup server. \n\nI'd like to back that up on a tape and take it offsite and then have another tape at home and do a rotation. Problem is, tape drives seem to be expensive. \n\nCan anyone recommended a good backup tape drive solution which is cheap and fits all my data on one tape ? Or some other solution I haven't thought of ? Do I need to buy more hard drives and rotate spinning rust instead ?\n\nThanks", "author_fullname": "t2_7pvjhp35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap tape backup solutions for 16TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twg7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685267514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My requirements I think are simple. I have a 16TB mirror raid (I&amp;#39;m a n00b yes) of stuff and it currently gets backed up against 2 8TB drives in my garage on a proxmox backup server. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to back that up on a tape and take it offsite and then have another tape at home and do a rotation. Problem is, tape drives seem to be expensive. &lt;/p&gt;\n\n&lt;p&gt;Can anyone recommended a good backup tape drive solution which is cheap and fits all my data on one tape ? Or some other solution I haven&amp;#39;t thought of ? Do I need to buy more hard drives and rotate spinning rust instead ?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13twg7o", "is_robot_indexable": true, "report_reasons": null, "author": "givemejuice1229", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13twg7o/cheap_tape_backup_solutions_for_16tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13twg7o/cheap_tape_backup_solutions_for_16tb/", "subreddit_subscribers": 684616, "created_utc": 1685267514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 4 TB Seagate portable HHD that I've had for less than a year and it's already giving me the C5 and C6 errors. I do have some pretty important stuff on there but it is backed up on Backblaze already but I'm curious how bad is this and is this covered under warranty or do I have to wait for it to die first? \n\n[https://imgur.com/a/a6p1cgN](https://imgur.com/a/a6p1cgN)\n\nThanks for any help in advance.", "author_fullname": "t2_v9opjyxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How concerning is \"uncorrectable sector count\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tqcug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685244937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 4 TB Seagate portable HHD that I&amp;#39;ve had for less than a year and it&amp;#39;s already giving me the C5 and C6 errors. I do have some pretty important stuff on there but it is backed up on Backblaze already but I&amp;#39;m curious how bad is this and is this covered under warranty or do I have to wait for it to die first? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/a6p1cgN\"&gt;https://imgur.com/a/a6p1cgN&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Uag4fmGtzCMwjphu5D97rsOuGuZEOK6o2hhQ6B_FKW0.jpg?auto=webp&amp;v=enabled&amp;s=a9b53767d2ab26aeb27199cc15611b70fcbed8ed", "width": 805, "height": 58}, "resolutions": [{"url": "https://external-preview.redd.it/Uag4fmGtzCMwjphu5D97rsOuGuZEOK6o2hhQ6B_FKW0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94fcc7e836d38a387f1bcdb5ddf97714bd020ef3", "width": 108, "height": 7}, {"url": "https://external-preview.redd.it/Uag4fmGtzCMwjphu5D97rsOuGuZEOK6o2hhQ6B_FKW0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c4508129f04267f61aa18e7b95e2ee83710057c", "width": 216, "height": 15}, {"url": "https://external-preview.redd.it/Uag4fmGtzCMwjphu5D97rsOuGuZEOK6o2hhQ6B_FKW0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9abbe972627a9df0e6797896be4b893848e84de2", "width": 320, "height": 23}, {"url": "https://external-preview.redd.it/Uag4fmGtzCMwjphu5D97rsOuGuZEOK6o2hhQ6B_FKW0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3656821d5c2001fd597158274f0f3064052dee29", "width": 640, "height": 46}], "variants": {}, "id": "Ux8bqnJ_QNIqGcMLtTOYWAgl4z6dP1HrcTyIE3BkdF8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tqcug", "is_robot_indexable": true, "report_reasons": null, "author": "iamwhoiwasnow", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tqcug/how_concerning_is_uncorrectable_sector_count/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tqcug/how_concerning_is_uncorrectable_sector_count/", "subreddit_subscribers": 684616, "created_utc": 1685244937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know I'm not the first one to come here after the drive-pocalypse a couple weeks ago. And I know there's lots of opinions about using the cloud here. But I did know this was coming, but it was too cheap to pass up while it was available. And I'm currently a student so I don't have the ability to drop a grand on drives to ensure the security of my data and to be able to replace drives at the drop of a hat, so the cloud is still my best bet for really precious stuff it seems.\n\nBut anyway, my current plan is to buy some more drives for my Unraid server and pare down my google drive from 50TB to below 5TB to just irreplaceable things (that also have local backups) like my carefully curated mostly  Music collection, podcast collection, and rare video and fan edits. $19.99 is still not bad for 5TB of storage. My understanding is that will stay the same price for now? Or is that going to go up to $36, because I can get 5TB of personal Drive storage for $24.99.\n\nThe rest I'm going to try to get down to under 30TB. I currently have 2x 3TB drives on my unraid server. No parity drive currently because it was only half full with linux iso's that were seeding, so pretty non-crucial data.\n\nNow I'm thinking I'm gonna have to rethink that. My budget is around $500, and I'm not entirely sure what my timeline is since it looks like I'll still have read access after July 16. Are WD Red Pro's a good direction to go? Any difference in reliability in the 12TB and 14TB models? I would like to add a parity drive eventually but nothing on the Unraid server will be irreplaceable, so I'm trying to weight that into things.\n\nThanks for your help in advance.", "author_fullname": "t2_43qil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A few questions about getting myself (mostly) off the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tne0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685235531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know I&amp;#39;m not the first one to come here after the drive-pocalypse a couple weeks ago. And I know there&amp;#39;s lots of opinions about using the cloud here. But I did know this was coming, but it was too cheap to pass up while it was available. And I&amp;#39;m currently a student so I don&amp;#39;t have the ability to drop a grand on drives to ensure the security of my data and to be able to replace drives at the drop of a hat, so the cloud is still my best bet for really precious stuff it seems.&lt;/p&gt;\n\n&lt;p&gt;But anyway, my current plan is to buy some more drives for my Unraid server and pare down my google drive from 50TB to below 5TB to just irreplaceable things (that also have local backups) like my carefully curated mostly  Music collection, podcast collection, and rare video and fan edits. $19.99 is still not bad for 5TB of storage. My understanding is that will stay the same price for now? Or is that going to go up to $36, because I can get 5TB of personal Drive storage for $24.99.&lt;/p&gt;\n\n&lt;p&gt;The rest I&amp;#39;m going to try to get down to under 30TB. I currently have 2x 3TB drives on my unraid server. No parity drive currently because it was only half full with linux iso&amp;#39;s that were seeding, so pretty non-crucial data.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m thinking I&amp;#39;m gonna have to rethink that. My budget is around $500, and I&amp;#39;m not entirely sure what my timeline is since it looks like I&amp;#39;ll still have read access after July 16. Are WD Red Pro&amp;#39;s a good direction to go? Any difference in reliability in the 12TB and 14TB models? I would like to add a parity drive eventually but nothing on the Unraid server will be irreplaceable, so I&amp;#39;m trying to weight that into things.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13tne0b", "is_robot_indexable": true, "report_reasons": null, "author": "Night-Man", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13tne0b/a_few_questions_about_getting_myself_mostly_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13tne0b/a_few_questions_about_getting_myself_mostly_off/", "subreddit_subscribers": 684616, "created_utc": 1685235531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there i need a public twitter account's tweets archived. but it has over 150k tweets. is there any free or paid tool/service out there ?", "author_fullname": "t2_su1qgjn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tweet Archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13theis", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685219470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there i need a public twitter account&amp;#39;s tweets archived. but it has over 150k tweets. is there any free or paid tool/service out there ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13theis", "is_robot_indexable": true, "report_reasons": null, "author": "Emergency-Flower-477", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13theis/tweet_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13theis/tweet_archiving/", "subreddit_subscribers": 684616, "created_utc": 1685219470.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}