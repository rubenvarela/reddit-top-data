{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ap0s21sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Minimum 7 years exp the field and expertise in NLP for 70k-80k CAD contract job. This country and the market is a joke. Look at the JD. It\u2019s even comical.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"24iqz18wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75b252b7f11784e97c5d8ea34254fd561beda357"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bc2ffd25d826b757eb4c8164e92c1c47ef9a117"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=333bc670feb252698ba1132e2be26f5016fa0ff9"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c288dbc6bdbfd4060e18a76bddf80747ac7019f4"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31aeb900d56df4f3937583b66c4a09756c3e2f9e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20c4720e79337e40d28b1d8bdf9ccd9fe4413d4c"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4826cdc38fb49904304911cae96ba9a8804e9f62"}, "id": "24iqz18wud2b1"}, "y41h498wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3843dec749dab6d30d514b5cc7afa5aa1f2c0260"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=578aca1af2cbf1ca42804f592712d9f70a951692"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=593d63dde06a5e5585200d6d3ae090751745203b"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b431334d411d2715b80eee85678bbad928ae922"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8310115d2cd1304c9b7650d6c5474dd2673fc16e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77de997b9864d5949745c662b2f04bbe3150683a"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=543c5c761a4d64d99fc88f5530b39315043d56bc"}, "id": "y41h498wud2b1"}}, "name": "t3_13t8q2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 282, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "y41h498wud2b1", "id": 280365940}, {"media_id": "24iqz18wud2b1", "id": 280365941}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 282, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cnh8ZhdS2yjJETGCxh-kC9waEuTXS1W3rjRfmwdzhFM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685197178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13t8q2x", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "13t8q2x", "is_robot_indexable": true, "report_reasons": null, "author": "hootandahalf_", "discussion_type": null, "num_comments": 147, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t8q2x/minimum_7_years_exp_the_field_and_expertise_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13t8q2x", "subreddit_subscribers": 911193, "created_utc": 1685197178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I'm an experienced data scientist but my current job of seven years wasn't particularly stats or ML intensive. I'm a wiz when it comes to data acquisition/wrangling/visualization but my last gig that really involved stats and modeling was quite a few years ago at this point. And unfortunately said job is coming to an end and I'm on the market for a new gig. \n\nI have a second round interview coming up and I'm worried about getting hit with a technical question I don't know the answer to. I'm giving myself a crash refresher with a data science interview book but I still think there's a non-trivial chance of getting hit with a technical question I just don't know. I'm wondering if anyone has suggestions on what to say or how to handle that scenario in a way that maximizes my chances of not scuttling the interview entirely.", "author_fullname": "t2_9wge0haf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to defer on a question I don't know in an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tm7t7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685232232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m an experienced data scientist but my current job of seven years wasn&amp;#39;t particularly stats or ML intensive. I&amp;#39;m a wiz when it comes to data acquisition/wrangling/visualization but my last gig that really involved stats and modeling was quite a few years ago at this point. And unfortunately said job is coming to an end and I&amp;#39;m on the market for a new gig. &lt;/p&gt;\n\n&lt;p&gt;I have a second round interview coming up and I&amp;#39;m worried about getting hit with a technical question I don&amp;#39;t know the answer to. I&amp;#39;m giving myself a crash refresher with a data science interview book but I still think there&amp;#39;s a non-trivial chance of getting hit with a technical question I just don&amp;#39;t know. I&amp;#39;m wondering if anyone has suggestions on what to say or how to handle that scenario in a way that maximizes my chances of not scuttling the interview entirely.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tm7t7", "is_robot_indexable": true, "report_reasons": null, "author": "Tamalelulu", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tm7t7/best_way_to_defer_on_a_question_i_dont_know_in_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tm7t7/best_way_to_defer_on_a_question_i_dont_know_in_an/", "subreddit_subscribers": 911193, "created_utc": 1685232232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "isnt the purpose to remove the noise/ clean the noise ?\n\nfor [this comment](https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;utm_medium=web2x&amp;context=3), a suggestion for dealing with too many features was: ' Add two new features that are both just random noise.  '\n\ncan someone explain why ?", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why do we add random noise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t2hl8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685178193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;isnt the purpose to remove the noise/ clean the noise ?&lt;/p&gt;\n\n&lt;p&gt;for &lt;a href=\"https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;this comment&lt;/a&gt;, a suggestion for dealing with too many features was: &amp;#39; Add two new features that are both just random noise.  &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;can someone explain why ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t2hl8", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "subreddit_subscribers": 911193, "created_utc": 1685178193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After an honest option here. I\u2019m currently in a data analyst role,  my first data-only role after almost a decade working in software dev related roles. I have a PhD in a neuroscience related field from a prestigious university in my country (not directly CS or DS) that used a lot of advanced statistics like Fourier transforms and Bayesian models and has direct links/ utility for computer vision applications (vision science). My published papers are in that field and not DS. \n\nI\u2019ve been a university lecturer in software design and I also have teaching experience on a vocational data science course (a private college). I\u2019ve done ML, NLP etc in personal portfolio projects and run analysis for AB tests, survival analysis etc as part of a software growth hacking team (direct work experience) in the past. The bulk of my past work experience is software user research and insights via both qualitative and quantitative (data based) research. I\u2019ve also worked mainly on data and analytics focused software apps, e.g a conversational AI startup.\n\nMy current role is definitely analyst level as I\u2019m mainly automating business intelligence reporting, building dashboards and providing insights with no ML, although there is a potential ML project on the horizon.\n\nAm I in a position to apply for jobs where \u2018data scientist\u2019 is the title? If not is there anything I can do to make myself more competitive for these types of roles?\n\nI\u2019m enjoying my current role, the workplace is great as is the compensation, however eventually I\u2019m going to want to apply my brain to more complicated types of analysis and modelling that a data science role would entail. Please let me know what you think.", "author_fullname": "t2_8gaman3n5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could I apply for Data Science roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tn0v0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685235729.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685234473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After an honest option here. I\u2019m currently in a data analyst role,  my first data-only role after almost a decade working in software dev related roles. I have a PhD in a neuroscience related field from a prestigious university in my country (not directly CS or DS) that used a lot of advanced statistics like Fourier transforms and Bayesian models and has direct links/ utility for computer vision applications (vision science). My published papers are in that field and not DS. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been a university lecturer in software design and I also have teaching experience on a vocational data science course (a private college). I\u2019ve done ML, NLP etc in personal portfolio projects and run analysis for AB tests, survival analysis etc as part of a software growth hacking team (direct work experience) in the past. The bulk of my past work experience is software user research and insights via both qualitative and quantitative (data based) research. I\u2019ve also worked mainly on data and analytics focused software apps, e.g a conversational AI startup.&lt;/p&gt;\n\n&lt;p&gt;My current role is definitely analyst level as I\u2019m mainly automating business intelligence reporting, building dashboards and providing insights with no ML, although there is a potential ML project on the horizon.&lt;/p&gt;\n\n&lt;p&gt;Am I in a position to apply for jobs where \u2018data scientist\u2019 is the title? If not is there anything I can do to make myself more competitive for these types of roles?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m enjoying my current role, the workplace is great as is the compensation, however eventually I\u2019m going to want to apply my brain to more complicated types of analysis and modelling that a data science role would entail. Please let me know what you think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tn0v0", "is_robot_indexable": true, "report_reasons": null, "author": "themeaning_42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tn0v0/could_i_apply_for_data_science_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tn0v0/could_i_apply_for_data_science_roles/", "subreddit_subscribers": 911193, "created_utc": 1685234473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.", "author_fullname": "t2_dt4iludq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop course from the official site.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ynq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685192665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ynq", "is_robot_indexable": true, "report_reasons": null, "author": "y3snomaybe", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "subreddit_subscribers": 911193, "created_utc": 1685192665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "*reposted from r/dataengineering \n\nRecent Computer engineering grad here. I\u2019m applying to data science and data engineering roles, but realize that I lack a lot of the backend technical skills. I\u2019m proficient in SQL, Java and Python (Pandas, TF, scipy, seaborn, etc), but it ends there. Ive taken many ML/analytics courses so I know the data science concepts.\n\nAlthough I\u2019m looking to take a course(s) with little data engineering knowledge that\u2019s ideally hands on (implementing through homework/projects) and does a wholistic overview of all the major concepts I often see on DS job applications. \n- Kafka and lambda architectures\n- Data lake, warehousing and fabric concepts \n- Spark/Hadoop, Scala, NoSQL, Airflow, Snowflake \n- AWS or GCP or Azure (namely synaptics, data lake and databricks)\n\nBecause I\u2019m using this to bolster my resume, I figured taking a shotgun approach in learning all the concepts rather specializing in one particular tech stack. Especially since I dont know what that stack will be once I land a job. I plan on putting this on my resume as form of \u201csecondary/continued education\u201d\n\nI\u2019ve seen course offerings on udacity (How to Become a Data Engineer), on coursera (IBM and Google certifications), udemy, datacamp, etc.\n\nDoes anyone have recommendations? I plan on doing this full time so time commitment (and how in depth it gets) isn\u2019t an issue. \n\nThanks!", "author_fullname": "t2_i1ylqnf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Course Recommendations for a New Grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tkvsd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685228648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;*reposted from &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Recent Computer engineering grad here. I\u2019m applying to data science and data engineering roles, but realize that I lack a lot of the backend technical skills. I\u2019m proficient in SQL, Java and Python (Pandas, TF, scipy, seaborn, etc), but it ends there. Ive taken many ML/analytics courses so I know the data science concepts.&lt;/p&gt;\n\n&lt;p&gt;Although I\u2019m looking to take a course(s) with little data engineering knowledge that\u2019s ideally hands on (implementing through homework/projects) and does a wholistic overview of all the major concepts I often see on DS job applications. \n- Kafka and lambda architectures\n- Data lake, warehousing and fabric concepts \n- Spark/Hadoop, Scala, NoSQL, Airflow, Snowflake \n- AWS or GCP or Azure (namely synaptics, data lake and databricks)&lt;/p&gt;\n\n&lt;p&gt;Because I\u2019m using this to bolster my resume, I figured taking a shotgun approach in learning all the concepts rather specializing in one particular tech stack. Especially since I dont know what that stack will be once I land a job. I plan on putting this on my resume as form of \u201csecondary/continued education\u201d&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen course offerings on udacity (How to Become a Data Engineer), on coursera (IBM and Google certifications), udemy, datacamp, etc.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have recommendations? I plan on doing this full time so time commitment (and how in depth it gets) isn\u2019t an issue. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tkvsd", "is_robot_indexable": true, "report_reasons": null, "author": "BoiFormer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tkvsd/course_recommendations_for_a_new_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tkvsd/course_recommendations_for_a_new_grad/", "subreddit_subscribers": 911193, "created_utc": 1685228648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello r/datascience!\n\nI came across [a post here on r/datascience about frustrations and limitations of existing no-code DS solutions](https://www.reddit.com/r/datascience/comments/13t11zh/what_are_the_biggest_limitations_and_frustrations/), where -- in the comments -- u/5dollarburger alluded to the requirement of a set of skills to avoid GIGO situations.\n\nI don't necessarily want to go down the semantic rabbit hole of defining what that skillset necessarily consists of (*unless* you do...), but reading that sentence **did** leave me with a small thought... well, more of a 'question'-thought:\n\n**What items (think: anything** ***from*** **basic 'do-it-every-time methods'** ***to*** **the kind of things that could basically amount to 'checklist items' from lessons learned) or experiences left a memorable impact on you as important to address or verify/validate on a project in an effort to avoid GIGO situations?**\n\nAs an example -- \"I'll never forget to take a look at \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ again, when it comes to data modeling... I did that *once* and I basically had to start over from square one on that particular project\"\n\nPardon the random/elementary discussion prompt... maybe this exchange will be helpful to someone, but I'm mostly just curious what kind of things you'll never skip over again that would have ultimately prevented an irreparable situation on a project.", "author_fullname": "t2_967xqwp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Avoiding \"Garbage In/Garbage Out\" Scenarios", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tlgnp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685230188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;I came across &lt;a href=\"https://www.reddit.com/r/datascience/comments/13t11zh/what_are_the_biggest_limitations_and_frustrations/\"&gt;a post here on r/datascience about frustrations and limitations of existing no-code DS solutions&lt;/a&gt;, where -- in the comments -- &lt;a href=\"/u/5dollarburger\"&gt;u/5dollarburger&lt;/a&gt; alluded to the requirement of a set of skills to avoid GIGO situations.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t necessarily want to go down the semantic rabbit hole of defining what that skillset necessarily consists of (&lt;em&gt;unless&lt;/em&gt; you do...), but reading that sentence &lt;strong&gt;did&lt;/strong&gt; leave me with a small thought... well, more of a &amp;#39;question&amp;#39;-thought:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What items (think: anything&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;from&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;basic &amp;#39;do-it-every-time methods&amp;#39;&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;to&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;the kind of things that could basically amount to &amp;#39;checklist items&amp;#39; from lessons learned) or experiences left a memorable impact on you as important to address or verify/validate on a project in an effort to avoid GIGO situations?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As an example -- &amp;quot;I&amp;#39;ll never forget to take a look at _____________ again, when it comes to data modeling... I did that &lt;em&gt;once&lt;/em&gt; and I basically had to start over from square one on that particular project&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Pardon the random/elementary discussion prompt... maybe this exchange will be helpful to someone, but I&amp;#39;m mostly just curious what kind of things you&amp;#39;ll never skip over again that would have ultimately prevented an irreparable situation on a project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tlgnp", "is_robot_indexable": true, "report_reasons": null, "author": "IdealState", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tlgnp/avoiding_garbage_ingarbage_out_scenarios/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tlgnp/avoiding_garbage_ingarbage_out_scenarios/", "subreddit_subscribers": 911193, "created_utc": 1685230188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently a new grad heading into an SDE role this summer. Not exactly trying to map out the trajectory of my career just yet, but I would like to know what flexibility there is to exploring different CS career paths.\n\nMore specifically, I'd like to explore data analyst/ scientist roles at other companies later down the line. But just in case I want to stick to software afterward, will taking these other roles affect my skills or hireability for SWE?\n\nStories about hopping between software and data roles in early career would be much appreciated!", "author_fullname": "t2_elgw9ojx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hopping between software and data roles in early career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tmp9s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685233572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a new grad heading into an SDE role this summer. Not exactly trying to map out the trajectory of my career just yet, but I would like to know what flexibility there is to exploring different CS career paths.&lt;/p&gt;\n\n&lt;p&gt;More specifically, I&amp;#39;d like to explore data analyst/ scientist roles at other companies later down the line. But just in case I want to stick to software afterward, will taking these other roles affect my skills or hireability for SWE?&lt;/p&gt;\n\n&lt;p&gt;Stories about hopping between software and data roles in early career would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tmp9s", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent-Change-94", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tmp9s/hopping_between_software_and_data_roles_in_early/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tmp9s/hopping_between_software_and_data_roles_in_early/", "subreddit_subscribers": 911193, "created_utc": 1685233572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I've been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It's been a while since I've been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.", "author_fullname": "t2_9anx9qeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources to get more domain knowledge on biotech market research?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t9xjg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I&amp;#39;ve been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It&amp;#39;s been a while since I&amp;#39;ve been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9xjg", "is_robot_indexable": true, "report_reasons": null, "author": "sommeilhotel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "subreddit_subscribers": 911193, "created_utc": 1685200270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone point me in the direction of YouTuber Earnings Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tul8g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mm3s3evo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "datasets", "selftext": "I am doing a project and would like to use earnings of top YouTube channels. I have found some datasets on Kaggle but need more detail on annual earnings. If any of you know where I could find that data or could post the datasets, data, or source here that would be amazing. Thank you!", "author_fullname": "t2_mm3s3evo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone point me in the direction of YouTuber Earnings Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datasets", "hidden": false, "pwls": 6, "link_flair_css_class": "dataset", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tuks6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "dataset", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685260310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing a project and would like to use earnings of top YouTube channels. I have found some datasets on Kaggle but need more detail on annual earnings. If any of you know where I could find that data or could post the datasets, data, or source here that would be amazing. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f074feb2-5bcd-11e6-8c1d-0e0220cd4035", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r97t", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tuks6", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Garlic1170", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "subreddit_subscribers": 175400, "created_utc": 1685260310.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1685260361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tul8g", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Garlic1170", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13tuks6", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tul8g/can_anyone_point_me_in_the_direction_of_youtuber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "subreddit_subscribers": 911193, "created_utc": 1685260361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement an activity tracker for my Reddit account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tu8b7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5hpv694y", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "developersIndia", "selftext": "I am looking to implement an activity tracker dashboard-like thing that gives me updates about comments counts, comment content, and upvotes made on my posts. I went through the functionality of PRAW and Reddit API documentation and understood that there is no direct endpoint to ask for updates.   \n\n\nNow the possible method is to store post IDs for each of my posts, and continuously poll via API to get status updates on these posts. But doing this for each post one by one will be lot time-consuming process. How can I optimize this process? Like how should I divide my tasks into multiprocessing processes  such that changes are reflected on my dashboard in minimum amount of time.", "author_fullname": "t2_5hpv694y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement an activity tracker for my Reddit account?", "link_flair_richtext": [{"e": "text", "t": "Help"}], "subreddit_name_prefixed": "r/developersIndia", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tu79e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685258849.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to implement an activity tracker dashboard-like thing that gives me updates about comments counts, comment content, and upvotes made on my posts. I went through the functionality of PRAW and Reddit API documentation and understood that there is no direct endpoint to ask for updates.   &lt;/p&gt;\n\n&lt;p&gt;Now the possible method is to store post IDs for each of my posts, and continuously poll via API to get status updates on these posts. But doing this for each post one by one will be lot time-consuming process. How can I optimize this process? Like how should I divide my tasks into multiprocessing processes  such that changes are reflected on my dashboard in minimum amount of time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ec36207e-3d06-11ea-8944-0ee745817ba1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2dfnk0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#373c3f", "id": "13tu79e", "is_robot_indexable": true, "report_reasons": null, "author": "mili_19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "subreddit_subscribers": 220126, "created_utc": 1685258849.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1685258969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tu8b7", "is_robot_indexable": true, "report_reasons": null, "author": "mili_19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13tu79e", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tu8b7/how_to_implement_an_activity_tracker_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "subreddit_subscribers": 911193, "created_utc": 1685258969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plakakia (tiles in Greek) is an image tiling library I made for quickly generating tiles from images. It would be great if people try it and give some feedback / raise issues on github. It's the first open-source library I ever made, so hopefully I learn from more experienced people.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_13ttxk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_f8vtd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jje0KypwRW1CZuUVf5fmUp4TjijHWX006uJQRoOfzHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "computervision", "selftext": "", "author_fullname": "t2_f8vtd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plakakia (tiles in Greek) is an image tiling library I made for quickly generating tiles from images. It would be great if people try it and give some feedback / raise issues on github. It's the first open-source library I ever made, so hopefully I learn from more experienced people.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/computervision", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_13ttw5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help: Project", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jje0KypwRW1CZuUVf5fmUp4TjijHWX006uJQRoOfzHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685257674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/kalfasyan/plakakia", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?auto=webp&amp;v=enabled&amp;s=408f42ad808e7887c97319065899b45754642e22", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35ffdc2e0ca4535ef2c01f7d30ec67827e1aa04e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14c6d204c3ea3dd5eac4909b42d07566d79d41d7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8dfd359f5dc5e8e29397b2cdbcb152674360c19", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab0a47a6e9ddf7d1473dcb4a7cb5bf21b316374b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93bc21cb125eca0c524f3c3ca8a367ba6fda9816", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8eda96665172ca30582491c032561f6bf71355", "width": 1080, "height": 540}], "variants": {}, "id": "79VUq2fR1LDm9Y69p5syIxmh7Dt3myfwPlIgKHhoqC8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2be07b9a-850c-11eb-9ef0-0e67fd476361", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2rfzn", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#fdff99", "id": "13ttw5o", "is_robot_indexable": true, "report_reasons": null, "author": "kalfasyan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/computervision/comments/13ttw5o/plakakia_tiles_in_greek_is_an_image_tiling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/kalfasyan/plakakia", "subreddit_subscribers": 75282, "created_utc": 1685257674.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1685257822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/kalfasyan/plakakia", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?auto=webp&amp;v=enabled&amp;s=408f42ad808e7887c97319065899b45754642e22", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35ffdc2e0ca4535ef2c01f7d30ec67827e1aa04e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14c6d204c3ea3dd5eac4909b42d07566d79d41d7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8dfd359f5dc5e8e29397b2cdbcb152674360c19", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab0a47a6e9ddf7d1473dcb4a7cb5bf21b316374b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93bc21cb125eca0c524f3c3ca8a367ba6fda9816", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8eda96665172ca30582491c032561f6bf71355", "width": 1080, "height": 540}], "variants": {}, "id": "79VUq2fR1LDm9Y69p5syIxmh7Dt3myfwPlIgKHhoqC8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ttxk4", "is_robot_indexable": true, "report_reasons": null, "author": "kalfasyan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13ttw5o", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ttxk4/plakakia_tiles_in_greek_is_an_image_tiling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/kalfasyan/plakakia", "subreddit_subscribers": 911193, "created_utc": 1685257822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI am involved in a data migration project. It is migrating from SAP to a newer version of SAP. I was notified we can choose what tool to use for analysis and I am wondering if anyone has suggestions. I am obviously overthinking this. Maybe some tools just aren't relevant for the project but I do want to learn more software as this is my first official role in data and I want to grow professionally. I do realize that to be a great data scientist, it's not just about having the right tools although that doesn't hurt.\n\n I am primarily interested in R, Python, SQL, and probably some HDFS for big data. I think I installed Hadoop correctly but probably need to learn how to run it. I used a different HDFS for a DS certificate I took. We used Hortonworks data platform for uploading and downloading files into Hadoop file system.\n\nI installed RStudio. I have Anaconda and that's got Spyder and Pycharm. I wanted to have the key Python packages like numpy and scikit-learn, tensorflow etc. I was watching some videos that suggested using Visual Studio Code. Tensorflow doesn't seem to be working on my Anaconda and not sure if it's due to security blocking access to downloading certain files.\n\nI tried installing RStudio on Anaconda but it was problematic and threads I've seen on Reddit say that using RStudio on Anaconda is a nightmare. Also read that Anaconda doesn't have the most recent version of it as well.\n\nMonths ago a colleague gave some installations so I have Postman and DBVisualizer installed (haven't used them yet). I think DBVisualizer should be sufficient for running SQL code but have read people suggesting other tools. I've used online compilers so have used postgresql.\n\nWhat do people use in their work and what would you want to use at your work?", "author_fullname": "t2_11ph6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for Open Source Tools to Use for Data Migration &amp; Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tfz9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685215732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am involved in a data migration project. It is migrating from SAP to a newer version of SAP. I was notified we can choose what tool to use for analysis and I am wondering if anyone has suggestions. I am obviously overthinking this. Maybe some tools just aren&amp;#39;t relevant for the project but I do want to learn more software as this is my first official role in data and I want to grow professionally. I do realize that to be a great data scientist, it&amp;#39;s not just about having the right tools although that doesn&amp;#39;t hurt.&lt;/p&gt;\n\n&lt;p&gt;I am primarily interested in R, Python, SQL, and probably some HDFS for big data. I think I installed Hadoop correctly but probably need to learn how to run it. I used a different HDFS for a DS certificate I took. We used Hortonworks data platform for uploading and downloading files into Hadoop file system.&lt;/p&gt;\n\n&lt;p&gt;I installed RStudio. I have Anaconda and that&amp;#39;s got Spyder and Pycharm. I wanted to have the key Python packages like numpy and scikit-learn, tensorflow etc. I was watching some videos that suggested using Visual Studio Code. Tensorflow doesn&amp;#39;t seem to be working on my Anaconda and not sure if it&amp;#39;s due to security blocking access to downloading certain files.&lt;/p&gt;\n\n&lt;p&gt;I tried installing RStudio on Anaconda but it was problematic and threads I&amp;#39;ve seen on Reddit say that using RStudio on Anaconda is a nightmare. Also read that Anaconda doesn&amp;#39;t have the most recent version of it as well.&lt;/p&gt;\n\n&lt;p&gt;Months ago a colleague gave some installations so I have Postman and DBVisualizer installed (haven&amp;#39;t used them yet). I think DBVisualizer should be sufficient for running SQL code but have read people suggesting other tools. I&amp;#39;ve used online compilers so have used postgresql.&lt;/p&gt;\n\n&lt;p&gt;What do people use in their work and what would you want to use at your work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tfz9k", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalDocSpock", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tfz9k/recommendations_for_open_source_tools_to_use_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tfz9k/recommendations_for_open_source_tools_to_use_for/", "subreddit_subscribers": 911193, "created_utc": 1685215732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,   \n\n\nI'm a currently a data science student, and my professor has tasked my class to do some machine learning projects.   \n\n\nI guess it's fairly straightforward. Get a dataset, preprocess it, and make a prediction.   \n\n\nThe challenge is, the dataset size must be atleast 50Gb(gigabytes) and must be uploaded into an AWS S3 bucket and processed using the AWS EMR on EC2 clusters.   \n\n\n  \nI've been looking around the AWS data store and it's mostly biotech and geo science data.   \n\n\nI was wondering if any one knows of where I can find ones in the finance or business setting kind of data.   \n\n\nAny suggestions or advice will be greatly appreciated.   \nThank you!", "author_fullname": "t2_15cnt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset sources for Predictive Machine Learning (classifier or regressor)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13td0kd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685207978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a currently a data science student, and my professor has tasked my class to do some machine learning projects.   &lt;/p&gt;\n\n&lt;p&gt;I guess it&amp;#39;s fairly straightforward. Get a dataset, preprocess it, and make a prediction.   &lt;/p&gt;\n\n&lt;p&gt;The challenge is, the dataset size must be atleast 50Gb(gigabytes) and must be uploaded into an AWS S3 bucket and processed using the AWS EMR on EC2 clusters.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking around the AWS data store and it&amp;#39;s mostly biotech and geo science data.   &lt;/p&gt;\n\n&lt;p&gt;I was wondering if any one knows of where I can find ones in the finance or business setting kind of data.   &lt;/p&gt;\n\n&lt;p&gt;Any suggestions or advice will be greatly appreciated.&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13td0kd", "is_robot_indexable": true, "report_reasons": null, "author": "kaiserdx", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13td0kd/dataset_sources_for_predictive_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13td0kd/dataset_sources_for_predictive_machine_learning/", "subreddit_subscribers": 911193, "created_utc": 1685207978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?", "author_fullname": "t2_1bmmkdkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to remove 1 class from dataset if it's count is very small compared to others?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t9tot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9tot", "is_robot_indexable": true, "report_reasons": null, "author": "The_artist_999", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "subreddit_subscribers": 911193, "created_utc": 1685200000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.\n\nMain characteristics:\n\n* Like DVC and Git LFS, integrates with Git itself.\n* Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.\n* Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of \\~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.\n* Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.\n* Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.\n* Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.\n\nLinks:\n\n* [https://news.ycombinator.com/item?id=35930895](https://news.ycombinator.com/item?id=35930895)\n* \\[no full checkout\\] [https://youtu.be/BxvVdB4-Aqc](https://youtu.be/BxvVdB4-Aqc)\n* [https://news.ycombinator.com/item?id=35806843](https://news.ycombinator.com/item?id=35806843)\n* \\[general intro\\] [https://youtu.be/J0L8-uUVayM](https://youtu.be/J0L8-uUVayM)\n\nThis paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.\n\nI built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.\n\nSome background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.\n\nI look forward to constructive feedback and suggestions!", "author_fullname": "t2_9mj1ygw0w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback needed: building Git for data that commits only diffs (for storage efficiency on large repositories), even without full checkouts of the datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ecd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685191175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.&lt;/p&gt;\n\n&lt;p&gt;Main characteristics:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Like DVC and Git LFS, integrates with Git itself.&lt;/li&gt;\n&lt;li&gt;Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of ~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.&lt;/li&gt;\n&lt;li&gt;Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35930895\"&gt;https://news.ycombinator.com/item?id=35930895&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[no full checkout] &lt;a href=\"https://youtu.be/BxvVdB4-Aqc\"&gt;https://youtu.be/BxvVdB4-Aqc&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35806843\"&gt;https://news.ycombinator.com/item?id=35806843&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[general intro] &lt;a href=\"https://youtu.be/J0L8-uUVayM\"&gt;https://youtu.be/J0L8-uUVayM&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.&lt;/p&gt;\n\n&lt;p&gt;I built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.&lt;/p&gt;\n\n&lt;p&gt;Some background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.&lt;/p&gt;\n\n&lt;p&gt;I look forward to constructive feedback and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ecd", "is_robot_indexable": true, "report_reasons": null, "author": "Usual-Maize1175", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "subreddit_subscribers": 911193, "created_utc": 1685191175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking into transitioning into data science (BA from a US university). I started out by taking college courses peripherally related to the field (Philosophy of Statistics and Philosophy of Machine Learning) and fell in love with it. I've been working on getting my technical as well as mathematical abilities up to par for just over a year now. I started with Python and have been working my way through different ds libraries. I know that I have a long way to go. I'm taking community college courses right now and am even considering a master's program in the near-ish future.  \n\n\nThat being said, I see tons on this thread about how data science is crazily saturated right now, how everyone is trying to get into this field, how it's near impossible, and how people like me aren't even well-suited to the positions they're applying for. It's hard to not get discouraged. This is a field that really grabbed me and I have spent hours upon hours of my free time working on developing my ability. I wake up early every day before work just to be able to spend 40 minutes on some new skill or area. I spend my lunch breaks reading for class or doing my community college cs assignments.\n\nI'm not totally sure why I'm writing this. Maybe just to see if there are some success stories to help get me through this trough. Sometimes I wonder if the time and money that I've put into this so far is just being wasted. I wonder if I'm one of the masses upon masses who aren't deserving of a role in this field and who won't get 5 seconds of time spent on their resume before being sent to the \"no\" pile. I know this doesn't change the fact that what I'm finding discouraging is true and really exists, it just feels like a lot rn.", "author_fullname": "t2_10xkkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to Pivot - Feeling Disheartened", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tm2p5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685231856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking into transitioning into data science (BA from a US university). I started out by taking college courses peripherally related to the field (Philosophy of Statistics and Philosophy of Machine Learning) and fell in love with it. I&amp;#39;ve been working on getting my technical as well as mathematical abilities up to par for just over a year now. I started with Python and have been working my way through different ds libraries. I know that I have a long way to go. I&amp;#39;m taking community college courses right now and am even considering a master&amp;#39;s program in the near-ish future.  &lt;/p&gt;\n\n&lt;p&gt;That being said, I see tons on this thread about how data science is crazily saturated right now, how everyone is trying to get into this field, how it&amp;#39;s near impossible, and how people like me aren&amp;#39;t even well-suited to the positions they&amp;#39;re applying for. It&amp;#39;s hard to not get discouraged. This is a field that really grabbed me and I have spent hours upon hours of my free time working on developing my ability. I wake up early every day before work just to be able to spend 40 minutes on some new skill or area. I spend my lunch breaks reading for class or doing my community college cs assignments.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not totally sure why I&amp;#39;m writing this. Maybe just to see if there are some success stories to help get me through this trough. Sometimes I wonder if the time and money that I&amp;#39;ve put into this so far is just being wasted. I wonder if I&amp;#39;m one of the masses upon masses who aren&amp;#39;t deserving of a role in this field and who won&amp;#39;t get 5 seconds of time spent on their resume before being sent to the &amp;quot;no&amp;quot; pile. I know this doesn&amp;#39;t change the fact that what I&amp;#39;m finding discouraging is true and really exists, it just feels like a lot rn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tm2p5", "is_robot_indexable": true, "report_reasons": null, "author": "Tackocky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tm2p5/trying_to_pivot_feeling_disheartened/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tm2p5/trying_to_pivot_feeling_disheartened/", "subreddit_subscribers": 911193, "created_utc": 1685231856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to learn how to webscrape from  [WNBA Stats | Players Traditional](https://stats.wnba.com/players/traditional/?sort=PTS&amp;dir=-1&amp;Season=2023&amp;SeasonType=Regular%20Season) . I've done very little webscraping, I've only been able to do scrape from ESPN or basketball reference. This is the code I used, but I have no idea how to adapt to this website, or if this website would even allow webscraping using the method that I did.  Any help would be greatly appreciated.\n\n\\------\n\nimport pandas as pd\n\nimport requests\n\nimport json\n\nfrom time import sleep\n\n \n\ndef get\\_data(page: int):\n\nheaders = {\n\n'authority': '[site.web.api.espn.com](https://site.web.api.espn.com)',\n\n'accept': '\\*/\\*',\n\n'accept-language': 'en-US,en;q=0.9',\n\n'origin': '[https://www.espn.com](https://www.espn.com)',\n\n'referer': '[https://www.espn.com/](https://www.espn.com/)',\n\n'sec-ch-ua': '\"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Microsoft Edge\";v=\"110\"',\n\n'sec-ch-ua-mobile': '?0',\n\n'sec-ch-ua-platform': '\"Windows\"',\n\n'sec-fetch-dest': 'empty',\n\n'sec-fetch-mode': 'cors',\n\n'sec-fetch-site': 'same-site',\n\n'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.49',\n\n}\n\n \n\nparams = {\n\n'region': 'us',\n\n'lang': 'en',\n\n'contentorigin': 'espn',\n\n'isqualified': 'true',\n\n'page': f'{page}',\n\n'limit': '50',\n\n'sort': 'offensive.avgPoints:desc',\n\n'conference': '4',\n\n}\n\n \n\nresponse = requests.get(\n\nurl='[https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\\\](https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\)\n\nregion=us&amp;lang=en&amp;contentorigin=espn&amp;isqualified=true&amp;page=2&amp;limit=50&amp;sort=offensive.avgPoints%3Adesc&amp;conference=4',\n\nheaders=headers,\n\nparams=params\n\n).json()\n\n \n\nreturn response\n\n&amp;#x200B;\n\ndef parse\\_json():\n\ndata = \\[\\]\n\nfor i in range(1,4):\n\njsonData = get\\_data(page=i)\n\nathletes = jsonData\\[\"athletes\"\\]\n\nfor athlete in athletes:\n\n\n\nname = athlete\\[\"athlete\"\\]\\[\"displayName\"\\]\n\nteamName = athlete\\['athlete'\\]\\['teamShortName'\\]\n\n\n\n\n\n\n\n\n\ngames\\_minutes\\_points = athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[0:2\\]\\\\\n\n\\+\\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[0\\]\\]\n\n\n\nrebounds\\_assists = \\[athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[12\\]\\]\\\\\n\n\\+ \\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[10\\]\\]\n\n\n\ntov\\_perg = \\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[11\\]\\]\n\n\n\nfouls\\_perg = \\[athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[2\\]\\]\n\n&amp;#x200B;\n\nsteals\\_blocks = athlete\\['categories'\\]\\[2\\]\\['totals'\\]\\[0:2\\]\n\n&amp;#x200B;\n\nshooting\\_totals = athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[1:10\\]\n\n\n\ntotals = games\\_minutes\\_points + rebounds\\_assists+steals\\_blocks\\\\\n\n\\+tov\\_perg+fouls\\_perg+shooting\\_totals\n\n\n\n\\# totals = athlete\\[\"categories\"\\]\\[1\\]\\[\"totals\"\\]\n\n\n\nplayer\\_position = athlete\\['athlete'\\]\\['position'\\]\\['name'\\]\n\nrank = athlete\\[\"categories\"\\]\\[1\\]\\[\"ranks\"\\]\\[0\\]\n\ndata.append(\n\n{\n\n\"name\": name,\n\n\"teamName\": teamName,\n\n\"position\": athlete\\['athlete'\\]\\['position'\\]\\['name'\\],\n\n\"totals\": totals,\n\n\"rank\": rank\n\n}\n\n)\n\nprint(f\"\\[INFO\\] {i}/3 processed\")\n\nsleep(3)\n\n \n\n \n\nwith open(\"jsonData.json\", \"w\", encoding =\"utf-8\") as file:\n\njson.dump(data, file, indent=4, ensure\\_ascii=False)\n\n \n\n \n\n \n\ndef main():\n\nparse\\_json()\n\n \n\n \n\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n\nmain()", "author_fullname": "t2_44ezd8dp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webscraping for Basketball (WNBA)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tr7gm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685247661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn how to webscrape from  &lt;a href=\"https://stats.wnba.com/players/traditional/?sort=PTS&amp;amp;dir=-1&amp;amp;Season=2023&amp;amp;SeasonType=Regular%20Season\"&gt;WNBA Stats | Players Traditional&lt;/a&gt; . I&amp;#39;ve done very little webscraping, I&amp;#39;ve only been able to do scrape from ESPN or basketball reference. This is the code I used, but I have no idea how to adapt to this website, or if this website would even allow webscraping using the method that I did.  Any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;------&lt;/p&gt;\n\n&lt;p&gt;import pandas as pd&lt;/p&gt;\n\n&lt;p&gt;import requests&lt;/p&gt;\n\n&lt;p&gt;import json&lt;/p&gt;\n\n&lt;p&gt;from time import sleep&lt;/p&gt;\n\n&lt;p&gt;def get_data(page: int):&lt;/p&gt;\n\n&lt;p&gt;headers = {&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;authority&amp;#39;: &amp;#39;&lt;a href=\"https://site.web.api.espn.com\"&gt;site.web.api.espn.com&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;accept&amp;#39;: &amp;#39;*/*&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;accept-language&amp;#39;: &amp;#39;en-US,en;q=0.9&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;origin&amp;#39;: &amp;#39;&lt;a href=\"https://www.espn.com\"&gt;https://www.espn.com&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;referer&amp;#39;: &amp;#39;&lt;a href=\"https://www.espn.com/\"&gt;https://www.espn.com/&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua&amp;#39;: &amp;#39;&amp;quot;Chromium&amp;quot;;v=&amp;quot;110&amp;quot;, &amp;quot;Not A(Brand&amp;quot;;v=&amp;quot;24&amp;quot;, &amp;quot;Microsoft Edge&amp;quot;;v=&amp;quot;110&amp;quot;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua-mobile&amp;#39;: &amp;#39;?0&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua-platform&amp;#39;: &amp;#39;&amp;quot;Windows&amp;quot;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-dest&amp;#39;: &amp;#39;empty&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-mode&amp;#39;: &amp;#39;cors&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-site&amp;#39;: &amp;#39;same-site&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;user-agent&amp;#39;: &amp;#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.49&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;params = {&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;region&amp;#39;: &amp;#39;us&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;lang&amp;#39;: &amp;#39;en&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;contentorigin&amp;#39;: &amp;#39;espn&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;isqualified&amp;#39;: &amp;#39;true&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;page&amp;#39;: f&amp;#39;{page}&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;limit&amp;#39;: &amp;#39;50&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sort&amp;#39;: &amp;#39;offensive.avgPoints:desc&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;conference&amp;#39;: &amp;#39;4&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;response = requests.get(&lt;/p&gt;\n\n&lt;p&gt;url=&amp;#39;[&lt;a href=\"https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?%5C%5C%5D(https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?%5C)\"&gt;https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\\\](https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;region=us&amp;amp;lang=en&amp;amp;contentorigin=espn&amp;amp;isqualified=true&amp;amp;page=2&amp;amp;limit=50&amp;amp;sort=offensive.avgPoints%3Adesc&amp;amp;conference=4&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;headers=headers,&lt;/p&gt;\n\n&lt;p&gt;params=params&lt;/p&gt;\n\n&lt;p&gt;).json()&lt;/p&gt;\n\n&lt;p&gt;return response&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;def parse_json():&lt;/p&gt;\n\n&lt;p&gt;data = []&lt;/p&gt;\n\n&lt;p&gt;for i in range(1,4):&lt;/p&gt;\n\n&lt;p&gt;jsonData = get_data(page=i)&lt;/p&gt;\n\n&lt;p&gt;athletes = jsonData[&amp;quot;athletes&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;for athlete in athletes:&lt;/p&gt;\n\n&lt;p&gt;name = athlete[&amp;quot;athlete&amp;quot;][&amp;quot;displayName&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;teamName = athlete[&amp;#39;athlete&amp;#39;][&amp;#39;teamShortName&amp;#39;]&lt;/p&gt;\n\n&lt;p&gt;games_minutes_points = athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][0:2]\\&lt;/p&gt;\n\n&lt;p&gt;+[athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][0]]&lt;/p&gt;\n\n&lt;p&gt;rebounds_assists = [athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][12]]\\&lt;/p&gt;\n\n&lt;p&gt;+ [athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][10]]&lt;/p&gt;\n\n&lt;p&gt;tov_perg = [athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][11]]&lt;/p&gt;\n\n&lt;p&gt;fouls_perg = [athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][2]]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;steals_blocks = athlete[&amp;#39;categories&amp;#39;][2][&amp;#39;totals&amp;#39;][0:2]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;shooting_totals = athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][1:10]&lt;/p&gt;\n\n&lt;p&gt;totals = games_minutes_points + rebounds_assists+steals_blocks\\&lt;/p&gt;\n\n&lt;p&gt;+tov_perg+fouls_perg+shooting_totals&lt;/p&gt;\n\n&lt;p&gt;# totals = athlete[&amp;quot;categories&amp;quot;][1][&amp;quot;totals&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;player_position = athlete[&amp;#39;athlete&amp;#39;][&amp;#39;position&amp;#39;][&amp;#39;name&amp;#39;]&lt;/p&gt;\n\n&lt;p&gt;rank = athlete[&amp;quot;categories&amp;quot;][1][&amp;quot;ranks&amp;quot;][0]&lt;/p&gt;\n\n&lt;p&gt;data.append(&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;name&amp;quot;: name,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;teamName&amp;quot;: teamName,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;position&amp;quot;: athlete[&amp;#39;athlete&amp;#39;][&amp;#39;position&amp;#39;][&amp;#39;name&amp;#39;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;totals&amp;quot;: totals,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;rank&amp;quot;: rank&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;print(f&amp;quot;[INFO] {i}/3 processed&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;sleep(3)&lt;/p&gt;\n\n&lt;p&gt;with open(&amp;quot;jsonData.json&amp;quot;, &amp;quot;w&amp;quot;, encoding =&amp;quot;utf-8&amp;quot;) as file:&lt;/p&gt;\n\n&lt;p&gt;json.dump(data, file, indent=4, ensure_ascii=False)&lt;/p&gt;\n\n&lt;p&gt;def main():&lt;/p&gt;\n\n&lt;p&gt;parse_json()&lt;/p&gt;\n\n&lt;p&gt;if __name__ == &amp;quot;__main__&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;main()&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tr7gm", "is_robot_indexable": true, "report_reasons": null, "author": "FinancialSundew", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tr7gm/webscraping_for_basketball_wnba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tr7gm/webscraping_for_basketball_wnba/", "subreddit_subscribers": 911193, "created_utc": 1685247661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, how are you? One question, I would like to start uploading my projects somewhere but I don't have much idea how to do it. At the moment I have two, one in excel and one in tableau. What would be the best way? My idea is to add more later", "author_fullname": "t2_8to5sap4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tlk0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685230436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, how are you? One question, I would like to start uploading my projects somewhere but I don&amp;#39;t have much idea how to do it. At the moment I have two, one in excel and one in tableau. What would be the best way? My idea is to add more later&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tlk0h", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Sand-27", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tlk0h/projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tlk0h/projects/", "subreddit_subscribers": 911193, "created_utc": 1685230436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Impress my Boss with new excel skills using scholarship data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t4fiw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_s0vrfwa", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "analytics", "selftext": "Hello everyone,\n\nI recently have been taking the google analytics certificate in tandem with a beginner to advanced excel class on Udemy (Kyle Pew). I have access to a bunch of scholarship data that was recently cleaned to provide an eligible list of students for a committee to pick from. I have things like major, GPA, city, confirmation on if they submitted an essay or not, and things like this. I was wondering if you all had any ideas how I could use this data in excel and both impress or provide an actionable insight to my supervisor? \n\nBackground I\u2019m going for a promotion that involves being good at excel so I figured providing a concrete example without being asked would increase my chances of securing the position.\n\nThanks again!", "author_fullname": "t2_s0vrfwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Impress my Boss with new excel skills using scholarship data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/analytics", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t4eyg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685185739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685185243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently have been taking the google analytics certificate in tandem with a beginner to advanced excel class on Udemy (Kyle Pew). I have access to a bunch of scholarship data that was recently cleaned to provide an eligible list of students for a committee to pick from. I have things like major, GPA, city, confirmation on if they submitted an essay or not, and things like this. I was wondering if you all had any ideas how I could use this data in excel and both impress or provide an actionable insight to my supervisor? &lt;/p&gt;\n\n&lt;p&gt;Background I\u2019m going for a promotion that involves being good at excel so I figured providing a concrete example without being asked would increase my chances of securing the position.&lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "33eaa002-9772-11ed-8e4c-ceed5ac07d71", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rhz9", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t4eyg", "is_robot_indexable": true, "report_reasons": null, "author": "nitsed004", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "subreddit_subscribers": 134036, "created_utc": 1685185243.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685185293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t4fiw", "is_robot_indexable": true, "report_reasons": null, "author": "nitsed004", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13t4eyg", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t4fiw/how_to_impress_my_boss_with_new_excel_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "subreddit_subscribers": 911193, "created_utc": 1685185293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I need help processing data. My friend offered me a helicopter ride (met through someone) in a certain city in the US in January of 2022 ... Lost contact of person who connected me the helicopter dude never gave me his name \ud83d\ude2d (he has an electrical engineering lisence from I'm assuming Florida... He owns a house in this city in south Florida) \n\nFast forward. I requested a FOIA (freedom of information act)  of all helicopters in that city January 2022 ... Less that 20 total. Easy. What happens. \n\nMy FOIA came in ANDDD according to the FOIA letter  they couldn't separate the rotorcrafts (helicopters) from the fixed wing (small planes \ud83d\ude2d) from January 2022. \n\nJanuary 2022 was a VERY BUSY month for planes... It's going to be an insane amount of data. \n\n(But it's probably over 10 pages with 50 aircraft info per page on 11 pt. Font) \n\nHow do I sort the helicopters out of the data. It was like 15 helis maximum. \n\nHOWEVER... \n\nYou can also download all the persons with pilot licenses. This guy has a pilot license (owns and flies his helicopter)... On a sheet that identifies type of lisence \n\nAs like p/h for helicopter.... How do you sort all the helicopter owners from this sheet? \n\nIt's as an excel sheet. \n\nPlease advise.", "author_fullname": "t2_c8quvjbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tpiyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685242238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need help processing data. My friend offered me a helicopter ride (met through someone) in a certain city in the US in January of 2022 ... Lost contact of person who connected me the helicopter dude never gave me his name \ud83d\ude2d (he has an electrical engineering lisence from I&amp;#39;m assuming Florida... He owns a house in this city in south Florida) &lt;/p&gt;\n\n&lt;p&gt;Fast forward. I requested a FOIA (freedom of information act)  of all helicopters in that city January 2022 ... Less that 20 total. Easy. What happens. &lt;/p&gt;\n\n&lt;p&gt;My FOIA came in ANDDD according to the FOIA letter  they couldn&amp;#39;t separate the rotorcrafts (helicopters) from the fixed wing (small planes \ud83d\ude2d) from January 2022. &lt;/p&gt;\n\n&lt;p&gt;January 2022 was a VERY BUSY month for planes... It&amp;#39;s going to be an insane amount of data. &lt;/p&gt;\n\n&lt;p&gt;(But it&amp;#39;s probably over 10 pages with 50 aircraft info per page on 11 pt. Font) &lt;/p&gt;\n\n&lt;p&gt;How do I sort the helicopters out of the data. It was like 15 helis maximum. &lt;/p&gt;\n\n&lt;p&gt;HOWEVER... &lt;/p&gt;\n\n&lt;p&gt;You can also download all the persons with pilot licenses. This guy has a pilot license (owns and flies his helicopter)... On a sheet that identifies type of lisence &lt;/p&gt;\n\n&lt;p&gt;As like p/h for helicopter.... How do you sort all the helicopter owners from this sheet? &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s as an excel sheet. &lt;/p&gt;\n\n&lt;p&gt;Please advise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tpiyb", "is_robot_indexable": true, "report_reasons": null, "author": "Soggy-Nectarine-3578", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tpiyb/data_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tpiyb/data_processing/", "subreddit_subscribers": 911193, "created_utc": 1685242238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I learned today that my friend's son, a recent graduate from Cornell, had an offer rescinded just before he was above to move to his new apartment this weekend before starting the new job next week. The company blamed it on \"uncertainty over the debt ceiling resolution\". What a joke.\n\nHow did we get to this absolutely unconscionable state? I graduated many years ago, and our first job was considered an honor, especially after interviewing the entire senior year. To see recent graduates getting this treatment is appalling, especially when they have financial commitments and are just starting their new careers.\n\nHaving consulted for many years, the state of corporate America is loathsome. I would have picked up the phone, called the CEO and put that company on full blast. Whatever happened to corporate responsibility and ethics? There are still companies that operate with principle (e.g., Procter &amp; Gamble) but they are few and far between. Just disgusting.", "author_fullname": "t2_6htailqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recent Graduate's Offer was Rescinded", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13to6f9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.35, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685237938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I learned today that my friend&amp;#39;s son, a recent graduate from Cornell, had an offer rescinded just before he was above to move to his new apartment this weekend before starting the new job next week. The company blamed it on &amp;quot;uncertainty over the debt ceiling resolution&amp;quot;. What a joke.&lt;/p&gt;\n\n&lt;p&gt;How did we get to this absolutely unconscionable state? I graduated many years ago, and our first job was considered an honor, especially after interviewing the entire senior year. To see recent graduates getting this treatment is appalling, especially when they have financial commitments and are just starting their new careers.&lt;/p&gt;\n\n&lt;p&gt;Having consulted for many years, the state of corporate America is loathsome. I would have picked up the phone, called the CEO and put that company on full blast. Whatever happened to corporate responsibility and ethics? There are still companies that operate with principle (e.g., Procter &amp;amp; Gamble) but they are few and far between. Just disgusting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13to6f9", "is_robot_indexable": true, "report_reasons": null, "author": "wavehnter", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13to6f9/recent_graduates_offer_was_rescinded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13to6f9/recent_graduates_offer_was_rescinded/", "subreddit_subscribers": 911193, "created_utc": 1685237938.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}