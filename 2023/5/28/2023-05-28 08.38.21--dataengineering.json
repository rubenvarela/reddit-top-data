{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I started in in fairly new role at a new company. The tech lead who just left decided that we would be using both databricks and snowflake. Those tools are now both stood up and ready for use, but we have no plan or best practices about how to leverage the strengths of both these platforms.\n\nMy boss wants us to definitely have an architecture that is using snowflake and databricks because he thinks it would be a bad look if we went down to one platform after paying/pitching for both.\n\nMy starting thought is use Databricks as the data lake and transformation layers. Push \u201cgold\u201d datasets over to snowflake that you would put in a data warehouse or something that would be fed off BI tool traditionally. Use Databricks also for exploratory analysis and research, machine learning, etc. Use Airflow as master orchestration layer.\n\nAny help or thoughts appreciated! I\u2019m kinda being forced into this decider role, which is cool, just polling for some community support :)", "author_fullname": "t2_lem3u0va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company wanted both Databricks and Snowflake so we have them (Airflow for data orchestration). Any advice on how best leverage these two platforms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tffsk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685214322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I started in in fairly new role at a new company. The tech lead who just left decided that we would be using both databricks and snowflake. Those tools are now both stood up and ready for use, but we have no plan or best practices about how to leverage the strengths of both these platforms.&lt;/p&gt;\n\n&lt;p&gt;My boss wants us to definitely have an architecture that is using snowflake and databricks because he thinks it would be a bad look if we went down to one platform after paying/pitching for both.&lt;/p&gt;\n\n&lt;p&gt;My starting thought is use Databricks as the data lake and transformation layers. Push \u201cgold\u201d datasets over to snowflake that you would put in a data warehouse or something that would be fed off BI tool traditionally. Use Databricks also for exploratory analysis and research, machine learning, etc. Use Airflow as master orchestration layer.&lt;/p&gt;\n\n&lt;p&gt;Any help or thoughts appreciated! I\u2019m kinda being forced into this decider role, which is cool, just polling for some community support :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13tffsk", "is_robot_indexable": true, "report_reasons": null, "author": "lezgomama", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tffsk/company_wanted_both_databricks_and_snowflake_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tffsk/company_wanted_both_databricks_and_snowflake_so/", "subreddit_subscribers": 107665, "created_utc": 1685214322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not a data engineer by trade so am pretty clueless about a lot of this stuff. Basically, I've built a web scraper that auto-runs daily using a 3rd party proxy. I then stumbled through a python script to use Regex to clean and organize all of the data. It's going to be 10-20k rows of data a day with like 20 columns.\n\nI was thinking of purchasing some sort of Azure database and putting all of the data in there. I would like to be able to also run the Python script from the database so that the entire thing is automatic. Researching the database solutions is incredibly overwhelming. I'm just looking for something simple and cost-effective that will work well with PowerBI which is the end use of this data. Any suggesstions?", "author_fullname": "t2_cpaosxa6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Appropriate database for small scraping project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tcpji", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685207177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a data engineer by trade so am pretty clueless about a lot of this stuff. Basically, I&amp;#39;ve built a web scraper that auto-runs daily using a 3rd party proxy. I then stumbled through a python script to use Regex to clean and organize all of the data. It&amp;#39;s going to be 10-20k rows of data a day with like 20 columns.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of purchasing some sort of Azure database and putting all of the data in there. I would like to be able to also run the Python script from the database so that the entire thing is automatic. Researching the database solutions is incredibly overwhelming. I&amp;#39;m just looking for something simple and cost-effective that will work well with PowerBI which is the end use of this data. Any suggesstions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13tcpji", "is_robot_indexable": true, "report_reasons": null, "author": "cre_guy_3", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tcpji/appropriate_database_for_small_scraping_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tcpji/appropriate_database_for_small_scraping_project/", "subreddit_subscribers": 107665, "created_utc": 1685207177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. First time caller long time listener. \n\nI am an experienced Sql server Dba but never dabbled in the DW world. Oddly. My current employer has no implementation whatsoever and we need it. Its trading platform and probably tons of current implementations out there I could use that could speed up the process. I think a Microsoft solution is logical but I don't care really. I think a methodology is most important early on but if that is product specific, then great.", "author_fullname": "t2_10kqri77", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehouse...where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t2joh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685178390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. First time caller long time listener. &lt;/p&gt;\n\n&lt;p&gt;I am an experienced Sql server Dba but never dabbled in the DW world. Oddly. My current employer has no implementation whatsoever and we need it. Its trading platform and probably tons of current implementations out there I could use that could speed up the process. I think a Microsoft solution is logical but I don&amp;#39;t care really. I think a methodology is most important early on but if that is product specific, then great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13t2joh", "is_robot_indexable": true, "report_reasons": null, "author": "Roedsten", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13t2joh/data_warehousewhere_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13t2joh/data_warehousewhere_to_start/", "subreddit_subscribers": 107665, "created_utc": 1685178390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recent Computer engineering grad here. I\u2019m applying to data science and data engineering roles, but realize that I lack a lot of the backend technical skills. I\u2019m proficient in SQL, Java and Python, but it ends there. \n\nI\u2019m looking to take a course(s) with little data engineering knowledge. Ideally something that\u2019s hands on (implementing through homework/projects) and does a wholistic overview of all the major concepts I see on job listing:\n- Kafka and lambda architectures\n- Data lake, warehousing and fabric concepts \n- Spark/Hadoop, Scala, NoSQL, Airflow, Snowflake \n- AWS or GCP or Azure (namely synaptics, data lake and databricks)\n\nBecause I\u2019m using this to bolster my resume, I figured taking a shotgun approach in learning all the concepts rather specializing in one particular tech stack. Especially since I dont know what that stack will be once I land a job. I plan on putting this on my resume as form of \u201csecondary/continued education\u201d\n\nI\u2019ve seen course offerings on udacity (How to Become a Data Engineer), on coursera (IBM and Google certifications), udemy, datacamp, etc.\n\nDoes anyone have recommendations? I plan on doing this full time so time commitment (and how in depth it gets) isn\u2019t an issue. \n\nThanks!", "author_fullname": "t2_i1ylqnf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE courses recommandations for a new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tkp7p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685228188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recent Computer engineering grad here. I\u2019m applying to data science and data engineering roles, but realize that I lack a lot of the backend technical skills. I\u2019m proficient in SQL, Java and Python, but it ends there. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to take a course(s) with little data engineering knowledge. Ideally something that\u2019s hands on (implementing through homework/projects) and does a wholistic overview of all the major concepts I see on job listing:\n- Kafka and lambda architectures\n- Data lake, warehousing and fabric concepts \n- Spark/Hadoop, Scala, NoSQL, Airflow, Snowflake \n- AWS or GCP or Azure (namely synaptics, data lake and databricks)&lt;/p&gt;\n\n&lt;p&gt;Because I\u2019m using this to bolster my resume, I figured taking a shotgun approach in learning all the concepts rather specializing in one particular tech stack. Especially since I dont know what that stack will be once I land a job. I plan on putting this on my resume as form of \u201csecondary/continued education\u201d&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen course offerings on udacity (How to Become a Data Engineer), on coursera (IBM and Google certifications), udemy, datacamp, etc.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have recommendations? I plan on doing this full time so time commitment (and how in depth it gets) isn\u2019t an issue. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13tkp7p", "is_robot_indexable": true, "report_reasons": null, "author": "BoiFormer", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tkp7p/de_courses_recommandations_for_a_new_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tkp7p/de_courses_recommandations_for_a_new_grad/", "subreddit_subscribers": 107665, "created_utc": 1685228188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for recommendations as to whether dbt core is worth using alongside databricks? I work in a very small data team (2/3 people) currently standing up databricks for our warehousing needs however, we have plans in the next year or so to move to streaming data in some domains.\n\nTrying to keep things as simple as possible aka. Not a load of tools but unsure if dbt would actually save time/effort adding it to the stack.\n\nNb. Haven't got a load of experience with databricks directly yet so unclear how difficult it is to develop a medallion architecture compared to dbt.\n\nAny thoughts greatly appreciated!", "author_fullname": "t2_t12o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks vs databricks + dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tj9y6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685224369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for recommendations as to whether dbt core is worth using alongside databricks? I work in a very small data team (2/3 people) currently standing up databricks for our warehousing needs however, we have plans in the next year or so to move to streaming data in some domains.&lt;/p&gt;\n\n&lt;p&gt;Trying to keep things as simple as possible aka. Not a load of tools but unsure if dbt would actually save time/effort adding it to the stack.&lt;/p&gt;\n\n&lt;p&gt;Nb. Haven&amp;#39;t got a load of experience with databricks directly yet so unclear how difficult it is to develop a medallion architecture compared to dbt.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13tj9y6", "is_robot_indexable": true, "report_reasons": null, "author": "KingslyLear", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tj9y6/databricks_vs_databricks_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tj9y6/databricks_vs_databricks_dbt/", "subreddit_subscribers": 107665, "created_utc": 1685224369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I heard it is a very demanded skill since not so many people can really master it. But is true?", "author_fullname": "t2_10spq8p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Spark a top demanded and highest paying framework in Data Engineering job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tu48e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685258530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I heard it is a very demanded skill since not so many people can really master it. But is true?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13tu48e", "is_robot_indexable": true, "report_reasons": null, "author": "andrey1736", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tu48e/is_apache_spark_a_top_demanded_and_highest_paying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tu48e/is_apache_spark_a_top_demanded_and_highest_paying/", "subreddit_subscribers": 107665, "created_utc": 1685258530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all , \nI'm working on a requirement where \n1. ODS layer gets data from source by Kafka .\n2. There are around 35 dimension tables gets loaded from around 300 tables in ODS \n3. Around 15 facts tables gets loaded from those dimensions.\n4. I need to create a mechanism that if anything changes in ODS , those changes should be reflected into facts( within 30 min) .\n\n So far I'm thinking of \n1. Creating a dynamic dag for dimensions \n2. Creating 35 SQL files for each dimensions tables.\n3. Pass 35 dimensions into it and that will check if there is any changes for the underlying table , and pick the update/ merge statement from the SQL file and execute.\n4. Same process for loading the facts \n5. All the dags are scheduled 30 min interval .\n\nAll my setup is at on prem .\nI'm worried that there could be too much tasks to handle at a point of time . \nIf there is any betterment or alternative better approach very much appreciated.", "author_fullname": "t2_2ofssxva", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow as near real time scheduler", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13ttwzl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685257762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all , \nI&amp;#39;m working on a requirement where \n1. ODS layer gets data from source by Kafka .\n2. There are around 35 dimension tables gets loaded from around 300 tables in ODS \n3. Around 15 facts tables gets loaded from those dimensions.\n4. I need to create a mechanism that if anything changes in ODS , those changes should be reflected into facts( within 30 min) .&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;m thinking of \n1. Creating a dynamic dag for dimensions \n2. Creating 35 SQL files for each dimensions tables.\n3. Pass 35 dimensions into it and that will check if there is any changes for the underlying table , and pick the update/ merge statement from the SQL file and execute.\n4. Same process for loading the facts \n5. All the dags are scheduled 30 min interval .&lt;/p&gt;\n\n&lt;p&gt;All my setup is at on prem .\nI&amp;#39;m worried that there could be too much tasks to handle at a point of time . \nIf there is any betterment or alternative better approach very much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ttwzl", "is_robot_indexable": true, "report_reasons": null, "author": "in_batman2015", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ttwzl/airflow_as_near_real_time_scheduler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ttwzl/airflow_as_near_real_time_scheduler/", "subreddit_subscribers": 107665, "created_utc": 1685257762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that the Parquet format keeps min/max statistics for integer columns.\n\nIn this way a query can directly skip several column chunk pages when they are not relevant. For example, if a chunk only contains the range \\[1, 5\\] and the query asks for number &gt; 10 you can skip that group of rows without loading it.\n\n1. Are there similar optimizations for a string column (e.g. a country name)?\n2. Are there similar optimizations for a long text field (e.g. a blog post) where you need to search some keywords?\n\nBasically I would like to understand if Parquet adds performance benefits only for numeric columns or if it adds performance gains also on string search.", "author_fullname": "t2_fsm2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Parquet file format index string columns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13th67v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685218851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that the Parquet format keeps min/max statistics for integer columns.&lt;/p&gt;\n\n&lt;p&gt;In this way a query can directly skip several column chunk pages when they are not relevant. For example, if a chunk only contains the range [1, 5] and the query asks for number &amp;gt; 10 you can skip that group of rows without loading it.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are there similar optimizations for a string column (e.g. a country name)?&lt;/li&gt;\n&lt;li&gt;Are there similar optimizations for a long text field (e.g. a blog post) where you need to search some keywords?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Basically I would like to understand if Parquet adds performance benefits only for numeric columns or if it adds performance gains also on string search.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13th67v", "is_robot_indexable": true, "report_reasons": null, "author": "collimarco", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13th67v/can_parquet_file_format_index_string_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13th67v/can_parquet_file_format_index_string_columns/", "subreddit_subscribers": 107665, "created_utc": 1685218851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently a couple years into a BI role doing ETL and dash boarding for a medium sized company. Everything is on prem and will likely not go to cloud for a very long time. \n\nRecently I received an offer for an ETL Dev job for a smaller e commerce company. Currently they use very dated low-code tools but are looking to switch over to more python scripting for their ETL processes. Also on prem at this time and not exactly sure about future tech. \n\nI want to take the offer as it\u2019s a ~20% pay bump and will get me away from dash boarding, but I\u2019m worried being in another role without more modern tech experience could be potentially harmful as I will continue to not get exposure to a lot of the modern tools and software organizations are using. \n\nWould you take the job to keep learning and potentially influence a shift to modern tech at the new company, or stay put and continue seeking a role where I could get exposure to tech that a lot more orgs are using?", "author_fullname": "t2_12r4c5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take ETL Dev Job With On Prem Tech Or Seek Cloud Role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tf9vo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685223059.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685213904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently a couple years into a BI role doing ETL and dash boarding for a medium sized company. Everything is on prem and will likely not go to cloud for a very long time. &lt;/p&gt;\n\n&lt;p&gt;Recently I received an offer for an ETL Dev job for a smaller e commerce company. Currently they use very dated low-code tools but are looking to switch over to more python scripting for their ETL processes. Also on prem at this time and not exactly sure about future tech. &lt;/p&gt;\n\n&lt;p&gt;I want to take the offer as it\u2019s a ~20% pay bump and will get me away from dash boarding, but I\u2019m worried being in another role without more modern tech experience could be potentially harmful as I will continue to not get exposure to a lot of the modern tools and software organizations are using. &lt;/p&gt;\n\n&lt;p&gt;Would you take the job to keep learning and potentially influence a shift to modern tech at the new company, or stay put and continue seeking a role where I could get exposure to tech that a lot more orgs are using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13tf9vo", "is_robot_indexable": true, "report_reasons": null, "author": "tab90925", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tf9vo/take_etl_dev_job_with_on_prem_tech_or_seek_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tf9vo/take_etl_dev_job_with_on_prem_tech_or_seek_cloud/", "subreddit_subscribers": 107665, "created_utc": 1685213904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I graduated about two years ago, since then I worked at a start up which specializes in data engineering for finance. During the period, I managed to work through a lake house project using databricks. \n\nI learned a lot during this time but I haven't gotten a raise. There are some opening positions for data engineering at a big asset manager, but I heard ppl there are less skilled so they can't seem to fulfil good projects. But at there I might get to learn other things and how to work through a big data engineering project and the pay would be better. Which one would be more sensible to choose? I haven't worked in a big company before so I might be missing something.", "author_fullname": "t2_9yos0fld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Company or Startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tdno2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685209681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I graduated about two years ago, since then I worked at a start up which specializes in data engineering for finance. During the period, I managed to work through a lake house project using databricks. &lt;/p&gt;\n\n&lt;p&gt;I learned a lot during this time but I haven&amp;#39;t gotten a raise. There are some opening positions for data engineering at a big asset manager, but I heard ppl there are less skilled so they can&amp;#39;t seem to fulfil good projects. But at there I might get to learn other things and how to work through a big data engineering project and the pay would be better. Which one would be more sensible to choose? I haven&amp;#39;t worked in a big company before so I might be missing something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13tdno2", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerSmart9636", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tdno2/big_company_or_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tdno2/big_company_or_startup/", "subreddit_subscribers": 107665, "created_utc": 1685209681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All  \nI have a genuine concern on data modelling. In most of the projects I worked as data engineer, I had less exposure to data modelling. How do I gain experience in real time modelling the data and stuff? Getting started is different, I find few good resources, getting hands-on on real projects is tricky. Any suggestions/ideas would be helpful", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling experience in real projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tu5mx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685258680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;br/&gt;\nI have a genuine concern on data modelling. In most of the projects I worked as data engineer, I had less exposure to data modelling. How do I gain experience in real time modelling the data and stuff? Getting started is different, I find few good resources, getting hands-on on real projects is tricky. Any suggestions/ideas would be helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13tu5mx", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tu5mx/data_modelling_experience_in_real_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13tu5mx/data_modelling_experience_in_real_projects/", "subreddit_subscribers": 107665, "created_utc": 1685258680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_imj3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Dignity: Developers Must Solve the AI Attribution Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13tho1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/l1XfyqWle-WKts-wK5XW-zYnc_PRV6Z0Bc4EpHKVrm8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685220167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "thenewstack.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://thenewstack.io/data-dignity-developers-must-solve-the-ai-attribution-problem/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?auto=webp&amp;v=enabled&amp;s=74015d7155c1313a4a14437741dcbebd780237d8", "width": 1280, "height": 853}, "resolutions": [{"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef8c00aca7027ad7238914170cf6fddce438c288", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b64eb6acd21d52788e61e22b18f6b384e64b951", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1eddc5fe08af03e945fb9f697eecf7beaf36f8a", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f170fa1f47634641fd40984c4f5250f05810b3f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff558ba0822c5df5d17e456eb70d38f09bbf4282", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/3WqrgJcnLYtQNpTIcKCWwj48euDKd800DaFdu_PQEs0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caa7e08f6ddf82d4da83accb53ef7ac9199463ad", "width": 1080, "height": 719}], "variants": {}, "id": "p9feqB0GUAnc162ph_q4Gz-Fl83BJ2a4zmAeS72jNaA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13tho1m", "is_robot_indexable": true, "report_reasons": null, "author": "ericabrookssf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13tho1m/data_dignity_developers_must_solve_the_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://thenewstack.io/data-dignity-developers-must-solve-the-ai-attribution-problem/", "subreddit_subscribers": 107665, "created_utc": 1685220167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm trying to reconcile the difference between data orchestration and a data orchestrator.\n\nThis seems to be a good definition of orchestration:\n\n Data orchestration is **the process of gathering siloed data from various locations across the company, organizing it into a consistent, usable format, and activating it for use by data analysis tools**. \n\nAnd this seems to be a data orchestrator is (from Apache Airflow):\n\nworkflow management platform for data engineering pipelines. It started at Airbnb in October 2014\\[2\\] as a solution to manage the company's increasingly complex workflows. Creating Airflow allowed Airbnb to programmatically author and schedule their workflows and monitor them via the built-in Airflow user interface.\\[3\\]\\[4\\] \n\nIs it fair to say thus:\n\n1) That data orchestration is the high level process of acquiring data from different locations, combining them, transforming them, and getting them ready for analysis\n\n2) A data orchestrator is more of a workflow management tool that handles coordinating all the different steps in the pipeline (like Fivetran, kafka, dbt, great expectations, DB management, etc.). The data orchestrator doesn't really do the data orchestration work - it just schedules and is workflow management for all the different modules in the MDS.\n\nThoughts?", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data orchestration vs data orchestrator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6lex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685191704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to reconcile the difference between data orchestration and a data orchestrator.&lt;/p&gt;\n\n&lt;p&gt;This seems to be a good definition of orchestration:&lt;/p&gt;\n\n&lt;p&gt;Data orchestration is &lt;strong&gt;the process of gathering siloed data from various locations across the company, organizing it into a consistent, usable format, and activating it for use by data analysis tools&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;And this seems to be a data orchestrator is (from Apache Airflow):&lt;/p&gt;\n\n&lt;p&gt;workflow management platform for data engineering pipelines. It started at Airbnb in October 2014[2] as a solution to manage the company&amp;#39;s increasingly complex workflows. Creating Airflow allowed Airbnb to programmatically author and schedule their workflows and monitor them via the built-in Airflow user interface.[3][4] &lt;/p&gt;\n\n&lt;p&gt;Is it fair to say thus:&lt;/p&gt;\n\n&lt;p&gt;1) That data orchestration is the high level process of acquiring data from different locations, combining them, transforming them, and getting them ready for analysis&lt;/p&gt;\n\n&lt;p&gt;2) A data orchestrator is more of a workflow management tool that handles coordinating all the different steps in the pipeline (like Fivetran, kafka, dbt, great expectations, DB management, etc.). The data orchestrator doesn&amp;#39;t really do the data orchestration work - it just schedules and is workflow management for all the different modules in the MDS.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13t6lex", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13t6lex/data_orchestration_vs_data_orchestrator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13t6lex/data_orchestration_vs_data_orchestrator/", "subreddit_subscribers": 107665, "created_utc": 1685191704.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}