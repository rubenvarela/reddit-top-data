{"kind": "Listing", "data": {"after": "t3_13ezfte", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "According to stack overflow survey 2022 Apache Spark is one of the highest paying technologies. But I am not sure if I can trust this survey. I am really afraid I will waste my time . So people with more experience could you please let me know if Apache Spark is high demanded and high paying skill? Will learning internals of it worth my time?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth learning Apache Spark in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eo3b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 115, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 115, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683813263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to stack overflow survey 2022 Apache Spark is one of the highest paying technologies. But I am not sure if I can trust this survey. I am really afraid I will waste my time . So people with more experience could you please let me know if Apache Spark is high demanded and high paying skill? Will learning internals of it worth my time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13eo3b3", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 105, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eo3b3/is_it_worth_learning_apache_spark_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eo3b3/is_it_worth_learning_apache_spark_in_2023/", "subreddit_subscribers": 105067, "created_utc": 1683813263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dlyjh58o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I didn\u2019t know you guys were paid THIS well", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13f4sbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-W5lW4G_sDXu5zmHbDU9uXeKZg22lfWQ5kyLCGW4zW4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683850188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3q8sosk43cza1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?auto=webp&amp;v=enabled&amp;s=e7c1108dac9af74b52e642937d3eaa09d1c2da16", "width": 828, "height": 829}, "resolutions": [{"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16581887d7722dcceef350d0e855111522cf4af1", "width": 108, "height": 108}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd160c1e59e0756894e6ef675488709405bae814", "width": 216, "height": 216}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0f0c6c600942d1c6e54507e86fffc22a1f75447", "width": 320, "height": 320}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=491017ed19445e1d73880bf6c09753df23c95e95", "width": 640, "height": 640}], "variants": {}, "id": "ztMXvGtUoH3Ex2Nl0cgDrNsUylSHVd8fjGHBfp7e5m0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13f4sbf", "is_robot_indexable": true, "report_reasons": null, "author": "BeneficialTitle9042", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13f4sbf/i_didnt_know_you_guys_were_paid_this_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3q8sosk43cza1.jpg", "subreddit_subscribers": 105067, "created_utc": 1683850188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not the first job post I've seen with something like this. \n\nCorrect me if I'm wrong, but didn't dbt only really take off in the last 3 years or so? It also said 7+ years as an analytics engineer. \n\nWhen you see job postings like this, do you facepalm?\n\nI'm aware that  version controlled data modeling existed prior to dbt, and the analytics engineer role existed prior to it's currently coined name.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I saw a job post asking for 7+ years of exp with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ep8an", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683815787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not the first job post I&amp;#39;ve seen with something like this. &lt;/p&gt;\n\n&lt;p&gt;Correct me if I&amp;#39;m wrong, but didn&amp;#39;t dbt only really take off in the last 3 years or so? It also said 7+ years as an analytics engineer. &lt;/p&gt;\n\n&lt;p&gt;When you see job postings like this, do you facepalm?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that  version controlled data modeling existed prior to dbt, and the analytics engineer role existed prior to it&amp;#39;s currently coined name.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ep8an", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13ep8an/i_saw_a_job_post_asking_for_7_years_of_exp_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ep8an/i_saw_a_job_post_asking_for_7_years_of_exp_with/", "subreddit_subscribers": 105067, "created_utc": 1683815787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we have a quite large RDS instance, MySQL 5.7, and its storage is \\~5-6TB.\n\nWe would like to perform a full dump of the data to S3, and we are comparing two options:\n\n* DMS \n* Apache Spark\n\n&amp;#x200B;\n\nWith DMS it is possible to perform a full snapshot on S3 in parquet format, and it takes 6-7 hours to do so with a 4 vCPU and 32 GB of memory. \n\nWith Spark, after 12 hours the snapshot is at 40-50% completion, with a 16 vCPU and 64GB of memory, in this case the snapshot is saved as json gzip (I could consider removing gzip compression, or using another codec like lz4, if you think gzip is a overhead that could drastically reduce CPU usage if removed).\n\n&amp;#x200B;\n\nWe would like to speed up the Spark implementation, also because we can slightly change the data format, a step that with DMS should be done after the full snapshot. (It's a simple column renaming/dropping, and wrapping some columns in a struct field, there are no expensive operations like joins or aggregations involved).\n\n&amp;#x200B;\n\nIs there anything that could be considered to speed up the Spark implementation? \n\n&amp;#x200B;\n\nThese are things I've already tested:\n\n* 4 queries when reading from the mysql tables, I use CRC32 % 4 of the primary key to define partitions to ingest.\n* FAIR scheduler of 4 FAIR  pools with the same weight and minShare of 2 cores, to avoid that the ingestion of a very large table keeps the others stuck\n* fetchSize is set to 10000", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS DMS vs Spark performances to dump mysql databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eejyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683784824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we have a quite large RDS instance, MySQL 5.7, and its storage is ~5-6TB.&lt;/p&gt;\n\n&lt;p&gt;We would like to perform a full dump of the data to S3, and we are comparing two options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DMS &lt;/li&gt;\n&lt;li&gt;Apache Spark&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;With DMS it is possible to perform a full snapshot on S3 in parquet format, and it takes 6-7 hours to do so with a 4 vCPU and 32 GB of memory. &lt;/p&gt;\n\n&lt;p&gt;With Spark, after 12 hours the snapshot is at 40-50% completion, with a 16 vCPU and 64GB of memory, in this case the snapshot is saved as json gzip (I could consider removing gzip compression, or using another codec like lz4, if you think gzip is a overhead that could drastically reduce CPU usage if removed).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We would like to speed up the Spark implementation, also because we can slightly change the data format, a step that with DMS should be done after the full snapshot. (It&amp;#39;s a simple column renaming/dropping, and wrapping some columns in a struct field, there are no expensive operations like joins or aggregations involved).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there anything that could be considered to speed up the Spark implementation? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;These are things I&amp;#39;ve already tested:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4 queries when reading from the mysql tables, I use CRC32 % 4 of the primary key to define partitions to ingest.&lt;/li&gt;\n&lt;li&gt;FAIR scheduler of 4 FAIR  pools with the same weight and minShare of 2 cores, to avoid that the ingestion of a very large table keeps the others stuck&lt;/li&gt;\n&lt;li&gt;fetchSize is set to 10000&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13eejyl", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13eejyl/aws_dms_vs_spark_performances_to_dump_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eejyl/aws_dms_vs_spark_performances_to_dump_mysql/", "subreddit_subscribers": 105067, "created_utc": 1683784824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have the trial right now, and want to take advantage of the free LinkedIn learning courses. I\u2019m still a beginner in data engineering, but I have python and SQL experience. Are there any courses that help familiarize with tools?", "author_fullname": "t2_62sz58k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any helpful LinkedIn learning courses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ebn70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683775115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have the trial right now, and want to take advantage of the free LinkedIn learning courses. I\u2019m still a beginner in data engineering, but I have python and SQL experience. Are there any courses that help familiarize with tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ebn70", "is_robot_indexable": true, "report_reasons": null, "author": "mangos5", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ebn70/are_there_any_helpful_linkedin_learning_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ebn70/are_there_any_helpful_linkedin_learning_courses/", "subreddit_subscribers": 105067, "created_utc": 1683775115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am a cloud and data architect who enjoys mentoring and guiding individuals in their data engineering careers. One common question I receive is, \"What resources should I use to learn?\" In my opinion, this is a personal preference, as everyone has their preferred method of consuming information.\n\nHowever, I am working on creating a free and accessible knowledge repository for learning data engineering. This repository will contain various types of resources, such as blogs, articles, videos, and free courses. Please note that all resources should be free and related to data engineering only.\n\nI would greatly appreciate your assistance in adding resources to this list. The link to the sheet can be found in the comments.\n\nThank you!", "author_fullname": "t2_rrbmofj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Learning Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqshf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683820379.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683819223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a cloud and data architect who enjoys mentoring and guiding individuals in their data engineering careers. One common question I receive is, &amp;quot;What resources should I use to learn?&amp;quot; In my opinion, this is a personal preference, as everyone has their preferred method of consuming information.&lt;/p&gt;\n\n&lt;p&gt;However, I am working on creating a free and accessible knowledge repository for learning data engineering. This repository will contain various types of resources, such as blogs, articles, videos, and free courses. Please note that all resources should be free and related to data engineering only.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your assistance in adding resources to this list. The link to the sheet can be found in the comments.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13eqshf", "is_robot_indexable": true, "report_reasons": null, "author": "Anishekkamal", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqshf/resources_for_learning_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqshf/resources_for_learning_data_engineering/", "subreddit_subscribers": 105067, "created_utc": 1683819223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I'm a seasoned data engineer, but I'm relatively new to Databricks. I thought Databricks architecture was built to support BI type workloads and using the Kimball design process would still be relevant. Is this the case or are there differences I should know about? Specifically, I'd like to use the Data Warehouse Bus Architecture and have several fact tables to model the different business processes. This is politically sensitive and I need to get my prep work done. I keep getting the \"Databricks is different\" argument and don't have the ammo to respond. Thanks!", "author_fullname": "t2_15z169", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and Kimball Design Methodology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eumw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683827662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;m a seasoned data engineer, but I&amp;#39;m relatively new to Databricks. I thought Databricks architecture was built to support BI type workloads and using the Kimball design process would still be relevant. Is this the case or are there differences I should know about? Specifically, I&amp;#39;d like to use the Data Warehouse Bus Architecture and have several fact tables to model the different business processes. This is politically sensitive and I need to get my prep work done. I keep getting the &amp;quot;Databricks is different&amp;quot; argument and don&amp;#39;t have the ammo to respond. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13eumw3", "is_robot_indexable": true, "report_reasons": null, "author": "brian313313", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eumw3/databricks_and_kimball_design_methodology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eumw3/databricks_and_kimball_design_methodology/", "subreddit_subscribers": 105067, "created_utc": 1683827662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT 101 - The Why And What Of ELT (Or The Why NOT Of ETL)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_13emfhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_U45ecsniw0MZrt-ZkYZLxVnPI3gypUtV0EbBdf7Z6w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683809263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/elt-101-the-why-and-what-of-elt-or-the-why-not-of-etl/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?auto=webp&amp;v=enabled&amp;s=3e7bfae807bd38392dd3184d8b1a3915ba9f9ca9", "width": 1600, "height": 760}, "resolutions": [{"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30d3adf67da4cbad7486c774839594a791b9b2df", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f34fa995012dcef46dc4f1270ad45833853d5b", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbad3936f082f45d25a5449d329719c2c5602479", "width": 320, "height": 152}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08509a10de100cc021f848d5d9cb69b7a6739c31", "width": 640, "height": 304}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cbefb17455f18c969587d37b615f0489e3bf4d1", "width": 960, "height": 456}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a84e6285df65082ee41fdd428d75cf98f7cd46bb", "width": 1080, "height": 513}], "variants": {}, "id": "t-qdIuB2oxr3uBAIhIi3yYRHyT7VRP9u_r4wrrOLflk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13emfhj", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13emfhj/elt_101_the_why_and_what_of_elt_or_the_why_not_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/elt-101-the-why-and-what-of-elt-or-the-why-not-of-etl/", "subreddit_subscribers": 105067, "created_utc": 1683809263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6kydy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coinbase's $65m Datadog bill, an interesting case study", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "name": "t3_13ew85o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DJ3WtQT4Oq-Pq8LyyggvunEnj0uJTzYNyAP1PujzDQE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683830977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newsletter.pragmaticengineer.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://newsletter.pragmaticengineer.com/p/datadogs-65myear-customer-mystery?utm_source=post-email-title&amp;publication_id=458709&amp;post_id=120778088&amp;isFreemail=true&amp;utm_medium=email", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JwbuA9Ma-q0m0A4VivuJ_eNdpI_tI54F2oCX1LJPgYc.jpg?auto=webp&amp;v=enabled&amp;s=b6cd9e555abc718df9e3da696f8aa063746419be", "width": 420, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/JwbuA9Ma-q0m0A4VivuJ_eNdpI_tI54F2oCX1LJPgYc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828969d646f09c85f572334e4775b1973802505c", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/JwbuA9Ma-q0m0A4VivuJ_eNdpI_tI54F2oCX1LJPgYc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3d48b5189902e878ad6f619b93c0c2584178bdb", "width": 216, "height": 154}, {"url": "https://external-preview.redd.it/JwbuA9Ma-q0m0A4VivuJ_eNdpI_tI54F2oCX1LJPgYc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55de2ac881731fcc6041d555d6333e55e310d0a3", "width": 320, "height": 228}], "variants": {}, "id": "mLCdrJ7tNmaGmMiYsfiZx_9fUmQwSziiZP5egcFPtqo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ew85o", "is_robot_indexable": true, "report_reasons": null, "author": "RockyMcNuts", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ew85o/coinbases_65m_datadog_bill_an_interesting_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://newsletter.pragmaticengineer.com/p/datadogs-65myear-customer-mystery?utm_source=post-email-title&amp;publication_id=458709&amp;post_id=120778088&amp;isFreemail=true&amp;utm_medium=email", "subreddit_subscribers": 105067, "created_utc": 1683830977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this depends sometimes on the tool, language, or database being used, but just curious on data engineers\u2019 preferred styles.\n\nAlso what style did I miss? (ran out of options in the poll).\n\nThese two are missed:\n\nCapital\\_Snake\n\nALLUPPERCASE\n\n[View Poll](https://www.reddit.com/poll/13ed95o)", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What case style does everyone use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ed95o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683780383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this depends sometimes on the tool, language, or database being used, but just curious on data engineers\u2019 preferred styles.&lt;/p&gt;\n\n&lt;p&gt;Also what style did I miss? (ran out of options in the poll).&lt;/p&gt;\n\n&lt;p&gt;These two are missed:&lt;/p&gt;\n\n&lt;p&gt;Capital_Snake&lt;/p&gt;\n\n&lt;p&gt;ALLUPPERCASE&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13ed95o\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ed95o", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1684385183772, "options": [{"text": "camelCase", "id": "22975681"}, {"text": "snake_case", "id": "22975682"}, {"text": "CapitalCamel", "id": "22975683"}, {"text": "SCREAMING_SNAKE", "id": "22975684"}, {"text": "alllower", "id": "22975685"}, {"text": "LGCYCASE (legacy case - 8 chars max, all upper)", "id": "22975686"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 668, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ed95o/what_case_style_does_everyone_use/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/13ed95o/what_case_style_does_everyone_use/", "subreddit_subscribers": 105067, "created_utc": 1683780383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are Streamlit's editable dataframes?\ud83d\udccb\u00a0Editable dataframes are a new feature in Streamlit that allows users to interactively edit data tables.\ud83d\udc49 Users can click on cells and edit their contents, add or delete rows, and copy-paste data from other sources.\n\n\ud83d\udd11Key features include  \n\ud83d\uddff Bulk editing  \n\ud83d\uddc3\ufe0f Support for various data types  \n\ud83d\udd23 Automatic input validation\ud83d\udcb2Rich editing experience with \u2611\ufe0fcheckboxes and dropdowns.  \n\n\nhttps://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb\n\n[https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over](https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over)", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deeper dive into Streamlit editable dataframes on top of \u2744\ufe0fSnowflake with example code showing how to create \u270d\ufe0f data write-back application using Streamlit and Snowflake. Replace Google Sheets https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6kcdybzra5za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fe15e81a5764c940d221c2ec1d683e3bae2da2c"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d21ab9394473652556d63f02e395e5d6010f3f4"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81d37d9b1795ac5872db915b0806c32c93f0a8b3"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d77f021bfcfba696084f17b4b66ac8607f67bfd"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b64efb4b7b5e045d3a4774a09bab2d35b639dc"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eea00ca04b03d6b71624818f4045dcdbb4b6e6e7"}], "s": {"y": 875, "x": 1920, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb"}, "id": "6kcdybzra5za1"}}, "name": "t3_13eew3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MVdA8qI1kzF9voun5EtowBWzu3IS6ZBu8w3sGxh9GhQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683786031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are Streamlit&amp;#39;s editable dataframes?\ud83d\udccb\u00a0Editable dataframes are a new feature in Streamlit that allows users to interactively edit data tables.\ud83d\udc49 Users can click on cells and edit their contents, add or delete rows, and copy-paste data from other sources.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd11Key features include&lt;br/&gt;\n\ud83d\uddff Bulk editing&lt;br/&gt;\n\ud83d\uddc3\ufe0f Support for various data types&lt;br/&gt;\n\ud83d\udd23 Automatic input validation\ud83d\udcb2Rich editing experience with \u2611\ufe0fcheckboxes and dropdowns.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb\"&gt;https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over\"&gt;https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13eew3d", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eew3d/deeper_dive_into_streamlit_editable_dataframes_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eew3d/deeper_dive_into_streamlit_editable_dataframes_on/", "subreddit_subscribers": 105067, "created_utc": 1683786031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since April I applied for like 1-200 job postings, had 20+ interview rounds, and got to the final interview stage for three companies. Then I was rejected from all of them.\n\nAll of them moved very fast from phone screening to the final stage (one interview to another next day)\u2026 then silence. No response to my follow-up request. Two weeks later I get a rejection letter.\n\nI get a fairly good amount of recruiter calls so I assumed my resume is fine even if not perfect. I am not very confident with my soft skill but I at least keep it very polite, just not extroverted. All those final interviews also felt like it went pretty well\u2026 (they felt like an actual conversation, went over the scheduled time talking about a bunch of extra stuff, and etc)\n\nI could keep revisiting my resume and practice coding questions, but also I am just lost on what other things to improve. What are the common reasons to be rejected from the final interviews? I would really appreciate some input from hiring manager\u2019s perspective.", "author_fullname": "t2_bga13dih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep failing at the final interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f2moo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683844935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since April I applied for like 1-200 job postings, had 20+ interview rounds, and got to the final interview stage for three companies. Then I was rejected from all of them.&lt;/p&gt;\n\n&lt;p&gt;All of them moved very fast from phone screening to the final stage (one interview to another next day)\u2026 then silence. No response to my follow-up request. Two weeks later I get a rejection letter.&lt;/p&gt;\n\n&lt;p&gt;I get a fairly good amount of recruiter calls so I assumed my resume is fine even if not perfect. I am not very confident with my soft skill but I at least keep it very polite, just not extroverted. All those final interviews also felt like it went pretty well\u2026 (they felt like an actual conversation, went over the scheduled time talking about a bunch of extra stuff, and etc)&lt;/p&gt;\n\n&lt;p&gt;I could keep revisiting my resume and practice coding questions, but also I am just lost on what other things to improve. What are the common reasons to be rejected from the final interviews? I would really appreciate some input from hiring manager\u2019s perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13f2moo", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Departure_8097", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f2moo/keep_failing_at_the_final_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f2moo/keep_failing_at_the_final_interview/", "subreddit_subscribers": 105067, "created_utc": 1683844935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, everyone.\n\nFor those that are still interested, I've add a `Fixtures` tab in my Streamlit dashboard.\n\nInstead of using BigQuery, I'm storing the data for each match in [Google Cloud's Firestore](https://firebase.google.com/docs/firestore/) which is part of Firebase.\n\nFirestore is NoSQL Document Database. The data from the Football API that I am using uses a JSON format and the matches have nested fields so storing it this way made sense instead of having to build a long table.\n\nHere is what the data looks like in Firestore:\n\n&amp;#x200B;\n\n[Firestore data.](https://preview.redd.it/tu2fyqnuw7za1.png?width=2798&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7d7138f3716a2b7e539b387ddb09d1dc4452cc1c)\n\nMy dashboard will only be concerned with the current season (until I decide to expand to historical statistics) so each `collection` is based off of the round and each `document` is based on the match.\n\nWith Streamlit, I can now display the fixtures per round!\n\n&amp;#x200B;\n\n[fixtures per round in streamlit](https://preview.redd.it/qm63ehg3y7za1.png?width=3056&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d8430d017e82177e537a877c36f4165cc9dd2b0e)\n\nI have the Python script responsible for this containerized and runs on Cloud Run three times a day.\n\nHere are some links for you to check out:\n\nGitHub Repository: [https://github.com/digitalghost-dev/premier-league](https://github.com/digitalghost-dev/premier-league)\n\nStreamlit Dashboard: [https://premierleague.streamlit.app](https://premierleague.streamlit.app)\n\n[Updated architecture flowchart](https://preview.redd.it/du8mlf6pz7za1.png?width=1584&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8e57bcd069571989a2ceab62db39484abe605d05)\n\nThanks \ud83e\udee1", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Firestore into my Premier League Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tu2fyqnuw7za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08503ff304ab9b2d9561003aa92dab3fc83b01ba"}, {"y": 81, "x": 216, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30a21d362d4e278bbb7724d3ce6d545ad3e000a9"}, {"y": 120, "x": 320, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84114ed6f6cc5da8bde92b8ac4b0ebde36adcd51"}, {"y": 240, "x": 640, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6700d12cd390af7bd0d5c96a37f710a7a3c6578"}, {"y": 360, "x": 960, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c205b6d977c688d7094ffbb1484c3b8e0ee33043"}, {"y": 405, "x": 1080, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c65197e3ab482dd9917b26170d8dac4db901f0a"}], "s": {"y": 1050, "x": 2798, "u": "https://preview.redd.it/tu2fyqnuw7za1.png?width=2798&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7d7138f3716a2b7e539b387ddb09d1dc4452cc1c"}, "id": "tu2fyqnuw7za1"}, "du8mlf6pz7za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 101, "x": 108, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a43e767525bfc6acc6ebfc40ec4ff0dd858256b"}, {"y": 203, "x": 216, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0064567a829d1ba0219015b0a8eb1e8ad49680d8"}, {"y": 301, "x": 320, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03acf4e65725c5c6cdfda902431d6a3c34dbe5e6"}, {"y": 602, "x": 640, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1c723a3e175f08a1a5e5ba43fbbae1ee67aabd7"}, {"y": 903, "x": 960, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3621e211c3bae18517b6014da2375e9f72481bf"}, {"y": 1015, "x": 1080, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1323fa9829ed62ef6f29244db237f4520d835fe"}], "s": {"y": 1490, "x": 1584, "u": "https://preview.redd.it/du8mlf6pz7za1.png?width=1584&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8e57bcd069571989a2ceab62db39484abe605d05"}, "id": "du8mlf6pz7za1"}, "qm63ehg3y7za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c161028f67c7d8c1c82c93c8a040992e79594cf6"}, {"y": 105, "x": 216, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c6e6d13aa309e1f2e5f06ca9895c2e20d4d8c3f"}, {"y": 156, "x": 320, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02072f213d1fd3c31825f812892f99b946805d8c"}, {"y": 312, "x": 640, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f829927c52947f06adfd3960e4ceefcd87135e8e"}, {"y": 469, "x": 960, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab29ed860ceff4074eb64fe2bb137a98dc18e10b"}, {"y": 527, "x": 1080, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5972f7af2e9a80e1bfb429c86c636d6d98101b35"}], "s": {"y": 1494, "x": 3056, "u": "https://preview.redd.it/qm63ehg3y7za1.png?width=3056&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d8430d017e82177e537a877c36f4165cc9dd2b0e"}, "id": "qm63ehg3y7za1"}}, "name": "t3_13eqbfy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WwVG4EDtv3R6mk3TasaEe2xtbO-Lqn5aoskFyxHoyFk.jpg", "edited": 1683818615.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683818191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, everyone.&lt;/p&gt;\n\n&lt;p&gt;For those that are still interested, I&amp;#39;ve add a &lt;code&gt;Fixtures&lt;/code&gt; tab in my Streamlit dashboard.&lt;/p&gt;\n\n&lt;p&gt;Instead of using BigQuery, I&amp;#39;m storing the data for each match in &lt;a href=\"https://firebase.google.com/docs/firestore/\"&gt;Google Cloud&amp;#39;s Firestore&lt;/a&gt; which is part of Firebase.&lt;/p&gt;\n\n&lt;p&gt;Firestore is NoSQL Document Database. The data from the Football API that I am using uses a JSON format and the matches have nested fields so storing it this way made sense instead of having to build a long table.&lt;/p&gt;\n\n&lt;p&gt;Here is what the data looks like in Firestore:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tu2fyqnuw7za1.png?width=2798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7d7138f3716a2b7e539b387ddb09d1dc4452cc1c\"&gt;Firestore data.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My dashboard will only be concerned with the current season (until I decide to expand to historical statistics) so each &lt;code&gt;collection&lt;/code&gt; is based off of the round and each &lt;code&gt;document&lt;/code&gt; is based on the match.&lt;/p&gt;\n\n&lt;p&gt;With Streamlit, I can now display the fixtures per round!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qm63ehg3y7za1.png?width=3056&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d8430d017e82177e537a877c36f4165cc9dd2b0e\"&gt;fixtures per round in streamlit&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have the Python script responsible for this containerized and runs on Cloud Run three times a day.&lt;/p&gt;\n\n&lt;p&gt;Here are some links for you to check out:&lt;/p&gt;\n\n&lt;p&gt;GitHub Repository: &lt;a href=\"https://github.com/digitalghost-dev/premier-league\"&gt;https://github.com/digitalghost-dev/premier-league&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Streamlit Dashboard: &lt;a href=\"https://premierleague.streamlit.app\"&gt;https://premierleague.streamlit.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/du8mlf6pz7za1.png?width=1584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8e57bcd069571989a2ceab62db39484abe605d05\"&gt;Updated architecture flowchart&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83e\udee1&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "13eqbfy", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/", "subreddit_subscribers": 105067, "created_utc": 1683818191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My current company uses Fivetran and it has mostly gone well, but I am moving to a new company soon and will probably need to make a decision on EL tooling.\n\nThe biggest thing that scares me about Fivetran is the MAR-based pricing, which I can definitely see blowing up at my current place over the next year or two. Especially as we start to add just the kinds of event and audit tables that would otherwise be useful in capturing and modeling historical data. My new place is a smaller, lean company so I don't want to set them up for exploding EL costs if avoidable.\n\nSo thoughts about Stitch vs. Fivetran specifically in these areas?  \n1) Production database syncs with CDC -- does Stitch do this well, is it performant? Does it actually capture all data changes or have people run into weird bugs? Stitch certainly looks much cheaper than Fivetran but I don't want to blunder into a \"you get what you pay for\" situation.  \n2) Any experiences using Stitch or Fivetran to capture Salesforce and NetSuite data? Does one of the tools seem more mature or performant in this area? Do they do a good job of capturing full history over time? Is it true that Fivetran will normalize to the extreme just to drive up MAR and cost on these API-based syncs?  \n\n\nThose are the two main questions. I see some general discussion but want to get into details if anyone has experience here. Much appreciated!", "author_fullname": "t2_ikd9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitch vs. Fivetran (some specific cases)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqh1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683818527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current company uses Fivetran and it has mostly gone well, but I am moving to a new company soon and will probably need to make a decision on EL tooling.&lt;/p&gt;\n\n&lt;p&gt;The biggest thing that scares me about Fivetran is the MAR-based pricing, which I can definitely see blowing up at my current place over the next year or two. Especially as we start to add just the kinds of event and audit tables that would otherwise be useful in capturing and modeling historical data. My new place is a smaller, lean company so I don&amp;#39;t want to set them up for exploding EL costs if avoidable.&lt;/p&gt;\n\n&lt;p&gt;So thoughts about Stitch vs. Fivetran specifically in these areas?&lt;br/&gt;\n1) Production database syncs with CDC -- does Stitch do this well, is it performant? Does it actually capture all data changes or have people run into weird bugs? Stitch certainly looks much cheaper than Fivetran but I don&amp;#39;t want to blunder into a &amp;quot;you get what you pay for&amp;quot; situation.&lt;br/&gt;\n2) Any experiences using Stitch or Fivetran to capture Salesforce and NetSuite data? Does one of the tools seem more mature or performant in this area? Do they do a good job of capturing full history over time? Is it true that Fivetran will normalize to the extreme just to drive up MAR and cost on these API-based syncs?  &lt;/p&gt;\n\n&lt;p&gt;Those are the two main questions. I see some general discussion but want to get into details if anyone has experience here. Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13eqh1h", "is_robot_indexable": true, "report_reasons": null, "author": "dlb8685", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqh1h/stitch_vs_fivetran_some_specific_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqh1h/stitch_vs_fivetran_some_specific_cases/", "subreddit_subscribers": 105067, "created_utc": 1683818527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[My attempt at an 'explain it to an 8 year old'](https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56)\n\n\u00a0The 2004 flick, \u201850 First Dates\u2019 with Adam Sandler and Drew Barrymore can help explain change data capture and Apache Kafka.\n\nIn the movie, a single Drew Barrymore suffers from severe amnesia after an accident and is unable to retain net new memories.\n\nOu lovestruck potential suitor, Adam Sandler, doesn\u2019t lose hope though. Instead, he creates a video tape (https://www.youtube.com/watch?v=XP8nQGv4eKI) that is to be watched each morning when she wakes up.\n\nThe tape (and her journal) linearly summarizes her life, the news, and the major milestones. He adds on to the end of tape each day so she is always up to the current reality.\n\nWhere it meets Kafka &amp; CDC:\n\nAppending the new video of each new date to the end of the videotape is the essence of Apache Kafka's log design as well as change data capture...\n\n\\*Instead of re-creating the tape from scratch each day, which would be very time consuming and equivalent to a nightly full database export, Adam is just appending onto the end of the tape\n\n\\*The videos are added in 'exact-order' they occurred\n\n\\*When Drew Barrymore starts at knowing nothing each day, the video tape is able to backfill her knowledge as if she was a data application.\n\n\\*The tape is never destroyed so the video-tape / log can shared with other should others need to remember\n\nReasonable comparison?", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How the movie '50 first date' explains Change Data Capture design (&amp; Apache Kafka)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "media_metadata": {"r0dtwu0i4bza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f17e5ba095b155525217ae680f0ef369f0a3e03f"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d55594742a0fa0b0acb74ca848247dbb29b7bab2"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f8212e15a9064054496609535f27b306d10df8"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eaa0a85935837dd3230901b94c43a7c32ae47a"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e0e5e54351831c6c55d0293e47d835b16bc744a"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c916f1bb1c1a8a133bcbcc303f95499c291247"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56"}, "id": "r0dtwu0i4bza1"}}, "name": "t3_13f7ceh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "50 First Dates: Lucy Watches Henry's Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "author_name": "Scene City", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XP8nQGv4eKI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SceneCityOfficial"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13f7ceh", "height": 200}, "link_flair_text": "Meme", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GqiWmpmaBCezjhJBrgog70R4yQ2rj0kNHapzhUtXqt8.jpg", "edited": 1683859686.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683856967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56\"&gt;My attempt at an &amp;#39;explain it to an 8 year old&amp;#39;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\u00a0The 2004 flick, \u201850 First Dates\u2019 with Adam Sandler and Drew Barrymore can help explain change data capture and Apache Kafka.&lt;/p&gt;\n\n&lt;p&gt;In the movie, a single Drew Barrymore suffers from severe amnesia after an accident and is unable to retain net new memories.&lt;/p&gt;\n\n&lt;p&gt;Ou lovestruck potential suitor, Adam Sandler, doesn\u2019t lose hope though. Instead, he creates a video tape (&lt;a href=\"https://www.youtube.com/watch?v=XP8nQGv4eKI\"&gt;https://www.youtube.com/watch?v=XP8nQGv4eKI&lt;/a&gt;) that is to be watched each morning when she wakes up.&lt;/p&gt;\n\n&lt;p&gt;The tape (and her journal) linearly summarizes her life, the news, and the major milestones. He adds on to the end of tape each day so she is always up to the current reality.&lt;/p&gt;\n\n&lt;p&gt;Where it meets Kafka &amp;amp; CDC:&lt;/p&gt;\n\n&lt;p&gt;Appending the new video of each new date to the end of the videotape is the essence of Apache Kafka&amp;#39;s log design as well as change data capture...&lt;/p&gt;\n\n&lt;p&gt;*Instead of re-creating the tape from scratch each day, which would be very time consuming and equivalent to a nightly full database export, Adam is just appending onto the end of the tape&lt;/p&gt;\n\n&lt;p&gt;*The videos are added in &amp;#39;exact-order&amp;#39; they occurred&lt;/p&gt;\n\n&lt;p&gt;*When Drew Barrymore starts at knowing nothing each day, the video tape is able to backfill her knowledge as if she was a data application.&lt;/p&gt;\n\n&lt;p&gt;*The tape is never destroyed so the video-tape / log can shared with other should others need to remember&lt;/p&gt;\n\n&lt;p&gt;Reasonable comparison?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?auto=webp&amp;v=enabled&amp;s=61474ddb54fb6b298cea112352e2c982667350fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712c8362b3e8c76407e3bb2c756ec8e33a6abfd9", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fef451d455ca0b092a1d7cec35116dbf9b6234ff", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=559543ba516df33ab2117a718e9357e791c8272b", "width": 320, "height": 240}], "variants": {}, "id": "VLXne7b-n5l2YV6V6ATWURluoHVEltN7IFxkZSBcATk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13f7ceh", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f7ceh/how_the_movie_50_first_date_explains_change_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f7ceh/how_the_movie_50_first_date_explains_change_data/", "subreddit_subscribers": 105067, "created_utc": 1683856967.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "50 First Dates: Lucy Watches Henry's Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "author_name": "Scene City", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XP8nQGv4eKI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SceneCityOfficial"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to gauge interest in data engineering career coaching. \n\nI\u2019ve been working in DE for 5+ years and worked my way from Data engineer to architect to manager while in consulting and tech companies. I would like to help others navigate their career. \n\nServices would include career planning, interview prep, salary negotiation, and a capstone project in a cloud provider (AWS, Azure, GCP)\n\n[View Poll](https://www.reddit.com/poll/13f70g1)", "author_fullname": "t2_ay99iuoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering Career Coach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13f70g1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683856103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to gauge interest in data engineering career coaching. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working in DE for 5+ years and worked my way from Data engineer to architect to manager while in consulting and tech companies. I would like to help others navigate their career. &lt;/p&gt;\n\n&lt;p&gt;Services would include career planning, interview prep, salary negotiation, and a capstone project in a cloud provider (AWS, Azure, GCP)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13f70g1\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13f70g1", "is_robot_indexable": true, "report_reasons": null, "author": "Rich_Repair", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1684115303266, "options": [{"text": "I\u2019m interested", "id": "22989366"}, {"text": "I\u2019m not interested", "id": "22989367"}, {"text": "I\u2019m maybe interested", "id": "22989368"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 15, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f70g1/data_engineering_career_coach/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/13f70g1/data_engineering_career_coach/", "subreddit_subscribers": 105067, "created_utc": 1683856103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ray is a framework for scaling Python applications. Ray allows you to execute the same Python program that you would run on your laptop on a cluster of computers with minimum effort. All you need is to tell Ray what part of your program needs to be scalable by decorating your Python functions and classes, and Ray takes care of the rest for you. Ray has been used by several companies including OpenAI for building ChatGPT.\n\n&amp;#x200B;\n\n[https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html](https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html)", "author_fullname": "t2_2rtceaie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ray: A Framework for Scaling Python Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f6a7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683854128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ray is a framework for scaling Python applications. Ray allows you to execute the same Python program that you would run on your laptop on a cluster of computers with minimum effort. All you need is to tell Ray what part of your program needs to be scalable by decorating your Python functions and classes, and Ray takes care of the rest for you. Ray has been used by several companies including OpenAI for building ChatGPT.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html\"&gt;https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?auto=webp&amp;v=enabled&amp;s=7f497d5be22e61ed476b9b368debd4ded7eea78e", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f000562da8ae6397a4a2d80935c6db51b527b9ab", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad5d8c762eb6c2c0dbfb39daf60942051c08759a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=511dd8c203aacf45ae98a7981e735942d4541558", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=186a7dfa6a2fb7e809c070862f216a11490ae02a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1b3c3c3cf4a712462710af620147dc0887061c3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9b0c3964c603ee14e260feb0953f26e06b9d9c4", "width": 1080, "height": 567}], "variants": {}, "id": "WyQs-qPvmyGCPPZ6sSCmms8ElLefyR3S3MwmCEA4-Gw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13f6a7c", "is_robot_indexable": true, "report_reasons": null, "author": "roohitavaf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f6a7c/ray_a_framework_for_scaling_python_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f6a7c/ray_a_framework_for_scaling_python_applications/", "subreddit_subscribers": 105067, "created_utc": 1683854128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I reviewed a data pipeline project that compares Louisville Metro expenditure data across fiscal years. The project utilized Terraform, a Prefect Docker container, and Google Cloud Storage/Big Query. I was impressed with the partitioning of data by fiscal year, fulfilling project requirements despite the dataset being less than 1GB. Clear instructions and a well-designed dashboard made it easy to navigate. Suggested future improvement is to include a script for downloading data directly from the original source to avoid excessive report generation. Kudos to everyone involved in DataTalksClub Data Engineering Zoomcamp 2023 and Louisville Open Data portal for public access to the data.\n\n[GitHub](https://github.com/Xanthus1/zoomcamp-louisville-data/tree/main)  \n\n\n\\#dezoomcamp", "author_fullname": "t2_52y1it67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review of Louisville Metro Expenditure Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13esll5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683823304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I reviewed a data pipeline project that compares Louisville Metro expenditure data across fiscal years. The project utilized Terraform, a Prefect Docker container, and Google Cloud Storage/Big Query. I was impressed with the partitioning of data by fiscal year, fulfilling project requirements despite the dataset being less than 1GB. Clear instructions and a well-designed dashboard made it easy to navigate. Suggested future improvement is to include a script for downloading data directly from the original source to avoid excessive report generation. Kudos to everyone involved in DataTalksClub Data Engineering Zoomcamp 2023 and Louisville Open Data portal for public access to the data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Xanthus1/zoomcamp-louisville-data/tree/main\"&gt;GitHub&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;#dezoomcamp&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "13esll5", "is_robot_indexable": true, "report_reasons": null, "author": "Manny-97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13esll5/review_of_louisville_metro_expenditure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13esll5/review_of_louisville_metro_expenditure_data/", "subreddit_subscribers": 105067, "created_utc": 1683823304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow data engineers.\n\nWe're currently poccing out Hudi to support our ML stack, and have been running it on EMR serverless. This went pretty smoothly in staging, however now we've shipped to prod the scale of things seems potentially off. \n\nJust wanted to get some ballpark figures from people doing similar stuff to check we are I'm the right area.\n\nSo our job is as simple as can be, it reads in some parquet and performs an upsert on a Hudi table. We're on the first phase of this project so it just reads and writes everything all the time.\n\nThe thing that's surprised me is the size of cluster needed to process a relatively small amount of data. We've got around 300gb of parquet in one table, and I've had to provision 1200vcpu, 4000gb of memory and 10000gb of storage. This seems insane to me, but anything lower and we get \"No space left on device\" errors. \n\nAny similar experiences, thoughts or info much appreciated!\n\nThanks", "author_fullname": "t2_r9ds5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Emr Serverless and Hudi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqpv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683819060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently poccing out Hudi to support our ML stack, and have been running it on EMR serverless. This went pretty smoothly in staging, however now we&amp;#39;ve shipped to prod the scale of things seems potentially off. &lt;/p&gt;\n\n&lt;p&gt;Just wanted to get some ballpark figures from people doing similar stuff to check we are I&amp;#39;m the right area.&lt;/p&gt;\n\n&lt;p&gt;So our job is as simple as can be, it reads in some parquet and performs an upsert on a Hudi table. We&amp;#39;re on the first phase of this project so it just reads and writes everything all the time.&lt;/p&gt;\n\n&lt;p&gt;The thing that&amp;#39;s surprised me is the size of cluster needed to process a relatively small amount of data. We&amp;#39;ve got around 300gb of parquet in one table, and I&amp;#39;ve had to provision 1200vcpu, 4000gb of memory and 10000gb of storage. This seems insane to me, but anything lower and we get &amp;quot;No space left on device&amp;quot; errors. &lt;/p&gt;\n\n&lt;p&gt;Any similar experiences, thoughts or info much appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13eqpv5", "is_robot_indexable": true, "report_reasons": null, "author": "hazza192837465", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqpv5/emr_serverless_and_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqpv5/emr_serverless_and_hudi/", "subreddit_subscribers": 105067, "created_utc": 1683819060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Hands-On Introduction to Data Engineering with dbt and Teradata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqffy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LMVmd7Ix2INWl_JcrbplZhqqz4j9q3T-SugUEQKSB9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683818433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/gitconnected/a-hands-on-introduction-to-data-engineering-with-dbt-and-teradata-f8d2a282d4de", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x-4ZxdVsFFqGiUgHP1KvF038IhIfbbC7eHiiUsOf27Y.jpg?auto=webp&amp;v=enabled&amp;s=1554820b1f1e3917b88eeea978326b63383a53a5", "width": 704, "height": 342}, "resolutions": [{"url": "https://external-preview.redd.it/x-4ZxdVsFFqGiUgHP1KvF038IhIfbbC7eHiiUsOf27Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eed6ab180c5ea5f8978d64a611be379cd8107ae9", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/x-4ZxdVsFFqGiUgHP1KvF038IhIfbbC7eHiiUsOf27Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af86eb83d3740db773c926d8be363073ffe7505d", "width": 216, "height": 104}, {"url": "https://external-preview.redd.it/x-4ZxdVsFFqGiUgHP1KvF038IhIfbbC7eHiiUsOf27Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b9dd07520f0da10b1bee4cea7e1883f3196abac", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/x-4ZxdVsFFqGiUgHP1KvF038IhIfbbC7eHiiUsOf27Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baa02e48dcb50b4d5da6f3f6abbb4c5b3908a627", "width": 640, "height": 310}], "variants": {}, "id": "_ISAm5C6LxEQ_Js1bUssCh53mtjbA75r4ktUbMOc7hU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13eqffy", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqffy/a_handson_introduction_to_data_engineering_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/gitconnected/a-hands-on-introduction-to-data-engineering-with-dbt-and-teradata-f8d2a282d4de", "subreddit_subscribers": 105067, "created_utc": 1683818433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am researching the concept of how viable is sql for stream processing. I know platforms like flink allow java / python for stream processing but platform\u2019s like decodable gives sql for stream processing. \n\nAny thoughts on sql for stream processes &amp; data pipelines? TIA.", "author_fullname": "t2_ncy21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do u use decodable platform ? Or sql for streaming for data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13emmjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683809759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am researching the concept of how viable is sql for stream processing. I know platforms like flink allow java / python for stream processing but platform\u2019s like decodable gives sql for stream processing. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts on sql for stream processes &amp;amp; data pipelines? TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13emmjd", "is_robot_indexable": true, "report_reasons": null, "author": "nandyk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13emmjd/do_u_use_decodable_platform_or_sql_for_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13emmjd/do_u_use_decodable_platform_or_sql_for_streaming/", "subreddit_subscribers": 105067, "created_utc": 1683809759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nWe are building a job portal. For the MVP, we used airtable to connect with webflow and showcase a limited number of jobs.\n\nNow as we want to create a scalable database and pipeline for this, we have designed a flow for my ETL, where we are thinking of making use of Airtable's free version for LIVE jobs on the portal, as each base can have up to 1200 records, google sheets as a data warehouse to store all the extracted job IDs and expired 'required' jobs details.\n\nIMO, Making use of these tools will reduce the cost of database and data warehousing at the start of this journey. The major cost will come from hosting the server, running CRON jobs, and website hosting.\n\nThis is just our first draft, I'm open to changing things around as well.\n\nI have uploaded the image of the design and also added a link for excalidraw.\n\nAny feedback is appreciated! Thank you!\n\n[Excalidraw](https://excalidraw.com/#json=iHpRnQdJdo1Rnx9fH2GUc,H1YS7J1YDBbVl-j_TltZdQ)\n\n[Design](https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066)", "author_fullname": "t2_w4mta741", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need feedback on my Job portal data design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"abgo69agk6za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 30, "x": 108, "u": "https://preview.redd.it/abgo69agk6za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31d15a68a6b06d23986246d3695e63db8ad1616c"}, {"y": 61, "x": 216, "u": "https://preview.redd.it/abgo69agk6za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48826468eef0e462026c5080ff1028176804c30a"}, {"y": 90, "x": 320, "u": "https://preview.redd.it/abgo69agk6za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e08b1fc4431ea25a18fd887c5f94d151c358e24"}, {"y": 181, "x": 640, "u": "https://preview.redd.it/abgo69agk6za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4702ab3a8bf086b3a33560efce3c0ea406e1014"}, {"y": 272, "x": 960, "u": "https://preview.redd.it/abgo69agk6za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3e6ec9acf744f44a9e0f2964a41cd176b8bfc89"}, {"y": 307, "x": 1080, "u": "https://preview.redd.it/abgo69agk6za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7edd803edf342ac95a3ea7f7a6241c82ded7eacc"}], "s": {"y": 1489, "x": 5237, "u": "https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066"}, "id": "abgo69agk6za1"}}, "name": "t3_13ejhyz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RFe7lKONXGm5gHanEKf5xwe3R5oWQ-tMm5nqvMIEU04.jpg", "edited": 1683807712.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683801587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;We are building a job portal. For the MVP, we used airtable to connect with webflow and showcase a limited number of jobs.&lt;/p&gt;\n\n&lt;p&gt;Now as we want to create a scalable database and pipeline for this, we have designed a flow for my ETL, where we are thinking of making use of Airtable&amp;#39;s free version for LIVE jobs on the portal, as each base can have up to 1200 records, google sheets as a data warehouse to store all the extracted job IDs and expired &amp;#39;required&amp;#39; jobs details.&lt;/p&gt;\n\n&lt;p&gt;IMO, Making use of these tools will reduce the cost of database and data warehousing at the start of this journey. The major cost will come from hosting the server, running CRON jobs, and website hosting.&lt;/p&gt;\n\n&lt;p&gt;This is just our first draft, I&amp;#39;m open to changing things around as well.&lt;/p&gt;\n\n&lt;p&gt;I have uploaded the image of the design and also added a link for excalidraw.&lt;/p&gt;\n\n&lt;p&gt;Any feedback is appreciated! Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://excalidraw.com/#json=iHpRnQdJdo1Rnx9fH2GUc,H1YS7J1YDBbVl-j_TltZdQ\"&gt;Excalidraw&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066\"&gt;Design&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?auto=webp&amp;v=enabled&amp;s=4cb9a0b6a3c8009039410ca42972373ebe4befe1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37964420873f7e84e3f5d8604525926b3d4590f3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a39df796a0f0269b29d71df78b0243902aa390f4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71e56794186e08b61e6d091b6bd715ae0541cf11", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dd9bf8a74e0aad8c0bdc88192e88a1c3647957f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c59c5b3ccf4f9d8081c9acdf857b0a8edef344b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a64b85280885079bf70f1262c03a40cb3b6b0bd4", "width": 1080, "height": 567}], "variants": {}, "id": "eKi-lMrkzQ0Tkft-A4LwK4MR73Yf1HwofRQsC3tBE4w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ejhyz", "is_robot_indexable": true, "report_reasons": null, "author": "Ketonium10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ejhyz/need_feedback_on_my_job_portal_data_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ejhyz/need_feedback_on_my_job_portal_data_design/", "subreddit_subscribers": 105067, "created_utc": 1683801587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am encountering the follow issue: \n\nThe spark job gets launched as usual and proceeds to readStream. While reading the input files, the executor gets removed, yarn top command shows 0G MEM and VCORES usage and the job pauses for some time. Once the gap period is over, another executor gets launched and the job proceeds to completion like nothing happened. There is no error or warning thrown. \n\nWhat could be the reason and how do I fix this? Which properties should I keep an eye on?", "author_fullname": "t2_t9iw9tl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark - Idle Time During Execution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f45n8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683848595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am encountering the follow issue: &lt;/p&gt;\n\n&lt;p&gt;The spark job gets launched as usual and proceeds to readStream. While reading the input files, the executor gets removed, yarn top command shows 0G MEM and VCORES usage and the job pauses for some time. Once the gap period is over, another executor gets launched and the job proceeds to completion like nothing happened. There is no error or warning thrown. &lt;/p&gt;\n\n&lt;p&gt;What could be the reason and how do I fix this? Which properties should I keep an eye on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13f45n8", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-End4310", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f45n8/spark_idle_time_during_execution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f45n8/spark_idle_time_during_execution/", "subreddit_subscribers": 105067, "created_utc": 1683848595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6io23nxgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "who's paying attention to this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_13f3w00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TS18MUpWfNe_MbP-DSGpvtdvrDpYkTgTFDl04aGLv64.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683847944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9a3dc8dgwbza1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?auto=webp&amp;v=enabled&amp;s=a4402306f26359994bda47d38f4d60d07d5d3bd6", "width": 1080, "height": 796}, "resolutions": [{"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=933473dc01be6a3ec4ffc16346934c4f1f041b2d", "width": 108, "height": 79}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=340335faf1b78e7ed71e43dc29f6f1d36888b3d4", "width": 216, "height": 159}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51e305e9a7583e84d9f1a0b368028dc88a445e7b", "width": 320, "height": 235}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef265961efae73a011ee62836b72ed6d370022c6", "width": 640, "height": 471}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1b47a8c91d09fac96aaabfa8b60566a82cb0d02", "width": 960, "height": 707}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec9b3967e9f8714ce248f4c18abf8a1b9e092032", "width": 1080, "height": 796}], "variants": {}, "id": "IeajqaI8vd-voqF1OeyvqngbCV3v2YtPRCYrdHLjnfQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13f3w00", "is_robot_indexable": true, "report_reasons": null, "author": "ricardokj", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f3w00/whos_paying_attention_to_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9a3dc8dgwbza1.png", "subreddit_subscribers": 105067, "created_utc": 1683847944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Google DataStream seems like the perfect solution for us - CDC from RDS Postgres to BigQuery. In testing, when we set lag to 0 seconds datasource synced usually in a few seconds, max a couple of minutes. Wished it could be a bit more deterministic, but still we'd love that.   \nThe problem is that we have a lot of tables in postgres that don't have a primary key and which we would rather not have a primary key (HABTM tables/Rails - primary keys are not supported). There is a workaround for these tables- create a replication identity. We created an identity \"full\". However, this table seemed to not sync at all.   \nHas anyone run into a similar issue? Or did you try a different setup that worked?", "author_fullname": "t2_7p7erpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you got Google DataStream to sync tables from Postgres without a primary key?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ezfte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683837934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google DataStream seems like the perfect solution for us - CDC from RDS Postgres to BigQuery. In testing, when we set lag to 0 seconds datasource synced usually in a few seconds, max a couple of minutes. Wished it could be a bit more deterministic, but still we&amp;#39;d love that.&lt;br/&gt;\nThe problem is that we have a lot of tables in postgres that don&amp;#39;t have a primary key and which we would rather not have a primary key (HABTM tables/Rails - primary keys are not supported). There is a workaround for these tables- create a replication identity. We created an identity &amp;quot;full&amp;quot;. However, this table seemed to not sync at all.&lt;br/&gt;\nHas anyone run into a similar issue? Or did you try a different setup that worked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ezfte", "is_robot_indexable": true, "report_reasons": null, "author": "homechefdit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ezfte/have_you_got_google_datastream_to_sync_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ezfte/have_you_got_google_datastream_to_sync_tables/", "subreddit_subscribers": 105067, "created_utc": 1683837934.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}