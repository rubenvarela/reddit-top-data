{"kind": "Listing", "data": {"after": "t3_13ezfte", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dlyjh58o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I didn\u2019t know you guys were paid THIS well", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13f4sbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "ups": 260, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 260, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-W5lW4G_sDXu5zmHbDU9uXeKZg22lfWQ5kyLCGW4zW4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683850188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3q8sosk43cza1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?auto=webp&amp;v=enabled&amp;s=e7c1108dac9af74b52e642937d3eaa09d1c2da16", "width": 828, "height": 829}, "resolutions": [{"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16581887d7722dcceef350d0e855111522cf4af1", "width": 108, "height": 108}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd160c1e59e0756894e6ef675488709405bae814", "width": 216, "height": 216}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0f0c6c600942d1c6e54507e86fffc22a1f75447", "width": 320, "height": 320}, {"url": "https://preview.redd.it/3q8sosk43cza1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=491017ed19445e1d73880bf6c09753df23c95e95", "width": 640, "height": 640}], "variants": {}, "id": "ztMXvGtUoH3Ex2Nl0cgDrNsUylSHVd8fjGHBfp7e5m0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13f4sbf", "is_robot_indexable": true, "report_reasons": null, "author": "BeneficialTitle9042", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13f4sbf/i_didnt_know_you_guys_were_paid_this_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3q8sosk43cza1.jpg", "subreddit_subscribers": 105217, "created_utc": 1683850188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I try to be super open and receptive to feedback if someone has a better  more efficient way of doing things. I take notes obsessively or ask plenty questions.\n\nWhen we do a code review someone who more junior than me corrects my code or says it can be improved somewhere. \n\nIt isn\u2019t overly pedantic corrections that junior people get into. However I do feel that little bit of insecurity that you aren\u2019t good enough technically or that you lose respect if don\u2019t shine in your logic.  \n\nYou can\u2019t be a chef and not know how to cook a meal.\n\nOne thing I find, is it lights a bit of fire in your belly. If you\u2019re expected to be a team lead you cannot be bad technically. It pushed self development.\n\nHow do you manage junior correcting you without coming across as overly submissive and still have their respect?", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle junior people who are better than you in terms of technical ability?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fmd1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683900743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I try to be super open and receptive to feedback if someone has a better  more efficient way of doing things. I take notes obsessively or ask plenty questions.&lt;/p&gt;\n\n&lt;p&gt;When we do a code review someone who more junior than me corrects my code or says it can be improved somewhere. &lt;/p&gt;\n\n&lt;p&gt;It isn\u2019t overly pedantic corrections that junior people get into. However I do feel that little bit of insecurity that you aren\u2019t good enough technically or that you lose respect if don\u2019t shine in your logic.  &lt;/p&gt;\n\n&lt;p&gt;You can\u2019t be a chef and not know how to cook a meal.&lt;/p&gt;\n\n&lt;p&gt;One thing I find, is it lights a bit of fire in your belly. If you\u2019re expected to be a team lead you cannot be bad technically. It pushed self development.&lt;/p&gt;\n\n&lt;p&gt;How do you manage junior correcting you without coming across as overly submissive and still have their respect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fmd1h", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fmd1h/how_do_you_handle_junior_people_who_are_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fmd1h/how_do_you_handle_junior_people_who_are_better/", "subreddit_subscribers": 105217, "created_utc": 1683900743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_74fdrilk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyJaws: A Pythonic Way to Define Databricks Jobs and Workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13fkeiq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BEhtB9frO_f1sYMEHGectzV0Y4zJW5pSI39sPgrw1-g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683896148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/rafaelpierre/pyjaws", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?auto=webp&amp;v=enabled&amp;s=6db90fee6eb5be2fc6fef0d7d08e3b69794415e4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e8cebc95fa46eeb9e4889c8f6310c19e1416c63", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=766549d2b6f8665d96adc390a4d116c4abe4565b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f4bdbe56d98e63e181e386afda6f13959a59170", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e945512f211b3a91368cf702c813e18e4b0f31c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0eeb738575673955a6592c91dfb3108f28dd3bc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CewLNmO5vcAs3at91Mb0ceuJXpHt7EEYUie_7O7Nd0k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a8d9c4d0e07136283a555d4861c63da99c98fdb", "width": 1080, "height": 540}], "variants": {}, "id": "aSY4vZzTkp5Y6EGwhKcdQYwqIq63YXlzWGq5M4zTVRc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13fkeiq", "is_robot_indexable": true, "report_reasons": null, "author": "j0selit0342", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fkeiq/pyjaws_a_pythonic_way_to_define_databricks_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/rafaelpierre/pyjaws", "subreddit_subscribers": 105217, "created_utc": 1683896148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[My attempt at an 'explain it to an 8 year old'](https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56)\n\n\u00a0The 2004 flick, \u201850 First Dates\u2019 with Adam Sandler and Drew Barrymore can help explain change data capture and Apache Kafka.\n\nIn the movie, a single Drew Barrymore suffers from severe amnesia after an accident and is unable to retain net new memories.\n\nOu lovestruck potential suitor, Adam Sandler, doesn\u2019t lose hope though. Instead, he creates a video tape ([https://www.youtube.com/watch?v=XP8nQGv4eKI](https://www.youtube.com/watch?v=XP8nQGv4eKI)) that is to be watched each morning when she wakes up.\n\nThe tape (and her journal) linearly summarizes her life, the news, and the major milestones. He adds on to the end of tape each day so she is always up to the current reality.\n\nWhere it meets Kafka &amp; CDC:\n\nAppending the new video of each new date to the end of the videotape is the essence of Apache Kafka's log design as well as change data capture...\n\n\\*Instead of re-creating the tape from scratch each day, which would be very time consuming and equivalent to a nightly full database export, Adam is just appending onto the end of the tape\n\n\\*The videos are added in 'exact-order' they occurred\n\n\\*When Drew Barrymore starts at knowing nothing each day, the video tape is able to backfill her knowledge as if she was a data application being spun up and we're replaying the Kafka log\n\n\\*The tape is never destroyed so the video-tape / log can shared with other should others need to remember\n\nReasonable comparison?", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How the movie '50 first date' explains Change Data Capture design (&amp; Apache Kafka)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"r0dtwu0i4bza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f17e5ba095b155525217ae680f0ef369f0a3e03f"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d55594742a0fa0b0acb74ca848247dbb29b7bab2"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f8212e15a9064054496609535f27b306d10df8"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eaa0a85935837dd3230901b94c43a7c32ae47a"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e0e5e54351831c6c55d0293e47d835b16bc744a"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c916f1bb1c1a8a133bcbcc303f95499c291247"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56"}, "id": "r0dtwu0i4bza1"}}, "name": "t3_13f7ceh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "50 First Dates: Lucy Watches Henry's Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "author_name": "Scene City", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XP8nQGv4eKI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SceneCityOfficial"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13f7ceh", "height": 200}, "link_flair_text": "Meme", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GqiWmpmaBCezjhJBrgog70R4yQ2rj0kNHapzhUtXqt8.jpg", "edited": 1683889093.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683856967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r0dtwu0i4bza1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=30f0f512b16c86dec9935d261bb76c31c1e36d56\"&gt;My attempt at an &amp;#39;explain it to an 8 year old&amp;#39;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\u00a0The 2004 flick, \u201850 First Dates\u2019 with Adam Sandler and Drew Barrymore can help explain change data capture and Apache Kafka.&lt;/p&gt;\n\n&lt;p&gt;In the movie, a single Drew Barrymore suffers from severe amnesia after an accident and is unable to retain net new memories.&lt;/p&gt;\n\n&lt;p&gt;Ou lovestruck potential suitor, Adam Sandler, doesn\u2019t lose hope though. Instead, he creates a video tape (&lt;a href=\"https://www.youtube.com/watch?v=XP8nQGv4eKI\"&gt;https://www.youtube.com/watch?v=XP8nQGv4eKI&lt;/a&gt;) that is to be watched each morning when she wakes up.&lt;/p&gt;\n\n&lt;p&gt;The tape (and her journal) linearly summarizes her life, the news, and the major milestones. He adds on to the end of tape each day so she is always up to the current reality.&lt;/p&gt;\n\n&lt;p&gt;Where it meets Kafka &amp;amp; CDC:&lt;/p&gt;\n\n&lt;p&gt;Appending the new video of each new date to the end of the videotape is the essence of Apache Kafka&amp;#39;s log design as well as change data capture...&lt;/p&gt;\n\n&lt;p&gt;*Instead of re-creating the tape from scratch each day, which would be very time consuming and equivalent to a nightly full database export, Adam is just appending onto the end of the tape&lt;/p&gt;\n\n&lt;p&gt;*The videos are added in &amp;#39;exact-order&amp;#39; they occurred&lt;/p&gt;\n\n&lt;p&gt;*When Drew Barrymore starts at knowing nothing each day, the video tape is able to backfill her knowledge as if she was a data application being spun up and we&amp;#39;re replaying the Kafka log&lt;/p&gt;\n\n&lt;p&gt;*The tape is never destroyed so the video-tape / log can shared with other should others need to remember&lt;/p&gt;\n\n&lt;p&gt;Reasonable comparison?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?auto=webp&amp;v=enabled&amp;s=61474ddb54fb6b298cea112352e2c982667350fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712c8362b3e8c76407e3bb2c756ec8e33a6abfd9", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fef451d455ca0b092a1d7cec35116dbf9b6234ff", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/20FVCnYZA_FOW2COQNCEZzijTbuiZhaKfMJXzs8d0ZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=559543ba516df33ab2117a718e9357e791c8272b", "width": 320, "height": 240}], "variants": {}, "id": "VLXne7b-n5l2YV6V6ATWURluoHVEltN7IFxkZSBcATk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13f7ceh", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f7ceh/how_the_movie_50_first_date_explains_change_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f7ceh/how_the_movie_50_first_date_explains_change_data/", "subreddit_subscribers": 105217, "created_utc": 1683856967.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "50 First Dates: Lucy Watches Henry's Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/XP8nQGv4eKI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"50 First Dates: Lucy Watches Henry&amp;#39;s Tape (DREW BARRYMORE, ADAM SANDLER HD CLIP)\"&gt;&lt;/iframe&gt;", "author_name": "Scene City", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XP8nQGv4eKI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SceneCityOfficial"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6io23nxgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "who's paying attention to this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_13f3w00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TS18MUpWfNe_MbP-DSGpvtdvrDpYkTgTFDl04aGLv64.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683847944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9a3dc8dgwbza1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?auto=webp&amp;v=enabled&amp;s=a4402306f26359994bda47d38f4d60d07d5d3bd6", "width": 1080, "height": 796}, "resolutions": [{"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=933473dc01be6a3ec4ffc16346934c4f1f041b2d", "width": 108, "height": 79}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=340335faf1b78e7ed71e43dc29f6f1d36888b3d4", "width": 216, "height": 159}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51e305e9a7583e84d9f1a0b368028dc88a445e7b", "width": 320, "height": 235}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef265961efae73a011ee62836b72ed6d370022c6", "width": 640, "height": 471}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1b47a8c91d09fac96aaabfa8b60566a82cb0d02", "width": 960, "height": 707}, {"url": "https://preview.redd.it/9a3dc8dgwbza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec9b3967e9f8714ce248f4c18abf8a1b9e092032", "width": 1080, "height": 796}], "variants": {}, "id": "IeajqaI8vd-voqF1OeyvqngbCV3v2YtPRCYrdHLjnfQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13f3w00", "is_robot_indexable": true, "report_reasons": null, "author": "ricardokj", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f3w00/whos_paying_attention_to_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9a3dc8dgwbza1.png", "subreddit_subscribers": 105217, "created_utc": 1683847944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've only been using trino for about a month now in a practical sense but I have really grown to love it. It's a really nice way of joining datasets across databases. \n\nI've been pulling data outta parquet files in s3 (hive/glue) then joining them with a posted instance. Works wonderfully. It's been working so well that I even got the green light from my boss to start using it in production. \n\nI don't see many folks use it here, which makes me wonder what obvious flaw in missing. Would anyone care to help me understand what it's barriers to adoption have been?", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experiences with trino? What am I missing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13ftlcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683917336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve only been using trino for about a month now in a practical sense but I have really grown to love it. It&amp;#39;s a really nice way of joining datasets across databases. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pulling data outta parquet files in s3 (hive/glue) then joining them with a posted instance. Works wonderfully. It&amp;#39;s been working so well that I even got the green light from my boss to start using it in production. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see many folks use it here, which makes me wonder what obvious flaw in missing. Would anyone care to help me understand what it&amp;#39;s barriers to adoption have been?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ftlcp", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ftlcp/experiences_with_trino_what_am_i_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ftlcp/experiences_with_trino_what_am_i_missing/", "subreddit_subscribers": 105217, "created_utc": 1683917336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for books that can help with learning database internals. Specifically the core components that makes up a database and how to implements.\n\nThe book should probably cover the query engine parts (sql parsing, query plans etc) and the persistence part.", "author_fullname": "t2_3euic3tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation on Database internals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13foyk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683906878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for books that can help with learning database internals. Specifically the core components that makes up a database and how to implements.&lt;/p&gt;\n\n&lt;p&gt;The book should probably cover the query engine parts (sql parsing, query plans etc) and the persistence part.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13foyk5", "is_robot_indexable": true, "report_reasons": null, "author": "finlaydotweber", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13foyk5/book_recommendation_on_database_internals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13foyk5/book_recommendation_on_database_internals/", "subreddit_subscribers": 105217, "created_utc": 1683906878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for some good Data Quality tool used in your (or ex) organization. Bonus points, if you tell me how its used to improve the data quality with the existing data.", "author_fullname": "t2_q6tghhmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggest some Data Quality tool used in your Org.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fl20s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683897715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some good Data Quality tool used in your (or ex) organization. Bonus points, if you tell me how its used to improve the data quality with the existing data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fl20s", "is_robot_indexable": true, "report_reasons": null, "author": "jimmy3579", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fl20s/suggest_some_data_quality_tool_used_in_your_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fl20s/suggest_some_data_quality_tool_used_in_your_org/", "subreddit_subscribers": 105217, "created_utc": 1683897715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since April I applied for like 1-200 job postings, had 20+ interview rounds, and got to the final interview stage for three companies. Then I was rejected from all of them.\n\nAll of them moved very fast from phone screening to the final stage (one interview to another next day)\u2026 then silence. No response to my follow-up request. Two weeks later I get a rejection letter.\n\nI get a fairly good amount of recruiter calls so I assumed my resume is fine even if not perfect. I am not very confident with my soft skill but I at least keep it very polite, just not extroverted. All those final interviews also felt like it went pretty well\u2026 (they felt like an actual conversation, went over the scheduled time talking about a bunch of extra stuff, and etc)\n\nI could keep revisiting my resume and practice coding questions, but also I am just lost on what other things to improve. What are the common reasons to be rejected from the final interviews? I would really appreciate some input from hiring manager\u2019s perspective.", "author_fullname": "t2_bga13dih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep failing at the final interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f2moo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683844935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since April I applied for like 1-200 job postings, had 20+ interview rounds, and got to the final interview stage for three companies. Then I was rejected from all of them.&lt;/p&gt;\n\n&lt;p&gt;All of them moved very fast from phone screening to the final stage (one interview to another next day)\u2026 then silence. No response to my follow-up request. Two weeks later I get a rejection letter.&lt;/p&gt;\n\n&lt;p&gt;I get a fairly good amount of recruiter calls so I assumed my resume is fine even if not perfect. I am not very confident with my soft skill but I at least keep it very polite, just not extroverted. All those final interviews also felt like it went pretty well\u2026 (they felt like an actual conversation, went over the scheduled time talking about a bunch of extra stuff, and etc)&lt;/p&gt;\n\n&lt;p&gt;I could keep revisiting my resume and practice coding questions, but also I am just lost on what other things to improve. What are the common reasons to be rejected from the final interviews? I would really appreciate some input from hiring manager\u2019s perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13f2moo", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Departure_8097", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f2moo/keep_failing_at_the_final_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f2moo/keep_failing_at_the_final_interview/", "subreddit_subscribers": 105217, "created_utc": 1683844935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26](https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI-Powered Accommodation Search: Harnessing the Power of Hadoop, MongoDB, Spark, GPT-3, React, and Flask", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v6n37u9r7fza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1c26591cf51b4899063a4de4e1cf4b840a736a5"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee43fa19a842bcae6fe04781993c81a1b272b249"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb13942a173c081a9b073041d17c3e4414ce988e"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cec9f8763636cde8dd4dc1ec9c60aabeca45c538"}, {"y": 704, "x": 960, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e868a51316e71aea5b378773510e791f30ed04c6"}, {"y": 792, "x": 1080, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f0bccc366557812792c49bd33a830bda20b1b8c"}], "s": {"y": 1467, "x": 2000, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155"}, "id": "v6n37u9r7fza1"}}, "name": "t3_13folyf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PY6rjNfYT2Nc_9EMr7ennoEXXscCEW2aZ7NF7zXYfZI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683906076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26\"&gt;https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155\"&gt;https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?auto=webp&amp;v=enabled&amp;s=b7d104e02301de6fdb1116e8ca11edf5927b1a31", "width": 1200, "height": 880}, "resolutions": [{"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58ad0ac5dd4dbef4e371d78585bc84f701a35919", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caea697455dcd7239ae98c0bd0fdb20a06bf8eb4", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=979a805dcd52927812fac9b54ed10767836551ac", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f266f195aa451fd20beca5af9a54e84bc793d701", "width": 640, "height": 469}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf7fa9c1efde6971bd29aba5a04e7843f84e7745", "width": 960, "height": 704}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=deefa11b543ad95610e1b55ca055ad6196473259", "width": 1080, "height": 792}], "variants": {}, "id": "iyM2CVIuoHRTdQ0EUrh1AW7Wm9uKzAJrNHLmek4I76c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "13folyf", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13folyf/aipowered_accommodation_search_harnessing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13folyf/aipowered_accommodation_search_harnessing_the/", "subreddit_subscribers": 105217, "created_utc": 1683906076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI'm currently in the process of researching different observability platforms for my organization, and I've come across Coralogix. I'm curious to know if anyone here has any experience with Coralogix and how it compares to Datadog.\n\nSpecifically, I'm interested in hearing from anyone who has implemented Coralogix in their organization. What were the pros and cons of using Coralogix? How did it compare to other observability platforms you've used, such as Datadog?\n\nI'd appreciate any insights you may have. Thanks in advance for your help!", "author_fullname": "t2_2nhoc35w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have experience with Coralogix as an observability platform? How does it compare to Datadog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fgst4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683886255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in the process of researching different observability platforms for my organization, and I&amp;#39;ve come across Coralogix. I&amp;#39;m curious to know if anyone here has any experience with Coralogix and how it compares to Datadog.&lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m interested in hearing from anyone who has implemented Coralogix in their organization. What were the pros and cons of using Coralogix? How did it compare to other observability platforms you&amp;#39;ve used, such as Datadog?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights you may have. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fgst4", "is_robot_indexable": true, "report_reasons": null, "author": "UpperEfficiency", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fgst4/anyone_have_experience_with_coralogix_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fgst4/anyone_have_experience_with_coralogix_as_an/", "subreddit_subscribers": 105217, "created_utc": 1683886255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First off, I'm not a data engineer right now, I'm trying to learn. \n\nI've gotten myself involved in a DE project. I can't go much into the specifics, but let's just say it's a side project of someone I know, who invited me on to help them, and help me transition into DE (which I had expressed interest in). The basic goal of the project at the moment is to pull data from an API and have a website frontend to explore the data. The problem I'm having is the tech stack seems possibly overengineered, or at least beyond me -- there are so many pieces that I don't know how to attack it. And in part because it's just a side project of someone who's years ahead of me in this game, the documentation isn't particularly exhaustive, certainly not educational at any rate.\n\nThe number of technologies and how they all fit together is just a bit overwhelming. There's terraform, kustomize, argoCD, and I'm supposed to develop locally with minikube (and docker, I guess?). There's a postgres db somewhere in the mix, and I've just been asked to review a PR which introduces a SQLite db managed with alembic, which I've no idea what the relationship between that and the postgres db is (my guess is as a backup, since the main sqlite db file is named \"postgres\" (a bit confusing, no?!)). \n\nMy background has involved a bit of data science, and I've made simple things like shiny apps. I feel like we could do what this project is trying to do with a much slimmer stack and the aim is to make it somehow super scalable from the get-go, which is maybe fine, but I'm probably in over my head. Neither of us are anywhere near able to be fulltime on this so I think it makes this a tougher nut to crack. \n\nI'm not sure what to do. This person is my only real connection in the field, so I don't want to burn it, but I don't feel like I can make progress with it as is.", "author_fullname": "t2_42aau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost after being dumped in (what seems like) the deep end", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ff5db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683880789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off, I&amp;#39;m not a data engineer right now, I&amp;#39;m trying to learn. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve gotten myself involved in a DE project. I can&amp;#39;t go much into the specifics, but let&amp;#39;s just say it&amp;#39;s a side project of someone I know, who invited me on to help them, and help me transition into DE (which I had expressed interest in). The basic goal of the project at the moment is to pull data from an API and have a website frontend to explore the data. The problem I&amp;#39;m having is the tech stack seems possibly overengineered, or at least beyond me -- there are so many pieces that I don&amp;#39;t know how to attack it. And in part because it&amp;#39;s just a side project of someone who&amp;#39;s years ahead of me in this game, the documentation isn&amp;#39;t particularly exhaustive, certainly not educational at any rate.&lt;/p&gt;\n\n&lt;p&gt;The number of technologies and how they all fit together is just a bit overwhelming. There&amp;#39;s terraform, kustomize, argoCD, and I&amp;#39;m supposed to develop locally with minikube (and docker, I guess?). There&amp;#39;s a postgres db somewhere in the mix, and I&amp;#39;ve just been asked to review a PR which introduces a SQLite db managed with alembic, which I&amp;#39;ve no idea what the relationship between that and the postgres db is (my guess is as a backup, since the main sqlite db file is named &amp;quot;postgres&amp;quot; (a bit confusing, no?!)). &lt;/p&gt;\n\n&lt;p&gt;My background has involved a bit of data science, and I&amp;#39;ve made simple things like shiny apps. I feel like we could do what this project is trying to do with a much slimmer stack and the aim is to make it somehow super scalable from the get-go, which is maybe fine, but I&amp;#39;m probably in over my head. Neither of us are anywhere near able to be fulltime on this so I think it makes this a tougher nut to crack. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what to do. This person is my only real connection in the field, so I don&amp;#39;t want to burn it, but I don&amp;#39;t feel like I can make progress with it as is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ff5db", "is_robot_indexable": true, "report_reasons": null, "author": "omgpop", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ff5db/lost_after_being_dumped_in_what_seems_like_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ff5db/lost_after_being_dumped_in_what_seems_like_the/", "subreddit_subscribers": 105217, "created_utc": 1683880789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ray is a framework for scaling Python applications. Ray allows you to execute the same Python program that you would run on your laptop on a cluster of computers with minimum effort. All you need is to tell Ray what part of your program needs to be scalable by decorating your Python functions and classes, and Ray takes care of the rest for you. Ray has been used by several companies including OpenAI for building ChatGPT.\n\n&amp;#x200B;\n\n[https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html](https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html)", "author_fullname": "t2_2rtceaie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ray: A Framework for Scaling Python Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f6a7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683854128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ray is a framework for scaling Python applications. Ray allows you to execute the same Python program that you would run on your laptop on a cluster of computers with minimum effort. All you need is to tell Ray what part of your program needs to be scalable by decorating your Python functions and classes, and Ray takes care of the rest for you. Ray has been used by several companies including OpenAI for building ChatGPT.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html\"&gt;https://www.mydistributed.systems/2023/05/ray-framework-for-scaling-python.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?auto=webp&amp;v=enabled&amp;s=7f497d5be22e61ed476b9b368debd4ded7eea78e", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f000562da8ae6397a4a2d80935c6db51b527b9ab", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad5d8c762eb6c2c0dbfb39daf60942051c08759a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=511dd8c203aacf45ae98a7981e735942d4541558", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=186a7dfa6a2fb7e809c070862f216a11490ae02a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1b3c3c3cf4a712462710af620147dc0887061c3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/caC79WyhNatrinvX8pI3iCj--ev8V5EZ0FV9z7_GiSk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9b0c3964c603ee14e260feb0953f26e06b9d9c4", "width": 1080, "height": 567}], "variants": {}, "id": "WyQs-qPvmyGCPPZ6sSCmms8ElLefyR3S3MwmCEA4-Gw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13f6a7c", "is_robot_indexable": true, "report_reasons": null, "author": "roohitavaf", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f6a7c/ray_a_framework_for_scaling_python_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f6a7c/ray_a_framework_for_scaling_python_applications/", "subreddit_subscribers": 105217, "created_utc": 1683854128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Spark is written in Scala. There is huge benefit in knowing Spark as a Data Engineer. But what about Scala? Is it widely used?\n\nOr is that like saying Python in written in C and so Engineers should know C?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On the premise of there being no stupid questions\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fevv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683879801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Spark is written in Scala. There is huge benefit in knowing Spark as a Data Engineer. But what about Scala? Is it widely used?&lt;/p&gt;\n\n&lt;p&gt;Or is that like saying Python in written in C and so Engineers should know C?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fevv1", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fevv1/on_the_premise_of_there_being_no_stupid_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fevv1/on_the_premise_of_there_being_no_stupid_questions/", "subreddit_subscribers": 105217, "created_utc": 1683879801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there anyone here trying Open Data Studio? Could you give some opinions about it?", "author_fullname": "t2_wd590jm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Data Studio \u2014 Open Data Studio documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fdit2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683875007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there anyone here trying Open Data Studio? Could you give some opinions about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fdit2", "is_robot_indexable": true, "report_reasons": null, "author": "xuancute", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fdit2/open_data_studio_open_data_studio_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fdit2/open_data_studio_open_data_studio_documentation/", "subreddit_subscribers": 105217, "created_utc": 1683875007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have completed 100 days of python by Angela Yu. I am still struggling on how to upskill python for data engineering. Should I just focus on boto3 and pandas? What makes a data engineer strong in python? Does anyone have advice or courses to take?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13fvcd9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683921504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have completed 100 days of python by Angela Yu. I am still struggling on how to upskill python for data engineering. Should I just focus on boto3 and pandas? What makes a data engineer strong in python? Does anyone have advice or courses to take?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fvcd9", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fvcd9/python_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fvcd9/python_advice/", "subreddit_subscribers": 105217, "created_utc": 1683921504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I already have about 5 years of experience in data engineering and devops, as well as an MS in CS.\n\n\n\n\n\nWith the job market not so great where I am, it seems like it would be worth it gaining valuable experience at my current job while doing Coursera courses in my free time.  My theory is that companies are now being more careful hiring candidates who are an exact match for the job description, instead of hiring engineers from other fields who taught themselves Python and SQL.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are online courses/certificates seen for experienced engineers applying for jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13fv0bk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683920905.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683920696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already have about 5 years of experience in data engineering and devops, as well as an MS in CS.&lt;/p&gt;\n\n&lt;p&gt;With the job market not so great where I am, it seems like it would be worth it gaining valuable experience at my current job while doing Coursera courses in my free time.  My theory is that companies are now being more careful hiring candidates who are an exact match for the job description, instead of hiring engineers from other fields who taught themselves Python and SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fv0bk", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fv0bk/how_are_online_coursescertificates_seen_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fv0bk/how_are_online_coursescertificates_seen_for/", "subreddit_subscribers": 105217, "created_utc": 1683920696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI\u2019m a Marketing Data Engineer. Right now, my company utilizes 3rd party solutions for customer attribution, such as Google Analytics. Recently we\u2019ve had a push to improve completeness and accuracy, and thereby audibility, of our customer attribution data. This drive comes from a huge uplift in the amount of reporting and analytics we\u2019re doing to learn more about our users and where they come from.\n\nMy idea is that we record the ID of the individual ad-click once customers arrive to our website, and then use our server to query the advertising network for data on that click. Data such as country, time, the ad that it belongs to, etc, and it\u2019ll get stored in our database. \n\nHowever, I\u2019m not really sure if something like this should be combined with existing infrastructure, like our reporting database, or if it should be a standalone data source. Our reporting database doesn\u2019t currently use any external sources to augment its data, and we actually reload the entire reporting database daily. So I\u2019m not sure incorporating 3rd party API calls into that is a good idea.\n\nI\u2019d like to know what some existing solutions are elsewhere and hopefully get some ideas rolling for myself. Is a typical relational database fine for this, or perhaps a graph database would be more future-proof if we wanted to expect into some deeper attribution concepts. I\u2019m not sure what the best call is at this stage.\n\nWhat do you do at your company? How do you manage the volume of attribution data as well? Thanks in advance!!", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company process customer attribution data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13fu79o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683918766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a Marketing Data Engineer. Right now, my company utilizes 3rd party solutions for customer attribution, such as Google Analytics. Recently we\u2019ve had a push to improve completeness and accuracy, and thereby audibility, of our customer attribution data. This drive comes from a huge uplift in the amount of reporting and analytics we\u2019re doing to learn more about our users and where they come from.&lt;/p&gt;\n\n&lt;p&gt;My idea is that we record the ID of the individual ad-click once customers arrive to our website, and then use our server to query the advertising network for data on that click. Data such as country, time, the ad that it belongs to, etc, and it\u2019ll get stored in our database. &lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m not really sure if something like this should be combined with existing infrastructure, like our reporting database, or if it should be a standalone data source. Our reporting database doesn\u2019t currently use any external sources to augment its data, and we actually reload the entire reporting database daily. So I\u2019m not sure incorporating 3rd party API calls into that is a good idea.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to know what some existing solutions are elsewhere and hopefully get some ideas rolling for myself. Is a typical relational database fine for this, or perhaps a graph database would be more future-proof if we wanted to expect into some deeper attribution concepts. I\u2019m not sure what the best call is at this stage.&lt;/p&gt;\n\n&lt;p&gt;What do you do at your company? How do you manage the volume of attribution data as well? Thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fu79o", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fu79o/how_does_your_company_process_customer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fu79o/how_does_your_company_process_customer/", "subreddit_subscribers": 105217, "created_utc": 1683918766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently using Airflow to orchestrate some tasks in our data pipeline (such as hitting a remote endpoint to fetch data). My task is a bash command that executes a Python script with lots of parameters (SFTP information, our data warehouse information). This feels like a poor pattern, and I was hoping to get some advice on what a better way of doing this is. Ideally, I'd like a solution that I could run locally as a standalone command, but could also be easily called by Airflow remotely.  \n\n\nTo be clear, I am not hardcoding sensitive information like access credentials as parameters. I fetch them from Airflow's Variable manager.  \n\n\nThank you!", "author_fullname": "t2_l16rampa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a better parameter passing pattern? (Airflow)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fqcbc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683909938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently using Airflow to orchestrate some tasks in our data pipeline (such as hitting a remote endpoint to fetch data). My task is a bash command that executes a Python script with lots of parameters (SFTP information, our data warehouse information). This feels like a poor pattern, and I was hoping to get some advice on what a better way of doing this is. Ideally, I&amp;#39;d like a solution that I could run locally as a standalone command, but could also be easily called by Airflow remotely.  &lt;/p&gt;\n\n&lt;p&gt;To be clear, I am not hardcoding sensitive information like access credentials as parameters. I fetch them from Airflow&amp;#39;s Variable manager.  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fqcbc", "is_robot_indexable": true, "report_reasons": null, "author": "Busy-Pie-4468", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fqcbc/suggestions_for_a_better_parameter_passing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fqcbc/suggestions_for_a_better_parameter_passing/", "subreddit_subscribers": 105217, "created_utc": 1683909938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone has any insight or experience using [Pivot](https://pivotcomputing.io/platform) to manage their DBT instance.  \n\n\nI am a one-man shop, using VS Code to write my code, mainly, and DBT cloud to run jobs on a schedule.  Each work off the same repository.  \n\n\nI'd like to use a more robust scheduler, but don't have the bandwidth to start learning Airflow.  Pivot looks more cost effective, and a good change from the free dbt Cloud offering.  \n\n\nThoughts?  Thanks, in advance, y'all.", "author_fullname": "t2_1ow2e6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Thoughts on Pivot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fpkgd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683908201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone has any insight or experience using &lt;a href=\"https://pivotcomputing.io/platform\"&gt;Pivot&lt;/a&gt; to manage their DBT instance.  &lt;/p&gt;\n\n&lt;p&gt;I am a one-man shop, using VS Code to write my code, mainly, and DBT cloud to run jobs on a schedule.  Each work off the same repository.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to use a more robust scheduler, but don&amp;#39;t have the bandwidth to start learning Airflow.  Pivot looks more cost effective, and a good change from the free dbt Cloud offering.  &lt;/p&gt;\n\n&lt;p&gt;Thoughts?  Thanks, in advance, y&amp;#39;all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?auto=webp&amp;v=enabled&amp;s=9ed9a5a7a7e99641a1e29a48e651f1103dab8e55", "width": 536, "height": 537}, "resolutions": [{"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f636c7dfde8c4e3617150d24ec7d827b99d5883c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c87c0bda2d9e0ff6c2b375c9833139b96432a0c", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb450abb15a673312ef31fca522853976fb6de40", "width": 320, "height": 320}], "variants": {}, "id": "e3zEncRW_tf7BAkQRULi2gaGkk_bcxRhTYI24wwtQjA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Head of BI", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fpkgd", "is_robot_indexable": true, "report_reasons": null, "author": "Cat_Phish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13fpkgd/any_thoughts_on_pivot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fpkgd/any_thoughts_on_pivot/", "subreddit_subscribers": 105217, "created_utc": 1683908201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any experience/recommendations on a greenfield build for a **financial** data warehouse stack? \n\nExample of the high level current process is in the image but basically the scope is to extract data from all billing, payment and operational systems that have financial information, transform them into both P&amp;L facts/dims and Journal Entries to integrate directly into Netsuite. \n\nVolume is over 1M a month in transactions, currently have snowflake with some basic connectors but I'm not married to anything! \n\nhttps://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9", "author_fullname": "t2_vl7599r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial Data Warehouse Stack - Greenfield", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1xfq6wmbqeza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ad90a44e06254f983a02437c202d3f579c55d2b"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7dfc27f5231781976a47021147e9fa047377b10"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2d77a0a658270bf3fe46411a6fa835d4b428137"}, {"y": 298, "x": 640, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5386ef7aec7d776fbf1cb0f5314981ca463cfd05"}, {"y": 447, "x": 960, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db1eb2a94857f2d64ba641eade64a0df8495dc48"}, {"y": 502, "x": 1080, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c664f191e93c907e4ae04fde551270edd55bd08a"}], "s": {"y": 556, "x": 1194, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9"}, "id": "1xfq6wmbqeza1"}}, "name": "t3_13fm7zf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/7khzCnkKqOLoAFzoG-uNWMZQVFlnP_vH4T-FrlGTOE4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683900408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any experience/recommendations on a greenfield build for a &lt;strong&gt;financial&lt;/strong&gt; data warehouse stack? &lt;/p&gt;\n\n&lt;p&gt;Example of the high level current process is in the image but basically the scope is to extract data from all billing, payment and operational systems that have financial information, transform them into both P&amp;amp;L facts/dims and Journal Entries to integrate directly into Netsuite. &lt;/p&gt;\n\n&lt;p&gt;Volume is over 1M a month in transactions, currently have snowflake with some basic connectors but I&amp;#39;m not married to anything! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9\"&gt;https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fm7zf", "is_robot_indexable": true, "report_reasons": null, "author": "Hopeful_Tutor3549", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fm7zf/financial_data_warehouse_stack_greenfield/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fm7zf/financial_data_warehouse_stack_greenfield/", "subreddit_subscribers": 105217, "created_utc": 1683900408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have to call the ServiceNow APIs from Power BI Service and maybe from SSIS down the line. We\u2019re thinking of using basic auth instead of auth 0. Is it okay security wise? Or should we push for auth 0. We were having a hard time with auth0 from power bi hence we thought basic auth is convenient. Any advice will be greatly appreciated \n\nThanks", "author_fullname": "t2_vls2w775", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is basic authentication \u2018fine\u2019 for security?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fds0j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683875887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have to call the ServiceNow APIs from Power BI Service and maybe from SSIS down the line. We\u2019re thinking of using basic auth instead of auth 0. Is it okay security wise? Or should we push for auth 0. We were having a hard time with auth0 from power bi hence we thought basic auth is convenient. Any advice will be greatly appreciated &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fds0j", "is_robot_indexable": true, "report_reasons": null, "author": "mysterioustechie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fds0j/is_basic_authentication_fine_for_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fds0j/is_basic_authentication_fine_for_security/", "subreddit_subscribers": 105217, "created_utc": 1683875887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried querying from Xano database (not enterprise plan) with an ETL tool? I searched about it and I saw Precog but I  am worried that it's too expensive for a small data startup. What are some other tools you have tried? Is the API call the only way? Thanks in advance!", "author_fullname": "t2_l4f3vumi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Tool for Xano no-code database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fbzid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683869699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried querying from Xano database (not enterprise plan) with an ETL tool? I searched about it and I saw Precog but I  am worried that it&amp;#39;s too expensive for a small data startup. What are some other tools you have tried? Is the API call the only way? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fbzid", "is_robot_indexable": true, "report_reasons": null, "author": "Which_Rutabaga2774", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fbzid/etl_tool_for_xano_nocode_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fbzid/etl_tool_for_xano_nocode_database/", "subreddit_subscribers": 105217, "created_utc": 1683869699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am encountering the follow issue: \n\nThe spark job gets launched as usual and proceeds to readStream. While reading the input files, the executor gets removed, yarn top command shows 0G MEM and VCORES usage and the job pauses for some time. Once the gap period is over, another executor gets launched and the job proceeds to completion like nothing happened. There is no error or warning thrown. \n\nWhat could be the reason and how do I fix this? Which properties should I keep an eye on?", "author_fullname": "t2_t9iw9tl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark - Idle Time During Execution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13f45n8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683848595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am encountering the follow issue: &lt;/p&gt;\n\n&lt;p&gt;The spark job gets launched as usual and proceeds to readStream. While reading the input files, the executor gets removed, yarn top command shows 0G MEM and VCORES usage and the job pauses for some time. Once the gap period is over, another executor gets launched and the job proceeds to completion like nothing happened. There is no error or warning thrown. &lt;/p&gt;\n\n&lt;p&gt;What could be the reason and how do I fix this? Which properties should I keep an eye on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13f45n8", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-End4310", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13f45n8/spark_idle_time_during_execution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13f45n8/spark_idle_time_during_execution/", "subreddit_subscribers": 105217, "created_utc": 1683848595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Google DataStream seems like the perfect solution for us - CDC from RDS Postgres to BigQuery. In testing, when we set lag to 0 seconds datasource synced usually in a few seconds, max a couple of minutes. Wished it could be a bit more deterministic, but still we'd love that.   \nThe problem is that we have a lot of tables in postgres that don't have a primary key and which we would rather not have a primary key (HABTM tables/Rails - primary keys are not supported). There is a workaround for these tables- create a replication identity. We created an identity \"full\". However, this table seemed to not sync at all.   \nHas anyone run into a similar issue? Or did you try a different setup that worked?", "author_fullname": "t2_7p7erpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you got Google DataStream to sync tables from Postgres without a primary key?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ezfte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683837934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google DataStream seems like the perfect solution for us - CDC from RDS Postgres to BigQuery. In testing, when we set lag to 0 seconds datasource synced usually in a few seconds, max a couple of minutes. Wished it could be a bit more deterministic, but still we&amp;#39;d love that.&lt;br/&gt;\nThe problem is that we have a lot of tables in postgres that don&amp;#39;t have a primary key and which we would rather not have a primary key (HABTM tables/Rails - primary keys are not supported). There is a workaround for these tables- create a replication identity. We created an identity &amp;quot;full&amp;quot;. However, this table seemed to not sync at all.&lt;br/&gt;\nHas anyone run into a similar issue? Or did you try a different setup that worked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ezfte", "is_robot_indexable": true, "report_reasons": null, "author": "homechefdit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ezfte/have_you_got_google_datastream_to_sync_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ezfte/have_you_got_google_datastream_to_sync_tables/", "subreddit_subscribers": 105217, "created_utc": 1683837934.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}