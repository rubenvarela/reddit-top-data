{"kind": "Listing", "data": {"after": "t3_135sery", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my organization, 1/2 of my responsibilities include pulling data from our financial system via APIs and on-prem SQL Server databases with Python scripts, making transformations if needed, then loading it in Power BI to build table relationships and create dashboards. There is another team member who also helps with just the dashboarding in Power BI. The infrastructure is all me.\n\nMe being on my own, there is no one to bounce ideas off of or for someone to check me if what I'm implementing makes sense but here is where I'm currently at:\n\n* Implementing version control via GitLab to store the Python scripts.\n* Going to start creating documentation and an overview of the architecture.\n* I'd like to implement a database to store the data then have Power BI read from there. Currently, the financial web APIs are being connected directly to Power BI and gives me no vision on whether a pull is working or if some are failing. It's also making the refreshes take a lot longer with the more connections we make because it's pulling all the data every single time. Still need to test this theory. This would also make me want to implement Airflow for orchestration.\n* We deploy the dashboards via the Power BI Service and the file is stored in SharePoint so all we have to do is replace the current file with an updated one and it'll pick up the changes and re-deploy on its own.\n\n... and that's it. Not sure if I am missing anything. I'm trying to learn as much as I can on my own but not sure what I could be missing as I simply might not know. I'd like for someone to come into this role in the future and be able to pick up where I left off.\n\nI'm not a data engineer by the way and these responsibilities fell on me but am grateful to have this opportunity.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a one man data team (pretty much). How can I be successful and as future proof as possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135mhee", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683037003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my organization, 1/2 of my responsibilities include pulling data from our financial system via APIs and on-prem SQL Server databases with Python scripts, making transformations if needed, then loading it in Power BI to build table relationships and create dashboards. There is another team member who also helps with just the dashboarding in Power BI. The infrastructure is all me.&lt;/p&gt;\n\n&lt;p&gt;Me being on my own, there is no one to bounce ideas off of or for someone to check me if what I&amp;#39;m implementing makes sense but here is where I&amp;#39;m currently at:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Implementing version control via GitLab to store the Python scripts.&lt;/li&gt;\n&lt;li&gt;Going to start creating documentation and an overview of the architecture.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;d like to implement a database to store the data then have Power BI read from there. Currently, the financial web APIs are being connected directly to Power BI and gives me no vision on whether a pull is working or if some are failing. It&amp;#39;s also making the refreshes take a lot longer with the more connections we make because it&amp;#39;s pulling all the data every single time. Still need to test this theory. This would also make me want to implement Airflow for orchestration.&lt;/li&gt;\n&lt;li&gt;We deploy the dashboards via the Power BI Service and the file is stored in SharePoint so all we have to do is replace the current file with an updated one and it&amp;#39;ll pick up the changes and re-deploy on its own.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;... and that&amp;#39;s it. Not sure if I am missing anything. I&amp;#39;m trying to learn as much as I can on my own but not sure what I could be missing as I simply might not know. I&amp;#39;d like for someone to come into this role in the future and be able to pick up where I left off.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a data engineer by the way and these responsibilities fell on me but am grateful to have this opportunity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "135mhee", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135mhee/im_a_one_man_data_team_pretty_much_how_can_i_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135mhee/im_a_one_man_data_team_pretty_much_how_can_i_be/", "subreddit_subscribers": 103875, "created_utc": 1683037003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_123h47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The SQL Unit Testing Landscape: 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_13622x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n8OWB7ApmbHiMtncCXSKtz2CjfC5IQXRqYqKKBMjtHs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683065641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/the-sql-unit-testing-landscape-2023-7a8c5f986dd3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?auto=webp&amp;v=enabled&amp;s=fb1f774d5a439ebae473d4c3f79d54494df8e5e3", "width": 1200, "height": 791}, "resolutions": [{"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfc25e271bfc28652ad40bfc19d9ca653a2dbbe2", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=517218a3fbebb2776fe425239859606904ed0250", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec80424ec5a080afd7bbc75bc288a83b20389579", "width": 320, "height": 210}, {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6524a46adf52b02fb27462219b109530011c154", "width": 640, "height": 421}, {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24a061f3478ffd09e841f342c9d2f79d1c0e1a5a", "width": 960, "height": 632}, {"url": "https://external-preview.redd.it/QPsSH3b7K5FTgaO3d01hHteS9SnEoCzLNOmnl6ta_A4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc3a5bc7728fee260898d12a66159cca1ebb280b", "width": 1080, "height": 711}], "variants": {}, "id": "fTnAcPQNcFB1QlPvwbv31XZ_IYN0ZDOqU8z6RfPb6RM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13622x1", "is_robot_indexable": true, "report_reasons": null, "author": "ryan_CritHits", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13622x1/the_sql_unit_testing_landscape_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/the-sql-unit-testing-landscape-2023-7a8c5f986dd3", "subreddit_subscribers": 103875, "created_utc": 1683065641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Casual observer was thinking the tooling and or feature sets around lake houses would be something to weigh against an actual data warehouse.\n\nI can't seem to find much that would suggest a lake house comes anywhere close to the performance and or features, complex SQL syntax, of a data warehouse. \n\nAm I missing something?", "author_fullname": "t2_5bfewy53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Checking in: lake houses don't seem to be replacing data warehouses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13695y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683084567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Casual observer was thinking the tooling and or feature sets around lake houses would be something to weigh against an actual data warehouse.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t seem to find much that would suggest a lake house comes anywhere close to the performance and or features, complex SQL syntax, of a data warehouse. &lt;/p&gt;\n\n&lt;p&gt;Am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13695y9", "is_robot_indexable": true, "report_reasons": null, "author": "hownottopetacat", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13695y9/checking_in_lake_houses_dont_seem_to_be_replacing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13695y9/checking_in_lake_houses_dont_seem_to_be_replacing/", "subreddit_subscribers": 103875, "created_utc": 1683084567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a solution architect, and I am always looking to improve or optimize the process and data pipelines.\n\nWhat do you guys do specifically for data validations and quality in your pipelines or projects? Or any tools/services/framework which you use.\n\nJust to give you some examples of validations and checks I do:\n\n* not empty\n* column not null\n* correct format\n* column is unique\n* column matches the business rules of another table\n* column doesn\u2019t have too many weird values\n\nI have used Great Expectations and a little bit of Soda SQL. Let me know your thoughts.", "author_fullname": "t2_rrbmofj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality and Validation Checks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135vq01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683051173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a solution architect, and I am always looking to improve or optimize the process and data pipelines.&lt;/p&gt;\n\n&lt;p&gt;What do you guys do specifically for data validations and quality in your pipelines or projects? Or any tools/services/framework which you use.&lt;/p&gt;\n\n&lt;p&gt;Just to give you some examples of validations and checks I do:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;not empty&lt;/li&gt;\n&lt;li&gt;column not null&lt;/li&gt;\n&lt;li&gt;correct format&lt;/li&gt;\n&lt;li&gt;column is unique&lt;/li&gt;\n&lt;li&gt;column matches the business rules of another table&lt;/li&gt;\n&lt;li&gt;column doesn\u2019t have too many weird values&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have used Great Expectations and a little bit of Soda SQL. Let me know your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "135vq01", "is_robot_indexable": true, "report_reasons": null, "author": "Anishekkamal", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135vq01/data_quality_and_validation_checks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135vq01/data_quality_and_validation_checks/", "subreddit_subscribers": 103875, "created_utc": 1683051173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my organization, we are looking for some tool that will help us easily create semantic layer. We have a lot of traffic tables and dashboard, and each one can calculate the KPI in a different way.\nWe are planning to create some layer and all the dashboard will take the metrics from this layer.\nBecause we have a lot of traffic tables, it's become pretty tough because in faxx the revenue will be faxx_revenue and in fayy it will be fayy_revenue. This requires a lot of semantic layers. There is some tool that can help us?", "author_fullname": "t2_s43j01w7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136bog1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683092619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my organization, we are looking for some tool that will help us easily create semantic layer. We have a lot of traffic tables and dashboard, and each one can calculate the KPI in a different way.\nWe are planning to create some layer and all the dashboard will take the metrics from this layer.\nBecause we have a lot of traffic tables, it&amp;#39;s become pretty tough because in faxx the revenue will be faxx_revenue and in fayy it will be fayy_revenue. This requires a lot of semantic layers. There is some tool that can help us?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136bog1", "is_robot_indexable": true, "report_reasons": null, "author": "gal_12345", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136bog1/semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136bog1/semantic_layer/", "subreddit_subscribers": 103875, "created_utc": 1683092619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Got an internal job role, but as I'm moving from Sr. to Intermediate role, there's a pay cut from 115k -&gt; 90k. Will you take it?  \n\n\nI'm a 28 y/o unmarried dude, just fyi in case.\n\nEdit: I considered applying for this new position as I thought it'd be a good chance to expand my skills, etc. and the hiring manager told me he would try to at least match my current salary, but I came to know from him today that it's not possible.", "author_fullname": "t2_4dkekwkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sr. Data Analyst -&gt; Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136d100", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683110534.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683097115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got an internal job role, but as I&amp;#39;m moving from Sr. to Intermediate role, there&amp;#39;s a pay cut from 115k -&amp;gt; 90k. Will you take it?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a 28 y/o unmarried dude, just fyi in case.&lt;/p&gt;\n\n&lt;p&gt;Edit: I considered applying for this new position as I thought it&amp;#39;d be a good chance to expand my skills, etc. and the hiring manager told me he would try to at least match my current salary, but I came to know from him today that it&amp;#39;s not possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "136d100", "is_robot_indexable": true, "report_reasons": null, "author": "Horror-Career-335", "discussion_type": null, "num_comments": 30, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136d100/sr_data_analyst_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136d100/sr_data_analyst_data_engineer/", "subreddit_subscribers": 103875, "created_utc": 1683097115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\na few weeks ago I shared about the project I had been working on for a few months. Dozer is a data API backend that allows us to easily capture, transform, and cache data, and create low-latency APIs with a simple configuration file. \n\nWe have gotten many good comments, but, one aspect that people found limiting was the fact that APIs were read-only. Sometimes it is necessary to take actions based on data changes and write back to the source system (i.e. the original PostgreSQL database).\n\nWe found these were all good suggestions and we decided to implement the first version of what we called a DCC (Data Change Condition). In summary, Dozer now allows to specify a SQL statement verifying a condition. If this condition is met, a Javascript or Python function is invoked and the record triggering the condition is passed to this function. This allows Dozer to be, not just a read-only system, but to be able to react in real-time to data changes. \n\nWe have published a short blog post describing the functionality with a sample:\n\n[https://getdozer.io/blog/unleashing-the-power-of-dozer-lambda-runtime-for-real-time-and-event-driven-data-apps](https://getdozer.io/blog/unleashing-the-power-of-dozer-lambda-runtime-for-real-time-and-event-driven-data-apps)\n\nWould love to get your feedback!", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time CDC-based lambda functions in Dozer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135ohbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683040034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;a few weeks ago I shared about the project I had been working on for a few months. Dozer is a data API backend that allows us to easily capture, transform, and cache data, and create low-latency APIs with a simple configuration file. &lt;/p&gt;\n\n&lt;p&gt;We have gotten many good comments, but, one aspect that people found limiting was the fact that APIs were read-only. Sometimes it is necessary to take actions based on data changes and write back to the source system (i.e. the original PostgreSQL database).&lt;/p&gt;\n\n&lt;p&gt;We found these were all good suggestions and we decided to implement the first version of what we called a DCC (Data Change Condition). In summary, Dozer now allows to specify a SQL statement verifying a condition. If this condition is met, a Javascript or Python function is invoked and the record triggering the condition is passed to this function. This allows Dozer to be, not just a read-only system, but to be able to react in real-time to data changes. &lt;/p&gt;\n\n&lt;p&gt;We have published a short blog post describing the functionality with a sample:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://getdozer.io/blog/unleashing-the-power-of-dozer-lambda-runtime-for-real-time-and-event-driven-data-apps\"&gt;https://getdozer.io/blog/unleashing-the-power-of-dozer-lambda-runtime-for-real-time-and-event-driven-data-apps&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would love to get your feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?auto=webp&amp;v=enabled&amp;s=f163ae35f6da41d04254c7438fd90545c22ac230", "width": 1200, "height": 602}, "resolutions": [{"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbc8d3b6c9dc5518dbb5eb9bc13a42c91dbf2773", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dc27178968b2fadaf8d4e4f0beb27b9c3139b8f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ee2ddc1391a342b6d062ad5c790babff73a8ac2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7dfe717b0f8e2f36961986446627bf2b0a13146", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=803f8c55ddb69ff64ad633974eb4cae01944bf34", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/81S4m0FGj1kii8T3RhBDfSFMBd_aE_EV90TuEF68Rwc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ffa7e82c325c3ed4e5846f2f76fb99dd159fdd3", "width": 1080, "height": 541}], "variants": {}, "id": "U0eUJp24v0zwerciGOqEBH54W-WPfIpMfgok0U-eDJU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "135ohbv", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135ohbv/realtime_cdcbased_lambda_functions_in_dozer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135ohbv/realtime_cdcbased_lambda_functions_in_dozer/", "subreddit_subscribers": 103875, "created_utc": 1683040034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All - \n\nDoes anyone have a solid example of what you wish the business was providing you with from the engineering side? (templates/format would be helpful here)\n\nContext: my team is mostly end to end BI so we are battling data viz, source questions, calculations, joins, as well as where does this live/how I can get it. In my eyes when we don't have requirements we can't hold each other accountable for the quality of work done or the timeline/scope.", "author_fullname": "t2_8isget48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Requirements for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135o3rn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683039698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All - &lt;/p&gt;\n\n&lt;p&gt;Does anyone have a solid example of what you wish the business was providing you with from the engineering side? (templates/format would be helpful here)&lt;/p&gt;\n\n&lt;p&gt;Context: my team is mostly end to end BI so we are battling data viz, source questions, calculations, joins, as well as where does this live/how I can get it. In my eyes when we don&amp;#39;t have requirements we can&amp;#39;t hold each other accountable for the quality of work done or the timeline/scope.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "135o3rn", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalDetail44", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135o3rn/business_requirements_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135o3rn/business_requirements_for_data_engineering/", "subreddit_subscribers": 103875, "created_utc": 1683039698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a good/bad idea to populate a data warehouse directly from source data?\n\nTo elaborate, and for example, what do you think about ingesting data directly from Postgres, via JDBC connection, and writing it to Redshift (using staging tables to have UPSERT) functionality?", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data straight to data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135pppz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683041189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a good/bad idea to populate a data warehouse directly from source data?&lt;/p&gt;\n\n&lt;p&gt;To elaborate, and for example, what do you think about ingesting data directly from Postgres, via JDBC connection, and writing it to Redshift (using staging tables to have UPSERT) functionality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "135pppz", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135pppz/data_straight_to_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135pppz/data_straight_to_data_warehouse/", "subreddit_subscribers": 103875, "created_utc": 1683041189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title.\n\nI\u2019ve found that I really enjoy the business/product management side of things but I also love the technical work that I do. Wondering if anyone here switched to product management and ended up regretting it.", "author_fullname": "t2_c8sn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here make the switch to product management, and hate it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135qbbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683041726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve found that I really enjoy the business/product management side of things but I also love the technical work that I do. Wondering if anyone here switched to product management and ended up regretting it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "135qbbv", "is_robot_indexable": true, "report_reasons": null, "author": "trosenau", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135qbbv/anyone_here_make_the_switch_to_product_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135qbbv/anyone_here_make_the_switch_to_product_management/", "subreddit_subscribers": 103875, "created_utc": 1683041726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to ask the community what kind of OSS software are using for Data Lineage that could allow for the generation of data contracts, if that is yet a thing.", "author_fullname": "t2_rmwyz77m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What OSS are you using for data contracts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136eyqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683103988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to ask the community what kind of OSS software are using for Data Lineage that could allow for the generation of data contracts, if that is yet a thing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136eyqg", "is_robot_indexable": true, "report_reasons": null, "author": "bernardo_galvao", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136eyqg/what_oss_are_you_using_for_data_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136eyqg/what_oss_are_you_using_for_data_contracts/", "subreddit_subscribers": 103875, "created_utc": 1683103988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, can someone tell me what would you do to \"Architect and design data pipelines that can handle billions of data events per month\". This is just a premise/ requirement I saw in a job ad, so no more info.\n\n&amp;#x200B;\n\nI think I would use kafka to process the data events and store them into Postgres. But not sure how to set up postgres to handle the volume.\n\n&amp;#x200B;\n\nCan you give me some insights? \n\n&amp;#x200B;\n\nThanks :)", "author_fullname": "t2_64tza4m8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Architect and design data pipelines that can handle billions of data events per month", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136i2v1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683114058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, can someone tell me what would you do to &amp;quot;Architect and design data pipelines that can handle billions of data events per month&amp;quot;. This is just a premise/ requirement I saw in a job ad, so no more info.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I think I would use kafka to process the data events and store them into Postgres. But not sure how to set up postgres to handle the volume.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you give me some insights? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136i2v1", "is_robot_indexable": true, "report_reasons": null, "author": "AndroidePsicokiller", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136i2v1/architect_and_design_data_pipelines_that_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136i2v1/architect_and_design_data_pipelines_that_can/", "subreddit_subscribers": 103875, "created_utc": 1683114058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to find out if there is a particular function that is more demanding than others? \n\nI would love to know if you see a pattern and how you mitigated this. It seems like the biggest roadblock to meaningful and strategic work.\n\n&amp;#x200B;\n\n[View Poll](https://www.reddit.com/poll/1369po9)", "author_fullname": "t2_391e8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Survey) Which function comes up with the most no. of ad-hoc requests from Data teams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1369po9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683086273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to find out if there is a particular function that is more demanding than others? &lt;/p&gt;\n\n&lt;p&gt;I would love to know if you see a pattern and how you mitigated this. It seems like the biggest roadblock to meaningful and strategic work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1369po9\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1369po9", "is_robot_indexable": true, "report_reasons": null, "author": "Tornado54", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1683518273458, "options": [{"text": "Marketing", "id": "22853888"}, {"text": "Finance", "id": "22853889"}, {"text": "Product", "id": "22853890"}, {"text": "Operations", "id": "22853891"}, {"text": "Sales", "id": "22853892"}, {"text": "Other", "id": "22853893"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 135, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1369po9/survey_which_function_comes_up_with_the_most_no/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1369po9/survey_which_function_comes_up_with_the_most_no/", "subreddit_subscribers": 103875, "created_utc": 1683086273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to build a simple, scheduled ETL process that will run once a day in Airflow. The target data source is a JSON API URL. My current thinking is just something that simply does:\n\nDownload data -&gt; Store in S3 -&gt; Read data from S3 &amp; upsert to database\n\nDoes this make sense? Any pitfalls I'm missing? What would be the best way to store historical copies of the intermediate state of the API response data? (just using &lt;date when job started&gt;\\_&lt;dataset name&gt;.json?)\n\nAlso when using services like S3, what tools do you use to enable local testing of your ETLs for dev sanity?", "author_fullname": "t2_319xs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple ETL Airflow advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1363br1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683068640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to build a simple, scheduled ETL process that will run once a day in Airflow. The target data source is a JSON API URL. My current thinking is just something that simply does:&lt;/p&gt;\n\n&lt;p&gt;Download data -&amp;gt; Store in S3 -&amp;gt; Read data from S3 &amp;amp; upsert to database&lt;/p&gt;\n\n&lt;p&gt;Does this make sense? Any pitfalls I&amp;#39;m missing? What would be the best way to store historical copies of the intermediate state of the API response data? (just using &amp;lt;date when job started&amp;gt;_&amp;lt;dataset name&amp;gt;.json?)&lt;/p&gt;\n\n&lt;p&gt;Also when using services like S3, what tools do you use to enable local testing of your ETLs for dev sanity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1363br1", "is_robot_indexable": true, "report_reasons": null, "author": "jaydub", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1363br1/simple_etl_airflow_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1363br1/simple_etl_airflow_advice/", "subreddit_subscribers": 103875, "created_utc": 1683068640.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a healthcare tech right after college. So that is a total of 2.5 years in the field -  be it data, IT, corporate, you name it. 2.5 years. Not a fresher. Not a senior either.\n\nFirst project was just a bunch of DML SQL queries fired up in Snowflake as we got tickets. I took time to learn Snowflake better, gain a bit of healthcare knowledge and so on. Current team is Data Governance and Data Quality in Informatica tech stack. I worked on tiny part of Python, APIs, PBI dashboards, small ETL setups via data bricks, ADLS and so on.  I know a couple of things about a lot of things, nothing in depth!\n\nIt is always maintaining something some senior has built. Then manager says that I \"lack initiative\". I have tried to create views that will help the business, delivered on everything to the best of my capacity. I am very active outside of my DE role in office. So what he means by \"lacking initiative\" I am not sure. He suggested that I could upskill, because I am not a \"fresher anymore\". I want to switch jobs, but I have NO CONFIDENCE in my tech skills.\n\nI thought of upskilling, did couple of projects end-to-end from EDA to building reports/dashboards using Tableau and Power BI.  I have this aim to utilize the company benefits policy and gain a certification in Azure Data Engineer Associate track, in the hope that I have SOME leverage in the hiring market. Completed Azure fundamentals and Data Fundamentals \\[mentioning here to show that I have already started prepping\\]\n\nI had even asked for project ideas in this subreddit in the past.\n\nBut nothing is giving me confidence, I am not sure why I am this lost in my mindset.\n\nIs it because we use loads of no-code ETL options? Maybe I am terrified to code? I have to google syntaxes a lot and that makes me scared, I cannot do that in an interview!!\n\nDo I spend more time doing projects? Do I stick to Azure because we are ALL migrating to Azure like crazy here. How much can you actually learn outside of work?\n\nI have started reading DE books too. To get a proper structure to my upskilling/gaining more knowledge process.\n\n&amp;#x200B;\n\nI love this field - because it makes sense, if you know what I mean? I hate typical SDE roles. ETL and Data Governance make sense! And I want to get better. I really want to look at a problem and come up with Data Architecture solutions, I want to do be able to do proper analysis and know what tools work together, which component goes where and build things from scratch!\n\nBut is there someone who has taken this path, faced similar struggles?\n\nI am okay getting called out too :D", "author_fullname": "t2_6zz659ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am lost. \"DE\" for 2+ years, but lost. Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_136kv4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683121254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a healthcare tech right after college. So that is a total of 2.5 years in the field -  be it data, IT, corporate, you name it. 2.5 years. Not a fresher. Not a senior either.&lt;/p&gt;\n\n&lt;p&gt;First project was just a bunch of DML SQL queries fired up in Snowflake as we got tickets. I took time to learn Snowflake better, gain a bit of healthcare knowledge and so on. Current team is Data Governance and Data Quality in Informatica tech stack. I worked on tiny part of Python, APIs, PBI dashboards, small ETL setups via data bricks, ADLS and so on.  I know a couple of things about a lot of things, nothing in depth!&lt;/p&gt;\n\n&lt;p&gt;It is always maintaining something some senior has built. Then manager says that I &amp;quot;lack initiative&amp;quot;. I have tried to create views that will help the business, delivered on everything to the best of my capacity. I am very active outside of my DE role in office. So what he means by &amp;quot;lacking initiative&amp;quot; I am not sure. He suggested that I could upskill, because I am not a &amp;quot;fresher anymore&amp;quot;. I want to switch jobs, but I have NO CONFIDENCE in my tech skills.&lt;/p&gt;\n\n&lt;p&gt;I thought of upskilling, did couple of projects end-to-end from EDA to building reports/dashboards using Tableau and Power BI.  I have this aim to utilize the company benefits policy and gain a certification in Azure Data Engineer Associate track, in the hope that I have SOME leverage in the hiring market. Completed Azure fundamentals and Data Fundamentals [mentioning here to show that I have already started prepping]&lt;/p&gt;\n\n&lt;p&gt;I had even asked for project ideas in this subreddit in the past.&lt;/p&gt;\n\n&lt;p&gt;But nothing is giving me confidence, I am not sure why I am this lost in my mindset.&lt;/p&gt;\n\n&lt;p&gt;Is it because we use loads of no-code ETL options? Maybe I am terrified to code? I have to google syntaxes a lot and that makes me scared, I cannot do that in an interview!!&lt;/p&gt;\n\n&lt;p&gt;Do I spend more time doing projects? Do I stick to Azure because we are ALL migrating to Azure like crazy here. How much can you actually learn outside of work?&lt;/p&gt;\n\n&lt;p&gt;I have started reading DE books too. To get a proper structure to my upskilling/gaining more knowledge process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I love this field - because it makes sense, if you know what I mean? I hate typical SDE roles. ETL and Data Governance make sense! And I want to get better. I really want to look at a problem and come up with Data Architecture solutions, I want to do be able to do proper analysis and know what tools work together, which component goes where and build things from scratch!&lt;/p&gt;\n\n&lt;p&gt;But is there someone who has taken this path, faced similar struggles?&lt;/p&gt;\n\n&lt;p&gt;I am okay getting called out too :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "136kv4w", "is_robot_indexable": true, "report_reasons": null, "author": "Aick_Aleck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136kv4w/i_am_lost_de_for_2_years_but_lost_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136kv4w/i_am_lost_de_for_2_years_but_lost_advice/", "subreddit_subscribers": 103875, "created_utc": 1683121254.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working on restructuring some of the previously setup processes to make them more efficient while working on adding some new requirements from clients. As i am getting familiar with the scripts for existing process i am realizing there are way too many scripts and the person was using subqueries a lot which makes it even more cumbersome to decipher the query. \n\nI was wondering if there is any tool, way, library tht i can use to parse multiple sql queries to get the table names, columns , joins, where clauses and any aggregat functions. Any help is appreciated. \n\nThanks in advance.", "author_fullname": "t2_81zlbrs6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parsing sql queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136fbyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683105259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working on restructuring some of the previously setup processes to make them more efficient while working on adding some new requirements from clients. As i am getting familiar with the scripts for existing process i am realizing there are way too many scripts and the person was using subqueries a lot which makes it even more cumbersome to decipher the query. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is any tool, way, library tht i can use to parse multiple sql queries to get the table names, columns , joins, where clauses and any aggregat functions. Any help is appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136fbyp", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPeanuts5237", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136fbyp/parsing_sql_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136fbyp/parsing_sql_queries/", "subreddit_subscribers": 103875, "created_utc": 1683105259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is the only difference self-managed vs. fully managed? What are other reasons why I'd want to use Prefect Cloud? Does your company use their cloud?", "author_fullname": "t2_117ntj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prefect vs. Prefect Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135x18x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683054141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the only difference self-managed vs. fully managed? What are other reasons why I&amp;#39;d want to use Prefect Cloud? Does your company use their cloud?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "135x18x", "is_robot_indexable": true, "report_reasons": null, "author": "saltyrefrigerator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135x18x/prefect_vs_prefect_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/135x18x/prefect_vs_prefect_cloud/", "subreddit_subscribers": 103875, "created_utc": 1683054141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aqvee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modeling maturity model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "name": "t3_136k359", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FCpy5U0WujVFlqlzy7lJozxXf2wUsy69u1fj1chZz-k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683119320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/a-maturity-model-for-data-modeling-and-design-b516d978655c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?auto=webp&amp;v=enabled&amp;s=240c13310c0c4f559310901587446f8e34a6fc99", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0014df565fe64c2cdd8b39f486742a7dfa457846", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4b2aab8ebd612281e210d219912a26176b538fb", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ada714076617dc9cb75b35fde06a8836d16b9616", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4354e820c9a91d8a55318808aa900550eac21258", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=550338a47e95fa4e425f17439e3623c22ea9f6bc", "width": 960, "height": 640}], "variants": {}, "id": "vLyVo8SPnZMi4Y6cVwzNYMw3KV6fMQNbCqzGPriMX4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "136k359", "is_robot_indexable": true, "report_reasons": null, "author": "willemkoenders", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136k359/data_modeling_maturity_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/a-maturity-model-for-data-modeling-and-design-b516d978655c", "subreddit_subscribers": 103875, "created_utc": 1683119320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m starting a new role as a data engineer next month after partaking in a Full-Stack Bootcamp. This is a dream for me but I didn\u2019t learn anything related to data engineering in my bootcamp. Can y\u2019all help me figure out what I should start learning on my own so I don\u2019t fall too behind?", "author_fullname": "t2_e1kommwl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just landed the job!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_136jfg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683117664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m starting a new role as a data engineer next month after partaking in a Full-Stack Bootcamp. This is a dream for me but I didn\u2019t learn anything related to data engineering in my bootcamp. Can y\u2019all help me figure out what I should start learning on my own so I don\u2019t fall too behind?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136jfg5", "is_robot_indexable": true, "report_reasons": null, "author": "geekyabs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136jfg5/i_just_landed_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136jfg5/i_just_landed_the_job/", "subreddit_subscribers": 103875, "created_utc": 1683117664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies if this question isn't suited for this subreddit:\n\nI'm learning about entity relationship diagrams and I'm having trouble understanding this example of a one-to-many relationship, provided by this [article](https://www.gleek.io/blog/er-model-cardinality):\n\n*With this one-to-many (1:N), one entity has an event that occurs one time, while the other entity can have more than one repetition of the event. Take for example a customer placing an order at a restaurant. Each customer only places an order one time, but many orders are placed. In this diagram, the one relationship is shown by the number 1, and the many is shown with N.*\n\n  \nIf a customer can only place an order one time how are multiple orders placed? \n\nI'm guessing that perhaps the author meant that an order can be placed *one at a time*  \\- hence a customer being associated with multiple orders but an order only being associated with one customer. \n\nThanks in advance!", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding a one-to-many relationship in ER diagrams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136d45n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683097388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this question isn&amp;#39;t suited for this subreddit:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m learning about entity relationship diagrams and I&amp;#39;m having trouble understanding this example of a one-to-many relationship, provided by this &lt;a href=\"https://www.gleek.io/blog/er-model-cardinality\"&gt;article&lt;/a&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;With this one-to-many (1:N), one entity has an event that occurs one time, while the other entity can have more than one repetition of the event. Take for example a customer placing an order at a restaurant. Each customer only places an order one time, but many orders are placed. In this diagram, the one relationship is shown by the number 1, and the many is shown with N.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;If a customer can only place an order one time how are multiple orders placed? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m guessing that perhaps the author meant that an order can be placed &lt;em&gt;one at a time&lt;/em&gt;  - hence a customer being associated with multiple orders but an order only being associated with one customer. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136d45n", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136d45n/understanding_a_onetomany_relationship_in_er/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136d45n/understanding_a_onetomany_relationship_in_er/", "subreddit_subscribers": 103875, "created_utc": 1683097388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im stuck on this for a few days now.\n\nI wish to filter the data based on a tag, but this won\u2019t be required everytime the pipeline is run.\n\nso basically, i have a parameter based on which i filter, but i want the filter to pass all data if no parameter is provided.\n\ni tried it with and if statement in the filter like this\n\niif(isNull(parameter), true(), ColumnName == parameter)\n\nbut if i pass null here, it displays no data, and if i pass a parameter, it just outputs 1 row (possibly the first row it encounters)\n\nhow can i achieve my goal of filtering only if a value to filter on is passed?\n\nany and all help is appreciated\n\nEDIT : SOLVED got the if statement working. Changed it from string to Array of Strings", "author_fullname": "t2_2lubobsn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory filter only if a value to filter on is passed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136b17v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683098028.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683090474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im stuck on this for a few days now.&lt;/p&gt;\n\n&lt;p&gt;I wish to filter the data based on a tag, but this won\u2019t be required everytime the pipeline is run.&lt;/p&gt;\n\n&lt;p&gt;so basically, i have a parameter based on which i filter, but i want the filter to pass all data if no parameter is provided.&lt;/p&gt;\n\n&lt;p&gt;i tried it with and if statement in the filter like this&lt;/p&gt;\n\n&lt;p&gt;iif(isNull(parameter), true(), ColumnName == parameter)&lt;/p&gt;\n\n&lt;p&gt;but if i pass null here, it displays no data, and if i pass a parameter, it just outputs 1 row (possibly the first row it encounters)&lt;/p&gt;\n\n&lt;p&gt;how can i achieve my goal of filtering only if a value to filter on is passed?&lt;/p&gt;\n\n&lt;p&gt;any and all help is appreciated&lt;/p&gt;\n\n&lt;p&gt;EDIT : SOLVED got the if statement working. Changed it from string to Array of Strings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136b17v", "is_robot_indexable": true, "report_reasons": null, "author": "CallMeKaulToo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136b17v/azure_data_factory_filter_only_if_a_value_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136b17v/azure_data_factory_filter_only_if_a_value_to/", "subreddit_subscribers": 103875, "created_utc": 1683090474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI have a dbt background and wondered how folks using Spark achieve similar things.\n\nSay I have a few source tables and am tasked with modeling a star schema. Using dbt, I would model in 3 dependent layers - staging (renaming cols, light changes), intermediate (reusable transformations), and dimensions/facts (final tables to be used in BI tool).\n\nThen, on a schedule, dbt would run all of these tables in the necessary order.\n\nHow do Spark folks achieve this? I can see a situation where a scheduler can be set up to run jobs where one job = one table, but how is this all coordinated? How does Spark figure out the dependencies? What tools are used to help with this?\n\nI can't imagine one massive file that holds all the table transformations. ", "author_fullname": "t2_7iitruic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Runs In Production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136afha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683088535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I have a dbt background and wondered how folks using Spark achieve similar things.&lt;/p&gt;\n\n&lt;p&gt;Say I have a few source tables and am tasked with modeling a star schema. Using dbt, I would model in 3 dependent layers - staging (renaming cols, light changes), intermediate (reusable transformations), and dimensions/facts (final tables to be used in BI tool).&lt;/p&gt;\n\n&lt;p&gt;Then, on a schedule, dbt would run all of these tables in the necessary order.&lt;/p&gt;\n\n&lt;p&gt;How do Spark folks achieve this? I can see a situation where a scheduler can be set up to run jobs where one job = one table, but how is this all coordinated? How does Spark figure out the dependencies? What tools are used to help with this?&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t imagine one massive file that holds all the table transformations. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136afha", "is_robot_indexable": true, "report_reasons": null, "author": "jduran9987", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136afha/spark_runs_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136afha/spark_runs_in_production/", "subreddit_subscribers": 103875, "created_utc": 1683088535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "End goal: export from Power App Dataverse to Data Lake\n\nLooks like you used to be able to export from Power App Dataverse direct to the Data Lake, but this has been deprecated as of November 2022, and now you have to spin up a Synapse instance to do it.\n\nThis seems like way over kill for a simple data export.\n\nAnyone using this and is it crazy expensive? Also was thinking just do a Power Automate routine instead to export but that might be just as expensive since it\u2019s a premium connector.\n\n\nThere is a Dataverse connector also in ADF but that looks like it\u2019s for Microsoft\u2019s CRM.\n\nI don\u2019t mind writing my own python connector but I can\u2019t find an API endpoint to connect into.\n\nThanks for any ideas", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone exporting Power App Dataverse to Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13691tu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683084205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;End goal: export from Power App Dataverse to Data Lake&lt;/p&gt;\n\n&lt;p&gt;Looks like you used to be able to export from Power App Dataverse direct to the Data Lake, but this has been deprecated as of November 2022, and now you have to spin up a Synapse instance to do it.&lt;/p&gt;\n\n&lt;p&gt;This seems like way over kill for a simple data export.&lt;/p&gt;\n\n&lt;p&gt;Anyone using this and is it crazy expensive? Also was thinking just do a Power Automate routine instead to export but that might be just as expensive since it\u2019s a premium connector.&lt;/p&gt;\n\n&lt;p&gt;There is a Dataverse connector also in ADF but that looks like it\u2019s for Microsoft\u2019s CRM.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t mind writing my own python connector but I can\u2019t find an API endpoint to connect into.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any ideas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13691tu", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13691tu/anyone_exporting_power_app_dataverse_to_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13691tu/anyone_exporting_power_app_dataverse_to_data_lake/", "subreddit_subscribers": 103875, "created_utc": 1683084205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI\u2019m in CS graduating this coming up fall and I\u2019ve really been wanting to complete a data pipeline project, but I\u2019m unsure what best practices are. I\u2019m currently learning the basics of Apache Airflow and Nifi and plan to do the same for Spark(with Pyspark).\n\nI had a plan set out to let Nifi handle data ingestion from the API sources, Spark handle the processing and loading into a DB, and Airflow would be orchestrating and scheduling these tasks.\n\nIs there something missing or is this a bad practice data pipeline? For example, is Nifi typically NOT used alongside an airflow orchestration, same with spark? Is all this typically done with one tool? Im aware Nifi and Spark both have a somewhat deeper learning curve, and I know nifi seems to want more Java knowledge which I\u2019ve only ever coded in Python/C++. Is it still good practice to use this tool for this type of pipeline? I\u2019m learning and wanting to create, at the same time be able to demonstrate usage of these tools, but I don\u2019t want to end up doing something that\u2019s unusual/not good or overkill.\n\nTLDR: using nifi airflow and spark in a data pipeline, mainly for the purpose of practical experience with these tools, unsure if it\u2019s overkill or unrealistic though", "author_fullname": "t2_55fytx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would this be a good summer project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13637kb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683076599.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683068380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m in CS graduating this coming up fall and I\u2019ve really been wanting to complete a data pipeline project, but I\u2019m unsure what best practices are. I\u2019m currently learning the basics of Apache Airflow and Nifi and plan to do the same for Spark(with Pyspark).&lt;/p&gt;\n\n&lt;p&gt;I had a plan set out to let Nifi handle data ingestion from the API sources, Spark handle the processing and loading into a DB, and Airflow would be orchestrating and scheduling these tasks.&lt;/p&gt;\n\n&lt;p&gt;Is there something missing or is this a bad practice data pipeline? For example, is Nifi typically NOT used alongside an airflow orchestration, same with spark? Is all this typically done with one tool? Im aware Nifi and Spark both have a somewhat deeper learning curve, and I know nifi seems to want more Java knowledge which I\u2019ve only ever coded in Python/C++. Is it still good practice to use this tool for this type of pipeline? I\u2019m learning and wanting to create, at the same time be able to demonstrate usage of these tools, but I don\u2019t want to end up doing something that\u2019s unusual/not good or overkill.&lt;/p&gt;\n\n&lt;p&gt;TLDR: using nifi airflow and spark in a data pipeline, mainly for the purpose of practical experience with these tools, unsure if it\u2019s overkill or unrealistic though&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13637kb", "is_robot_indexable": true, "report_reasons": null, "author": "ToothPickLegs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13637kb/would_this_be_a_good_summer_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13637kb/would_this_be_a_good_summer_project/", "subreddit_subscribers": 103875, "created_utc": 1683068380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I asked in r/cscareersEU but the answers were pretty much 50/50 with a slight lean into CS. But they might be biased because its a CS subreddit.\n\nFor context: my bachelors of applied science focused mainly on software engineering, code quality, SOLID, OO, SQL, DRY, testing, databases, UML etc. But in my extracurriculars I chose statistics, mathematics, formal logic and machine learning. \n\nSo what would be the ideal master for a Data Engineer? One who likes the technical stuff but doesnt shy away from business/sales/managing side of things? I already have 3 years of experience working as a Data Engineer of which 1 year as internships.\n\n[View Poll](https://www.reddit.com/poll/135sery)", "author_fullname": "t2_mmckx7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finished my BaSC in CS but I want a masters and to get into Data Engineering. Where is most demand/which masters should I take?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135sery", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683043968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked in &lt;a href=\"/r/cscareersEU\"&gt;r/cscareersEU&lt;/a&gt; but the answers were pretty much 50/50 with a slight lean into CS. But they might be biased because its a CS subreddit.&lt;/p&gt;\n\n&lt;p&gt;For context: my bachelors of applied science focused mainly on software engineering, code quality, SOLID, OO, SQL, DRY, testing, databases, UML etc. But in my extracurriculars I chose statistics, mathematics, formal logic and machine learning. &lt;/p&gt;\n\n&lt;p&gt;So what would be the ideal master for a Data Engineer? One who likes the technical stuff but doesnt shy away from business/sales/managing side of things? I already have 3 years of experience working as a Data Engineer of which 1 year as internships.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/135sery\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "135sery", "is_robot_indexable": true, "report_reasons": null, "author": "0ne2many", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1683216768104, "options": [{"text": "Computer Science Master", "id": "22845283"}, {"text": "Data Science Master", "id": "22845284"}, {"text": "Business Administration in CS Master", "id": "22845285"}, {"text": "Business intelligence Master", "id": "22845286"}, {"text": "Other/results/please comment", "id": "22845287"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 60, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/135sery/finished_my_basc_in_cs_but_i_want_a_masters_and/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/135sery/finished_my_basc_in_cs_but_i_want_a_masters_and/", "subreddit_subscribers": 103875, "created_utc": 1683043968.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}