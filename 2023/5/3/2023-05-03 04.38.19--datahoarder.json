{"kind": "Listing", "data": {"after": "t3_135w55u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4ulrx5xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vice Media preparing to file for bankruptcy - NYT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_135es09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 850, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 850, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-y97XVEDSnYAU6sVbsHWks9R3Z_2BviCOod-s5DWLPs.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683014717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reuters.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reuters.com/business/media-telecom/vice-preparing-file-bankruptcy-nyt-2023-05-01/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?auto=webp&amp;v=enabled&amp;s=db55e4b20270804546509532ee818299b4ae3b42", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db81df5e285b5fe803cd76ad9d423e14198ed1a5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c4a8ecdb9fa1cd59de48ff85650866387fb37a0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c123dd2d6841e1c13fd02059c8a21421700e128", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0135766768689a79ad0e879042399684da416894", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c16cb4e926e7a8be71dbdf7f788218b7baeff48b", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/CgOX8hETm_FA-1TyWgPRM_kv1LkJiTjrP_RwwEzgVv4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7957338c5bcb3250ab1af8b29287615b98bc9e71", "width": 1080, "height": 565}], "variants": {}, "id": "yeoGKOkXtJa4kY9trjKNJxewv77_mYv1leV5SIYIh0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135es09", "is_robot_indexable": true, "report_reasons": null, "author": "Merchant_Lawrence", "discussion_type": null, "num_comments": 136, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/135es09/vice_media_preparing_to_file_for_bankruptcy_nyt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reuters.com/business/media-telecom/vice-preparing-file-bankruptcy-nyt-2023-05-01/", "subreddit_subscribers": 680610, "created_utc": 1683014717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With the recent Imgur and potential upcoming Reddit API changes, I know that this may be valuable to some people in their search, so I am providing a full subreddit list (zipped) in CSV format, along with the content \"status\", sorted in chronological order. Fields are subscriber count, subreddit name, and \"you-know-what status\". Dataset count is 3,697,545 subreddits as of May 2nd.\n\n[https://drive.google.com/file/d/1GqZRZcrU-b1DkKNL7\\_PWnteiI0QxjyJB/view?usp=sharing](https://drive.google.com/file/d/1GqZRZcrU-b1DkKNL7_PWnteiI0QxjyJB/view?usp=sharing)\n\nI will have this up for a limited time, but you can always reach out to me. Happy hunting!", "author_fullname": "t2_o0j0c7z8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of all Subreddits. Here you go.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135wupl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683053740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the recent Imgur and potential upcoming Reddit API changes, I know that this may be valuable to some people in their search, so I am providing a full subreddit list (zipped) in CSV format, along with the content &amp;quot;status&amp;quot;, sorted in chronological order. Fields are subscriber count, subreddit name, and &amp;quot;you-know-what status&amp;quot;. Dataset count is 3,697,545 subreddits as of May 2nd.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/file/d/1GqZRZcrU-b1DkKNL7_PWnteiI0QxjyJB/view?usp=sharing\"&gt;https://drive.google.com/file/d/1GqZRZcrU-b1DkKNL7_PWnteiI0QxjyJB/view?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I will have this up for a limited time, but you can always reach out to me. Happy hunting!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135wupl", "is_robot_indexable": true, "report_reasons": null, "author": "attentionbender", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135wupl/list_of_all_subreddits_here_you_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135wupl/list_of_all_subreddits_here_you_go/", "subreddit_subscribers": 680610, "created_utc": 1683053740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello together,\n\nI want to provide technical resources for academic shadow libraries.\n\nI know about Academic Torrents (https://academictorrents.com/) and Freeread/Libgen (https://freeread.org/torrents.html) and I have read about various IPFS server infrastructures behind various projects. How can I participate efficiently and technically with servers/seedboxes?\n\nI don't want to just seed random torrents and, above all, I want to understand in how far I can keep control about traffic and sizes in this context.\n\nCan you please give me some straightforward hints/links?\n\nThanks!", "author_fullname": "t2_j26c0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to provide technical resources for academic shadow libraries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135mnpd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683037398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello together,&lt;/p&gt;\n\n&lt;p&gt;I want to provide technical resources for academic shadow libraries.&lt;/p&gt;\n\n&lt;p&gt;I know about Academic Torrents (&lt;a href=\"https://academictorrents.com/\"&gt;https://academictorrents.com/&lt;/a&gt;) and Freeread/Libgen (&lt;a href=\"https://freeread.org/torrents.html\"&gt;https://freeread.org/torrents.html&lt;/a&gt;) and I have read about various IPFS server infrastructures behind various projects. How can I participate efficiently and technically with servers/seedboxes?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to just seed random torrents and, above all, I want to understand in how far I can keep control about traffic and sizes in this context.&lt;/p&gt;\n\n&lt;p&gt;Can you please give me some straightforward hints/links?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?auto=webp&amp;v=enabled&amp;s=918b2eeb77d118fd8f4ba293fa5244eb3286a9c4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff569e6656835558df2eb771cd6c91a6cf219c17", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73b26d33631721450780f7ec8348b184ec52bb60", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b6563332be0778922ae7d781b4de71ae36c5970", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0a85df145bd3584118bc59eecc1952652f8e1e5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bb05ca3c8192d78215c635f3bff8a98f332659c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=427bc2290a0c6c1b2004e5dadd7d6573f8b74411", "width": 1080, "height": 567}], "variants": {}, "id": "9ZQzIXgHwWUMmDwxygJ-VDFa1eAMjAGg-cgqxWhg4Js"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135mnpd", "is_robot_indexable": true, "report_reasons": null, "author": "Cuioma", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135mnpd/whats_the_best_way_to_provide_technical_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135mnpd/whats_the_best_way_to_provide_technical_resources/", "subreddit_subscribers": 680610, "created_utc": 1683037398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Right now I'm studying for exams, and I earlier this semester, I downloaded all the videos from the courses, most of which were recorded in 2020 and 2021, and am now going through them after having neatly sorted both semesters by course. Earlier this year my brother, who recently finished his masters in EE, gave me his files that he had collected over his education.\n\nI'm using all this to study, while at school, and all the files are on my NAS in my attic at home. I downloaded most of this automatically with a combination of yt-dlp, extensions, and some scripts I found online.\n\nI have over a TB of movies and tv, and a bunch of audiobooks, and podcasts that I've consumed over the years. I can access all of this remotely from anywhere, and it's all neatly organized. I will probably create a database at some point, which will automatically track what I have in an excel file as well, so I can for example look over all my books and see what I have on audio and what not, and who the narrator is.\n\nI have over 4 TB of gaming sessions with my friends, as I always record when I talk with someone online. I have highlight sessions organized into a separate folder, and have edited highlights as well. Some of my best memories eternalized.\n\nI have all of my favorite youtube channels from my teens archived, along with all my favorite videos over the years. All of Jerma, Star_, Yogscast, Redlettermedia, Uberhaxornova, Horrible Reviews, and many more. Every Norm Macdonald appearance.\n\nHundreds of movie commentaries, many of which I had to manually record from DVDs, as I didn't know how to get around it. My music collection with over 1500 songs, as I refuse to use proprietary apps for anything. My youtube channel from when I was 13 playing with friends I will probably never talk with again. Photo album that my mother scanned years ago, and videos from her childhood that my grandpa recorded on 8mm in the US. My father's architecture files. My brother's gaming files from years back.\n\nMy heart aches for my lost Minecraft worlds and some of my childhood videos that my mother stored on a single harddrive that of course failed. But I have 14+ TB of priceless stuff, that I have backed up like crazy at multiple locations. People may call this an obsession, but it's for me it's more than worth it.", "author_fullname": "t2_583qq7w2z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I love my home server. Tell me about yours.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1360jdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683062148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now I&amp;#39;m studying for exams, and I earlier this semester, I downloaded all the videos from the courses, most of which were recorded in 2020 and 2021, and am now going through them after having neatly sorted both semesters by course. Earlier this year my brother, who recently finished his masters in EE, gave me his files that he had collected over his education.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using all this to study, while at school, and all the files are on my NAS in my attic at home. I downloaded most of this automatically with a combination of yt-dlp, extensions, and some scripts I found online.&lt;/p&gt;\n\n&lt;p&gt;I have over a TB of movies and tv, and a bunch of audiobooks, and podcasts that I&amp;#39;ve consumed over the years. I can access all of this remotely from anywhere, and it&amp;#39;s all neatly organized. I will probably create a database at some point, which will automatically track what I have in an excel file as well, so I can for example look over all my books and see what I have on audio and what not, and who the narrator is.&lt;/p&gt;\n\n&lt;p&gt;I have over 4 TB of gaming sessions with my friends, as I always record when I talk with someone online. I have highlight sessions organized into a separate folder, and have edited highlights as well. Some of my best memories eternalized.&lt;/p&gt;\n\n&lt;p&gt;I have all of my favorite youtube channels from my teens archived, along with all my favorite videos over the years. All of Jerma, Star_, Yogscast, Redlettermedia, Uberhaxornova, Horrible Reviews, and many more. Every Norm Macdonald appearance.&lt;/p&gt;\n\n&lt;p&gt;Hundreds of movie commentaries, many of which I had to manually record from DVDs, as I didn&amp;#39;t know how to get around it. My music collection with over 1500 songs, as I refuse to use proprietary apps for anything. My youtube channel from when I was 13 playing with friends I will probably never talk with again. Photo album that my mother scanned years ago, and videos from her childhood that my grandpa recorded on 8mm in the US. My father&amp;#39;s architecture files. My brother&amp;#39;s gaming files from years back.&lt;/p&gt;\n\n&lt;p&gt;My heart aches for my lost Minecraft worlds and some of my childhood videos that my mother stored on a single harddrive that of course failed. But I have 14+ TB of priceless stuff, that I have backed up like crazy at multiple locations. People may call this an obsession, but it&amp;#39;s for me it&amp;#39;s more than worth it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1360jdz", "is_robot_indexable": true, "report_reasons": null, "author": "hellowwg2", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1360jdz/i_love_my_home_server_tell_me_about_yours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1360jdz/i_love_my_home_server_tell_me_about_yours/", "subreddit_subscribers": 680610, "created_utc": 1683062148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm seeing some ominous posts about changes to the API and some unanswered issues regarding Reddit third part app support. If the site loses support for third party apps like RIF, I gotta go because that's what Reddit is to me. \n\n I'm also seeing Tumblresque content purges in progress. My question for DH is, what is the most efficient way to download the content of my accounts before I leave the site?\n\nSide question: I have ***thousands*** (maybe even tens of thousands) of RIF screenshots of favorited/best of content going back 10+ years from at least four phones. What is the best way to OCR these image files to make them searchable? I tried to do it once with Adobe Acrobat with mixed results and haven't worked on the project since.", "author_fullname": "t2_2xmxta74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit exit strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135x0l1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683054102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m seeing some ominous posts about changes to the API and some unanswered issues regarding Reddit third part app support. If the site loses support for third party apps like RIF, I gotta go because that&amp;#39;s what Reddit is to me. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also seeing Tumblresque content purges in progress. My question for DH is, what is the most efficient way to download the content of my accounts before I leave the site?&lt;/p&gt;\n\n&lt;p&gt;Side question: I have &lt;strong&gt;&lt;em&gt;thousands&lt;/em&gt;&lt;/strong&gt; (maybe even tens of thousands) of RIF screenshots of favorited/best of content going back 10+ years from at least four phones. What is the best way to OCR these image files to make them searchable? I tried to do it once with Adobe Acrobat with mixed results and haven&amp;#39;t worked on the project since.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135x0l1", "is_robot_indexable": true, "report_reasons": null, "author": "Jollyoldstdick", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135x0l1/reddit_exit_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135x0l1/reddit_exit_strategy/", "subreddit_subscribers": 680610, "created_utc": 1683054102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How to export MS Teams Chats without administrative access to the organization the accounts belongs to?\n\nI am looking for a script or somethin like that to automate that.", "author_fullname": "t2_6hu89s4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to export MS Teams Chats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135xa6m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683054705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to export MS Teams Chats without administrative access to the organization the accounts belongs to?&lt;/p&gt;\n\n&lt;p&gt;I am looking for a script or somethin like that to automate that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135xa6m", "is_robot_indexable": true, "report_reasons": null, "author": "SignFRG", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135xa6m/how_to_export_ms_teams_chats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135xa6m/how_to_export_ms_teams_chats/", "subreddit_subscribers": 680610, "created_utc": 1683054705.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, sorry if this is the wrong sub, pls lmk if it is.\n\n&amp;#x200B;\n\nI'm looking to archive lots of my old files, mostly photo work, but I want to store it offline and with redundancy. At the same time, I don't want to just have two sets of drives that I have to copy everything to twice. Has anyone ever made or encountered a solution where I could save my data to it once, and have it backup twice? something like a NAS, but cheaper and not needing to be network accessed.\n\n&amp;#x200B;\n\nthanks", "author_fullname": "t2_i98hi69k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redundant offline storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13642m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683070490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, sorry if this is the wrong sub, pls lmk if it is.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to archive lots of my old files, mostly photo work, but I want to store it offline and with redundancy. At the same time, I don&amp;#39;t want to just have two sets of drives that I have to copy everything to twice. Has anyone ever made or encountered a solution where I could save my data to it once, and have it backup twice? something like a NAS, but cheaper and not needing to be network accessed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13642m3", "is_robot_indexable": true, "report_reasons": null, "author": "MiceLiceandVice", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13642m3/redundant_offline_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13642m3/redundant_offline_storage/", "subreddit_subscribers": 680610, "created_utc": 1683070490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm looking to buy some drives and reichelt currently has a good deal. I've never purchased from them and since drives are both expensive and fragile, I would like to ask the community if Reichelt has a good or bad reputation on how they pack drives for shipping. They ship to my country of Belgium with DPD, a shipping service that's quite bad in my personal experience, so I'd like to be sure drives are properly packed. \n\nI have of course done some due diligence and looked on the web, but couldn't find much conclusive info so perhaps such info is mainly on German-speaking forums and not EN ones?\n\nMany thanks", "author_fullname": "t2_6lx0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[EU/Germany] Feedback on reichelt.{com/de}'s drive shipping practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135sehu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683043949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to buy some drives and reichelt currently has a good deal. I&amp;#39;ve never purchased from them and since drives are both expensive and fragile, I would like to ask the community if Reichelt has a good or bad reputation on how they pack drives for shipping. They ship to my country of Belgium with DPD, a shipping service that&amp;#39;s quite bad in my personal experience, so I&amp;#39;d like to be sure drives are properly packed. &lt;/p&gt;\n\n&lt;p&gt;I have of course done some due diligence and looked on the web, but couldn&amp;#39;t find much conclusive info so perhaps such info is mainly on German-speaking forums and not EN ones?&lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "84 TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135sehu", "is_robot_indexable": true, "report_reasons": null, "author": "fawkesdotbe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/135sehu/eugermany_feedback_on_reicheltcomdes_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135sehu/eugermany_feedback_on_reicheltcomdes_drive/", "subreddit_subscribers": 680610, "created_utc": 1683043949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So i just found some old cd's/vcd's some dating 23 years most are scrached.\n\nI bought a dvd to usb player and when i right click and open it with windows media player they play fine like some parts are just artifacts but others are fine.\n\nI tried using vlc to convert but it stops when it reaches the artifact part.\n\nI tried [this](https://superuser.com/questions/331169/a-scratched-cd-cannot-be-copied-but-can-be-viewed-by-vlc-or-jetaudio-how) but no success. any ideas?", "author_fullname": "t2_7iv74tpf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Ideas to make scrached CD's to digital copies.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135elm5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683014035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i just found some old cd&amp;#39;s/vcd&amp;#39;s some dating 23 years most are scrached.&lt;/p&gt;\n\n&lt;p&gt;I bought a dvd to usb player and when i right click and open it with windows media player they play fine like some parts are just artifacts but others are fine.&lt;/p&gt;\n\n&lt;p&gt;I tried using vlc to convert but it stops when it reaches the artifact part.&lt;/p&gt;\n\n&lt;p&gt;I tried &lt;a href=\"https://superuser.com/questions/331169/a-scratched-cd-cannot-be-copied-but-can-be-viewed-by-vlc-or-jetaudio-how\"&gt;this&lt;/a&gt; but no success. any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/40X4wKoYqNFZ4tGwyKdrlUObuYGH16pk7Re1me-vCm8.jpg?auto=webp&amp;v=enabled&amp;s=5bf61032a6a11077440cf0421aceee21a943a62d", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/40X4wKoYqNFZ4tGwyKdrlUObuYGH16pk7Re1me-vCm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbd71549aa2d678c4628f02ae8cd5b7ddaf23d73", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/40X4wKoYqNFZ4tGwyKdrlUObuYGH16pk7Re1me-vCm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=451335daa7d9e8aa739cd3a851acc983948bf130", "width": 216, "height": 216}], "variants": {}, "id": "PJ2AnV34BC-Bc5jLZ5IhQtzJPf-P0PW2LhpwYCeTNyE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135elm5", "is_robot_indexable": true, "report_reasons": null, "author": "Breath-Previous", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135elm5/any_ideas_to_make_scrached_cds_to_digital_copies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135elm5/any_ideas_to_make_scrached_cds_to_digital_copies/", "subreddit_subscribers": 680610, "created_utc": 1683014035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone ever come across something like this?", "author_fullname": "t2_r4fz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When is someone going to make a hot swap bay for nvme drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1361hb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683064222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone ever come across something like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1361hb2", "is_robot_indexable": true, "report_reasons": null, "author": "justvano", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1361hb2/when_is_someone_going_to_make_a_hot_swap_bay_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1361hb2/when_is_someone_going_to_make_a_hot_swap_bay_for/", "subreddit_subscribers": 680610, "created_utc": 1683064222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to edit the metadata for over 862 mkv files and I was hoping you guys can recommend a good metadata editor. I was looking to go with  MKVToolNix but after doing a bit of research I saw a lot of red flags but those post were old so I don't know if they are still and issue or not. \n\nAny and all help is greatly appreciated.", "author_fullname": "t2_v9opjyxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Metadata editor would you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135txar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683047296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to edit the metadata for over 862 mkv files and I was hoping you guys can recommend a good metadata editor. I was looking to go with  MKVToolNix but after doing a bit of research I saw a lot of red flags but those post were old so I don&amp;#39;t know if they are still and issue or not. &lt;/p&gt;\n\n&lt;p&gt;Any and all help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135txar", "is_robot_indexable": true, "report_reasons": null, "author": "iamwhoiwasnow", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135txar/what_metadata_editor_would_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135txar/what_metadata_editor_would_you_recommend/", "subreddit_subscribers": 680610, "created_utc": 1683047296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a very specific situation that I wonder if any of you would have any thoughts on...\n\nMy wife loves the old-school method of physical photos collected in albums.  To be honest, really dig it too.  It saves photos being buried in the network storage, never to be seen again, and there's something very enjoyable with the tactility of thumbing through the pages of a holiday.\n\nAnyway... I also make sure they're all backed up digitally.  But I want to ensure that anyone looking to recover for a disaster many years from now can easily reproduce the photos.  We lost stacks of my Nan's photos via environmental damage and I don't want that to happen to mine.\n\nPopping an M-DISC in the back cover of the albums is my current go-to.\n\n* I don't trust SD cards, having fallen victim to bitrot a couple of times.\n* I've read that SSDs can corrupt if left unpowered for long enough.\n* HDDs are just too cumbersome to include in an album.\n* Tapes are even more bulky and too complicated for a family member to restore from.\n\nBut I do fear for optical media, seeing that almost nothing comes with a drive any more.\n\nIs there something I'm not aware of that is as *apparently* stable as an M-DISC, but compact like an SD card?\n\nI'd love it if Prof. Clever would invent a write-once, never-decays card-sized flat USB drive.\n\nOne can dream.", "author_fullname": "t2_ccavg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is M-DISC still the best alternative for simple, stable, small archiving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135sju4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683044269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very specific situation that I wonder if any of you would have any thoughts on...&lt;/p&gt;\n\n&lt;p&gt;My wife loves the old-school method of physical photos collected in albums.  To be honest, really dig it too.  It saves photos being buried in the network storage, never to be seen again, and there&amp;#39;s something very enjoyable with the tactility of thumbing through the pages of a holiday.&lt;/p&gt;\n\n&lt;p&gt;Anyway... I also make sure they&amp;#39;re all backed up digitally.  But I want to ensure that anyone looking to recover for a disaster many years from now can easily reproduce the photos.  We lost stacks of my Nan&amp;#39;s photos via environmental damage and I don&amp;#39;t want that to happen to mine.&lt;/p&gt;\n\n&lt;p&gt;Popping an M-DISC in the back cover of the albums is my current go-to.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I don&amp;#39;t trust SD cards, having fallen victim to bitrot a couple of times.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve read that SSDs can corrupt if left unpowered for long enough.&lt;/li&gt;\n&lt;li&gt;HDDs are just too cumbersome to include in an album.&lt;/li&gt;\n&lt;li&gt;Tapes are even more bulky and too complicated for a family member to restore from.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;But I do fear for optical media, seeing that almost nothing comes with a drive any more.&lt;/p&gt;\n\n&lt;p&gt;Is there something I&amp;#39;m not aware of that is as &lt;em&gt;apparently&lt;/em&gt; stable as an M-DISC, but compact like an SD card?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love it if Prof. Clever would invent a write-once, never-decays card-sized flat USB drive.&lt;/p&gt;\n\n&lt;p&gt;One can dream.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "135sju4", "is_robot_indexable": true, "report_reasons": null, "author": "FluffyMumbles", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135sju4/is_mdisc_still_the_best_alternative_for_simple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135sju4/is_mdisc_still_the_best_alternative_for_simple/", "subreddit_subscribers": 680610, "created_utc": 1683044269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, i got 8 16tb drives in a 8bay qnap nas in a raid 6 config and i would like to backup/sync that data to 12 8tb drives which i previously used but cant really come up with a efficient way to do this.\n\nCurrently im doing all of this manually because i got certain folders on my NAS that are bigger than the destination drives and i dont know if there are any tools that can backup such folders to multiple destinations.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ctmg5xzdffxa1.png?width=1061&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c737a3d994949e4eced21a45cae7a07dbc135f5d", "author_fullname": "t2_2yjt9hpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up a folder to multiple destination drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ctmg5xzdffxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7034f09c2799e3e62367f176ce4bd7cd5c21bd98"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2765fabbfc4e7fc1ab27548cdee6657dca07174"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6d55f0af2abec0abf7e8a1d31c6f118ce53d680"}, {"y": 170, "x": 640, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d37d4b5e2ffe816b7e5d47b3b2d114800d5c1d48"}, {"y": 256, "x": 960, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f86fdf291bfb9002372a441e4bf8a1fa7bc43a6c"}], "s": {"y": 283, "x": 1061, "u": "https://preview.redd.it/ctmg5xzdffxa1.png?width=1061&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c737a3d994949e4eced21a45cae7a07dbc135f5d"}, "id": "ctmg5xzdffxa1"}}, "name": "t3_135mfj6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c_RFUUfzfyoXmhEk3XqIAzgqQR5XZZP_fp9Id39UWGg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683036890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i got 8 16tb drives in a 8bay qnap nas in a raid 6 config and i would like to backup/sync that data to 12 8tb drives which i previously used but cant really come up with a efficient way to do this.&lt;/p&gt;\n\n&lt;p&gt;Currently im doing all of this manually because i got certain folders on my NAS that are bigger than the destination drives and i dont know if there are any tools that can backup such folders to multiple destinations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ctmg5xzdffxa1.png?width=1061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c737a3d994949e4eced21a45cae7a07dbc135f5d\"&gt;https://preview.redd.it/ctmg5xzdffxa1.png?width=1061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c737a3d994949e4eced21a45cae7a07dbc135f5d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135mfj6", "is_robot_indexable": true, "report_reasons": null, "author": "adac69", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135mfj6/backing_up_a_folder_to_multiple_destination_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135mfj6/backing_up_a_folder_to_multiple_destination_drives/", "subreddit_subscribers": 680610, "created_utc": 1683036890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are a ton of blue SAS to SATA cables on eBay and Amazon that seem like the same cables from brands I've never heard of. \n\nI was wondering if there is a certain brand of Mini-SAS to SATA cable (for LSI HBA card) that is proven for it's reliability? \n\nI also am looking for cables for my standard SATA drives as well - I'm having trouble routing the standard thick flat SATA cables in my chassis.", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended SAS to SATA Cables for LSI card", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135lb3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683034288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are a ton of blue SAS to SATA cables on eBay and Amazon that seem like the same cables from brands I&amp;#39;ve never heard of. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is a certain brand of Mini-SAS to SATA cable (for LSI HBA card) that is proven for it&amp;#39;s reliability? &lt;/p&gt;\n\n&lt;p&gt;I also am looking for cables for my standard SATA drives as well - I&amp;#39;m having trouble routing the standard thick flat SATA cables in my chassis.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135lb3u", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/135lb3u/recommended_sas_to_sata_cables_for_lsi_card/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135lb3u/recommended_sas_to_sata_cables_for_lsi_card/", "subreddit_subscribers": 680610, "created_utc": 1683034288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "R\u00ebdit has banned them. I saw a torrent of all their data going back to December 2022. Is there a way to get the additional data up to May 1st?", "author_fullname": "t2_2nlr1umm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Pushshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135ghkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683021180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;R\u00ebdit has banned them. I saw a torrent of all their data going back to December 2022. Is there a way to get the additional data up to May 1st?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "135ghkq", "is_robot_indexable": true, "report_reasons": null, "author": "smarthome_fan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135ghkq/archiving_pushshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135ghkq/archiving_pushshift/", "subreddit_subscribers": 680610, "created_utc": 1683021180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title says it all, I don't know what to do at this point except format my drive but I have too much data, this folder is irrelevant for me but it's annoying. I can only assume the data that I moved over from my old drive to this relatively new drive was corrupt and now it's corrupt here, or a brief power outage during Bitlocker encrypting made it corrupt? I decrypted everything, took like 3 days and still can't delete it.", "author_fullname": "t2_76kxmgv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a folder on my external HDD that I can't delete, get this error \"0x80070091 The directory is not empty\" tried chkdsk and got An unspecified error occurred (766f6c756d652e63 475). Scanned drive with CrystalDisk and drive is fine. exFAT drive so no security tab. Please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1367a44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683079399.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683079150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title says it all, I don&amp;#39;t know what to do at this point except format my drive but I have too much data, this folder is irrelevant for me but it&amp;#39;s annoying. I can only assume the data that I moved over from my old drive to this relatively new drive was corrupt and now it&amp;#39;s corrupt here, or a brief power outage during Bitlocker encrypting made it corrupt? I decrypted everything, took like 3 days and still can&amp;#39;t delete it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1367a44", "is_robot_indexable": true, "report_reasons": null, "author": "JustADesignerDogToy", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1367a44/i_have_a_folder_on_my_external_hdd_that_i_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1367a44/i_have_a_folder_on_my_external_hdd_that_i_cant/", "subreddit_subscribers": 680610, "created_utc": 1683079150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For the past 2 years now I have been looking for a basic website where I can host alot of images and assign tags to them to make it easier to find the image, sort of like a booru, for example. I havent been able to find any websites at all that are basic and easy to use with tagging. The booru project website which is what was used to make private boorus is closed, szurubooru is incredibly difficult to install (if anyone could help me with this I would greatly apprechiate it) Hydrus has a UI i dont enjoy using (however if it comes down to it ill suck it up and get used to it) and at this point im lost. I just want a basic software to host my images/videos/gifs and apply basic tags to them. Please, help me find a website or application that does this. Perferably I would want it to be simple and easy to use and install, but if none of them are then I guess I just have to deal with it. Anything would help, thank you. \n(Note: When im uploading folders it will be around 800 images average at a time)", "author_fullname": "t2_ecta9o1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A website where I can organize images using tags, like a booru of some sort", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1366tni", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683077880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the past 2 years now I have been looking for a basic website where I can host alot of images and assign tags to them to make it easier to find the image, sort of like a booru, for example. I havent been able to find any websites at all that are basic and easy to use with tagging. The booru project website which is what was used to make private boorus is closed, szurubooru is incredibly difficult to install (if anyone could help me with this I would greatly apprechiate it) Hydrus has a UI i dont enjoy using (however if it comes down to it ill suck it up and get used to it) and at this point im lost. I just want a basic software to host my images/videos/gifs and apply basic tags to them. Please, help me find a website or application that does this. Perferably I would want it to be simple and easy to use and install, but if none of them are then I guess I just have to deal with it. Anything would help, thank you. \n(Note: When im uploading folders it will be around 800 images average at a time)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1366tni", "is_robot_indexable": true, "report_reasons": null, "author": "estifxy220", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1366tni/a_website_where_i_can_organize_images_using_tags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1366tni/a_website_where_i_can_organize_images_using_tags/", "subreddit_subscribers": 680610, "created_utc": 1683077880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't really care about text posts, only media. But if there's an option for text posts too, that'd be cool", "author_fullname": "t2_2dgnha39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way I can download all of the media posts in my profile?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136673d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683076167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t really care about text posts, only media. But if there&amp;#39;s an option for text posts too, that&amp;#39;d be cool&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "136673d", "is_robot_indexable": true, "report_reasons": null, "author": "RaulsterMaster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/136673d/is_there_a_way_i_can_download_all_of_the_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/136673d/is_there_a_way_i_can_download_all_of_the_media/", "subreddit_subscribers": 680610, "created_utc": 1683076167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://tweakers.net/pricewatch/1851890/wd-gold-22tb.html](https://tweakers.net/pricewatch/1851890/wd-gold-22tb.html)  \n[https://tweakers.net/pricewatch/1857294/wd-dc-hc570-sata-se-22tb/specificaties/](https://tweakers.net/pricewatch/1857294/wd-dc-hc570-sata-se-22tb/specificaties/)  \n\n\nIm always used to buying WD gold for my nas. Is there a difference in this WD DC drive in this use cage? is one more reliable?", "author_fullname": "t2_dqi7ja43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between these 2 drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1363m1v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683069329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://tweakers.net/pricewatch/1851890/wd-gold-22tb.html\"&gt;https://tweakers.net/pricewatch/1851890/wd-gold-22tb.html&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://tweakers.net/pricewatch/1857294/wd-dc-hc570-sata-se-22tb/specificaties/\"&gt;https://tweakers.net/pricewatch/1857294/wd-dc-hc570-sata-se-22tb/specificaties/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Im always used to buying WD gold for my nas. Is there a difference in this WD DC drive in this use cage? is one more reliable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1363m1v", "is_robot_indexable": true, "report_reasons": null, "author": "Patient-Culture2192", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1363m1v/difference_between_these_2_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1363m1v/difference_between_these_2_drives/", "subreddit_subscribers": 680610, "created_utc": 1683069329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a directory of images, too many to look through by hand. I\u2019m looking for a tool where I can provide a photo of an object or face, and have it return all images that contain that object or face. Does a tool like this exist for windows?", "author_fullname": "t2_2ro3bwn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tools to match faces &amp; objects in a directory of images? (Local facial recognition/reverse image search)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13633jj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683068107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a directory of images, too many to look through by hand. I\u2019m looking for a tool where I can provide a photo of an object or face, and have it return all images that contain that object or face. Does a tool like this exist for windows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13633jj", "is_robot_indexable": true, "report_reasons": null, "author": "drunk_recipe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13633jj/any_tools_to_match_faces_objects_in_a_directory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13633jj/any_tools_to_match_faces_objects_in_a_directory/", "subreddit_subscribers": 680610, "created_utc": 1683068107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my gihub repo I got some [selfhosted guides](https://github.com/DoTheEvo/selfhosted-apps-docker) and I used imgur when I needed to have picture in documentation.\n\nWould prefer saving it and not spending days on it.. and I could probably write some script to get it, but maybe I save some time by asking for one?\n\nThough maybe with github stuff actually seems cached as picture link does not go to imgur... but still I like for plain md files to be \"working\"", "author_fullname": "t2_svh0fd3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some script that would go through text files in a folder and download any imgur link it finds?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1362ieb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683066669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my gihub repo I got some &lt;a href=\"https://github.com/DoTheEvo/selfhosted-apps-docker\"&gt;selfhosted guides&lt;/a&gt; and I used imgur when I needed to have picture in documentation.&lt;/p&gt;\n\n&lt;p&gt;Would prefer saving it and not spending days on it.. and I could probably write some script to get it, but maybe I save some time by asking for one?&lt;/p&gt;\n\n&lt;p&gt;Though maybe with github stuff actually seems cached as picture link does not go to imgur... but still I like for plain md files to be &amp;quot;working&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?auto=webp&amp;v=enabled&amp;s=b026a5e25b1e6c937f8e3d81b01def74c321f2c8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec1595b5da85e29f8c14701c6b924f2bf7bcb8f0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3820354d2580f26185a4b9829a35f95e995963b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f94e3a2aed81035366ad377b6d5f49fd712605d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66adb23bfb7bdeaf8ddc547b00986b89c1a2fac2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8bbed8b387daa0761ad98341e7d6dacf3292e01", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_NZfyFK7n2QTr7DCPgdFvI3XBFFm-GCScBT1k5rct14.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74ce9bda90e97443d79fecd466ac2b2074d7d79d", "width": 1080, "height": 540}], "variants": {}, "id": "bHRDzaCFXFdaLO8RaAmrRHO4OajN7kOEBeC8jdDNlvg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1362ieb", "is_robot_indexable": true, "report_reasons": null, "author": "Do_TheEvolution", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1362ieb/some_script_that_would_go_through_text_files_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1362ieb/some_script_that_would_go_through_text_files_in_a/", "subreddit_subscribers": 680610, "created_utc": 1683066669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm quite new to web scraping (the farthest I have gotten so far is to download blob:url videos). There is this video (replay of a live stream, more accurately) that I would love (and frankly need) to watch. When I reopened the link though, I discovered it was \"unavailable\", *however,* I have the view-source page from when it wasn't yet on the \"This video is private\" page.\n\nHow do I find the direct download link for the video on that page? So far, I have found these\n\n    https://rr4---sn-jucj-4gje.googlevideo.com/generate_204\n    https://rr4---sn-jucj-4gje.googlevideo.com/generate_204?conn2\n\nwhich resemble other direct links but am unsure on how to proceed. Any guidance is greatly appreciated.\n\nOriginal link: [https://www.youtube.com/watch?v=bobZa1f60Ls](https://www.youtube.com/watch?v=bobZa1f60Ls)\n\n[Pastes.io](https://Pastes.io) link (Pastebin's filters lit up): [https://pastes.io/5nuxskhl8e](https://pastes.io/5nuxskhl8e)", "author_fullname": "t2_2sqb10mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you help me extract a video download link from this view-source page?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1361k3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683064782.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683064400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m quite new to web scraping (the farthest I have gotten so far is to download blob:url videos). There is this video (replay of a live stream, more accurately) that I would love (and frankly need) to watch. When I reopened the link though, I discovered it was &amp;quot;unavailable&amp;quot;, &lt;em&gt;however,&lt;/em&gt; I have the view-source page from when it wasn&amp;#39;t yet on the &amp;quot;This video is private&amp;quot; page.&lt;/p&gt;\n\n&lt;p&gt;How do I find the direct download link for the video on that page? So far, I have found these&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;https://rr4---sn-jucj-4gje.googlevideo.com/generate_204\nhttps://rr4---sn-jucj-4gje.googlevideo.com/generate_204?conn2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;which resemble other direct links but am unsure on how to proceed. Any guidance is greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Original link: &lt;a href=\"https://www.youtube.com/watch?v=bobZa1f60Ls\"&gt;https://www.youtube.com/watch?v=bobZa1f60Ls&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://Pastes.io\"&gt;Pastes.io&lt;/a&gt; link (Pastebin&amp;#39;s filters lit up): &lt;a href=\"https://pastes.io/5nuxskhl8e\"&gt;https://pastes.io/5nuxskhl8e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1361k3n", "is_robot_indexable": true, "report_reasons": null, "author": "pigaroos", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1361k3n/can_you_help_me_extract_a_video_download_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1361k3n/can_you_help_me_extract_a_video_download_link/", "subreddit_subscribers": 680610, "created_utc": 1683064400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently bought a new 2 bay NAS and I will be doing a raid 1 array with two 14tb drives. I have an older WD Red drive (which is 60% filled) and I recently bought a new WD Red Plus drive. \n\nOn the new drive I loaded linux mint and did \"sudo badblocks -b 4096 -wsv /dev/sda\" and then checked the Smart values using \"smartctl -t long /dev/sda\".  Badblocks does a destructive read write test with four different patterns and from what I have read this is considered good enough to locate any bad sectors. From what I have understood if there were any significant changes in the SMART stats, especially the rellocated sector counts the drive would be deemed faulty and it would be in my best interest to return it. \n\nOn the second, already-filled drive I thought about running a read only test, move the data to a 10tb backup seagate drive and then after the raid-1 is created and the disks are formated move the data back to the raid-1 array.\n\nDo you believe that by not running a destructive multiple pass read write test on badblocks I am making a mistake? What is the general consensus on badblocks and would you recommend something different?", "author_fullname": "t2_4y5htn81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to check a new and a used drive before setting up a Raid-1 array", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1360oal", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683062463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently bought a new 2 bay NAS and I will be doing a raid 1 array with two 14tb drives. I have an older WD Red drive (which is 60% filled) and I recently bought a new WD Red Plus drive. &lt;/p&gt;\n\n&lt;p&gt;On the new drive I loaded linux mint and did &amp;quot;sudo badblocks -b 4096 -wsv /dev/sda&amp;quot; and then checked the Smart values using &amp;quot;smartctl -t long /dev/sda&amp;quot;.  Badblocks does a destructive read write test with four different patterns and from what I have read this is considered good enough to locate any bad sectors. From what I have understood if there were any significant changes in the SMART stats, especially the rellocated sector counts the drive would be deemed faulty and it would be in my best interest to return it. &lt;/p&gt;\n\n&lt;p&gt;On the second, already-filled drive I thought about running a read only test, move the data to a 10tb backup seagate drive and then after the raid-1 is created and the disks are formated move the data back to the raid-1 array.&lt;/p&gt;\n\n&lt;p&gt;Do you believe that by not running a destructive multiple pass read write test on badblocks I am making a mistake? What is the general consensus on badblocks and would you recommend something different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1360oal", "is_robot_indexable": true, "report_reasons": null, "author": "Olrik57", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1360oal/what_is_the_best_way_to_check_a_new_and_a_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1360oal/what_is_the_best_way_to_check_a_new_and_a_used/", "subreddit_subscribers": 680610, "created_utc": 1683062463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So i'm scratching my head here a bit.   I had 2 disks recently go south in my truenas raidz2   i paid for advance RMA with seagate and they sent 2 drives.\n\nOne of the replacements went fine no issues at all swapped in the disk and replaced.  \n\nThe other disk appeared DOA it wouldn't show up via devices and when it was trying to negotiate sata link speed it failed.  It was also making a strange beeping almost mechanical beeping i noticed when i was trying to diagnose the disk via a usb sata.   The disk also didn't show up as a device while on usb sata.    \n\nI contacted seagate and over a bit of talking with them they sent out another advance RMA disk.  This disk arrived today it is also DOA  these are seagate exos x18 14TB disks.  Now i'm either thinking they have a batch of bad disks they are RMA'ing or my disk slot is some how killing these disks when they arrive.  The next disk i get i will test via usb sata enclosure first as it is working fine i tested with another disk from this same array.  I'm worried they may not want to send me a 3rd disk now as this is starting to get ridiculous.  \n\nThe reason for this post is i'm curious if anyone else is having these issues with RMA disks from seagate?", "author_fullname": "t2_129tv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Advance RMA 2xDOA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135z9qi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683059314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m scratching my head here a bit.   I had 2 disks recently go south in my truenas raidz2   i paid for advance RMA with seagate and they sent 2 drives.&lt;/p&gt;\n\n&lt;p&gt;One of the replacements went fine no issues at all swapped in the disk and replaced.  &lt;/p&gt;\n\n&lt;p&gt;The other disk appeared DOA it wouldn&amp;#39;t show up via devices and when it was trying to negotiate sata link speed it failed.  It was also making a strange beeping almost mechanical beeping i noticed when i was trying to diagnose the disk via a usb sata.   The disk also didn&amp;#39;t show up as a device while on usb sata.    &lt;/p&gt;\n\n&lt;p&gt;I contacted seagate and over a bit of talking with them they sent out another advance RMA disk.  This disk arrived today it is also DOA  these are seagate exos x18 14TB disks.  Now i&amp;#39;m either thinking they have a batch of bad disks they are RMA&amp;#39;ing or my disk slot is some how killing these disks when they arrive.  The next disk i get i will test via usb sata enclosure first as it is working fine i tested with another disk from this same array.  I&amp;#39;m worried they may not want to send me a 3rd disk now as this is starting to get ridiculous.  &lt;/p&gt;\n\n&lt;p&gt;The reason for this post is i&amp;#39;m curious if anyone else is having these issues with RMA disks from seagate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "135z9qi", "is_robot_indexable": true, "report_reasons": null, "author": "mavericm1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135z9qi/seagate_advance_rma_2xdoa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135z9qi/seagate_advance_rma_2xdoa/", "subreddit_subscribers": 680610, "created_utc": 1683059314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran into my image collection, and it made me think I should explore some additional backup solutions in the event of a catastrophe.  I'm curious if others use any offline backup storage techniques. I want to make a backup of my systems and back in the day we used to use tape but they always seemed to fail. Was reading about LTO tapes that have a pretty crazy capacity.  Anyone else try these? Otherwise, what do you use (beyond just more disks)?", "author_fullname": "t2_2rizd171", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Offline Storage Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_135w55u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683052150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran into my image collection, and it made me think I should explore some additional backup solutions in the event of a catastrophe.  I&amp;#39;m curious if others use any offline backup storage techniques. I want to make a backup of my systems and back in the day we used to use tape but they always seemed to fail. Was reading about LTO tapes that have a pretty crazy capacity.  Anyone else try these? Otherwise, what do you use (beyond just more disks)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "135w55u", "is_robot_indexable": true, "report_reasons": null, "author": "breadcrumb1977", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/135w55u/local_offline_storage_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/135w55u/local_offline_storage_recommendations/", "subreddit_subscribers": 680610, "created_utc": 1683052150.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}