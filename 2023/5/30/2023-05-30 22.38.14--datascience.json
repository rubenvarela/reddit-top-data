{"kind": "Listing", "data": {"after": "t3_13vkbo3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, today i've had a last round interview with my (hopefully) future manager. The job is a data science internship in a bank. The question was as follows:\n\n\"Let's say you have 250 variables which you can use to construct a model. However, you will have to explain why you chose these variables to your colleague, who is going to decide whether it goes into production or not. How many do you keep?\"\n\nAnd that's it! Nothing on the context, data, nature of the problem or even the aformentioned colleague. I believe it wasn't a question regarding my knowledge on data pre-processing and feature selection, because we have discussed these pretty intensively in the questions before. Nevertheless, I told him about these once more and said that it varies from case to case. In the end, he still asked for an estimate, so I said \"50 maximum, 20-25 optimally\", and argued that a model with more variables would probably be tough to interpret and that explaining that many to my colleague would probably take way too long.\n\nOverall, I've got a feeling I did pretty well in the interview. This question is the only thing I'm uncertain of. From what I heard and saw, this wasn't meant to reveal my way of thinking etc. He simply wanted to know the estimated value.\n\nWhat do you guys think was the purpose of this?\n\nWhat's the correct answer?\n\nDo you think I replied well?\n\nEDIT: I can see some of you say it was about data preprocessing/feature selection/dimensionality reduction. I'm no expert in ds interviews, but as i mentioned \nearlier I've already told him what i know about these topics. It seems weird to ask someone the same thing twice.", "author_fullname": "t2_25ix3tty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unusual interview question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vtrp8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685481356.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685461495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, today i&amp;#39;ve had a last round interview with my (hopefully) future manager. The job is a data science internship in a bank. The question was as follows:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Let&amp;#39;s say you have 250 variables which you can use to construct a model. However, you will have to explain why you chose these variables to your colleague, who is going to decide whether it goes into production or not. How many do you keep?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;And that&amp;#39;s it! Nothing on the context, data, nature of the problem or even the aformentioned colleague. I believe it wasn&amp;#39;t a question regarding my knowledge on data pre-processing and feature selection, because we have discussed these pretty intensively in the questions before. Nevertheless, I told him about these once more and said that it varies from case to case. In the end, he still asked for an estimate, so I said &amp;quot;50 maximum, 20-25 optimally&amp;quot;, and argued that a model with more variables would probably be tough to interpret and that explaining that many to my colleague would probably take way too long.&lt;/p&gt;\n\n&lt;p&gt;Overall, I&amp;#39;ve got a feeling I did pretty well in the interview. This question is the only thing I&amp;#39;m uncertain of. From what I heard and saw, this wasn&amp;#39;t meant to reveal my way of thinking etc. He simply wanted to know the estimated value.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think was the purpose of this?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the correct answer?&lt;/p&gt;\n\n&lt;p&gt;Do you think I replied well?&lt;/p&gt;\n\n&lt;p&gt;EDIT: I can see some of you say it was about data preprocessing/feature selection/dimensionality reduction. I&amp;#39;m no expert in ds interviews, but as i mentioned \nearlier I&amp;#39;ve already told him what i know about these topics. It seems weird to ask someone the same thing twice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vtrp8", "is_robot_indexable": true, "report_reasons": null, "author": "Woznyyyy", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vtrp8/unusual_interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vtrp8/unusual_interview_question/", "subreddit_subscribers": 913527, "created_utc": 1685461495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm fairly new to working with this type of problem and am hoping to get some advice beyond what I was able to find from searching online.  I'm modeling on a large dataset using random forest. I get strong evaluation scores (R-squared of \\~0.85) on a preliminary run on the training set with no hyperparameter tuning, however, when I introduce cross-validation and hyperparameter tuning, I end up with something like 0.20 for my best model. \n\nMy guess is that this indicates overfitting, but are there any other issues that I may be concerned with? My understanding is that overfitting is much less common in random forest models-- with my dataset being pretty large, would this just indicate that the data are highly noisy? Is there a 'best approach' to assessing/solving this issue?\n\nThanks in advance for any advice more experienced members are able to give.", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High scoring training set, but low scoring with cross-validation. Is this from overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrlbs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685456341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new to working with this type of problem and am hoping to get some advice beyond what I was able to find from searching online.  I&amp;#39;m modeling on a large dataset using random forest. I get strong evaluation scores (R-squared of ~0.85) on a preliminary run on the training set with no hyperparameter tuning, however, when I introduce cross-validation and hyperparameter tuning, I end up with something like 0.20 for my best model. &lt;/p&gt;\n\n&lt;p&gt;My guess is that this indicates overfitting, but are there any other issues that I may be concerned with? My understanding is that overfitting is much less common in random forest models-- with my dataset being pretty large, would this just indicate that the data are highly noisy? Is there a &amp;#39;best approach&amp;#39; to assessing/solving this issue?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any advice more experienced members are able to give.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrlbs", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrlbs/high_scoring_training_set_but_low_scoring_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrlbs/high_scoring_training_set_but_low_scoring_with/", "subreddit_subscribers": 913527, "created_utc": 1685456341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work on a trading desk and right now they've mainly been asking me to do more data engineering and ad hoc analysis work.  There was a past modeling project with some regressions written in R.  I'm basically the only  data scientist/technologist on the trading desk, but I have a lot of flexibility in terms of what I can work, but I would just need to justify in terms of providing business impact.  How do you justify investing time into machine learning/modeling projects to your business stakeholders?", "author_fullname": "t2_g07ne0x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate more machine learning/modeling into my day to day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vd89v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685411893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on a trading desk and right now they&amp;#39;ve mainly been asking me to do more data engineering and ad hoc analysis work.  There was a past modeling project with some regressions written in R.  I&amp;#39;m basically the only  data scientist/technologist on the trading desk, but I have a lot of flexibility in terms of what I can work, but I would just need to justify in terms of providing business impact.  How do you justify investing time into machine learning/modeling projects to your business stakeholders?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vd89v", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Wolf-2439", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vd89v/how_to_integrate_more_machine_learningmodeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vd89v/how_to_integrate_more_machine_learningmodeling/", "subreddit_subscribers": 913527, "created_utc": 1685411893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vle5v8ic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is DataOps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13vro8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is DataOps?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "author_name": "Polyseam", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/HNgpk9IUfK4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@polyseam"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13vro8l", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZV9tDN9N8Oy3pnxB22xIP11rQZvrVyX4a3uRkht-ZQU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685456536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/HNgpk9IUfK4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?auto=webp&amp;v=enabled&amp;s=558ed727ae34d44e61e800d5c68b6d4e3b06c9b5", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8987cee6ecdb05960e5deea7cec8c9c38efe0c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c5ce5990d7fd1f1cf4b4389b41bc453fc017fdb", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/W1qM9D_6cWiZbGrXpiuQqPmrErnOBlTyAJPpGfrgRtw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2be9fc510038f6f9ddb00aac3996a20d0ea37dc", "width": 320, "height": 240}], "variants": {}, "id": "YzEWw94GU1pBBr-CsbqyKbtLUvvhgd5ZFCQ5vQvUDYI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vro8l", "is_robot_indexable": true, "report_reasons": null, "author": "Polyseam", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vro8l/what_is_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/HNgpk9IUfK4", "subreddit_subscribers": 913527, "created_utc": 1685456536.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What is DataOps?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/HNgpk9IUfK4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What is DataOps?\"&gt;&lt;/iframe&gt;", "author_name": "Polyseam", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/HNgpk9IUfK4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@polyseam"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is offering to pay my way to a conference or workshop or similar to advance my skills. Where should I go? \n\nWe're in the healthcare space. I'm sort of a jack-of-all-trades so I'm open to a lot of stuff. Perhaps optimization would be a good area, or generative neural networks. \n\nWhat are the biggest &amp; best overall DS conferences? Healthcare specifically? Is there a good GNN conference/workshop?", "author_fullname": "t2_dw43hwdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What conference should I go to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vbd84", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685406593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is offering to pay my way to a conference or workshop or similar to advance my skills. Where should I go? &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re in the healthcare space. I&amp;#39;m sort of a jack-of-all-trades so I&amp;#39;m open to a lot of stuff. Perhaps optimization would be a good area, or generative neural networks. &lt;/p&gt;\n\n&lt;p&gt;What are the biggest &amp;amp; best overall DS conferences? Healthcare specifically? Is there a good GNN conference/workshop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vbd84", "is_robot_indexable": true, "report_reasons": null, "author": "GlitteringBusiness22", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vbd84/what_conference_should_i_go_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vbd84/what_conference_should_i_go_to/", "subreddit_subscribers": 913527, "created_utc": 1685406593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm needing some extra money and I could certainly use a second income right now. However, I know nothing about freelancing besides that some platforms help with that like fiverr and upwork. Should I simply subscribe in one of these platforms? Should I try to start on linkedin? I'd like to work with the delivery of data analysis projects with AI models or dashboard creation with Power BI (these are my main skills). \n\n&amp;#x200B;\n\nAny tips?", "author_fullname": "t2_ax0lvvdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to start as a freelancer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vc17l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685408446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m needing some extra money and I could certainly use a second income right now. However, I know nothing about freelancing besides that some platforms help with that like fiverr and upwork. Should I simply subscribe in one of these platforms? Should I try to start on linkedin? I&amp;#39;d like to work with the delivery of data analysis projects with AI models or dashboard creation with Power BI (these are my main skills). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vc17l", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Reach818", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vc17l/how_to_start_as_a_freelancer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vc17l/how_to_start_as_a_freelancer/", "subreddit_subscribers": 913527, "created_utc": 1685408446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In past companies where I worked as a statistician (in the healthcare/insurance industry), the data prep and cleaning were handled by separate teams while I focused on modeling and literature research.\n\nIn my current position we have to do everything -- this doesn't seem terribly efficient.\n\nIs this \"jack of all trades/master of none\" job description standard among other data scientists?", "author_fullname": "t2_6cjiszgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better for data prep &amp; modelling to be separate positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vqd25", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685453335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In past companies where I worked as a statistician (in the healthcare/insurance industry), the data prep and cleaning were handled by separate teams while I focused on modeling and literature research.&lt;/p&gt;\n\n&lt;p&gt;In my current position we have to do everything -- this doesn&amp;#39;t seem terribly efficient.&lt;/p&gt;\n\n&lt;p&gt;Is this &amp;quot;jack of all trades/master of none&amp;quot; job description standard among other data scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vqd25", "is_robot_indexable": true, "report_reasons": null, "author": "RobertWF_47", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vqd25/better_for_data_prep_modelling_to_be_separate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vqd25/better_for_data_prep_modelling_to_be_separate/", "subreddit_subscribers": 913527, "created_utc": 1685453335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a student at UC Berkeley studying data science as an undergraduate, preparing for data science internship interviews for the upcoming summer of my junior year. While my coursework has covered the fundamentals, I am keen to explore the subject further to better prepare myself for these interviews.\n\nHere's some background about my current academic standing:\n\n1. Courses: I have completed a course named [DATA 100](https://ds100.org/sp23/) (prerequisites being linear algebra and python) at UC Berkeley that delved into the mathematical foundations of topics like linear and logistic regression, and also taught me substantial coding using the Pandas library and SQL. Additionally, I am planning to take a dedicated course on probability theory in the fall and another course on machine learning/inference later.\n2. Interests: I am keen to learn more about various statistical/ML techniques used in the field. Gaining knowledge that might give me an edge in internship interviews and bolster my probability/statistical understanding is my primary goal.\n\nHere are some areas I'd love to explore further:\n\n1. Advanced machine learning algorithms: Given that I'll be studying machine learning/inference in the future, I'd love to get a head start on this. Any books that dive deep into this topic and their practical applications would be appreciated.\n2. Advanced statistics: I am looking to strengthen my grasp of advanced statistical methods commonly used in data science.\n3. Real-world applications: Books that demonstrate real-world data science projects or case studies, showing how data science principles are applied across different industries, would be very helpful.\n4. Interview prep: I would also appreciate any recommendations for books or resources specifically targeted toward preparing for data science internship interviews.\n\nI'm looking for resources that are comprehensive, practical, and able to offer both theoretical understanding and real-world application. Please share your recommendations below, whether they're textbooks, guidebooks, or resources that have influenced your own data science journey.\n\nI want to dedicate this summer to preparing for next year, so your insights and experiences are greatly appreciated. Thank you in advance for your time and help!\n\n**TL;DR**: I'm a junior data science student preparing for data science internship interviews. Seeking book or any other resource recommendations to deepen my understanding of ML algorithms, advanced statistics, real-world data science applications, and interview preparation. Your insights and experiences are greatly appreciated!", "author_fullname": "t2_2itz5ka1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Book Recommendations (or any other resources) for cracking the Data Science Internship Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vjnwx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685433216.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685432264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a student at UC Berkeley studying data science as an undergraduate, preparing for data science internship interviews for the upcoming summer of my junior year. While my coursework has covered the fundamentals, I am keen to explore the subject further to better prepare myself for these interviews.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some background about my current academic standing:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Courses: I have completed a course named &lt;a href=\"https://ds100.org/sp23/\"&gt;DATA 100&lt;/a&gt; (prerequisites being linear algebra and python) at UC Berkeley that delved into the mathematical foundations of topics like linear and logistic regression, and also taught me substantial coding using the Pandas library and SQL. Additionally, I am planning to take a dedicated course on probability theory in the fall and another course on machine learning/inference later.&lt;/li&gt;\n&lt;li&gt;Interests: I am keen to learn more about various statistical/ML techniques used in the field. Gaining knowledge that might give me an edge in internship interviews and bolster my probability/statistical understanding is my primary goal.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here are some areas I&amp;#39;d love to explore further:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Advanced machine learning algorithms: Given that I&amp;#39;ll be studying machine learning/inference in the future, I&amp;#39;d love to get a head start on this. Any books that dive deep into this topic and their practical applications would be appreciated.&lt;/li&gt;\n&lt;li&gt;Advanced statistics: I am looking to strengthen my grasp of advanced statistical methods commonly used in data science.&lt;/li&gt;\n&lt;li&gt;Real-world applications: Books that demonstrate real-world data science projects or case studies, showing how data science principles are applied across different industries, would be very helpful.&lt;/li&gt;\n&lt;li&gt;Interview prep: I would also appreciate any recommendations for books or resources specifically targeted toward preparing for data science internship interviews.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m looking for resources that are comprehensive, practical, and able to offer both theoretical understanding and real-world application. Please share your recommendations below, whether they&amp;#39;re textbooks, guidebooks, or resources that have influenced your own data science journey.&lt;/p&gt;\n\n&lt;p&gt;I want to dedicate this summer to preparing for next year, so your insights and experiences are greatly appreciated. Thank you in advance for your time and help!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: I&amp;#39;m a junior data science student preparing for data science internship interviews. Seeking book or any other resource recommendations to deepen my understanding of ML algorithms, advanced statistics, real-world data science applications, and interview preparation. Your insights and experiences are greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vjnwx", "is_robot_indexable": true, "report_reasons": null, "author": "ejderIMP", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vjnwx/seeking_book_recommendations_or_any_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vjnwx/seeking_book_recommendations_or_any_other/", "subreddit_subscribers": 913527, "created_utc": 1685432264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There dataset is large enough. Very mild correlation.", "author_fullname": "t2_9y42hl3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a prediction model where there is negligible relation between the target variable and independent variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrk0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685456253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There dataset is large enough. Very mild correlation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrk0x", "is_robot_indexable": true, "report_reasons": null, "author": "ilovekungfuu", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrk0x/how_to_build_a_prediction_model_where_there_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrk0x/how_to_build_a_prediction_model_where_there_is/", "subreddit_subscribers": 913527, "created_utc": 1685456253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7tpw2nbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing Jupyter Notebooks from localhost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13vyhdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K0s5acGmBFpLQath3rISaAgo6tS1oIHws2nuzNZT76s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685472425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pinggy.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?auto=webp&amp;v=enabled&amp;s=8879d7f15715c0622e0916aaedca8d2afb69f727", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=422f020c501c2ef89b12b705aea313e1c6aa151a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7f4914bd9db1d5ef86db25c39502d52bd1582f2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a10f495be6e4162572b9685897b8c12d60c8ab93", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ca00afdc443d902a1c8bb4d489402bd62c14172", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95c4a1af46b911cd76606123fb71db7243aca521", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/p9CqsaWnlAbfalnht2WohaSHPFk8s6P2Qkimj7dRrsQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c666b63be723ebba4c1c2cd10de2350390f1c66", "width": 1080, "height": 607}], "variants": {}, "id": "OGdm_ujqca1mKitGu5akhCopk6oU69W93sJmL_kNI38"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vyhdz", "is_robot_indexable": true, "report_reasons": null, "author": "bishakhghosh_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vyhdz/sharing_jupyter_notebooks_from_localhost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pinggy.io/blog/share_jupyter_notebook_from_localhost/", "subreddit_subscribers": 913527, "created_utc": 1685472425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I'm using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I'm trying to go through some troubleshooting steps to see if I can improve things.\n\nWhen looking at histograms and box plots, I noticed that many of my numeric features and my target aren't normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?\n\nAny additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on handling skewed data in a random forest model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vujck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685465213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685463274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working on my first major project in my DS role and am running into trouble. I have a decently large dataset with about 30 features that I&amp;#39;m using RandomForestRegressor with. After doing a stratified shuffle split based on an unbalanced feature, removing a few major outliers, one hot encoding my categorical features, and tuning my hyperparameters with GridSearchCV, my best R-squared value is very low (about 0.20). Preliminary projects suggest that there should be a much stronger relationship here, so I&amp;#39;m trying to go through some troubleshooting steps to see if I can improve things.&lt;/p&gt;\n\n&lt;p&gt;When looking at histograms and box plots, I noticed that many of my numeric features and my target aren&amp;#39;t normally distributed, and are instead heavily skewed. How does this impact my random forest model? Should I do some sort of transformation on these columns? If so, how will this impact my ability to get accurate estimations from my model later on?&lt;/p&gt;\n\n&lt;p&gt;Any additional troubleshooting advice is also welcome. Thanks a ton in advance for any thoughts here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vujck", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vujck/thoughts_on_handling_skewed_data_in_a_random/", "subreddit_subscribers": 913527, "created_utc": 1685463274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Want to learn more about preprocessing techniques for natural language? Check out [this tutorial on preprocessing techniques](https://medium.com/@oieivind/6-pre-processing-techniques-to-use-for-your-information-retrieval-system-f9baa9e4dd12)!", "author_fullname": "t2_9ssuhjvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn about preprocessing techniques for natural language!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13w357k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to learn more about preprocessing techniques for natural language? Check out &lt;a href=\"https://medium.com/@oieivind/6-pre-processing-techniques-to-use-for-your-information-retrieval-system-f9baa9e4dd12\"&gt;this tutorial on preprocessing techniques&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-1Gz4nOf_IuyqFg3XH1Oj3rvBY8Ctc2bAhBLECOwZe8.jpg?auto=webp&amp;v=enabled&amp;s=63ed7fb63df3b3ae7ffe13261636a0f35976dbb3", "width": 399, "height": 222}, "resolutions": [{"url": "https://external-preview.redd.it/-1Gz4nOf_IuyqFg3XH1Oj3rvBY8Ctc2bAhBLECOwZe8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82d616307051f526143df5e131c28e7b29467463", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/-1Gz4nOf_IuyqFg3XH1Oj3rvBY8Ctc2bAhBLECOwZe8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1e14a779e4e3cd2056aa924dd22295accc59b47", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/-1Gz4nOf_IuyqFg3XH1Oj3rvBY8Ctc2bAhBLECOwZe8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4079a820e2364d7e22123f45f5ac6ae626097c9f", "width": 320, "height": 178}], "variants": {}, "id": "sYeRHjbAAnkndap5XtpuzATsMk7ASRupcJZ7pIWJdeE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w357k", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Highlight_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w357k/learn_about_preprocessing_techniques_for_natural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w357k/learn_about_preprocessing_techniques_for_natural/", "subreddit_subscribers": 913527, "created_utc": 1685483166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A few years ago my brother started a city skate wear clothing brand and made some decent money. He\u2019s not very organized and he lost all the momentum after two years. He\u2019d much rather focus on the creative side of the brand, instead of the business responsibilities. I have time now and will be helping him restart the brand. I have background education in data science and want to know what DS skills I can apply to help restart the company/make $$$. I see a lot of potential in marketing. Any thoughts?", "author_fullname": "t2_a1p3e02j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS techniques for small clothing brand", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13w334m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few years ago my brother started a city skate wear clothing brand and made some decent money. He\u2019s not very organized and he lost all the momentum after two years. He\u2019d much rather focus on the creative side of the brand, instead of the business responsibilities. I have time now and will be helping him restart the brand. I have background education in data science and want to know what DS skills I can apply to help restart the company/make $$$. I see a lot of potential in marketing. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w334m", "is_robot_indexable": true, "report_reasons": null, "author": "Tall-Artichoke-3561", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w334m/ds_techniques_for_small_clothing_brand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w334m/ds_techniques_for_small_clothing_brand/", "subreddit_subscribers": 913527, "created_utc": 1685483035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crops prediction with Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": true, "media_metadata": {"7srhy44w033b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/7srhy44w033b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02f3694cc239878ccf2a217aec626bb365be297"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/7srhy44w033b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c809c138766c4846e3956ee6e307f091cdbe5e62"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/7srhy44w033b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0914ed50006928f281a06956dd5c47453a937ef8"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/7srhy44w033b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96189182f829d41bb6d914ee482dfc4ee4e15ad6"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/7srhy44w033b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8779fcf97744747a8179cf975c729770e88266"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/7srhy44w033b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd037219cb6c71cdeb7f9024cf9db81157dba217"}], "s": {"y": 902, "x": 2500, "u": "https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c"}, "id": "7srhy44w033b1"}}, "name": "t3_13w3g3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2aTLJHuqZnjlHyX0Z1XFj9PDRRtHcyPFuhpMeYRg5xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685483880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Linear Regression to predict the production of crops, the results are in plot bellow. Is the model reasonable or is it overfitting?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c\"&gt;https://preview.redd.it/7srhy44w033b1.png?width=2500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2c0bff13805dd3ba0da2b77d167e0ef58b37967c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13w3g3h", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13w3g3h/crops_prediction_with_linear_regression/", "subreddit_subscribers": 913527, "created_utc": 1685483880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We get dozens and dozens of file patterns that are VERY consistent coming in that have to be cleaned up and reformatted to .csv files which we compare against the data in the database to see if it needs to be updated or if its outdated. Once its been cleaned we load it into the database and all is good, but we are repeating the same process over and over and I want ways to automate the pattern matching.\n\nThe challenge is that each of these formats are quite large but almost always one of about 11 different formats and I'm repeating the same cleaning steps each time. What is a DataScience step, tool, function or process to create a \\`pattern\\` or \\`map\\` that python can use to recognize \\`oh hey random\\_dirty\\_file\\_00n format matches clean\\_data\\_file\\_00n format &gt;90%\\` so lets reformat it.\n\nWe used something like this before years ago using MongoDB where they created a large script that compared the format and layout of a .csv, .txt, .tsv, .xml file that were 95% the same from customer exports, database exports, web scraping, data migrations or whatever. Isn't there a RL or SL 'thing' for this?\n\n\\`\\`\\`\n\n\"if this \\`dirty\\_data\\_pattern\\_001\\`:\n\nthen reformat to \\`clean\\_data\\_pattern\\_001\\`\"\n\n\\`\\`\\`\n\nMy notes just mention it was a mapping or formatting script but don't have access to that code from 7 years ago.\n\nPerhaps I'm overlooking or don't have the experience to know which but I've used\n\n1. Python regex\n2. MongoDB integrated with python\n3. Python \\`map()\\` function\n4. \\[Python NLTK functions\\]([https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/](https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/))\n5. Python scripts using \\`sklearn.preprocessing\\` like \\[[Jeremyjordan.me](https://Jeremyjordan.me)\\]([https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/](https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/)) using script like this works for words but not whole documents\n\nI hope this script below is formatted correctly but its close to what we use for individual word matching.\n\nEdit: for some reason I had to click inline code, then code block and the 'inserting spaces doesn't work' it only works when putting the code in \"triple marks and doing \\`code block\\` and doing \\`inline code\\`\" but it seems to be showing correctly now\n\n\\`\\`\\`\n\n    male_terms = [\"male\", \"m\", \"mal\", \"msle\", \"malr\", \"mail\", \"make\", \"cis male\", \"man\", \"maile\", \"male (cis)\", \"cis man\"]\n    \n    female_terms = [\"female\", \"f\", \"woman\", \"femake\", \"femaile\", \"femake\", \"cis female\", \"cis-female/femme\", \"female (cis)\", \"femail\", \"cis woman\"]\n    \n    def clean_gender(response):\n        if response.lower().rstrip() in male_terms:\n            return \"Male\"\n        elif response.lower().rstrip() in female_terms:\n            return \"Female\"\n        else:\n            return \"Other\"\n    \n    df['Gender'] = df[\"Gender\"].apply(lambda x: clean_gender(x))\n\n\\`\\`\\`", "author_fullname": "t2_cbz254uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the data science process or best practices for Reinforcement Learning RL or Supervised Learning SL method to map `dirty_data_pattern_001` to `clean_data_pattern_001` is this a tensor flow or map function?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vzawy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685474554.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685474214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We get dozens and dozens of file patterns that are VERY consistent coming in that have to be cleaned up and reformatted to .csv files which we compare against the data in the database to see if it needs to be updated or if its outdated. Once its been cleaned we load it into the database and all is good, but we are repeating the same process over and over and I want ways to automate the pattern matching.&lt;/p&gt;\n\n&lt;p&gt;The challenge is that each of these formats are quite large but almost always one of about 11 different formats and I&amp;#39;m repeating the same cleaning steps each time. What is a DataScience step, tool, function or process to create a `pattern` or `map` that python can use to recognize `oh hey random_dirty_file_00n format matches clean_data_file_00n format &amp;gt;90%` so lets reformat it.&lt;/p&gt;\n\n&lt;p&gt;We used something like this before years ago using MongoDB where they created a large script that compared the format and layout of a .csv, .txt, .tsv, .xml file that were 95% the same from customer exports, database exports, web scraping, data migrations or whatever. Isn&amp;#39;t there a RL or SL &amp;#39;thing&amp;#39; for this?&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;if this `dirty_data_pattern_001`:&lt;/p&gt;\n\n&lt;p&gt;then reformat to `clean_data_pattern_001`&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;My notes just mention it was a mapping or formatting script but don&amp;#39;t have access to that code from 7 years ago.&lt;/p&gt;\n\n&lt;p&gt;Perhaps I&amp;#39;m overlooking or don&amp;#39;t have the experience to know which but I&amp;#39;ve used&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python regex&lt;/li&gt;\n&lt;li&gt;MongoDB integrated with python&lt;/li&gt;\n&lt;li&gt;Python `map()` function&lt;/li&gt;\n&lt;li&gt;[Python NLTK functions](&lt;a href=\"https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/\"&gt;https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/&lt;/a&gt;)&lt;/li&gt;\n&lt;li&gt;Python scripts using `sklearn.preprocessing` like [&lt;a href=\"https://Jeremyjordan.me\"&gt;Jeremyjordan.me&lt;/a&gt;](&lt;a href=\"https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/\"&gt;https://www.jeremyjordan.me/preparing-data-for-a-machine-learning-model/&lt;/a&gt;) using script like this works for words but not whole documents&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I hope this script below is formatted correctly but its close to what we use for individual word matching.&lt;/p&gt;\n\n&lt;p&gt;Edit: for some reason I had to click inline code, then code block and the &amp;#39;inserting spaces doesn&amp;#39;t work&amp;#39; it only works when putting the code in &amp;quot;triple marks and doing `code block` and doing `inline code`&amp;quot; but it seems to be showing correctly now&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;male_terms = [&amp;quot;male&amp;quot;, &amp;quot;m&amp;quot;, &amp;quot;mal&amp;quot;, &amp;quot;msle&amp;quot;, &amp;quot;malr&amp;quot;, &amp;quot;mail&amp;quot;, &amp;quot;make&amp;quot;, &amp;quot;cis male&amp;quot;, &amp;quot;man&amp;quot;, &amp;quot;maile&amp;quot;, &amp;quot;male (cis)&amp;quot;, &amp;quot;cis man&amp;quot;]\n\nfemale_terms = [&amp;quot;female&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;woman&amp;quot;, &amp;quot;femake&amp;quot;, &amp;quot;femaile&amp;quot;, &amp;quot;femake&amp;quot;, &amp;quot;cis female&amp;quot;, &amp;quot;cis-female/femme&amp;quot;, &amp;quot;female (cis)&amp;quot;, &amp;quot;femail&amp;quot;, &amp;quot;cis woman&amp;quot;]\n\ndef clean_gender(response):\n    if response.lower().rstrip() in male_terms:\n        return &amp;quot;Male&amp;quot;\n    elif response.lower().rstrip() in female_terms:\n        return &amp;quot;Female&amp;quot;\n    else:\n        return &amp;quot;Other&amp;quot;\n\ndf[&amp;#39;Gender&amp;#39;] = df[&amp;quot;Gender&amp;quot;].apply(lambda x: clean_gender(x))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kVnBrWGTrbn8IcPl7jUrXtEdtv9OiF6cB5yvHuhS0DQ.jpg?auto=webp&amp;v=enabled&amp;s=3d1e12b29962c29b283f923a8285f732781426f8", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/kVnBrWGTrbn8IcPl7jUrXtEdtv9OiF6cB5yvHuhS0DQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82c07b6e523f5002d402aeb9b881bb14b774c110", "width": 108, "height": 108}], "variants": {}, "id": "LrwawBOrEFhMR9Nbh20vF8BGtS6Co_BAR39WQmpv-34"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vzawy", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Win_3457", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vzawy/what_is_the_data_science_process_or_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vzawy/what_is_the_data_science_process_or_best/", "subreddit_subscribers": 913527, "created_utc": 1685474214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  \n\n\nThe ratings at my company are as follows  \n1 - Did not meet expectations  \n2 - Met some expectations  \n3 - Met expectations  \n4 - Exceeded expecations  \n5 - Went over and beyond expectations  \n\n\nThe reasons given for my rating were as follows:  \nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March '23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  \n\n\nWhile discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  \n\n\nOn a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  \n\n\nThe feedback from other stakeholders was mostly positive, citing things like I'm curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  \n\n\nDuring the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  \n\n\nIn our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  \n\n\nTLDR:\n\nTo summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager's dissatisfaction, as I believe this issue may arise again in my next review.  \nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. \n\nWhile I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don't want to quit without an other job lined up, given the situation of the current market. There's been no talk of a PIP, so I guess I'll be safe for the next 6 months. However, I'm not sure how much of a big difference I can make  \n\n\nAny suggestions would be greatly appreciated.", "author_fullname": "t2_7n4roggm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a bad performance review - Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vxim7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday, I had my performance review with my manager and received a 2.5 rating, which will be calibrated to a 3. In my previous reviews, I received a 4 (Exceeded expectations) and a 3.5 (Met expectations +), which will remain a 3 on my profile. I work as a Data Scientist at a well-paying company in India and have almost 2 years of experience.  &lt;/p&gt;\n\n&lt;p&gt;The ratings at my company are as follows&lt;br/&gt;\n1 - Did not meet expectations&lt;br/&gt;\n2 - Met some expectations&lt;br/&gt;\n3 - Met expectations&lt;br/&gt;\n4 - Exceeded expecations&lt;br/&gt;\n5 - Went over and beyond expectations  &lt;/p&gt;\n\n&lt;p&gt;The reasons given for my rating were as follows:&lt;br/&gt;\nI faced a challenge during the execution of a project and reached out to my manager for help after attempting to solve it myself for a couple of days. Due to communication gaps, our discussions on the approach took some time, and I admit I should have documented things better to facilitate faster resolution. This resulted in a delay of 2-3 weeks. Eventually, we agreed on a solution, and I managed to deliver the project before the March &amp;#39;23 deadline. My manager mentioned that I should have been able to figure things out independently, as I had done in a previous instance.  &lt;/p&gt;\n\n&lt;p&gt;While discussing some project details with external stakeholders, I encountered a question that confused me. I informed them that I would provide an answer after reviewing the code. My manager pointed out that I should have been prepared and already had the answer. I agree that I should have been more proactive in my preparation.  &lt;/p&gt;\n\n&lt;p&gt;On a couple of occasions, I made small mistakes or overlooked corner cases when calculating metrics and reporting them in meetings. As soon as I realized these errors, I promptly informed all relevant stakeholders in the project.  &lt;/p&gt;\n\n&lt;p&gt;The feedback from other stakeholders was mostly positive, citing things like I&amp;#39;m curious in nature, dive very deep into a problem ask a lot of questions which are very relevant, etc. A few points of improvement were basically what was listed above, need to get my analysis correct in the first attempt  &lt;/p&gt;\n\n&lt;p&gt;During the review meeting, I discussed areas for improvement in detail. However, when I sought clarification on a few points not mentioned above, my manager did not provide clear answers. He later advised me not to take it personally and to view the feedback in the right spirit.  &lt;/p&gt;\n\n&lt;p&gt;In our monthly 1:1 meetings, my manager has emphasized the need to improve my execution speed and take on more challenging tasks. While he sometimes compliments my work, I explained that I am already giving my best despite working on multiple parallel projects, which may not be sufficient compared to my initial projects.  &lt;/p&gt;\n\n&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;To summarize, despite my dedicated efforts, including working extra hours and weekends, I received a less-than-satisfactory performance review. Some of the reasons provided were unclear to me. I have made minor mistakes, but nothing major (at least from my perspective). This experience has made it challenging for me to stay motivated and has led me to question my suitability for the role. I am also unsure how to seek clarification on future tasks without risking my manager&amp;#39;s dissatisfaction, as I believe this issue may arise again in my next review.&lt;br/&gt;\nI am contemplating whether it is worth going above and beyond to prove myself or if I should focus on updating my resume, start working on leetcode/data science questions, basically exploring other opportunities. &lt;/p&gt;\n\n&lt;p&gt;While I definitely do not enjoy working with my manager here (felt this way since the disagreement about the project), I certainly don&amp;#39;t want to quit without an other job lined up, given the situation of the current market. There&amp;#39;s been no talk of a PIP, so I guess I&amp;#39;ll be safe for the next 6 months. However, I&amp;#39;m not sure how much of a big difference I can make  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vxim7", "is_robot_indexable": true, "report_reasons": null, "author": "Public-Drag1602", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vxim7/had_a_bad_performance_review_advice_needed/", "subreddit_subscribers": 913527, "created_utc": 1685470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).\n\nThe usual estimator is mean(Y)\\_{t} - mean(Y)\\_{c}. This is the same as fitting the model \n\nY = b\\_0 + b\\_t x Indicator.\n\nb\\_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. \n\nNow my question is why don't we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b\\_t without introducing bias. To me it seems like a no-brainer. Any catch here?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_dx4dz5s2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we use regression to estimate treatment effect in randomized experiment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vwdzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685467555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s just assume the simplest case where we have a completely randomized experiment. We want to estimate the treatment effect on revenue (Y).&lt;/p&gt;\n\n&lt;p&gt;The usual estimator is mean(Y)_{t} - mean(Y)_{c}. This is the same as fitting the model &lt;/p&gt;\n\n&lt;p&gt;Y = b_0 + b_t x Indicator.&lt;/p&gt;\n\n&lt;p&gt;b_t is unbiased because of assumption completely randomized. The error is uncorrelated with the treatment assignment. &lt;/p&gt;\n\n&lt;p&gt;Now my question is why don&amp;#39;t we add other independent variables to the model? So long as the variables are 1. uncorrelated with the treatment assignment, 2. greatly reduced residuals, 3, not a collider, adding variables to improve the fit of the model should reduce the variance of the estimator b_t without introducing bias. To me it seems like a no-brainer. Any catch here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vwdzd", "is_robot_indexable": true, "report_reasons": null, "author": "aggis_husky", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vwdzd/should_we_use_regression_to_estimate_treatment/", "subreddit_subscribers": 913527, "created_utc": 1685467555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently started a position as analytics manager at a small non-tech company. This is my first true leadership role and I have a lot of leeway as far as what direction the company should take to do the whole \u201cdata thing.\u201d In my first couple months I want to map out systems, data collection/movement/schema, departmental workflows, existing reports\u2014 your basic lay of the land type of stuff. Does anyone have advice about how to approach this processes strategically, tools/methods recommended to stay organized or general guidance for how to think about this? Thanks,", "author_fullname": "t2_7fhzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onboarding/Roadmapping Advice for New Analytics Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vscrb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685458188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently started a position as analytics manager at a small non-tech company. This is my first true leadership role and I have a lot of leeway as far as what direction the company should take to do the whole \u201cdata thing.\u201d In my first couple months I want to map out systems, data collection/movement/schema, departmental workflows, existing reports\u2014 your basic lay of the land type of stuff. Does anyone have advice about how to approach this processes strategically, tools/methods recommended to stay organized or general guidance for how to think about this? Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vscrb", "is_robot_indexable": true, "report_reasons": null, "author": "whispertoke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vscrb/onboardingroadmapping_advice_for_new_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vscrb/onboardingroadmapping_advice_for_new_analytics/", "subreddit_subscribers": 913527, "created_utc": 1685458188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just came up on the year mark for my first data scientist role and I\u2019m thinking about what to do about my career long-term.\n\nSome context: I work in finance in a data science team that\u2019s heavily focused on experimental design and causal inference. It\u2019s a bit of a weird role because my job is more around enforcing standards for experimental design and measurement, vetting and analyzing causal inference use cases and scoping work for novel methods in causal inference and measurement. I wrote virtually no sql in my job.\n\nThe good:\n- get some really good experience in designing good experiments and auditing the execution of the experimental design from end to end\n- soft skills development. Experimental designs need to be socialized which requires a lot of listening to precisely understand the business problem and communicating how the experimental design answers the business problem\n- freedom to explore and work on projects that use novel methods (likely won\u2019t go anywhere besides impressing my boss but good experience nonetheless)\n- great mentorship, my manager is a PhD statistician who has a ton of exp in experimental design and the director of the team is a PhD statistician as well so the value of the work we do is well understood and within the business\n- recognizable name brand on my resume \n- good pay for early career role in a non-tech industry\n\nThe bad:\n- no sql exposure, all the data comes from other analysts\n- no dashboard dev work\n- no opportunities for modeling in the predictive sense (we do use statistical modeling techniques but they\u2019re typically in service of causal inference work which is quite different than traditional modeling)\n- no coding best practices (no one uses git, we don\u2019t have a repo, just notebooks sent over email)\n- skill ceiling in experimental design. Our problems aren\u2019t as complicated and interesting as what\u2019s encountered in the tech industry\n\nIdeally I\u2019d like to have a long career in the field. I love experimental design (have a prior PhD in engineering and worked in my industry for a couple years before becoming a DS) and causal inference, it\u2019s a fun field. \n\nMy goals are to get a role in the tech industry and work on more interesting problems either within or adjacent to my sub field. I do some pro-bono consulting work for nonprofits on the side that give me more exposure to modeling but obviously the strength of this is limited relative to the strength of doing work problems in this.\n\nI\u2019m worried however that the negatives of my role and specializing is really going to limit my career growth and an not sure if I should spend time and find opportunities to shore these up. Would love to hear from others who have experience on what they think.", "author_fullname": "t2_9plbo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I specialize or look towards generalizing as an early career data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vrgd6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685455994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just came up on the year mark for my first data scientist role and I\u2019m thinking about what to do about my career long-term.&lt;/p&gt;\n\n&lt;p&gt;Some context: I work in finance in a data science team that\u2019s heavily focused on experimental design and causal inference. It\u2019s a bit of a weird role because my job is more around enforcing standards for experimental design and measurement, vetting and analyzing causal inference use cases and scoping work for novel methods in causal inference and measurement. I wrote virtually no sql in my job.&lt;/p&gt;\n\n&lt;p&gt;The good:\n- get some really good experience in designing good experiments and auditing the execution of the experimental design from end to end\n- soft skills development. Experimental designs need to be socialized which requires a lot of listening to precisely understand the business problem and communicating how the experimental design answers the business problem\n- freedom to explore and work on projects that use novel methods (likely won\u2019t go anywhere besides impressing my boss but good experience nonetheless)\n- great mentorship, my manager is a PhD statistician who has a ton of exp in experimental design and the director of the team is a PhD statistician as well so the value of the work we do is well understood and within the business\n- recognizable name brand on my resume \n- good pay for early career role in a non-tech industry&lt;/p&gt;\n\n&lt;p&gt;The bad:\n- no sql exposure, all the data comes from other analysts\n- no dashboard dev work\n- no opportunities for modeling in the predictive sense (we do use statistical modeling techniques but they\u2019re typically in service of causal inference work which is quite different than traditional modeling)\n- no coding best practices (no one uses git, we don\u2019t have a repo, just notebooks sent over email)\n- skill ceiling in experimental design. Our problems aren\u2019t as complicated and interesting as what\u2019s encountered in the tech industry&lt;/p&gt;\n\n&lt;p&gt;Ideally I\u2019d like to have a long career in the field. I love experimental design (have a prior PhD in engineering and worked in my industry for a couple years before becoming a DS) and causal inference, it\u2019s a fun field. &lt;/p&gt;\n\n&lt;p&gt;My goals are to get a role in the tech industry and work on more interesting problems either within or adjacent to my sub field. I do some pro-bono consulting work for nonprofits on the side that give me more exposure to modeling but obviously the strength of this is limited relative to the strength of doing work problems in this.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried however that the negatives of my role and specializing is really going to limit my career growth and an not sure if I should spend time and find opportunities to shore these up. Would love to hear from others who have experience on what they think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vrgd6", "is_robot_indexable": true, "report_reasons": null, "author": "ColickingSeahorse", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vrgd6/should_i_specialize_or_look_towards_generalizing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vrgd6/should_i_specialize_or_look_towards_generalizing/", "subreddit_subscribers": 913527, "created_utc": 1685455994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do I Check If There Exists a Pattern in My Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vj4h3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7ilybfvp", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnmachinelearning", "selftext": "Here is my understanding of supervised ML models: You use one of the many algorithms to train a model to learn the function that maps features to labels. But this is only possible if there is indeed some relationship to be learned in the data, if there exists no meaningful relationship between the features and labels then the models will keep underperforming.\n\nIs there a prior step I can take, before trying to fit my data to some algorithms, to determine if there indeed exists a relationship in the data?\n\nWhat I'm worried about is if I don't know firsthand whether or not there is a relationship to be learned, then I might waste time trying different algorithms thinking they are just underperforming because they are not the right choice, while actually, it is because there just isn't any pattern there.", "author_fullname": "t2_7ilybfvp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do I Check If There Exists a Pattern in My Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnmachinelearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13viv73", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685430387.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685429377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is my understanding of supervised ML models: You use one of the many algorithms to train a model to learn the function that maps features to labels. But this is only possible if there is indeed some relationship to be learned in the data, if there exists no meaningful relationship between the features and labels then the models will keep underperforming.&lt;/p&gt;\n\n&lt;p&gt;Is there a prior step I can take, before trying to fit my data to some algorithms, to determine if there indeed exists a relationship in the data?&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m worried about is if I don&amp;#39;t know firsthand whether or not there is a relationship to be learned, then I might waste time trying different algorithms thinking they are just underperforming because they are not the right choice, while actually, it is because there just isn&amp;#39;t any pattern there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3cqa1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13viv73", "is_robot_indexable": true, "report_reasons": null, "author": "ozian20", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnmachinelearning/comments/13viv73/how_do_i_check_if_there_exists_a_pattern_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnmachinelearning/comments/13viv73/how_do_i_check_if_there_exists_a_pattern_in_my/", "subreddit_subscribers": 301777, "created_utc": 1685429377.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685430292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnmachinelearning/comments/13viv73/how_do_i_check_if_there_exists_a_pattern_in_my/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vj4h3", "is_robot_indexable": true, "report_reasons": null, "author": "ozian20", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13viv73", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vj4h3/how_do_i_check_if_there_exists_a_pattern_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnmachinelearning/comments/13viv73/how_do_i_check_if_there_exists_a_pattern_in_my/", "subreddit_subscribers": 913527, "created_utc": 1685430292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks,\n\nI'm looking for an advice on what project to choose through which I can have good chances for getting a job after I graduate. \n\nI'm an international student studying MSc datascience in London and it's my final semester where I have do to dissertation. I have some good experience with NLP but I also have some knowledge of Computer vision. I was thinking of starting to work on transcription project(Speech to text) and there's another idea in my mind which might be a little complex is Translating the transcripted text in realtime which basically means for instance if there's a video of speaker, speaking in English the captions/subtitles will appear as translated to maybe some other language like French, Spanish or any other. I'll rate my machine learning skills as 4/10.\n\nHere's the project I did in my bachelor\u2019s it was a desktop application developed using PyQt5, NLP and Computer Vision. \n\nhttps://github.com/wings-cofandt/Final-Year-Project\n\n\nBased on the above scenario could you please give me some valuable advices on how to start working on something that will atleast have good chances of getting appreciated in the eyes of recruiters and ofcourse my supervisor.", "author_fullname": "t2_8ekexage", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice needed regarding ML/DL Project ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vzkh8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685474816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for an advice on what project to choose through which I can have good chances for getting a job after I graduate. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an international student studying MSc datascience in London and it&amp;#39;s my final semester where I have do to dissertation. I have some good experience with NLP but I also have some knowledge of Computer vision. I was thinking of starting to work on transcription project(Speech to text) and there&amp;#39;s another idea in my mind which might be a little complex is Translating the transcripted text in realtime which basically means for instance if there&amp;#39;s a video of speaker, speaking in English the captions/subtitles will appear as translated to maybe some other language like French, Spanish or any other. I&amp;#39;ll rate my machine learning skills as 4/10.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the project I did in my bachelor\u2019s it was a desktop application developed using PyQt5, NLP and Computer Vision. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/wings-cofandt/Final-Year-Project\"&gt;https://github.com/wings-cofandt/Final-Year-Project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Based on the above scenario could you please give me some valuable advices on how to start working on something that will atleast have good chances of getting appreciated in the eyes of recruiters and ofcourse my supervisor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?auto=webp&amp;v=enabled&amp;s=d630397efeeaebff5b3bc896da16cd72ca8ede68", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e791a127903900c04020e8bc129c92712c6329e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d9d7da8192722fa477af12ef20537fe38f665c6", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bf909e436cc902102cf6b60c5ab645fae32f9b0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c66795fa36e7600f71474030a3b5362512863aa2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=840c5746cd57d2af74b828c12f533ee8b760a196", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/M4app6OjtLVMD0Evuu3zVq2F6mSmmITR8dr4uzC7gCM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b97444111acfb45a8033a366d2b678eb23b72a3a", "width": 1080, "height": 540}], "variants": {}, "id": "CqommJ5TdpIFDFB607m3RiArZJPNOWq-xMw4pX1Lp00"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vzkh8", "is_robot_indexable": true, "report_reasons": null, "author": "Hungry_Show_201", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vzkh8/advice_needed_regarding_mldl_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vzkh8/advice_needed_regarding_mldl_project_ideas/", "subreddit_subscribers": 913527, "created_utc": 1685474816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in an ML/CV team and would like to learn more about how ML/CV/DS teams manage their projects within the team. we currently use Kanban, but it has been somewhat inefficient, as it focuses too much on the stages of a product and less on the research and development processes...\n\nHow does your team organize and manage the flow of projects?", "author_fullname": "t2_9s1yrp6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team/squad/tribe organize their projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vw57e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685466985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an ML/CV team and would like to learn more about how ML/CV/DS teams manage their projects within the team. we currently use Kanban, but it has been somewhat inefficient, as it focuses too much on the stages of a product and less on the research and development processes...&lt;/p&gt;\n\n&lt;p&gt;How does your team organize and manage the flow of projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vw57e", "is_robot_indexable": true, "report_reasons": null, "author": "ddponwheels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vw57e/how_does_your_teamsquadtribe_organize_their/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vw57e/how_does_your_teamsquadtribe_organize_their/", "subreddit_subscribers": 913527, "created_utc": 1685466985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " In this tutorial, I will show you how to use Langchain and Streamlit to analyze CSV files,   \n[https://medium.com/p/5cb8a0db87e0](https://medium.com/p/5cb8a0db87e0)", "author_fullname": "t2_icilc2wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Talk To Your CSV: How To Visualize Your Data With Langchain And Streamlit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13vu9ae", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685462633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this tutorial, I will show you how to use Langchain and Streamlit to analyze CSV files,&lt;br/&gt;\n&lt;a href=\"https://medium.com/p/5cb8a0db87e0\"&gt;https://medium.com/p/5cb8a0db87e0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?auto=webp&amp;v=enabled&amp;s=32c1b1133dc62000200bfc6b1b8216eba1ffdf97", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=785806541acdd2858c9ca646a831f3aabfc0ac91", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d7c397f534bf82fe3f9455142772691f89f4d75", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3af444e3ec657377aa83f8d94fc511de632de8c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=508f0daebaa6a3f19a3d4cb97f78aec23c34ec06", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0b7e14cc509753ae27120d5b8517a6271fdbe2a", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/z52Rq_YsW73kGtKsZm-g6S3gGYUgQbrPGwRujH2CG-Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21db52550dadd1db10f8eb6084e1c918a47832a3", "width": 1080, "height": 607}], "variants": {}, "id": "PDysISo2F3CJXN3OEAQsXRQaUbtDHEO1IZ6ahbrsuXY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vu9ae", "is_robot_indexable": true, "report_reasons": null, "author": "gaodalie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vu9ae/talk_to_your_csv_how_to_visualize_your_data_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13vu9ae/talk_to_your_csv_how_to_visualize_your_data_with/", "subreddit_subscribers": 913527, "created_utc": 1685462633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Did you took/saw/study that course? Is for free on youtube\n\n[View Poll](https://www.reddit.com/poll/13w1ba8)", "author_fullname": "t2_16ei22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Andrew Ng &amp; CS229 Stanford", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13w1ba8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685478902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you took/saw/study that course? Is for free on youtube&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13w1ba8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "13w1ba8", "is_robot_indexable": true, "report_reasons": null, "author": "satchurated", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1685651702754, "options": [{"text": "Yes", "id": "23261800"}, {"text": "No", "id": "23261801"}, {"text": "I don't know Andrew Ng", "id": "23261802"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 15, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13w1ba8/andrew_ng_cs229_stanford/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/13w1ba8/andrew_ng_cs229_stanford/", "subreddit_subscribers": 913527, "created_utc": 1685478902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_gj8rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-feature Granger causality - seeing e.g. EEG two separate causality waves in frontal cortex, would be merged in standard methods", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_13vkbo3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/EG34fovo2FQsZsDCLx9IMzIv61eq9c1rO_2h4JNK850.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685434650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/up3btgjtgx2b1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/up3btgjtgx2b1.png?auto=webp&amp;v=enabled&amp;s=1ce44645b8cdc9be291f32c13780736dd7331557", "width": 2133, "height": 1818}, "resolutions": [{"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c43f55e59865fd7e7e91f935bf54abb06514d45b", "width": 108, "height": 92}, {"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bd2171cf7a6337c1e5513fb0dff360450a5a733", "width": 216, "height": 184}, {"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c2ff6f3d970cf6af777ec9e7fda2bab6065c19f", "width": 320, "height": 272}, {"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c805fee3c6bb7b1aace6e5b13ae885093c0dfb9", "width": 640, "height": 545}, {"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6b18dd9ab731fe897191179b8ee1eeca58a39e1", "width": 960, "height": 818}, {"url": "https://preview.redd.it/up3btgjtgx2b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1dfdfdc320809556fe67cd369232a75d009097d", "width": 1080, "height": 920}], "variants": {}, "id": "b55ltmg0cfHYt80l7NtdnP4zumlwONU0n6OnNrQD05I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13vkbo3", "is_robot_indexable": true, "report_reasons": null, "author": "jarekduda", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13vkbo3/multifeature_granger_causality_seeing_eg_eeg_two/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/up3btgjtgx2b1.png", "subreddit_subscribers": 913527, "created_utc": 1685434650.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}