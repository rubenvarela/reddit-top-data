{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Redpanda going to replace Apache Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ahkh7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683448250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark\"&gt;https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?auto=webp&amp;v=enabled&amp;s=a34b1613855b1e3e7b23d18369adfc586ca53c77", "width": 1170, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f8e4522268a5fdf969f9f3c55606fe5640829f5", "width": 108, "height": 66}, {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc8b728fb1562baafc9b4396407421db515dc3e5", "width": 216, "height": 132}, {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c62e08b51037feaf8b3a0c4fc03720827c34a802", "width": 320, "height": 196}, {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adee7ca243c32a9e2fd4a4639272d58b4aaa38fe", "width": 640, "height": 393}, {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e45d1ac1b4b9e4a552c1fd3f3f0e8b93cbf8fc17", "width": 960, "height": 590}, {"url": "https://external-preview.redd.it/tAvhCYL_CPz8Snhn1nCU56SiT5G091t6Puaqgeog2LA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=197bb75b3831c3efb678f141bb79eb4090f52817", "width": 1080, "height": 664}], "variants": {}, "id": "b02hSD6fK-02oym8-LDsyi4dLz-sGMVoqadlnXaGuj0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ahkh7", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ahkh7/is_redpanda_going_to_replace_apache_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ahkh7/is_redpanda_going_to_replace_apache_kafka/", "subreddit_subscribers": 104489, "created_utc": 1683448250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've built a table focused around attributions that currently has  \\~10 Billion rows. In this table there is a field called \"cohort\" that consists of two distinct values: \"test\" and \"control\". End user queries will almost certainly only use this field in a group by clause and not as a filter in the where clause.\n\nI'm already partitioning on two other fields: \"attribution\\_type\" and \"date\", which will both be used heavily to filter. I'm wondering if this very low cardinality field has a place as another partition column or to colocate data by using ZORDER BY, or neither? Adding this as a partition introduces more skew and I've read that you don't want to ZORDER BY on a low cardinality field, but it seems like I should be using this field somehow to optimize queries. Any suggestions?", "author_fullname": "t2_3i1tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partition Or ZORDER On Low Cardinality Field? (Spark)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13a94kr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683424185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a table focused around attributions that currently has  ~10 Billion rows. In this table there is a field called &amp;quot;cohort&amp;quot; that consists of two distinct values: &amp;quot;test&amp;quot; and &amp;quot;control&amp;quot;. End user queries will almost certainly only use this field in a group by clause and not as a filter in the where clause.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m already partitioning on two other fields: &amp;quot;attribution_type&amp;quot; and &amp;quot;date&amp;quot;, which will both be used heavily to filter. I&amp;#39;m wondering if this very low cardinality field has a place as another partition column or to colocate data by using ZORDER BY, or neither? Adding this as a partition introduces more skew and I&amp;#39;ve read that you don&amp;#39;t want to ZORDER BY on a low cardinality field, but it seems like I should be using this field somehow to optimize queries. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13a94kr", "is_robot_indexable": true, "report_reasons": null, "author": "Shatonmedeek", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13a94kr/partition_or_zorder_on_low_cardinality_field_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13a94kr/partition_or_zorder_on_low_cardinality_field_spark/", "subreddit_subscribers": 104489, "created_utc": 1683424185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview next week and they are asking for sample code or ER   diagrams. The position requires coding t-sql on SQL server for reporting purposes. \n\nI have never saved any SQL code and ER diagrams as they are all work related.\n\nHow should I proceed?\n\n1. Tell them all my SQL code and ER diagrams were made at work and are company property. I am therefore not allowed to share.\n2. Make SQL Code and ER Diagrams. What is a good source for a project like this?  They only want to see SQL code or an ER Diagram.\n\nThank you in advance.\n\nEDIT: Is it okay to ask them for a  business problem / use case  to solve before the interview?", "author_fullname": "t2_a9egczxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviewer is asking for Sample Code and ER Diagrams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13a8f2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683424507.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683422304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview next week and they are asking for sample code or ER   diagrams. The position requires coding t-sql on SQL server for reporting purposes. &lt;/p&gt;\n\n&lt;p&gt;I have never saved any SQL code and ER diagrams as they are all work related.&lt;/p&gt;\n\n&lt;p&gt;How should I proceed?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Tell them all my SQL code and ER diagrams were made at work and are company property. I am therefore not allowed to share.&lt;/li&gt;\n&lt;li&gt;Make SQL Code and ER Diagrams. What is a good source for a project like this?  They only want to see SQL code or an ER Diagram.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Is it okay to ask them for a  business problem / use case  to solve before the interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13a8f2h", "is_robot_indexable": true, "report_reasons": null, "author": "babyyodda1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13a8f2h/interviewer_is_asking_for_sample_code_and_er/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13a8f2h/interviewer_is_asking_for_sample_code_and_er/", "subreddit_subscribers": 104489, "created_utc": 1683422304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the best way to load delta records from on prem sql server db to snowflake?\n\nWe are planning on ADF copy feature which seems use blob storage as intermediate stage - which I feel may cause performance issues, so are there any better ways people do? Is there a way to directly load to snowflake?  Delta extract would be based on record update date.. and need to cover 100s of tables.. with a hourly job\n\n.", "author_fullname": "t2_khph1234", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to ELT from on-prem sql server db to snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13auxhk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683476007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the best way to load delta records from on prem sql server db to snowflake?&lt;/p&gt;\n\n&lt;p&gt;We are planning on ADF copy feature which seems use blob storage as intermediate stage - which I feel may cause performance issues, so are there any better ways people do? Is there a way to directly load to snowflake?  Delta extract would be based on record update date.. and need to cover 100s of tables.. with a hourly job&lt;/p&gt;\n\n&lt;p&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13auxhk", "is_robot_indexable": true, "report_reasons": null, "author": "misc0007", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13auxhk/whats_the_best_way_to_elt_from_onprem_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13auxhk/whats_the_best_way_to_elt_from_onprem_sql_server/", "subreddit_subscribers": 104489, "created_utc": 1683476007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A colleague wants to receive Industrial IoT data from multiple Pub/Sub and Kafka topics. He believes a data collection agent is the simplest/best approach, but I  have my doubts. \n\nI'd rather stick to traditional tools than gamble with a  collection agent. Am I being overly pragmatic?", "author_fullname": "t2_76d1dys0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a data collection agent a more effective approach for receiving messages from Pub/Sub (or Kafka) compared to Data Engineering Tools like Apache Airflow, Flink, or Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139xceh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683396307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A colleague wants to receive Industrial IoT data from multiple Pub/Sub and Kafka topics. He believes a data collection agent is the simplest/best approach, but I  have my doubts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d rather stick to traditional tools than gamble with a  collection agent. Am I being overly pragmatic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139xceh", "is_robot_indexable": true, "report_reasons": null, "author": "Revolution_Little", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/139xceh/is_a_data_collection_agent_a_more_effective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139xceh/is_a_data_collection_agent_a_more_effective/", "subreddit_subscribers": 104489, "created_utc": 1683396307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions/ideas for a data engineering hackathon. Thanks in advance.", "author_fullname": "t2_62mycgca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering hackathon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139ypf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683399295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions/ideas for a data engineering hackathon. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139ypf5", "is_robot_indexable": true, "report_reasons": null, "author": "Wonderful_Original61", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139ypf5/data_engineering_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139ypf5/data_engineering_hackathon/", "subreddit_subscribers": 104489, "created_utc": 1683399295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone , i have a python script that scrapes a website for data.\n\nI was wondering how i can automate it to run everyday  and store the content into a csv file then  visualize it with powerbi. \n\nTIA", "author_fullname": "t2_5phrmwmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running a python scraper every day and update", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13an1zf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683464433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone , i have a python script that scrapes a website for data.&lt;/p&gt;\n\n&lt;p&gt;I was wondering how i can automate it to run everyday  and store the content into a csv file then  visualize it with powerbi. &lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13an1zf", "is_robot_indexable": true, "report_reasons": null, "author": "naffra", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13an1zf/running_a_python_scraper_every_day_and_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13an1zf/running_a_python_scraper_every_day_and_update/", "subreddit_subscribers": 104489, "created_utc": 1683464433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently been tasked with exporting around 5 years - approximately 13 million records - worth of data from an Azure SQL database to monthly csv files. This format is required by the vendor. \n\nThe data itself is an MS Dynamics table of emails - with one of the columns being the HTML content of the email itself - which is understandably massive. \n\nI\u2019m currently using Pandas to connect to the database via ODBC and reading the records in chunks before using the to_csv method to spit the files out to an SFTP location. Due to the sheer size of the HTML description column (some of which are around 900k characters), this process is taking an extremely long time. \n\nI\u2019ve tried the write process using Polars, which seems significantly quicker but I\u2019m having issues connecting to the database using it so I\u2019ve been reading the files through the above Pandas routine and converting them to Polars dataframes in my tests. \n\nDoes anybody have any better ideas or experience doing something similar?", "author_fullname": "t2_xu27r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting Large Datasets to csv", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13aru6c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683471467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently been tasked with exporting around 5 years - approximately 13 million records - worth of data from an Azure SQL database to monthly csv files. This format is required by the vendor. &lt;/p&gt;\n\n&lt;p&gt;The data itself is an MS Dynamics table of emails - with one of the columns being the HTML content of the email itself - which is understandably massive. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently using Pandas to connect to the database via ODBC and reading the records in chunks before using the to_csv method to spit the files out to an SFTP location. Due to the sheer size of the HTML description column (some of which are around 900k characters), this process is taking an extremely long time. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried the write process using Polars, which seems significantly quicker but I\u2019m having issues connecting to the database using it so I\u2019ve been reading the files through the above Pandas routine and converting them to Polars dataframes in my tests. &lt;/p&gt;\n\n&lt;p&gt;Does anybody have any better ideas or experience doing something similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13aru6c", "is_robot_indexable": true, "report_reasons": null, "author": "PurpleChicken7", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13aru6c/exporting_large_datasets_to_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13aru6c/exporting_large_datasets_to_csv/", "subreddit_subscribers": 104489, "created_utc": 1683471467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Step-by-Step Guide to Building a High-Performing Risk Data Mart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13au2ky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pj5nWuQJkLDYKSEuGmj4lEvutY3IAbcvOSnzEqDkags.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683474133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dev-genius/step-by-step-guide-to-building-a-high-performing-risk-data-mart-8a7aaaac9535", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?auto=webp&amp;v=enabled&amp;s=7ec5db1777f5770010c1d86f59e3e7a6c4458c87", "width": 1200, "height": 798}, "resolutions": [{"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1438ed3094ceb74db1e3b63b09e4e0c897ba46cb", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=927a7c4f808cd46b681e4839c7e815aa29c0778c", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f83a4f7d91452da3fa203026cc73c849cac37db", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c3cb1306f9391a9e114547cb74534847c3f7af5", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fbf8d59a9b011df666323c50afe9882fde7dc81", "width": 960, "height": 638}, {"url": "https://external-preview.redd.it/SosrA9B-xbCffaRvfwZlqk1MVIfgf89wvKFgBbBXczk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d17d3eb3d990e8a6afc717af80b291d3fc5e0551", "width": 1080, "height": 718}], "variants": {}, "id": "lrpJC_WbxYIlrkQfUB3wVqpwlxjH31HAzXfKIQP3RrI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13au2ky", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13au2ky/stepbystep_guide_to_building_a_highperforming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dev-genius/step-by-step-guide-to-building-a-high-performing-risk-data-mart-8a7aaaac9535", "subreddit_subscribers": 104489, "created_utc": 1683474133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have created a Cassandra database on Datastax and want to connect it with Pyspark, but I am not able to wrap my head around the required procedure. I did refer to some blogs and documentation but still could understand how to do so. Kindly please me here. Reference to any articles, books, or video links will be a great help. Also what reference should I use to understand Spark even better?", "author_fullname": "t2_5hpv694y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect Pyspark with the Cassandra database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13abkxh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683430529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created a Cassandra database on Datastax and want to connect it with Pyspark, but I am not able to wrap my head around the required procedure. I did refer to some blogs and documentation but still could understand how to do so. Kindly please me here. Reference to any articles, books, or video links will be a great help. Also what reference should I use to understand Spark even better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13abkxh", "is_robot_indexable": true, "report_reasons": null, "author": "mili_19", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13abkxh/how_to_connect_pyspark_with_the_cassandra_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13abkxh/how_to_connect_pyspark_with_the_cassandra_database/", "subreddit_subscribers": 104489, "created_utc": 1683430529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wish to set up a data warehouse with DBT and an Azure SQL database (and a data lake for the RAW layer). I like how DBT makes the transformation process more practical and takes care of the DML. We are using Azure, and the data warehouse will be under 100GB, which means Synapse or Snowflake won't be necessary and an Azure SQL database is more cost effective.\n\nDBT does not have official support for Azure SQL database, and I would need to use a community version. Can you tell me if this has significant disadvantages? And give me feedback on this architecture?", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT with Azure SQL Database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13a4b0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683412154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wish to set up a data warehouse with DBT and an Azure SQL database (and a data lake for the RAW layer). I like how DBT makes the transformation process more practical and takes care of the DML. We are using Azure, and the data warehouse will be under 100GB, which means Synapse or Snowflake won&amp;#39;t be necessary and an Azure SQL database is more cost effective.&lt;/p&gt;\n\n&lt;p&gt;DBT does not have official support for Azure SQL database, and I would need to use a community version. Can you tell me if this has significant disadvantages? And give me feedback on this architecture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13a4b0v", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13a4b0v/dbt_with_azure_sql_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13a4b0v/dbt_with_azure_sql_database/", "subreddit_subscribers": 104489, "created_utc": 1683412154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Work in a large organisation with a big focus on data initiatives.\nWe have some smaller data engineering groups out in the business units. \nBut IT centrally is responsible for the overall infrastructure.\n\nMain problem is that IT centrally are filled up with architects with non-technical background (ex-project managers, ex business-analyst etc). We feel like often they make really stupid architectural decisions, and don\u2019t want to listen to the actual engineers out in the BUs. \nIs this common elsewhere? \n\nI would have thought that the best architects would have some hands on experience with developing solutions in order to make informed decisions.", "author_fullname": "t2_55lwhlsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are your orgs architects technical?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ajf2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683453982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Work in a large organisation with a big focus on data initiatives.\nWe have some smaller data engineering groups out in the business units. \nBut IT centrally is responsible for the overall infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Main problem is that IT centrally are filled up with architects with non-technical background (ex-project managers, ex business-analyst etc). We feel like often they make really stupid architectural decisions, and don\u2019t want to listen to the actual engineers out in the BUs. \nIs this common elsewhere? &lt;/p&gt;\n\n&lt;p&gt;I would have thought that the best architects would have some hands on experience with developing solutions in order to make informed decisions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ajf2d", "is_robot_indexable": true, "report_reasons": null, "author": "scalahtmlsql", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ajf2d/are_your_orgs_architects_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ajf2d/are_your_orgs_architects_technical/", "subreddit_subscribers": 104489, "created_utc": 1683453982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14djpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demo: Developed a simple tool to identify data quality issues within spreadsheets - Feedback is highly appreciated! Join the waitlist in the description!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_13a6rdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.45, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/obig6zqydcya1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1910, "scrubber_media_url": "https://v.redd.it/obig6zqydcya1/DASH_96.mp4", "dash_url": "https://v.redd.it/obig6zqydcya1/DASHPlaylist.mpd?a=1686076704%2CZGM5M2Q3ZGE1MzVmNzA4MTQ1ZWZmZjI3YzBmZTliNThkMDJlMjBkYjE2YTc5ZWE3ZGNiNWJhMzMzZDk1OGQ5Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 17, "hls_url": "https://v.redd.it/obig6zqydcya1/HLSPlaylist.m3u8?a=1686076704%2CNTM5MWEyNDY5ZDY5MzJmNTE3MzU1Y2UwNmNmMjYwY2RhMWJjMmRiY2NkMWU1MTRhYmY2MGNkZmQ3NTY2Zjk5Yw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=140&amp;height=79&amp;crop=140:79,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=22393497925d8efdf2ada906df13dbbb7836cbbd", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683417986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/obig6zqydcya1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1e7cd5f6db41d4fab19e5643a070543c2b0ab3fc", "width": 2556, "height": 1446}, "resolutions": [{"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d02c795469bc12df7763da7f4236e56e92bb4ef7", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=16a9feb0a892df8412b395c8af771e43912f6a53", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=347f476fddbc883daecf2230988b3c5079dfe824", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5371365b912fa3c5982381a440f06f978222ac81", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a0073f043fb33d3be25cb2d6c0dab692fc85187f", "width": 960, "height": 543}, {"url": "https://external-preview.redd.it/RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=576d6babc539a79b59fa407db96a0d62e36d157e", "width": 1080, "height": 610}], "variants": {}, "id": "RFBTO9dE8q5pREQ0ZTM7R3IAt5obQ87UMO5YLA0h3Nw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13a6rdw", "is_robot_indexable": true, "report_reasons": null, "author": "felix-reddit", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13a6rdw/demo_developed_a_simple_tool_to_identify_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/obig6zqydcya1", "subreddit_subscribers": 104489, "created_utc": 1683417986.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/obig6zqydcya1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1910, "scrubber_media_url": "https://v.redd.it/obig6zqydcya1/DASH_96.mp4", "dash_url": "https://v.redd.it/obig6zqydcya1/DASHPlaylist.mpd?a=1686076704%2CZGM5M2Q3ZGE1MzVmNzA4MTQ1ZWZmZjI3YzBmZTliNThkMDJlMjBkYjE2YTc5ZWE3ZGNiNWJhMzMzZDk1OGQ5Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 17, "hls_url": "https://v.redd.it/obig6zqydcya1/HLSPlaylist.m3u8?a=1686076704%2CNTM5MWEyNDY5ZDY5MzJmNTE3MzU1Y2UwNmNmMjYwY2RhMWJjMmRiY2NkMWU1MTRhYmY2MGNkZmQ3NTY2Zjk5Yw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}], "before": null}}