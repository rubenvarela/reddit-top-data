{"kind": "Listing", "data": {"after": "t3_137ff79", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When collaborating with Software Engineering, Product, etc. there are always things that come up regarding best practices in a production database.\n\n* timestamps should always include a time zone and be stored in UTC (right?)\n* Foreign key constraints should always be defined on foreign keys\n* Column names should be descriptive\n* Boolean columns should begin with is\\_ or has\\_\n\nYou get the idea. There are dozens or hundreds of standards I could think of if I kept going.\n\nI see a few nascent attempts, but I'm surprised that with decades of SQL usage gone by, there aren't some standards that seem more.... authoritative at this point. Does anyone know of any semi-official standards, or have thoughts here?\n\n \\- [https://ovid.github.io/articles/database-design-standards.html](https://ovid.github.io/articles/database-design-standards.html)  \n \\- [https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e\\_0](https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0)  \n\n\nIt would be really handy to have something authoritative, at least as a starting point, instead of arguing about these from scratch and not getting anywhere.", "author_fullname": "t2_ikd9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there database design Standards out there? As in, formal documents listing exact best practices for OLTP database design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136rwag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683130690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When collaborating with Software Engineering, Product, etc. there are always things that come up regarding best practices in a production database.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;timestamps should always include a time zone and be stored in UTC (right?)&lt;/li&gt;\n&lt;li&gt;Foreign key constraints should always be defined on foreign keys&lt;/li&gt;\n&lt;li&gt;Column names should be descriptive&lt;/li&gt;\n&lt;li&gt;Boolean columns should begin with is_ or has_&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You get the idea. There are dozens or hundreds of standards I could think of if I kept going.&lt;/p&gt;\n\n&lt;p&gt;I see a few nascent attempts, but I&amp;#39;m surprised that with decades of SQL usage gone by, there aren&amp;#39;t some standards that seem more.... authoritative at this point. Does anyone know of any semi-official standards, or have thoughts here?&lt;/p&gt;\n\n&lt;p&gt;- &lt;a href=\"https://ovid.github.io/articles/database-design-standards.html\"&gt;https://ovid.github.io/articles/database-design-standards.html&lt;/a&gt;&lt;br/&gt;\n - &lt;a href=\"https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0\"&gt;https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;It would be really handy to have something authoritative, at least as a starting point, instead of arguing about these from scratch and not getting anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?auto=webp&amp;v=enabled&amp;s=abd422b029c6345857a292786ca4d16be8f2830c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6a53368b90bffe05ee4a4765df106a5400174de", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4545a61cb8c010f3742489c40dd2877a96b7619", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6c0886833f43676efe965b4c4a1d2497b453691", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af03f83ddb073cada8a305abcf0ba39ff9a96d0e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87afa074d6cd28277b31dc47df853cf74c8beb76", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35eb4aee9f02195139fc1bc9f605d382690d0beb", "width": 1080, "height": 567}], "variants": {}, "id": "9KhCOfskbM2VYm3zdj6PLtIKhgqnUxOBHr5z1-emBYI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136rwag", "is_robot_indexable": true, "report_reasons": null, "author": "dlb8685", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136rwag/are_there_database_design_standards_out_there_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136rwag/are_there_database_design_standards_out_there_as/", "subreddit_subscribers": 104007, "created_utc": 1683130690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a healthcare tech right after college. So that is a total of 2.5 years in the field -  be it data, IT, corporate, you name it. 2.5 years. Not a fresher. Not a senior either.\n\nFirst project was just a bunch of DML SQL queries fired up in Snowflake as we got tickets. I took time to learn Snowflake better, gain a bit of healthcare knowledge and so on. Current team is Data Governance and Data Quality in Informatica tech stack. I worked on tiny part of Python, APIs, PBI dashboards, small ETL setups via data bricks, ADLS and so on.  I know a couple of things about a lot of things, nothing in depth!\n\nIt is always maintaining something some senior has built. Then manager says that I \"lack initiative\". I have tried to create views that will help the business, delivered on everything to the best of my capacity. I am very active outside of my DE role in office. So what he means by \"lacking initiative\" I am not sure. He suggested that I could upskill, because I am not a \"fresher anymore\". I want to switch jobs, but I have NO CONFIDENCE in my tech skills.\n\nI thought of upskilling, did couple of projects end-to-end from EDA to building reports/dashboards using Tableau and Power BI.  I have this aim to utilize the company benefits policy and gain a certification in Azure Data Engineer Associate track, in the hope that I have SOME leverage in the hiring market. Completed Azure fundamentals and Data Fundamentals \\[mentioning here to show that I have already started prepping\\]\n\nI had even asked for project ideas in this subreddit in the past.\n\nBut nothing is giving me confidence, I am not sure why I am this lost in my mindset.\n\nIs it because we use loads of no-code ETL options? Maybe I am terrified to code? I have to google syntaxes a lot and that makes me scared, I cannot do that in an interview!!\n\nDo I spend more time doing projects? Do I stick to Azure because we are ALL migrating to Azure like crazy here. How much can you actually learn outside of work?\n\nI have started reading DE books too. To get a proper structure to my upskilling/gaining more knowledge process.\n\n&amp;#x200B;\n\nI love this field - because it makes sense, if you know what I mean? I hate typical SDE roles. ETL and Data Governance make sense! And I want to get better. I really want to look at a problem and come up with Data Architecture solutions, I want to do be able to do proper analysis and know what tools work together, which component goes where and build things from scratch!\n\nBut is there someone who has taken this path, faced similar struggles?\n\nI am okay getting called out too :D", "author_fullname": "t2_6zz659ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am lost. \"DE\" for 2+ years, but lost. Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136kv4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683121254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a healthcare tech right after college. So that is a total of 2.5 years in the field -  be it data, IT, corporate, you name it. 2.5 years. Not a fresher. Not a senior either.&lt;/p&gt;\n\n&lt;p&gt;First project was just a bunch of DML SQL queries fired up in Snowflake as we got tickets. I took time to learn Snowflake better, gain a bit of healthcare knowledge and so on. Current team is Data Governance and Data Quality in Informatica tech stack. I worked on tiny part of Python, APIs, PBI dashboards, small ETL setups via data bricks, ADLS and so on.  I know a couple of things about a lot of things, nothing in depth!&lt;/p&gt;\n\n&lt;p&gt;It is always maintaining something some senior has built. Then manager says that I &amp;quot;lack initiative&amp;quot;. I have tried to create views that will help the business, delivered on everything to the best of my capacity. I am very active outside of my DE role in office. So what he means by &amp;quot;lacking initiative&amp;quot; I am not sure. He suggested that I could upskill, because I am not a &amp;quot;fresher anymore&amp;quot;. I want to switch jobs, but I have NO CONFIDENCE in my tech skills.&lt;/p&gt;\n\n&lt;p&gt;I thought of upskilling, did couple of projects end-to-end from EDA to building reports/dashboards using Tableau and Power BI.  I have this aim to utilize the company benefits policy and gain a certification in Azure Data Engineer Associate track, in the hope that I have SOME leverage in the hiring market. Completed Azure fundamentals and Data Fundamentals [mentioning here to show that I have already started prepping]&lt;/p&gt;\n\n&lt;p&gt;I had even asked for project ideas in this subreddit in the past.&lt;/p&gt;\n\n&lt;p&gt;But nothing is giving me confidence, I am not sure why I am this lost in my mindset.&lt;/p&gt;\n\n&lt;p&gt;Is it because we use loads of no-code ETL options? Maybe I am terrified to code? I have to google syntaxes a lot and that makes me scared, I cannot do that in an interview!!&lt;/p&gt;\n\n&lt;p&gt;Do I spend more time doing projects? Do I stick to Azure because we are ALL migrating to Azure like crazy here. How much can you actually learn outside of work?&lt;/p&gt;\n\n&lt;p&gt;I have started reading DE books too. To get a proper structure to my upskilling/gaining more knowledge process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I love this field - because it makes sense, if you know what I mean? I hate typical SDE roles. ETL and Data Governance make sense! And I want to get better. I really want to look at a problem and come up with Data Architecture solutions, I want to do be able to do proper analysis and know what tools work together, which component goes where and build things from scratch!&lt;/p&gt;\n\n&lt;p&gt;But is there someone who has taken this path, faced similar struggles?&lt;/p&gt;\n\n&lt;p&gt;I am okay getting called out too :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "136kv4w", "is_robot_indexable": true, "report_reasons": null, "author": "Aick_Aleck", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136kv4w/i_am_lost_de_for_2_years_but_lost_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136kv4w/i_am_lost_de_for_2_years_but_lost_advice/", "subreddit_subscribers": 104007, "created_utc": 1683121254.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm interested in learning about the supplementary tools you use in conjunction with dbt and how they enhance your workflows. As we begin with dbt core, I'm curious to explore the complementary tools that work well alongside dbt. Please share your experiences and insights regarding the tools you find beneficial when using dbt.\n\nThanks,\n\nMc", "author_fullname": "t2_1v4h09lt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which supplementary tools are you using alongside dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137cym8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683184313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in learning about the supplementary tools you use in conjunction with dbt and how they enhance your workflows. As we begin with dbt core, I&amp;#39;m curious to explore the complementary tools that work well alongside dbt. Please share your experiences and insights regarding the tools you find beneficial when using dbt.&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n\n&lt;p&gt;Mc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137cym8", "is_robot_indexable": true, "report_reasons": null, "author": "mrcool444", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137cym8/which_supplementary_tools_are_you_using_alongside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137cym8/which_supplementary_tools_are_you_using_alongside/", "subreddit_subscribers": 104007, "created_utc": 1683184313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am computer engineer graduate and I want to start career in Data Engineering, but I can not start by youtube I tried many times but it is not effective in my case, I need bootcamp which is affordable and will help me to get the skill to land the first job.", "author_fullname": "t2_kzbbagfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Bootcamp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136x9q8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683142912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am computer engineer graduate and I want to start career in Data Engineering, but I can not start by youtube I tried many times but it is not effective in my case, I need bootcamp which is affordable and will help me to get the skill to land the first job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "136x9q8", "is_robot_indexable": true, "report_reasons": null, "author": "TreacleWild4127", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136x9q8/data_engineering_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136x9q8/data_engineering_bootcamp/", "subreddit_subscribers": 104007, "created_utc": 1683142912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df](https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df)\n\n[ Unveiling the true cost of your ride-sharing and food delivery habits with an ELT data pipeline, PostgreSQL, dbt, and Power BI. ](https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uber Project: Analyzing Personal Uber and Uber Eats Expenses with ELT Data Pipeline Using DBT, Postgres, Gmail, Python, SQL And PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"g7bbaja6fnxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41de5f4b7c0ef8f1402fab5169398cd294cf27e6"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a5671f5f7a2849124d41ff3e228436d735f86f0"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be78e82a8733cacf2829f953d15b68bb08233cf0"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1399af540ce025e63a4b093566c8e550b07d3b48"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62cdf7326d9d6558f3cc5b5d1aba774d2801a368"}, {"y": 604, "x": 1080, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7142eebbefdb68a526932a22a4cd43a5c805ffad"}], "s": {"y": 660, "x": 1180, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26"}, "id": "g7bbaja6fnxa1"}}, "name": "t3_136tb10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_nG9Ial9BLiWKcZNJGgwQKock2lS_ND32TfHWzV0QHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683133839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df\"&gt;https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26\"&gt; Unveiling the true cost of your ride-sharing and food delivery habits with an ELT data pipeline, PostgreSQL, dbt, and Power BI. &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?auto=webp&amp;v=enabled&amp;s=e23d6a097db23a80cd97986f29f8bf936e4fcaea", "width": 1180, "height": 660}, "resolutions": [{"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cfb1f02c76b97d3781cbb0450214468b023e789", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31c910296902350e2aaabd280045f1f439333251", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0faa9fe24a5d23673079f19617667b1c9f8dceb", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e970911e2d9172b675468f59955192312b954dd9", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc38c42c572b5d050c33da2be86bef56ed2ca117", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84492644a6cbb40347f0cfa4eae070e3dd5dacab", "width": 1080, "height": 604}], "variants": {}, "id": "sXge4upQJVpIh82dfcR-hH1qDtBS22SFSZ6wf6g7Kz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "136tb10", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136tb10/uber_project_analyzing_personal_uber_and_uber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136tb10/uber_project_analyzing_personal_uber_and_uber/", "subreddit_subscribers": 104007, "created_utc": 1683133839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_20tfe7ur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Certifications\u2014Which One is Best to Pursue in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_137bmjg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ztcgjz4C9CIuYGKluBtnKpD-00-9PG1dWWtZRHv7lL0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683179877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "chaosgenius.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.chaosgenius.io/blog/snowflake-certifications/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?auto=webp&amp;v=enabled&amp;s=ddf845843a22c51ff5fb2191808ea2ebf024a049", "width": 2000, "height": 1524}, "resolutions": [{"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46bfb0e1262b81941de0cd747531f8b99e2f3bc8", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d1c03f3517b63bc4335dd9d84e5f5626cec4917", "width": 216, "height": 164}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=984a19468137b9407b0deda67db8c7629dc24e1c", "width": 320, "height": 243}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd4d8efcc248b9d9bb977a06c26b7d3c0fc673ff", "width": 640, "height": 487}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ef7977a7c8958f0c15e72df0342bc626e73b97f", "width": 960, "height": 731}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd1a4abc3c8215c8db4731a93918c5d7f4454d43", "width": 1080, "height": 822}], "variants": {}, "id": "XNwz6ja4ti9eCjpewcXHVx74xSw6hrBKa1cY7vNJcEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137bmjg", "is_robot_indexable": true, "report_reasons": null, "author": "pramit_marattha", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137bmjg/snowflake_certificationswhich_one_is_best_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.chaosgenius.io/blog/snowflake-certifications/", "subreddit_subscribers": 104007, "created_utc": 1683179877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).\n\n\n\n\nEven ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of work can a data engineer do if they can't find employment as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137ij6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683202929.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683201719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).&lt;/p&gt;\n\n&lt;p&gt;Even ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137ij6s", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "subreddit_subscribers": 104007, "created_utc": 1683201719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have time series data files that are ~1 gig in size. Currently we are using Airflow for batch processing these files. At some point in the near future, we will need to stream the data from the source (it wont be 2 gigs in size then as it will be sent at certain intervals). Someone on my team mentioned that we should use NiFi with Kafka at the point, but I didn't fully understand the purpose of NiFi. The data will be used downstream for inference. \n\nWhen does it make sense to use Apache NiFi? What are the pros and cons of it. I would really appreciate if you can give me sample use cases.\n\nThank you \ud83d\ude4f", "author_fullname": "t2_1bxy4pss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache NiFi usecase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13733xe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683156296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have time series data files that are ~1 gig in size. Currently we are using Airflow for batch processing these files. At some point in the near future, we will need to stream the data from the source (it wont be 2 gigs in size then as it will be sent at certain intervals). Someone on my team mentioned that we should use NiFi with Kafka at the point, but I didn&amp;#39;t fully understand the purpose of NiFi. The data will be used downstream for inference. &lt;/p&gt;\n\n&lt;p&gt;When does it make sense to use Apache NiFi? What are the pros and cons of it. I would really appreciate if you can give me sample use cases.&lt;/p&gt;\n\n&lt;p&gt;Thank you \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13733xe", "is_robot_indexable": true, "report_reasons": null, "author": "iamkatana", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13733xe/apache_nifi_usecase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13733xe/apache_nifi_usecase/", "subreddit_subscribers": 104007, "created_utc": 1683156296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling \u2014 The Unsung Hero of Data Engineering: Modeling Approaches and Techniques (Part 2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_136wwbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Luakl5G7MQUxjouP2ayBj_5_OBWiEkpC1cxEgUsVzNA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683142063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-approaches-and-techniques", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?auto=webp&amp;v=enabled&amp;s=261aa0047aaa2f024c69ce7aeeb765c965bc45b6", "width": 1398, "height": 759}, "resolutions": [{"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c018677cdb23284e1318b53caed2d7398b51c366", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5495e000c0e2d258ddc0c7ab1c5ef31a32a7a702", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acf81aa92304a993cf52d26be7219363fad96c2a", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8261e19ec61b26f19dc5eac9edc6de25dec41d07", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16a09b57e0af20f26bf706181714ff4b9a0cced3", "width": 960, "height": 521}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c4479cf7f7d44772ea8d73c6e732ce9926a3cad", "width": 1080, "height": 586}], "variants": {}, "id": "sAv0LQfAX5D6adD8AWOXJxW0jvWpbS_k8UNjK63jUOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "136wwbg", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/136wwbg/data_modeling_the_unsung_hero_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-approaches-and-techniques", "subreddit_subscribers": 104007, "created_utc": 1683142063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouses vs Data Lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_136vh7g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/136vh7g", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dkgfePmTwlhjDvdbF07lNZZRY_VO5dVdFOKKgMxt-8Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683138787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xbtK43WlkMs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?auto=webp&amp;v=enabled&amp;s=efd25af1081c58827d479668ffa6c256fa2818b0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad41e971d1e0838c4c49837be54ae9f4a56962db", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5dff204a03ea70392c8c9f3a746257f4904b381", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6585e60fe811684616aa131692d6a2971ded5e2", "width": 320, "height": 240}], "variants": {}, "id": "y1-ztg6CqTUIpsSMCro3W1_odauB7Vb_7yUnCwY1H7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "136vh7g", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136vh7g/data_warehouses_vs_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xbtK43WlkMs", "subreddit_subscribers": 104007, "created_utc": 1683138787.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I wanted to share my personal newsletter with you. Every week, I collect information from the data world and compile it into the newsletter. If you're interested, please feel free to check it out. :)\n\n[https://patrikbraborec.substack.com/p/data-news-26](https://patrikbraborec.substack.com/p/data-news-26)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data news #26", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137fbwg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683192223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I wanted to share my personal newsletter with you. Every week, I collect information from the data world and compile it into the newsletter. If you&amp;#39;re interested, please feel free to check it out. :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://patrikbraborec.substack.com/p/data-news-26\"&gt;https://patrikbraborec.substack.com/p/data-news-26&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?auto=webp&amp;v=enabled&amp;s=d6516117109b746272aa481075306a3f636cf116", "width": 728, "height": 410}, "resolutions": [{"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91270145edd6445d657193709e74d65217783def", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7915398bcf5335938d8a3aca59fc4e649e45150", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a9fead389d87f45d460517bd7076c93d663a0fb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56e0a8b5790d83cfbe3f6dcbb4fae1f30de50873", "width": 640, "height": 360}], "variants": {}, "id": "pjoi_vcvcsZBx-uaz1ZygihHBy9couKiRgilZlSbgx0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137fbwg", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137fbwg/data_news_26/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137fbwg/data_news_26/", "subreddit_subscribers": 104007, "created_utc": 1683192223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Deploying subnets, clusters, iam roles and policies, workspaces, users, groups, and metastore. I\u2019ve really only deployed simple aws resources and have a little bit of knowledge with modules after experimenting with them. I\u2019ve also gotten through a few courses in the DB DE path but have paused learning since they are updating the course. \n\nAny advice?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expected to terraform and deploy all of our DataBricks resources as our first implementation, little knowledge of TF and DB, any advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1372hz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683154794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deploying subnets, clusters, iam roles and policies, workspaces, users, groups, and metastore. I\u2019ve really only deployed simple aws resources and have a little bit of knowledge with modules after experimenting with them. I\u2019ve also gotten through a few courses in the DB DE path but have paused learning since they are updating the course. &lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1372hz9", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1372hz9/expected_to_terraform_and_deploy_all_of_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1372hz9/expected_to_terraform_and_deploy_all_of_our/", "subreddit_subscribers": 104007, "created_utc": 1683154794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to chat with you about it", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Google PaLM for Data Engineering related tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136xjc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683143528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to chat with you about it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136xjc9", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/136xjc9/has_anyone_used_google_palm_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136xjc9/has_anyone_used_google_palm_for_data_engineering/", "subreddit_subscribers": 104007, "created_utc": 1683143528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Sharding in Apache Doris", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_136nzfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/AW22M9w-o3pkhrPJuMG5IOIhS8BVzVoNS90MA_dJmL8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683125056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9lggrvt7pmxa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9lggrvt7pmxa1.png?auto=webp&amp;v=enabled&amp;s=0bffecb0b03fec50b05a05618763e32a50a7b9f7", "width": 683, "height": 453}, "resolutions": [{"url": "https://preview.redd.it/9lggrvt7pmxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f940b05d44276ea15d9dbd3abeda697e514663bf", "width": 108, "height": 71}, {"url": "https://preview.redd.it/9lggrvt7pmxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e2b43de9492ad3f38149587d4c18e7bad87b860", "width": 216, "height": 143}, {"url": "https://preview.redd.it/9lggrvt7pmxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab689244c452eb450ae1053f11a85fb329c13426", "width": 320, "height": 212}, {"url": "https://preview.redd.it/9lggrvt7pmxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3d6eb5f22c046314a5c1637259f272f10aec992", "width": 640, "height": 424}], "variants": {}, "id": "zcuU6MUyagcpjbiAD9GTTg3gPFN6ztzFSqr7zy7en5Y"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "136nzfb", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136nzfb/data_sharding_in_apache_doris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9lggrvt7pmxa1.png", "subreddit_subscribers": 104007, "created_utc": 1683125056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aqvee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modeling maturity model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_136k359", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FCpy5U0WujVFlqlzy7lJozxXf2wUsy69u1fj1chZz-k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683119320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/a-maturity-model-for-data-modeling-and-design-b516d978655c", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?auto=webp&amp;v=enabled&amp;s=240c13310c0c4f559310901587446f8e34a6fc99", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0014df565fe64c2cdd8b39f486742a7dfa457846", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4b2aab8ebd612281e210d219912a26176b538fb", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ada714076617dc9cb75b35fde06a8836d16b9616", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4354e820c9a91d8a55318808aa900550eac21258", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/NU2LyZxgQMak_5MhZLI-ZT6wa7NSkBrPVRlmvVi9J28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=550338a47e95fa4e425f17439e3623c22ea9f6bc", "width": 960, "height": 640}], "variants": {}, "id": "vLyVo8SPnZMi4Y6cVwzNYMw3KV6fMQNbCqzGPriMX4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "136k359", "is_robot_indexable": true, "report_reasons": null, "author": "willemkoenders", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136k359/data_modeling_maturity_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/a-maturity-model-for-data-modeling-and-design-b516d978655c", "subreddit_subscribers": 104007, "created_utc": 1683119320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I need a little bit of advice:\n\nI have to implement a data platform (basically a data lake in S3 where we pool all their data so we can perform joins / analytics) for a company. One source of data to the datalake is a postgres database (AWS Aurora) that services a CRM tool. Would you recommend implementing some sort of CDC that just feeds the various tables to the datalake? if so what CDC tool would you recommend? Also would love \"recommended reading\" on architecting the resulting datalake tables in a robust/production-grade way.\n\nedit: sry meant OLTP not OLAP in title", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analytics on an OLAP RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137h2w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683199018.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683197655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I need a little bit of advice:&lt;/p&gt;\n\n&lt;p&gt;I have to implement a data platform (basically a data lake in S3 where we pool all their data so we can perform joins / analytics) for a company. One source of data to the datalake is a postgres database (AWS Aurora) that services a CRM tool. Would you recommend implementing some sort of CDC that just feeds the various tables to the datalake? if so what CDC tool would you recommend? Also would love &amp;quot;recommended reading&amp;quot; on architecting the resulting datalake tables in a robust/production-grade way.&lt;/p&gt;\n\n&lt;p&gt;edit: sry meant OLTP not OLAP in title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137h2w9", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137h2w9/data_analytics_on_an_olap_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137h2w9/data_analytics_on_an_olap_rdbms/", "subreddit_subscribers": 104007, "created_utc": 1683197655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I have some questions that are less data-oriented, but these questions are likely relevant to any data development team: I assume that most people here develop in sprints. \n\nIn my opinion, in data engineering workloads, there are many unknown factors during the grooming time that can affect tasks within the sprint, creating more challenges compared to more classical software development sprints.\n\n* How do you estimate time for tasks - in hours or story points and why?\n* How do you measure the velocity of developers or are you being measured?\n* How do you deal with overestimated tasks as team leaders, and how do you communicate efficiently that you think it should take less?\n* If a task is blocked due to missing data, decisions need to be taken by stakeholders or PM, UAT, or due to DevOps or any other reason that prevents you from developing - if there is a deviation in the defined time frame - how do you take this into account when evaluating the quality and speed at which the task was completed?\n* Continuing from the previous question, are all the deadlines for all the tasks in the sprint are the end of the sprint, or do you communicate deadlines for tasks based on their priority in the sprint and estimation? If it's the end of the sprint, how do you deal with pressure from senior management to know the date the task will be completed, which you probably know will be before the end of the sprint because it's a top priority?", "author_fullname": "t2_ctqlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sprint management in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dwry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683187478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I have some questions that are less data-oriented, but these questions are likely relevant to any data development team: I assume that most people here develop in sprints. &lt;/p&gt;\n\n&lt;p&gt;In my opinion, in data engineering workloads, there are many unknown factors during the grooming time that can affect tasks within the sprint, creating more challenges compared to more classical software development sprints.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you estimate time for tasks - in hours or story points and why?&lt;/li&gt;\n&lt;li&gt;How do you measure the velocity of developers or are you being measured?&lt;/li&gt;\n&lt;li&gt;How do you deal with overestimated tasks as team leaders, and how do you communicate efficiently that you think it should take less?&lt;/li&gt;\n&lt;li&gt;If a task is blocked due to missing data, decisions need to be taken by stakeholders or PM, UAT, or due to DevOps or any other reason that prevents you from developing - if there is a deviation in the defined time frame - how do you take this into account when evaluating the quality and speed at which the task was completed?&lt;/li&gt;\n&lt;li&gt;Continuing from the previous question, are all the deadlines for all the tasks in the sprint are the end of the sprint, or do you communicate deadlines for tasks based on their priority in the sprint and estimation? If it&amp;#39;s the end of the sprint, how do you deal with pressure from senior management to know the date the task will be completed, which you probably know will be before the end of the sprint because it&amp;#39;s a top priority?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137dwry", "is_robot_indexable": true, "report_reasons": null, "author": "Snirisl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137dwry/sprint_management_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137dwry/sprint_management_in_data_engineering/", "subreddit_subscribers": 104007, "created_utc": 1683187478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Glue Crawler to map data from S3 to Glue tables. Currenlty, I can capture schema changes (add new columns only) only when the recrawl policy is set to crawl everything. However, when I set recrawl policy to craw new sub-folders only, the new columns are not added.   \n\n\nIs this a limitation right now with Glue Crawler?\n\nBelow is my config. Recrawl new only isn't working for addition of new columns in subsequent runs. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue Crawler Schema Changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "media_metadata": {"d50ow1rweqxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=724dfca3fa83028d1997b5e7059d42d122db7ab7"}, {"y": 64, "x": 216, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b9e371225a7d4ddd3f3477583663ca5b68bae2a"}, {"y": 95, "x": 320, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b948121eb8a93ec099f96a2134a4e1a663b366b1"}, {"y": 191, "x": 640, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd47e068e41180503883e40297e397214dc45658"}, {"y": 287, "x": 960, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d54cde38d46871b9c9784784a78aa822b21e590"}, {"y": 323, "x": 1080, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae2d3e31afb08379e4a43573b10d6906f40414d9"}], "s": {"y": 882, "x": 2942, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a"}, "id": "d50ow1rweqxa1"}}, "name": "t3_1378acm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-IXrKCUSr2jN3oXZnaQza0k4lEtiTgNjjwMgBKjkCvM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683169985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Glue Crawler to map data from S3 to Glue tables. Currenlty, I can capture schema changes (add new columns only) only when the recrawl policy is set to crawl everything. However, when I set recrawl policy to craw new sub-folders only, the new columns are not added.   &lt;/p&gt;\n\n&lt;p&gt;Is this a limitation right now with Glue Crawler?&lt;/p&gt;\n\n&lt;p&gt;Below is my config. Recrawl new only isn&amp;#39;t working for addition of new columns in subsequent runs. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a\"&gt;https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1378acm", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1378acm/glue_crawler_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1378acm/glue_crawler_schema_changes/", "subreddit_subscribers": 104007, "created_utc": 1683169985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am really new to data engineering and I am currently working with some medical data (free mimicsIII) dataset, and I wish to ingest them into a database. I am using drawio to draw my ERD. I am wondering what is your favorite tool to directly converting ERD to DDL for my database, let's say postgres?", "author_fullname": "t2_12wrnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERD to DDL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13773aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683166840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am really new to data engineering and I am currently working with some medical data (free mimicsIII) dataset, and I wish to ingest them into a database. I am using drawio to draw my ERD. I am wondering what is your favorite tool to directly converting ERD to DDL for my database, let&amp;#39;s say postgres?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13773aj", "is_robot_indexable": true, "report_reasons": null, "author": "diceHots", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13773aj/erd_to_ddl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13773aj/erd_to_ddl_tool/", "subreddit_subscribers": 104007, "created_utc": 1683166840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, we're looking to use Segment + Mixpanel and we're confused about how it complies with the UK GDPR. It seems only Segment's Business plan is compliant, but the price is much higher than the Team plan (low 5 figures according to Segment's sales person).\n\nCan anyone confirm or clarify that? If we use Segment's Team plan, are we in breach of the UK GDPR?\n\nThanks!", "author_fullname": "t2_9llx2i45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Segment and UK GDPR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136mm71", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683123750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, we&amp;#39;re looking to use Segment + Mixpanel and we&amp;#39;re confused about how it complies with the UK GDPR. It seems only Segment&amp;#39;s Business plan is compliant, but the price is much higher than the Team plan (low 5 figures according to Segment&amp;#39;s sales person).&lt;/p&gt;\n\n&lt;p&gt;Can anyone confirm or clarify that? If we use Segment&amp;#39;s Team plan, are we in breach of the UK GDPR?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "136mm71", "is_robot_indexable": true, "report_reasons": null, "author": "cyberfunk2066", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136mm71/segment_and_uk_gdpr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136mm71/segment_and_uk_gdpr/", "subreddit_subscribers": 104007, "created_utc": 1683123750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Engineering as a field has lots of things to be done as a data engineer, how do you learn all that's required and be confident of it too, for eg: Databases(SQL, NoSQL), Cloud(AWS, Azure), ETL (Dbt, etc..), Python/Scala, Linux, DevOps/CI-CD tools(Git, Jenkins, etc..), Orchestration (airflow, Luigi).\n\nHow do you keep up with learning all these? Please reply if you are an experienced DE.", "author_fullname": "t2_60oji2x5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Know-how - To the Experienced Folks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137julp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683204986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Engineering as a field has lots of things to be done as a data engineer, how do you learn all that&amp;#39;s required and be confident of it too, for eg: Databases(SQL, NoSQL), Cloud(AWS, Azure), ETL (Dbt, etc..), Python/Scala, Linux, DevOps/CI-CD tools(Git, Jenkins, etc..), Orchestration (airflow, Luigi).&lt;/p&gt;\n\n&lt;p&gt;How do you keep up with learning all these? Please reply if you are an experienced DE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137julp", "is_robot_indexable": true, "report_reasons": null, "author": "rakash_ram", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137julp/data_engineering_knowhow_to_the_experienced_folks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137julp/data_engineering_knowhow_to_the_experienced_folks/", "subreddit_subscribers": 104007, "created_utc": 1683204986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The vector database hype explained - the story of Victor Hector and Lecter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_137i1gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fdrtyazIWJ479hucWX56dknNQEK8GDYpxajsPp87-5I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683200374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "thdpth.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://thdpth.substack.com/p/the-vector-database-hype-explained", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?auto=webp&amp;v=enabled&amp;s=42a0117c34e9e5145582dce01f9c7f7504def609", "width": 1073, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e881cc60390fcacb4088f27d9333c08519358a9a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=191c6a7cc20abe56155ab48b8858f9379afa9b69", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0156be3a4820b6132713908b7606d9d6940fb1f9", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbbb65b969d955ed141bc1c7e3e1ae484bd55671", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/UXUfb_EHgvRHCvwRs42AHzon-mAGKYt9nkZl9aw-vqQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=195c32edd5d04639a1a8fa7069423143c2a4d812", "width": 960, "height": 536}], "variants": {}, "id": "fHTmoHPt8ioLJD_NFTiTNE-s68s9_8Y53Hg8GSg3BHI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137i1gx", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137i1gx/the_vector_database_hype_explained_the_story_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://thdpth.substack.com/p/the-vector-database-hype-explained", "subreddit_subscribers": 104007, "created_utc": 1683200374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nI changed the spark.scheduler.mode to FAIR to better share the resources of pyspark shell for the team I am working with. The problem however is very unusual, the pyspark shell works fine for me but the following colleagues face this issue: \"pyspark.sql.utils.IllegalArgumentException: &lt;exception str() failed&gt;\" for even the simplest commands like reading a simple file from s3 or using createDataFrame command. \n\nI have tried comparing sparkContext properties and couldn't find anything suspicious. What could be the solution?\n\n&amp;#x200B;\n\nAlso is there another way I can somehow leverage spark resources in a better manner to make simultaneous work smooth for the team?", "author_fullname": "t2_t9iw9tl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark - Resource Management for Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137h0kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683197458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I changed the spark.scheduler.mode to FAIR to better share the resources of pyspark shell for the team I am working with. The problem however is very unusual, the pyspark shell works fine for me but the following colleagues face this issue: &amp;quot;pyspark.sql.utils.IllegalArgumentException: &amp;lt;exception str() failed&amp;gt;&amp;quot; for even the simplest commands like reading a simple file from s3 or using createDataFrame command. &lt;/p&gt;\n\n&lt;p&gt;I have tried comparing sparkContext properties and couldn&amp;#39;t find anything suspicious. What could be the solution?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also is there another way I can somehow leverage spark resources in a better manner to make simultaneous work smooth for the team?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137h0kp", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-End4310", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137h0kp/spark_resource_management_for_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137h0kp/spark_resource_management_for_team/", "subreddit_subscribers": 104007, "created_utc": 1683197458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI have been reading a lot about data contracts and was hoping to implement them in the company I work for.\n\nBefore that, I had a few questions:\n\n\\- How many of you regularly use data contracts?\n\n\\- How do you create/represent them? Do you use Google's Protocol Buffers or Apache Avro or something different?\n\n\\- How do you enforce them? (This is the main question I'm struggling with - what's the least effort way or tool to enforce data contracts).\n\nThanks in advance!", "author_fullname": "t2_mytvjynu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data contracts - do you use them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137glbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683196175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been reading a lot about data contracts and was hoping to implement them in the company I work for.&lt;/p&gt;\n\n&lt;p&gt;Before that, I had a few questions:&lt;/p&gt;\n\n&lt;p&gt;- How many of you regularly use data contracts?&lt;/p&gt;\n\n&lt;p&gt;- How do you create/represent them? Do you use Google&amp;#39;s Protocol Buffers or Apache Avro or something different?&lt;/p&gt;\n\n&lt;p&gt;- How do you enforce them? (This is the main question I&amp;#39;m struggling with - what&amp;#39;s the least effort way or tool to enforce data contracts).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137glbo", "is_robot_indexable": true, "report_reasons": null, "author": "a-layerup", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "subreddit_subscribers": 104007, "created_utc": 1683196175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently we are extracting full operational db table to landing zone (inside data warehouse) where it goes to daily partition. So for each daily partition there\u2019s a full db table. Is this good practise? Would it be better to have partitions based on updated field that comes from the source? Then it wouldn\u2019t create that much data that is actually the same data.", "author_fullname": "t2_ed8ku5bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landing layer question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ff79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683192527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we are extracting full operational db table to landing zone (inside data warehouse) where it goes to daily partition. So for each daily partition there\u2019s a full db table. Is this good practise? Would it be better to have partitions based on updated field that comes from the source? Then it wouldn\u2019t create that much data that is actually the same data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137ff79", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Bike_316", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137ff79/landing_layer_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137ff79/landing_layer_question/", "subreddit_subscribers": 104007, "created_utc": 1683192527.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}