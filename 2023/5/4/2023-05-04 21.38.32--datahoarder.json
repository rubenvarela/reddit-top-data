{"kind": "Listing", "data": {"after": "t3_1372br2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_f3l6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This Reddit Community Has Been Archived", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1371qr6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 559, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 559, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1683152968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "the-eye.eu", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://the-eye.eu/redarcs/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Not As Retired", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1371qr6", "is_robot_indexable": true, "report_reasons": null, "author": "-Archivist", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1371qr6/this_reddit_community_has_been_archived/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://the-eye.eu/redarcs/", "subreddit_subscribers": 680781, "created_utc": 1683152968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1a927l58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze Drive Stats for Q1 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_137ph3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 103, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 103, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V8o7cXx1QEk8lEkn7a2F7atC7Yu4_vyb9x78iRqIlzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683213195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "backblaze.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.backblaze.com/blog/backblaze-drive-stats-for-q1-2023/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?auto=webp&amp;v=enabled&amp;s=7e0fbaa59bc74324c931fc919ce4ce4b6fc47713", "width": 1440, "height": 820}, "resolutions": [{"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b593ab5ad325fba3286ead5f7ec500d855b87080", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b195378190a30a40018bfbdff1ea752e274eedf8", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4daeb1ff1c2e8a4f02e3214dbbd3be9991e43041", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccbae6ca1eed6a581cb6cb40006908cc05b8f6e6", "width": 640, "height": 364}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17a17b35c344a41142aa16f52565d84a08b8df62", "width": 960, "height": 546}, {"url": "https://external-preview.redd.it/ENKmkg9sCOawGhQeMf7xl4b75gyiHgaDLjh7h9PCmaU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91d94c5d5d95d67b5faca45296142c45adf1dfbc", "width": 1080, "height": 615}], "variants": {}, "id": "m0ieKlY8zlIxLzAoz0IgGYiLvyxDDRZuQnsTWWjU0PI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137ph3i", "is_robot_indexable": true, "report_reasons": null, "author": "g0rbe", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137ph3i/backblaze_drive_stats_for_q1_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.backblaze.com/blog/backblaze-drive-stats-for-q1-2023/", "subreddit_subscribers": 680781, "created_utc": 1683213195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "is it better to have a backup and a main, let the main hard drive be used til it dies, then use the backup and make another backup \n\nor is it better to have backup and main, and every month, swap them over monthly to keep them warm and used\n\ni plan on eventually using lto tape to long term backup, but for now i have less money . my 10 tb music hard drive is always in use, external hard drive, i use it 24 7 and i wonder, should i have my backup in storage in my trunk ready for when my primary drive dies, or should i alternate between them regularly", "author_fullname": "t2_1153xs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "better to alternate backup and main or let main die first", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1373nuw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683157725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is it better to have a backup and a main, let the main hard drive be used til it dies, then use the backup and make another backup &lt;/p&gt;\n\n&lt;p&gt;or is it better to have backup and main, and every month, swap them over monthly to keep them warm and used&lt;/p&gt;\n\n&lt;p&gt;i plan on eventually using lto tape to long term backup, but for now i have less money . my 10 tb music hard drive is always in use, external hard drive, i use it 24 7 and i wonder, should i have my backup in storage in my trunk ready for when my primary drive dies, or should i alternate between them regularly&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1373nuw", "is_robot_indexable": true, "report_reasons": null, "author": "KozmicBlooze", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1373nuw/better_to_alternate_backup_and_main_or_let_main/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1373nuw/better_to_alternate_backup_and_main_or_let_main/", "subreddit_subscribers": 680781, "created_utc": 1683157725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In another post someone whined about how data hoarders are just wasting their time keeping stuff no one will see.\n\nWhich does bring me to think. If I wanted to share the stuff I have hoarded how do I go about it? I don't necessarily mean whip a torrent and throw it out on the high seas, but have the ability that when someone says \"I'm looking for X\" I can respond \"I got it\".\n\nIs there such a way? What do you think?", "author_fullname": "t2_vue5jfe0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you/we share the stuff we hoard so those looking for stuff find it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1372jo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683154893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In another post someone whined about how data hoarders are just wasting their time keeping stuff no one will see.&lt;/p&gt;\n\n&lt;p&gt;Which does bring me to think. If I wanted to share the stuff I have hoarded how do I go about it? I don&amp;#39;t necessarily mean whip a torrent and throw it out on the high seas, but have the ability that when someone says &amp;quot;I&amp;#39;m looking for X&amp;quot; I can respond &amp;quot;I got it&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Is there such a way? What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1372jo1", "is_robot_indexable": true, "report_reasons": null, "author": "tootallsol", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1372jo1/how_do_youwe_share_the_stuff_we_hoard_so_those/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1372jo1/how_do_youwe_share_the_stuff_we_hoard_so_those/", "subreddit_subscribers": 680781, "created_utc": 1683154893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was originally going to grab a 12TB Exos off of Server Part Deals, but after further research, these \"enterprise tier\" drives are apparently super noisy and vibrate a lot, even at idle, and I'm not looking to buy a NAS setup anytime soon. I only have so much money and I just want a cheap and quick fix for the time being.\n\nI want something with a lot of storage that I can stick directly into my PC and not be any nosier than my two old 1TB HDDs already are. For reference, my drives aren't any louder than my CPU cooler (Dark Rock Pro 4) or case fans when I'm idle, and aren't that much louder than them when writing either.\n\nI'm mainly going to be using this new drive to store unimportant videos and miscellaneous files, so it doesn't need to be fast. I'm hoping that I can get one at a good price ($100 - $150 range). Any ideas? Would a Barracuda be better in this instance with the slower RPM?\n\nUnfortunately, anything above 8TB seems to be exponentially more expensive on Amazon, but I can live with just 8TB for years to come. I mainly just want the extra storage for convenience as my +5 years of hoarding have only just started to max out my whopping 3TB total of drives.\n\nThanks in advance!", "author_fullname": "t2_1azvp51y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New and clueless buyer looking for a quiet HDD.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dqg4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683186900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was originally going to grab a 12TB Exos off of Server Part Deals, but after further research, these &amp;quot;enterprise tier&amp;quot; drives are apparently super noisy and vibrate a lot, even at idle, and I&amp;#39;m not looking to buy a NAS setup anytime soon. I only have so much money and I just want a cheap and quick fix for the time being.&lt;/p&gt;\n\n&lt;p&gt;I want something with a lot of storage that I can stick directly into my PC and not be any nosier than my two old 1TB HDDs already are. For reference, my drives aren&amp;#39;t any louder than my CPU cooler (Dark Rock Pro 4) or case fans when I&amp;#39;m idle, and aren&amp;#39;t that much louder than them when writing either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m mainly going to be using this new drive to store unimportant videos and miscellaneous files, so it doesn&amp;#39;t need to be fast. I&amp;#39;m hoping that I can get one at a good price ($100 - $150 range). Any ideas? Would a Barracuda be better in this instance with the slower RPM?&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, anything above 8TB seems to be exponentially more expensive on Amazon, but I can live with just 8TB for years to come. I mainly just want the extra storage for convenience as my +5 years of hoarding have only just started to max out my whopping 3TB total of drives.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137dqg4", "is_robot_indexable": true, "report_reasons": null, "author": "xYamax", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137dqg4/new_and_clueless_buyer_looking_for_a_quiet_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137dqg4/new_and_clueless_buyer_looking_for_a_quiet_hdd/", "subreddit_subscribers": 680781, "created_utc": 1683186900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are some movies and TV shows that you've found in high quality? It can be easy to find almost anything but I'm specifically talking about high quality files. A fan remaster or an AI upscale or maybe just a high quality project that was removed or gone now. For an example, I have been looking for the 1995 reboot series of the outer limits. I found some low-quality copies floating around and eventually stumbled on a 1080p AI upscale in a totally random place and it seriously looks like a Blu-ray remastered it's absolutely amazing. Just wondering what other cool gems people have found?", "author_fullname": "t2_95h04o2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a rare or hard to find movie or tv show you've found in high quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1370ukr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683150961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some movies and TV shows that you&amp;#39;ve found in high quality? It can be easy to find almost anything but I&amp;#39;m specifically talking about high quality files. A fan remaster or an AI upscale or maybe just a high quality project that was removed or gone now. For an example, I have been looking for the 1995 reboot series of the outer limits. I found some low-quality copies floating around and eventually stumbled on a 1080p AI upscale in a totally random place and it seriously looks like a Blu-ray remastered it&amp;#39;s absolutely amazing. Just wondering what other cool gems people have found?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1370ukr", "is_robot_indexable": true, "report_reasons": null, "author": "Rob_Mortuary", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1370ukr/what_is_a_rare_or_hard_to_find_movie_or_tv_show/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1370ukr/what_is_a_rare_or_hard_to_find_movie_or_tv_show/", "subreddit_subscribers": 680781, "created_utc": 1683150961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I archive YouTube livestreams on my PC by using ytarchive (channel monitor function) running 24/7. But my PC is pretty high end and I don't necessarily want it running 24/7 just for this purpose. I was thinking of getting a cheap laptop just for running the livestream archiving program, but I heard laptops aren't great for 24/7 use (but they can be purchased for pretty cheap!) because of dust and fans being difficult to replace. Any suggestions from other data hoarders?", "author_fullname": "t2_14zhkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap computer for archiving livestreams: any experiences/suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137t6c9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683219540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I archive YouTube livestreams on my PC by using ytarchive (channel monitor function) running 24/7. But my PC is pretty high end and I don&amp;#39;t necessarily want it running 24/7 just for this purpose. I was thinking of getting a cheap laptop just for running the livestream archiving program, but I heard laptops aren&amp;#39;t great for 24/7 use (but they can be purchased for pretty cheap!) because of dust and fans being difficult to replace. Any suggestions from other data hoarders?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137t6c9", "is_robot_indexable": true, "report_reasons": null, "author": "fenrisulfr-pnw", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137t6c9/cheap_computer_for_archiving_livestreams_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137t6c9/cheap_computer_for_archiving_livestreams_any/", "subreddit_subscribers": 680781, "created_utc": 1683219540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In my ~decade on Reddit I've curated a save folder with a lot of NSFW content (feels weird posting on /r/datahoarder with my porn alt, but here we are...). Using [eternity](https://eternity.portals.sh/) I have it organized into an excel file with post titles, subreddits, date posted, and links to the comments. Using this what would be the easiest way to mass download my collection so when imgur gets wiped I still have access to things and they don't get nuked on the 15th?  \n\nMy knowledge of programming is somewhat limited so an ELI5 explanation of what kind of script (if any) I would have to run would be appreciated.\n\n\nThanks.", "author_fullname": "t2_axv1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question regarding the Imgur ToS change", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1376lb5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683165888.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683165577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my ~decade on Reddit I&amp;#39;ve curated a save folder with a lot of NSFW content (feels weird posting on &lt;a href=\"/r/datahoarder\"&gt;/r/datahoarder&lt;/a&gt; with my porn alt, but here we are...). Using &lt;a href=\"https://eternity.portals.sh/\"&gt;eternity&lt;/a&gt; I have it organized into an excel file with post titles, subreddits, date posted, and links to the comments. Using this what would be the easiest way to mass download my collection so when imgur gets wiped I still have access to things and they don&amp;#39;t get nuked on the 15th?  &lt;/p&gt;\n\n&lt;p&gt;My knowledge of programming is somewhat limited so an ELI5 explanation of what kind of script (if any) I would have to run would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1376lb5", "is_robot_indexable": true, "report_reasons": null, "author": "my7676account", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1376lb5/question_regarding_the_imgur_tos_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1376lb5/question_regarding_the_imgur_tos_change/", "subreddit_subscribers": 680781, "created_utc": 1683165577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "this is how OS identifies the bridge:\n\n\n\n    May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_GETMAXLUN set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\n    May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_PREVENT_ALLOW set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\n    May  4 15:37:58 NomadBSD kernel: ugen0.3: &lt;JMicron JMS567&gt; at usbus0\n    May  4 15:37:58 NomadBSD kernel: umass2 on uhub0\n    May  4 15:37:58 NomadBSD kernel: umass2: &lt;JMicron JMS567, class 0/0, rev 2.10/66.01, addr 2&gt; on usbus0\n    May  4 15:37:58 NomadBSD kernel: umass2:  SCSI over Bulk-Only; quirks = 0x8100\n    May  4 15:37:58 NomadBSD kernel: umass2:4:2: Attached to scbus4\n    May  4 15:37:58 NomadBSD kernel: da2 at umass-sim2 bus 2 scbus4 target 0 lun 0\n    May  4 15:37:58 NomadBSD kernel: da2: &lt;ST1000LM 024 HN-M101MBB 6601&gt; Fixed Direct Access SPC-4 SCSI device\n    May  4 15:37:58 NomadBSD kernel: da2: Serial Number DB9876543211545\n    May  4 15:37:58 NomadBSD kernel: da2: 40.000MB/s transfers\n    May  4 15:37:58 NomadBSD kernel: da2: 953869MB (1953525168 512 byte sectors)\n    May  4 15:37:58 NomadBSD kernel: da2: quirks=0x2&lt;NO_6_BYTE&gt;\n\n\n\nwhen issuing normal inquiry, smartctl says:\n\n\n    /dev/da2: Unknown USB bridge [0x7825:0xa2a4 (0x6601)]\n    Please specify device type with the -d option.\n\n\nthe only way to get anything from the drive is through:\n\n\n    root@NomadBSD:~ # smartctl -d sat,auto -a /dev/da2\n    smartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n    \n    === START OF INFORMATION SECTION ===\n    Vendor:               ST1000LM\n    Product:              024 HN-M101MBB\n    Revision:             6601\n    Compliance:           SPC-4\n    User Capacity:        1,000,204,886,016 bytes [1.00 TB]\n    &lt;snip&gt;\n\n\n\nunfortunately -A (get attributes) doesn't work - prints just the header... one would think that maybe specifying **usbjmicron** would be any better, but nada... it can't even open the device with this type (subparameters p and 0 don't work either):\n\n\n    root@NomadBSD:~ # smartctl -d usbjmicron -a /dev/da2\n    smartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n    \n    Smartctl open device: /dev/da2 [USB JMicron] failed: No device connected\n    \n\n\ni know that it is possible to get through this bridge - other programs are able to read SMART attributes (like CrystalDiskInfo or Victoria).\n\nis there *any* other way? maybe somebody has the same enclosure (bridge) and figured this out?", "author_fullname": "t2_14uv2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "get SMART attributes (via smartctl) through JMicron JMS567 USB bridge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137na7l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683211045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;this is how OS identifies the bridge:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;May  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_GETMAXLUN set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\nMay  4 15:37:58 NomadBSD kernel: usb_msc_auto_quirk: UQ_MSC_NO_PREVENT_ALLOW set for USB mass storage device JMicron JMS567 (0x7825:0xa2a4)\nMay  4 15:37:58 NomadBSD kernel: ugen0.3: &amp;lt;JMicron JMS567&amp;gt; at usbus0\nMay  4 15:37:58 NomadBSD kernel: umass2 on uhub0\nMay  4 15:37:58 NomadBSD kernel: umass2: &amp;lt;JMicron JMS567, class 0/0, rev 2.10/66.01, addr 2&amp;gt; on usbus0\nMay  4 15:37:58 NomadBSD kernel: umass2:  SCSI over Bulk-Only; quirks = 0x8100\nMay  4 15:37:58 NomadBSD kernel: umass2:4:2: Attached to scbus4\nMay  4 15:37:58 NomadBSD kernel: da2 at umass-sim2 bus 2 scbus4 target 0 lun 0\nMay  4 15:37:58 NomadBSD kernel: da2: &amp;lt;ST1000LM 024 HN-M101MBB 6601&amp;gt; Fixed Direct Access SPC-4 SCSI device\nMay  4 15:37:58 NomadBSD kernel: da2: Serial Number DB9876543211545\nMay  4 15:37:58 NomadBSD kernel: da2: 40.000MB/s transfers\nMay  4 15:37:58 NomadBSD kernel: da2: 953869MB (1953525168 512 byte sectors)\nMay  4 15:37:58 NomadBSD kernel: da2: quirks=0x2&amp;lt;NO_6_BYTE&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;when issuing normal inquiry, smartctl says:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;/dev/da2: Unknown USB bridge [0x7825:0xa2a4 (0x6601)]\nPlease specify device type with the -d option.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;the only way to get anything from the drive is through:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root@NomadBSD:~ # smartctl -d sat,auto -a /dev/da2\nsmartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n\n=== START OF INFORMATION SECTION ===\nVendor:               ST1000LM\nProduct:              024 HN-M101MBB\nRevision:             6601\nCompliance:           SPC-4\nUser Capacity:        1,000,204,886,016 bytes [1.00 TB]\n&amp;lt;snip&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;unfortunately -A (get attributes) doesn&amp;#39;t work - prints just the header... one would think that maybe specifying &lt;strong&gt;usbjmicron&lt;/strong&gt; would be any better, but nada... it can&amp;#39;t even open the device with this type (subparameters p and 0 don&amp;#39;t work either):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root@NomadBSD:~ # smartctl -d usbjmicron -a /dev/da2\nsmartctl 7.3 2022-02-28 r5338 [FreeBSD 13.1-RELEASE-p5 amd64] (local build)\nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n\nSmartctl open device: /dev/da2 [USB JMicron] failed: No device connected\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;i know that it is possible to get through this bridge - other programs are able to read SMART attributes (like CrystalDiskInfo or Victoria).&lt;/p&gt;\n\n&lt;p&gt;is there &lt;em&gt;any&lt;/em&gt; other way? maybe somebody has the same enclosure (bridge) and figured this out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137na7l", "is_robot_indexable": true, "report_reasons": null, "author": "paprok", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137na7l/get_smart_attributes_via_smartctl_through_jmicron/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137na7l/get_smart_attributes_via_smartctl_through_jmicron/", "subreddit_subscribers": 680781, "created_utc": 1683211045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planning to build my own NAS system that runs mainly for Plex but also a little bit of something else.\n\nSince I'm going to put the system in my own room, I was planning to get the WD Red Plus with 8TB that runs at 5640RPM as it should technically be much quieter than those 7200RPM ones.\n\nHowever, as I was reading WD's specification about their drives, I learned that apparently the 12TB and above ones are all heliosealed and should be even quieter than the 8TB one according to their own documents.\n\nMeanwhile, I'm can still read from some places that the 12TB ones can still be quite annoying as you can hear high pitch noise from them.\n\nNow I'm just really confused and really need someone who actually owns both of them to give me their suggestions.\n\ntl;dr I'd like to know the quietest HDD with large capacity.", "author_fullname": "t2_k3g4b5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noise level 5640RPM air-sealed vs 7200RPM heliosealed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dxc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683187528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning to build my own NAS system that runs mainly for Plex but also a little bit of something else.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m going to put the system in my own room, I was planning to get the WD Red Plus with 8TB that runs at 5640RPM as it should technically be much quieter than those 7200RPM ones.&lt;/p&gt;\n\n&lt;p&gt;However, as I was reading WD&amp;#39;s specification about their drives, I learned that apparently the 12TB and above ones are all heliosealed and should be even quieter than the 8TB one according to their own documents.&lt;/p&gt;\n\n&lt;p&gt;Meanwhile, I&amp;#39;m can still read from some places that the 12TB ones can still be quite annoying as you can hear high pitch noise from them.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m just really confused and really need someone who actually owns both of them to give me their suggestions.&lt;/p&gt;\n\n&lt;p&gt;tl;dr I&amp;#39;d like to know the quietest HDD with large capacity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137dxc9", "is_robot_indexable": true, "report_reasons": null, "author": "Paul860913", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137dxc9/noise_level_5640rpm_airsealed_vs_7200rpm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137dxc9/noise_level_5640rpm_airsealed_vs_7200rpm/", "subreddit_subscribers": 680781, "created_utc": 1683187528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I download stuff from YouTube with yt-dlp and use the options `--embed-metadata` and `--embed-thumbnail`. If the output file is an mp4 I can easily see such metadata with kid3, but in mkv files I can only see them in vlc and not even all of them, or with mkvtoolnix-gui I can export the thumbnail which is saved as an attachment. For this reason I tend to always use the mp4 container even if the codecs are vp9/opus.\n\nI looked around but counldn't find anything about metadata management for mkv files. Usually mkv are what everybody recommends, but I can't switch to them because of this reason. It also feels limiting to depend on one container format and one specific software for this, and on top of that vlc can't see metadata in mp4 files, so it's either one or the other.\n\nSaving this data in separate files is a no-go for me, downloading a channel already results in hundreds of files, I don't want them to become thousands, it would make browsing folders a nightmare.\n\nDo you have suggestions? Preferably using free software for Linux.", "author_fullname": "t2_vmnrc67i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mkv vs mp4 metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1370owm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683150599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I download stuff from YouTube with yt-dlp and use the options &lt;code&gt;--embed-metadata&lt;/code&gt; and &lt;code&gt;--embed-thumbnail&lt;/code&gt;. If the output file is an mp4 I can easily see such metadata with kid3, but in mkv files I can only see them in vlc and not even all of them, or with mkvtoolnix-gui I can export the thumbnail which is saved as an attachment. For this reason I tend to always use the mp4 container even if the codecs are vp9/opus.&lt;/p&gt;\n\n&lt;p&gt;I looked around but counldn&amp;#39;t find anything about metadata management for mkv files. Usually mkv are what everybody recommends, but I can&amp;#39;t switch to them because of this reason. It also feels limiting to depend on one container format and one specific software for this, and on top of that vlc can&amp;#39;t see metadata in mp4 files, so it&amp;#39;s either one or the other.&lt;/p&gt;\n\n&lt;p&gt;Saving this data in separate files is a no-go for me, downloading a channel already results in hundreds of files, I don&amp;#39;t want them to become thousands, it would make browsing folders a nightmare.&lt;/p&gt;\n\n&lt;p&gt;Do you have suggestions? Preferably using free software for Linux.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1370owm", "is_robot_indexable": true, "report_reasons": null, "author": "Few-Associate2009", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1370owm/mkv_vs_mp4_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1370owm/mkv_vs_mp4_metadata/", "subreddit_subscribers": 680781, "created_utc": 1683150599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know quite a few formats E.g mkv are not worth zipping as they are already compressed. \n\nDoes anyone know if the same applies to epub or other ebook formats?\n\nMy motivation is to pay less for cloud backups.", "author_fullname": "t2_d2ja9fnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does epub compress well?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137vuob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683225366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know quite a few formats E.g mkv are not worth zipping as they are already compressed. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know if the same applies to epub or other ebook formats?&lt;/p&gt;\n\n&lt;p&gt;My motivation is to pay less for cloud backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137vuob", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Warning-4186", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137vuob/does_epub_compress_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137vuob/does_epub_compress_well/", "subreddit_subscribers": 680781, "created_utc": 1683225366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from DS1513+ with DX513 to DS2422+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ucxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2elzat07", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "synology", "selftext": "I got one volume expanded over both units (yes I know..) both units are populated full and with mostly 10tb drives. The DS1513+ is runnning latest DSM 7.1.1-42962 Update 5\n\nThis has been running nicely.\n\nCan I just pop all 10 drives in the DS2422+ and voila?", "author_fullname": "t2_2elzat07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from DS1513+ with DX513 to DS2422+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/synology", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_134m4tm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "NAS hardware", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682946702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got one volume expanded over both units (yes I know..) both units are populated full and with mostly 10tb drives. The DS1513+ is runnning latest DSM 7.1.1-42962 Update 5&lt;/p&gt;\n\n&lt;p&gt;This has been running nicely.&lt;/p&gt;\n\n&lt;p&gt;Can I just pop all 10 drives in the DS2422+ and voila?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b45c7c8-4b25-11ed-a1f3-5a29a1a8c4d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4co", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "134m4tm", "is_robot_indexable": true, "report_reasons": null, "author": "sewzter", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "subreddit_subscribers": 122183, "created_utc": 1682946702.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1683222082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137ucxf", "is_robot_indexable": true, "report_reasons": null, "author": "sewzter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_134m4tm", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137ucxf/migrating_from_ds1513_with_dx513_to_ds2422/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/synology/comments/134m4tm/migrating_from_ds1513_with_dx513_to_ds2422/", "subreddit_subscribers": 680781, "created_utc": 1683222082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone!\n\nI have a problem with my setup and need some advice. I searched and asked here and there but got no answer.   \nSo the problem is the following : I have a couple of disks that i want to spindown while they are idling for 45-60 mins (they are idle almost the whole day). I use a 3gbps  HP - 487738-001 SAS Expander card with SFF8087 (Mini Sas) to sata break out cable. On the host machine i have a simple LSI HBA with 2xSFF8088 ports. The problem is that the drives are never spindown as i configured them under TrueNAS Scale.   \nThe questions are the following : \n\n1. Do the Expander / HBA prevents HDD Spindown? If yes, how can i bypass this?\n2. Do TrueNAS prevents Spindown? (The drives set to minimal power consumption with spindown after 60min of idle time + System DataSet is on another Pool.\n\nThe spindown is actually to save on my Electricity Bill (im from Europe -&gt; Germany -&gt; 0,40Euro/kWh)  \n\n\nIf it is the wrong thread, please leave a comment where should i post it. Many thanks! :)", "author_fullname": "t2_5q5zg4h0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Spindown", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137sc21", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683217687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I have a problem with my setup and need some advice. I searched and asked here and there but got no answer.&lt;br/&gt;\nSo the problem is the following : I have a couple of disks that i want to spindown while they are idling for 45-60 mins (they are idle almost the whole day). I use a 3gbps  HP - 487738-001 SAS Expander card with SFF8087 (Mini Sas) to sata break out cable. On the host machine i have a simple LSI HBA with 2xSFF8088 ports. The problem is that the drives are never spindown as i configured them under TrueNAS Scale.&lt;br/&gt;\nThe questions are the following : &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do the Expander / HBA prevents HDD Spindown? If yes, how can i bypass this?&lt;/li&gt;\n&lt;li&gt;Do TrueNAS prevents Spindown? (The drives set to minimal power consumption with spindown after 60min of idle time + System DataSet is on another Pool.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The spindown is actually to save on my Electricity Bill (im from Europe -&amp;gt; Germany -&amp;gt; 0,40Euro/kWh)  &lt;/p&gt;\n\n&lt;p&gt;If it is the wrong thread, please leave a comment where should i post it. Many thanks! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137sc21", "is_robot_indexable": true, "report_reasons": null, "author": "iShane94", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137sc21/hdd_spindown/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137sc21/hdd_spindown/", "subreddit_subscribers": 680781, "created_utc": 1683217687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " So I\u2019ve got a bunch of DVDs and Blu-rays that I never take out of the case any more, I want to get them ripped and on to a service like Plex (or a different one if there\u2019s a better service, that\u2019s just the only one I know.) I\u2019m looking for advice on the best software to rip the movies, ideally with the menu and everything intact.  \n\n\nAlso, I don\u2019t even have a Blu-ray drive on my computer, so I\u2019m going to have buy one. If there\u2019s some hardware that\u2019s specifically designed for ripping movies that could be interesting.  \n\n\nI haven\u2019t ripped anything in like 10 years, so any advice you can give me would be greatly appreciated.", "author_fullname": "t2_7grcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help Porting DVD/Blu-ray Library to Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137rjbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683215971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve got a bunch of DVDs and Blu-rays that I never take out of the case any more, I want to get them ripped and on to a service like Plex (or a different one if there\u2019s a better service, that\u2019s just the only one I know.) I\u2019m looking for advice on the best software to rip the movies, ideally with the menu and everything intact.  &lt;/p&gt;\n\n&lt;p&gt;Also, I don\u2019t even have a Blu-ray drive on my computer, so I\u2019m going to have buy one. If there\u2019s some hardware that\u2019s specifically designed for ripping movies that could be interesting.  &lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t ripped anything in like 10 years, so any advice you can give me would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137rjbv", "is_robot_indexable": true, "report_reasons": null, "author": "Honbomb", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137rjbv/need_help_porting_dvdbluray_library_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137rjbv/need_help_porting_dvdbluray_library_to_cloud/", "subreddit_subscribers": 680781, "created_utc": 1683215971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got 102 2gb files to download for my Google Photos data export.  I'm using IDM to download, but figured out how to automate it so I don't have to click each individual link.  One issue seems to be that I can't get IDM/Google to play nice, as the downloads sometimes require my login/password, and for some reason Google isn't accepting the credentials submitted via IDM.\n\nI realize there's probably some necessary information I haven't provided, but am savvy enough to be able to get whatever info is needed.  Any help you folks can provide would be greatly appreciated :-)", "author_fullname": "t2_frcwun8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Download Manager and Google Photos Export", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137o5v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683211825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got 102 2gb files to download for my Google Photos data export.  I&amp;#39;m using IDM to download, but figured out how to automate it so I don&amp;#39;t have to click each individual link.  One issue seems to be that I can&amp;#39;t get IDM/Google to play nice, as the downloads sometimes require my login/password, and for some reason Google isn&amp;#39;t accepting the credentials submitted via IDM.&lt;/p&gt;\n\n&lt;p&gt;I realize there&amp;#39;s probably some necessary information I haven&amp;#39;t provided, but am savvy enough to be able to get whatever info is needed.  Any help you folks can provide would be greatly appreciated :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137o5v1", "is_robot_indexable": true, "report_reasons": null, "author": "Papapot1755", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137o5v1/internet_download_manager_and_google_photos_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137o5v1/internet_download_manager_and_google_photos_export/", "subreddit_subscribers": 680781, "created_utc": 1683211825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted to share my frustrating experience with Western Digital's RMA service. At the beginning of April, my Easystore 14tb hard drive stopped working, even though I hadn't filled up its entire capacity yet. Since the drive was under warranty, I tried to start an RMA process on Western Digital's website, only to find that the service was unavailable due to a hacking incident.\n\nI kept checking the website status every day, and on April 18, I noticed that the RMA service was back online. I submitted my RMA request on the same day and shipped the package to Western Digital. According to the package tracking, it was delivered on April 21. However, today is May 4th, and my RMA case still shows \"pending return,\" which means Western Digital hasn't even updated the status to confirm that they received my drive.\n\nI even contacted Western Digital's Twitter customer service, who told me that it would take 5 to 7 business days to process the RMA. However, it's been way more than that since the package was delivered.\n\nI understand that Western Digital might be dealing with a backlog of RMAs, but it's unacceptable to leave customers in the dark for weeks without any updates. My experience has left me feeling frustrated and disappointed in Western Digital's customer service. \n\n  \nI lost all of my data and waited for a month just want to process my RMA!!! I will stay away from their drives now. \n\nIn addition, Seagate provides free NTFS software for Mac and they also provide free data recovery service for the defective drive.  \n\nI hope that by sharing my story, others can be aware of the potential issues with Western Digital's RMA service.", "author_fullname": "t2_7zmggtym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My frustrating experience with Western Digital's EXTREMELY SLOW RMA service", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137n7ua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683210983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to share my frustrating experience with Western Digital&amp;#39;s RMA service. At the beginning of April, my Easystore 14tb hard drive stopped working, even though I hadn&amp;#39;t filled up its entire capacity yet. Since the drive was under warranty, I tried to start an RMA process on Western Digital&amp;#39;s website, only to find that the service was unavailable due to a hacking incident.&lt;/p&gt;\n\n&lt;p&gt;I kept checking the website status every day, and on April 18, I noticed that the RMA service was back online. I submitted my RMA request on the same day and shipped the package to Western Digital. According to the package tracking, it was delivered on April 21. However, today is May 4th, and my RMA case still shows &amp;quot;pending return,&amp;quot; which means Western Digital hasn&amp;#39;t even updated the status to confirm that they received my drive.&lt;/p&gt;\n\n&lt;p&gt;I even contacted Western Digital&amp;#39;s Twitter customer service, who told me that it would take 5 to 7 business days to process the RMA. However, it&amp;#39;s been way more than that since the package was delivered.&lt;/p&gt;\n\n&lt;p&gt;I understand that Western Digital might be dealing with a backlog of RMAs, but it&amp;#39;s unacceptable to leave customers in the dark for weeks without any updates. My experience has left me feeling frustrated and disappointed in Western Digital&amp;#39;s customer service. &lt;/p&gt;\n\n&lt;p&gt;I lost all of my data and waited for a month just want to process my RMA!!! I will stay away from their drives now. &lt;/p&gt;\n\n&lt;p&gt;In addition, Seagate provides free NTFS software for Mac and they also provide free data recovery service for the defective drive.  &lt;/p&gt;\n\n&lt;p&gt;I hope that by sharing my story, others can be aware of the potential issues with Western Digital&amp;#39;s RMA service.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "137n7ua", "is_robot_indexable": true, "report_reasons": null, "author": "superee33", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137n7ua/my_frustrating_experience_with_western_digitals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137n7ua/my_frustrating_experience_with_western_digitals/", "subreddit_subscribers": 680781, "created_utc": 1683210983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I managed to scan all the books i purchased now I want to convert it into searchable text. Do you guys know any site or app to convert large files (100mb+) into searchable text via OCR or other methods?", "author_fullname": "t2_t2ay8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OCR for Large Files and Books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137b1zd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683178063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I managed to scan all the books i purchased now I want to convert it into searchable text. Do you guys know any site or app to convert large files (100mb+) into searchable text via OCR or other methods?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137b1zd", "is_robot_indexable": true, "report_reasons": null, "author": "Yordzz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137b1zd/ocr_for_large_files_and_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137b1zd/ocr_for_large_files_and_books/", "subreddit_subscribers": 680781, "created_utc": 1683178063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've been downloading Twitch VODs for 3 years, having 75+ TB, but I'm starting to hate pasting links one by one every day in a span of 16 hours a day. Now it's getting out of hand and I'm starting to not keep up to download all the VODs in time (I'm 45-59 days behind the newest VOD most of the time, now reached the 60 multiple times after doing just fine for 2 years :/). I tried Tartube, but it just don't download at all. Am I doing something wrong? Is there any other downloader that will do what I want? Thanks for help. I just don't want to end downloading VODs because I don't care as much.", "author_fullname": "t2_4k764gx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitch Downloader that will download a full channel VODs without needing to paste links", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137200f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683154057.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683153564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been downloading Twitch VODs for 3 years, having 75+ TB, but I&amp;#39;m starting to hate pasting links one by one every day in a span of 16 hours a day. Now it&amp;#39;s getting out of hand and I&amp;#39;m starting to not keep up to download all the VODs in time (I&amp;#39;m 45-59 days behind the newest VOD most of the time, now reached the 60 multiple times after doing just fine for 2 years :/). I tried Tartube, but it just don&amp;#39;t download at all. Am I doing something wrong? Is there any other downloader that will do what I want? Thanks for help. I just don&amp;#39;t want to end downloading VODs because I don&amp;#39;t care as much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137200f", "is_robot_indexable": true, "report_reasons": null, "author": "Duajkfn", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137200f/twitch_downloader_that_will_download_a_full/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137200f/twitch_downloader_that_will_download_a_full/", "subreddit_subscribers": 680781, "created_utc": 1683153564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve been tinkering with libgen torrents for fun (metadata fanatic) but the files I down have no extensions. I have read I need to assign extensions based on an md5 (or some such) db table.  \nI\u2019ve sifted the files and the web but can\u2019t find anything about building bulk archives, only single file extraction.  \nAnyone here read about this by chance?\n\nYea, I know, it would be &gt;100TB for fiction alone, not of interest to me. It\u2019s the tech publications I want to analyze.  \nAny help would be greatly appreciated.", "author_fullname": "t2_97tl1p28", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Libgen archivists question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136zacl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683147418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with libgen torrents for fun (metadata fanatic) but the files I down have no extensions. I have read I need to assign extensions based on an md5 (or some such) db table.&lt;br/&gt;\nI\u2019ve sifted the files and the web but can\u2019t find anything about building bulk archives, only single file extraction.&lt;br/&gt;\nAnyone here read about this by chance?&lt;/p&gt;\n\n&lt;p&gt;Yea, I know, it would be &amp;gt;100TB for fiction alone, not of interest to me. It\u2019s the tech publications I want to analyze.&lt;br/&gt;\nAny help would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "136zacl", "is_robot_indexable": true, "report_reasons": null, "author": "Hungry-Sentence-6722", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/136zacl/libgen_archivists_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/136zacl/libgen_archivists_question/", "subreddit_subscribers": 680781, "created_utc": 1683147418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using 1DM+ to download Twitter videos for a few years without issue, but in the last few weeks I've been getting this error regardless of what kinds of videos I'm attempting to download.  \n\nEven when doing as the error says, and using the 1DM+ Browser to access Twitter and using the injected green Download button fails to grab any videos.\n\nAnyone have experience troubleshooting 1DM+ or Twitter?  Are there alternatives to grabbing videos from my phone?\n\n[Error Image](https://imgur.com/a/J3bVSgX)", "author_fullname": "t2_164kxv33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading Twitter Videos with 1DM+ on Android", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137wzrt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683227855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using 1DM+ to download Twitter videos for a few years without issue, but in the last few weeks I&amp;#39;ve been getting this error regardless of what kinds of videos I&amp;#39;m attempting to download.  &lt;/p&gt;\n\n&lt;p&gt;Even when doing as the error says, and using the 1DM+ Browser to access Twitter and using the injected green Download button fails to grab any videos.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience troubleshooting 1DM+ or Twitter?  Are there alternatives to grabbing videos from my phone?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/J3bVSgX\"&gt;Error Image&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iqsKSBEz1JcK7KMu6WhS4_v5lkuGpUUfyIYt6OaA59I.jpg?auto=webp&amp;v=enabled&amp;s=b6ddefeabb2808f2652621554734e95bb229e8e5", "width": 955, "height": 609}, "resolutions": [{"url": "https://external-preview.redd.it/iqsKSBEz1JcK7KMu6WhS4_v5lkuGpUUfyIYt6OaA59I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed8ce21a53763fd8a8042df38aaac2512d6e99a5", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/iqsKSBEz1JcK7KMu6WhS4_v5lkuGpUUfyIYt6OaA59I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b53151511d148fc5074b9e8f6df1b5eebbd56003", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/iqsKSBEz1JcK7KMu6WhS4_v5lkuGpUUfyIYt6OaA59I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=194872425f5d6350feb57b2778a707ac05e9350a", "width": 320, "height": 204}, {"url": "https://external-preview.redd.it/iqsKSBEz1JcK7KMu6WhS4_v5lkuGpUUfyIYt6OaA59I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97e852c686943806c3a22fff263d3a904ff728ad", "width": 640, "height": 408}], "variants": {}, "id": "zKGuAicSQVe2_sFe9gtcTI-WCJXivYZbirqwmGuMUpc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137wzrt", "is_robot_indexable": true, "report_reasons": null, "author": "KapesMcNapes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137wzrt/downloading_twitter_videos_with_1dm_on_android/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137wzrt/downloading_twitter_videos_with_1dm_on_android/", "subreddit_subscribers": 680781, "created_utc": 1683227855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a 20TB ironwolf pro that I've been backing my movie collection to. It's about half way full at this point. \n\nAll of a sudden I've been getting messages in makemkv that it's outputting faster than the drive can write which to be fair I'm usually ripping multiple discs and remuxing subtitle fixes at the same time. \n\nI started to do some benchmarks like Atto which I actually score significantly higher than nascompares review however my crystaldiskmark is significantly lower, especially in the mixed 70% read 30% write. It's actually about half of nascompares score. Is this normal now that the drive is full or should I be concerned?", "author_fullname": "t2_7gpdlh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does mixed read/write performance slow as the drive fills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137pkv1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683213292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a 20TB ironwolf pro that I&amp;#39;ve been backing my movie collection to. It&amp;#39;s about half way full at this point. &lt;/p&gt;\n\n&lt;p&gt;All of a sudden I&amp;#39;ve been getting messages in makemkv that it&amp;#39;s outputting faster than the drive can write which to be fair I&amp;#39;m usually ripping multiple discs and remuxing subtitle fixes at the same time. &lt;/p&gt;\n\n&lt;p&gt;I started to do some benchmarks like Atto which I actually score significantly higher than nascompares review however my crystaldiskmark is significantly lower, especially in the mixed 70% read 30% write. It&amp;#39;s actually about half of nascompares score. Is this normal now that the drive is full or should I be concerned?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137pkv1", "is_robot_indexable": true, "report_reasons": null, "author": "Tresnugget", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137pkv1/does_mixed_readwrite_performance_slow_as_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/137pkv1/does_mixed_readwrite_performance_slow_as_the/", "subreddit_subscribers": 680781, "created_utc": 1683213292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8j0mbvmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which option would be better for backing up whatsapp messages? Or is there a better way to backup whatsapp messages for android?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_137geec", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w2N6CmyV18XHqnypITalmLs6bgRiFe6yGMU-WRBBb5g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683195590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4f7iev5o0uxa1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?auto=webp&amp;v=enabled&amp;s=c6ff3abcaf3cd9d27cd80f8bd8c3a71088a66ad7", "width": 1080, "height": 2400}, "resolutions": [{"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ddd798b25bfbd3bd0b1f126a42e5ca53e9ca74c4", "width": 108, "height": 216}, {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c29e93a08f8a0e8aa1b628d4fb3743206a35b2", "width": 216, "height": 432}, {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9d35c175b0b3b95c097b5bc89eaad2b4368bfc5", "width": 320, "height": 640}, {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e14f8c8b6173119b03f5d4b25d3429feffb84f0", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=716e04614d43256c2f647cbdd9ca54d902bb1f0d", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/4f7iev5o0uxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=688cb3be2468fa3fb8d10e75a4c04a7dc1c76dd5", "width": 1080, "height": 2160}], "variants": {}, "id": "-hfufxW26FXlZfGjRSSn_bUsyPiiANpZbUPuL9V_CJA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "137geec", "is_robot_indexable": true, "report_reasons": null, "author": "AtakanKoza", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/137geec/which_option_would_be_better_for_backing_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4f7iev5o0uxa1.png", "subreddit_subscribers": 680781, "created_utc": 1683195590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a good Reddit sub downloader that can grab all images gifs and videos for a sub which one do you recommend??  I do not want a Python script I am looking for something with a GUI or a exe installer.  I have been using Ripme which has not been updated in like 2 1/2 years I am getting a error with the program on most subs it will only download like 5% to 15% of the sub here is the error JSONObject[\"video\"] not found, there is no work around for this error I need another program.", "author_fullname": "t2_34nci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Good Reddit Sub Downloaders??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1372yxh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683155938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a good Reddit sub downloader that can grab all images gifs and videos for a sub which one do you recommend??  I do not want a Python script I am looking for something with a GUI or a exe installer.  I have been using Ripme which has not been updated in like 2 1/2 years I am getting a error with the program on most subs it will only download like 5% to 15% of the sub here is the error JSONObject[&amp;quot;video&amp;quot;] not found, there is no work around for this error I need another program.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1372yxh", "is_robot_indexable": true, "report_reasons": null, "author": "DJboutit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1372yxh/any_good_reddit_sub_downloaders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1372yxh/any_good_reddit_sub_downloaders/", "subreddit_subscribers": 680781, "created_utc": 1683155938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.westerndigital.com/en-se/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb](https://www.westerndigital.com/en-se/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb)  \n\n\nI need to upgrade real soon but i kinda dont want 22 TB but even bigger so...", "author_fullname": "t2_dqi7ja43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultrastar DC HC670 26 TB when is it releasing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1372br2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683154349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.westerndigital.com/en-se/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb\"&gt;https://www.westerndigital.com/en-se/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I need to upgrade real soon but i kinda dont want 22 TB but even bigger so...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?auto=webp&amp;v=enabled&amp;s=4077fbf3f5a789885dafc7866517fd7f7b22cfba", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4af28e64533dfcf0966caecdccabb962db15b339", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dfe87ddaa5ee6d6fa07d5b82c418c5256c53c56", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71ca55d187cdb57092190a529bd93dd9e0a075b0", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59598073f1407c1bcc94153fa03e84ccad1bd514", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b2cc577b493f118d1e9a516f0172c2307078bee", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6767ddaecfa1620f37c9d73d977cbe88ad32ef1", "width": 1080, "height": 1080}], "variants": {}, "id": "Khc_0UMAclTalgRJT3IYyERuIUrcrmbqKAeBllAcL7U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1372br2", "is_robot_indexable": true, "report_reasons": null, "author": "Patient-Culture2192", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1372br2/ultrastar_dc_hc670_26_tb_when_is_it_releasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1372br2/ultrastar_dc_hc670_26_tb_when_is_it_releasing/", "subreddit_subscribers": 680781, "created_utc": 1683154349.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}