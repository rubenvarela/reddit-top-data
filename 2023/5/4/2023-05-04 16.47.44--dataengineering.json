{"kind": "Listing", "data": {"after": "t3_137lajn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When collaborating with Software Engineering, Product, etc. there are always things that come up regarding best practices in a production database.\n\n* timestamps should always include a time zone and be stored in UTC (right?)\n* Foreign key constraints should always be defined on foreign keys\n* Column names should be descriptive\n* Boolean columns should begin with is\\_ or has\\_\n\nYou get the idea. There are dozens or hundreds of standards I could think of if I kept going.\n\nI see a few nascent attempts, but I'm surprised that with decades of SQL usage gone by, there aren't some standards that seem more.... authoritative at this point. Does anyone know of any semi-official standards, or have thoughts here?\n\n \\- [https://ovid.github.io/articles/database-design-standards.html](https://ovid.github.io/articles/database-design-standards.html)  \n \\- [https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e\\_0](https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0)  \n\n\nIt would be really handy to have something authoritative, at least as a starting point, instead of arguing about these from scratch and not getting anywhere.", "author_fullname": "t2_ikd9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there database design Standards out there? As in, formal documents listing exact best practices for OLTP database design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136rwag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683130690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When collaborating with Software Engineering, Product, etc. there are always things that come up regarding best practices in a production database.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;timestamps should always include a time zone and be stored in UTC (right?)&lt;/li&gt;\n&lt;li&gt;Foreign key constraints should always be defined on foreign keys&lt;/li&gt;\n&lt;li&gt;Column names should be descriptive&lt;/li&gt;\n&lt;li&gt;Boolean columns should begin with is_ or has_&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You get the idea. There are dozens or hundreds of standards I could think of if I kept going.&lt;/p&gt;\n\n&lt;p&gt;I see a few nascent attempts, but I&amp;#39;m surprised that with decades of SQL usage gone by, there aren&amp;#39;t some standards that seem more.... authoritative at this point. Does anyone know of any semi-official standards, or have thoughts here?&lt;/p&gt;\n\n&lt;p&gt;- &lt;a href=\"https://ovid.github.io/articles/database-design-standards.html\"&gt;https://ovid.github.io/articles/database-design-standards.html&lt;/a&gt;&lt;br/&gt;\n - &lt;a href=\"https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0\"&gt;https://fdotwww.blob.core.windows.net/sitefinity/docs/default-source/content/it/docs/standards/databasedesignstandards02042016.pdf?sfvrsn=115b611e_0&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;It would be really handy to have something authoritative, at least as a starting point, instead of arguing about these from scratch and not getting anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?auto=webp&amp;v=enabled&amp;s=abd422b029c6345857a292786ca4d16be8f2830c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6a53368b90bffe05ee4a4765df106a5400174de", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4545a61cb8c010f3742489c40dd2877a96b7619", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6c0886833f43676efe965b4c4a1d2497b453691", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af03f83ddb073cada8a305abcf0ba39ff9a96d0e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87afa074d6cd28277b31dc47df853cf74c8beb76", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/IuYNTb-6tn_e5zw-O-FPZnU6z3416rNLOnkCQmbAR58.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35eb4aee9f02195139fc1bc9f605d382690d0beb", "width": 1080, "height": 567}], "variants": {}, "id": "9KhCOfskbM2VYm3zdj6PLtIKhgqnUxOBHr5z1-emBYI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136rwag", "is_robot_indexable": true, "report_reasons": null, "author": "dlb8685", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136rwag/are_there_database_design_standards_out_there_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136rwag/are_there_database_design_standards_out_there_as/", "subreddit_subscribers": 104030, "created_utc": 1683130690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm interested in learning about the supplementary tools you use in conjunction with dbt and how they enhance your workflows. As we begin with dbt core, I'm curious to explore the complementary tools that work well alongside dbt. Please share your experiences and insights regarding the tools you find beneficial when using dbt.\n\nThanks,\n\nMc", "author_fullname": "t2_1v4h09lt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which supplementary tools are you using alongside dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137cym8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683184313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in learning about the supplementary tools you use in conjunction with dbt and how they enhance your workflows. As we begin with dbt core, I&amp;#39;m curious to explore the complementary tools that work well alongside dbt. Please share your experiences and insights regarding the tools you find beneficial when using dbt.&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n\n&lt;p&gt;Mc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137cym8", "is_robot_indexable": true, "report_reasons": null, "author": "mrcool444", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137cym8/which_supplementary_tools_are_you_using_alongside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137cym8/which_supplementary_tools_are_you_using_alongside/", "subreddit_subscribers": 104030, "created_utc": 1683184313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).\n\n\n\n\nEven ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of work can a data engineer do if they can't find employment as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137ij6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683202929.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683201719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employed as a data engineer, with about 5 years of experience across this field and devops.  I decided to give applying in this job market a try, and was surprised to see how competitive everything is even at smaller/less well-known companies.  Companies whose interview process 2 years ago involved asking candidates to find the most frequently occurring element in an array are now asking Leetcode hard questions and exact experience with certain technologies (even though it can be learned quickly!).&lt;/p&gt;\n\n&lt;p&gt;Even ignoring my work experience, I had a much easier time as a very average new grad engineer.  How can a data engineer get employed as soon as possible, if data and devops engineering jobs have gotten so competitive even at smaller companies?  I am mostly talking about any job that is tech/IT related.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137ij6s", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137ij6s/what_kind_of_work_can_a_data_engineer_do_if_they/", "subreddit_subscribers": 104030, "created_utc": 1683201719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am computer engineer graduate and I want to start career in Data Engineering, but I can not start by youtube I tried many times but it is not effective in my case, I need bootcamp which is affordable and will help me to get the skill to land the first job.", "author_fullname": "t2_kzbbagfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Bootcamp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136x9q8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683142912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am computer engineer graduate and I want to start career in Data Engineering, but I can not start by youtube I tried many times but it is not effective in my case, I need bootcamp which is affordable and will help me to get the skill to land the first job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "136x9q8", "is_robot_indexable": true, "report_reasons": null, "author": "TreacleWild4127", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136x9q8/data_engineering_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136x9q8/data_engineering_bootcamp/", "subreddit_subscribers": 104030, "created_utc": 1683142912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df](https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df)\n\n[ Unveiling the true cost of your ride-sharing and food delivery habits with an ELT data pipeline, PostgreSQL, dbt, and Power BI. ](https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uber Project: Analyzing Personal Uber and Uber Eats Expenses with ELT Data Pipeline Using DBT, Postgres, Gmail, Python, SQL And PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"g7bbaja6fnxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41de5f4b7c0ef8f1402fab5169398cd294cf27e6"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a5671f5f7a2849124d41ff3e228436d735f86f0"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be78e82a8733cacf2829f953d15b68bb08233cf0"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1399af540ce025e63a4b093566c8e550b07d3b48"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62cdf7326d9d6558f3cc5b5d1aba774d2801a368"}, {"y": 604, "x": 1080, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7142eebbefdb68a526932a22a4cd43a5c805ffad"}], "s": {"y": 660, "x": 1180, "u": "https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26"}, "id": "g7bbaja6fnxa1"}}, "name": "t3_136tb10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_nG9Ial9BLiWKcZNJGgwQKock2lS_ND32TfHWzV0QHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683133839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df\"&gt;https://medium.com/@stefentaime_10958/uber-project-analyzing-personal-uber-and-uber-eats-expenses-with-elt-data-pipeline-using-dbt-91ead4aea5df&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/g7bbaja6fnxa1.png?width=1180&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4610dc5e227a1ab015a80a0f8459c67ab7fe2d26\"&gt; Unveiling the true cost of your ride-sharing and food delivery habits with an ELT data pipeline, PostgreSQL, dbt, and Power BI. &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?auto=webp&amp;v=enabled&amp;s=e23d6a097db23a80cd97986f29f8bf936e4fcaea", "width": 1180, "height": 660}, "resolutions": [{"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cfb1f02c76b97d3781cbb0450214468b023e789", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31c910296902350e2aaabd280045f1f439333251", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0faa9fe24a5d23673079f19617667b1c9f8dceb", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e970911e2d9172b675468f59955192312b954dd9", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc38c42c572b5d050c33da2be86bef56ed2ca117", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/JSXtP4tiQFSDIj22E0bbXoToLRwf8imZI0A_cT78Sn0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84492644a6cbb40347f0cfa4eae070e3dd5dacab", "width": 1080, "height": 604}], "variants": {}, "id": "sXge4upQJVpIh82dfcR-hH1qDtBS22SFSZ6wf6g7Kz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "136tb10", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136tb10/uber_project_analyzing_personal_uber_and_uber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136tb10/uber_project_analyzing_personal_uber_and_uber/", "subreddit_subscribers": 104030, "created_utc": 1683133839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_20tfe7ur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Certifications\u2014Which One is Best to Pursue in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_137bmjg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ztcgjz4C9CIuYGKluBtnKpD-00-9PG1dWWtZRHv7lL0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683179877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "chaosgenius.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.chaosgenius.io/blog/snowflake-certifications/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?auto=webp&amp;v=enabled&amp;s=ddf845843a22c51ff5fb2191808ea2ebf024a049", "width": 2000, "height": 1524}, "resolutions": [{"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46bfb0e1262b81941de0cd747531f8b99e2f3bc8", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d1c03f3517b63bc4335dd9d84e5f5626cec4917", "width": 216, "height": 164}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=984a19468137b9407b0deda67db8c7629dc24e1c", "width": 320, "height": 243}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd4d8efcc248b9d9bb977a06c26b7d3c0fc673ff", "width": 640, "height": 487}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ef7977a7c8958f0c15e72df0342bc626e73b97f", "width": 960, "height": 731}, {"url": "https://external-preview.redd.it/2TQlR0RzzoVEGMOElfMRdOqwkdA_y_ctdISMZARttUg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd1a4abc3c8215c8db4731a93918c5d7f4454d43", "width": 1080, "height": 822}], "variants": {}, "id": "XNwz6ja4ti9eCjpewcXHVx74xSw6hrBKa1cY7vNJcEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137bmjg", "is_robot_indexable": true, "report_reasons": null, "author": "pramit_marattha", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137bmjg/snowflake_certificationswhich_one_is_best_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.chaosgenius.io/blog/snowflake-certifications/", "subreddit_subscribers": 104030, "created_utc": 1683179877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I wanted to share my personal newsletter with you. Every week, I collect information from the data world and compile it into the newsletter. If you're interested, please feel free to check it out. :)\n\n[https://patrikbraborec.substack.com/p/data-news-26](https://patrikbraborec.substack.com/p/data-news-26)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data news #26", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137fbwg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683192223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I wanted to share my personal newsletter with you. Every week, I collect information from the data world and compile it into the newsletter. If you&amp;#39;re interested, please feel free to check it out. :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://patrikbraborec.substack.com/p/data-news-26\"&gt;https://patrikbraborec.substack.com/p/data-news-26&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?auto=webp&amp;v=enabled&amp;s=d6516117109b746272aa481075306a3f636cf116", "width": 728, "height": 410}, "resolutions": [{"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91270145edd6445d657193709e74d65217783def", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7915398bcf5335938d8a3aca59fc4e649e45150", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a9fead389d87f45d460517bd7076c93d663a0fb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/FoO0cpB1vKco5X56Ch_Wk5BpAexQ1DS1f0pohhSkHcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56e0a8b5790d83cfbe3f6dcbb4fae1f30de50873", "width": 640, "height": 360}], "variants": {}, "id": "pjoi_vcvcsZBx-uaz1ZygihHBy9couKiRgilZlSbgx0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137fbwg", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137fbwg/data_news_26/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137fbwg/data_news_26/", "subreddit_subscribers": 104030, "created_utc": 1683192223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I have some questions that are less data-oriented, but these questions are likely relevant to any data development team: I assume that most people here develop in sprints. \n\nIn my opinion, in data engineering workloads, there are many unknown factors during the grooming time that can affect tasks within the sprint, creating more challenges compared to more classical software development sprints.\n\n* How do you estimate time for tasks - in hours or story points and why?\n* How do you measure the velocity of developers or are you being measured?\n* How do you deal with overestimated tasks as team leaders, and how do you communicate efficiently that you think it should take less?\n* If a task is blocked due to missing data, decisions need to be taken by stakeholders or PM, UAT, or due to DevOps or any other reason that prevents you from developing - if there is a deviation in the defined time frame - how do you take this into account when evaluating the quality and speed at which the task was completed?\n* Continuing from the previous question, are all the deadlines for all the tasks in the sprint are the end of the sprint, or do you communicate deadlines for tasks based on their priority in the sprint and estimation? If it's the end of the sprint, how do you deal with pressure from senior management to know the date the task will be completed, which you probably know will be before the end of the sprint because it's a top priority?", "author_fullname": "t2_ctqlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sprint management in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137dwry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683187478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I have some questions that are less data-oriented, but these questions are likely relevant to any data development team: I assume that most people here develop in sprints. &lt;/p&gt;\n\n&lt;p&gt;In my opinion, in data engineering workloads, there are many unknown factors during the grooming time that can affect tasks within the sprint, creating more challenges compared to more classical software development sprints.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you estimate time for tasks - in hours or story points and why?&lt;/li&gt;\n&lt;li&gt;How do you measure the velocity of developers or are you being measured?&lt;/li&gt;\n&lt;li&gt;How do you deal with overestimated tasks as team leaders, and how do you communicate efficiently that you think it should take less?&lt;/li&gt;\n&lt;li&gt;If a task is blocked due to missing data, decisions need to be taken by stakeholders or PM, UAT, or due to DevOps or any other reason that prevents you from developing - if there is a deviation in the defined time frame - how do you take this into account when evaluating the quality and speed at which the task was completed?&lt;/li&gt;\n&lt;li&gt;Continuing from the previous question, are all the deadlines for all the tasks in the sprint are the end of the sprint, or do you communicate deadlines for tasks based on their priority in the sprint and estimation? If it&amp;#39;s the end of the sprint, how do you deal with pressure from senior management to know the date the task will be completed, which you probably know will be before the end of the sprint because it&amp;#39;s a top priority?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137dwry", "is_robot_indexable": true, "report_reasons": null, "author": "Snirisl", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137dwry/sprint_management_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137dwry/sprint_management_in_data_engineering/", "subreddit_subscribers": 104030, "created_utc": 1683187478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have time series data files that are ~1 gig in size. Currently we are using Airflow for batch processing these files. At some point in the near future, we will need to stream the data from the source (it wont be 2 gigs in size then as it will be sent at certain intervals). Someone on my team mentioned that we should use NiFi with Kafka at the point, but I didn't fully understand the purpose of NiFi. The data will be used downstream for inference. \n\nWhen does it make sense to use Apache NiFi? What are the pros and cons of it. I would really appreciate if you can give me sample use cases.\n\nThank you \ud83d\ude4f", "author_fullname": "t2_1bxy4pss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache NiFi usecase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13733xe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683156296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have time series data files that are ~1 gig in size. Currently we are using Airflow for batch processing these files. At some point in the near future, we will need to stream the data from the source (it wont be 2 gigs in size then as it will be sent at certain intervals). Someone on my team mentioned that we should use NiFi with Kafka at the point, but I didn&amp;#39;t fully understand the purpose of NiFi. The data will be used downstream for inference. &lt;/p&gt;\n\n&lt;p&gt;When does it make sense to use Apache NiFi? What are the pros and cons of it. I would really appreciate if you can give me sample use cases.&lt;/p&gt;\n\n&lt;p&gt;Thank you \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13733xe", "is_robot_indexable": true, "report_reasons": null, "author": "iamkatana", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13733xe/apache_nifi_usecase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13733xe/apache_nifi_usecase/", "subreddit_subscribers": 104030, "created_utc": 1683156296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Deploying subnets, clusters, iam roles and policies, workspaces, users, groups, and metastore. I\u2019ve really only deployed simple aws resources and have a little bit of knowledge with modules after experimenting with them. I\u2019ve also gotten through a few courses in the DB DE path but have paused learning since they are updating the course. \n\nAny advice?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expected to terraform and deploy all of our DataBricks resources as our first implementation, little knowledge of TF and DB, any advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1372hz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683154794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deploying subnets, clusters, iam roles and policies, workspaces, users, groups, and metastore. I\u2019ve really only deployed simple aws resources and have a little bit of knowledge with modules after experimenting with them. I\u2019ve also gotten through a few courses in the DB DE path but have paused learning since they are updating the course. &lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1372hz9", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1372hz9/expected_to_terraform_and_deploy_all_of_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1372hz9/expected_to_terraform_and_deploy_all_of_our/", "subreddit_subscribers": 104030, "created_utc": 1683154794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling \u2014 The Unsung Hero of Data Engineering: Modeling Approaches and Techniques (Part 2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_136wwbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": "transparent", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Luakl5G7MQUxjouP2ayBj_5_OBWiEkpC1cxEgUsVzNA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683142063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-approaches-and-techniques", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?auto=webp&amp;v=enabled&amp;s=261aa0047aaa2f024c69ce7aeeb765c965bc45b6", "width": 1398, "height": 759}, "resolutions": [{"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c018677cdb23284e1318b53caed2d7398b51c366", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5495e000c0e2d258ddc0c7ab1c5ef31a32a7a702", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acf81aa92304a993cf52d26be7219363fad96c2a", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8261e19ec61b26f19dc5eac9edc6de25dec41d07", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16a09b57e0af20f26bf706181714ff4b9a0cced3", "width": 960, "height": 521}, {"url": "https://external-preview.redd.it/22B6Jl53vNNSdQSpsLfYgv9elOEYriexL1e45uu4Q5s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c4479cf7f7d44772ea8d73c6e732ce9926a3cad", "width": 1080, "height": 586}], "variants": {}, "id": "sAv0LQfAX5D6adD8AWOXJxW0jvWpbS_k8UNjK63jUOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "136wwbg", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/136wwbg/data_modeling_the_unsung_hero_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-approaches-and-techniques", "subreddit_subscribers": 104030, "created_utc": 1683142063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouses vs Data Lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_136vh7g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/136vh7g", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dkgfePmTwlhjDvdbF07lNZZRY_VO5dVdFOKKgMxt-8Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683138787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xbtK43WlkMs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?auto=webp&amp;v=enabled&amp;s=efd25af1081c58827d479668ffa6c256fa2818b0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad41e971d1e0838c4c49837be54ae9f4a56962db", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5dff204a03ea70392c8c9f3a746257f4904b381", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VXvtViZ-a_AufzH-8kX--zpDT5X9e5S9tpbHSV1R4hk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6585e60fe811684616aa131692d6a2971ded5e2", "width": 320, "height": 240}], "variants": {}, "id": "y1-ztg6CqTUIpsSMCro3W1_odauB7Vb_7yUnCwY1H7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "136vh7g", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/136vh7g/data_warehouses_vs_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xbtK43WlkMs", "subreddit_subscribers": 104030, "created_utc": 1683138787.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "LinkedIn seems like the default but wondering if any of you have found a better or more data-specific option.", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job boards that you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137n7ud", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683210983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;LinkedIn seems like the default but wondering if any of you have found a better or more data-specific option.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "137n7ud", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137n7ud/job_boards_that_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137n7ud/job_boards_that_you_use/", "subreddit_subscribers": 104030, "created_utc": 1683210983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI have been reading a lot about data contracts and was hoping to implement them in the company I work for.\n\nBefore that, I had a few questions:\n\n\\- How many of you regularly use data contracts?\n\n\\- How do you create/represent them? Do you use Google's Protocol Buffers or Apache Avro or something different?\n\n\\- How do you enforce them? (This is the main question I'm struggling with - what's the least effort way or tool to enforce data contracts).\n\nThanks in advance!", "author_fullname": "t2_mytvjynu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data contracts - do you use them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137glbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683196175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been reading a lot about data contracts and was hoping to implement them in the company I work for.&lt;/p&gt;\n\n&lt;p&gt;Before that, I had a few questions:&lt;/p&gt;\n\n&lt;p&gt;- How many of you regularly use data contracts?&lt;/p&gt;\n\n&lt;p&gt;- How do you create/represent them? Do you use Google&amp;#39;s Protocol Buffers or Apache Avro or something different?&lt;/p&gt;\n\n&lt;p&gt;- How do you enforce them? (This is the main question I&amp;#39;m struggling with - what&amp;#39;s the least effort way or tool to enforce data contracts).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137glbo", "is_robot_indexable": true, "report_reasons": null, "author": "a-layerup", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137glbo/data_contracts_do_you_use_them/", "subreddit_subscribers": 104030, "created_utc": 1683196175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to chat with you about it", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Google PaLM for Data Engineering related tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_136xjc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683143528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to chat with you about it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "136xjc9", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/136xjc9/has_anyone_used_google_palm_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/136xjc9/has_anyone_used_google_palm_for_data_engineering/", "subreddit_subscribers": 104030, "created_utc": 1683143528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently in the process of deciding on a topic for my Master's dissertation in data engineering after the changes announce for Reddit Data API (I was planning to analyze comments and submissions on streaming from a custom feed) and I need some ideas. I'm very interested in this field (wanting to switch later from my current frontend/mobile junior developer role), working with Spark and I want to make sure that the topic I choose is relevant and useful. I'm finding hard to find streaming datasets that I find interesting too.\n\nI think I\u2019ll stay away from streaming sentiment analysis of messages in social media, as there are lots of dissertations on analyzing tweets, Twitch chat messages are too noisy for doing a plausible analysis and I\u2019m really dissapointed with recent decissions of Reddit regarding it\u2019s API. That doesn\u2019t mean I\u2019m closing the doors on doing something with NLP.\n\nIf anyone has any suggestions for potential projects in data engineering (with streaming data if possible), I would greatly appreciate it. I\u2019m open to any ideas and would love to hear from those who have experience in this field. If I can\u2019t get any idea, I\u2019ll stick to do a continuation of my degree\u2019s dissertation on Open Data and CKAN.\n\nThank you in advance for your help and suggestions.", "author_fullname": "t2_w8tez48c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need ideas for Master\u2019s Dissertation topic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137fp2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683193422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently in the process of deciding on a topic for my Master&amp;#39;s dissertation in data engineering after the changes announce for Reddit Data API (I was planning to analyze comments and submissions on streaming from a custom feed) and I need some ideas. I&amp;#39;m very interested in this field (wanting to switch later from my current frontend/mobile junior developer role), working with Spark and I want to make sure that the topic I choose is relevant and useful. I&amp;#39;m finding hard to find streaming datasets that I find interesting too.&lt;/p&gt;\n\n&lt;p&gt;I think I\u2019ll stay away from streaming sentiment analysis of messages in social media, as there are lots of dissertations on analyzing tweets, Twitch chat messages are too noisy for doing a plausible analysis and I\u2019m really dissapointed with recent decissions of Reddit regarding it\u2019s API. That doesn\u2019t mean I\u2019m closing the doors on doing something with NLP.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any suggestions for potential projects in data engineering (with streaming data if possible), I would greatly appreciate it. I\u2019m open to any ideas and would love to hear from those who have experience in this field. If I can\u2019t get any idea, I\u2019ll stick to do a continuation of my degree\u2019s dissertation on Open Data and CKAN.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137fp2v", "is_robot_indexable": true, "report_reasons": null, "author": "samuelrs98", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137fp2v/need_ideas_for_masters_dissertation_topic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137fp2v/need_ideas_for_masters_dissertation_topic/", "subreddit_subscribers": 104030, "created_utc": 1683193422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Glue Crawler to map data from S3 to Glue tables. Currenlty, I can capture schema changes (add new columns only) only when the recrawl policy is set to crawl everything. However, when I set recrawl policy to craw new sub-folders only, the new columns are not added.   \n\n\nIs this a limitation right now with Glue Crawler?\n\nBelow is my config. Recrawl new only isn't working for addition of new columns in subsequent runs. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue Crawler Schema Changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "media_metadata": {"d50ow1rweqxa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=724dfca3fa83028d1997b5e7059d42d122db7ab7"}, {"y": 64, "x": 216, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b9e371225a7d4ddd3f3477583663ca5b68bae2a"}, {"y": 95, "x": 320, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b948121eb8a93ec099f96a2134a4e1a663b366b1"}, {"y": 191, "x": 640, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd47e068e41180503883e40297e397214dc45658"}, {"y": 287, "x": 960, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d54cde38d46871b9c9784784a78aa822b21e590"}, {"y": 323, "x": 1080, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae2d3e31afb08379e4a43573b10d6906f40414d9"}], "s": {"y": 882, "x": 2942, "u": "https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a"}, "id": "d50ow1rweqxa1"}}, "name": "t3_1378acm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-IXrKCUSr2jN3oXZnaQza0k4lEtiTgNjjwMgBKjkCvM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683169985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Glue Crawler to map data from S3 to Glue tables. Currenlty, I can capture schema changes (add new columns only) only when the recrawl policy is set to crawl everything. However, when I set recrawl policy to craw new sub-folders only, the new columns are not added.   &lt;/p&gt;\n\n&lt;p&gt;Is this a limitation right now with Glue Crawler?&lt;/p&gt;\n\n&lt;p&gt;Below is my config. Recrawl new only isn&amp;#39;t working for addition of new columns in subsequent runs. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a\"&gt;https://preview.redd.it/d50ow1rweqxa1.png?width=2942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9cb9bef3a2e0a26cd588c2a1f761fdb7bf22af0a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1378acm", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1378acm/glue_crawler_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1378acm/glue_crawler_schema_changes/", "subreddit_subscribers": 104030, "created_utc": 1683169985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am really new to data engineering and I am currently working with some medical data (free mimicsIII) dataset, and I wish to ingest them into a database. I am using drawio to draw my ERD. I am wondering what is your favorite tool to directly converting ERD to DDL for my database, let's say postgres?", "author_fullname": "t2_12wrnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERD to DDL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13773aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683166840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am really new to data engineering and I am currently working with some medical data (free mimicsIII) dataset, and I wish to ingest them into a database. I am using drawio to draw my ERD. I am wondering what is your favorite tool to directly converting ERD to DDL for my database, let&amp;#39;s say postgres?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13773aj", "is_robot_indexable": true, "report_reasons": null, "author": "diceHots", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13773aj/erd_to_ddl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13773aj/erd_to_ddl_tool/", "subreddit_subscribers": 104030, "created_utc": 1683166840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9re8o8eo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you confused about where to start your MLOps journey? Are you confused with the sheer amount of tools out there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_137rjoy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FXGkQ8hD0ngk%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw%26days_since_epoch%3D19481&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 450}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "http://youtube.com", "description": "Starting point for understanding ML in production", "title": "MLOps 101", "type": "video", "thumbnail_width": 168, "height": 450, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FXGkQ8hD0ngk%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw%26days_since_epoch%3D19481&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XGkQ8hD0ngk/hqdefault.jpg?sqp=-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ==&amp;rs=AOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw&amp;days_since_epoch=19481", "thumbnail_height": 94}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FXGkQ8hD0ngk%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw%26days_since_epoch%3D19481&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/137rjoy", "height": 450}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4KkquHrIkeUToIrVh11AZWUR-MUaEnZ71UmohUT5Y_A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683215995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/playlist?list=PLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tTBxBO2rqZQXd4rA5VM1vi1Qr_pAKuOJJ3zeP69170M.jpg?auto=webp&amp;v=enabled&amp;s=af96541cb63e89f747105574cc8a13d05d79c806", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/tTBxBO2rqZQXd4rA5VM1vi1Qr_pAKuOJJ3zeP69170M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41c6217a1555ef0db8ad8a41dab026453af192bb", "width": 108, "height": 60}], "variants": {}, "id": "s9YZNAfFKKdycSvDVkLd070KmzP84g8IJMMeHWAn-oY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137rjoy", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic_Study9171", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137rjoy/are_you_confused_about_where_to_start_your_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/playlist?list=PLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79", "subreddit_subscribers": 104030, "created_utc": 1683215995.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "http://youtube.com", "description": "Starting point for understanding ML in production", "title": "MLOps 101", "type": "video", "thumbnail_width": 168, "height": 450, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPLk8POlTHkzG-7JDgTgM3YuJ9voXGpvr79&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FXGkQ8hD0ngk%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw%26days_since_epoch%3D19481&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/XGkQ8hD0ngk/hqdefault.jpg?sqp=-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ==&amp;rs=AOn4CLCSDPSqvs6w2W9I5uUFE7bMC2sksw&amp;days_since_epoch=19481", "thumbnail_height": 94}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nComing at this from an analytical data engineer POV. \n\nJust wondering if/how your intake process works to support parts of the business like finance, marketing, and others. \n\nHow do you guide other teams to format their request as a data requirement that will enable data engineers to do their work without too much back and forth with the business? \n\nI\u2019ve had some luck having the teams creat a dummy report of the fields and rows they want , but wondering if there is a better way.", "author_fullname": "t2_1nay9ocv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics Engineering - requirement gathering.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137rb68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683215453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Coming at this from an analytical data engineer POV. &lt;/p&gt;\n\n&lt;p&gt;Just wondering if/how your intake process works to support parts of the business like finance, marketing, and others. &lt;/p&gt;\n\n&lt;p&gt;How do you guide other teams to format their request as a data requirement that will enable data engineers to do their work without too much back and forth with the business? &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve had some luck having the teams creat a dummy report of the fields and rows they want , but wondering if there is a better way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137rb68", "is_robot_indexable": true, "report_reasons": null, "author": "pure_coconut_water", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137rb68/analytics_engineering_requirement_gathering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137rb68/analytics_engineering_requirement_gathering/", "subreddit_subscribers": 104030, "created_utc": 1683215453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a BA grad student, recently received an offer to work at an early stage startup as a summer intern. The startup is building a cloud tool for a retailer to validate POS transactions. My role is to write SQL queries for the validation purposes based on business requirements and build on the existing python code for APIs. Is this a good opportunity to take on if my goal is to become a data engineer after graduation?", "author_fullname": "t2_c9dcr4wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for intern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137r14a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683215728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683214819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a BA grad student, recently received an offer to work at an early stage startup as a summer intern. The startup is building a cloud tool for a retailer to validate POS transactions. My role is to write SQL queries for the validation purposes based on business requirements and build on the existing python code for APIs. Is this a good opportunity to take on if my goal is to become a data engineer after graduation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "137r14a", "is_robot_indexable": true, "report_reasons": null, "author": "sigapuranger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137r14a/advice_for_intern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137r14a/advice_for_intern/", "subreddit_subscribers": 104030, "created_utc": 1683214819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I may sound stupid, just newbee on dv\n\nWhy do we need Hub and Link tables since we can derived the same from Sat tables itself as we can include those columns from hub and link in Sat?", "author_fullname": "t2_khph1234", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data vault model question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137pnwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683214393.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683213368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I may sound stupid, just newbee on dv&lt;/p&gt;\n\n&lt;p&gt;Why do we need Hub and Link tables since we can derived the same from Sat tables itself as we can include those columns from hub and link in Sat?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137pnwq", "is_robot_indexable": true, "report_reasons": null, "author": "misc0007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137pnwq/data_vault_model_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137pnwq/data_vault_model_question/", "subreddit_subscribers": 104030, "created_utc": 1683213368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was scheduled an interview recently and the job position requires CI/CD experience as an add-on in data engineering.\n\nMy previous experience in data engineering is a bit vague because we were using self-built platforms and tooling to deploy our ETL jobs. \n\nThis is how we do: normally we would write code locally, run the code block by block on our ad-hoc query platform. If the code runs smooth and result is fine, we would deploy the code and testing the whole pipeline. The code is versioned. Which means the job can be iterated or reversed back to the previous version. \n\nFor a single ETL pipeline it can be tested or published( pushed as the prod version). but code reviews are not many because there\u2019s NO GIT REPO branches or merge requests.\nHowever we still take carefully in terms of code readability and efficiency but it\u2019s still pretty wild west.\n\nI\u2019m having the interview tomorrow and I don\u2019t really know what to say if they ask me if I have CI/CD experience. \n\nA few questions here:\n\nHow much difference does it have between our ways of deploying code and the normal ways?\n\nWhat can I mention in front of such question?\n\nWhat\u2019s the difference from CI/CD between data engineering and common software engineering?", "author_fullname": "t2_oorup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you practice CI/CD in your work? What\u2019s the difference from CI/CD in common software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_137oibw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683212189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was scheduled an interview recently and the job position requires CI/CD experience as an add-on in data engineering.&lt;/p&gt;\n\n&lt;p&gt;My previous experience in data engineering is a bit vague because we were using self-built platforms and tooling to deploy our ETL jobs. &lt;/p&gt;\n\n&lt;p&gt;This is how we do: normally we would write code locally, run the code block by block on our ad-hoc query platform. If the code runs smooth and result is fine, we would deploy the code and testing the whole pipeline. The code is versioned. Which means the job can be iterated or reversed back to the previous version. &lt;/p&gt;\n\n&lt;p&gt;For a single ETL pipeline it can be tested or published( pushed as the prod version). but code reviews are not many because there\u2019s NO GIT REPO branches or merge requests.\nHowever we still take carefully in terms of code readability and efficiency but it\u2019s still pretty wild west.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having the interview tomorrow and I don\u2019t really know what to say if they ask me if I have CI/CD experience. &lt;/p&gt;\n\n&lt;p&gt;A few questions here:&lt;/p&gt;\n\n&lt;p&gt;How much difference does it have between our ways of deploying code and the normal ways?&lt;/p&gt;\n\n&lt;p&gt;What can I mention in front of such question?&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the difference from CI/CD between data engineering and common software engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "137oibw", "is_robot_indexable": true, "report_reasons": null, "author": "GeForceKawaiiyo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137oibw/how_do_you_practice_cicd_in_your_work_whats_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137oibw/how_do_you_practice_cicd_in_your_work_whats_the/", "subreddit_subscribers": 104030, "created_utc": 1683212189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Im parsing some XMLs and loading them into postgres and given the nature of the records it generates a lot of duplicates.\n\nI would like to know whats the most efficient tool for removing dups. The first thing that comes to mind its PySpark but im not sure. Wdyt?", "author_fullname": "t2_8k92uib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's PySpark an adecuate tool for deduplication?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_137lk6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683208855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Im parsing some XMLs and loading them into postgres and given the nature of the records it generates a lot of duplicates.&lt;/p&gt;\n\n&lt;p&gt;I would like to know whats the most efficient tool for removing dups. The first thing that comes to mind its PySpark but im not sure. Wdyt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "137lk6p", "is_robot_indexable": true, "report_reasons": null, "author": "DeUnaShabown", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137lk6p/its_pyspark_an_adecuate_tool_for_deduplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/137lk6p/its_pyspark_an_adecuate_tool_for_deduplication/", "subreddit_subscribers": 104030, "created_utc": 1683208855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udca1 What are Slowly Changing Dimensions (SCD) \ud83d\udca1 SCD Types \ud83d\udca1 How to implement SCD Type 2 in VDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_137lajn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AkNTFhi0_jb7z3ll1fh1DFfoK0ujczHBIWl3ke6hLHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683208250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/how-to-keep-track-of-data-versions-using-versatile-data-kit-f1916f18737e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?auto=webp&amp;v=enabled&amp;s=62b1541d9f092e383be97e915acbc14ca00cde3e", "width": 1200, "height": 802}, "resolutions": [{"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67e4ee5233df2873f8d62400ae385c2f495f706e", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=057c3f8b98867d26953a38ed7cfaf9b4509343dd", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65446bd8634b72dbcaa55307180cb0acdeeb9044", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=552f9ea3195ff6499f90fbdb56bb968cd2370a6d", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74a953d497daca5ca4fcfe8b22fa41ec1333d403", "width": 960, "height": 641}, {"url": "https://external-preview.redd.it/dk5i9t9vQR2LheAhuXMeYjpZCrKgMP5zjxMvyPxqqx8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02a6d555c070b4ed0d1f8063e47546d1ab4cb8f6", "width": 1080, "height": 721}], "variants": {}, "id": "oVejV9TkbC0Iu-JH8IBRENViFvCDP1jk-8CZobweJVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "137lajn", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/137lajn/what_are_slowly_changing_dimensions_scd_scd_types/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/how-to-keep-track-of-data-versions-using-versatile-data-kit-f1916f18737e", "subreddit_subscribers": 104030, "created_utc": 1683208250.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}