{"kind": "Listing", "data": {"after": "t3_13pq89y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looks interesting.. What do you guys think?\n\nhttps://azure.microsoft.com/en-us/blog/introducing-microsoft-fabric-data-analytics-for-the-era-of-ai/", "author_fullname": "t2_9fr6if3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft announces Fabric data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ptsio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684860197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looks interesting.. What do you guys think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://azure.microsoft.com/en-us/blog/introducing-microsoft-fabric-data-analytics-for-the-era-of-ai/\"&gt;https://azure.microsoft.com/en-us/blog/introducing-microsoft-fabric-data-analytics-for-the-era-of-ai/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?auto=webp&amp;v=enabled&amp;s=28a77d59e9df7eb9f98aee41f6f040db9a5737ef", "width": 1024, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5677afed120db134858325e27fb5e36408cbb554", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abfc77958ae6aa9c3ef396f265e1e8fd05ee2c5e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bad10c7a0efb90b70cdb7b59afa00a0090b2e9c1", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70ddb2cec383ce3213465b566b0e79864e21d87", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/CfbhchoEbwQNf90PNJ0EWlLAkUDyFiIHEkv5TB6G2Uc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d15115f6440f35b05b7e61f6ef7555586672e54", "width": 960, "height": 502}], "variants": {}, "id": "E1ZPDHx_PF0YMqiqKy0UdRWYMLlPZ6oKh68g45qehY8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ptsio", "is_robot_indexable": true, "report_reasons": null, "author": "aj_here_", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ptsio/microsoft_announces_fabric_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ptsio/microsoft_announces_fabric_data_platform/", "subreddit_subscribers": 106933, "created_utc": 1684860197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this job market, there aren't many high paying data engineering roles that are open in my area.  However, I found some roles that interest me and pay much more than what I'm making now.  The only thing is that they don't use any cloud providers.\n\n\n\n\n\n\nI already have 5 years of experience and tons of experience using one of the major cloud providers, so would these types of jobs hurt my career.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does moving to a company that doesn't use cloud services hurt your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13plvgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684841542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this job market, there aren&amp;#39;t many high paying data engineering roles that are open in my area.  However, I found some roles that interest me and pay much more than what I&amp;#39;m making now.  The only thing is that they don&amp;#39;t use any cloud providers.&lt;/p&gt;\n\n&lt;p&gt;I already have 5 years of experience and tons of experience using one of the major cloud providers, so would these types of jobs hurt my career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13plvgz", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13plvgz/does_moving_to_a_company_that_doesnt_use_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13plvgz/does_moving_to_a_company_that_doesnt_use_cloud/", "subreddit_subscribers": 106933, "created_utc": 1684841542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My current title is Data Engineer, although I landed here in a non-tradition way. I started as an intern on a Data Management team, hired on as IT Application analyst, then the company re-titled all IT staff to either data engineer or software engineer. Since, I was in the data space, I received the data engineer title. I do not have coding background, my department purchased third party vendor tools for most tasks in our workflow (i.e. Informatica (ETL), MicroStrategy (BI), etc.). Recently, my company has transitioned to AWS with an emphasis on CI/CD and Infrastructure as Code. I realize that I am extremely unqualified for my job title. I have watched Python videos online in hopes of learning. I recently completed a free Data Analysis with Python course (more geared towards Data Analyst than DE). I currently work primarily with new engineers so the lift I provide the team is essentially my knowledge and experience in the data space (include data domain knowledge, ETL and data quality standards, etc.). I primarily play more of a consultation role -- I design and they build.\n\nI am in search of Data Engineer work and willing to take entry level work because I want to work alongside other data engineers and learn. But, all roles require Python. I'm looking for advice, suggestions, or recommendations on what to do. Ideally, I would like to remain in a data engineer position, but without the coding background I cannot consciously embellish my python experience. Those familiar with my situation tells me \"to apply for the job I want not the job I qualify for\". But, I feel the lack of Python is significant. My team currently has an individual who potentially embellished their experience and I just don't want to be stuck in that same situation where I cannot pick up coding efforts...\n\nI have considered instead a Data Analyst or Data Governance Analyst position. My SQL querying skills are fairly decent. But, I would lose out on the technical knowledge I've gained in the past few years (especially the AWS experience).", "author_fullname": "t2_bmo1kv8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Title but Unqualified for Position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pb7dr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684808610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current title is Data Engineer, although I landed here in a non-tradition way. I started as an intern on a Data Management team, hired on as IT Application analyst, then the company re-titled all IT staff to either data engineer or software engineer. Since, I was in the data space, I received the data engineer title. I do not have coding background, my department purchased third party vendor tools for most tasks in our workflow (i.e. Informatica (ETL), MicroStrategy (BI), etc.). Recently, my company has transitioned to AWS with an emphasis on CI/CD and Infrastructure as Code. I realize that I am extremely unqualified for my job title. I have watched Python videos online in hopes of learning. I recently completed a free Data Analysis with Python course (more geared towards Data Analyst than DE). I currently work primarily with new engineers so the lift I provide the team is essentially my knowledge and experience in the data space (include data domain knowledge, ETL and data quality standards, etc.). I primarily play more of a consultation role -- I design and they build.&lt;/p&gt;\n\n&lt;p&gt;I am in search of Data Engineer work and willing to take entry level work because I want to work alongside other data engineers and learn. But, all roles require Python. I&amp;#39;m looking for advice, suggestions, or recommendations on what to do. Ideally, I would like to remain in a data engineer position, but without the coding background I cannot consciously embellish my python experience. Those familiar with my situation tells me &amp;quot;to apply for the job I want not the job I qualify for&amp;quot;. But, I feel the lack of Python is significant. My team currently has an individual who potentially embellished their experience and I just don&amp;#39;t want to be stuck in that same situation where I cannot pick up coding efforts...&lt;/p&gt;\n\n&lt;p&gt;I have considered instead a Data Analyst or Data Governance Analyst position. My SQL querying skills are fairly decent. But, I would lose out on the technical knowledge I&amp;#39;ve gained in the past few years (especially the AWS experience).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13pb7dr", "is_robot_indexable": true, "report_reasons": null, "author": "Mindless_Space_1486", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pb7dr/de_title_but_unqualified_for_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pb7dr/de_title_but_unqualified_for_position/", "subreddit_subscribers": 106933, "created_utc": 1684808610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your opinion on today\u2019s release of Microsoft fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_13pvcss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZvriRPeq7WvOE4Jb3JxUneYLcHJ1ISxi40gdC1RMMuE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684863778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1urjzbw1tn1b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?auto=webp&amp;v=enabled&amp;s=71e7270f9b2ac04a6ed3663ef604eb7fddbf2c78", "width": 1536, "height": 818}, "resolutions": [{"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cc42c083648b121212c4f3db8cf23a3896b7335", "width": 108, "height": 57}, {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58257133944acd6168c5249f44292760f72c1ede", "width": 216, "height": 115}, {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4ec6d04a17cb5334cc78642e08d97511f8ca270", "width": 320, "height": 170}, {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cde80319e4a7253900f0a83e8c27bedfc7b9c724", "width": 640, "height": 340}, {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e83e53b61292073e5c87295f914b170714bcabde", "width": 960, "height": 511}, {"url": "https://preview.redd.it/1urjzbw1tn1b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=852e2904d113dd1d799c737a9684b95ae5a1ed8d", "width": 1080, "height": 575}], "variants": {}, "id": "PLsjRt3QOn83AsuBb_NgKSh4VX33tfO78vwUV07aLG0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13pvcss", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pvcss/whats_your_opinion_on_todays_release_of_microsoft/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1urjzbw1tn1b1.jpg", "subreddit_subscribers": 106933, "created_utc": 1684863778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently landed my first job, after studying by myself for like 8 months. I also studied and passed GCP and Azure Data Engineering certificates just to bolster my chances since I have no software engineering background/education.\n\nMy tasks at work are mostly the equivalent of centering the div. I play more TFT (some game) on the job than I actually work and I do not like that, I actually feel less skilled than when I was actively working on my personal projects.\n\n  \nSo I want to use my spare time to improve, I don't want to cram ever again, I don't want to be 2-3 years into a data job, then when applying to a senior position find out that I need X skill, so i start cramming, nah, I want to take things slow and gradual, let them sink, and learn them well without pressure.\n\nTLDR **what are the most impactful skills and knowledge that I could work on right now as a junior data engineer to prepare myself for things like a senior data engineer/architect/lead in the future?** \n\nP.S I come from civil engineering background and have worked as project manager and team manager in engineering and non engineering fields, so I was thinking maybe studying for a PMP would be advantageous for some lead position in the field, but I could be wrong, or maybe there are more impactful things that I should prioritize.", "author_fullname": "t2_85fin9nj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to progress after landing a junior data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ppolj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684851023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently landed my first job, after studying by myself for like 8 months. I also studied and passed GCP and Azure Data Engineering certificates just to bolster my chances since I have no software engineering background/education.&lt;/p&gt;\n\n&lt;p&gt;My tasks at work are mostly the equivalent of centering the div. I play more TFT (some game) on the job than I actually work and I do not like that, I actually feel less skilled than when I was actively working on my personal projects.&lt;/p&gt;\n\n&lt;p&gt;So I want to use my spare time to improve, I don&amp;#39;t want to cram ever again, I don&amp;#39;t want to be 2-3 years into a data job, then when applying to a senior position find out that I need X skill, so i start cramming, nah, I want to take things slow and gradual, let them sink, and learn them well without pressure.&lt;/p&gt;\n\n&lt;p&gt;TLDR &lt;strong&gt;what are the most impactful skills and knowledge that I could work on right now as a junior data engineer to prepare myself for things like a senior data engineer/architect/lead in the future?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;P.S I come from civil engineering background and have worked as project manager and team manager in engineering and non engineering fields, so I was thinking maybe studying for a PMP would be advantageous for some lead position in the field, but I could be wrong, or maybe there are more impactful things that I should prioritize.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13ppolj", "is_robot_indexable": true, "report_reasons": null, "author": "DimensionOne9851", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ppolj/how_to_progress_after_landing_a_junior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ppolj/how_to_progress_after_landing_a_junior_data/", "subreddit_subscribers": 106933, "created_utc": 1684851023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://www.linkedin.com/feed/update/urn:li:activity:7066434691280580608?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7066434691280580608%29", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Useful LI post on reducing Snowflake bill", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p7zst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684800289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7066434691280580608?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7066434691280580608%29\"&gt;https://www.linkedin.com/feed/update/urn:li:activity:7066434691280580608?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7066434691280580608%29&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pr__ixyfYZlmpDSv6CoH2t9SuOR-uxP0_uW9u3mYxt8.jpg?auto=webp&amp;v=enabled&amp;s=2a405947344d943ef29dad81d3cd89c931c979aa", "width": 800, "height": 431}, "resolutions": [{"url": "https://external-preview.redd.it/pr__ixyfYZlmpDSv6CoH2t9SuOR-uxP0_uW9u3mYxt8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09c3db21abc108c22b9f45b9298014b341493f87", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/pr__ixyfYZlmpDSv6CoH2t9SuOR-uxP0_uW9u3mYxt8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d488eb22ebc5eb711fc29132fb662eba88d44497", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/pr__ixyfYZlmpDSv6CoH2t9SuOR-uxP0_uW9u3mYxt8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8454d0387cdb132f53363f550742e90ae1583fcd", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/pr__ixyfYZlmpDSv6CoH2t9SuOR-uxP0_uW9u3mYxt8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c297ea5fde7b9b6ea33ee843014c5ec4d9c33d3", "width": 640, "height": 344}], "variants": {}, "id": "mpvOKm0fUg2iVXEkZKC0HDtx6E2Mm-4vbVA_KG5pV20"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13p7zst", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p7zst/useful_li_post_on_reducing_snowflake_bill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p7zst/useful_li_post_on_reducing_snowflake_bill/", "subreddit_subscribers": 106933, "created_utc": 1684800289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Orchestrators 101: Everything You Need To Know To Get Started", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_13po709", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aeXCacULyDcZdq1ajCZlpF4QSvNpaOmdUaJ33bfF3yU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684847656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "finishslime.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.finishslime.com/c/data-orchestrator-101", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?auto=webp&amp;v=enabled&amp;s=6ab5d19c9c869a6a0bbc5b777a57f3ab5101788d", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c5d86f04f24fbabe5c4b28f81590d0bb4f00646", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=675a954b7f7c2059942d6ec4c4bb644c1167ff7d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f89f106225234370f250c81914842a0e8f6609b4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d068c56cb7a4d1d30b15cd27c7b10879117bcc07", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0eef99e1d04145261e0004bc611334d855bf746b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/sotomJgjyYjADguDUg9FMlshb8CgPBEoP9lqLcXhUK4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a99346dd414456d438e96ec8a0cf85266c482ce", "width": 1080, "height": 567}], "variants": {}, "id": "uPtFY8iKaSTLqEuJd0nnyUn4vjEjmWDY-GV82dBpxVQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13po709", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13po709/data_orchestrators_101_everything_you_need_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.finishslime.com/c/data-orchestrator-101", "subreddit_subscribers": 106933, "created_utc": 1684847656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.youtube.com/watch?v=pOqQ-0cRWKU&amp;t=1815s](https://www.youtube.com/watch?v=pOqQ-0cRWKU&amp;t=1815s)  \n\n\nTopics covered: \n\n\\*Why streaming incurs less compute cost\n\n\\*How they compare on latency/throughput\n\n  \n\\*Idempotency in Streaming\n\n\\*Schema evolution in Streaming", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast on the Nuances of Batch vs. Streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pqniz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684853226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=pOqQ-0cRWKU&amp;amp;t=1815s\"&gt;https://www.youtube.com/watch?v=pOqQ-0cRWKU&amp;amp;t=1815s&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Topics covered: &lt;/p&gt;\n\n&lt;p&gt;*Why streaming incurs less compute cost&lt;/p&gt;\n\n&lt;p&gt;*How they compare on latency/throughput&lt;/p&gt;\n\n&lt;p&gt;*Idempotency in Streaming&lt;/p&gt;\n\n&lt;p&gt;*Schema evolution in Streaming&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2OJxdzZoPZW3Suu_XIx6lOXq4XRYOHe2YexCMOieJRY.jpg?auto=webp&amp;v=enabled&amp;s=64f8dd399126f6303f974511198a0790abcc2a53", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/2OJxdzZoPZW3Suu_XIx6lOXq4XRYOHe2YexCMOieJRY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1784d7ec3d5668005494a7c38495e87e5f7d119", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/2OJxdzZoPZW3Suu_XIx6lOXq4XRYOHe2YexCMOieJRY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f075abeb6cb8e955ba8966ee78d9b612c9ce8ae", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/2OJxdzZoPZW3Suu_XIx6lOXq4XRYOHe2YexCMOieJRY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0449d5ebefff102549fc12c6e723bbfc4b66b685", "width": 320, "height": 240}], "variants": {}, "id": "LuG4AxhGQQdrI8TNWf7bToRarKzr_31WMYPPF6vuIhw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13pqniz", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pqniz/podcast_on_the_nuances_of_batch_vs_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pqniz/podcast_on_the_nuances_of_batch_vs_streaming/", "subreddit_subscribers": 106933, "created_utc": 1684853226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Governance with policy implementations , how to do design a system to push alerts on non compliance", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you store the SLA's for the pipeline and metadata as a part of good practise ? What are the policy that you have set for pipelines for production systems ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13plv4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684841512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Governance with policy implementations , how to do design a system to push alerts on non compliance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13plv4f", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13plv4f/where_do_you_store_the_slas_for_the_pipeline_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13plv4f/where_do_you_store_the_slas_for_the_pipeline_and/", "subreddit_subscribers": 106933, "created_utc": 1684841512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe currently have an airflow setup with lots of library dependencies. We are currently using good old python virtual env with `requirements.txt` to install it in prod server as well as local of individual team members. But we've been facing issues with reproducability across individual team member systems. Say I install all packages today. Then 2 months later, if I do `pip freeze &gt; requirements.txt` and pass it on to someone else, we see errors in installation due to newer version of the libraries being released constantly.\n\nTo counter this, we have thought of using docker. But even docker images need to be built, which needs to be done with pip. So, for local testing as well as prod server, is it a good idea to just pull docker image from docker registry rather than building it in every system we want the airflow setup as the building will again cause potential dependency issue?\n\nis it a good practice to just pull docker images and modify files, install libraries from within docker container? What are the pros and cons of pulling image vs building it?", "author_fullname": "t2_14bzgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question about good practice when using docker.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pl7tk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684839727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We currently have an airflow setup with lots of library dependencies. We are currently using good old python virtual env with &lt;code&gt;requirements.txt&lt;/code&gt; to install it in prod server as well as local of individual team members. But we&amp;#39;ve been facing issues with reproducability across individual team member systems. Say I install all packages today. Then 2 months later, if I do &lt;code&gt;pip freeze &amp;gt; requirements.txt&lt;/code&gt; and pass it on to someone else, we see errors in installation due to newer version of the libraries being released constantly.&lt;/p&gt;\n\n&lt;p&gt;To counter this, we have thought of using docker. But even docker images need to be built, which needs to be done with pip. So, for local testing as well as prod server, is it a good idea to just pull docker image from docker registry rather than building it in every system we want the airflow setup as the building will again cause potential dependency issue?&lt;/p&gt;\n\n&lt;p&gt;is it a good practice to just pull docker images and modify files, install libraries from within docker container? What are the pros and cons of pulling image vs building it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13pl7tk", "is_robot_indexable": true, "report_reasons": null, "author": "downloaderfan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pl7tk/a_question_about_good_practice_when_using_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pl7tk/a_question_about_good_practice_when_using_docker/", "subreddit_subscribers": 106933, "created_utc": 1684839727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some Azure SQL Database instances which are not maintened. Looking at why the 100 DTUs are necessary, I found out, to date, that the culprit might be the \"DELETE ...\" queries run as runbook on those databases every day to delete data older than 60 days.\n\nI'm uneducated about databases, I started today. What would you do to tackle down the problem, educate myself, and try to find a way to see if that logic could be implemented in another way so that resources are used constantly and not with those huge spikes?\n\n&amp;#x200B;\n\nPlease let me know if and what context I could provide to gain more insights. Thank you.\n\nEDITs:\n\n`SELECT COUNT(*) FROM mytable` took `48m50s`, the count is of the order of `120*10^6 (120M`) rows\n\n`SELECT COUNT(*) FROM mytable WHERE [TimeStamp] &lt; DATEADD(DAY, -60, GETDATE())` took `1.5s`, the count is of the order of `420*10^3 (420K`) rows", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure SQL Database: Log IO bottleneck when deleting data older than 60 days", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pin2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684834071.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684831370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some Azure SQL Database instances which are not maintened. Looking at why the 100 DTUs are necessary, I found out, to date, that the culprit might be the &amp;quot;DELETE ...&amp;quot; queries run as runbook on those databases every day to delete data older than 60 days.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m uneducated about databases, I started today. What would you do to tackle down the problem, educate myself, and try to find a way to see if that logic could be implemented in another way so that resources are used constantly and not with those huge spikes?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please let me know if and what context I could provide to gain more insights. Thank you.&lt;/p&gt;\n\n&lt;p&gt;EDITs:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT COUNT(*) FROM mytable&lt;/code&gt; took &lt;code&gt;48m50s&lt;/code&gt;, the count is of the order of &lt;code&gt;120*10^6 (120M&lt;/code&gt;) rows&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT COUNT(*) FROM mytable WHERE [TimeStamp] &amp;lt; DATEADD(DAY, -60, GETDATE())&lt;/code&gt; took &lt;code&gt;1.5s&lt;/code&gt;, the count is of the order of &lt;code&gt;420*10^3 (420K&lt;/code&gt;) rows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13pin2w", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pin2w/azure_sql_database_log_io_bottleneck_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pin2w/azure_sql_database_log_io_bottleneck_when/", "subreddit_subscribers": 106933, "created_utc": 1684831370.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a project that requires creating lookup/dimensional tables for countries &amp; country codes, states/provinces &amp; their codes, cities, and zip codes. \n\nDue to the nature of the project, depending on the client data, they will use either Country ISO 3166-1 alpha-2, alpha-3 as well as UN codes (for country). \n\nI feel like the solution here would be to purchase some of this standardized data formatted relationally with parent/child for country/state or province/city/zip code. Am I on the right track here?\n\nI queried a single on our clients data that doesn't even have a country level, so the query was just SELECT DISTINCT STATE, CITY, ZIP CODE and there was over 1.5mm records. \n\nHas anyone else had to create a data warehouse and needed to create dimensional tables for this type of geolocation data?", "author_fullname": "t2_7yxn2qnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Geolocation Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p7zig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684800266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a project that requires creating lookup/dimensional tables for countries &amp;amp; country codes, states/provinces &amp;amp; their codes, cities, and zip codes. &lt;/p&gt;\n\n&lt;p&gt;Due to the nature of the project, depending on the client data, they will use either Country ISO 3166-1 alpha-2, alpha-3 as well as UN codes (for country). &lt;/p&gt;\n\n&lt;p&gt;I feel like the solution here would be to purchase some of this standardized data formatted relationally with parent/child for country/state or province/city/zip code. Am I on the right track here?&lt;/p&gt;\n\n&lt;p&gt;I queried a single on our clients data that doesn&amp;#39;t even have a country level, so the query was just SELECT DISTINCT STATE, CITY, ZIP CODE and there was over 1.5mm records. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else had to create a data warehouse and needed to create dimensional tables for this type of geolocation data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13p7zig", "is_robot_indexable": true, "report_reasons": null, "author": "dilbertdad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p7zig/geolocation_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p7zig/geolocation_databases/", "subreddit_subscribers": 106933, "created_utc": 1684800266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[dbt Cloud](https://getdbt.com/) rightfully gets a lot of credit for creating dbt Core and for being the first managed dbt Core platform, but there are several entrants in the market; from those who just run dbt jobs like [Fivetran](https://fivetran.com/docs/transformations/dbt) to platforms that offer more like EL + T like [Mozart Data](https://mozartdata.com/) and [Datacoves](https://datacoves.com/) which also has hosted VS Code editor for dbt development and  Airflow.\n\nThere's always the option to roll your own with just dbt Core.\n\nWhat's your experience with setting up dbt for your company or for your customers?", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on dbt Cloud vs other managed dbt Core platforms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pt2zs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684858639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://getdbt.com/\"&gt;dbt Cloud&lt;/a&gt; rightfully gets a lot of credit for creating dbt Core and for being the first managed dbt Core platform, but there are several entrants in the market; from those who just run dbt jobs like &lt;a href=\"https://fivetran.com/docs/transformations/dbt\"&gt;Fivetran&lt;/a&gt; to platforms that offer more like EL + T like &lt;a href=\"https://mozartdata.com/\"&gt;Mozart Data&lt;/a&gt; and &lt;a href=\"https://datacoves.com/\"&gt;Datacoves&lt;/a&gt; which also has hosted VS Code editor for dbt development and  Airflow.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s always the option to roll your own with just dbt Core.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your experience with setting up dbt for your company or for your customers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?auto=webp&amp;v=enabled&amp;s=d4169652ab7f36209622ee244f310aefe0cf8ce2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd185c71f8fd75a33c0c79555ab7aa66ff94f024", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10e2c53de9b2969366504c9ded514bbe1e2eb4d1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7634b43f18facd6b7a0eaa901c2b135c2c9f47cf", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=487560d27ca62339efe41270d29a0644753c4362", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43637abd63f6c913d8d643f155a22cfee21ab4eb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7eff2686e5c425ddf4ad53b33e6ccec820db7c7", "width": 1080, "height": 567}], "variants": {}, "id": "2FMzESMf4JTwwEXCI7l6BQ_Y4vxSjUVpLJpZ0tVaorg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13pt2zs", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pt2zs/what_are_your_thoughts_on_dbt_cloud_vs_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pt2zs/what_are_your_thoughts_on_dbt_cloud_vs_other/", "subreddit_subscribers": 106933, "created_utc": 1684858639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Vlog on how to build an on-premise Data Lake?  | Build your own Data Lake | Open Source Tools | On-Premise\n\n[https://www.youtube.com/watch?v=DLRiUs1EvhM&amp;t](https://www.youtube.com/watch?v=DLRiUs1EvhM&amp;t=625s)\n\nTopics covered:\n\n* Benefit of data lake\n* Setup infrastructure for on-premise data lake\n* Configure a S3 bucket in MinIO S3 compatible storage, Hive Metastore and Trino SQL engine\n* Create external tables and Query data lake data using Trino\n\nTech Stack:  **Docker, MinIO, Hive Metastore and Trino**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build your own Data Lake on your infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pzknz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684873333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Vlog on how to build an on-premise Data Lake?  | Build your own Data Lake | Open Source Tools | On-Premise&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=DLRiUs1EvhM&amp;amp;t=625s\"&gt;https://www.youtube.com/watch?v=DLRiUs1EvhM&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Benefit of data lake&lt;/li&gt;\n&lt;li&gt;Setup infrastructure for on-premise data lake&lt;/li&gt;\n&lt;li&gt;Configure a S3 bucket in MinIO S3 compatible storage, Hive Metastore and Trino SQL engine&lt;/li&gt;\n&lt;li&gt;Create external tables and Query data lake data using Trino&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack:  &lt;strong&gt;Docker, MinIO, Hive Metastore and Trino&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l4_jGymfXDRgJD89lQuGpmz_zA8I48CJBzkP4vA5gxI.jpg?auto=webp&amp;v=enabled&amp;s=3e9c221e50a2dff0a3da95f74067c3c4c3fcc943", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/l4_jGymfXDRgJD89lQuGpmz_zA8I48CJBzkP4vA5gxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e80dc4da4052df09c452144a8055a7492c66593d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/l4_jGymfXDRgJD89lQuGpmz_zA8I48CJBzkP4vA5gxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74104f62cc96f3225ff25c4cf6831575cc05f214", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/l4_jGymfXDRgJD89lQuGpmz_zA8I48CJBzkP4vA5gxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e6947638275ab715f0e04c77dfb6001da69b4f9", "width": 320, "height": 240}], "variants": {}, "id": "TOnH2O7IiemRnGg9znKMWOVGwjbMwzLgLzf5f1QBHQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13pzknz", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pzknz/build_your_own_data_lake_on_your_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pzknz/build_your_own_data_lake_on_your_infrastructure/", "subreddit_subscribers": 106933, "created_utc": 1684873333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to figure out a low impact, easy to use and maintain way to communicate in near real time the health and status of key tables in our warehouse. I can invest in catalog or observability tools but was considering creating simple data pipelines that calculate stats about business tables and produce a \u201chealth report table\u201d that users can query directly without going into another UI.\n\nSay I have \u201ccustomers_tbl\u201d table that is used by other people and pipelines. I will create a job (in SQL wIthin Snowflake, in my case) to calculate column and table stats, that will be written to a \u201c_health_customers_tbl\u201d.\n\nIf anyone wants to know when was the \u201ccustomers_tbl\u201d updated or when was schema changed or column distribution, etc. they can just query this health table.\n\nIs this idea crazy? Has anyone done something like this before?  \n\nI can assume this will add some compute cost but I think it will be less than paying for a data observability tool.", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are \u201chealth report tables\u201d a good idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p6lnd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684796853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to figure out a low impact, easy to use and maintain way to communicate in near real time the health and status of key tables in our warehouse. I can invest in catalog or observability tools but was considering creating simple data pipelines that calculate stats about business tables and produce a \u201chealth report table\u201d that users can query directly without going into another UI.&lt;/p&gt;\n\n&lt;p&gt;Say I have \u201ccustomers_tbl\u201d table that is used by other people and pipelines. I will create a job (in SQL wIthin Snowflake, in my case) to calculate column and table stats, that will be written to a \u201c_health_customers_tbl\u201d.&lt;/p&gt;\n\n&lt;p&gt;If anyone wants to know when was the \u201ccustomers_tbl\u201d updated or when was schema changed or column distribution, etc. they can just query this health table.&lt;/p&gt;\n\n&lt;p&gt;Is this idea crazy? Has anyone done something like this before?  &lt;/p&gt;\n\n&lt;p&gt;I can assume this will add some compute cost but I think it will be less than paying for a data observability tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13p6lnd", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p6lnd/are_health_report_tables_a_good_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p6lnd/are_health_report_tables_a_good_idea/", "subreddit_subscribers": 106933, "created_utc": 1684796853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Best I can tell is it's basically GCP's clone of dbt without Python models and slightly different syntax.\n\nFor some reasons might be preferred by my org to dbt.  Doing an investigation now, but was wondering if anyone has used it and can give me a headsup on the gotchas to watch out for.\n\nThanks in advance!", "author_fullname": "t2_94vh7oax8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using DataForms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13px7x4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684868062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Best I can tell is it&amp;#39;s basically GCP&amp;#39;s clone of dbt without Python models and slightly different syntax.&lt;/p&gt;\n\n&lt;p&gt;For some reasons might be preferred by my org to dbt.  Doing an investigation now, but was wondering if anyone has used it and can give me a headsup on the gotchas to watch out for.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13px7x4", "is_robot_indexable": true, "report_reasons": null, "author": "a_library_socialist", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13px7x4/anyone_using_dataforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13px7x4/anyone_using_dataforms/", "subreddit_subscribers": 106933, "created_utc": 1684868062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It is crucial to do side projects and having them on your resume when applying for entry level roles. However, does this apply to mid and senior level DE roles? Or is the job experience and doing well on technical interviews enough?", "author_fullname": "t2_9jq8g6tr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pp4h6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684849767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is crucial to do side projects and having them on your resume when applying for entry level roles. However, does this apply to mid and senior level DE roles? Or is the job experience and doing well on technical interviews enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13pp4h6", "is_robot_indexable": true, "report_reasons": null, "author": "WorldlyDirt5024", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pp4h6/side_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pp4h6/side_projects/", "subreddit_subscribers": 106933, "created_utc": 1684849767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the actual use cases when you opted for multi tenant architecture for a data engineering project ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single Tenant Vs Multi tenant architecture in Azure Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pbr9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684810084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the actual use cases when you opted for multi tenant architecture for a data engineering project ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13pbr9t", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pbr9t/single_tenant_vs_multi_tenant_architecture_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pbr9t/single_tenant_vs_multi_tenant_architecture_in/", "subreddit_subscribers": 106933, "created_utc": 1684810084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization has recently decided upon IBM cp4d on prem and all of the associated systems as their be all end all solution to everything. No training has occurred and it seems that we are stuck with it. \n\nI'm having a hard time finding resources other than IBMS own shitty documentation in order to get familiar with this shitty system. Everything seems to be in beta and bugs are everywhere. \n\nIt's not like I can just go look at old threads on stackoverflow and get any wiser , as it seems literally zero other organizations use this POS. \n\nAny tips or suggestions to cope ?\n\nI currently need to utilize IBMS datastage just to perform simple queries on existing dvs, which is quite exhausting due to the many bugs. I am told that Watson query might become available in a later update.....", "author_fullname": "t2_dsw4juwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Cloud pak for data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pzrqu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684873778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization has recently decided upon IBM cp4d on prem and all of the associated systems as their be all end all solution to everything. No training has occurred and it seems that we are stuck with it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having a hard time finding resources other than IBMS own shitty documentation in order to get familiar with this shitty system. Everything seems to be in beta and bugs are everywhere. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not like I can just go look at old threads on stackoverflow and get any wiser , as it seems literally zero other organizations use this POS. &lt;/p&gt;\n\n&lt;p&gt;Any tips or suggestions to cope ?&lt;/p&gt;\n\n&lt;p&gt;I currently need to utilize IBMS datastage just to perform simple queries on existing dvs, which is quite exhausting due to the many bugs. I am told that Watson query might become available in a later update.....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13pzrqu", "is_robot_indexable": true, "report_reasons": null, "author": "LegitimatePea2758", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pzrqu/ibm_cloud_pak_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pzrqu/ibm_cloud_pak_for_data/", "subreddit_subscribers": 106933, "created_utc": 1684873778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm here to ask about a project I'm working on. This is my first time using AWS, and I'm eager to learn more about it alongside this project. \n\nThe project involves creating a simple analysis of Twitter accounts. The idea is to analyze the overall sentiment of tweets and get a sense of people's personalities. To make it happen, I was planning to use the GPT API for sentiment analysis. Once I process the data, I'll store it in a data warehouse (s3) for future analysis. \n\nThe application will be in the form of a web application, where data scraping and processing will occur upon user request. I'm considering implementing a queue system, but I'm not familiar with the tools yet.\n\nHere's the architecture I've come up with: \n\nhttps://preview.redd.it/7bksvk2cnj1b1.png?width=2142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b61dc804ca88cfd9dbca0ff3e5b18fdbef1fe43\n\nMy background is mainly in web development, and I've never ventured into the world of data engineering until now. So, I'm hoping you awesome folks here can lend a hand by suggesting simpler system solutions for this project since I'll be working on it by myself, so any help would be greatly appreciated.\n\nThank you!", "author_fullname": "t2_n016w5k8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on architecture and tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7bksvk2cnj1b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=824e67243071561ae038f42d2158bf49478c7f13"}, {"y": 106, "x": 216, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08ad4a5a5994abf291a7e7b5119463090dac6c23"}, {"y": 157, "x": 320, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=211d7607acda44a2ff8345564726f79d105ba3e5"}, {"y": 314, "x": 640, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5546e4040b2412966f8209361d32db20eabe3cf8"}, {"y": 471, "x": 960, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=350e703db6686dd7066ab152e93a47ff4182ce6a"}, {"y": 530, "x": 1080, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c5f46ebce953df1ccbcf27fb39fe7dd2c060abf"}], "s": {"y": 1052, "x": 2142, "u": "https://preview.redd.it/7bksvk2cnj1b1.png?width=2142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b61dc804ca88cfd9dbca0ff3e5b18fdbef1fe43"}, "id": "7bksvk2cnj1b1"}}, "name": "t3_13piswd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IbObAwVtlrFZNEU3qWR7QlJA50jJw8K0nSlSloGQczY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684831938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here to ask about a project I&amp;#39;m working on. This is my first time using AWS, and I&amp;#39;m eager to learn more about it alongside this project. &lt;/p&gt;\n\n&lt;p&gt;The project involves creating a simple analysis of Twitter accounts. The idea is to analyze the overall sentiment of tweets and get a sense of people&amp;#39;s personalities. To make it happen, I was planning to use the GPT API for sentiment analysis. Once I process the data, I&amp;#39;ll store it in a data warehouse (s3) for future analysis. &lt;/p&gt;\n\n&lt;p&gt;The application will be in the form of a web application, where data scraping and processing will occur upon user request. I&amp;#39;m considering implementing a queue system, but I&amp;#39;m not familiar with the tools yet.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the architecture I&amp;#39;ve come up with: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7bksvk2cnj1b1.png?width=2142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3b61dc804ca88cfd9dbca0ff3e5b18fdbef1fe43\"&gt;https://preview.redd.it/7bksvk2cnj1b1.png?width=2142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3b61dc804ca88cfd9dbca0ff3e5b18fdbef1fe43&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My background is mainly in web development, and I&amp;#39;ve never ventured into the world of data engineering until now. So, I&amp;#39;m hoping you awesome folks here can lend a hand by suggesting simpler system solutions for this project since I&amp;#39;ll be working on it by myself, so any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13piswd", "is_robot_indexable": true, "report_reasons": null, "author": "undefinedenv", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13piswd/looking_for_feedback_on_architecture_and_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13piswd/looking_for_feedback_on_architecture_and_tools/", "subreddit_subscribers": 106933, "created_utc": 1684831938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems that everyone has a different definition of what real-time is. When you say real-time, what level of latency do you mean?\n\n[View Poll](https://www.reddit.com/poll/13pzmz6)", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers, what level of latency is real-time to you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pzmz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "#46d160", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684873475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems that everyone has a different definition of what real-time is. When you say real-time, what level of latency do you mean?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13pzmz6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13pzmz6", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1685478275062, "options": [{"text": "As fast as possible (seconds)", "id": "23158729"}, {"text": "Under 5 minutes", "id": "23158730"}, {"text": "Under 15 minutes", "id": "23158731"}, {"text": "Under 30 minutes", "id": "23158732"}, {"text": "Under 1 hour", "id": "23158733"}, {"text": "See results", "id": "23158734"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 113, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/13pzmz6/data_engineers_what_level_of_latency_is_realtime/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/13pzmz6/data_engineers_what_level_of_latency_is_realtime/", "subreddit_subscribers": 106933, "created_utc": 1684873475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently had an interview with a reputable international retailer. They've now asked me to complete a technical exercise using AWS, and asked me to set up a free account to complete this in.\n\nI've done this (and supplied my personal credit card in the billing section), and I've been working through the exercise (setting up a Redshift cluster, loading in data from their sample s3 bucket etc).\n\nIn order to submit my work, the hiring company are saying they need access to my console and are requesting my account id, username, and password.\n\nIs this as terrible as I think it is?\n\nI would be surprised if this company was doing anything untoward in their hiring process, but this just seems like very bad practice. Has anyone been in a similar situation? Any suggestions?\n\nThank you in advance.", "author_fullname": "t2_bwm3z164q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handing over passwords for job interview (x-post r/aws)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pydky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684870659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had an interview with a reputable international retailer. They&amp;#39;ve now asked me to complete a technical exercise using AWS, and asked me to set up a free account to complete this in.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done this (and supplied my personal credit card in the billing section), and I&amp;#39;ve been working through the exercise (setting up a Redshift cluster, loading in data from their sample s3 bucket etc).&lt;/p&gt;\n\n&lt;p&gt;In order to submit my work, the hiring company are saying they need access to my console and are requesting my account id, username, and password.&lt;/p&gt;\n\n&lt;p&gt;Is this as terrible as I think it is?&lt;/p&gt;\n\n&lt;p&gt;I would be surprised if this company was doing anything untoward in their hiring process, but this just seems like very bad practice. Has anyone been in a similar situation? Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13pydky", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Examination6378", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pydky/handing_over_passwords_for_job_interview_xpost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pydky/handing_over_passwords_for_job_interview_xpost/", "subreddit_subscribers": 106933, "created_utc": 1684870659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a common challenge for us, and I'm curious how others are handling it? I work in a data team in a biotech, and we generate lots of data locally across all of our instruments. Our current (and only approach) is AWS DataSync. We install the DataSync Agent on ESXi on our local network and mount it to our instrument PCs with SMB, and all data movements are coordinated by DataSync.\n\nThis solution works, but it does technically vendor lock us. Also, we're reliant on other departments to setup the DataSync Agent on ESXi for us. I'm curious if other teams are using anything else for these data movements? Ideally we'd just want everything to be up in S3 at the end of the day!", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to automate data movement from local networks into the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13py2bl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684869955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a common challenge for us, and I&amp;#39;m curious how others are handling it? I work in a data team in a biotech, and we generate lots of data locally across all of our instruments. Our current (and only approach) is AWS DataSync. We install the DataSync Agent on ESXi on our local network and mount it to our instrument PCs with SMB, and all data movements are coordinated by DataSync.&lt;/p&gt;\n\n&lt;p&gt;This solution works, but it does technically vendor lock us. Also, we&amp;#39;re reliant on other departments to setup the DataSync Agent on ESXi for us. I&amp;#39;m curious if other teams are using anything else for these data movements? Ideally we&amp;#39;d just want everything to be up in S3 at the end of the day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13py2bl", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13py2bl/best_way_to_automate_data_movement_from_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13py2bl/best_way_to_automate_data_movement_from_local/", "subreddit_subscribers": 106933, "created_utc": 1684869955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am building a data sync between Hubspot and a custom CRM. I currently am just working on the contacts and have success updating the Azure sql database for the custom CRM when a new contact is created in Hubspot. I used the webhook from a public app in Hubspot to trigger an Azure function that grabs the contact information and stores it in an ADL Gen2 container. This then activates an event storage which triggers a pipeline to process the json and store it into the Azure SQL.\n\n&amp;#x200B;\n\nI am having an issue trying to do the reverse. I have CDC enable for the azure sql database which appears to be working correctly. However, I cant seem to format the data in the correct way for Hubspot because when I create a new contact in the sql database, the entry is blank in Hubspot. \n\n&amp;#x200B;\n\nI believe this issue is do to not grouping the columns into an object called properties. Here is an example of what hubspot sends for a Get which shows the complex type properties:  \n[https://imgur.com/a/WJ3p4b7](https://imgur.com/a/WJ3p4b7)\n\nHere is what the data preview looks like after I perform a SelectForSink transformation:  \n https://imgur.com/bNoiS3Y \n\nI think I need to make a derived column called properties and group the columns into it. I see that I can make an array but I dont see how I can make an object {}. \n\n&amp;#x200B;\n\nCan someone please give me some advice on what I should do? If I am unable to do it this way then I will probably have to make an Azure function.", "author_fullname": "t2_97un5mf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create a complex data type in ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pqd9a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684852569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building a data sync between Hubspot and a custom CRM. I currently am just working on the contacts and have success updating the Azure sql database for the custom CRM when a new contact is created in Hubspot. I used the webhook from a public app in Hubspot to trigger an Azure function that grabs the contact information and stores it in an ADL Gen2 container. This then activates an event storage which triggers a pipeline to process the json and store it into the Azure SQL.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am having an issue trying to do the reverse. I have CDC enable for the azure sql database which appears to be working correctly. However, I cant seem to format the data in the correct way for Hubspot because when I create a new contact in the sql database, the entry is blank in Hubspot. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I believe this issue is do to not grouping the columns into an object called properties. Here is an example of what hubspot sends for a Get which shows the complex type properties:&lt;br/&gt;\n&lt;a href=\"https://imgur.com/a/WJ3p4b7\"&gt;https://imgur.com/a/WJ3p4b7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is what the data preview looks like after I perform a SelectForSink transformation:&lt;br/&gt;\n &lt;a href=\"https://imgur.com/bNoiS3Y\"&gt;https://imgur.com/bNoiS3Y&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I think I need to make a derived column called properties and group the columns into it. I see that I can make an array but I dont see how I can make an object {}. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can someone please give me some advice on what I should do? If I am unable to do it this way then I will probably have to make an Azure function.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?auto=webp&amp;v=enabled&amp;s=6892f3e05a6b6dfadb69517bbed16d391822cf52", "width": 3039, "height": 815}, "resolutions": [{"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77226aed15ca874452728ffe6752eb03e7010ed1", "width": 108, "height": 28}, {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f957d5565c14e80bb4adbe30bbf12397dfc1ef8", "width": 216, "height": 57}, {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd5032148a025c3337655b471c87d79b1a04b3ec", "width": 320, "height": 85}, {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130fd43f9acafd255aba16408940a8535330e971", "width": 640, "height": 171}, {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69a8ac3dd35115c632de967f187d4d3adef8d500", "width": 960, "height": 257}, {"url": "https://external-preview.redd.it/NDOQTC4UHC-R1Xuqn-F4Ijqjzzgy5jM_ifhEpBmNjA0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a88898eb16083cc0da6e0f60a4ac1d3c3d6dc48", "width": 1080, "height": 289}], "variants": {}, "id": "NPkAwkAaU1T_FCb3pH9LrfrHQjZyiczwJ-6LiP1I-a4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13pqd9a", "is_robot_indexable": true, "report_reasons": null, "author": "Connect-Nectarine233", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pqd9a/how_to_create_a_complex_data_type_in_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pqd9a/how_to_create_a_complex_data_type_in_adf/", "subreddit_subscribers": 106933, "created_utc": 1684852569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There\u2019s a very specific Hudi schema evolution constraint which is problematic for us: nested columns within an array type are not allowed. How does the community overcome this?", "author_fullname": "t2_swz6nr80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hudi schema evolution constraints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pq89y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684852256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There\u2019s a very specific Hudi schema evolution constraint which is problematic for us: nested columns within an array type are not allowed. How does the community overcome this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13pq89y", "is_robot_indexable": true, "report_reasons": null, "author": "godmadetexas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13pq89y/hudi_schema_evolution_constraints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13pq89y/hudi_schema_evolution_constraints/", "subreddit_subscribers": 106933, "created_utc": 1684852256.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}