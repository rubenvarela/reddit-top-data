{"kind": "Listing", "data": {"after": "t3_13p9lqb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work at a large firm but a relatively new data science team. The manager is apparently an experienced data scientist, or so I'm told.\n\nI'm analyzing HR data of applicants to our company, specifically new graduates who have attended our seminars and partaken in surveys. The surveys are non-anonymous, their name and applicant ID, school, whatever, all visible. Questions like \"Are you excited to work for us?\" and questions related to benefits and salary are asked. This is obviously going to lead to Social desirability biased answers, right? Am I crazy? Who the hell is going to answer negatively about a company they are applying for as a new graduate with no experience?\n\nOh and we use 6-point likert scales for some survey questions, because the manager thinks 5 or 7 point scales are \"just textbook stuff\".\n\nI think I'm gonna gtfo soon /rant", "author_fullname": "t2_24el30e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager doesn't think our non-anonymous survey data is biased", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ow6gb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 237, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 237, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684774136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a large firm but a relatively new data science team. The manager is apparently an experienced data scientist, or so I&amp;#39;m told.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m analyzing HR data of applicants to our company, specifically new graduates who have attended our seminars and partaken in surveys. The surveys are non-anonymous, their name and applicant ID, school, whatever, all visible. Questions like &amp;quot;Are you excited to work for us?&amp;quot; and questions related to benefits and salary are asked. This is obviously going to lead to Social desirability biased answers, right? Am I crazy? Who the hell is going to answer negatively about a company they are applying for as a new graduate with no experience?&lt;/p&gt;\n\n&lt;p&gt;Oh and we use 6-point likert scales for some survey questions, because the manager thinks 5 or 7 point scales are &amp;quot;just textbook stuff&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;m gonna gtfo soon /rant&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ow6gb", "is_robot_indexable": true, "report_reasons": null, "author": "NipponPanda", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ow6gb/manager_doesnt_think_our_nonanonymous_survey_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ow6gb/manager_doesnt_think_our_nonanonymous_survey_data/", "subreddit_subscribers": 907104, "created_utc": 1684774136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi. I'm 24. Female. Recently finished my masters in statistics. Interested in data science and miraculously I was hired to do analysis for two large restaurant companies under the same parent group. I was super excited but 3 months later. I'm miserable. \n\nI thought I would've been able to take some data and clean it up and do some cool analysis on it. But it's so much. I can't handle this. I have to keep track of customer and sales data for two large companies. Most of the data isn't even clean. There's about 5 platforms to keep track of for each. There's stupid meetings every day. Presentations for each company every week. And then in-between that I have to find time to do my own work. I have no personal time. My relationship died.\n\nMy boss is an absolute nightmare. A stereotypical corporate bro. The most emotionless uncaring blunt workaholic person I've ever met. I can do nothing right in his eyes. I've never received a list of specific tasks to do. Sometimes I give him insights into some data and he ignores it. I don't care for a bunch of emotional shit but a little bit of empathy or something. And then they're telling me about their plans for me long term in the company and they've already sent me on a trip abroad for training.\n\nI just wanted to use some sales/customer data and do some analysis man. This is too much. How do I even navigate this?", "author_fullname": "t2_mnwtz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job is a nightmare - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13peb5z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 125, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 125, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684817319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I&amp;#39;m 24. Female. Recently finished my masters in statistics. Interested in data science and miraculously I was hired to do analysis for two large restaurant companies under the same parent group. I was super excited but 3 months later. I&amp;#39;m miserable. &lt;/p&gt;\n\n&lt;p&gt;I thought I would&amp;#39;ve been able to take some data and clean it up and do some cool analysis on it. But it&amp;#39;s so much. I can&amp;#39;t handle this. I have to keep track of customer and sales data for two large companies. Most of the data isn&amp;#39;t even clean. There&amp;#39;s about 5 platforms to keep track of for each. There&amp;#39;s stupid meetings every day. Presentations for each company every week. And then in-between that I have to find time to do my own work. I have no personal time. My relationship died.&lt;/p&gt;\n\n&lt;p&gt;My boss is an absolute nightmare. A stereotypical corporate bro. The most emotionless uncaring blunt workaholic person I&amp;#39;ve ever met. I can do nothing right in his eyes. I&amp;#39;ve never received a list of specific tasks to do. Sometimes I give him insights into some data and he ignores it. I don&amp;#39;t care for a bunch of emotional shit but a little bit of empathy or something. And then they&amp;#39;re telling me about their plans for me long term in the company and they&amp;#39;ve already sent me on a trip abroad for training.&lt;/p&gt;\n\n&lt;p&gt;I just wanted to use some sales/customer data and do some analysis man. This is too much. How do I even navigate this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13peb5z", "is_robot_indexable": true, "report_reasons": null, "author": "secretmacaroni", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13peb5z/job_is_a_nightmare_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13peb5z/job_is_a_nightmare_advice/", "subreddit_subscribers": 907104, "created_utc": 1684817319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Agree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13pdj6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jGygU1zEpilvebgcS0VAJvshK3a_DVub3v1AgyviRuI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684814974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zz5stj1cai1b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zz5stj1cai1b1.jpg?auto=webp&amp;v=enabled&amp;s=97f2a85fe76429dee2377c0b892e241dad6d6f91", "width": 908, "height": 998}, "resolutions": [{"url": "https://preview.redd.it/zz5stj1cai1b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f8c59646040bc1906cf7e121bdf3cc293e0e2b3", "width": 108, "height": 118}, {"url": "https://preview.redd.it/zz5stj1cai1b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ff72ec2dc38bbbddb3efeba584ce3fc4ba81d2f", "width": 216, "height": 237}, {"url": "https://preview.redd.it/zz5stj1cai1b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf64ed0834ec14094e71e8367225f83e9014d9b2", "width": 320, "height": 351}, {"url": "https://preview.redd.it/zz5stj1cai1b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eeecf8129b0e4a394382f7314ae0cd8886a0f50", "width": 640, "height": 703}], "variants": {}, "id": "Pf1KrCuGDoiznTxiDTHUNtK6sPUuiO7qMk2VInBFW-c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pdj6t", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pdj6t/agree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zz5stj1cai1b1.jpg", "subreddit_subscribers": 907104, "created_utc": 1684814974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all!\n\nI\u2019m currently a data scientist in the civil service in London and earn approximately \u00a342K. I have around 2 years DS experience, but before then I was in analytics for around 10 years, so I understand that I\u2019m pretty under paid compared to others who are of a similar level to me. \n\nI\u2019ve just been offered a role in the analytics consulting department of a big 4 company, and they have offered me a base rate of \u00a355K. The recruiter informed me it was based on my current salary but I figured as it\u2019s private, it would be significantly more, and they would take in my experience. I\u2019ve been told there isn\u2019t much wiggle room and that \u00a355K is what I should expect as it\u2019s a manager role. \n\nDoes this seem right to you? Should I accept the offer?\n\nThank you everyone!", "author_fullname": "t2_15vycc2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary offer in UK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p061h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684782803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a data scientist in the civil service in London and earn approximately \u00a342K. I have around 2 years DS experience, but before then I was in analytics for around 10 years, so I understand that I\u2019m pretty under paid compared to others who are of a similar level to me. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve just been offered a role in the analytics consulting department of a big 4 company, and they have offered me a base rate of \u00a355K. The recruiter informed me it was based on my current salary but I figured as it\u2019s private, it would be significantly more, and they would take in my experience. I\u2019ve been told there isn\u2019t much wiggle room and that \u00a355K is what I should expect as it\u2019s a manager role. &lt;/p&gt;\n\n&lt;p&gt;Does this seem right to you? Should I accept the offer?&lt;/p&gt;\n\n&lt;p&gt;Thank you everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p061h", "is_robot_indexable": true, "report_reasons": null, "author": "datataa", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p061h/salary_offer_in_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p061h/salary_offer_in_uk/", "subreddit_subscribers": 907104, "created_utc": 1684782803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 2 models, a random forest and a xgboost for a binary classification problem. During training and validation the xgboost preforms better looking at f1 score (unbalanced data). \n\nBut when looking at new data, it\u2019s giving bad results. I\u2019m not too familiar with hyper parameter tuning on Xgboost and just tuned a few basic parameters until I got the best f1 score, so maybe it\u2019s something there? I\u2019m 100% certain there\u2019s no data leakage between the training and validation. Any idea what it could be? The predictions are also very liberal (highest is .999) compared to the random forest (highest is .25). \n\nAlso I\u2019m still fairly new to DS(&lt;2 years), so my knowledge is mostly beginner.", "author_fullname": "t2_495cn7pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Xgboost model is vastly underperforming compared to my Random Forest and I can\u2019t figure out why", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pllob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684840807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 models, a random forest and a xgboost for a binary classification problem. During training and validation the xgboost preforms better looking at f1 score (unbalanced data). &lt;/p&gt;\n\n&lt;p&gt;But when looking at new data, it\u2019s giving bad results. I\u2019m not too familiar with hyper parameter tuning on Xgboost and just tuned a few basic parameters until I got the best f1 score, so maybe it\u2019s something there? I\u2019m 100% certain there\u2019s no data leakage between the training and validation. Any idea what it could be? The predictions are also very liberal (highest is .999) compared to the random forest (highest is .25). &lt;/p&gt;\n\n&lt;p&gt;Also I\u2019m still fairly new to DS(&amp;lt;2 years), so my knowledge is mostly beginner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pllob", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawayforgainz99", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pllob/my_xgboost_model_is_vastly_underperforming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pllob/my_xgboost_model_is_vastly_underperforming/", "subreddit_subscribers": 907104, "created_utc": 1684840807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I've figured I have a natural tendency to undervalue things that come naturally to me and pursue things that don't come naturally to me. I think it's because the knowledge of not knowing something makes me feel insecure.\n\nTrying to keep that in mind to keep me checked from self sabotage. But wondering if anyone else has gone through similar problems and what worked best in your case to overcome this.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your best tip to feel more psychologically secure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p4j56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684792119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve figured I have a natural tendency to undervalue things that come naturally to me and pursue things that don&amp;#39;t come naturally to me. I think it&amp;#39;s because the knowledge of not knowing something makes me feel insecure.&lt;/p&gt;\n\n&lt;p&gt;Trying to keep that in mind to keep me checked from self sabotage. But wondering if anyone else has gone through similar problems and what worked best in your case to overcome this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p4j56", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p4j56/whats_your_best_tip_to_feel_more_psychologically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p4j56/whats_your_best_tip_to_feel_more_psychologically/", "subreddit_subscribers": 907104, "created_utc": 1684792119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_btzj2powd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Data Science Application: It\u2019s Time to Do Away With Majority-Minority Districts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_13ox36q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4sl_LGxd5HEr4k3HKejoojW-KVCZ5DQitf3iaKpLSgY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684776096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataanddivergence.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://dataanddivergence.substack.com/p/its-time-to-do-away-with-majority", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?auto=webp&amp;v=enabled&amp;s=1d846b83a0b65815db71b69d4ada45ca3ed1d1c7", "width": 1151, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=937ecaa73b8b63ef1dcf86800f96dd5a66c993e6", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f6a1d92df798f364812b63eabde04df5d86baec", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c27aeee1f9d7e128b81289fd108773219dd43fc6", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1e3b2853e01dda6ef816bc7bf1869b595d2c356", "width": 640, "height": 333}, {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28314833c578a667395ddac9016655ec5d6dd621", "width": 960, "height": 500}, {"url": "https://external-preview.redd.it/IKeZIF3ZyviyxxCHMDAV3hypkH-9nkyj6-jNglWxZlI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fb86f41c8154d9dfc46efac720b844fc59c665a", "width": 1080, "height": 562}], "variants": {}, "id": "NpXQ5H-7smzcZ5k8XJcZmWaN6ksgFkosI0o5LIkuCbo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ox36q", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-Fishing-146", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ox36q/great_data_science_application_its_time_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataanddivergence.substack.com/p/its-time-to-do-away-with-majority", "subreddit_subscribers": 907104, "created_utc": 1684776096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am hoping to get thoughts from folks here. I am currently in a senior position as a data engineer at Salesforce. The job is incredible, I love the product I work on, I love the people I work with, it's been amazing being here. I was approached recently by Google, who is interested in my skill-set doing similar work for them. They asked me what it would take for me to move and I told them more than my current range. They admitted that they wouldn't offer me much more than what I'm currently making - it's less than $30K more - and I'm really not that into the work that they described. They also asked if I was open to relocating; when I flat-out said \"No,\" they said, \"Okay, remote is fine.\" \n\nThat does raise some questions in my head regarding if I'd be pressured to move if I was hired. I received an invitation for the next round of the interview process and it was full of courses and lists to prepare for the interview, and I just thought, this is a **lot** of work for a job I'm really not that interested in and for a product that Google owns that I don't think has legs. But I also know that Google is the \"white whale\" of FAANG and I'm wondering if I'm being absurd in not taking this opportunity. I'd like to hear from anyone who has worked both places and what your thoughts are on this scenario.", "author_fullname": "t2_45ukz986", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google vs Salesforce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p8xwy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684802720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am hoping to get thoughts from folks here. I am currently in a senior position as a data engineer at Salesforce. The job is incredible, I love the product I work on, I love the people I work with, it&amp;#39;s been amazing being here. I was approached recently by Google, who is interested in my skill-set doing similar work for them. They asked me what it would take for me to move and I told them more than my current range. They admitted that they wouldn&amp;#39;t offer me much more than what I&amp;#39;m currently making - it&amp;#39;s less than $30K more - and I&amp;#39;m really not that into the work that they described. They also asked if I was open to relocating; when I flat-out said &amp;quot;No,&amp;quot; they said, &amp;quot;Okay, remote is fine.&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;That does raise some questions in my head regarding if I&amp;#39;d be pressured to move if I was hired. I received an invitation for the next round of the interview process and it was full of courses and lists to prepare for the interview, and I just thought, this is a &lt;strong&gt;lot&lt;/strong&gt; of work for a job I&amp;#39;m really not that interested in and for a product that Google owns that I don&amp;#39;t think has legs. But I also know that Google is the &amp;quot;white whale&amp;quot; of FAANG and I&amp;#39;m wondering if I&amp;#39;m being absurd in not taking this opportunity. I&amp;#39;d like to hear from anyone who has worked both places and what your thoughts are on this scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p8xwy", "is_robot_indexable": true, "report_reasons": null, "author": "goldenquetzal", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p8xwy/google_vs_salesforce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p8xwy/google_vs_salesforce/", "subreddit_subscribers": 907104, "created_utc": 1684802720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have a dumb question, can someone help me understand how I should approach it?\n\nMy team is running an A/B test, that was set to run for about 4 weeks. It\u2019s a standard ads experiment changing the UI of our ads on our homepage \n\nWe calculated the sample size based of:\n\n- primary metric CTR\n- MDE of 1%\n- sig level of 0.05\n- 80% power \n\nWe found that we need ~1M users, and this would be ~10% of our daily active users.\n\nThere has been a shift in the experiment plans and now we only have 2 weeks to run the test.\n\nI'm being asked to re-create the test plan - manager talked about for example what % of our daily active users do we need if we have 14 days to run vs 21 days to run the test (as opposed to the original 28 days)\n\nI feel dumb because, we calculated that we need 10% of daily users, and 14-day run time wouldn't change the sample size required (\\~1M), so why would the % of users change? I feel like I'm not understanding something fundamental here. Thank you", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic A/B test question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pf1fh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684822007.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684819519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a dumb question, can someone help me understand how I should approach it?&lt;/p&gt;\n\n&lt;p&gt;My team is running an A/B test, that was set to run for about 4 weeks. It\u2019s a standard ads experiment changing the UI of our ads on our homepage &lt;/p&gt;\n\n&lt;p&gt;We calculated the sample size based of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;primary metric CTR&lt;/li&gt;\n&lt;li&gt;MDE of 1%&lt;/li&gt;\n&lt;li&gt;sig level of 0.05&lt;/li&gt;\n&lt;li&gt;80% power &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We found that we need ~1M users, and this would be ~10% of our daily active users.&lt;/p&gt;\n\n&lt;p&gt;There has been a shift in the experiment plans and now we only have 2 weeks to run the test.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m being asked to re-create the test plan - manager talked about for example what % of our daily active users do we need if we have 14 days to run vs 21 days to run the test (as opposed to the original 28 days)&lt;/p&gt;\n\n&lt;p&gt;I feel dumb because, we calculated that we need 10% of daily users, and 14-day run time wouldn&amp;#39;t change the sample size required (~1M), so why would the % of users change? I feel like I&amp;#39;m not understanding something fundamental here. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pf1fh", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pf1fh/basic_ab_test_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pf1fh/basic_ab_test_question/", "subreddit_subscribers": 907104, "created_utc": 1684819519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am wondering if anyone here uses DS for his/her own business. If yes, in what context?", "author_fullname": "t2_27k9kc92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use Data Science as self employed ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oz1i2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684780343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering if anyone here uses DS for his/her own business. If yes, in what context?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13oz1i2", "is_robot_indexable": true, "report_reasons": null, "author": "Avedis77", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13oz1i2/do_you_use_data_science_as_self_employed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13oz1i2/do_you_use_data_science_as_self_employed/", "subreddit_subscribers": 907104, "created_utc": 1684780343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, \nI am really exhausted with this job search, I had a call from a company for interviewing for an entry-level data scientist position and it was truly entry-level. I was sent a invite for a teams meet and the interviewer never showed up, I followed back and asked whether there was a problem they simply replied that they are no longer looking for candidates for the position as the position has been filled. They could have emailed me before I entered that teams meeting.\n\nThe other thing that happened was I gave the first round at a different company and the interviewer was really impressed by my answers and scheduled another interview, even this time the interviewer didn\u2019t show up and after following up they said they have filled up the position.\n\nI just don\u2019t get it why are hiring managers ghosting people on interview calls? \n\nWith that being said I am really desperate to find a job and willing to relocate nationally anywhere in the US. Please help a brother out.\n\nThank you.", "author_fullname": "t2_9stxp5vi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oxw02", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684777890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, \nI am really exhausted with this job search, I had a call from a company for interviewing for an entry-level data scientist position and it was truly entry-level. I was sent a invite for a teams meet and the interviewer never showed up, I followed back and asked whether there was a problem they simply replied that they are no longer looking for candidates for the position as the position has been filled. They could have emailed me before I entered that teams meeting.&lt;/p&gt;\n\n&lt;p&gt;The other thing that happened was I gave the first round at a different company and the interviewer was really impressed by my answers and scheduled another interview, even this time the interviewer didn\u2019t show up and after following up they said they have filled up the position.&lt;/p&gt;\n\n&lt;p&gt;I just don\u2019t get it why are hiring managers ghosting people on interview calls? &lt;/p&gt;\n\n&lt;p&gt;With that being said I am really desperate to find a job and willing to relocate nationally anywhere in the US. Please help a brother out.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13oxw02", "is_robot_indexable": true, "report_reasons": null, "author": "Sid_datahunter", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13oxw02/looking_for_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13oxw02/looking_for_a_job/", "subreddit_subscribers": 907104, "created_utc": 1684777890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_icilc2wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LangChain Tutorial: A Step-by-Step LangChain Python Crash Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13oxp3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QRj7d7zNzXZcsMrxWjd-xlpgbbVzxkQ5wbkB_0f4DXs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684777461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/9d74c4ab1995", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?auto=webp&amp;v=enabled&amp;s=e5ef6de716d4b1ae91348fe046d69c185120bb14", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b44c33004fb55296ca8461223395907483b14dd", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eff20d8b874fa166c86b2aea80b9b503c644e16c", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba7c6d2d9cc981b6ae2a29f6c0767a9568c168f7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a4c96282b4fd4cacda1c16e368553940f4530bd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4912f1b0300021fbe2f25244d461fb155a0ff96", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/XYMIJ68-pw3g03wC832Uc2YcworIELRZLnmJU6KqtiM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeb4eb7b1e933dd574a98467ae399e6c636e0643", "width": 1080, "height": 607}], "variants": {}, "id": "c-kQo2VBYYha1BwQlEJUseiiyQf7oyobsogzVYNzzMI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13oxp3i", "is_robot_indexable": true, "report_reasons": null, "author": "gaodalie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13oxp3i/langchain_tutorial_a_stepbystep_langchain_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/9d74c4ab1995", "subreddit_subscribers": 907104, "created_utc": 1684777461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97o87945r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage dependencies and handle versioning in Python projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13pnjwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684846085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pnjwg", "is_robot_indexable": true, "report_reasons": null, "author": "asquare-buzz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pnjwg/how_do_you_manage_dependencies_and_handle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pnjwg/how_do_you_manage_dependencies_and_handle/", "subreddit_subscribers": 907104, "created_utc": 1684846085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would like a web app visualisation similar to newsmap.js-herokuapp treemap but with added functionality of filtering a key word like #russia or #germany and only include news of yesterday (meaning last 24 hours from midnight). I would like when clicking on a news headlines to have it text to speech read by Whisper AI or Google Text to Speech API. Or maybe there's a free service. Willing to ppal you to help me create this! Can negotiate anything until we find a good solution. \n\nWhat I have done so far is just purchase a domain. Since I'm a sound designer and not a web developer and need help with backend and frontend - all I was able to do since I got the idea is do research on what tools exist and possible ways to go about this little funky idea I had. \n\nHere are two options of proceeding that might or might not be viable for the Web app.\n\n(1. Option)\n\n1a. Google news seems to have a way to filter out news according to a keyword and a duration as in Give me news from \"Iran\" from last \"24 hours\". This seems to be a very viable option for the concept. Then we went to site elements and found all the 'hrefs' to get data for the text of Headings.\n\n1b. There's this thing called the puppeteer browser. Have you worked with it? From what we understand it's basically a node based library which provides a API to control headless Chrome or Chromium over the DevTools system.but also full Chrome or Chromium.\n\nPuppeteer:\nhttps://www.lambdatest.com/puppeteer\n\n1c. There exists a tool called BeautifulSoup which is a library for parsing HTML etdatas. I saw it being used for some project involving  the parsing of podcast RSS feeds.\n\nBeautifulSoup:\nhttps://www.crummy.com/software/BeautifulSoup/bs4/doc/\n\n1d. No new findings regarding Text to Speech concept. BUT there are a ton of possibilities, all seem to unfortunately cost something but be free for a certain amount of minutes or data being handled. \n\nElevenlabs: https://beta.elevenlabs.io/blog/rvg/\n\n(SECOND option,more suitable if don't want to rely on JS)\n\n2a. This is an option that does not involve one to web-scape Google because, as you can see JavaScript in there.\nIt isn't that useful to do it, because one needs to get the URL and that go and load the information on that page. \n\n2b. Instead choose to get posts from RSS feeds and from Twitter and post them to a Mastodon server. This would be useful to have, thia local Mastodon server, for two reasons.\n1. Use it as a staging server. We can post the data on the server and process it later.\n2. Use it for curating the data.\nThe curating of the data is something I would do with #hashtags. It would allow a Human to re-classify a post. This is popularly known as crowd-sourcing. I think it is called semi-supervised learning. \n\nI haven't made any progress on this, but maybe it is a good way to go about this. Maybe you how to do it within the code.\n\n2c. The staging server works well in the examples. I've seen people implemented it in Kotlin. It's on the web here\nhttps://sourceforge.net/p/mastodon4kt/code/ci/master/tree/\n\n2d. The application I've seen being written is in app-kt. The \"lib\" project is the Mastodon client library. It allows us to interrogate the local Mastodon server and get the details from it. \n\n2e. The HTML parsing library is in app-kt. It's called JSoup https://jsoup.org/\n\n2f. One could just scan the post as it appears on a local Mastodon, take the body text; access any URLs in it, and capture that body text as well.\n\n2g. Both the source text and the indirect text are then put into a translator. https://libretranslate.com/\n\n2h. One could have a local server running within my network. Could have set it up so that it only supports Arabic and Russian let's say.\n\n2i. We could move on to Natural Language Processing. There's a concept called Topic Modelling. I'm following this guy:\nhttps://medium.com/analytics-vidhya/distributed-topic-modelling-using-spark-nlp-and-spark-mllib-lda-6db3f06a4da3\nHis test data is ABC news headlines. There are some buzzwords a set of documents is called a Corpus.\nThe idea of the Latent Dirichlet Allocation algorithm is that each document in the Corpus will have a Topic score. The Topics are formed from the Corpus as that set of keywords that Maximises the Expectation so that most documents have a reasonable score. It's a form of cluster analysis.\n\n2j. After some training, the system produces a predictor, which can work in \"on-line\" mode. That means a new document can be \"transformed\" into its Topic score. Typically I would like to have about 10 topics. The Topics are machine-generated and are nothing more than a bundle of high-scoring words. \nIt is possible to seed Topics. Basically, if you *know* (\"a-priori\") that a document is \"Government propaganda relating to the Revolution\", you can distil its keywords and add those to other documents that you also believe to \"Government propaganda relating to the Revolution\".\nThere are various tricks I am reading about that one can use with the \"a-priori\" documents like use Word2Vec to generate lists of associated words and add those to the Topic. This isn't anything special. It's just Hashtagging the toots, but using Word2Vec to get many more hashtags. \n\n2k. As the musician in this project receiving the data, a new post should sent up to the Mastodon server, and my app-kt application captures the body text and translates it text to speech or a sound. \n\n2l. It should then be passed through the predictor which gives it its Topic scores and, I, the Musician, would then receive the Topic scores. I can add some timing data: from the time of the last post, one can derive the rate. It would also be interesting  to distinguish the rates by Topic.\n\n2m. I haven't done much thinking to work with the Timing, maybe we can think of options together.\n\nPlease let me know if you would like to join into this research! We could apply to an online hackathon :-)", "author_fullname": "t2_24xisatw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Russia news visualisation on steroids", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "name": "t3_13pni6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IhId1KkNpozr2TQ9DZ-HcEgO34eHEXa3iNFcq2m7DPE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684845961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like a web app visualisation similar to newsmap.js-herokuapp treemap but with added functionality of filtering a key word like #russia or #germany and only include news of yesterday (meaning last 24 hours from midnight). I would like when clicking on a news headlines to have it text to speech read by Whisper AI or Google Text to Speech API. Or maybe there&amp;#39;s a free service. Willing to ppal you to help me create this! Can negotiate anything until we find a good solution. &lt;/p&gt;\n\n&lt;p&gt;What I have done so far is just purchase a domain. Since I&amp;#39;m a sound designer and not a web developer and need help with backend and frontend - all I was able to do since I got the idea is do research on what tools exist and possible ways to go about this little funky idea I had. &lt;/p&gt;\n\n&lt;p&gt;Here are two options of proceeding that might or might not be viable for the Web app.&lt;/p&gt;\n\n&lt;p&gt;(1. Option)&lt;/p&gt;\n\n&lt;p&gt;1a. Google news seems to have a way to filter out news according to a keyword and a duration as in Give me news from &amp;quot;Iran&amp;quot; from last &amp;quot;24 hours&amp;quot;. This seems to be a very viable option for the concept. Then we went to site elements and found all the &amp;#39;hrefs&amp;#39; to get data for the text of Headings.&lt;/p&gt;\n\n&lt;p&gt;1b. There&amp;#39;s this thing called the puppeteer browser. Have you worked with it? From what we understand it&amp;#39;s basically a node based library which provides a API to control headless Chrome or Chromium over the DevTools system.but also full Chrome or Chromium.&lt;/p&gt;\n\n&lt;p&gt;Puppeteer:\n&lt;a href=\"https://www.lambdatest.com/puppeteer\"&gt;https://www.lambdatest.com/puppeteer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;1c. There exists a tool called BeautifulSoup which is a library for parsing HTML etdatas. I saw it being used for some project involving  the parsing of podcast RSS feeds.&lt;/p&gt;\n\n&lt;p&gt;BeautifulSoup:\n&lt;a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"&gt;https://www.crummy.com/software/BeautifulSoup/bs4/doc/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;1d. No new findings regarding Text to Speech concept. BUT there are a ton of possibilities, all seem to unfortunately cost something but be free for a certain amount of minutes or data being handled. &lt;/p&gt;\n\n&lt;p&gt;Elevenlabs: &lt;a href=\"https://beta.elevenlabs.io/blog/rvg/\"&gt;https://beta.elevenlabs.io/blog/rvg/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(SECOND option,more suitable if don&amp;#39;t want to rely on JS)&lt;/p&gt;\n\n&lt;p&gt;2a. This is an option that does not involve one to web-scape Google because, as you can see JavaScript in there.\nIt isn&amp;#39;t that useful to do it, because one needs to get the URL and that go and load the information on that page. &lt;/p&gt;\n\n&lt;p&gt;2b. Instead choose to get posts from RSS feeds and from Twitter and post them to a Mastodon server. This would be useful to have, thia local Mastodon server, for two reasons.\n1. Use it as a staging server. We can post the data on the server and process it later.\n2. Use it for curating the data.\nThe curating of the data is something I would do with #hashtags. It would allow a Human to re-classify a post. This is popularly known as crowd-sourcing. I think it is called semi-supervised learning. &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t made any progress on this, but maybe it is a good way to go about this. Maybe you how to do it within the code.&lt;/p&gt;\n\n&lt;p&gt;2c. The staging server works well in the examples. I&amp;#39;ve seen people implemented it in Kotlin. It&amp;#39;s on the web here\n&lt;a href=\"https://sourceforge.net/p/mastodon4kt/code/ci/master/tree/\"&gt;https://sourceforge.net/p/mastodon4kt/code/ci/master/tree/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2d. The application I&amp;#39;ve seen being written is in app-kt. The &amp;quot;lib&amp;quot; project is the Mastodon client library. It allows us to interrogate the local Mastodon server and get the details from it. &lt;/p&gt;\n\n&lt;p&gt;2e. The HTML parsing library is in app-kt. It&amp;#39;s called JSoup &lt;a href=\"https://jsoup.org/\"&gt;https://jsoup.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2f. One could just scan the post as it appears on a local Mastodon, take the body text; access any URLs in it, and capture that body text as well.&lt;/p&gt;\n\n&lt;p&gt;2g. Both the source text and the indirect text are then put into a translator. &lt;a href=\"https://libretranslate.com/\"&gt;https://libretranslate.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2h. One could have a local server running within my network. Could have set it up so that it only supports Arabic and Russian let&amp;#39;s say.&lt;/p&gt;\n\n&lt;p&gt;2i. We could move on to Natural Language Processing. There&amp;#39;s a concept called Topic Modelling. I&amp;#39;m following this guy:\n&lt;a href=\"https://medium.com/analytics-vidhya/distributed-topic-modelling-using-spark-nlp-and-spark-mllib-lda-6db3f06a4da3\"&gt;https://medium.com/analytics-vidhya/distributed-topic-modelling-using-spark-nlp-and-spark-mllib-lda-6db3f06a4da3&lt;/a&gt;\nHis test data is ABC news headlines. There are some buzzwords a set of documents is called a Corpus.\nThe idea of the Latent Dirichlet Allocation algorithm is that each document in the Corpus will have a Topic score. The Topics are formed from the Corpus as that set of keywords that Maximises the Expectation so that most documents have a reasonable score. It&amp;#39;s a form of cluster analysis.&lt;/p&gt;\n\n&lt;p&gt;2j. After some training, the system produces a predictor, which can work in &amp;quot;on-line&amp;quot; mode. That means a new document can be &amp;quot;transformed&amp;quot; into its Topic score. Typically I would like to have about 10 topics. The Topics are machine-generated and are nothing more than a bundle of high-scoring words. \nIt is possible to seed Topics. Basically, if you &lt;em&gt;know&lt;/em&gt; (&amp;quot;a-priori&amp;quot;) that a document is &amp;quot;Government propaganda relating to the Revolution&amp;quot;, you can distil its keywords and add those to other documents that you also believe to &amp;quot;Government propaganda relating to the Revolution&amp;quot;.\nThere are various tricks I am reading about that one can use with the &amp;quot;a-priori&amp;quot; documents like use Word2Vec to generate lists of associated words and add those to the Topic. This isn&amp;#39;t anything special. It&amp;#39;s just Hashtagging the toots, but using Word2Vec to get many more hashtags. &lt;/p&gt;\n\n&lt;p&gt;2k. As the musician in this project receiving the data, a new post should sent up to the Mastodon server, and my app-kt application captures the body text and translates it text to speech or a sound. &lt;/p&gt;\n\n&lt;p&gt;2l. It should then be passed through the predictor which gives it its Topic scores and, I, the Musician, would then receive the Topic scores. I can add some timing data: from the time of the last post, one can derive the rate. It would also be interesting  to distinguish the rates by Topic.&lt;/p&gt;\n\n&lt;p&gt;2m. I haven&amp;#39;t done much thinking to work with the Timing, maybe we can think of options together.&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you would like to join into this research! We could apply to an online hackathon :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/diyz61g2cm1b1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/diyz61g2cm1b1.png?auto=webp&amp;v=enabled&amp;s=b1a5579ae19e4a855ead0821ad28959b418ec8fd", "width": 1080, "height": 719}, "resolutions": [{"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f15caa43db6c7ef316cdbb027a8cf7511c0c5e11", "width": 108, "height": 71}, {"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45e6dc2a60508f6387b5b2e42ba571b0c7384c9f", "width": 216, "height": 143}, {"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=297599ab528a273c8d529dd23378f755a80c372b", "width": 320, "height": 213}, {"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71156331e609d8f0a613c44ef9e3fbf3d1555599", "width": 640, "height": 426}, {"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a2944c15693f8afa09460a9f4f99e9cedd9a293", "width": 960, "height": 639}, {"url": "https://preview.redd.it/diyz61g2cm1b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4c27ea59ba0d628a2364000d88013663f5f99dc", "width": 1080, "height": 719}], "variants": {}, "id": "YDX5xmfTVEVH3Ml5Xggy8yoQZWI3KPWj7OrAiiLhPhQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pni6t", "is_robot_indexable": true, "report_reasons": null, "author": "mllnmchld", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pni6t/russia_news_visualisation_on_steroids/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/diyz61g2cm1b1.png", "subreddit_subscribers": 907104, "created_utc": 1684845961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'd like to integrate in industry as a data scientist and people keep telling me I should contribute to open-source projects on github. My question \"roughly speaking\" is -- how to do it effectively? That is, how to find a \"good\" repository from which I can\n\n1. benefit while searching for a job\n2. (heaven forbid) Learn something and improve my git &amp; Data skills", "author_fullname": "t2_t6tuznl6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find \"good\" open-source repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pje4c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684833974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to integrate in industry as a data scientist and people keep telling me I should contribute to open-source projects on github. My question &amp;quot;roughly speaking&amp;quot; is -- how to do it effectively? That is, how to find a &amp;quot;good&amp;quot; repository from which I can&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;benefit while searching for a job&lt;/li&gt;\n&lt;li&gt;(heaven forbid) Learn something and improve my git &amp;amp; Data skills&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pje4c", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Sea-658", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pje4c/how_to_find_good_opensource_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pje4c/how_to_find_good_opensource_repositories/", "subreddit_subscribers": 907104, "created_utc": 1684833974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I wanted to know what would be the future of agent based models. Will it be used in future as compared to generative data. How does it compare to other systems. I'm just a beginner and wanted to know if there are any open source platform where I can get to know more information about this.", "author_fullname": "t2_8vv5blv7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the future of agent based models ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p8y9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684802745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I wanted to know what would be the future of agent based models. Will it be used in future as compared to generative data. How does it compare to other systems. I&amp;#39;m just a beginner and wanted to know if there are any open source platform where I can get to know more information about this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p8y9x", "is_robot_indexable": true, "report_reasons": null, "author": "buggedgpt14", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p8y9x/what_is_the_future_of_agent_based_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p8y9x/what_is_the_future_of_agent_based_models/", "subreddit_subscribers": 907104, "created_utc": 1684802745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm 30, an immigrant citizen, 8 YOE with 100k CAD working at a bank in Toronto doing customer insights, business insights... Want to move to the US for better salary. I'm aware of the visa options\n\nSpecifically looking for examples to understand challenges faced, timelines, your goals for the job, how you executed etc?", "author_fullname": "t2_er4x03wj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you make your move to the US as a Canadian?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p6c3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684797584.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684796252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 30, an immigrant citizen, 8 YOE with 100k CAD working at a bank in Toronto doing customer insights, business insights... Want to move to the US for better salary. I&amp;#39;m aware of the visa options&lt;/p&gt;\n\n&lt;p&gt;Specifically looking for examples to understand challenges faced, timelines, your goals for the job, how you executed etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p6c3b", "is_robot_indexable": true, "report_reasons": null, "author": "No-Wallaby5033", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p6c3b/how_did_you_make_your_move_to_the_us_as_a_canadian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p6c3b/how_did_you_make_your_move_to_the_us_as_a_canadian/", "subreddit_subscribers": 907104, "created_utc": 1684796252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on analyzing this survey, which btw, nobody took my input while designing it. \nIt asks our customers to rate things like price, reliability of service and distance to physical locations .. on a scale of not important to extremely important, each.\nI mean which customer is going to say price is not important and reliability is not important. This question is so poorly designed. I feel embarrassed showing the results of this to the management team. \ud83d\ude1e\ud83d\ude1e", "author_fullname": "t2_fb3rtf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer Survey questions done so painfully wrong", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p44m5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684791227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on analyzing this survey, which btw, nobody took my input while designing it. \nIt asks our customers to rate things like price, reliability of service and distance to physical locations .. on a scale of not important to extremely important, each.\nI mean which customer is going to say price is not important and reliability is not important. This question is so poorly designed. I feel embarrassed showing the results of this to the management team. \ud83d\ude1e\ud83d\ude1e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p44m5", "is_robot_indexable": true, "report_reasons": null, "author": "cj-tww", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p44m5/customer_survey_questions_done_so_painfully_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p44m5/customer_survey_questions_done_so_painfully_wrong/", "subreddit_subscribers": 907104, "created_utc": 1684791227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a startup as a data scientist and we\u2019ve been having a lot of internal debate over how our production and dev databases can work for data science.\n\nWe have terabytes of data and nearly all of it contains PIH. It\u2019s not financially reasonable (and sometimes not contractually allowed) to duplicate this data for dev. So when our data science team develops models, we are pretty much forced to work in the production environment. Obviously this is bad but we don\u2019t really know a good solution. The nature of the data makes it so we can\u2019t make synthetic versions to fill dev and our models rely on real data for training and testing anyway. \n\nSo, I\u2019m curious if anyone on this sub has run into a solution for this kind of problem.?\n\nPut simply, when you have large amounts of data that can\u2019t be synthesized or reasonably duplicated, how do you partition the production and development environments effectively?", "author_fullname": "t2_3uf8nami", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle dev databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p3dow", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684789861.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684789657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a startup as a data scientist and we\u2019ve been having a lot of internal debate over how our production and dev databases can work for data science.&lt;/p&gt;\n\n&lt;p&gt;We have terabytes of data and nearly all of it contains PIH. It\u2019s not financially reasonable (and sometimes not contractually allowed) to duplicate this data for dev. So when our data science team develops models, we are pretty much forced to work in the production environment. Obviously this is bad but we don\u2019t really know a good solution. The nature of the data makes it so we can\u2019t make synthetic versions to fill dev and our models rely on real data for training and testing anyway. &lt;/p&gt;\n\n&lt;p&gt;So, I\u2019m curious if anyone on this sub has run into a solution for this kind of problem.?&lt;/p&gt;\n\n&lt;p&gt;Put simply, when you have large amounts of data that can\u2019t be synthesized or reasonably duplicated, how do you partition the production and development environments effectively?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p3dow", "is_robot_indexable": true, "report_reasons": null, "author": "GradientCollapse", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p3dow/how_do_you_handle_dev_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p3dow/how_do_you_handle_dev_databases/", "subreddit_subscribers": 907104, "created_utc": 1684789657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve read through a lot of posts and such regarding this but I experience a lot of imposter syndrome and would appreciate some genuine insight into my personal career prospects.\n\nI got into the data world about 1.5 years ago. I was hired at a company for customer service but ended up designing custom SQL queries for all of our reporting, building custom python and excel vba automations to format to client specifications and organize data. I\u2019ve been combining legacy data and using programming to update old reports.\n\nBecause I\u2019m the only person at my company who does this I don\u2019t get a lot of insight from professionals on the quality of my work, best practices and usually am a complete self starter on projects and software I develop for the team. I was set to receive a promotion for my contributions but that has recently been rescinded with no reasonable expectation it will return in the future.\n\nI\u2019ve been studying but I personally feel my technical skills are on the low side. The SQL I use doesn\u2019t have update as an option and I\u2019m missing more advanced features. I usually have to come up with complex workarounds to get what I want. As well I still find myself using places like stack overflow a lot. \n\nI\u2019m currently weighing my options as I don\u2019t make a lot of money and genuinely need a bit more to survive.\n\nJust some general advice and insight would mean the world to me as I don\u2019t have any professional friends or colleagues to discuss this with.", "author_fullname": "t2_4cyboy95", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ox794", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684776357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve read through a lot of posts and such regarding this but I experience a lot of imposter syndrome and would appreciate some genuine insight into my personal career prospects.&lt;/p&gt;\n\n&lt;p&gt;I got into the data world about 1.5 years ago. I was hired at a company for customer service but ended up designing custom SQL queries for all of our reporting, building custom python and excel vba automations to format to client specifications and organize data. I\u2019ve been combining legacy data and using programming to update old reports.&lt;/p&gt;\n\n&lt;p&gt;Because I\u2019m the only person at my company who does this I don\u2019t get a lot of insight from professionals on the quality of my work, best practices and usually am a complete self starter on projects and software I develop for the team. I was set to receive a promotion for my contributions but that has recently been rescinded with no reasonable expectation it will return in the future.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been studying but I personally feel my technical skills are on the low side. The SQL I use doesn\u2019t have update as an option and I\u2019m missing more advanced features. I usually have to come up with complex workarounds to get what I want. As well I still find myself using places like stack overflow a lot. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently weighing my options as I don\u2019t make a lot of money and genuinely need a bit more to survive.&lt;/p&gt;\n\n&lt;p&gt;Just some general advice and insight would mean the world to me as I don\u2019t have any professional friends or colleagues to discuss this with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ox794", "is_robot_indexable": true, "report_reasons": null, "author": "Dstrung", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ox794/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ox794/career_advice/", "subreddit_subscribers": 907104, "created_utc": 1684776357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_n4dj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easier Data Debugging With Zed\u2019s First-class Errors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ox3kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684776118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "brimdata.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.brimdata.io/blog/debugging-data-first-class-errors/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ox3kh", "is_robot_indexable": true, "report_reasons": null, "author": "jkerr838", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ox3kh/easier_data_debugging_with_zeds_firstclass_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.brimdata.io/blog/debugging-data-first-class-errors/", "subreddit_subscribers": 907104, "created_utc": 1684776118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHello all,\n\nI want to cluster\u00a0Electricity energy consumption time series data with K-Means and Dynamic Time Warping.  i am new in this area so i can't solve the problem. Can you please help me in solving this problem using python programming?  Here i have attached the time series data on which i want to apply clustering. \n\nThank you for your help.", "author_fullname": "t2_bvvjy7bje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "consumption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13pm5j1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684842355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I want to cluster\u00a0Electricity energy consumption time series data with K-Means and Dynamic Time Warping.  i am new in this area so i can&amp;#39;t solve the problem. Can you please help me in solving this problem using python programming?  Here i have attached the time series data on which i want to apply clustering. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pm5j1", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Purple_4375", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pm5j1/consumption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pm5j1/consumption/", "subreddit_subscribers": 907104, "created_utc": 1684842355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_aklbmwfgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "7 Best Data Science Project Ideas To Get Hired by Top MNCs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pf9ft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684820226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.learnbay.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://blog.learnbay.co/the-7-best-data-science-project-ideas-to-get-hired-by-top-mncs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pf9ft", "is_robot_indexable": true, "report_reasons": null, "author": "Learnbay_blogs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pf9ft/7_best_data_science_project_ideas_to_get_hired_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.learnbay.co/the-7-best-data-science-project-ideas-to-get-hired-by-top-mncs", "subreddit_subscribers": 907104, "created_utc": 1684820226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am a UX design student, and am working on a project which includes redesigning a data science platform. I had some questions about the same, which would really give me a direction for this project. Data practitioners, data enthusiasts, data analysts- please do give insights on the following:\n\n1. When using data science platforms like Data Iku, Rapid Miner, Data Robot etc., as new/ experienced users, what are your expectations from the UI/UX of the platform?\n2. How should the visual design be? Any examples of good design you have come across?\n3. Main struggles while using/ navigating such platforms? (eg. inconsistency, lack of onboarding) \n4. For mainly what purpose did you use the platform? Data visualization, data prediction, analysis etc.?\n5. What are the main factors I should keep in mind while designing the dashboards? eg. Glanceability, addition of visuals etc.\n\nThank you in advance!", "author_fullname": "t2_bvn3788o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A brief research on the User Experience of data science platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pe11g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684816469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a UX design student, and am working on a project which includes redesigning a data science platform. I had some questions about the same, which would really give me a direction for this project. Data practitioners, data enthusiasts, data analysts- please do give insights on the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;When using data science platforms like Data Iku, Rapid Miner, Data Robot etc., as new/ experienced users, what are your expectations from the UI/UX of the platform?&lt;/li&gt;\n&lt;li&gt;How should the visual design be? Any examples of good design you have come across?&lt;/li&gt;\n&lt;li&gt;Main struggles while using/ navigating such platforms? (eg. inconsistency, lack of onboarding) &lt;/li&gt;\n&lt;li&gt;For mainly what purpose did you use the platform? Data visualization, data prediction, analysis etc.?&lt;/li&gt;\n&lt;li&gt;What are the main factors I should keep in mind while designing the dashboards? eg. Glanceability, addition of visuals etc.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13pe11g", "is_robot_indexable": true, "report_reasons": null, "author": "Cute-Pomegranate-706", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13pe11g/a_brief_research_on_the_user_experience_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13pe11g/a_brief_research_on_the_user_experience_of_data/", "subreddit_subscribers": 907104, "created_utc": 1684816469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If i'm running text analytics (specifically sentiment analysis in R) on a hashtag from twitter for a computational linguistics class.  **How many tweets do I need to download for statistical significance?**  One book said 1800, one said 3000, and one said 15000.  What do y'all think?  I'm also going to need to defend why I chose that amount so is there some mathematical way of determining what's significant?  What do y'all think?", "author_fullname": "t2_9mqzw2ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Statistically Significant Sample Size in Text Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p9lqb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684804292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If i&amp;#39;m running text analytics (specifically sentiment analysis in R) on a hashtag from twitter for a computational linguistics class.  &lt;strong&gt;How many tweets do I need to download for statistical significance?&lt;/strong&gt;  One book said 1800, one said 3000, and one said 15000.  What do y&amp;#39;all think?  I&amp;#39;m also going to need to defend why I chose that amount so is there some mathematical way of determining what&amp;#39;s significant?  What do y&amp;#39;all think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13p9lqb", "is_robot_indexable": true, "report_reasons": null, "author": "KandaceKooch", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13p9lqb/statistically_significant_sample_size_in_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13p9lqb/statistically_significant_sample_size_in_text/", "subreddit_subscribers": 907104, "created_utc": 1684804292.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}