{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im new to Airflow, been studying for over a month now.\nI know this is probably a very simple question but im kinda confused.\n\nI have read that XCom is only made for sharing some metadata or flags between tasks and shouldnt be used for passing real data like for example a pandas dataframe.\n\nNow what would be the best way to run a simple python ETL pipeline with pandas.\n\nShould I let the tasks read/write from/to external csv files for example? Is this an efficient way? \n\nAnother question where is the best place to put my python script? Because I also read that the DAG python file should only be used for the DAG configuration and not for real code, However, all the tutorials I found just define their python functions within the DAG file. Is this acceptable? Whats the best practice?\n\nThanks \ud83d\ude0a", "author_fullname": "t2_8bw9894u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow with Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139ma7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683377949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im new to Airflow, been studying for over a month now.\nI know this is probably a very simple question but im kinda confused.&lt;/p&gt;\n\n&lt;p&gt;I have read that XCom is only made for sharing some metadata or flags between tasks and shouldnt be used for passing real data like for example a pandas dataframe.&lt;/p&gt;\n\n&lt;p&gt;Now what would be the best way to run a simple python ETL pipeline with pandas.&lt;/p&gt;\n\n&lt;p&gt;Should I let the tasks read/write from/to external csv files for example? Is this an efficient way? &lt;/p&gt;\n\n&lt;p&gt;Another question where is the best place to put my python script? Because I also read that the DAG python file should only be used for the DAG configuration and not for real code, However, all the tutorials I found just define their python functions within the DAG file. Is this acceptable? Whats the best practice?&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "139ma7j", "is_robot_indexable": true, "report_reasons": null, "author": "GameFitAverage", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139ma7j/airflow_with_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139ma7j/airflow_with_pandas/", "subreddit_subscribers": 104347, "created_utc": 1683377949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says... I can't think of a reason why CDC would ever not be the \"gold standard\" for any ELT data integration processes? I can understand that in some scenarios, CDC may not be possible, how would you have a proper EL process without CDC?\n\nThe only other patterns I can think of would be:\n\n1. You can schedule a full source database scan during off-hours and simply replace all of the tables in the destination, but this would be far too inefficient. Even worse, for global companies, there aren't really any \"off-hours\" that a job like this could run during. Even more, you would lose any ability to analyze the history of something with a changing state, for example: open orders on July 1st in 2019, or customers who had an address change. I don't see how you would handle SCDs with this full \"flush as replace\" pattern. Lastly, you can forget about low-latency analytics, I think that is obviously a true statement.\n2. Something better would be to ingest records that have a \"modified\\_at\" column where I could create an extractor to just extract records that have been modified since the last extraction, and then upsert those changes into my destination tables. I think it would be very wishful to think that every table has a column like this to begin with. I could also handle SCD's to flag an updates to a record as \"current\". Also, what if there are multiple state changes between extraction jobs? This pattern would only pick up the most recent state of a record, which could be bad. Finally, I suppose you can have more frequent \"micro-batches\" that issues a SELECT query to all tables every 5 minutes to get the newly modified records, but this seems quite inefficient.\n3. The only other option (I can think of) would be CDC. Every data mutation to a source table is considered an event that would create a message in a queue. Subscribers would get notified to persist the mutation into the target location. Every mutation is captured in the order that it occurred, so analysts could then analyze any data at any state at a given point of time.", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would you ever not use CDC for ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1393kdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683325698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says... I can&amp;#39;t think of a reason why CDC would ever not be the &amp;quot;gold standard&amp;quot; for any ELT data integration processes? I can understand that in some scenarios, CDC may not be possible, how would you have a proper EL process without CDC?&lt;/p&gt;\n\n&lt;p&gt;The only other patterns I can think of would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;You can schedule a full source database scan during off-hours and simply replace all of the tables in the destination, but this would be far too inefficient. Even worse, for global companies, there aren&amp;#39;t really any &amp;quot;off-hours&amp;quot; that a job like this could run during. Even more, you would lose any ability to analyze the history of something with a changing state, for example: open orders on July 1st in 2019, or customers who had an address change. I don&amp;#39;t see how you would handle SCDs with this full &amp;quot;flush as replace&amp;quot; pattern. Lastly, you can forget about low-latency analytics, I think that is obviously a true statement.&lt;/li&gt;\n&lt;li&gt;Something better would be to ingest records that have a &amp;quot;modified_at&amp;quot; column where I could create an extractor to just extract records that have been modified since the last extraction, and then upsert those changes into my destination tables. I think it would be very wishful to think that every table has a column like this to begin with. I could also handle SCD&amp;#39;s to flag an updates to a record as &amp;quot;current&amp;quot;. Also, what if there are multiple state changes between extraction jobs? This pattern would only pick up the most recent state of a record, which could be bad. Finally, I suppose you can have more frequent &amp;quot;micro-batches&amp;quot; that issues a SELECT query to all tables every 5 minutes to get the newly modified records, but this seems quite inefficient.&lt;/li&gt;\n&lt;li&gt;The only other option (I can think of) would be CDC. Every data mutation to a source table is considered an event that would create a message in a queue. Subscribers would get notified to persist the mutation into the target location. Every mutation is captured in the order that it occurred, so analysts could then analyze any data at any state at a given point of time.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1393kdj", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1393kdj/why_would_you_ever_not_use_cdc_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1393kdj/why_would_you_ever_not_use_cdc_for_elt/", "subreddit_subscribers": 104347, "created_utc": 1683325698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Redditors, I have gathered the courage and have entered payment details to get a free GCP Account 300$ worth of free credits for the next 90 days. I plan on learning the following asap -\n\n1. Docker - can learn via Cloud Shell\n2. Kubernetes - can learn via Cloud Shell\n3. Apache Airflow - how do I learn this in free GCP? Will I have to spin up a new VM via Compute Engine?\n\nMoreover, is the plan sufficient enough to learn these?", "author_fullname": "t2_6hp3gp78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gathered courage and created a Trial GCP Account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139qju4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683382558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Redditors, I have gathered the courage and have entered payment details to get a free GCP Account 300$ worth of free credits for the next 90 days. I plan on learning the following asap -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Docker - can learn via Cloud Shell&lt;/li&gt;\n&lt;li&gt;Kubernetes - can learn via Cloud Shell&lt;/li&gt;\n&lt;li&gt;Apache Airflow - how do I learn this in free GCP? Will I have to spin up a new VM via Compute Engine?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Moreover, is the plan sufficient enough to learn these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139qju4", "is_robot_indexable": true, "report_reasons": null, "author": "rohetoric", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139qju4/gathered_courage_and_created_a_trial_gcp_account/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139qju4/gathered_courage_and_created_a_trial_gcp_account/", "subreddit_subscribers": 104347, "created_utc": 1683382558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Reddit DE - I'm a data analyst that changed jobs to join a dinosaur working with Redshift. I was previously working with Bigquery for SQL scripts, where just looking at table samples (e.g. SELECT \\* FROM table LIMIT 5) took microseconds. Under the AWS Redshift architecture, these same table sampling jobs now take 3+ minutes and I'm going crazy. \n\nThe admins have set up resources dedicated under a user cluster, so things could be worse, but is there anything small you suggest I push for to make life more bearable? I think I need to start by asking for more 2x, 3x more resource slots, but please stop me if this sounds stupid.", "author_fullname": "t2_b3kfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can I do about redshift slowness?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139wcpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683394119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Reddit DE - I&amp;#39;m a data analyst that changed jobs to join a dinosaur working with Redshift. I was previously working with Bigquery for SQL scripts, where just looking at table samples (e.g. SELECT * FROM table LIMIT 5) took microseconds. Under the AWS Redshift architecture, these same table sampling jobs now take 3+ minutes and I&amp;#39;m going crazy. &lt;/p&gt;\n\n&lt;p&gt;The admins have set up resources dedicated under a user cluster, so things could be worse, but is there anything small you suggest I push for to make life more bearable? I think I need to start by asking for more 2x, 3x more resource slots, but please stop me if this sounds stupid.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "139wcpq", "is_robot_indexable": true, "report_reasons": null, "author": "jestors", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139wcpq/what_can_i_do_about_redshift_slowness/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139wcpq/what_can_i_do_about_redshift_slowness/", "subreddit_subscribers": 104347, "created_utc": 1683394119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been doing data engineering for about 10 years but feel so behind. Most of my career involved building ETL pipelines with SQL, data governance, and modeling dimensional tables for BI reports. In the last couple years, I have been working in more cutting edge companies. I was hired as a data engineer but feel so lost in the new stack. Everything is written in python and deployed in containers. It makes me think what did I do for the last decade haha. Is this a common feeling in this role? How do I gain the python skills quickly? I just feel overwhelmed.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1395g7w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683330248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been doing data engineering for about 10 years but feel so behind. Most of my career involved building ETL pipelines with SQL, data governance, and modeling dimensional tables for BI reports. In the last couple years, I have been working in more cutting edge companies. I was hired as a data engineer but feel so lost in the new stack. Everything is written in python and deployed in containers. It makes me think what did I do for the last decade haha. Is this a common feeling in this role? How do I gain the python skills quickly? I just feel overwhelmed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1395g7w", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1395g7w/advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1395g7w/advice/", "subreddit_subscribers": 104347, "created_utc": 1683330248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions/ideas for a data engineering hackathon. Thanks in advance.", "author_fullname": "t2_62mycgca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering hackathon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139ypf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683399295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions/ideas for a data engineering hackathon. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139ypf5", "is_robot_indexable": true, "report_reasons": null, "author": "Wonderful_Original61", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139ypf5/data_engineering_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139ypf5/data_engineering_hackathon/", "subreddit_subscribers": 104347, "created_utc": 1683399295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What options are on the table for exporting data from azure sql server to azure storage blobs.\n\nI don\u2019t like data factory so looking for other options.\n\nCurrently using odbc with a python function but hoping someone has a better Rex", "author_fullname": "t2_2wr0i9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental export azure sql server to blob", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13999eo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683339973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What options are on the table for exporting data from azure sql server to azure storage blobs.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t like data factory so looking for other options.&lt;/p&gt;\n\n&lt;p&gt;Currently using odbc with a python function but hoping someone has a better Rex&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13999eo", "is_robot_indexable": true, "report_reasons": null, "author": "BlazeMcChillington", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13999eo/incremental_export_azure_sql_server_to_blob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13999eo/incremental_export_azure_sql_server_to_blob/", "subreddit_subscribers": 104347, "created_utc": 1683339973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're going through a transformation at our institution and there isn't a solid understanding of what Analytics is, let alone data engineering. Our unit has been moving forward with much more modern approach and have been recently been getting some attention due to the process we've made. There's a lot of talk now about what resides within the scope of the Analytics team (or Institutional Research in it's traditional title) and what is purely Information Technology. My understanding from the private sector is that the data team, and especially the DE team kinda straddles the two worlds, with let's say a dotted line reporting relationship into both. Is anyone working in a similar environment, or even a more mature state? I'd also love to hear any thoughts anyone has on this kind of natal state within an already large organization and navigating through it.  Based on my experience and conversations it seems the idea of data engineering itself is a fairly new concept in the higher ed sector, so it would also be great to connect if any of you are out there.", "author_fullname": "t2_9x6ven2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone in Higher Ed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139u1p0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683389113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re going through a transformation at our institution and there isn&amp;#39;t a solid understanding of what Analytics is, let alone data engineering. Our unit has been moving forward with much more modern approach and have been recently been getting some attention due to the process we&amp;#39;ve made. There&amp;#39;s a lot of talk now about what resides within the scope of the Analytics team (or Institutional Research in it&amp;#39;s traditional title) and what is purely Information Technology. My understanding from the private sector is that the data team, and especially the DE team kinda straddles the two worlds, with let&amp;#39;s say a dotted line reporting relationship into both. Is anyone working in a similar environment, or even a more mature state? I&amp;#39;d also love to hear any thoughts anyone has on this kind of natal state within an already large organization and navigating through it.  Based on my experience and conversations it seems the idea of data engineering itself is a fairly new concept in the higher ed sector, so it would also be great to connect if any of you are out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139u1p0", "is_robot_indexable": true, "report_reasons": null, "author": "seaefjaye", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139u1p0/anyone_in_higher_ed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139u1p0/anyone_in_higher_ed/", "subreddit_subscribers": 104347, "created_utc": 1683389113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Monthly post is shared, I extracted this article from my work experience and it is useful if you have certain pipeline design requirements that can fit in this self serve pipeline architecture. \n\nPlease provide feedback, thanks!\n\n&amp;#x200B;\n\nLearn how to build Self Serve Data Engineering Pipelines. Includes an example pipeline architecture with a config driven approach. \n\n[https://www.junaideffendi.com/blog/self-serve-data-engineering-pipelines/](https://www.junaideffendi.com/blog/self-serve-data-engineering-pipelines/)", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Serve Data Engineering Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139uy5m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683391055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Monthly post is shared, I extracted this article from my work experience and it is useful if you have certain pipeline design requirements that can fit in this self serve pipeline architecture. &lt;/p&gt;\n\n&lt;p&gt;Please provide feedback, thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Learn how to build Self Serve Data Engineering Pipelines. Includes an example pipeline architecture with a config driven approach. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.junaideffendi.com/blog/self-serve-data-engineering-pipelines/\"&gt;https://www.junaideffendi.com/blog/self-serve-data-engineering-pipelines/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?auto=webp&amp;v=enabled&amp;s=2976752258a5a674777b1ad370f019f994f75b25", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89cb78006c0d90447c42f8b1ff918bc4341e451e", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d8a460c646a86f53e3d88d85b1f111a1dad1731", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13e0fe6b26d2c25791f84a7ebe32c5c2b70015ce", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=689ddc7e5ab92f3df8cf6139e17a1110d8339737", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ae938805cb8e0a63a6328b16d20d8a95af93ba6", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/RSEMcrDnDEmB2iXkx91OKGqXHEC4neGr2SMzcZiEgEs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c910626aec58e9e043b6f485f8506bb4a81eafe6", "width": 1080, "height": 719}], "variants": {}, "id": "GNYRWbYbY0xLgLn14v1Zq6ddkD71870evE58ocsrDSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "139uy5m", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139uy5m/self_serve_data_engineering_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139uy5m/self_serve_data_engineering_pipelines/", "subreddit_subscribers": 104347, "created_utc": 1683391055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you land a DE role with 3 portfolio projects?", "author_fullname": "t2_kniyzkt1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Junior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139xhm8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683396622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you land a DE role with 3 portfolio projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139xhm8", "is_robot_indexable": true, "report_reasons": null, "author": "brittle_devs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139xhm8/junior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139xhm8/junior_data_engineer/", "subreddit_subscribers": 104347, "created_utc": 1683396622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A colleague wants to receive Industrial IoT data from multiple Pub/Sub and Kafka topics. He believes a data collection agent is the simplest/best approach, but I  have my doubts. \n\nI'd rather stick to traditional tools than gamble with a  collection agent. Am I being overly pragmatic?", "author_fullname": "t2_76d1dys0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a data collection agent a more effective approach for receiving messages from Pub/Sub (or Kafka) compared to Data Engineering Tools like Apache Airflow, Flink, or Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_139xceh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683396307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A colleague wants to receive Industrial IoT data from multiple Pub/Sub and Kafka topics. He believes a data collection agent is the simplest/best approach, but I  have my doubts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d rather stick to traditional tools than gamble with a  collection agent. Am I being overly pragmatic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139xceh", "is_robot_indexable": true, "report_reasons": null, "author": "Revolution_Little", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/139xceh/is_a_data_collection_agent_a_more_effective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/139xceh/is_a_data_collection_agent_a_more_effective/", "subreddit_subscribers": 104347, "created_utc": 1683396307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8kummc9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of command in sql part 2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_139zovc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AdVKR4hJCtId32vcbkX9Ize01fWvwb_gDzaBREByEiI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683401522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "guerillateck.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.guerillateck.com/2023/05/alter-command-distinct-function-types.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fcinZO34yCrxve0j3Z7qUtiK-nu1UZqlDp7Z0y8AwV0.jpg?auto=webp&amp;v=enabled&amp;s=fb6eb8e9d18c4c940b7a893ddbde587c2614497c", "width": 441, "height": 248}, "resolutions": [{"url": "https://external-preview.redd.it/fcinZO34yCrxve0j3Z7qUtiK-nu1UZqlDp7Z0y8AwV0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0e6f9931edf6826df4ac22245d2f809615e77bd", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fcinZO34yCrxve0j3Z7qUtiK-nu1UZqlDp7Z0y8AwV0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d2b7b7141ce5db276e2dca39679db928610a62a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fcinZO34yCrxve0j3Z7qUtiK-nu1UZqlDp7Z0y8AwV0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20b2a77a6a3946af13075c9bdfec5791a407bbbb", "width": 320, "height": 179}], "variants": {}, "id": "QD58brOsFgVVZvr2oO8SEW38POaXUNX963ploWH_5II"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "139zovc", "is_robot_indexable": true, "report_reasons": null, "author": "Wolverine_6011", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/139zovc/types_of_command_in_sql_part_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.guerillateck.com/2023/05/alter-command-distinct-function-types.html", "subreddit_subscribers": 104347, "created_utc": 1683401522.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}