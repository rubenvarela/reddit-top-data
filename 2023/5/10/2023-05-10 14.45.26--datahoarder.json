{"kind": "Listing", "data": {"after": "t3_13dk0pl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Cause over time, it's gonna dry up and start to disintegrate, causing CRC errors in your SMART logs.", "author_fullname": "t2_9eczu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Western Digital HDD shuckers, don't use masking tape to block the 3.3V pin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d9o47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 309, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 309, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683674660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cause over time, it&amp;#39;s gonna dry up and start to disintegrate, causing CRC errors in your SMART logs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13d9o47", "is_robot_indexable": true, "report_reasons": null, "author": "lerouemm", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d9o47/psa_western_digital_hdd_shuckers_dont_use_masking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d9o47/psa_western_digital_hdd_shuckers_dont_use_masking/", "subreddit_subscribers": 681889, "created_utc": 1683674660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I assume that by now most of us have heard of [youtube-dl](https://github.com/ytdl-org/youtube-dl)/[yt-dlp](https://github.com/yt-dlp/yt-dlp), and [gallery-dl](https://github.com/mikf/gallery-dl). And sure those are really really good if you want to download from sites popular enough to warrant extractors. But what if what you want to archive can't be archived by these tools?\n\nI want to see tools most of us have never heard or even thought of. Extractors for obscure websites or websites we don't think of in terms of extractors [like megatools](https://megatools.megous.com/) or [Mediafire Bulk Downloader](https://github.com/NicKoehler/mediafire_bulk_downloader). \"Glue\" tools like [rclone's `serve` command (as well as the rest of rclone)](https://rclone.org/commands/rclone_serve/) and [lftp](https://lftp.yar.ru/) that makes stuff work together easier. Phone apps like [FE File Explorer Pro (sadly the free version seems to be gone)](https://apps.apple.com/ca/app/fe-file-explorer-pro/id499470113) that makes accessing a home FTP server so much easier (once you've set up OpenVPN of course)\n\nAnd *especially* stuff so few people need that you had to make your own tools. We've all made crappy \"# TODO: FIX\" python scripts at 2am. There's no judgment at all from me\n\nHell, even if you only got 20% through making a downloader it may be a very useful start for people willing and able to finish it", "author_fullname": "t2_yj3jz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's a really niche tool you use that you can't live without?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dcxh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 186, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 186, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683683296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I assume that by now most of us have heard of &lt;a href=\"https://github.com/ytdl-org/youtube-dl\"&gt;youtube-dl&lt;/a&gt;/&lt;a href=\"https://github.com/yt-dlp/yt-dlp\"&gt;yt-dlp&lt;/a&gt;, and &lt;a href=\"https://github.com/mikf/gallery-dl\"&gt;gallery-dl&lt;/a&gt;. And sure those are really really good if you want to download from sites popular enough to warrant extractors. But what if what you want to archive can&amp;#39;t be archived by these tools?&lt;/p&gt;\n\n&lt;p&gt;I want to see tools most of us have never heard or even thought of. Extractors for obscure websites or websites we don&amp;#39;t think of in terms of extractors &lt;a href=\"https://megatools.megous.com/\"&gt;like megatools&lt;/a&gt; or &lt;a href=\"https://github.com/NicKoehler/mediafire_bulk_downloader\"&gt;Mediafire Bulk Downloader&lt;/a&gt;. &amp;quot;Glue&amp;quot; tools like &lt;a href=\"https://rclone.org/commands/rclone_serve/\"&gt;rclone&amp;#39;s &lt;code&gt;serve&lt;/code&gt; command (as well as the rest of rclone)&lt;/a&gt; and &lt;a href=\"https://lftp.yar.ru/\"&gt;lftp&lt;/a&gt; that makes stuff work together easier. Phone apps like &lt;a href=\"https://apps.apple.com/ca/app/fe-file-explorer-pro/id499470113\"&gt;FE File Explorer Pro (sadly the free version seems to be gone)&lt;/a&gt; that makes accessing a home FTP server so much easier (once you&amp;#39;ve set up OpenVPN of course)&lt;/p&gt;\n\n&lt;p&gt;And &lt;em&gt;especially&lt;/em&gt; stuff so few people need that you had to make your own tools. We&amp;#39;ve all made crappy &amp;quot;# TODO: FIX&amp;quot; python scripts at 2am. There&amp;#39;s no judgment at all from me&lt;/p&gt;\n\n&lt;p&gt;Hell, even if you only got 20% through making a downloader it may be a very useful start for people willing and able to finish it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?auto=webp&amp;v=enabled&amp;s=11fa2ce22c0c277a773be64ffbd163f8b87aba24", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3310e5d2b5ec98736d08bac31856bbe7ff3fc1eb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a11d31bd31633dc9809d85f35a1c607d5706420f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d47e27dc1446186631c093ea9344e121135fb437", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=336634dd0b528a8ba26bbebc43e2e159d928d868", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f1bcc9ed2688c10732c622fa470a60f3e41c357", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9ESi-sGeI-oz2o8DjYJofRlh8qQxu7HLEA02V5jA81U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ac65670017096cd0240446267a46d89f1a7ac4d", "width": 1080, "height": 540}], "variants": {}, "id": "iOkfw7fTCubXFKjzrDQNlZPSG2GLlas8Oq9HbiK2Tlw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "The sexiest data storage medium", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13dcxh2", "is_robot_indexable": true, "report_reasons": null, "author": "Scripter17", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13dcxh2/whats_a_really_niche_tool_you_use_that_you_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dcxh2/whats_a_really_niche_tool_you_use_that_you_cant/", "subreddit_subscribers": 681889, "created_utc": 1683683296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3a4wg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital: Customer info stolen in March IT attack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13ddd0n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JtY45QQNHzoC9fJBSkJOv7hO_OkITtIm6QzqUuzc5_M.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683684453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theregister.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theregister.com/2023/05/08/western_digital_customer_data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?auto=webp&amp;v=enabled&amp;s=e329e9e0319a12b4dfebd454fb10da87cdef130a", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6242184437122114547aebe205773922f4591f22", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5afeaab3dda95340d2993c20fba08a8dae4b56a0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46aacd6cf55b7d4e1d496eb9181c2ee1ef7b0508", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92f5bcc8964232b311af6220e621cbc2de63354b", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Mvf0tcbte6pj7PnnHn-1CVxZIwPE6uHSCRN43LV_qwo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=781f43a5175ef3ae9c7c7b581ed40c630434a181", "width": 960, "height": 640}], "variants": {}, "id": "scfEFwMYcZ5Z-cKYYQWl4vq8b_i-y2GT6cE8LSiewe4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ddd0n", "is_robot_indexable": true, "report_reasons": null, "author": "wewewawa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13ddd0n/western_digital_customer_info_stolen_in_march_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theregister.com/2023/05/08/western_digital_customer_data/", "subreddit_subscribers": 681889, "created_utc": 1683684453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looks like it's dead for real this time.  Comment/submission datadumps have all been taken down today and the API has not been working for a week.  RIP\n\nMight be worth taking a look at their hacker news/twitter/stackoverflow archive before that's taken down as well", "author_fullname": "t2_jxsk4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pushshift Reddit archive is dead", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dds95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683685653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looks like it&amp;#39;s dead for real this time.  Comment/submission datadumps have all been taken down today and the API has not been working for a week.  RIP&lt;/p&gt;\n\n&lt;p&gt;Might be worth taking a look at their hacker news/twitter/stackoverflow archive before that&amp;#39;s taken down as well&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "100 Zettabytes zfs", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dds95", "is_robot_indexable": true, "report_reasons": null, "author": "Yekab0f", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13dds95/pushshift_reddit_archive_is_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dds95/pushshift_reddit_archive_is_dead/", "subreddit_subscribers": 681889, "created_utc": 1683685653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone found a way to digitize there DVD collection for there NAS/Plex Server?\n\nI was thinking about buying a DVD/CD Duplicator and modding it's 7 drives to connect to USB 3.0 hub and connecting it to my computer, and using software to automate it.\n\nAny thoughts?", "author_fullname": "t2_52dasc0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to digitize multiple DVDs for plex server/NAS storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d5ij5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683665242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone found a way to digitize there DVD collection for there NAS/Plex Server?&lt;/p&gt;\n\n&lt;p&gt;I was thinking about buying a DVD/CD Duplicator and modding it&amp;#39;s 7 drives to connect to USB 3.0 hub and connecting it to my computer, and using software to automate it.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d5ij5", "is_robot_indexable": true, "report_reasons": null, "author": "mediagenius", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d5ij5/easiest_way_to_digitize_multiple_dvds_for_plex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d5ij5/easiest_way_to_digitize_multiple_dvds_for_plex/", "subreddit_subscribers": 681889, "created_utc": 1683665242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to maybe re-configure my system. I have 2 LSI IT mode x8 2 port cards, cant seem to find anything on x16 4 port cards that support 16 drives. \n\nDoes anyone have any good recommendations?", "author_fullname": "t2_45xca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good PCIE x16 16 port sas cards that work in IT mode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d79iu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683669067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to maybe re-configure my system. I have 2 LSI IT mode x8 2 port cards, cant seem to find anything on x16 4 port cards that support 16 drives. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any good recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d79iu", "is_robot_indexable": true, "report_reasons": null, "author": "spikerman", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d79iu/any_good_pcie_x16_16_port_sas_cards_that_work_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d79iu/any_good_pcie_x16_16_port_sas_cards_that_work_in/", "subreddit_subscribers": 681889, "created_utc": 1683669067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to save every scorecard, profile, series, etc. from the MyCricket website ([http://mycricket.cricket.com.au/?entityid=1900&amp;save=0](http://mycricket.cricket.com.au/?entityid=1900&amp;save=0))? The site operators have announced that it will be taken down from Aug 31, 2023 and they have no current plans to save all the historical stats. \n\nSo other than going page by page manually, is it possible to download a working copy of the website locally or bulk export the data somehow? I've tried searching around, but didn't know what I should be looking for.", "author_fullname": "t2_4na0kimf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I save content from the MyCricket website before Aug 31?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dhk52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683697472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to save every scorecard, profile, series, etc. from the MyCricket website (&lt;a href=\"http://mycricket.cricket.com.au/?entityid=1900&amp;amp;save=0\"&gt;http://mycricket.cricket.com.au/?entityid=1900&amp;amp;save=0&lt;/a&gt;)? The site operators have announced that it will be taken down from Aug 31, 2023 and they have no current plans to save all the historical stats. &lt;/p&gt;\n\n&lt;p&gt;So other than going page by page manually, is it possible to download a working copy of the website locally or bulk export the data somehow? I&amp;#39;ve tried searching around, but didn&amp;#39;t know what I should be looking for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/v8F3DY9uCIf-PdDmFmV0D1QuQRFhTNCYGx48XbWG4HQ.jpg?auto=webp&amp;v=enabled&amp;s=b5d8bf455bf5174ab950581c453bcdc7192b1ecf", "width": 135, "height": 175}, "resolutions": [{"url": "https://external-preview.redd.it/v8F3DY9uCIf-PdDmFmV0D1QuQRFhTNCYGx48XbWG4HQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76f53bcc8c579c91868fbac9b4f50b9bc8a132c3", "width": 108, "height": 140}], "variants": {}, "id": "aEEE8wuNoSUz5gWgUZF74Wty48zcSncMeDDQRd3t13I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dhk52", "is_robot_indexable": true, "report_reasons": null, "author": "chainglitch", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dhk52/how_can_i_save_content_from_the_mycricket_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dhk52/how_can_i_save_content_from_the_mycricket_website/", "subreddit_subscribers": 681889, "created_utc": 1683697472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hola,\n\nSo a bit of backstory, my friend and I are photographers and he recently lent me his Extreme for a trip when my Orico M\n2 enclosure crapped out on me. My workflow consists of having my Lightroom catalog and the past year's photos on a portable drive and have the rest on my PC. This lets me easily sort and edit photos on my PC and Macbook. I also have an external backup.\n\nI'm returning this drive to him and intend on buying my own in 2TB, but I don't know which.\n\nOn one hand, the Extreme is smaller, noticeably lighter, and I quite like the shorter cable.\n\nThe Pro is 2x as fast, however, that speed I'm not going to utilize until I upgrade my PC a few years from now. The Pro is $60CAD or $45USD more than the Extreme.\n\nSo I have 2 schools of thought at the moment:\n1. Futureproof myself now at a slightly higher price.\n2. Keep the cheaper version, and when I need to upgrade to a faster 4TB, I can use the Extreme as a PS5 external drive.\n\nThoughts?", "author_fullname": "t2_gq2n9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme Portable vs Extreme Pro Portable. Which one to buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13dllfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dUCTeZzpEKCuAPvlFNucwf3Ompozy8P4oshwIZBWhWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683711728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hola,&lt;/p&gt;\n\n&lt;p&gt;So a bit of backstory, my friend and I are photographers and he recently lent me his Extreme for a trip when my Orico M\n2 enclosure crapped out on me. My workflow consists of having my Lightroom catalog and the past year&amp;#39;s photos on a portable drive and have the rest on my PC. This lets me easily sort and edit photos on my PC and Macbook. I also have an external backup.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m returning this drive to him and intend on buying my own in 2TB, but I don&amp;#39;t know which.&lt;/p&gt;\n\n&lt;p&gt;On one hand, the Extreme is smaller, noticeably lighter, and I quite like the shorter cable.&lt;/p&gt;\n\n&lt;p&gt;The Pro is 2x as fast, however, that speed I&amp;#39;m not going to utilize until I upgrade my PC a few years from now. The Pro is $60CAD or $45USD more than the Extreme.&lt;/p&gt;\n\n&lt;p&gt;So I have 2 schools of thought at the moment:\n1. Futureproof myself now at a slightly higher price.\n2. Keep the cheaper version, and when I need to upgrade to a faster 4TB, I can use the Extreme as a PS5 external drive.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lmrm5bqen0za1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?auto=webp&amp;v=enabled&amp;s=e44e3e0252d727676ddbd12e11be6206c40713cd", "width": 3000, "height": 4000}, "resolutions": [{"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52aaf53ab2c9304aea26be9537c7918bca71e471", "width": 108, "height": 144}, {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c666408bfef4cedc9d73efb9d9e2ecca67380ac5", "width": 216, "height": 288}, {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eee2928b496a0e19658deb9a10093fa51f552c6a", "width": 320, "height": 426}, {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1897042d0915debd15f25512044d52b5696d3c5a", "width": 640, "height": 853}, {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a13fca662c1bb5cf7378547042a03031c8d6ff31", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/lmrm5bqen0za1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95efa7e5a2806400bf4534f1f862e7e51fc9e6fe", "width": 1080, "height": 1440}], "variants": {}, "id": "9c8hBJ-Niq5FBjPN7Cdn7iXofl7M-B7Qd76hpLAAOPs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dllfx", "is_robot_indexable": true, "report_reasons": null, "author": "NavXIII", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dllfx/sandisk_extreme_portable_vs_extreme_pro_portable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lmrm5bqen0za1.jpg", "subreddit_subscribers": 681889, "created_utc": 1683711728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI've trying to find the means to batch download a user's full profile on TikTok without watermark. Most posts on this subreddit about this issue have outdated methods, that no longer work (for example yt-dlp). I've also tried JDownloader 2, but it doesn't work for me.\n\nI've found [this Chinese GitHub](https://github.com/Johnserf-Seed/TikTokDownload), but I'm not sure how to use it as I do not know the language.\n\nDoes someone know another method of doing it? Preferably a FOSS way, that's compatible with Windows, but Linux is also fine I guess.\n\nAnyways, thank you for reading my post! Have a nice life!", "author_fullname": "t2_2p9hjt1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading all videos on a TikTok profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d3esi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683661530.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683660572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve trying to find the means to batch download a user&amp;#39;s full profile on TikTok without watermark. Most posts on this subreddit about this issue have outdated methods, that no longer work (for example yt-dlp). I&amp;#39;ve also tried JDownloader 2, but it doesn&amp;#39;t work for me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found &lt;a href=\"https://github.com/Johnserf-Seed/TikTokDownload\"&gt;this Chinese GitHub&lt;/a&gt;, but I&amp;#39;m not sure how to use it as I do not know the language.&lt;/p&gt;\n\n&lt;p&gt;Does someone know another method of doing it? Preferably a FOSS way, that&amp;#39;s compatible with Windows, but Linux is also fine I guess.&lt;/p&gt;\n\n&lt;p&gt;Anyways, thank you for reading my post! Have a nice life!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?auto=webp&amp;v=enabled&amp;s=446640de3735a7474516b7f9f9ada91a50b31ab9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ba73a37a39626bf44f86cfb055a84930b1e4ab", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=171313dd3f49691b1916e0ffb28dbce22546351b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3260b6e4780114e648ad96696ab5c97059f45da", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d021281b3da2a077ff5d4bb6b4121f4402b8599", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94107dc7692bde0e6cf6b83c907b24072198f729", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/mOZ7vmYSm5qOYp_ZscI9eareJCYNkAn9k1D_VywwwFQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e626728fee30caaba2986178d0b2901dd8a78be1", "width": 1080, "height": 540}], "variants": {}, "id": "qJ18FxgfqBxpOtYBodythfd3v_cpt-sZtkflZ0zrH7I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d3esi", "is_robot_indexable": true, "report_reasons": null, "author": "InterMob", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d3esi/downloading_all_videos_on_a_tiktok_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d3esi/downloading_all_videos_on_a_tiktok_profile/", "subreddit_subscribers": 681889, "created_utc": 1683660572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to download a video with yt-dlp with only one specific video and audio track. The formats available are \n\n    ID EXT RESOLUTION FPS \u2502   TBR PROTO \u2502 VCODEC          VBR ACODEC      \n    14 m4a audio only     \u2502  449k dash  \u2502 audio only          ac-3      \n    13 m4a audio only     \u2502  196k dash  \u2502 audio only          mp4a.40.2\n    11 m4a audio only     \u2502  196k dash  \u2502 audio only          mp4a.40.2 \n    15 m4a audio only     \u2502  197k dash  \u2502 audio only          mp4a.40.2\n    9  mp4 416x234     25 \u2502  606k dash  \u2502 avc1.42c01f    606k video only\n    4  mp4 416x234     25 \u2502  448k dash  \u2502 hvc1.2.4.L123  448k video only\n    8  mp4 640x360     25 \u2502 1510k dash  \u2502 avc1.4d401f   1510k video only\n    3  mp4 640x360     25 \u2502  856k dash  \u2502 hvc1.2.4.L123  856k video only\n    7  mp4 960x540     25 \u2502 2299k dash  \u2502 avc1.4d401f   2299k video only\n    2  mp4 960x540     25 \u2502 1580k dash  \u2502 hvc1.2.4.L123 1580k video only\n    6  mp4 1280x720    25 \u2502 3631k dash  \u2502 avc1.4d401f   3631k video only\n    1  mp4 1280x720    25 \u2502 2458k dash  \u2502 hvc1.2.4.L123 2458k video only\n    5  mp4 1920x1080   25 \u2502 5435k dash  \u2502 avc1.640029   5435k video only\n    0  mp4 1920x1080   25 \u2502 4486k dash  \u2502 hvc1.2.4.L123 4486k video only\n\nI can get a correct format by using `-f mergeall` but that gives me several accessibility audio tracks that I'm currently not interested in having. If I use `-f 0,11` for example it gives me separate output files (one mp4 file which is only the video, and a separate m4a file that is audio only). Is there a way to merge video and audio output without having to download all formats?", "author_fullname": "t2_bjlgrfr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using yt-dlp to merge video and audio from specific formats only?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dcmxv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683682502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to download a video with yt-dlp with only one specific video and audio track. The formats available are &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ID EXT RESOLUTION FPS \u2502   TBR PROTO \u2502 VCODEC          VBR ACODEC      \n14 m4a audio only     \u2502  449k dash  \u2502 audio only          ac-3      \n13 m4a audio only     \u2502  196k dash  \u2502 audio only          mp4a.40.2\n11 m4a audio only     \u2502  196k dash  \u2502 audio only          mp4a.40.2 \n15 m4a audio only     \u2502  197k dash  \u2502 audio only          mp4a.40.2\n9  mp4 416x234     25 \u2502  606k dash  \u2502 avc1.42c01f    606k video only\n4  mp4 416x234     25 \u2502  448k dash  \u2502 hvc1.2.4.L123  448k video only\n8  mp4 640x360     25 \u2502 1510k dash  \u2502 avc1.4d401f   1510k video only\n3  mp4 640x360     25 \u2502  856k dash  \u2502 hvc1.2.4.L123  856k video only\n7  mp4 960x540     25 \u2502 2299k dash  \u2502 avc1.4d401f   2299k video only\n2  mp4 960x540     25 \u2502 1580k dash  \u2502 hvc1.2.4.L123 1580k video only\n6  mp4 1280x720    25 \u2502 3631k dash  \u2502 avc1.4d401f   3631k video only\n1  mp4 1280x720    25 \u2502 2458k dash  \u2502 hvc1.2.4.L123 2458k video only\n5  mp4 1920x1080   25 \u2502 5435k dash  \u2502 avc1.640029   5435k video only\n0  mp4 1920x1080   25 \u2502 4486k dash  \u2502 hvc1.2.4.L123 4486k video only\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I can get a correct format by using &lt;code&gt;-f mergeall&lt;/code&gt; but that gives me several accessibility audio tracks that I&amp;#39;m currently not interested in having. If I use &lt;code&gt;-f 0,11&lt;/code&gt; for example it gives me separate output files (one mp4 file which is only the video, and a separate m4a file that is audio only). Is there a way to merge video and audio output without having to download all formats?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dcmxv", "is_robot_indexable": true, "report_reasons": null, "author": "ConstantConsumption", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dcmxv/using_ytdlp_to_merge_video_and_audio_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dcmxv/using_ytdlp_to_merge_video_and_audio_from/", "subreddit_subscribers": 681889, "created_utc": 1683682502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought a WD Red Plus WD40EFZX 4 TB 5400 rpm CMR cache 128 MB as an internal device (SATA) for my PC to store movies and other data. I am using it as a normal HDD without RAID or anything else.\n\nWhen I transfer files from my other volumes, the speed is good for a second (150 MB/s) and then it drops and gets stuck at 0 bytes/s. I searched up on the internet and everyone says that this problem is common in SMR HDD and I should move to a CMR HDD. **But I have a CMR HDD**.\n\nI know tt's not the origin volume because it's an NVMe.\n\nAlso, the movies I was able to transfer are not possibile to open directly from the volume because they won't load up. I know it's a 5400 rpm volume created for NAS, but I didn't think it would be that bad as an internal HDD.\n\nI'm definitely missing something. \n\nThank you in advance for your help, and sorry if I am a noob in the matter.", "author_fullname": "t2_psbwpiiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CMR HDD transfer speed drops to 0 bytes/s ???", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d2euj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683658360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought a WD Red Plus WD40EFZX 4 TB 5400 rpm CMR cache 128 MB as an internal device (SATA) for my PC to store movies and other data. I am using it as a normal HDD without RAID or anything else.&lt;/p&gt;\n\n&lt;p&gt;When I transfer files from my other volumes, the speed is good for a second (150 MB/s) and then it drops and gets stuck at 0 bytes/s. I searched up on the internet and everyone says that this problem is common in SMR HDD and I should move to a CMR HDD. &lt;strong&gt;But I have a CMR HDD&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I know tt&amp;#39;s not the origin volume because it&amp;#39;s an NVMe.&lt;/p&gt;\n\n&lt;p&gt;Also, the movies I was able to transfer are not possibile to open directly from the volume because they won&amp;#39;t load up. I know it&amp;#39;s a 5400 rpm volume created for NAS, but I didn&amp;#39;t think it would be that bad as an internal HDD.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m definitely missing something. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help, and sorry if I am a noob in the matter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d2euj", "is_robot_indexable": true, "report_reasons": null, "author": "sambertan_", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d2euj/cmr_hdd_transfer_speed_drops_to_0_bytess/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d2euj/cmr_hdd_transfer_speed_drops_to_0_bytess/", "subreddit_subscribers": 681889, "created_utc": 1683658360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found this one [https://www.amazon.ca/VERBATIM-External-Blu-ray-Compatible-71097/dp/B09PY6SC9Y/](https://www.amazon.ca/VERBATIM-External-Blu-ray-Compatible-71097/dp/B09PY6SC9Y/) \n\nIts the best price I've been able to find for a good brand but Its still a bit expensive. I also heard that only specific ones can do 4k discs? I'm mostly just going to use MakeMKV with it.\n\nIt can be an internal one with an external shell if thats better, I'm not sure what is better in this case.", "author_fullname": "t2_dd6cqc46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help me pick out a good BD Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dhoa7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683697857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found this one &lt;a href=\"https://www.amazon.ca/VERBATIM-External-Blu-ray-Compatible-71097/dp/B09PY6SC9Y/\"&gt;https://www.amazon.ca/VERBATIM-External-Blu-ray-Compatible-71097/dp/B09PY6SC9Y/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Its the best price I&amp;#39;ve been able to find for a good brand but Its still a bit expensive. I also heard that only specific ones can do 4k discs? I&amp;#39;m mostly just going to use MakeMKV with it.&lt;/p&gt;\n\n&lt;p&gt;It can be an internal one with an external shell if thats better, I&amp;#39;m not sure what is better in this case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dhoa7", "is_robot_indexable": true, "report_reasons": null, "author": "Standard-Historian79", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dhoa7/can_anyone_help_me_pick_out_a_good_bd_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dhoa7/can_anyone_help_me_pick_out_a_good_bd_drive/", "subreddit_subscribers": 681889, "created_utc": 1683697857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, \nLong time lurker first time poster...\nMy question is the best budget way to connect my drives..\nSo for context my setups is:\n- 4 bay WD My cloud ex4 (4x3TB) (RAID10 bcz worst purchase i ever did, run away from WD for NAS hardware z their HDDs are great though)\n- 1 enterprise 14TB Seagate for backup (of the nas in an external box hooked directly via USB)\n- 1x12TB wd easystore media hooked to PC (not shucked)\n- 1x8TB Seagate backup plus (not shucked)\n\nInternally in my PC:\n1x 3TB \n1x 4TB\n(Other SSDs for operation irrelevant here) so my PC can't fit more drives \nLastely 2 unplugged HDDs\n2TB Seagate barracuda\n3TB Seagate Barracuda \n\nNow I'm looking into mainly start using those 2 Seagates,(other than external usb enclosures) \n\nWhat is the best way to properly get on-line all my drives? Why all online bcz I'm lazy to store them offline with data.\n\nShucking the 8tb and 12tb is an option but i don't mind leaving these portable\n\nI looked into DAS solutions but felt they are quite expensive .\nCurrently I'm not looking into a new NAS cz of cost and I would like one day to build my own NAS \n\nAny advice for an amateur hoarder?\n\nThanks\n\nEditing chuck to shuck", "author_fullname": "t2_1wio452u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing multiple HDDs the cheap way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dhif5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683710252.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683697313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, \nLong time lurker first time poster...\nMy question is the best budget way to connect my drives..\nSo for context my setups is:\n- 4 bay WD My cloud ex4 (4x3TB) (RAID10 bcz worst purchase i ever did, run away from WD for NAS hardware z their HDDs are great though)\n- 1 enterprise 14TB Seagate for backup (of the nas in an external box hooked directly via USB)\n- 1x12TB wd easystore media hooked to PC (not shucked)\n- 1x8TB Seagate backup plus (not shucked)&lt;/p&gt;\n\n&lt;p&gt;Internally in my PC:\n1x 3TB \n1x 4TB\n(Other SSDs for operation irrelevant here) so my PC can&amp;#39;t fit more drives \nLastely 2 unplugged HDDs\n2TB Seagate barracuda\n3TB Seagate Barracuda &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m looking into mainly start using those 2 Seagates,(other than external usb enclosures) &lt;/p&gt;\n\n&lt;p&gt;What is the best way to properly get on-line all my drives? Why all online bcz I&amp;#39;m lazy to store them offline with data.&lt;/p&gt;\n\n&lt;p&gt;Shucking the 8tb and 12tb is an option but i don&amp;#39;t mind leaving these portable&lt;/p&gt;\n\n&lt;p&gt;I looked into DAS solutions but felt they are quite expensive .\nCurrently I&amp;#39;m not looking into a new NAS cz of cost and I would like one day to build my own NAS &lt;/p&gt;\n\n&lt;p&gt;Any advice for an amateur hoarder?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;Editing chuck to shuck&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dhif5", "is_robot_indexable": true, "report_reasons": null, "author": "Elkhose", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dhif5/managing_multiple_hdds_the_cheap_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dhif5/managing_multiple_hdds_the_cheap_way/", "subreddit_subscribers": 681889, "created_utc": 1683697313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "im collecting prototypes and and rare game media for the past 2 years, i got a nice collection, BUT there are a few things on the betaArchive that id love to grab but it appears you need to upload and contribute unique media, and stupidly donating money doesnt give access either.\n\ndoes anyone know a way to downlaod on there without having account access", "author_fullname": "t2_1nrkmxag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any way to download from BetaArchive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dba2b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683678825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;im collecting prototypes and and rare game media for the past 2 years, i got a nice collection, BUT there are a few things on the betaArchive that id love to grab but it appears you need to upload and contribute unique media, and stupidly donating money doesnt give access either.&lt;/p&gt;\n\n&lt;p&gt;does anyone know a way to downlaod on there without having account access&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13dba2b", "is_robot_indexable": true, "report_reasons": null, "author": "Suicidalbutbaked", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dba2b/any_way_to_download_from_betaarchive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dba2b/any_way_to_download_from_betaarchive/", "subreddit_subscribers": 681889, "created_utc": 1683678825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have a 55TB NAS and it is working great, houses my personal files, backups of the computers etc.\n\nIt also houses my ever growing library of BluRay rips for my PleX server. \n\nI use a cloud provider for my offsite backups but am struggling with terrible upload from my ISP (max of 30Mbps up). As the media library grows fast and the upload is so low; it takes literal months for an initial backup to the cloud provider. \n\nIn the next year or two I am hoping to have a Fiber Option available at my house that will give me 1Gbps upload which fixes this issue and allows the cloud back up to be a viable solution for everything. \n\n&amp;#x200B;\n\nRight now, I want to have at least 2 copies of the media library on 2 different devices (in case of catastrophic failure).  I currently have 12TB and that will continue to increase in size. I would like to have the files on the desktop storage connected directly to the server and use my NAS as a backup of that. What are the suggestions for a Linux compatible Desktop storage I could connect to my PleX server?\n\n&amp;#x200B;\n\nSuggestions? Thoughts?", "author_fullname": "t2_10sn4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linux Compatible Desktop Storage For 20TB of Media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13dpre3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683723156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a 55TB NAS and it is working great, houses my personal files, backups of the computers etc.&lt;/p&gt;\n\n&lt;p&gt;It also houses my ever growing library of BluRay rips for my PleX server. &lt;/p&gt;\n\n&lt;p&gt;I use a cloud provider for my offsite backups but am struggling with terrible upload from my ISP (max of 30Mbps up). As the media library grows fast and the upload is so low; it takes literal months for an initial backup to the cloud provider. &lt;/p&gt;\n\n&lt;p&gt;In the next year or two I am hoping to have a Fiber Option available at my house that will give me 1Gbps upload which fixes this issue and allows the cloud back up to be a viable solution for everything. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Right now, I want to have at least 2 copies of the media library on 2 different devices (in case of catastrophic failure).  I currently have 12TB and that will continue to increase in size. I would like to have the files on the desktop storage connected directly to the server and use my NAS as a backup of that. What are the suggestions for a Linux compatible Desktop storage I could connect to my PleX server?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Suggestions? Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dpre3", "is_robot_indexable": true, "report_reasons": null, "author": "nowhereman1223", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13dpre3/linux_compatible_desktop_storage_for_20tb_of_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dpre3/linux_compatible_desktop_storage_for_20tb_of_media/", "subreddit_subscribers": 681889, "created_utc": 1683723156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My struggle is that the auto filename is the name of the email subject so if there\u2019s a back and forth conversation, it\u2019ll ask if I want to overwrite because the filename matches another reply.", "author_fullname": "t2_837akngy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have to save thousands Of outlook emails to save without overwriting, any tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dnise", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683717487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My struggle is that the auto filename is the name of the email subject so if there\u2019s a back and forth conversation, it\u2019ll ask if I want to overwrite because the filename matches another reply.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dnise", "is_robot_indexable": true, "report_reasons": null, "author": "ZeBloodyStretchr", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dnise/i_have_to_save_thousands_of_outlook_emails_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dnise/i_have_to_save_thousands_of_outlook_emails_to/", "subreddit_subscribers": 681889, "created_utc": 1683717487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning on buying some large capacity used/refurbished HDDs to replace my multiple smaller capacity drives. I have zeroed in on serverpartdeals &amp; goharddrive for purchase. Comparing the two I came across these drives on goharddrive which look better value for money compared to SPD prices.\n\n&gt; HGST Ultrastar He10 HUH721010ALE601 (0F27468) 10TB 7200RPM 256MB Cache SATA 6.0Gb/s 3.5\" Enterprise Hard Drive [Power Disabled] (Certified Refurbished) - 5 Year Warranty - $79.99\n\n&gt; HGST Ultrastar HE10 HUH721010ALE600 (0F27490) 10TB 7200RPM 128MB Cache SATA 6.0Gb/s 3.5\" Enterprise Hard Drive (Certified Refurbished) - 5 Year Warranty - $79.99\n\n&gt; WD / HGST Ultrastar He10 HUH721010ALE604 10TB 7200RPM 256MB Cache SATA 6.0Gb/s 3.5\" Enterprise Hard Drive (Factory Recertified) - 5 Year Warranty - $89.99\n\nWhat are the differences between above three drives &amp; which ones are suggested? Are there better options available on SPD because I couldn't find one? I am planning on getting three such drives for total 30TB space as JBOD in my desktop(2 drives) &amp; one in my single bay NAS.", "author_fullname": "t2_2yk8rpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions and opinions regarding buying used drives from goharddrive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dl3tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683710069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning on buying some large capacity used/refurbished HDDs to replace my multiple smaller capacity drives. I have zeroed in on serverpartdeals &amp;amp; goharddrive for purchase. Comparing the two I came across these drives on goharddrive which look better value for money compared to SPD prices.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;HGST Ultrastar He10 HUH721010ALE601 (0F27468) 10TB 7200RPM 256MB Cache SATA 6.0Gb/s 3.5&amp;quot; Enterprise Hard Drive [Power Disabled] (Certified Refurbished) - 5 Year Warranty - $79.99&lt;/p&gt;\n\n&lt;p&gt;HGST Ultrastar HE10 HUH721010ALE600 (0F27490) 10TB 7200RPM 128MB Cache SATA 6.0Gb/s 3.5&amp;quot; Enterprise Hard Drive (Certified Refurbished) - 5 Year Warranty - $79.99&lt;/p&gt;\n\n&lt;p&gt;WD / HGST Ultrastar He10 HUH721010ALE604 10TB 7200RPM 256MB Cache SATA 6.0Gb/s 3.5&amp;quot; Enterprise Hard Drive (Factory Recertified) - 5 Year Warranty - $89.99&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What are the differences between above three drives &amp;amp; which ones are suggested? Are there better options available on SPD because I couldn&amp;#39;t find one? I am planning on getting three such drives for total 30TB space as JBOD in my desktop(2 drives) &amp;amp; one in my single bay NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dl3tn", "is_robot_indexable": true, "report_reasons": null, "author": "random_999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dl3tn/need_suggestions_and_opinions_regarding_buying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dl3tn/need_suggestions_and_opinions_regarding_buying/", "subreddit_subscribers": 681889, "created_utc": 1683710069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After a lot of research. The choice paralysis is real. \n\n  \nI want to save a copy of 2 drives on my windows 10 pc to respective folders on a larger Hard Drive on the same system. As a backup of sorts. Id like for the software to make sure all the files are the same and not corrupted (if possible).   \n\n\nIt would be preferred if the software was open source.   \n\n\nThank you Reddit, You are my only hope.", "author_fullname": "t2_4lrsy7em", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help choosing a sync/backup software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13df7nf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683689919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a lot of research. The choice paralysis is real. &lt;/p&gt;\n\n&lt;p&gt;I want to save a copy of 2 drives on my windows 10 pc to respective folders on a larger Hard Drive on the same system. As a backup of sorts. Id like for the software to make sure all the files are the same and not corrupted (if possible).   &lt;/p&gt;\n\n&lt;p&gt;It would be preferred if the software was open source.   &lt;/p&gt;\n\n&lt;p&gt;Thank you Reddit, You are my only hope.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13df7nf", "is_robot_indexable": true, "report_reasons": null, "author": "DeconThe1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13df7nf/need_help_choosing_a_syncbackup_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13df7nf/need_help_choosing_a_syncbackup_software/", "subreddit_subscribers": 681889, "created_utc": 1683689919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://zfsonlinux.topicbox.com/groups/zfs-discuss/Te01f8cde6fcb9be4](https://zfsonlinux.topicbox.com/groups/zfs-discuss/Te01f8cde6fcb9be4)\n\n&amp;#x200B;\n\n2nd drive failure during rebuild. RAIDZ1 appears to work fine - until it doesn't.\n\nIf you're using drives over 2TB, USE RAIDZ2 / RAID6. Unless your backups are rock-solid, tested, and you can afford the downtime to rebuild.", "author_fullname": "t2_1vbtepb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Still think RAID5 / RAIDZ1 is sufficient? You're tempting fate.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13dqy41", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683725909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://zfsonlinux.topicbox.com/groups/zfs-discuss/Te01f8cde6fcb9be4\"&gt;https://zfsonlinux.topicbox.com/groups/zfs-discuss/Te01f8cde6fcb9be4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2nd drive failure during rebuild. RAIDZ1 appears to work fine - until it doesn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re using drives over 2TB, USE RAIDZ2 / RAID6. Unless your backups are rock-solid, tested, and you can afford the downtime to rebuild.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB \ud83d\ude07 \ud83d\ude1c \ud83d\ude43", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dqy41", "is_robot_indexable": true, "report_reasons": null, "author": "zfsbest", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13dqy41/psa_still_think_raid5_raidz1_is_sufficient_youre/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dqy41/psa_still_think_raid5_raidz1_is_sufficient_youre/", "subreddit_subscribers": 681889, "created_utc": 1683725909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, \n\nNot sure if a tool like this exists, but I have a few places where I archive HLS streams from using browser plugins.\n\nIt works great, however I have to visit each page with media and download this manually. What I'd love is some sort of way to do this in bulk, if such a method exists. If I could throw a bunch of links at a program &amp; get it to pull the media automatically it would change my life. \n\nAnyone out there know of anything?", "author_fullname": "t2_wk1t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk HLS Downloader?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13dqhqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683724879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Not sure if a tool like this exists, but I have a few places where I archive HLS streams from using browser plugins.&lt;/p&gt;\n\n&lt;p&gt;It works great, however I have to visit each page with media and download this manually. What I&amp;#39;d love is some sort of way to do this in bulk, if such a method exists. If I could throw a bunch of links at a program &amp;amp; get it to pull the media automatically it would change my life. &lt;/p&gt;\n\n&lt;p&gt;Anyone out there know of anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dqhqh", "is_robot_indexable": true, "report_reasons": null, "author": "watsee", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dqhqh/bulk_hls_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dqhqh/bulk_hls_downloader/", "subreddit_subscribers": 681889, "created_utc": 1683724879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I'm trying to figure out what would be the most lossless way to record video from a PC to a VCR/VHS tape. Would it be to go from Hdmi output on my video card and use some adapter to go to S-video input to the VCR? Trying to maintain picture quality as much as possible (even though the idea is to get vhs quality picture in the end). Does anyone know the most lossless way to go about this? Thanks!", "author_fullname": "t2_8kv0d6cx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to record video from PC (HDMI) to VCR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d41ik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683661942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m trying to figure out what would be the most lossless way to record video from a PC to a VCR/VHS tape. Would it be to go from Hdmi output on my video card and use some adapter to go to S-video input to the VCR? Trying to maintain picture quality as much as possible (even though the idea is to get vhs quality picture in the end). Does anyone know the most lossless way to go about this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d41ik", "is_robot_indexable": true, "report_reasons": null, "author": "Dead_wet_flesh_jets", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13d41ik/whats_the_best_way_to_record_video_from_pc_hdmi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d41ik/whats_the_best_way_to_record_video_from_pc_hdmi/", "subreddit_subscribers": 681889, "created_utc": 1683661942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've swapped out the SATA cable and put it in a different port on the mobo so it looks like it's just the drive, but I've never had one go faulty so soon. It also shows as perfectly fine in Hard Disk Sentinel, just nothing accessible.", "author_fullname": "t2_6d7bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a new shucked 12TB WD, only a month old that now shows as \"Drive not accessible\". Any ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13d0aa1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683653749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve swapped out the SATA cable and put it in a different port on the mobo so it looks like it&amp;#39;s just the drive, but I&amp;#39;ve never had one go faulty so soon. It also shows as perfectly fine in Hard Disk Sentinel, just nothing accessible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "49TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13d0aa1", "is_robot_indexable": true, "report_reasons": null, "author": "xenochria", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13d0aa1/i_have_a_new_shucked_12tb_wd_only_a_month_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13d0aa1/i_have_a_new_shucked_12tb_wd_only_a_month_old/", "subreddit_subscribers": 681889, "created_utc": 1683653749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Getting this error a lot lately.  I wonder what the 'limiting' means in this context.\n\nI have my account set up for NSFW viewing, so it can't be that, in my case. Do the creators block non-followers from viewing? Is it some kind of region lock? Or do they disallow linking from somewhere else? Or have they totally privated their works? (In which case, why even have them on Pixiv?)\n\nAnd are there any ways to circumvent and save their works anyway?", "author_fullname": "t2_48lhljdii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pixiv \"An error has occurred. The creator has limited who can view this content\" - what does it mean, exactly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cvswz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683646184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Getting this error a lot lately.  I wonder what the &amp;#39;limiting&amp;#39; means in this context.&lt;/p&gt;\n\n&lt;p&gt;I have my account set up for NSFW viewing, so it can&amp;#39;t be that, in my case. Do the creators block non-followers from viewing? Is it some kind of region lock? Or do they disallow linking from somewhere else? Or have they totally privated their works? (In which case, why even have them on Pixiv?)&lt;/p&gt;\n\n&lt;p&gt;And are there any ways to circumvent and save their works anyway?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13cvswz", "is_robot_indexable": true, "report_reasons": null, "author": "WatneyLittle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13cvswz/pixiv_an_error_has_occurred_the_creator_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13cvswz/pixiv_an_error_has_occurred_the_creator_has/", "subreddit_subscribers": 681889, "created_utc": 1683646184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I was helping my dad clean up and found an hhd containing windows 7. I would like to archive it by compressing it but kept getting permission denied. Tried 7zip but that doesn't work either. Then I tried to copy the whole thing to my local laptop but files suddenly stopped transferring.\n\n&amp;#x200B;\n\nSo I thought might as well ask here. I just wanted to archive windows 7 for fun tbh. Thanks so much!!", "author_fullname": "t2_i3ejtg6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to archive Windows 7?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cs776", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683642997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was helping my dad clean up and found an hhd containing windows 7. I would like to archive it by compressing it but kept getting permission denied. Tried 7zip but that doesn&amp;#39;t work either. Then I tried to copy the whole thing to my local laptop but files suddenly stopped transferring.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I thought might as well ask here. I just wanted to archive windows 7 for fun tbh. Thanks so much!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13cs776", "is_robot_indexable": true, "report_reasons": null, "author": "Soupisgoodforhealth", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13cs776/how_to_archive_windows_7/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13cs776/how_to_archive_windows_7/", "subreddit_subscribers": 681889, "created_utc": 1683642997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ive just took out from my old pc a 1tb hdd and 1 250gb ssd. Surprisingly the ssd and hdd survived. Most impressive is that the ssd survived for over 5 years without any power. My Old pc was stored in my basement. What i noticed is that the hdd has still 1tb space while the ssd only has 100gb  free space and the other 150gb cells are i guess \"dead\". My question now is, I have currently a backup folder of around 600gb. Is it worth it to make a backup on the old hdd? I allready have a 4tb external ssd and 4tb external hdd with my files backed up to it.", "author_fullname": "t2_am2g29s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 year old ssd and hdd survived", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dk0pl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683706049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ive just took out from my old pc a 1tb hdd and 1 250gb ssd. Surprisingly the ssd and hdd survived. Most impressive is that the ssd survived for over 5 years without any power. My Old pc was stored in my basement. What i noticed is that the hdd has still 1tb space while the ssd only has 100gb  free space and the other 150gb cells are i guess &amp;quot;dead&amp;quot;. My question now is, I have currently a backup folder of around 600gb. Is it worth it to make a backup on the old hdd? I allready have a 4tb external ssd and 4tb external hdd with my files backed up to it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13dk0pl", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Insect54", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13dk0pl/5_year_old_ssd_and_hdd_survived/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13dk0pl/5_year_old_ssd_and_hdd_survived/", "subreddit_subscribers": 681889, "created_utc": 1683706049.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}