{"kind": "Listing", "data": {"after": "t3_13of9eo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud Comparison by simonholdorf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13oaw8m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 155, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 155, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qvdN6zLe7G0B89HD7SowO4gRRw5v3T7fNx_B5GkR6HU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684714441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/k8myhl1bz91b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/k8myhl1bz91b1.jpg?auto=webp&amp;v=enabled&amp;s=26de42f0a93be9c9ce87e97586e393bc3bc69a26", "width": 916, "height": 1387}, "resolutions": [{"url": "https://preview.redd.it/k8myhl1bz91b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b03d3baad23511dd3f94e04e1247d11f6e46a2e", "width": 108, "height": 163}, {"url": "https://preview.redd.it/k8myhl1bz91b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3db1f13e53c7ad7352758f6bbe205f06d66c5b60", "width": 216, "height": 327}, {"url": "https://preview.redd.it/k8myhl1bz91b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ac8ef2fd2078c13d3a74f1813f8696016e29477", "width": 320, "height": 484}, {"url": "https://preview.redd.it/k8myhl1bz91b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f44b7861c6fec0b7a35ae9c2f0e1dec409e18992", "width": 640, "height": 969}], "variants": {}, "id": "Dc4R39cdvIxmHYZ7wJ6eKelCDOIAw_iupStzcpu9To4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13oaw8m", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13oaw8m/cloud_comparison_by_simonholdorf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/k8myhl1bz91b1.jpg", "subreddit_subscribers": 106766, "created_utc": 1684714441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u5y5wno7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL: Thinking in Lambdas (lambda SQL)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13opt23", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/2ZdNvFiwh3gzyLeSI3wmlOz64nkLVRFHgnznsUW5eA4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684759229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "firebolt.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.firebolt.io/blog/sql-thinking-in-lambdas", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?auto=webp&amp;v=enabled&amp;s=a0c39e7b6fa2f90c19b4a6182a3bb5dcd86f8f25", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb9e67bc730f931be2db9fa8916a29d0a8a5666b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cd3bce9f592c4d34341d810ac892108d7e20734", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40a4f5dd4f22a796247fabcef82a244a1b4e848e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75a3348fa5d9b76870d231113136bc396041b84d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bJR1f04rOFfbDlfrV-_7J1wWN-GXNARNyf5F7nf3AMg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82fd0880e023ccc2f567ed1c84268517b360e3b3", "width": 960, "height": 480}], "variants": {}, "id": "t_H3EH9Wu3VVf5CRKXbNGZW7MH06gEVzxIXKs-goYVw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13opt23", "is_robot_indexable": true, "report_reasons": null, "author": "rayhumrib", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13opt23/sql_thinking_in_lambdas_lambda_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.firebolt.io/blog/sql-thinking-in-lambdas", "subreddit_subscribers": 106766, "created_utc": 1684759229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I often come across discussions, articles, and videos comparing Snowflake and Databricks individually, but what about considering the combination of Snowflake and Databricks? From my perspective, I could extract and load all source data from many relational databases into Snowflake for analytical data storage, rather than into Data Lake or Data Lakehouse. Then, within Snowflake, DBT could be utilized to construct data models and marts specifically for traditional reporting and data warehouse workloads. Simultaneously, the data stored in Snowflake could be accessed and analyzed through Databricks for advanced analytics, data science, and machine learning use-cases. I find that this approach would offer the benefits of centralized data management within the warehouse while enabling both BI and ML on the same data, which could be a superior alternative to a Lakehouse architecture.\n\nI guess alternatively, you could ingest/stream data into landing -&gt; bronze -&gt; silver Lakehouse layers and then ETL from silver into a kimball-style warehouse in Snowflake. Not sure which method would be preferred?\n\nSure, I'm familiar with the fact that Databricks, with its Lakehouse architecture, is capable of supporting both data warehousing and machine learning workloads. However, if an organization heavily relies on both of these workloads, I question whether Databricks performs as effectively in the realm of data warehousing compared to Snowflake. Instead of solely relying on one platform, why not leverage both platforms to get the benefits from each and achieve the best possible outcomes?\n\n&amp;#x200B;\n\nEdit: Rephrasing", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Snowflake + Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13otv07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684771352.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684768805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often come across discussions, articles, and videos comparing Snowflake and Databricks individually, but what about considering the combination of Snowflake and Databricks? From my perspective, I could extract and load all source data from many relational databases into Snowflake for analytical data storage, rather than into Data Lake or Data Lakehouse. Then, within Snowflake, DBT could be utilized to construct data models and marts specifically for traditional reporting and data warehouse workloads. Simultaneously, the data stored in Snowflake could be accessed and analyzed through Databricks for advanced analytics, data science, and machine learning use-cases. I find that this approach would offer the benefits of centralized data management within the warehouse while enabling both BI and ML on the same data, which could be a superior alternative to a Lakehouse architecture.&lt;/p&gt;\n\n&lt;p&gt;I guess alternatively, you could ingest/stream data into landing -&amp;gt; bronze -&amp;gt; silver Lakehouse layers and then ETL from silver into a kimball-style warehouse in Snowflake. Not sure which method would be preferred?&lt;/p&gt;\n\n&lt;p&gt;Sure, I&amp;#39;m familiar with the fact that Databricks, with its Lakehouse architecture, is capable of supporting both data warehousing and machine learning workloads. However, if an organization heavily relies on both of these workloads, I question whether Databricks performs as effectively in the realm of data warehousing compared to Snowflake. Instead of solely relying on one platform, why not leverage both platforms to get the benefits from each and achieve the best possible outcomes?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: Rephrasing&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13otv07", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13otv07/anyone_using_snowflake_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13otv07/anyone_using_snowflake_databricks/", "subreddit_subscribers": 106766, "created_utc": 1684768805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Surprise us with some uses of Airflow few of us have heard of!", "author_fullname": "t2_d5urdlpf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some unconventional uses of Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oxcur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684776708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Surprise us with some uses of Airflow few of us have heard of!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13oxcur", "is_robot_indexable": true, "report_reasons": null, "author": "CandidLuck591", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13oxcur/what_are_some_unconventional_uses_of_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13oxcur/what_are_some_unconventional_uses_of_airflow/", "subreddit_subscribers": 106766, "created_utc": 1684776708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had a nice reaction to posting my articles on data modelling last week, so I've tidied up and posted one that's been sitting in my drafts for a while.\n\nThis time it's about [an approach I've been using to bring data from GCP Cloud SQL into BigQuery](\nhttps://medium.com/apolitical-engineering/how-we-use-dbt-and-bigquery-external-connections-to-easily-and-reliably-warehouse-cloud-sql-data-b0f68e873aad).\n\nI admit it's a trifle hacky, but if your needs are simple (small-ish tables, no need for live data or an exact history of changes) then it might help you get up-and-running quickly! At the end of the article I discuss some of the tradeoffs and potential improvements.\n\nAnyway, hope it's of interest.", "author_fullname": "t2_7920orfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery External Queries + DBT = instant pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_13opsn1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tryPWPc8-2-BO8z-yZUhuohNCaCyK-eDAYas54oOs7k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684759203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had a nice reaction to posting my articles on data modelling last week, so I&amp;#39;ve tidied up and posted one that&amp;#39;s been sitting in my drafts for a while.&lt;/p&gt;\n\n&lt;p&gt;This time it&amp;#39;s about &lt;a href=\"https://medium.com/apolitical-engineering/how-we-use-dbt-and-bigquery-external-connections-to-easily-and-reliably-warehouse-cloud-sql-data-b0f68e873aad\"&gt;an approach I&amp;#39;ve been using to bring data from GCP Cloud SQL into BigQuery&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I admit it&amp;#39;s a trifle hacky, but if your needs are simple (small-ish tables, no need for live data or an exact history of changes) then it might help you get up-and-running quickly! At the end of the article I discuss some of the tradeoffs and potential improvements.&lt;/p&gt;\n\n&lt;p&gt;Anyway, hope it&amp;#39;s of interest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/apolitical-engineering/how-we-use-dbt-and-bigquery-external-connections-to-easily-and-reliably-warehouse-cloud-sql-data-b0f68e873aad", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?auto=webp&amp;v=enabled&amp;s=4d57414e3d999a3bce6c591651f9551c6f592aad", "width": 1200, "height": 510}, "resolutions": [{"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1574cbdbdb8714086b6f45c408d6927a3ceaf53d", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8bd04bdf4e0e6ca9ae5382fb6e09f3e7c98863e", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4045ca353e21a124d5328f58dbec7edf6dae8448", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7cbdf8d9824de8db2c3dd0ee108b790078dbd665", "width": 640, "height": 272}, {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836e8e1d074400906b7862c098775d30e552cfa1", "width": 960, "height": 408}, {"url": "https://external-preview.redd.it/MZRIWHP7ZfSiyQ3XVCm5gUJW2QyCT8AWwMAl9aPziI8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1cccd21f34200a8849d46bd4486bd73873cf5871", "width": 1080, "height": 459}], "variants": {}, "id": "29s1amXtE8-XWPjNwjr-V-Mk5Mk1Ba7aHLhirNUOQ1Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13opsn1", "is_robot_indexable": true, "report_reasons": null, "author": "PaddyAlton", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13opsn1/bigquery_external_queries_dbt_instant_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/apolitical-engineering/how-we-use-dbt-and-bigquery-external-connections-to-easily-and-reliably-warehouse-cloud-sql-data-b0f68e873aad", "subreddit_subscribers": 106766, "created_utc": 1684759203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been through a lot A LOT of articles and videos in search of a good hobby project that I can also showcase in my CV (cuz I'm creatively dead rn) and also learn something out of it but everything seems the same. So can anyone tell me what should I do.", "author_fullname": "t2_bpknwjqm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projects for Mid level DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13onc2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684752236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been through a lot A LOT of articles and videos in search of a good hobby project that I can also showcase in my CV (cuz I&amp;#39;m creatively dead rn) and also learn something out of it but everything seems the same. So can anyone tell me what should I do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13onc2y", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Goose-839", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13onc2y/projects_for_mid_level_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13onc2y/projects_for_mid_level_de/", "subreddit_subscribers": 106766, "created_utc": 1684752236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nWe're currently in the process of putting data from different systems in our organisationin our data warehouse. We're running into a bottleneck when it comes to user acceptance testing. As it's manual labour, the end user is only able to test a small sample of our data to see if it's as what they see in their system.\n\nI was wondering if anyone knows of a framework like [https://fitnesse.github.io/fitnessedotorg/](https://fitnesse.github.io/fitnessedotorg/) or [http://watir.com/](http://watir.com/) which can automate the testing of new data attributes in our warehouse?", "author_fullname": "t2_3vwt4864", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a user acceptance testing framework for data products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13otpcl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684768425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently in the process of putting data from different systems in our organisationin our data warehouse. We&amp;#39;re running into a bottleneck when it comes to user acceptance testing. As it&amp;#39;s manual labour, the end user is only able to test a small sample of our data to see if it&amp;#39;s as what they see in their system.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone knows of a framework like &lt;a href=\"https://fitnesse.github.io/fitnessedotorg/\"&gt;https://fitnesse.github.io/fitnessedotorg/&lt;/a&gt; or &lt;a href=\"http://watir.com/\"&gt;http://watir.com/&lt;/a&gt; which can automate the testing of new data attributes in our warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13otpcl", "is_robot_indexable": true, "report_reasons": null, "author": "chonbee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13otpcl/is_there_a_user_acceptance_testing_framework_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13otpcl/is_there_a_user_acceptance_testing_framework_for/", "subreddit_subscribers": 106766, "created_utc": 1684768425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was working with this client for almost 4 months now.\n\nHe hired a DBA full-time one month back.\nFrom then on my headaches started,\n\nThis DBA has only worked with Microsoft's SQL Server his whole life and wanted me to pool all our data sources (Google Sheet, MongoDB and postgresDB )  into one single DB.\n\nI was fine with this pooling of resources into a single place for his convenience sake but what pissed me off that he wanted me to get rid of those existing sources. \n\nIts not like I hate SQL Server, Of all the databases I've worked with SQL Server the most myself. I personally think its the best in SQL world. However, All these sources was created for specific purposes. \n- Google sheets  was like a dashboard to get inventory stats for the client \n- MongoDB was used to dump the initial uncleaned json data\n- Postgres was used to store the final data after cleaning.\n\nThis pipeline was setup perfectly and was working smoothly for all of us.\nTrust me if I could get rid of one them i definitely would but all three were serving their unique purposes. \n\nBut this new DBA guy started putting nonsense in client's head and now the client is questioning the integrity of this data Platform I created. Its ok that requirements change and shit happens but we shouldn't spoil the relationship. \n\nThinking back I can feel  that rejecting the new reporting order costed me a good client.\n\nHe ll come back!", "author_fullname": "t2_6jhkkc1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is multiple data sources a bad thing!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13orbyc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684763033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was working with this client for almost 4 months now.&lt;/p&gt;\n\n&lt;p&gt;He hired a DBA full-time one month back.\nFrom then on my headaches started,&lt;/p&gt;\n\n&lt;p&gt;This DBA has only worked with Microsoft&amp;#39;s SQL Server his whole life and wanted me to pool all our data sources (Google Sheet, MongoDB and postgresDB )  into one single DB.&lt;/p&gt;\n\n&lt;p&gt;I was fine with this pooling of resources into a single place for his convenience sake but what pissed me off that he wanted me to get rid of those existing sources. &lt;/p&gt;\n\n&lt;p&gt;Its not like I hate SQL Server, Of all the databases I&amp;#39;ve worked with SQL Server the most myself. I personally think its the best in SQL world. However, All these sources was created for specific purposes. \n- Google sheets  was like a dashboard to get inventory stats for the client \n- MongoDB was used to dump the initial uncleaned json data\n- Postgres was used to store the final data after cleaning.&lt;/p&gt;\n\n&lt;p&gt;This pipeline was setup perfectly and was working smoothly for all of us.\nTrust me if I could get rid of one them i definitely would but all three were serving their unique purposes. &lt;/p&gt;\n\n&lt;p&gt;But this new DBA guy started putting nonsense in client&amp;#39;s head and now the client is questioning the integrity of this data Platform I created. Its ok that requirements change and shit happens but we shouldn&amp;#39;t spoil the relationship. &lt;/p&gt;\n\n&lt;p&gt;Thinking back I can feel  that rejecting the new reporting order costed me a good client.&lt;/p&gt;\n\n&lt;p&gt;He ll come back!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13orbyc", "is_robot_indexable": true, "report_reasons": null, "author": "Meta-Morpheus-New", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13orbyc/is_multiple_data_sources_a_bad_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13orbyc/is_multiple_data_sources_a_bad_thing/", "subreddit_subscribers": 106766, "created_utc": 1684763033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a use-case where I need to sync changes from Postgres to ElasticSearch. It looks like this is exactly the use-case for Debezium.\n\nIf you've used Debezium to do something similar, I'd love to hear your experience. If you've got a different recommendation, I'd love to hear that as well.", "author_fullname": "t2_gs0mp007", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres Updates to ElasticSearch Using Debezium or other?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oc3sh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684717770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use-case where I need to sync changes from Postgres to ElasticSearch. It looks like this is exactly the use-case for Debezium.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve used Debezium to do something similar, I&amp;#39;d love to hear your experience. If you&amp;#39;ve got a different recommendation, I&amp;#39;d love to hear that as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13oc3sh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomWalk55", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13oc3sh/postgres_updates_to_elasticsearch_using_debezium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13oc3sh/postgres_updates_to_elasticsearch_using_debezium/", "subreddit_subscribers": 106766, "created_utc": 1684717770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've started reading \"The Fundamentals of Data Engineering\" by Joe Reis and Matt Housley, and I'm getting hung up on something. I see that the authors consistently refer to \"analysts and data scientists\" as data consumers, whereas software engineers (and the stuff they build) are more commonly thought of as data producers.\n\nHere's my question: What if software engineers are building features on top of pipelines that data engineering is building? Don't they then become consumers? Isn't this a pretty common pattern? What am I missing?", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are software engineers data consumers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p2f9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684787694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve started reading &amp;quot;The Fundamentals of Data Engineering&amp;quot; by Joe Reis and Matt Housley, and I&amp;#39;m getting hung up on something. I see that the authors consistently refer to &amp;quot;analysts and data scientists&amp;quot; as data consumers, whereas software engineers (and the stuff they build) are more commonly thought of as data producers.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my question: What if software engineers are building features on top of pipelines that data engineering is building? Don&amp;#39;t they then become consumers? Isn&amp;#39;t this a pretty common pattern? What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13p2f9t", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p2f9t/are_software_engineers_data_consumers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p2f9t/are_software_engineers_data_consumers/", "subreddit_subscribers": 106766, "created_utc": 1684787694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks!\n\nI'm going to propose the following plan / solution to my team, but I'm unsure whether it's a reasonable plan or I am completely off here.\n\n&amp;#x200B;\n\nFirst off, we're currently having the following two issues:\n\n* We currently have a lot of ETL/ELT scripts running in different places such as Linux and Windows servers, AWS Lambdas and scheduled queries in AWS Redshift. Consequently, there's no overview anywhere of them and in case anything goes wrong you have to search in many different places to find which one of our scripts failed and why.\n* We currently import all raw data into PowerBI and perform all data transformations and aggregations in PowerBI using PowerQuery/DAX. Since recently, PowerBI crashes during that process because the amount of raw data has simply gotten too large (the entire data warehouse containing all raw data is being imported)\n\n&amp;#x200B;\n\n**Issue 1**\n\nTo solve the 1st issue, I want to suggest using an orchestrator such as Airflow, Prefect or Dagster. Basically my idea is to either use a managed service (e.g. Prefect Cloud) or deploy Prefect on our own infrastructure in AWS. Then rewrite the existing scripts, that are currently running on e.g. Lambda and Linux servers, to a Prefect Flow so you can observe all scripts in Prefect, no matter where they are being run. They could thus stay wherever they are running, but they could be observed in the orchestrator. Does that seem reasonable? Or would it be more ideal to completely rewrite old ETL/ELT scripts to Prefect Flows and schedule them using Prefect but execute them all in the same place, e.g. AWS ECS/Fargate (i.e. take them out of the system they're currently running and execute them somewhere else)?\n\n&amp;#x200B;\n\n**Issue 2**\n\nFor the 2nd issue, I'd suggest using DBT to perform data transformations and aggregations in the data warehouse instead of in PowerBI. That way PowerBI wouldn't have to import raw data anymore, but could instead import the already modelled data (which would be way less).\n\n&amp;#x200B;\n\nLet me know what you guys think of this approach, I hope this seems reasonable!", "author_fullname": "t2_ck4survm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this plan that I'll propose to my team sound reasonable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13othmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684767946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to propose the following plan / solution to my team, but I&amp;#39;m unsure whether it&amp;#39;s a reasonable plan or I am completely off here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;First off, we&amp;#39;re currently having the following two issues:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We currently have a lot of ETL/ELT scripts running in different places such as Linux and Windows servers, AWS Lambdas and scheduled queries in AWS Redshift. Consequently, there&amp;#39;s no overview anywhere of them and in case anything goes wrong you have to search in many different places to find which one of our scripts failed and why.&lt;/li&gt;\n&lt;li&gt;We currently import all raw data into PowerBI and perform all data transformations and aggregations in PowerBI using PowerQuery/DAX. Since recently, PowerBI crashes during that process because the amount of raw data has simply gotten too large (the entire data warehouse containing all raw data is being imported)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issue 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;To solve the 1st issue, I want to suggest using an orchestrator such as Airflow, Prefect or Dagster. Basically my idea is to either use a managed service (e.g. Prefect Cloud) or deploy Prefect on our own infrastructure in AWS. Then rewrite the existing scripts, that are currently running on e.g. Lambda and Linux servers, to a Prefect Flow so you can observe all scripts in Prefect, no matter where they are being run. They could thus stay wherever they are running, but they could be observed in the orchestrator. Does that seem reasonable? Or would it be more ideal to completely rewrite old ETL/ELT scripts to Prefect Flows and schedule them using Prefect but execute them all in the same place, e.g. AWS ECS/Fargate (i.e. take them out of the system they&amp;#39;re currently running and execute them somewhere else)?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issue 2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For the 2nd issue, I&amp;#39;d suggest using DBT to perform data transformations and aggregations in the data warehouse instead of in PowerBI. That way PowerBI wouldn&amp;#39;t have to import raw data anymore, but could instead import the already modelled data (which would be way less).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Let me know what you guys think of this approach, I hope this seems reasonable!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13othmc", "is_robot_indexable": true, "report_reasons": null, "author": "learning_on_the_job", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13othmc/does_this_plan_that_ill_propose_to_my_team_sound/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13othmc/does_this_plan_that_ill_propose_to_my_team_sound/", "subreddit_subscribers": 106766, "created_utc": 1684767946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,     \n\n\nI've been recently following [https://medium.com/@Tonyseale](https://medium.com/@Tonyseale) more closely.     \n\n\nHe advocates for using the schema.org blueprint for data integration and building a distributed knowledge graph using JSON-LD. At the Knowledge Graph Conference one and a half weeks ago, UBS presented exactly that architecture and said that it dramatically sped up their time to get insights from their data. I find the idea quite intriguing.   \n\n\nThere are some companies like Fluree with their Product Fluree Sense, which are going in that direction as well. And from how I understand Eccenca and co. are moving in a similar direction.   However, I am struggling a bit to understand where this fits into the existing data landscape. I think somewhere on top of the data catalogs. (In their talk UBS said, they have 7 data catalogs and built this thing anyways)    \n\n\nWhat are your thoughts, where do you see utility for an approach like this?", "author_fullname": "t2_dnvo7htn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schema.org and JSON-LD for Data Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13okpfh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684743663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,     &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been recently following &lt;a href=\"https://medium.com/@Tonyseale\"&gt;https://medium.com/@Tonyseale&lt;/a&gt; more closely.     &lt;/p&gt;\n\n&lt;p&gt;He advocates for using the schema.org blueprint for data integration and building a distributed knowledge graph using JSON-LD. At the Knowledge Graph Conference one and a half weeks ago, UBS presented exactly that architecture and said that it dramatically sped up their time to get insights from their data. I find the idea quite intriguing.   &lt;/p&gt;\n\n&lt;p&gt;There are some companies like Fluree with their Product Fluree Sense, which are going in that direction as well. And from how I understand Eccenca and co. are moving in a similar direction.   However, I am struggling a bit to understand where this fits into the existing data landscape. I think somewhere on top of the data catalogs. (In their talk UBS said, they have 7 data catalogs and built this thing anyways)    &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts, where do you see utility for an approach like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YdySg72qfdoonk9gXuYQX5iOJI4yUdqSyRYBpK57W3s.jpg?auto=webp&amp;v=enabled&amp;s=dfcf9fa550d83280a7f988dda0d1964e4a408af2", "width": 50, "height": 50}, "resolutions": [], "variants": {}, "id": "NM3BWuVPr8I4Cs7LYS_ViFBkUZeO6-_bHE9jcOe-CPA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13okpfh", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Math5316", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13okpfh/schemaorg_and_jsonld_for_data_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13okpfh/schemaorg_and_jsonld_for_data_integration/", "subreddit_subscribers": 106766, "created_utc": 1684743663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I use Stitch to load customer Google  Analytics data for internal reporting, and I noticed that the new GA4 integration uses 30/60/90 rolling window (based on the conversion window) for loading data - as in reload the data from the last 90 days every day you load data, which makes it an infeasible option, purely due to volumes. I can reduce it to 30, but that is not much better.\n\nDid anyone else encounter this? Am I getting this right? Or am I maybe missing some configuration? \n\nI like Stitch and their UI, especially that they added the 'Clone Integration' feature which allows me to quickly setup a new integration for a new  client. What other options do I have?", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loading GA4 data via Stitch 90x bump data volume compared to the old integration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13omuyd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684750749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use Stitch to load customer Google  Analytics data for internal reporting, and I noticed that the new GA4 integration uses 30/60/90 rolling window (based on the conversion window) for loading data - as in reload the data from the last 90 days every day you load data, which makes it an infeasible option, purely due to volumes. I can reduce it to 30, but that is not much better.&lt;/p&gt;\n\n&lt;p&gt;Did anyone else encounter this? Am I getting this right? Or am I maybe missing some configuration? &lt;/p&gt;\n\n&lt;p&gt;I like Stitch and their UI, especially that they added the &amp;#39;Clone Integration&amp;#39; feature which allows me to quickly setup a new integration for a new  client. What other options do I have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13omuyd", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13omuyd/loading_ga4_data_via_stitch_90x_bump_data_volume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13omuyd/loading_ga4_data_via_stitch_90x_bump_data_volume/", "subreddit_subscribers": 106766, "created_utc": 1684750749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With so many options available in the market(Airflow, Prefect, Dagster, Mage), it can be challenging to choose the right tool for your needs. What are the key criteria that you consider when evaluating orchestration tools? \n\nWe are a mid-size enterprise currently using control-m and looking to move to airflow but we would like to evaluate other tools before deciding on airflow. We are also looking into dbt-core as we are more into ELT, so considering that could you please share your thoughts and experiences with the orchestration tools in the comments below ?\n\nTIA", "author_fullname": "t2_1v4h09lt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the key criteria to consider when evaluating orchestration tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oc1mx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684717601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With so many options available in the market(Airflow, Prefect, Dagster, Mage), it can be challenging to choose the right tool for your needs. What are the key criteria that you consider when evaluating orchestration tools? &lt;/p&gt;\n\n&lt;p&gt;We are a mid-size enterprise currently using control-m and looking to move to airflow but we would like to evaluate other tools before deciding on airflow. We are also looking into dbt-core as we are more into ELT, so considering that could you please share your thoughts and experiences with the orchestration tools in the comments below ?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13oc1mx", "is_robot_indexable": true, "report_reasons": null, "author": "mrcool444", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13oc1mx/what_are_the_key_criteria_to_consider_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13oc1mx/what_are_the_key_criteria_to_consider_when/", "subreddit_subscribers": 106766, "created_utc": 1684717601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm just about to end the free 14 month trial of azure Databricks and I want to keep going but I don't want to spend a fortune.\n\nI'm only ever planning on running a single cluster with a 20 minute timeout, I'll probably have about 50 hours max a month of runtime. It'll be 4 cores \n\nFor data I won't be storing much maybe a few gigs at most.\n\nI'll be in the UK South area.\n\nI know it depends on other variables so I'm not expecting a bang on estimate but would someone be able to give me a ball park figure? Like would it cost less than \u00a35/$5 a month?\n\nMany thanks!", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roughly how much would an azure and azure Databricks account set me back (more info in post)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ovijl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684776436.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684772568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m just about to end the free 14 month trial of azure Databricks and I want to keep going but I don&amp;#39;t want to spend a fortune.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m only ever planning on running a single cluster with a 20 minute timeout, I&amp;#39;ll probably have about 50 hours max a month of runtime. It&amp;#39;ll be 4 cores &lt;/p&gt;\n\n&lt;p&gt;For data I won&amp;#39;t be storing much maybe a few gigs at most.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be in the UK South area.&lt;/p&gt;\n\n&lt;p&gt;I know it depends on other variables so I&amp;#39;m not expecting a bang on estimate but would someone be able to give me a ball park figure? Like would it cost less than \u00a35/$5 a month?&lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ovijl", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ovijl/roughly_how_much_would_an_azure_and_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ovijl/roughly_how_much_would_an_azure_and_azure/", "subreddit_subscribers": 106766, "created_utc": 1684772568.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am struggling to understand this concept. Can someone break it down to me? The pros/cons - what is actually happening behind the scenes and how to do it?", "author_fullname": "t2_90vn3hxrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks File Size Tuning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13osjd9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684765826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am struggling to understand this concept. Can someone break it down to me? The pros/cons - what is actually happening behind the scenes and how to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13osjd9", "is_robot_indexable": true, "report_reasons": null, "author": "Amazing_Individual74", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13osjd9/databricks_file_size_tuning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13osjd9/databricks_file_size_tuning/", "subreddit_subscribers": 106766, "created_utc": 1684765826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/13op0br)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks users, which metastore do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13op0br", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684757156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13op0br\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13op0br", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1685016357007, "options": [{"text": "Built-in Hive Metastore", "id": "23136930"}, {"text": "External Hive Metastore", "id": "23136931"}, {"text": "Unity", "id": "23136932"}, {"text": "See Results", "id": "23136933"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 69, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13op0br/databricks_users_which_metastore_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/13op0br/databricks_users_which_metastore_do_you_use/", "subreddit_subscribers": 106766, "created_utc": 1684757156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a warehouse in Snowflake. There is an Analytics Team that has built the semantic layer in Power BI, and then there is a self-service access to the semantic layer to create reports, plus the team creates 'vetted' reports for the business.\n\nWe've received requests from some areas of the business to access the data warehouse through the Snowflake UI directly.\n\nNot sure how I feel about this. You wouldn't give access to any other database directly. It should all go through an API (or semantic layer). But am I being overly restrictive?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do your users access your DWH?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13oglr5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684730475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a warehouse in Snowflake. There is an Analytics Team that has built the semantic layer in Power BI, and then there is a self-service access to the semantic layer to create reports, plus the team creates &amp;#39;vetted&amp;#39; reports for the business.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve received requests from some areas of the business to access the data warehouse through the Snowflake UI directly.&lt;/p&gt;\n\n&lt;p&gt;Not sure how I feel about this. You wouldn&amp;#39;t give access to any other database directly. It should all go through an API (or semantic layer). But am I being overly restrictive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13oglr5", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13oglr5/how_do_your_users_access_your_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13oglr5/how_do_your_users_access_your_dwh/", "subreddit_subscribers": 106766, "created_utc": 1684730475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a current CS freshman in university, I'm set on becoming a data engineer or cloud architect but I don't know what industry I want to pursue. I know biotech is going to be a big field so I'm learning towards that. What do you guys think? Any other fields I should check out? Or should I abandon programming and pursue another field cause of AI?", "author_fullname": "t2_8yj3ydo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering in BioTech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13p5mhv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684794586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a current CS freshman in university, I&amp;#39;m set on becoming a data engineer or cloud architect but I don&amp;#39;t know what industry I want to pursue. I know biotech is going to be a big field so I&amp;#39;m learning towards that. What do you guys think? Any other fields I should check out? Or should I abandon programming and pursue another field cause of AI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13p5mhv", "is_robot_indexable": true, "report_reasons": null, "author": "Human-Blackberry3325", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p5mhv/data_engineering_in_biotech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p5mhv/data_engineering_in_biotech/", "subreddit_subscribers": 106766, "created_utc": 1684794586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wasn't sure if anyone's done this or if it's possible.\n\nI tried a few methods and guides, but I just end up with a ton of errors.\n\nI was following this video:\n\n[https://www.youtube.com/watch?v=MdW2ZHHJWeo](https://www.youtube.com/watch?v=MdW2ZHHJWeo)\n\nAnd then this guide, which proposes a way to make it work:\n\n[https://medium.com/@benjcabalonajr\\_56579/using-docker-operator-on-airflow-running-inside-a-docker-container-7df5286daaa5](https://medium.com/@benjcabalonajr_56579/using-docker-operator-on-airflow-running-inside-a-docker-container-7df5286daaa5)\n\n&amp;#x200B;\n\nI also tried mounting the docker.sock volumes in the docker-compose.yml, which is supposed to basically mount the one that's running on Ubuntu in the Windows Subsystem for Linux:\n\n\\`\\`\\`\n\nvolumes:  \n\u00a0 \u00a0 \\- ${AIRFLOW\\_PROJ\\_DIR:-.}/dags:/opt/airflow/dags  \n\u00a0 \u00a0 \\- ${AIRFLOW\\_PROJ\\_DIR:-.}/logs:/opt/airflow/logs  \n\u00a0 \u00a0 \\- ${AIRFLOW\\_PROJ\\_DIR:-.}/plugins:/opt/airflow/plugins  \n\u00a0 \u00a0 **- //var/run/docker.sock:/var/run/docker.sock**\n\n\\`\\`\\`\n\n&amp;#x200B;\n\nI tried many versions of my DAG, but here's version 19:\n\n\\`\\`\\`\n\nfrom airflow.decorators import task, dag  \nfrom airflow.providers.docker.operators.docker import DockerOperator  \nfrom datetime import datetime  \nu/dag(dag\\_id='docker\\_operator\\_day\\_v19', start\\_date=datetime(2023, 5, 19), schedule\\_interval='@daily', catchup=False)  \ndef docker\\_dag():  \n\u00a0 \u00a0 u/task  \n def t1():  \n pass  \n\u00a0 \u00a0 t2 = DockerOperator(  \n\u00a0 \u00a0 \u00a0 \u00a0 task\\_id= 't2',  \n\u00a0 \u00a0 \u00a0 \u00a0 image = 'ubuntu',  \n\u00a0 \u00a0 \u00a0 \u00a0 command = 'echo \"comando running in container\"',  \n\u00a0 \u00a0 \u00a0 \u00a0 docker\\_url = 'TCP://docker-socket-proxy:2375',  \n\u00a0 \u00a0 \u00a0 \u00a0 network\\_mode = 'bridge',  \n\u00a0 \u00a0 \u00a0 \u00a0 api\\_version = 'auto'  \n\u00a0 \u00a0 )  \n   \n\u00a0 \u00a0 t1() &gt;&gt; t2\n\ndag = docker\\_dag()\n\n\\`\\`\\`\n\nThe full error I get with Airflow is here:\n\n[https://pastebin.com/kt09dSKT](https://pastebin.com/kt09dSKT)\n\n&amp;#x200B;\n\nI was just trying to see if anyone's gotten this to work on Windows and might have a quick guide on how to do it. If not, I'll probably try it on Linux sometime... or maybe in the Cloud.\n\nI've heard about using PythonOperator, PythonVirtualenvOperator, and ExternalPythonOperator, so maybe one of these will work better in my case?\n\nI'm not doing anything incredibly fancy yet, just trying to get larger Python scripts to run via a DAG. Maybe a web scraper that would run daily, or an ETL processing script written in Python that connects with Snowflake, for example.\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_cj9cv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerOperator with Airflow running on Docker - on Windows 11 with WSL? Alternative to DockerOperator to run larger Python Scripts (ex. A Daily Webscraper?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13p0v30", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684784345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t sure if anyone&amp;#39;s done this or if it&amp;#39;s possible.&lt;/p&gt;\n\n&lt;p&gt;I tried a few methods and guides, but I just end up with a ton of errors.&lt;/p&gt;\n\n&lt;p&gt;I was following this video:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=MdW2ZHHJWeo\"&gt;https://www.youtube.com/watch?v=MdW2ZHHJWeo&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And then this guide, which proposes a way to make it work:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@benjcabalonajr_56579/using-docker-operator-on-airflow-running-inside-a-docker-container-7df5286daaa5\"&gt;https://medium.com/@benjcabalonajr_56579/using-docker-operator-on-airflow-running-inside-a-docker-container-7df5286daaa5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also tried mounting the docker.sock volumes in the docker-compose.yml, which is supposed to basically mount the one that&amp;#39;s running on Ubuntu in the Windows Subsystem for Linux:&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;volumes:&lt;br/&gt;\n\u00a0 \u00a0 - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags&lt;br/&gt;\n\u00a0 \u00a0 - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs&lt;br/&gt;\n\u00a0 \u00a0 - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins&lt;br/&gt;\n\u00a0 \u00a0 &lt;strong&gt;- //var/run/docker.sock:/var/run/docker.sock&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I tried many versions of my DAG, but here&amp;#39;s version 19:&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;from airflow.decorators import task, dag&lt;br/&gt;\nfrom airflow.providers.docker.operators.docker import DockerOperator&lt;br/&gt;\nfrom datetime import datetime&lt;br/&gt;\n&lt;a href=\"/u/dag\"&gt;u/dag&lt;/a&gt;(dag_id=&amp;#39;docker_operator_day_v19&amp;#39;, start_date=datetime(2023, 5, 19), schedule_interval=&amp;#39;@daily&amp;#39;, catchup=False)&lt;br/&gt;\ndef docker_dag():&lt;br/&gt;\n\u00a0 \u00a0 &lt;a href=\"/u/task\"&gt;u/task&lt;/a&gt;&lt;br/&gt;\n def t1():&lt;br/&gt;\n pass&lt;br/&gt;\n\u00a0 \u00a0 t2 = DockerOperator(&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 task_id= &amp;#39;t2&amp;#39;,&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 image = &amp;#39;ubuntu&amp;#39;,&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 command = &amp;#39;echo &amp;quot;comando running in container&amp;quot;&amp;#39;,&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 docker_url = &amp;#39;TCP://docker-socket-proxy:2375&amp;#39;,&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 network_mode = &amp;#39;bridge&amp;#39;,&lt;br/&gt;\n\u00a0 \u00a0 \u00a0 \u00a0 api_version = &amp;#39;auto&amp;#39;&lt;br/&gt;\n\u00a0 \u00a0 )  &lt;/p&gt;\n\n&lt;p&gt;\u00a0 \u00a0 t1() &amp;gt;&amp;gt; t2&lt;/p&gt;\n\n&lt;p&gt;dag = docker_dag()&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;The full error I get with Airflow is here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/kt09dSKT\"&gt;https://pastebin.com/kt09dSKT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was just trying to see if anyone&amp;#39;s gotten this to work on Windows and might have a quick guide on how to do it. If not, I&amp;#39;ll probably try it on Linux sometime... or maybe in the Cloud.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard about using PythonOperator, PythonVirtualenvOperator, and ExternalPythonOperator, so maybe one of these will work better in my case?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not doing anything incredibly fancy yet, just trying to get larger Python scripts to run via a DAG. Maybe a web scraper that would run daily, or an ETL processing script written in Python that connects with Snowflake, for example.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yjHFsBDVP5pfbnngcGVBbqDiWkT5EyCutXYIi2DQ4iM.jpg?auto=webp&amp;v=enabled&amp;s=39413dfb3b3dafdc78d0cb77bde7a4b597d03907", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yjHFsBDVP5pfbnngcGVBbqDiWkT5EyCutXYIi2DQ4iM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68885ad89ddbc748e7d1e89e25666a4835997a65", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yjHFsBDVP5pfbnngcGVBbqDiWkT5EyCutXYIi2DQ4iM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66b2347f7222f007d261e49d3c60e1868b523b75", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yjHFsBDVP5pfbnngcGVBbqDiWkT5EyCutXYIi2DQ4iM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=141cbc404b630da9d9b8c1cd4f96fee601147896", "width": 320, "height": 240}], "variants": {}, "id": "n6KH7ikfvbnYupRJscmElypgfNCDjod9IwOF6n-ONQc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13p0v30", "is_robot_indexable": true, "report_reasons": null, "author": "Vladz0r", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13p0v30/dockeroperator_with_airflow_running_on_docker_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13p0v30/dockeroperator_with_airflow_running_on_docker_on/", "subreddit_subscribers": 106766, "created_utc": 1684784345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a data analyst for a smaller consulting agency for just under a year, I made a career switch from the education field before starting my current role. My goal initially was to stay with my current company for 1.5 - 2ish years and move on to another DA or other data related role, I came across this reddit and started to learn more about DE and that's the career path I'd like to continue on. \n\nCurrently my position on this project is Analytics Engineering-ish, I've been using DBT, learning about snowflake and data warehousing and even some BI work through Qlik Sense. I feel like this has been a really good first project for myself considering I'm still very new to the data field. I still have plenty to learn and feel like I'm trending upward and starting to gain a little more confidence in my day to day tasks. \n\nI know there are plenty of \"how do I go from Analyst to DE?\" posts on this reddit and that's not the advice I'm looking for, I feel like I'm on the right track in terms of learning skills to make that transition and all the materials and posts in this subreddit have been really helpful. I feel like my professional development isn't great and am wondering how I can improve the situation at my current company or are these things red flags and I should be applying to other orgs for better professional development?\n\nSome examples that frustrate/worry me about my professional development:\n\n* my manager constantly bumps our 1 on 1s. They used to be every week now they're every other week and are always rescheduled. When I do actually have them I try to update him on what I've been working on so I can practice explaining the process and answering questions to fill in the gaps. I don't every really get feedback on my performance or areas I can improve on unless it's a formal review which is conducted every 6 months (I'm coming up on my 2nd review here in the next few weeks)\n* The lead on the project can be condescending to myself and other team members while in front of clients. He's got a sarcastic personality and maybe I'm just being soft but verbatim in a meeting with the client \"I'm sorry I do this to you **my name**, but I'm really good at it\" and what he's good at is talking/taking over a demo when he asked me to do/show something on a call with the client and he just does it himself. When I ask him for feedback he mentions how he wants me to engage with the client more.\n* The lead also tends to take on everything himself and when I ask for clarifications on tasks through MS teams I get spammed with 5 different answers in succession. Very often it's difficult for me to follow and will make me even more confused.\n\nI'm sure there's other little things but these are my major pain points when it comes to my job, and of course nowhere is perfect to work, but are these serious red flags? Has anyone had similar situations and have advice on how to navigate them or should I just start looking elsewhere?\n\nThanks in advance!", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How/Should I Move on from Data Analyst Role with Current Consulting Org", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13owqlg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684775333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a data analyst for a smaller consulting agency for just under a year, I made a career switch from the education field before starting my current role. My goal initially was to stay with my current company for 1.5 - 2ish years and move on to another DA or other data related role, I came across this reddit and started to learn more about DE and that&amp;#39;s the career path I&amp;#39;d like to continue on. &lt;/p&gt;\n\n&lt;p&gt;Currently my position on this project is Analytics Engineering-ish, I&amp;#39;ve been using DBT, learning about snowflake and data warehousing and even some BI work through Qlik Sense. I feel like this has been a really good first project for myself considering I&amp;#39;m still very new to the data field. I still have plenty to learn and feel like I&amp;#39;m trending upward and starting to gain a little more confidence in my day to day tasks. &lt;/p&gt;\n\n&lt;p&gt;I know there are plenty of &amp;quot;how do I go from Analyst to DE?&amp;quot; posts on this reddit and that&amp;#39;s not the advice I&amp;#39;m looking for, I feel like I&amp;#39;m on the right track in terms of learning skills to make that transition and all the materials and posts in this subreddit have been really helpful. I feel like my professional development isn&amp;#39;t great and am wondering how I can improve the situation at my current company or are these things red flags and I should be applying to other orgs for better professional development?&lt;/p&gt;\n\n&lt;p&gt;Some examples that frustrate/worry me about my professional development:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;my manager constantly bumps our 1 on 1s. They used to be every week now they&amp;#39;re every other week and are always rescheduled. When I do actually have them I try to update him on what I&amp;#39;ve been working on so I can practice explaining the process and answering questions to fill in the gaps. I don&amp;#39;t every really get feedback on my performance or areas I can improve on unless it&amp;#39;s a formal review which is conducted every 6 months (I&amp;#39;m coming up on my 2nd review here in the next few weeks)&lt;/li&gt;\n&lt;li&gt;The lead on the project can be condescending to myself and other team members while in front of clients. He&amp;#39;s got a sarcastic personality and maybe I&amp;#39;m just being soft but verbatim in a meeting with the client &amp;quot;I&amp;#39;m sorry I do this to you &lt;strong&gt;my name&lt;/strong&gt;, but I&amp;#39;m really good at it&amp;quot; and what he&amp;#39;s good at is talking/taking over a demo when he asked me to do/show something on a call with the client and he just does it himself. When I ask him for feedback he mentions how he wants me to engage with the client more.&lt;/li&gt;\n&lt;li&gt;The lead also tends to take on everything himself and when I ask for clarifications on tasks through MS teams I get spammed with 5 different answers in succession. Very often it&amp;#39;s difficult for me to follow and will make me even more confused.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s other little things but these are my major pain points when it comes to my job, and of course nowhere is perfect to work, but are these serious red flags? Has anyone had similar situations and have advice on how to navigate them or should I just start looking elsewhere?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13owqlg", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13owqlg/howshould_i_move_on_from_data_analyst_role_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13owqlg/howshould_i_move_on_from_data_analyst_role_with/", "subreddit_subscribers": 106766, "created_utc": 1684775333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am using dbterd python library to generate a .dbml file based off my relationship tests in dbt. \n\nIdeally I want to do the first option or second. \n\n1) generate an html file that enables zoom as host ur in a gcp bucket, so u can just overwrite a new html file on every new pull (to capture new tables in ERD)\n\n2) Create image of ERD based of .dbml file and have that image saved in dbt documentation descriptions area. \n\n\nThe issue I am having is scripting in python to create ERD from and .dbml. I know there are commercial softwares like dbdocs that handle this but I want to use cli and have sort of automated ci. \nAlso I know about /dbml-renderer library on GitHub but the svg file is bad experience to interact with. \n\n\nAny thoughts from anyone who built a solution like this ?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate Generation of ERD based off .dbml file? (Apart of ci/cd)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ownys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684777975.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684775175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using dbterd python library to generate a .dbml file based off my relationship tests in dbt. &lt;/p&gt;\n\n&lt;p&gt;Ideally I want to do the first option or second. &lt;/p&gt;\n\n&lt;p&gt;1) generate an html file that enables zoom as host ur in a gcp bucket, so u can just overwrite a new html file on every new pull (to capture new tables in ERD)&lt;/p&gt;\n\n&lt;p&gt;2) Create image of ERD based of .dbml file and have that image saved in dbt documentation descriptions area. &lt;/p&gt;\n\n&lt;p&gt;The issue I am having is scripting in python to create ERD from and .dbml. I know there are commercial softwares like dbdocs that handle this but I want to use cli and have sort of automated ci. \nAlso I know about /dbml-renderer library on GitHub but the svg file is bad experience to interact with. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts from anyone who built a solution like this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ownys", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ownys/automate_generation_of_erd_based_off_dbml_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ownys/automate_generation_of_erd_based_off_dbml_file/", "subreddit_subscribers": 106766, "created_utc": 1684775175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_oayms61l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Scalable and Reliable Machine Learning Systems \u2013 DataTalks.Club", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "name": "t3_13olvtn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a9KLt28m18Uz3-aEudgRj3Fk-t43vQA895sbMSk7guw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684747646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datatalks.club", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datatalks.club/podcast/s14e01-building-scalable-and-reliable-machine-learning-systems.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/joWo1RXebnJ0xiKs_O6b5KeDRwtqkQyOIqbKsmggEtA.jpg?auto=webp&amp;v=enabled&amp;s=02a4553fe8bb6b0823e33915acb86bf3b7a2233e", "width": 940, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/joWo1RXebnJ0xiKs_O6b5KeDRwtqkQyOIqbKsmggEtA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3217fd5878686ab6b6b31d6a441b8c474f3d805a", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/joWo1RXebnJ0xiKs_O6b5KeDRwtqkQyOIqbKsmggEtA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90f9ff2ed70b3e0b7c3cd2059b8e1f6256f3ee6b", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/joWo1RXebnJ0xiKs_O6b5KeDRwtqkQyOIqbKsmggEtA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=602ad00b01000c35b9b8f3f3373020817c278034", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/joWo1RXebnJ0xiKs_O6b5KeDRwtqkQyOIqbKsmggEtA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5d30eb4e891d0ad2432b90e5c9e1ad57664dccd", "width": 640, "height": 374}], "variants": {}, "id": "UiBUn0DY0z3ggGnOcVNIOQlXbXj_3EnXAv6TWx9WH6M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13olvtn", "is_robot_indexable": true, "report_reasons": null, "author": "StjepanJ", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13olvtn/building_scalable_and_reliable_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datatalks.club/podcast/s14e01-building-scalable-and-reliable-machine-learning-systems.html", "subreddit_subscribers": 106766, "created_utc": 1684747646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to Move from Batch to Streaming (DataCouncil Talk)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13obwks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qJ3PWyx7w2Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qJ3PWyx7w2Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax\"&gt;&lt;/iframe&gt;", "author_name": "Data Council", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/qJ3PWyx7w2Q/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataCouncil"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qJ3PWyx7w2Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13obwks", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/05f0G73-jlXxR0hWwE_Hq_x7NMtp3_NMGlFScICUVaU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684717234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=qJ3PWyx7w2Q", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZqjOEr-vv3rEJBpDSftGK9zkbAkRBoxs43j2Y1OGpUg.jpg?auto=webp&amp;v=enabled&amp;s=de62769e27913477e485c7b507e8effb4ea94688", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ZqjOEr-vv3rEJBpDSftGK9zkbAkRBoxs43j2Y1OGpUg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c3e1254c6b9083053e6b6a1a938d39eba86f650", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ZqjOEr-vv3rEJBpDSftGK9zkbAkRBoxs43j2Y1OGpUg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd9337ab29e5f7bb91b0adddb8cb43ac7b5f895c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ZqjOEr-vv3rEJBpDSftGK9zkbAkRBoxs43j2Y1OGpUg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7ba64aa6e8b12e9927c769eaff47d48ab769924", "width": 320, "height": 240}], "variants": {}, "id": "VtF24KzqdYGBTXtjZU4EcQYVXkPIE6p0EhoQ0_pyxM8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13obwks", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13obwks/when_to_move_from_batch_to_streaming_datacouncil/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=qJ3PWyx7w2Q", "subreddit_subscribers": 106766, "created_utc": 1684717234.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qJ3PWyx7w2Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"When to Move from Batch to Streaming and how to do it without hiring an entirely new team | Bytewax\"&gt;&lt;/iframe&gt;", "author_name": "Data Council", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/qJ3PWyx7w2Q/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataCouncil"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just landed my first job as a data engineer (coming from analytics). Now, this new company is in an industry I am completely new to, but I want to learn our data lineage quickly, unfortunately I was made aware that the team doesn't have one and it's not a high priority. Does anyone have any tips on learning the data lineage without having a tool that shows it?", "author_fullname": "t2_vzxrztxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips for picking up on a new data landscape?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13of9eo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684726495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just landed my first job as a data engineer (coming from analytics). Now, this new company is in an industry I am completely new to, but I want to learn our data lineage quickly, unfortunately I was made aware that the team doesn&amp;#39;t have one and it&amp;#39;s not a high priority. Does anyone have any tips on learning the data lineage without having a tool that shows it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13of9eo", "is_robot_indexable": true, "report_reasons": null, "author": "da_muffin_man_12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13of9eo/tips_for_picking_up_on_a_new_data_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13of9eo/tips_for_picking_up_on_a_new_data_landscape/", "subreddit_subscribers": 106766, "created_utc": 1684726495.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}