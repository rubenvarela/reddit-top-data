{"kind": "Listing", "data": {"after": "t3_13j87ao", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13jgov7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 103, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BHwzDmr6d7s/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13jgov7", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 103, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1wy2crkMHl-uwJdEw5K2gTWbL8yH_Jt--rSBRFSQBQI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684269901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=BHwzDmr6d7s", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?auto=webp&amp;v=enabled&amp;s=283a9b291bf0f4f79d93e128c510eb93c3920ca7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d76cd5eb6637fbe0ea0c9556e61d4ae524072eca", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f55f62c00226bd292ff2d6cfc891a70ab32cfd98", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6fa4725dfb0269acd769825ea2d71f0f69df305", "width": 320, "height": 240}], "variants": {}, "id": "vzJx_S3Oc0eW55Awi7t0McsvyL755J93HnRQ0TGOnZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jgov7", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jgov7/secret_to_optimizing_sql_queries_understand_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=BHwzDmr6d7s", "subreddit_subscribers": 105866, "created_utc": 1684269901.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BHwzDmr6d7s/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fuypuqcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Version Control Data Pipelines Using the Medallion Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_13j2kyc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4fL9huhf2PyrPEJRPEpphtB3u7qvfR3hbr_w3Ey3Nhw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684236738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/version-control-data-pipelines-medallion-architecture/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?auto=webp&amp;v=enabled&amp;s=0798ce0b32b898304ff3f7ada66636c1e5ddd062", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8deaf3521f5ad2ac56520c6d1fd827175bd8ff1c", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae6983711b568f74bbaa0db43d3e6871a6a455a6", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/ZuFFsUSvoNFmiwMEClAd4iA3wKC8Dqlbs8-G2xTLOXE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=372e4fecde84db7d9f5acf12715619be3c31fa8d", "width": 320, "height": 274}], "variants": {}, "id": "_bkpW0AXYJ9FWCIiGSYjujhYfz_Us5R6mF_dVLAssLE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13j2kyc", "is_robot_indexable": true, "report_reasons": null, "author": "towtoo893", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2kyc/version_control_data_pipelines_using_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/version-control-data-pipelines-medallion-architecture/", "subreddit_subscribers": 105866, "created_utc": 1684236738.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To those using Snowpark in addition or as a replacement to pySpark, how has your experience been? \nMy organization is looking at Snowpark and Snowflake is pushing hard for us to move away from Databricks.", "author_fullname": "t2_bjfbzxo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts About Snowpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j4dch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684241532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To those using Snowpark in addition or as a replacement to pySpark, how has your experience been? \nMy organization is looking at Snowpark and Snowflake is pushing hard for us to move away from Databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j4dch", "is_robot_indexable": true, "report_reasons": null, "author": "booyahtech", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13j4dch/thoughts_about_snowpark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j4dch/thoughts_about_snowpark/", "subreddit_subscribers": 105866, "created_utc": 1684241532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all - I just got my first \"big\" job as a data engineer for a large corporation. I thought I would enjoy the stability, but I find I'm getting pretty stressed out by the constant pressure to hit corporate targets. I'm thinking about looking for a better fit, but I haven't even been here for a year yet. I don't know if I should stick it out, change my mindset, or look for something else and risk being a \"job-hopper\". What do you think? Thanks for your help.", "author_fullname": "t2_mgkmuyar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I don't like my job, should I job-hop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j5kn6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684244476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - I just got my first &amp;quot;big&amp;quot; job as a data engineer for a large corporation. I thought I would enjoy the stability, but I find I&amp;#39;m getting pretty stressed out by the constant pressure to hit corporate targets. I&amp;#39;m thinking about looking for a better fit, but I haven&amp;#39;t even been here for a year yet. I don&amp;#39;t know if I should stick it out, change my mindset, or look for something else and risk being a &amp;quot;job-hopper&amp;quot;. What do you think? Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j5kn6", "is_robot_indexable": true, "report_reasons": null, "author": "calamari_gringo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j5kn6/if_i_dont_like_my_job_should_i_jobhop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j5kn6/if_i_dont_like_my_job_should_i_jobhop/", "subreddit_subscribers": 105866, "created_utc": 1684244476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering because it seems the interview process at my company changed to be much more difficult for engineers at my level.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would anyone else not pass the interview process at their current company if they interviewed today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j3493", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684238298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering because it seems the interview process at my company changed to be much more difficult for engineers at my level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j3493", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j3493/would_anyone_else_not_pass_the_interview_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j3493/would_anyone_else_not_pass_the_interview_process/", "subreddit_subscribers": 105866, "created_utc": 1684238298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We extract data from 70-ish external systems (via REST) every few minutes and push the raw data to Kafka topics for downstream transformation/processing. We're facing some significant refactoring and I want to look at alternatives to our large, homegrown codebase.\n\nI'm looking to understand what options work well to query from REST APIs, perform some config-based transforms in memory and load to Kafka. It looks like Airbyte and FiveTran use ELT and transform using DBT, this may not be a fit for us considering we're really looking for micro-batch or stream transformations. \n\nWhat works well for you in a similar scenario?", "author_fullname": "t2_gs0mp007", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for Extract/Transform of data from REST APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j69kh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684246078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We extract data from 70-ish external systems (via REST) every few minutes and push the raw data to Kafka topics for downstream transformation/processing. We&amp;#39;re facing some significant refactoring and I want to look at alternatives to our large, homegrown codebase.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to understand what options work well to query from REST APIs, perform some config-based transforms in memory and load to Kafka. It looks like Airbyte and FiveTran use ELT and transform using DBT, this may not be a fit for us considering we&amp;#39;re really looking for micro-batch or stream transformations. &lt;/p&gt;\n\n&lt;p&gt;What works well for you in a similar scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j69kh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomWalk55", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j69kh/what_do_you_use_for_extracttransform_of_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j69kh/what_do_you_use_for_extracttransform_of_data_from/", "subreddit_subscribers": 105866, "created_utc": 1684246078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have y'all ever had a time where your data warehouses were not optimized, that lead to extremely high costs ? E.g. Bad queries, Duplicated data etc. If so, what was it and how did you fix it ?", "author_fullname": "t2_2urj7hkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jqqz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684296026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have y&amp;#39;all ever had a time where your data warehouses were not optimized, that lead to extremely high costs ? E.g. Bad queries, Duplicated data etc. If so, what was it and how did you fix it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jqqz3", "is_robot_indexable": true, "report_reasons": null, "author": "sman1235678", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jqqz3/data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jqqz3/data_warehouse/", "subreddit_subscribers": 105866, "created_utc": 1684296026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now we use Informatica to orchestrate and load data from source databases and load into our target warehouse.  Say we'd like to switch to a code based stack such as Prefect/Airflow + Python EL.  What are the logistical constraints to consider? We're doing nightly batch loads ranging from 1 - 300m rows, with occasional 10b+ rows for one-time initial table loads. Less than 1000 tables total.  Say we'd like to write some basic parallelization utilizing multi-threading (something like concurrent futures) to be able to EL more than 1 table at a time.  Ideally we'd use Airflow to orchestrate, and use SSH operators to execute python scripts on a specified executor vm (out of multiple boxes) utilizing PyArrow or Polars. Is Spark needed to read source tables into a dataframe, and write it into the target database?", "author_fullname": "t2_4rifsjav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do we need Spark if we're just loading data from source to target? Trying to move away from Informatica", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j5syd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684245018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now we use Informatica to orchestrate and load data from source databases and load into our target warehouse.  Say we&amp;#39;d like to switch to a code based stack such as Prefect/Airflow + Python EL.  What are the logistical constraints to consider? We&amp;#39;re doing nightly batch loads ranging from 1 - 300m rows, with occasional 10b+ rows for one-time initial table loads. Less than 1000 tables total.  Say we&amp;#39;d like to write some basic parallelization utilizing multi-threading (something like concurrent futures) to be able to EL more than 1 table at a time.  Ideally we&amp;#39;d use Airflow to orchestrate, and use SSH operators to execute python scripts on a specified executor vm (out of multiple boxes) utilizing PyArrow or Polars. Is Spark needed to read source tables into a dataframe, and write it into the target database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j5syd", "is_robot_indexable": true, "report_reasons": null, "author": "Techthrowaway2222888", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j5syd/do_we_need_spark_if_were_just_loading_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j5syd/do_we_need_spark_if_were_just_loading_data_from/", "subreddit_subscribers": 105866, "created_utc": 1684245018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gej5riou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All you need is data and functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jtjso", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684304683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mckayla.blog", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jtjso", "is_robot_indexable": true, "report_reasons": null, "author": "gemconbet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jtjso/all_you_need_is_data_and_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "subreddit_subscribers": 105866, "created_utc": 1684304683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the risk of being on the job market after the contract ends\u2026", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think it\u2019s worth accepting a contract to hire position to break into the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jr35m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684296978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the risk of being on the job market after the contract ends\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jr35m", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13jr35m/do_you_think_its_worth_accepting_a_contract_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jr35m/do_you_think_its_worth_accepting_a_contract_to/", "subreddit_subscribers": 105866, "created_utc": 1684296978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I generally understand the usefulness of data lakes for large append-only datasets (sensor data, logs, etc). But what about for large datasets that experience updates and deletions regularly?\n\nI know newer file-based engines can handle updates, deletes and upserts transactionally but I can\u2019t help but wonder\u2026 why? Why not use a DBMS as the repository for data that\u2019s going to be constantly in flux? They\u2019ve worked well for such purposes for decades.\n\nManagement loves the sales pitches on data lakes and I\u2019m just not seeing it for the data we work with.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lakes for Changing Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jmyaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684285621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I generally understand the usefulness of data lakes for large append-only datasets (sensor data, logs, etc). But what about for large datasets that experience updates and deletions regularly?&lt;/p&gt;\n\n&lt;p&gt;I know newer file-based engines can handle updates, deletes and upserts transactionally but I can\u2019t help but wonder\u2026 why? Why not use a DBMS as the repository for data that\u2019s going to be constantly in flux? They\u2019ve worked well for such purposes for decades.&lt;/p&gt;\n\n&lt;p&gt;Management loves the sales pitches on data lakes and I\u2019m just not seeing it for the data we work with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jmyaw", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jmyaw/data_lakes_for_changing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jmyaw/data_lakes_for_changing_data/", "subreddit_subscribers": 105866, "created_utc": 1684285621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I\u2019ve been trying to emulate the behavior of a dynamic window,  as Flink does not support dynamic window sizes. My operator inherits from KeyedProcessFunction, and I\u2019m only using KeyedStates to manipulate the window\\_size. I\u2019m clearing the KeyedStates when my bucket(window) is complete, to reset the bucket size.\n\nMy concern is, as Flink does not support dynamic windows, is this approach going against Flink Architecture?  Like will it break checkpointing mechanism in distributed systems? It's been noted that I\u2019m only using KeyedStates for maintaining or implementing the dynamic window.", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamic Windowing in Apache Flink", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j2j00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684236589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019ve been trying to emulate the behavior of a dynamic window,  as Flink does not support dynamic window sizes. My operator inherits from KeyedProcessFunction, and I\u2019m only using KeyedStates to manipulate the window_size. I\u2019m clearing the KeyedStates when my bucket(window) is complete, to reset the bucket size.&lt;/p&gt;\n\n&lt;p&gt;My concern is, as Flink does not support dynamic windows, is this approach going against Flink Architecture?  Like will it break checkpointing mechanism in distributed systems? It&amp;#39;s been noted that I\u2019m only using KeyedStates for maintaining or implementing the dynamic window.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j2j00", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2j00/dynamic_windowing_in_apache_flink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j2j00/dynamic_windowing_in_apache_flink/", "subreddit_subscribers": 105866, "created_utc": 1684236589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Kestra, a Declarative Orchestration Alternative to Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 39, "top_awarded_type": null, "hide_score": false, "name": "t3_13j2c79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EWZ2vBZGK0DemPEM-wVbeHgEh730S5kDAD3Pz478AYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684236014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.devgenius.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.devgenius.io/introduction-to-kestra-a-declarative-orchestration-alternative-to-apache-airflow-10eaac05143d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?auto=webp&amp;v=enabled&amp;s=8f9ebe39b4b1002e65750c49d3ee6b7a9bbe3305", "width": 1200, "height": 337}, "resolutions": [{"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67597e808aa102d6452eb105e0fc7fbe7f24094c", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ac0677271bb054ed12cac6e30e70cc3e0bff259", "width": 216, "height": 60}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1a039af4ef88b0f0b62a54c1a3ec507462a2cb2", "width": 320, "height": 89}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72b6c84574eecc20175bb7b31c4c78f687660c83", "width": 640, "height": 179}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3712f8b3a1f958da94344dafc6a67db37afd2753", "width": 960, "height": 269}, {"url": "https://external-preview.redd.it/eSPTx2J8I2vLbZ71GveAN-Mix50n9QFuEpPJjDAgOIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6dee55c17679a7491698ecf8edff5d6acfcdaad", "width": 1080, "height": 303}], "variants": {}, "id": "FJAaQpsUIhM9-ETXbiwIyUjoau521Tql_4jveeqBNjY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13j2c79", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j2c79/introduction_to_kestra_a_declarative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.devgenius.io/introduction-to-kestra-a-declarative-orchestration-alternative-to-apache-airflow-10eaac05143d", "subreddit_subscribers": 105866, "created_utc": 1684236014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_g3jo5zvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT Data Breach BreakDown - Why it Should be a Concern for Everyone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13jtiaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/YVkgluFKNSs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"ChatGPT Data Breach Break Down\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "ChatGPT Data Breach Break Down", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/YVkgluFKNSs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"ChatGPT Data Breach Break Down\"&gt;&lt;/iframe&gt;", "author_name": "GitGuardian", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/YVkgluFKNSs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GitGuardian"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/YVkgluFKNSs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"ChatGPT Data Breach Break Down\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13jtiaj", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d2vknKQU9la4cg4oE0-zQqSfXc5BX9m5ses76aiwoJE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684304542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=YVkgluFKNSs&amp;feature=youtu.be", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lLR7xHLGm08Jof5Mvgz2ux-h9MOBEYbXgOFgCmSTWCg.jpg?auto=webp&amp;v=enabled&amp;s=3b8842f9175c7a5845284269738ab223395fdc91", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/lLR7xHLGm08Jof5Mvgz2ux-h9MOBEYbXgOFgCmSTWCg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ded19994d05c9bc4698cd0f282b16269b6492b3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/lLR7xHLGm08Jof5Mvgz2ux-h9MOBEYbXgOFgCmSTWCg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87e00de777f10e296700a3eb7b472b5c3f9ca1b7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/lLR7xHLGm08Jof5Mvgz2ux-h9MOBEYbXgOFgCmSTWCg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4163cbf2bcc334b373ed5a2d8423c6a677d53ef", "width": 320, "height": 240}], "variants": {}, "id": "8pJZr_59EM51MFYEOrr9B8zQdSsKhAPY4pNrOZ5scgA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jtiaj", "is_robot_indexable": true, "report_reasons": null, "author": "wetskydig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jtiaj/chatgpt_data_breach_breakdown_why_it_should_be_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=YVkgluFKNSs&amp;feature=youtu.be", "subreddit_subscribers": 105866, "created_utc": 1684304542.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "ChatGPT Data Breach Break Down", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/YVkgluFKNSs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"ChatGPT Data Breach Break Down\"&gt;&lt;/iframe&gt;", "author_name": "GitGuardian", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/YVkgluFKNSs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GitGuardian"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "create  a data structure to retain all data from ETFs and stocks(  [https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset](https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset).) with the following columns.Symbol: string Security Name: string Date: string (YYYY-MM-DD) Open: float High: float Low: float Close: float Adj Close: float Volume: Number \n\ncan someone explain how to do this ?", "author_fullname": "t2_8vmwwx5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jql74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684295575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;create  a data structure to retain all data from ETFs and stocks(  &lt;a href=\"https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset\"&gt;https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset&lt;/a&gt;.) with the following columns.Symbol: string Security Name: string Date: string (YYYY-MM-DD) Open: float High: float Low: float Close: float Adj Close: float Volume: Number &lt;/p&gt;\n\n&lt;p&gt;can someone explain how to do this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?auto=webp&amp;v=enabled&amp;s=90570b8b5a3ef645cb8162a0cbfddb80018a66b1", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62e4010b88a37d4a3327a4774c1436827a9c6865", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b40cbaf19f365c54d6427c317e34fcacfb605e6f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e943b1387cc34d08b8e5070ef0b4b8f60da4551", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02cd337bfd9bfff54cb5461d974d7920142a2fdd", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=118ecd851a4165832fb68f76bd4ed7a2f7a80f9c", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/Wcr58UvQuIdk1D9M4FtmCxvkuTJ2WCY2h1Wfp-odHpc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d5ee8d30eda11c63abc433c1f0aa8485c486a08", "width": 1080, "height": 1080}], "variants": {}, "id": "C5dZJvhjcxHUMEfGZa5JACdMneAbDqDEIEBTaC-M7vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jql74", "is_robot_indexable": true, "report_reasons": null, "author": "lifealtering111", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jql74/data_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jql74/data_processing/", "subreddit_subscribers": 105866, "created_utc": 1684295575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Moving my way through interview rounds for a DE role at my current healthcare company. Part of my role would require support duty and on call. I don\u2019t mind as I already do this as a Business Analyst, but I would find it more interesting since it\u2019s related to data rather than Epic.  My org uses service now so I assume it would be the same for this operations team. \n\nWhat are Barriers you face when doing support and how does it vary around Epic upgrades, holidays, time of day etc?", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many of you do support and how does it fair in the healthcare space?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jegfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684264762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moving my way through interview rounds for a DE role at my current healthcare company. Part of my role would require support duty and on call. I don\u2019t mind as I already do this as a Business Analyst, but I would find it more interesting since it\u2019s related to data rather than Epic.  My org uses service now so I assume it would be the same for this operations team. &lt;/p&gt;\n\n&lt;p&gt;What are Barriers you face when doing support and how does it vary around Epic upgrades, holidays, time of day etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jegfo", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jegfo/how_many_of_you_do_support_and_how_does_it_fair/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jegfo/how_many_of_you_do_support_and_how_does_it_fair/", "subreddit_subscribers": 105866, "created_utc": 1684264762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Microsoft Learn #CloudSkillsChallenge! \ud83d\udde3\ufe0f\n\nPre-register before the fun begins on May 23", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSBuild 2023 is here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j6trz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684247377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "msft.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft Learn #CloudSkillsChallenge! \ud83d\udde3\ufe0f&lt;/p&gt;\n\n&lt;p&gt;Pre-register before the fun begins on May 23&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://msft.it/6049gnt3f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13j6trz", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j6trz/msbuild_2023_is_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://msft.it/6049gnt3f", "subreddit_subscribers": 105866, "created_utc": 1684247377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, has anyone used AZCopy  to migrate data from one system to another in their project ?\nIf they have used ,can you please explain the advantages it has over the copy activity present in ADF/Synapse ?", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AZCopy over Copy activity in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j1ifs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684233488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, has anyone used AZCopy  to migrate data from one system to another in their project ?\nIf they have used ,can you please explain the advantages it has over the copy activity present in ADF/Synapse ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j1ifs", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j1ifs/using_azcopy_over_copy_activity_in_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j1ifs/using_azcopy_over_copy_activity_in_azure_data/", "subreddit_subscribers": 105866, "created_utc": 1684233488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering job market currently saturated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13jx5k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684317119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jx5k6", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "subreddit_subscribers": 105866, "created_utc": 1684317119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm planning to switch my domain as I'm not very satisfied with the current role.\n\nI'm currently doing a course in udacity, so looking for insights on how to work on interview process and questions often asked.\n\nCan anyone please share your experience that will be really helpful.", "author_fullname": "t2_qcfcg002", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Domain switch to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13jwtsm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684316011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning to switch my domain as I&amp;#39;m not very satisfied with the current role.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently doing a course in udacity, so looking for insights on how to work on interview process and questions often asked.&lt;/p&gt;\n\n&lt;p&gt;Can anyone please share your experience that will be really helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jwtsm", "is_robot_indexable": true, "report_reasons": null, "author": "Unusual_Tower4306", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jwtsm/domain_switch_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jwtsm/domain_switch_to_data_engineering/", "subreddit_subscribers": 105866, "created_utc": 1684316011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a continuation to this post I had posted earlier.\n\n[https://www.reddit.com/r/dataengineering/comments/12vaprs/looking\\_for\\_advice\\_on\\_edw/](https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/)\n\nAll my staging and therefore core tables have surrogate keys built in. Its basically an auto increment number.\n\nThe question is, for the dimension and fact tables, what should be the surrogate key? Specially, if there are multiple data sources involved.\n\nFor example, what if the \"Clients\" are coming from multiple data sources? What should be the surrogate key for DIM\\_Clients table where all clients get consolidated?", "author_fullname": "t2_8kbtrdm4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Surrogate Key question in a EDW", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jg0n6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684268357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a continuation to this post I had posted earlier.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/\"&gt;https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All my staging and therefore core tables have surrogate keys built in. Its basically an auto increment number.&lt;/p&gt;\n\n&lt;p&gt;The question is, for the dimension and fact tables, what should be the surrogate key? Specially, if there are multiple data sources involved.&lt;/p&gt;\n\n&lt;p&gt;For example, what if the &amp;quot;Clients&amp;quot; are coming from multiple data sources? What should be the surrogate key for DIM_Clients table where all clients get consolidated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13jg0n6", "is_robot_indexable": true, "report_reasons": null, "author": "alphaqu22vice", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jg0n6/surrogate_key_question_in_a_edw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jg0n6/surrogate_key_question_in_a_edw/", "subreddit_subscribers": 105866, "created_utc": 1684268357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a medium sized biotech currently about a year into an ambitious data mesh project. Our team supports all enterprise and analytics for all business units. At first, my understanding was that I'd be coming in to architect data projects and implement solutions with my own team of engineers. But now, I'm realizing that what the company actually wants is for me to architect a data ecosystem that's fully maintainable by the business units. Our engineers should be building out the managed tools used to implement the solutions, but business units should be focused on implementing and maintaining the solutions.\n\nRight now, I'm thinking that I should really be looking into building out low/no-code solutions for data pipelines, databases, applications, and visualizations, but I'm not sure where to start? The other challenge is that the technical literacy of these business units varies greatly!\n\nI'm coming in as a lead architect, but since I've never worked in a project like this before, I'm curious where to focus?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to build a data ecosystem fully maintainable by the business units? Has anyone heard of similar projects initiated in other companies? How do these efforts usually play out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jdilu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684262636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a medium sized biotech currently about a year into an ambitious data mesh project. Our team supports all enterprise and analytics for all business units. At first, my understanding was that I&amp;#39;d be coming in to architect data projects and implement solutions with my own team of engineers. But now, I&amp;#39;m realizing that what the company actually wants is for me to architect a data ecosystem that&amp;#39;s fully maintainable by the business units. Our engineers should be building out the managed tools used to implement the solutions, but business units should be focused on implementing and maintaining the solutions.&lt;/p&gt;\n\n&lt;p&gt;Right now, I&amp;#39;m thinking that I should really be looking into building out low/no-code solutions for data pipelines, databases, applications, and visualizations, but I&amp;#39;m not sure where to start? The other challenge is that the technical literacy of these business units varies greatly!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m coming in as a lead architect, but since I&amp;#39;ve never worked in a project like this before, I&amp;#39;m curious where to focus?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jdilu", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jdilu/is_it_possible_to_build_a_data_ecosystem_fully/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jdilu/is_it_possible_to_build_a_data_ecosystem_fully/", "subreddit_subscribers": 105866, "created_utc": 1684262636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how do you version manage snowflake schema changes with git?\n\nIs there a trick or tool to compare and sync up changes done in snowflake database by a developer to git repo? Something like SSDT do with SQL Server", "author_fullname": "t2_khph1234", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you version manage snowflake schema changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jddaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684268850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684262311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how do you version manage snowflake schema changes with git?&lt;/p&gt;\n\n&lt;p&gt;Is there a trick or tool to compare and sync up changes done in snowflake database by a developer to git repo? Something like SSDT do with SQL Server&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13jddaj", "is_robot_indexable": true, "report_reasons": null, "author": "misc0007", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jddaj/how_do_you_version_manage_snowflake_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jddaj/how_do_you_version_manage_snowflake_schema_changes/", "subreddit_subscribers": 105866, "created_utc": 1684262311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I would like to extract text from a quizlet website with more than 300 pages. I have tried parsehub and tried to use all troubleshooting methods but nothing has worked so far. Do you have any suggestions to what can help with this. I have absolutely no background in automation and web scraping or the likes but I really need to finish this and I hope there's someone here who can help or give me any suggestions. Thank you.", "author_fullname": "t2_qwuvj9dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j9u98", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684254204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I would like to extract text from a quizlet website with more than 300 pages. I have tried parsehub and tried to use all troubleshooting methods but nothing has worked so far. Do you have any suggestions to what can help with this. I have absolutely no background in automation and web scraping or the likes but I really need to finish this and I hope there&amp;#39;s someone here who can help or give me any suggestions. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j9u98", "is_robot_indexable": true, "report_reasons": null, "author": "icedfitch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j9u98/web_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j9u98/web_scraping/", "subreddit_subscribers": 105866, "created_utc": 1684254204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, please I would like you to help me clarify the differences among these three courses in terms of content, ability to cope and career opportunities. I had my first degree in Biochemistry, but have always loved to work with figures, and so fell in love when I had the opportunity to partake in a 6months data analytic bootcamp. Now I want to go for my masters, but confused about the differences among these three as they keep popping in my face.", "author_fullname": "t2_gmbd12l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSc Data Science vs MSc Big Data vs MSc Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j87ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684250490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, please I would like you to help me clarify the differences among these three courses in terms of content, ability to cope and career opportunities. I had my first degree in Biochemistry, but have always loved to work with figures, and so fell in love when I had the opportunity to partake in a 6months data analytic bootcamp. Now I want to go for my masters, but confused about the differences among these three as they keep popping in my face.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j87ao", "is_robot_indexable": true, "report_reasons": null, "author": "Ceccybabe", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j87ao/msc_data_science_vs_msc_big_data_vs_msc_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j87ao/msc_data_science_vs_msc_big_data_vs_msc_data/", "subreddit_subscribers": 105866, "created_utc": 1684250490.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}