{"kind": "Listing", "data": {"after": "t3_13jhwjr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13jgov7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 119, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BHwzDmr6d7s/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13jgov7", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 119, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1wy2crkMHl-uwJdEw5K2gTWbL8yH_Jt--rSBRFSQBQI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684269901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=BHwzDmr6d7s", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?auto=webp&amp;v=enabled&amp;s=283a9b291bf0f4f79d93e128c510eb93c3920ca7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d76cd5eb6637fbe0ea0c9556e61d4ae524072eca", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f55f62c00226bd292ff2d6cfc891a70ab32cfd98", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/KEVr5qLF4Y62axsZ-ufzpqtVWJlCkjOINGz00Dozvp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6fa4725dfb0269acd769825ea2d71f0f69df305", "width": 320, "height": 240}], "variants": {}, "id": "vzJx_S3Oc0eW55Awi7t0McsvyL755J93HnRQ0TGOnZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jgov7", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jgov7/secret_to_optimizing_sql_queries_understand_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=BHwzDmr6d7s", "subreddit_subscribers": 105885, "created_utc": 1684269901.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Secret To Optimizing SQL Queries - Understand The SQL Execution Order", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BHwzDmr6d7s?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Secret To Optimizing SQL Queries - Understand The SQL Execution Order\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BHwzDmr6d7s/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all - I just got my first \"big\" job as a data engineer for a large corporation. I thought I would enjoy the stability, but I find I'm getting pretty stressed out by the constant pressure to hit corporate targets. I'm thinking about looking for a better fit, but I haven't even been here for a year yet. I don't know if I should stick it out, change my mindset, or look for something else and risk being a \"job-hopper\". What do you think? Thanks for your help.", "author_fullname": "t2_mgkmuyar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I don't like my job, should I job-hop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j5kn6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684244476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - I just got my first &amp;quot;big&amp;quot; job as a data engineer for a large corporation. I thought I would enjoy the stability, but I find I&amp;#39;m getting pretty stressed out by the constant pressure to hit corporate targets. I&amp;#39;m thinking about looking for a better fit, but I haven&amp;#39;t even been here for a year yet. I don&amp;#39;t know if I should stick it out, change my mindset, or look for something else and risk being a &amp;quot;job-hopper&amp;quot;. What do you think? Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j5kn6", "is_robot_indexable": true, "report_reasons": null, "author": "calamari_gringo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j5kn6/if_i_dont_like_my_job_should_i_jobhop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j5kn6/if_i_dont_like_my_job_should_i_jobhop/", "subreddit_subscribers": 105885, "created_utc": 1684244476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We extract data from 70-ish external systems (via REST) every few minutes and push the raw data to Kafka topics for downstream transformation/processing. We're facing some significant refactoring and I want to look at alternatives to our large, homegrown codebase.\n\nI'm looking to understand what options work well to query from REST APIs, perform some config-based transforms in memory and load to Kafka. It looks like Airbyte and FiveTran use ELT and transform using DBT, this may not be a fit for us considering we're really looking for micro-batch or stream transformations. \n\nWhat works well for you in a similar scenario?", "author_fullname": "t2_gs0mp007", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for Extract/Transform of data from REST APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j69kh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684246078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We extract data from 70-ish external systems (via REST) every few minutes and push the raw data to Kafka topics for downstream transformation/processing. We&amp;#39;re facing some significant refactoring and I want to look at alternatives to our large, homegrown codebase.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to understand what options work well to query from REST APIs, perform some config-based transforms in memory and load to Kafka. It looks like Airbyte and FiveTran use ELT and transform using DBT, this may not be a fit for us considering we&amp;#39;re really looking for micro-batch or stream transformations. &lt;/p&gt;\n\n&lt;p&gt;What works well for you in a similar scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j69kh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomWalk55", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j69kh/what_do_you_use_for_extracttransform_of_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j69kh/what_do_you_use_for_extracttransform_of_data_from/", "subreddit_subscribers": 105885, "created_utc": 1684246078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have y'all ever had a time where your data warehouses were not optimized, that lead to extremely high costs ? E.g. Bad queries, Duplicated data etc. If so, what was it and how did you fix it ?", "author_fullname": "t2_2urj7hkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jqqz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684296026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have y&amp;#39;all ever had a time where your data warehouses were not optimized, that lead to extremely high costs ? E.g. Bad queries, Duplicated data etc. If so, what was it and how did you fix it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jqqz3", "is_robot_indexable": true, "report_reasons": null, "author": "sman1235678", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jqqz3/data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jqqz3/data_warehouse/", "subreddit_subscribers": 105885, "created_utc": 1684296026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gej5riou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All you need is data and functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jtjso", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684304683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mckayla.blog", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jtjso", "is_robot_indexable": true, "report_reasons": null, "author": "gemconbet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jtjso/all_you_need_is_data_and_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mckayla.blog/posts/all-you-need-is-data-and-functions.html", "subreddit_subscribers": 105885, "created_utc": 1684304683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering job market currently saturated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jx5k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684317119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I was talking to people from DS/DE and they confirmed that after layoffs market is really saturated with more people, and it is really hard to find a job. Is that true or is DE still has a shortage of data engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jx5k6", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jx5k6/is_data_engineering_job_market_currently_saturated/", "subreddit_subscribers": 105885, "created_utc": 1684317119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the risk of being on the job market after the contract ends\u2026", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think it\u2019s worth accepting a contract to hire position to break into the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jr35m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684296978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the risk of being on the job market after the contract ends\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13jr35m", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13jr35m/do_you_think_its_worth_accepting_a_contract_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jr35m/do_you_think_its_worth_accepting_a_contract_to/", "subreddit_subscribers": 105885, "created_utc": 1684296978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I generally understand the usefulness of data lakes for large append-only datasets (sensor data, logs, etc). But what about for large datasets that experience updates and deletions regularly?\n\nI know newer file-based engines can handle updates, deletes and upserts transactionally but I can\u2019t help but wonder\u2026 why? Why not use a DBMS as the repository for data that\u2019s going to be constantly in flux? They\u2019ve worked well for such purposes for decades.\n\nManagement loves the sales pitches on data lakes and I\u2019m just not seeing it for the data we work with.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lakes for Changing Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jmyaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684285621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I generally understand the usefulness of data lakes for large append-only datasets (sensor data, logs, etc). But what about for large datasets that experience updates and deletions regularly?&lt;/p&gt;\n\n&lt;p&gt;I know newer file-based engines can handle updates, deletes and upserts transactionally but I can\u2019t help but wonder\u2026 why? Why not use a DBMS as the repository for data that\u2019s going to be constantly in flux? They\u2019ve worked well for such purposes for decades.&lt;/p&gt;\n\n&lt;p&gt;Management loves the sales pitches on data lakes and I\u2019m just not seeing it for the data we work with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jmyaw", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jmyaw/data_lakes_for_changing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jmyaw/data_lakes_for_changing_data/", "subreddit_subscribers": 105885, "created_utc": 1684285621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now we use Informatica to orchestrate and load data from source databases and load into our target warehouse.  Say we'd like to switch to a code based stack such as Prefect/Airflow + Python EL.  What are the logistical constraints to consider? We're doing nightly batch loads ranging from 1 - 300m rows, with occasional 10b+ rows for one-time initial table loads. Less than 1000 tables total.  Say we'd like to write some basic parallelization utilizing multi-threading (something like concurrent futures) to be able to EL more than 1 table at a time.  Ideally we'd use Airflow to orchestrate, and use SSH operators to execute python scripts on a specified executor vm (out of multiple boxes) utilizing PyArrow or Polars. Is Spark needed to read source tables into a dataframe, and write it into the target database?", "author_fullname": "t2_4rifsjav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do we need Spark if we're just loading data from source to target? Trying to move away from Informatica", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j5syd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684245018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now we use Informatica to orchestrate and load data from source databases and load into our target warehouse.  Say we&amp;#39;d like to switch to a code based stack such as Prefect/Airflow + Python EL.  What are the logistical constraints to consider? We&amp;#39;re doing nightly batch loads ranging from 1 - 300m rows, with occasional 10b+ rows for one-time initial table loads. Less than 1000 tables total.  Say we&amp;#39;d like to write some basic parallelization utilizing multi-threading (something like concurrent futures) to be able to EL more than 1 table at a time.  Ideally we&amp;#39;d use Airflow to orchestrate, and use SSH operators to execute python scripts on a specified executor vm (out of multiple boxes) utilizing PyArrow or Polars. Is Spark needed to read source tables into a dataframe, and write it into the target database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j5syd", "is_robot_indexable": true, "report_reasons": null, "author": "Techthrowaway2222888", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j5syd/do_we_need_spark_if_were_just_loading_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j5syd/do_we_need_spark_if_were_just_loading_data_from/", "subreddit_subscribers": 105885, "created_utc": 1684245018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came across some jobs that have the same descirption as DE but have different titles (exp ETL developper). I was wondering what are the rest of the possibilities.", "author_fullname": "t2_um2qwii8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the other names for data engineering jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13jzt1u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684325101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across some jobs that have the same descirption as DE but have different titles (exp ETL developper). I was wondering what are the rest of the possibilities.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jzt1u", "is_robot_indexable": true, "report_reasons": null, "author": "NoChemical1223", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jzt1u/what_are_the_other_names_for_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jzt1u/what_are_the_other_names_for_data_engineering_jobs/", "subreddit_subscribers": 105885, "created_utc": 1684325101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When it comes to storing clickstream events in any warehouse or say hive external tables or the likes, what is the approach you are following? Single table for all clickstream events. OR one table per event.\n\nWhat does the community think of its pros and cons?", "author_fullname": "t2_e5czp0ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single table vs multiple table for clickstream events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jxsq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684319223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When it comes to storing clickstream events in any warehouse or say hive external tables or the likes, what is the approach you are following? Single table for all clickstream events. OR one table per event.&lt;/p&gt;\n\n&lt;p&gt;What does the community think of its pros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jxsq0", "is_robot_indexable": true, "report_reasons": null, "author": "jaisukku", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jxsq0/single_table_vs_multiple_table_for_clickstream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jxsq0/single_table_vs_multiple_table_for_clickstream/", "subreddit_subscribers": 105885, "created_utc": 1684319223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Moving my way through interview rounds for a DE role at my current healthcare company. Part of my role would require support duty and on call. I don\u2019t mind as I already do this as a Business Analyst, but I would find it more interesting since it\u2019s related to data rather than Epic.  My org uses service now so I assume it would be the same for this operations team. \n\nWhat are Barriers you face when doing support and how does it vary around Epic upgrades, holidays, time of day etc?", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many of you do support and how does it fair in the healthcare space?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jegfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684264762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moving my way through interview rounds for a DE role at my current healthcare company. Part of my role would require support duty and on call. I don\u2019t mind as I already do this as a Business Analyst, but I would find it more interesting since it\u2019s related to data rather than Epic.  My org uses service now so I assume it would be the same for this operations team. &lt;/p&gt;\n\n&lt;p&gt;What are Barriers you face when doing support and how does it vary around Epic upgrades, holidays, time of day etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jegfo", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jegfo/how_many_of_you_do_support_and_how_does_it_fair/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jegfo/how_many_of_you_do_support_and_how_does_it_fair/", "subreddit_subscribers": 105885, "created_utc": 1684264762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Microsoft Learn #CloudSkillsChallenge! \ud83d\udde3\ufe0f\n\nPre-register before the fun begins on May 23", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSBuild 2023 is here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j6trz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684247377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "msft.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft Learn #CloudSkillsChallenge! \ud83d\udde3\ufe0f&lt;/p&gt;\n\n&lt;p&gt;Pre-register before the fun begins on May 23&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://msft.it/6049gnt3f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13j6trz", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j6trz/msbuild_2023_is_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://msft.it/6049gnt3f", "subreddit_subscribers": 105885, "created_utc": 1684247377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The Snowflake community is rife with information dumps on how to optimize expensive queries. We know because we combed through a ton of them. What we present here are three tactical ways in which we\u2019ve done this at [Toplyne](https://www.toplyne.io/).\n\n[https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01](https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01)  \n\n\nhashnode: [https://toplyne.hashnode.dev/cooking-with-snowflake](https://toplyne.hashnode.dev/cooking-with-snowflake)", "author_fullname": "t2_11mmk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cooking with Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13k0u4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684327794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Snowflake community is rife with information dumps on how to optimize expensive queries. We know because we combed through a ton of them. What we present here are three tactical ways in which we\u2019ve done this at &lt;a href=\"https://www.toplyne.io/\"&gt;Toplyne&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01\"&gt;https://medium.com/toplyne-engineering/cooking-with-snowflake-833a1139ab01&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;hashnode: &lt;a href=\"https://toplyne.hashnode.dev/cooking-with-snowflake\"&gt;https://toplyne.hashnode.dev/cooking-with-snowflake&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?auto=webp&amp;v=enabled&amp;s=51be4efb76e306644bb1ac106ce7329c56cb85b1", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ed30cabb11f40a64afa20fba4137d94dd3e4caa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5a2b05b006fe97d319ba40b75c7a2fabedc85e0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b993ec3bda0ae5f64a8c916c91b303dcddc4e49e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7209521a9de64ba328aa9f3785879d8b9c34589", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21ea0c1e63c2454ac26dc3426e1f518a72189886", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/y_wChVPCd7LvEB62ymQaoWCk7ncynZoUnZlmqq7JkKY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abaa2e32064a30ff80aa0fc9a08a9a6001708d88", "width": 1080, "height": 607}], "variants": {}, "id": "mWF3LAbLbxtgk91lqNheYK4vTh9LkvNn5DurUSJd_v8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13k0u4u", "is_robot_indexable": true, "report_reasons": null, "author": "Pbd1194", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k0u4u/cooking_with_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k0u4u/cooking_with_snowflake/", "subreddit_subscribers": 105885, "created_utc": 1684327794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,  \nfor a few years, we have been using Redash as our internal SQL-based data analysis and dashboards. But since it has not been maintained for some time, we are looking for a replacement.  \n\n\nWhich tools do you use and do you have some recommendations?  \nPreferably open source but any recommendation will be great.", "author_fullname": "t2_yu7cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a great replacement for Redash?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13k0tfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684327742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nfor a few years, we have been using Redash as our internal SQL-based data analysis and dashboards. But since it has not been maintained for some time, we are looking for a replacement.  &lt;/p&gt;\n\n&lt;p&gt;Which tools do you use and do you have some recommendations?&lt;br/&gt;\nPreferably open source but any recommendation will be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13k0tfn", "is_robot_indexable": true, "report_reasons": null, "author": "UserPobro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13k0tfn/what_would_be_a_great_replacement_for_redash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13k0tfn/what_would_be_a_great_replacement_for_redash/", "subreddit_subscribers": 105885, "created_utc": 1684327742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fbliz6iq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Odigos v0.1.5 - Managing OpenTelemetry using Kubernetes labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_13jxj4t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OjxmyylSJgKp_eD5b5u0T_N3oeyhvHV4E_zBc_uElWA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684318355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "keyval.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://keyval.dev/labels-support/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?auto=webp&amp;v=enabled&amp;s=b1d5de80ff3a04af7d94fa29a3516ded6a998837", "width": 738, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94c162a2de48c4b1592001f3a45f152e43c072ae", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fe5e5c1af29c946c85905c915eac85c564cf064", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49ec4e18c60620c1babef719f3af7c4fab5852a0", "width": 320, "height": 272}, {"url": "https://external-preview.redd.it/kdGladmDg8nLM1MqEteVbYcNoG6s_8bh6OWZCB6J9Fk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd66c84c4bb9af2336479b1873cdee8944e000ff", "width": 640, "height": 544}], "variants": {}, "id": "X7VuIcpdDWamVcOA5XBSIKHnF-pkmVMowxsUlaKf8ts"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jxj4t", "is_robot_indexable": true, "report_reasons": null, "author": "Barakikia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jxj4t/odigos_v015_managing_opentelemetry_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://keyval.dev/labels-support/", "subreddit_subscribers": 105885, "created_utc": 1684318355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a continuation to this post I had posted earlier.\n\n[https://www.reddit.com/r/dataengineering/comments/12vaprs/looking\\_for\\_advice\\_on\\_edw/](https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/)\n\nAll my staging and therefore core tables have surrogate keys built in. Its basically an auto increment number.\n\nThe question is, for the dimension and fact tables, what should be the surrogate key? Specially, if there are multiple data sources involved.\n\nFor example, what if the \"Clients\" are coming from multiple data sources? What should be the surrogate key for DIM\\_Clients table where all clients get consolidated?", "author_fullname": "t2_8kbtrdm4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Surrogate Key question in a EDW", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jg0n6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684268357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a continuation to this post I had posted earlier.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/\"&gt;https://www.reddit.com/r/dataengineering/comments/12vaprs/looking_for_advice_on_edw/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All my staging and therefore core tables have surrogate keys built in. Its basically an auto increment number.&lt;/p&gt;\n\n&lt;p&gt;The question is, for the dimension and fact tables, what should be the surrogate key? Specially, if there are multiple data sources involved.&lt;/p&gt;\n\n&lt;p&gt;For example, what if the &amp;quot;Clients&amp;quot; are coming from multiple data sources? What should be the surrogate key for DIM_Clients table where all clients get consolidated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13jg0n6", "is_robot_indexable": true, "report_reasons": null, "author": "alphaqu22vice", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jg0n6/surrogate_key_question_in_a_edw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jg0n6/surrogate_key_question_in_a_edw/", "subreddit_subscribers": 105885, "created_utc": 1684268357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a medium sized biotech currently about a year into an ambitious data mesh project. Our team supports all enterprise and analytics for all business units. At first, my understanding was that I'd be coming in to architect data projects and implement solutions with my own team of engineers. But now, I'm realizing that what the company actually wants is for me to architect a data ecosystem that's fully maintainable by the business units. Our engineers should be building out the managed tools used to implement the solutions, but business units should be focused on implementing and maintaining the solutions.\n\nRight now, I'm thinking that I should really be looking into building out low/no-code solutions for data pipelines, databases, applications, and visualizations, but I'm not sure where to start? The other challenge is that the technical literacy of these business units varies greatly!\n\nI'm coming in as a lead architect, but since I've never worked in a project like this before, I'm curious where to focus?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to build a data ecosystem fully maintainable by the business units? Has anyone heard of similar projects initiated in other companies? How do these efforts usually play out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jdilu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684262636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a medium sized biotech currently about a year into an ambitious data mesh project. Our team supports all enterprise and analytics for all business units. At first, my understanding was that I&amp;#39;d be coming in to architect data projects and implement solutions with my own team of engineers. But now, I&amp;#39;m realizing that what the company actually wants is for me to architect a data ecosystem that&amp;#39;s fully maintainable by the business units. Our engineers should be building out the managed tools used to implement the solutions, but business units should be focused on implementing and maintaining the solutions.&lt;/p&gt;\n\n&lt;p&gt;Right now, I&amp;#39;m thinking that I should really be looking into building out low/no-code solutions for data pipelines, databases, applications, and visualizations, but I&amp;#39;m not sure where to start? The other challenge is that the technical literacy of these business units varies greatly!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m coming in as a lead architect, but since I&amp;#39;ve never worked in a project like this before, I&amp;#39;m curious where to focus?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13jdilu", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jdilu/is_it_possible_to_build_a_data_ecosystem_fully/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jdilu/is_it_possible_to_build_a_data_ecosystem_fully/", "subreddit_subscribers": 105885, "created_utc": 1684262636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how do you version manage snowflake schema changes with git?\n\nIs there a trick or tool to compare and sync up changes done in snowflake database by a developer to git repo? Something like SSDT do with SQL Server", "author_fullname": "t2_khph1234", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you version manage snowflake schema changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jddaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684268850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684262311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how do you version manage snowflake schema changes with git?&lt;/p&gt;\n\n&lt;p&gt;Is there a trick or tool to compare and sync up changes done in snowflake database by a developer to git repo? Something like SSDT do with SQL Server&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13jddaj", "is_robot_indexable": true, "report_reasons": null, "author": "misc0007", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jddaj/how_do_you_version_manage_snowflake_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jddaj/how_do_you_version_manage_snowflake_schema_changes/", "subreddit_subscribers": 105885, "created_utc": 1684262311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I would like to extract text from a quizlet website with more than 300 pages. I have tried parsehub and tried to use all troubleshooting methods but nothing has worked so far. Do you have any suggestions to what can help with this. I have absolutely no background in automation and web scraping or the likes but I really need to finish this and I hope there's someone here who can help or give me any suggestions. Thank you.", "author_fullname": "t2_qwuvj9dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j9u98", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684254204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I would like to extract text from a quizlet website with more than 300 pages. I have tried parsehub and tried to use all troubleshooting methods but nothing has worked so far. Do you have any suggestions to what can help with this. I have absolutely no background in automation and web scraping or the likes but I really need to finish this and I hope there&amp;#39;s someone here who can help or give me any suggestions. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j9u98", "is_robot_indexable": true, "report_reasons": null, "author": "icedfitch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j9u98/web_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j9u98/web_scraping/", "subreddit_subscribers": 105885, "created_utc": 1684254204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, please I would like you to help me clarify the differences among these three courses in terms of content, ability to cope and career opportunities. I had my first degree in Biochemistry, but have always loved to work with figures, and so fell in love when I had the opportunity to partake in a 6months data analytic bootcamp. Now I want to go for my masters, but confused about the differences among these three as they keep popping in my face.", "author_fullname": "t2_gmbd12l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSc Data Science vs MSc Big Data vs MSc Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j87ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684250490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, please I would like you to help me clarify the differences among these three courses in terms of content, ability to cope and career opportunities. I had my first degree in Biochemistry, but have always loved to work with figures, and so fell in love when I had the opportunity to partake in a 6months data analytic bootcamp. Now I want to go for my masters, but confused about the differences among these three as they keep popping in my face.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13j87ao", "is_robot_indexable": true, "report_reasons": null, "author": "Ceccybabe", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j87ao/msc_data_science_vs_msc_big_data_vs_msc_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j87ao/msc_data_science_vs_msc_big_data_vs_msc_data/", "subreddit_subscribers": 105885, "created_utc": 1684250490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! I want to develop a pipeline that captures real-time changes from a PostgreSQL database and dumps them into BigQuery to later create charts of that data with Superset. Initially, I thought about using Airbyte to synchronize data from PostgreSQL to BigQuery. The problem is that Airbyte only allows synchronizations every 5 minutes and doesn't support streaming. As an alternative, I have found CloudQuery, which  seems to support real-time synchronization with CDC. Do you think  CloudQuery is the right tool for this? Are you familiar with any other open-source tools that support real-time synchronization?", "author_fullname": "t2_962s9s5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice on Real-Time Data Synchronization from PostgreSQL to BigQuery: Airbyte vs. CloudQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j7izr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684248967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I want to develop a pipeline that captures real-time changes from a PostgreSQL database and dumps them into BigQuery to later create charts of that data with Superset. Initially, I thought about using Airbyte to synchronize data from PostgreSQL to BigQuery. The problem is that Airbyte only allows synchronizations every 5 minutes and doesn&amp;#39;t support streaming. As an alternative, I have found CloudQuery, which  seems to support real-time synchronization with CDC. Do you think  CloudQuery is the right tool for this? Are you familiar with any other open-source tools that support real-time synchronization?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13j7izr", "is_robot_indexable": true, "report_reasons": null, "author": "Sea-Brain-1248", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j7izr/need_advice_on_realtime_data_synchronization_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j7izr/need_advice_on_realtime_data_synchronization_from/", "subreddit_subscribers": 105885, "created_utc": 1684248967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The ones who don't have azure subscription or have their short trial already done. How are we supposed to practice it and get hands on experience?\n\nIs there any way ? Thank you.", "author_fullname": "t2_lxdil748", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I practice ADF , Synapse and such?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13j5p9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684244783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The ones who don&amp;#39;t have azure subscription or have their short trial already done. How are we supposed to practice it and get hands on experience?&lt;/p&gt;\n\n&lt;p&gt;Is there any way ? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13j5p9u", "is_robot_indexable": true, "report_reasons": null, "author": "GandalfTheChad", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13j5p9u/where_can_i_practice_adf_synapse_and_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13j5p9u/where_can_i_practice_adf_synapse_and_such/", "subreddit_subscribers": 105885, "created_utc": 1684244783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nWith a couple of years of experience in the data engineering professional space, I\u2019ve decided it\u2019s about time to share some of the knowledge learned, so I\u2019ve started a Data Engineering blog on Medium.\n\nSo far I\u2019ve written 3 posts about:\n- Data preparation,\n- Pandas update function use cases,\n- Using AWS LF-Tags to scale datalake access control.\n\nIf you\u2019re interested, please consider following me, I will be very grateful! Hitting 100 followers will let me get a bit of side income out of this newly found hobby!\n\nHere\u2019s a link to my profile: https://medium.com/@marcinp55\n\nThanks in advance!", "author_fullname": "t2_1fnc9sle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All Data Engineering/Science personal blog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jxz26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684319778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;With a couple of years of experience in the data engineering professional space, I\u2019ve decided it\u2019s about time to share some of the knowledge learned, so I\u2019ve started a Data Engineering blog on Medium.&lt;/p&gt;\n\n&lt;p&gt;So far I\u2019ve written 3 posts about:\n- Data preparation,\n- Pandas update function use cases,\n- Using AWS LF-Tags to scale datalake access control.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, please consider following me, I will be very grateful! Hitting 100 followers will let me get a bit of side income out of this newly found hobby!&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s a link to my profile: &lt;a href=\"https://medium.com/@marcinp55\"&gt;https://medium.com/@marcinp55&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P-nSrDX6O-9xMsD5SLb9uqbCu3q9UHY94-k19xsAJcw.jpg?auto=webp&amp;v=enabled&amp;s=66e0f050e9eb09fae97b2e057a5aef5e9d39ab39", "width": 543, "height": 596}, "resolutions": [{"url": "https://external-preview.redd.it/P-nSrDX6O-9xMsD5SLb9uqbCu3q9UHY94-k19xsAJcw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc53700c84e79e0ab6562b6f7c45d466d7436881", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/P-nSrDX6O-9xMsD5SLb9uqbCu3q9UHY94-k19xsAJcw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6dccaebfa1e1371bd1ac8c7234655931bfade2a7", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/P-nSrDX6O-9xMsD5SLb9uqbCu3q9UHY94-k19xsAJcw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70d090c65e313f3d40f4c2535b4a50c1e72e699e", "width": 320, "height": 351}], "variants": {}, "id": "n5F7iJuusHGJeFW_XL4zMHT7N27-jnKiOCvRXrzvsIk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13jxz26", "is_robot_indexable": true, "report_reasons": null, "author": "SignalDot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jxz26/all_data_engineeringscience_personal_blog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jxz26/all_data_engineeringscience_personal_blog/", "subreddit_subscribers": 105885, "created_utc": 1684319778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for help on many different levels with this question, so please bear with me.\n\nLets say I have a table that contains 2 fields:\n\nGroup\\_ID\n\nUser\\_ID\n\n&amp;#x200B;\n\nI want to be able to efficiently execute combinations of User\\_IDs that are in various combinations of groups.  For example:\n\nGroup\\_ID, User\\_ID\n\nGroup1, Johnny\n\nGroup1, Carter\n\nGroup1, Sara\n\nGroup2, Carter\n\nGroup3, Carter\n\nGroup3, Sara\n\n&amp;#x200B;\n\nI want to be able to say \"give me all users that are in both GROUP1 and GROUP2 and NOT in GROUP3, for example\".\n\nAnd I need the \"count\" of User\\_IDs to come back relatively quickly.\n\n&amp;#x200B;\n\nSo my questions:\n\n1) What kind of technology would be best to work with this data?\n\n2) Is there a more efficient data model that helps here?  (i.e. store Group\\_ID into columns?)\n\n&amp;#x200B;\n\nThanks if you have any thoughts.", "author_fullname": "t2_rerk9zyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Select a list of rows across a combination of groupings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13jhwjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684272741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for help on many different levels with this question, so please bear with me.&lt;/p&gt;\n\n&lt;p&gt;Lets say I have a table that contains 2 fields:&lt;/p&gt;\n\n&lt;p&gt;Group_ID&lt;/p&gt;\n\n&lt;p&gt;User_ID&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to be able to efficiently execute combinations of User_IDs that are in various combinations of groups.  For example:&lt;/p&gt;\n\n&lt;p&gt;Group_ID, User_ID&lt;/p&gt;\n\n&lt;p&gt;Group1, Johnny&lt;/p&gt;\n\n&lt;p&gt;Group1, Carter&lt;/p&gt;\n\n&lt;p&gt;Group1, Sara&lt;/p&gt;\n\n&lt;p&gt;Group2, Carter&lt;/p&gt;\n\n&lt;p&gt;Group3, Carter&lt;/p&gt;\n\n&lt;p&gt;Group3, Sara&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to be able to say &amp;quot;give me all users that are in both GROUP1 and GROUP2 and NOT in GROUP3, for example&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;And I need the &amp;quot;count&amp;quot; of User_IDs to come back relatively quickly.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So my questions:&lt;/p&gt;\n\n&lt;p&gt;1) What kind of technology would be best to work with this data?&lt;/p&gt;\n\n&lt;p&gt;2) Is there a more efficient data model that helps here?  (i.e. store Group_ID into columns?)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks if you have any thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13jhwjr", "is_robot_indexable": true, "report_reasons": null, "author": "BurnsyBurner", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13jhwjr/select_a_list_of_rows_across_a_combination_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13jhwjr/select_a_list_of_rows_across_a_combination_of/", "subreddit_subscribers": 105885, "created_utc": 1684272741.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}