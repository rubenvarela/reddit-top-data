{"kind": "Listing", "data": {"after": "t3_13qgay5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mjusn", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "PlayStation Game (Frogger 2) Source Code recovered from damaged magnetic tape", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13q1pv7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 1179, "total_awards_received": 2, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1179, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/cz7hutsnDoZWWw3tSgBohQvG8nAX-c-F98IeNd9UBA8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684878033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Kneesnap/onstream-data-recovery/blob/main/info/INTRO.MD", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?auto=webp&amp;v=enabled&amp;s=24d181b381ab782ba1f674abfeb461874ebfed34", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21e8fbfcb62e7cf4abb1ec0f0692657d436649ed", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6322f9f228a2df9c1b78999f0a07fac83b898310", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8901464df1937e806dec8c15eebe9ea1330e6bda", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=228feef6d9eaa111e655debfe0580f299c756924", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a3baf95b74bb32a831700309c3e5d000d00a24e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ou9t1L-3bYOM-dOna8fowUMS6ABdPQycBLAA627n1Ls.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2dd369082d3b1ce602b714d3b5108eb9a521f3c", "width": 1080, "height": 540}], "variants": {}, "id": "4VrF5BMeMrocF4s6_7VFRFf-Gve_-DjG2xDxEYJI7jo"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=32add54efce28cc8ce035c5e2bc89a27286a815e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dfb00ece05340570177df7cfa1af6d2737c0910b", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8b0b87b868f6cd6313e2c90975dac636e4a0412", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=2a3ad7ec2ccc57b6c65b17e2b57647a81f335039", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d4a8ca64b391e8b057408067d77f503752c29b7e", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=4efb20a46b5cee58042da74830ee914d1547236c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=83e8bea70baef2140842017e967f163a9f530a9d", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=14fb29ce140b35a21a7cc7ee1c4d212ce0b1179d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=533b05085677b48f15004bd7f9ff19ec5b29099f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=6f767b3c289e5cb2a733b24da5f4c46d9c079bc7", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q1pv7", "is_robot_indexable": true, "report_reasons": null, "author": "Kneesnap", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q1pv7/playstation_game_frogger_2_source_code_recovered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Kneesnap/onstream-data-recovery/blob/main/info/INTRO.MD", "subreddit_subscribers": 684094, "created_utc": 1684878033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_9igqvq1b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Was asked to share pics of my locker here.. I guess it's a reminder to backup your stuff. I still have more damaged HDDs, let me know how I can make use of them other than art.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fo9zscjg9n1b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=025efe70ce79d7541236fbaf5a3c1e535c982b24"}, {"y": 144, "x": 216, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04b7bf8a1f59729246dee1cc4e81040df2cff4de"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac8371e979c1f544539fe5252751813a97f67b17"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e58b43b77fdd4b0af4de457ef04976336b36854"}, {"y": 640, "x": 960, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dffcb3542a3af4cfa4ce117929b8696637e13bad"}, {"y": 720, "x": 1080, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae560deac68e73de78beef361106b0f1163326e7"}], "s": {"y": 4160, "x": 6240, "u": "https://preview.redd.it/fo9zscjg9n1b1.jpg?width=6240&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9e1605fc20bd742028245e85fb5e5fa5bf191ac0"}, "id": "fo9zscjg9n1b1"}, "k4esiacg9n1b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 179, "x": 108, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=806c87328d67a1dc8387d4530c31fb7b014e05da"}, {"y": 358, "x": 216, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=895a20adf55dc248b6fdfe887fe6e4acba521562"}, {"y": 530, "x": 320, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b614c75b61da8a27a9a9bed62252a8ea970f5884"}, {"y": 1061, "x": 640, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81141da51d578a4fbfb226101016586409767ef0"}, {"y": 1591, "x": 960, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3bd1dee419142494462fb716c7c8b91ec6ca866"}, {"y": 1790, "x": 1080, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faf4d8a69dc5640ad41f77cbf37a0f9b45f9cfcd"}], "s": {"y": 6200, "x": 3739, "u": "https://preview.redd.it/k4esiacg9n1b1.jpg?width=3739&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=67575b93a9b36cbdd277dafc4542bc8f6e5805b0"}, "id": "k4esiacg9n1b1"}}, "name": "t3_13q0i65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 55, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "k4esiacg9n1b1", "id": 278854156}, {"media_id": "fo9zscjg9n1b1", "id": 278854157}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ArZG_4xhbASpvrUEdn3YUdVRv_YAsqTexYY7e0Cb5c4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684875383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13q0i65", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13q0i65", "is_robot_indexable": true, "report_reasons": null, "author": "500xp1", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q0i65/was_asked_to_share_pics_of_my_locker_here_i_guess/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13q0i65", "subreddit_subscribers": 684094, "created_utc": 1684875383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a need to save certain conversations, text conversations, from my iPhone to a PC. More and more customers request things via text and I need to document that to protect my business. I don't have time or the desire to screenshot whole conversations and save them that way. There has to be an easier way. I don't mind paying for an app if it is easy and efficient to use. Any suggestions?\n\nEdit: Export to PDF would be best, if that is available.", "author_fullname": "t2_10uwdzji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoard messages from my phone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pujyo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684862223.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684861940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a need to save certain conversations, text conversations, from my iPhone to a PC. More and more customers request things via text and I need to document that to protect my business. I don&amp;#39;t have time or the desire to screenshot whole conversations and save them that way. There has to be an easier way. I don&amp;#39;t mind paying for an app if it is easy and efficient to use. Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;Edit: Export to PDF would be best, if that is available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13pujyo", "is_robot_indexable": true, "report_reasons": null, "author": "Discontented_Beaver", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13pujyo/hoard_messages_from_my_phone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13pujyo/hoard_messages_from_my_phone/", "subreddit_subscribers": 684094, "created_utc": 1684861940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all! I'm one of the many people here losing their Google Drive unlimited storage. I've only ever owned desktop and laptop PCs, never even a NAS, but I'd like to setup a local storage option, and I'm at that point where I'm know what the equipment I need sort of looks like, but I feel like I don't have the vocabulary to start educating myself properly yet. \n\n1. I want to start small, but have the ability to scale up drastically. I assume there's not really a middle ground between consumer and enterprise equipment. So like, rackmount server equipment? Excuse me for my assumptions, guesses, and unfamiliarity. I'm trying to find my footing in vaguely familiar territory. I know my way around computers as a hobbyist, so there's lots that's familiar, but lots that's new to me.\n2. I see something called disk arrays, but it's unclear to me whether these are like a rackmount NAS, with its own mainboard, or just a big disk enclosure? I see them with network jacks, and also SAS connectors, which are new to me. I'm starting to read up on them, but I figured I could get some good nudges in the right direction by asking here. I'm not really sure what options are available to me yet.\n3. I am comfortable with used equipment, and I have solar panels, so I'm not scared of less efficient equipment if I can get more room for future expansion.\n4. I'll be using it for a media server, so it'll spend more time reading than writing, if that's a consideration.\n5. I'm very uncomfortable being clueless about things, but I love to learn. Is there a good place to learn about this type of equipment in general terms? \n\nThanks so much for any advice or input.", "author_fullname": "t2_49966vn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Setting Up Local Storage Properly from the Start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q2n9d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684880129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I&amp;#39;m one of the many people here losing their Google Drive unlimited storage. I&amp;#39;ve only ever owned desktop and laptop PCs, never even a NAS, but I&amp;#39;d like to setup a local storage option, and I&amp;#39;m at that point where I&amp;#39;m know what the equipment I need sort of looks like, but I feel like I don&amp;#39;t have the vocabulary to start educating myself properly yet. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I want to start small, but have the ability to scale up drastically. I assume there&amp;#39;s not really a middle ground between consumer and enterprise equipment. So like, rackmount server equipment? Excuse me for my assumptions, guesses, and unfamiliarity. I&amp;#39;m trying to find my footing in vaguely familiar territory. I know my way around computers as a hobbyist, so there&amp;#39;s lots that&amp;#39;s familiar, but lots that&amp;#39;s new to me.&lt;/li&gt;\n&lt;li&gt;I see something called disk arrays, but it&amp;#39;s unclear to me whether these are like a rackmount NAS, with its own mainboard, or just a big disk enclosure? I see them with network jacks, and also SAS connectors, which are new to me. I&amp;#39;m starting to read up on them, but I figured I could get some good nudges in the right direction by asking here. I&amp;#39;m not really sure what options are available to me yet.&lt;/li&gt;\n&lt;li&gt;I am comfortable with used equipment, and I have solar panels, so I&amp;#39;m not scared of less efficient equipment if I can get more room for future expansion.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ll be using it for a media server, so it&amp;#39;ll spend more time reading than writing, if that&amp;#39;s a consideration.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m very uncomfortable being clueless about things, but I love to learn. Is there a good place to learn about this type of equipment in general terms? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks so much for any advice or input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q2n9d", "is_robot_indexable": true, "report_reasons": null, "author": "flapjack_fiasco", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q2n9d/advice_on_setting_up_local_storage_properly_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13q2n9d/advice_on_setting_up_local_storage_properly_from/", "subreddit_subscribers": 684094, "created_utc": 1684880129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey y'all. I got 5 Years of free Acronis True Image For WD, it works fine but eats a lot of resources and when making backup PC is lagging ( I7 8th, 32Gb Ram, all SSD's ). Veeam and IOMEI free works fine.\n\nWhy needs to ping  `telemetry.acronis.com` every 3-6min? Is not even running in the background \ud83d\ude02\n\nhttps://i.redd.it/3vh2epd3qm1b1.gif", "author_fullname": "t2_661rjff6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Acronis True Image For WD needs to ping theirs telemetry servers? The normal Free version in the same. DELETED \u263a", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 134, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3vh2epd3qm1b1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 103, "x": 108, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=89d67c47a5ef42f873581ccda9aae066bc4c1e96"}, {"y": 207, "x": 216, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=5b1e0e7fa195400075bb4a60b18e86380df5977d"}, {"y": 307, "x": 320, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=a3b4faabba139becfb95ba273de9650407ca3d14"}, {"y": 614, "x": 640, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=349838433905a5e3e4481a3021ffb5b7f2350987"}, {"y": 922, "x": 960, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=e3c0aa726f687bdc24d6731daaf88b5efe53b4cf"}, {"y": 1037, "x": 1080, "u": "https://preview.redd.it/3vh2epd3qm1b1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=36e9a47c367df818ee44f61ca787af79718bf501"}], "s": {"y": 1095, "gif": "https://i.redd.it/3vh2epd3qm1b1.gif", "mp4": "https://preview.redd.it/3vh2epd3qm1b1.gif?format=mp4&amp;v=enabled&amp;s=2298fddcba4ff2d20e0128a4cb585809d65f0e25", "x": 1140}, "id": "3vh2epd3qm1b1"}}, "name": "t3_13px93d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YiIE0rYssOInY-fyDM3QGXVq0IXx7vMNrhfsuYj-wgg.jpg", "edited": 1684868690.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684868135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all. I got 5 Years of free Acronis True Image For WD, it works fine but eats a lot of resources and when making backup PC is lagging ( I7 8th, 32Gb Ram, all SSD&amp;#39;s ). Veeam and IOMEI free works fine.&lt;/p&gt;\n\n&lt;p&gt;Why needs to ping  &lt;code&gt;telemetry.acronis.com&lt;/code&gt; every 3-6min? Is not even running in the background \ud83d\ude02&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/3vh2epd3qm1b1.gif\"&gt;https://i.redd.it/3vh2epd3qm1b1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13px93d", "is_robot_indexable": true, "report_reasons": null, "author": "bebe_92", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13px93d/why_acronis_true_image_for_wd_needs_to_ping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13px93d/why_acronis_true_image_for_wd_needs_to_ping/", "subreddit_subscribers": 684094, "created_utc": 1684868135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!    \n\n\nI just wanted to ask if anyone here has kept or \"hoarded\" a copy of Business 2.0 magazine.    \nIt's a discontinued magazine.     \n\n\nAnd I've been looking for soft copies of the magazine. \n\n  \nhttps://en.wikipedia.org/wiki/Business\\_2.0 https://web.archive.org/web/20060106091838/http://money.cnn.com/magazines/business2/business2\\_archive/ https://web.archive.org/web/20171102074930/http://money.cnn.com/magazines/business2/business2\\_archive/", "author_fullname": "t2_mbrkalxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone kept soft copies of Business 2.0 magazine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13qr861", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684947785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!    &lt;/p&gt;\n\n&lt;p&gt;I just wanted to ask if anyone here has kept or &amp;quot;hoarded&amp;quot; a copy of Business 2.0 magazine.&lt;br/&gt;\nIt&amp;#39;s a discontinued magazine.     &lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;ve been looking for soft copies of the magazine. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://en.wikipedia.org/wiki/Business%5C_2.0\"&gt;https://en.wikipedia.org/wiki/Business\\_2.0&lt;/a&gt; &lt;a href=\"https://web.archive.org/web/20060106091838/http://money.cnn.com/magazines/business2/business2%5C_archive/\"&gt;https://web.archive.org/web/20060106091838/http://money.cnn.com/magazines/business2/business2\\_archive/&lt;/a&gt; &lt;a href=\"https://web.archive.org/web/20171102074930/http://money.cnn.com/magazines/business2/business2%5C_archive/\"&gt;https://web.archive.org/web/20171102074930/http://money.cnn.com/magazines/business2/business2\\_archive/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qr861", "is_robot_indexable": true, "report_reasons": null, "author": "kerkerby", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qr861/has_anyone_kept_soft_copies_of_business_20/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qr861/has_anyone_kept_soft_copies_of_business_20/", "subreddit_subscribers": 684094, "created_utc": 1684947785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a synology ds920+ nas and I am connecting it to an eaton 5e850iusb ups. The nas draws 45w power. I am currently living in a country in which the electricity cuts for a long time like 5 hours to 8 hours. My ups can only keep the nas on for 30 minutes when the electricity cuts so when the electricity cuts for a long time I am switching off the nas. Also I am switching off the ups because it beeps when the electricity cuts.\n\nI don't like to regularly switch the nas and ups off and on so I need a way to keep them on when the electricity cuts for a long time. There are portable ac generators which can give you electricity when you are outdoors. I want to buy one and I will use it like this: portable ac generator --&gt; ups --&gt; nas. For example there is this [https://mojitech.net/product/portable-power-station-t300-300w-296wh-solar-generator-with-pd-usb-c-ports110v-pure-sine-wave-ac-outlet-cpap-backup-lithium-battery-with-led-light-for-camping-lebanon/](https://mojitech.net/product/portable-power-station-t300-300w-296wh-solar-generator-with-pd-usb-c-ports110v-pure-sine-wave-ac-outlet-cpap-backup-lithium-battery-with-led-light-for-camping-lebanon/). I want to ask:-\n\n1. For how many hours can a 80000mAh 296Wh portable ac generator keep the nas on when there is no electricity? How do I calculate the number of hours?\n2. Is it safe for the battery of the ups if the ups is connected to a portable ac generator?\n3. I can charge a portable ac generator by connecting it to a wall socket. There are portable ac generators which are 110v and the wall socket is 220v. Is that ok?\n4. If the ups is connected to a portable ac generator and the electricity cuts then the ups shouldn't beep because it is still getting electricity from the portable ac generator. Correct?", "author_fullname": "t2_5wph0by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the needed power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qnuw9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684940729.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684939854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a synology ds920+ nas and I am connecting it to an eaton 5e850iusb ups. The nas draws 45w power. I am currently living in a country in which the electricity cuts for a long time like 5 hours to 8 hours. My ups can only keep the nas on for 30 minutes when the electricity cuts so when the electricity cuts for a long time I am switching off the nas. Also I am switching off the ups because it beeps when the electricity cuts.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t like to regularly switch the nas and ups off and on so I need a way to keep them on when the electricity cuts for a long time. There are portable ac generators which can give you electricity when you are outdoors. I want to buy one and I will use it like this: portable ac generator --&amp;gt; ups --&amp;gt; nas. For example there is this &lt;a href=\"https://mojitech.net/product/portable-power-station-t300-300w-296wh-solar-generator-with-pd-usb-c-ports110v-pure-sine-wave-ac-outlet-cpap-backup-lithium-battery-with-led-light-for-camping-lebanon/\"&gt;https://mojitech.net/product/portable-power-station-t300-300w-296wh-solar-generator-with-pd-usb-c-ports110v-pure-sine-wave-ac-outlet-cpap-backup-lithium-battery-with-led-light-for-camping-lebanon/&lt;/a&gt;. I want to ask:-&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;For how many hours can a 80000mAh 296Wh portable ac generator keep the nas on when there is no electricity? How do I calculate the number of hours?&lt;/li&gt;\n&lt;li&gt;Is it safe for the battery of the ups if the ups is connected to a portable ac generator?&lt;/li&gt;\n&lt;li&gt;I can charge a portable ac generator by connecting it to a wall socket. There are portable ac generators which are 110v and the wall socket is 220v. Is that ok?&lt;/li&gt;\n&lt;li&gt;If the ups is connected to a portable ac generator and the electricity cuts then the ups shouldn&amp;#39;t beep because it is still getting electricity from the portable ac generator. Correct?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eWk9g7SHYiHv7azqaRplL1IldOWx6gFn7PVEO4-7pDc.jpg?auto=webp&amp;v=enabled&amp;s=779c3fcf0007874115f2b05263487beb81878bf9", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/eWk9g7SHYiHv7azqaRplL1IldOWx6gFn7PVEO4-7pDc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c23ee576fdc9812b94da02bfbe421abf104b9c3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/eWk9g7SHYiHv7azqaRplL1IldOWx6gFn7PVEO4-7pDc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a66b44d10d85d71fcbf43e7232f32a5d70adfbf", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/eWk9g7SHYiHv7azqaRplL1IldOWx6gFn7PVEO4-7pDc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=513ba2f69559fa9129066f234496aa9100d18947", "width": 320, "height": 320}], "variants": {}, "id": "8KdqUeYuLX9JpKdlV3J7Cx0XPh-j8ul_Lw00qCIzQco"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13qnuw9", "is_robot_indexable": true, "report_reasons": null, "author": "cns000", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qnuw9/what_is_the_needed_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qnuw9/what_is_the_needed_power/", "subreddit_subscribers": 684094, "created_utc": 1684939854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Raid card died. I swapped it for another and it died within a day. Card is a LSI 9886cv-8e installed into R510 cabled to DS4246 stack. I'm wondering if it's a bad cable, bad iom6, or bad pcie slot on the server. Anyone have advice on troubleshooting before I put another Raid card in and burn it too?", "author_fullname": "t2_4lcd732x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID card died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qnekk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684938760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Raid card died. I swapped it for another and it died within a day. Card is a LSI 9886cv-8e installed into R510 cabled to DS4246 stack. I&amp;#39;m wondering if it&amp;#39;s a bad cable, bad iom6, or bad pcie slot on the server. Anyone have advice on troubleshooting before I put another Raid card in and burn it too?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qnekk", "is_robot_indexable": true, "report_reasons": null, "author": "Valanog", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qnekk/raid_card_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qnekk/raid_card_died/", "subreddit_subscribers": 684094, "created_utc": 1684938760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there any software that can bulk download all the images in a Wordpress blog? \nI tried with JDownloader2, but it was very disorganized and only downloaded 1 page instead of the whole blog", "author_fullname": "t2_agltsfum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk image downloading from a Wordpress blog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qjjlp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684929646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any software that can bulk download all the images in a Wordpress blog? \nI tried with JDownloader2, but it was very disorganized and only downloaded 1 page instead of the whole blog&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qjjlp", "is_robot_indexable": true, "report_reasons": null, "author": "No_Price_3299", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qjjlp/bulk_image_downloading_from_a_wordpress_blog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qjjlp/bulk_image_downloading_from_a_wordpress_blog/", "subreddit_subscribers": 684094, "created_utc": 1684929646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys, I\u2019m currently using two Mediasonic 8 bay towers with USB 3.1 capabilities. Linked below\n\nhttps://a.co/d/djDEy3L\n\nThey\u2019ve been incredible in running my Plex server in which I have 10-15 active streamers with as many as 8-10 simultaneous streams. Unfortunately, there was flooding in the room they are located and both of them died. Hopefully none of the hard drives but that\u2019s yet to be determined.  \n\nSince they were working great for more than 2 years, I\u2019m not planning on replacing them with different models or brands but I\u2019m looking at two versions: one that supports USB 3.1 (linked above) and the other which supports 3.0 (linked below). \n\nhttps://a.co/d/1J6W9No\n\nI get that for HDDs USB 3.0 is more than enough but wouldn\u2019t the 3.1 perform much better when I have streams running from multiple HDDs? \n\nFor example, I have show X on 1 HDD and movie Y on another, and you can extrapolate on that example by adding many more video files. Will there come a point where USB 3.1 is needed to ensure stable streams?", "author_fullname": "t2_st621ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mediasonic 8 bay USB 3.0 or 3.1?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qil92", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684926995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I\u2019m currently using two Mediasonic 8 bay towers with USB 3.1 capabilities. Linked below&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://a.co/d/djDEy3L\"&gt;https://a.co/d/djDEy3L&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They\u2019ve been incredible in running my Plex server in which I have 10-15 active streamers with as many as 8-10 simultaneous streams. Unfortunately, there was flooding in the room they are located and both of them died. Hopefully none of the hard drives but that\u2019s yet to be determined.  &lt;/p&gt;\n\n&lt;p&gt;Since they were working great for more than 2 years, I\u2019m not planning on replacing them with different models or brands but I\u2019m looking at two versions: one that supports USB 3.1 (linked above) and the other which supports 3.0 (linked below). &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://a.co/d/1J6W9No\"&gt;https://a.co/d/1J6W9No&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I get that for HDDs USB 3.0 is more than enough but wouldn\u2019t the 3.1 perform much better when I have streams running from multiple HDDs? &lt;/p&gt;\n\n&lt;p&gt;For example, I have show X on 1 HDD and movie Y on another, and you can extrapolate on that example by adding many more video files. Will there come a point where USB 3.1 is needed to ensure stable streams?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qil92", "is_robot_indexable": true, "report_reasons": null, "author": "Naif1992", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qil92/mediasonic_8_bay_usb_30_or_31/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qil92/mediasonic_8_bay_usb_30_or_31/", "subreddit_subscribers": 684094, "created_utc": 1684926995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like a system similar to what Dropbox and [Sync.com](https://Sync.com) offers with their \"Rewind\" feature, that allows to undo a large number of changes at once. It's especially useful in case of major data loss, such as when a virus attacks your account (ransomware).\n\nI was interested in using [MEGA.nz](https://MEGA.nz), but they have no real way to quickly and easily recover data in case of massive modification by ransomware.\n\nWebsites like [Alternativeto.net](https://Alternativeto.net) doesn't list that specific feature to filter services, so I wonder if you knew some cloud storage provider with a full data rewind feature other than Dropbox and [Sync.com](https://Sync.com)?", "author_fullname": "t2_46dtq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you know some cloud storage provider with a full data rewind feature other than Dropbox and Sync.com?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qgio0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684920040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like a system similar to what Dropbox and &lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt; offers with their &amp;quot;Rewind&amp;quot; feature, that allows to undo a large number of changes at once. It&amp;#39;s especially useful in case of major data loss, such as when a virus attacks your account (ransomware).&lt;/p&gt;\n\n&lt;p&gt;I was interested in using &lt;a href=\"https://MEGA.nz\"&gt;MEGA.nz&lt;/a&gt;, but they have no real way to quickly and easily recover data in case of massive modification by ransomware.&lt;/p&gt;\n\n&lt;p&gt;Websites like &lt;a href=\"https://Alternativeto.net\"&gt;Alternativeto.net&lt;/a&gt; doesn&amp;#39;t list that specific feature to filter services, so I wonder if you knew some cloud storage provider with a full data rewind feature other than Dropbox and &lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qgio0", "is_robot_indexable": true, "report_reasons": null, "author": "AyneHancer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qgio0/do_you_know_some_cloud_storage_provider_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qgio0/do_you_know_some_cloud_storage_provider_with_a/", "subreddit_subscribers": 684094, "created_utc": 1684920040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am feeling there is a current trend to trying to \"monetize\" certain websites and features and am fearing that stackoverflow might go with it, is there anything to do regarding this? Besides this point, how realistic, is the idea of having an offline copy of stackoverflow? I mean after all, all that is needed to preserve are technically pages of text? right?", "author_fullname": "t2_3yyuddqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am worried about stackoverflow, is there anything we/I/someone can do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qgb5a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684919307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am feeling there is a current trend to trying to &amp;quot;monetize&amp;quot; certain websites and features and am fearing that stackoverflow might go with it, is there anything to do regarding this? Besides this point, how realistic, is the idea of having an offline copy of stackoverflow? I mean after all, all that is needed to preserve are technically pages of text? right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qgb5a", "is_robot_indexable": true, "report_reasons": null, "author": "PsychologicalDrawer0", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qgb5a/i_am_worried_about_stackoverflow_is_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qgb5a/i_am_worried_about_stackoverflow_is_there/", "subreddit_subscribers": 684094, "created_utc": 1684919307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is what I am working with: \n\n&gt;reddit-img-dl --save-dir c:  --user cantstoppoppin --subreddit worldnewsvideo --sort-top 1000 --concurrency 1000\n\nWhen I start the command, it begins the process then suddenly stops. Could someone please explain what I am doing wrong. Thank you for your time and understanding in this matter any help would be much apricated.", "author_fullname": "t2_173icc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could someone please review my reddit-img-dl command", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qc0b2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684905132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is what I am working with: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;reddit-img-dl --save-dir c:  --user cantstoppoppin --subreddit worldnewsvideo --sort-top 1000 --concurrency 1000&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;When I start the command, it begins the process then suddenly stops. Could someone please explain what I am doing wrong. Thank you for your time and understanding in this matter any help would be much apricated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qc0b2", "is_robot_indexable": true, "report_reasons": null, "author": "CantStopPoppin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qc0b2/could_someone_please_review_my_redditimgdl_command/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qc0b2/could_someone_please_review_my_redditimgdl_command/", "subreddit_subscribers": 684094, "created_utc": 1684905132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like the title says... A group of friends has a long running (7+ years) group chat on Facebook. How can I archive the entirety of our chat history, including images etc that have been shared? Is there a decent automated tool for this? Do they have an Api I could use? I am a developer by trade, so scripting against an Api isn't hard for me.", "author_fullname": "t2_83iyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook Messenger Group Chat - Archive all messages and images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q5uqu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684888113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like the title says... A group of friends has a long running (7+ years) group chat on Facebook. How can I archive the entirety of our chat history, including images etc that have been shared? Is there a decent automated tool for this? Do they have an Api I could use? I am a developer by trade, so scripting against an Api isn&amp;#39;t hard for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q5uqu", "is_robot_indexable": true, "report_reasons": null, "author": "rswafford", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q5uqu/facebook_messenger_group_chat_archive_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13q5uqu/facebook_messenger_group_chat_archive_all/", "subreddit_subscribers": 684094, "created_utc": 1684888113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been active on Quora for well over 6 years now, and some users keep surprising me with quality content. Here's the thing: I'd like to catalog all answers of a few users so I can skim through the old ones as well instead of just having access to their recent content. The problem with Quora is that it's very hard to efficiently search answers - you literally have to scroll down on someone's profile to read all of the old stuff - a task that's quite literally impossible for writers with more than a 1,000 answers.\n\nAre there any ways in which I can efficiently download someone's entire feed? I've tried [this](https://www.quora.com/Can-you-download-all-Quora-answers-from-one-person/answer/Mehul-Mohan?no_redirect=1), but it gets stuck after about 1,200 answers. The specific user whose feed I'd most like to download has over &gt;12,000 answers. Is there any way to efficiently collect these answers?\n\nThanks if anyone here could help me, it would be greatly appreciated.", "author_fullname": "t2_2th6gqmm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to download someone's entire Quora feed (with &gt;10k posts)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q3939", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684881531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been active on Quora for well over 6 years now, and some users keep surprising me with quality content. Here&amp;#39;s the thing: I&amp;#39;d like to catalog all answers of a few users so I can skim through the old ones as well instead of just having access to their recent content. The problem with Quora is that it&amp;#39;s very hard to efficiently search answers - you literally have to scroll down on someone&amp;#39;s profile to read all of the old stuff - a task that&amp;#39;s quite literally impossible for writers with more than a 1,000 answers.&lt;/p&gt;\n\n&lt;p&gt;Are there any ways in which I can efficiently download someone&amp;#39;s entire feed? I&amp;#39;ve tried &lt;a href=\"https://www.quora.com/Can-you-download-all-Quora-answers-from-one-person/answer/Mehul-Mohan?no_redirect=1\"&gt;this&lt;/a&gt;, but it gets stuck after about 1,200 answers. The specific user whose feed I&amp;#39;d most like to download has over &amp;gt;12,000 answers. Is there any way to efficiently collect these answers?&lt;/p&gt;\n\n&lt;p&gt;Thanks if anyone here could help me, it would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EZhZrqPluVknG_AuDaGgA3-j9BNWazNyCSZ_QJv6Avk.jpg?auto=webp&amp;v=enabled&amp;s=19096863413702b11238c3c048384142910c2ded", "width": 256, "height": 87}, "resolutions": [{"url": "https://external-preview.redd.it/EZhZrqPluVknG_AuDaGgA3-j9BNWazNyCSZ_QJv6Avk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7cb3075d34b670540c7b8ca0888f0ea2c483f214", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/EZhZrqPluVknG_AuDaGgA3-j9BNWazNyCSZ_QJv6Avk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb02b6b80e1c4d55596c314229d150835660d118", "width": 216, "height": 73}], "variants": {}, "id": "5VOKBNDK_3e15katGJ_vEEVc_4dTNmDqRxmF4FVExdE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q3939", "is_robot_indexable": true, "report_reasons": null, "author": "Per451", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q3939/i_want_to_download_someones_entire_quora_feed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13q3939/i_want_to_download_someones_entire_quora_feed/", "subreddit_subscribers": 684094, "created_utc": 1684881531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI'm currently rethinking my backup/archival strategy, and I was wondering if tape drives give a good solution for home use.\n\nCurrently I have a single copy of all my files locally, and the most important, irreplacable data is also in the cloud. But this seems a bit too little, so I was thinking what else should I do.\n\nI was thinking about tape, because they are small, easy to carry for example to an offsite location, and from what I've seen, cost less /TB than a HDD. (I have around 3TB of important data, and another 6 which is replacable but would be a PITA).\n\n&amp;#x200B;\n\nWhat do you guys think? And what about tape storage in general?\n\n&amp;#x200B;\n\nEdit: I've looked at the tape drive prices..... HUH", "author_fullname": "t2_1381kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tape drives for home archiving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13qq178", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684945460.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684945024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently rethinking my backup/archival strategy, and I was wondering if tape drives give a good solution for home use.&lt;/p&gt;\n\n&lt;p&gt;Currently I have a single copy of all my files locally, and the most important, irreplacable data is also in the cloud. But this seems a bit too little, so I was thinking what else should I do.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about tape, because they are small, easy to carry for example to an offsite location, and from what I&amp;#39;ve seen, cost less /TB than a HDD. (I have around 3TB of important data, and another 6 which is replacable but would be a PITA).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? And what about tape storage in general?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;ve looked at the tape drive prices..... HUH&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qq178", "is_robot_indexable": true, "report_reasons": null, "author": "Shapperd", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13qq178/tape_drives_for_home_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qq178/tape_drives_for_home_archiving/", "subreddit_subscribers": 684094, "created_utc": 1684945024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My download directory `D:\\Misc\\Downloads` contains folders. I use [dirhash](https://idrassi.github.io/DirHash/) on each folder and export the sumfile to inside the folder.\n\nFor example, say I've got two folders in that directory that are called \"FolderOne\" and \"FolderTwo\", that'd mean:\n\n    dirhash \"D:\\Misc\\Downloads\\FolderOne\" Blake3 -t \"D:\\Misc\\Downloads\\FolderOne\\sumfile.blake3\" -progress -sum -sumRelativePath -nowait -nologo -quiet\n    dirhash \"D:\\Misc\\Downloads\\FolderTwo\" Blake3 -t \"D:\\Misc\\Downloads\\FolderTwo\\sumfile.blake3\" -progress -sum -sumRelativePath -nowait -nologo -quiet\n\nI want to run a script that does this for each folder in that download directory. If someone knows how, please help me.", "author_fullname": "t2_6m84ad7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with automating Dirhash on folders inside a directory (Dirhash is a sumfile CLI tool)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qliy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684934432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My download directory &lt;code&gt;D:\\Misc\\Downloads&lt;/code&gt; contains folders. I use &lt;a href=\"https://idrassi.github.io/DirHash/\"&gt;dirhash&lt;/a&gt; on each folder and export the sumfile to inside the folder.&lt;/p&gt;\n\n&lt;p&gt;For example, say I&amp;#39;ve got two folders in that directory that are called &amp;quot;FolderOne&amp;quot; and &amp;quot;FolderTwo&amp;quot;, that&amp;#39;d mean:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;dirhash &amp;quot;D:\\Misc\\Downloads\\FolderOne&amp;quot; Blake3 -t &amp;quot;D:\\Misc\\Downloads\\FolderOne\\sumfile.blake3&amp;quot; -progress -sum -sumRelativePath -nowait -nologo -quiet\ndirhash &amp;quot;D:\\Misc\\Downloads\\FolderTwo&amp;quot; Blake3 -t &amp;quot;D:\\Misc\\Downloads\\FolderTwo\\sumfile.blake3&amp;quot; -progress -sum -sumRelativePath -nowait -nologo -quiet\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I want to run a script that does this for each folder in that download directory. If someone knows how, please help me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qliy5", "is_robot_indexable": true, "report_reasons": null, "author": "Jungy1eong", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qliy5/help_with_automating_dirhash_on_folders_inside_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qliy5/help_with_automating_dirhash_on_folders_inside_a/", "subreddit_subscribers": 684094, "created_utc": 1684934432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got wfdownloader but can't find a setting to get it to download images to 1 folder, instead of 100+ folders with 1 image each from a gallery. Can anyone help me?", "author_fullname": "t2_erkql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm trying to use wfdownloader on reddit but it's downloading each image in its own folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qds7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684910522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got wfdownloader but can&amp;#39;t find a setting to get it to download images to 1 folder, instead of 100+ folders with 1 image each from a gallery. Can anyone help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qds7y", "is_robot_indexable": true, "report_reasons": null, "author": "Likander", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qds7y/im_trying_to_use_wfdownloader_on_reddit_but_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qds7y/im_trying_to_use_wfdownloader_on_reddit_but_its/", "subreddit_subscribers": 684094, "created_utc": 1684910522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What file transfer app is easy to use and has things like checking files/folders for the same data and only writing new data like teracopy has? Bonus if it checks the files for successful copy. Need it for mac something with a gui.", "author_fullname": "t2_797nmkox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teracopy like", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qdb5u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1684909588.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684908938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What file transfer app is easy to use and has things like checking files/folders for the same data and only writing new data like teracopy has? Bonus if it checks the files for successful copy. Need it for mac something with a gui.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qdb5u", "is_robot_indexable": true, "report_reasons": null, "author": "Simkinn1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qdb5u/teracopy_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qdb5u/teracopy_like/", "subreddit_subscribers": 684094, "created_utc": 1684908938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently, I have my server running on Windows because I bought DrivePool a long while back, as I came from Windows Home Server, and Windows is generally my background.\n\nI've been considering moving to a Linux server, probably Ubuntu because I'm somewhat familiar with Mint. I'd like to keep using a JBOD, but I can pull enough data off to use a single 8tb drive to kickstart a file system change.\n\nCan default Ubuntu Server JBOD disks like this? I need the pool accessible for network shares to Windows, and under a single mount point for deluge and Plex.", "author_fullname": "t2_8cd14", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stablebit DrivePool alternative for Linux", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q7w8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684893680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have my server running on Windows because I bought DrivePool a long while back, as I came from Windows Home Server, and Windows is generally my background.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been considering moving to a Linux server, probably Ubuntu because I&amp;#39;m somewhat familiar with Mint. I&amp;#39;d like to keep using a JBOD, but I can pull enough data off to use a single 8tb drive to kickstart a file system change.&lt;/p&gt;\n\n&lt;p&gt;Can default Ubuntu Server JBOD disks like this? I need the pool accessible for network shares to Windows, and under a single mount point for deluge and Plex.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "38Tb", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q7w8b", "is_robot_indexable": true, "report_reasons": null, "author": "raduque", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13q7w8b/stablebit_drivepool_alternative_for_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13q7w8b/stablebit_drivepool_alternative_for_linux/", "subreddit_subscribers": 684094, "created_utc": 1684893680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I renamed the folders on one drive (added the year) and want to rename the same folders I have (with the same content) on another drive. \n\nI'm trying to avoid moving files and is there a faster way than clicking on each folder and adding the date info to match the source drive?\n\nKeep in mind these are only directories, I'm not renaming any files.", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Renaming directories quickly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q3rgs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684882748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I renamed the folders on one drive (added the year) and want to rename the same folders I have (with the same content) on another drive. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to avoid moving files and is there a faster way than clicking on each folder and adding the date info to match the source drive?&lt;/p&gt;\n\n&lt;p&gt;Keep in mind these are only directories, I&amp;#39;m not renaming any files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13q3rgs", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13q3rgs/renaming_directories_quickly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13q3rgs/renaming_directories_quickly/", "subreddit_subscribers": 684094, "created_utc": 1684882748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, since Google Drive has now enforced the usage limit on my account and that in 2 months I'll be locked in read-only, I'm looking at a cost effective alternative to backup my local server.\n\nRoughly speaking I currently have used around 36TB of data of 100TB of usable data pool on my home server. I would like to estimate the costs of using Amazon S3 and the downsides of it.\n\nLet's speak for a theoretical 50TB of data.\n\nFor S3 Glacier Deep Archive, the initial upload would be at $0.00099 per GB which would mean a $49.50 USD per month.\n\nI find it hard to comprehend but it seems by reading their documentation you have to pay for 6 months of usage for any files that are uploaded even though you delete/replace them by a new copy.\n\nI guess that only the fact of moving files and reorganizing data on my server would count as new copies right?\n\nSo is the only viable option is to live with the fact that I have an updated backup every 6 months without additional costs?\n\nSo I would setup a Amazon S3 Cloud sync task in TrueNAS to run every 6 months and voila? BUT\n\nI counted that if I have to retrieve 80TB of data at their current rate it would cost $6200 USD in case of a major failure. This is double the price of a new server (that I currently cannot afford) where I could store all my data without any limitations.\n\nI value my digital data which contains a lot of work and rare stuff. What people in my situation will do to backup hundred of TB of data?", "author_fullname": "t2_hbwoyw04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Amazon S3... what would you do in my situation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pzys5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684874205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, since Google Drive has now enforced the usage limit on my account and that in 2 months I&amp;#39;ll be locked in read-only, I&amp;#39;m looking at a cost effective alternative to backup my local server.&lt;/p&gt;\n\n&lt;p&gt;Roughly speaking I currently have used around 36TB of data of 100TB of usable data pool on my home server. I would like to estimate the costs of using Amazon S3 and the downsides of it.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s speak for a theoretical 50TB of data.&lt;/p&gt;\n\n&lt;p&gt;For S3 Glacier Deep Archive, the initial upload would be at $0.00099 per GB which would mean a $49.50 USD per month.&lt;/p&gt;\n\n&lt;p&gt;I find it hard to comprehend but it seems by reading their documentation you have to pay for 6 months of usage for any files that are uploaded even though you delete/replace them by a new copy.&lt;/p&gt;\n\n&lt;p&gt;I guess that only the fact of moving files and reorganizing data on my server would count as new copies right?&lt;/p&gt;\n\n&lt;p&gt;So is the only viable option is to live with the fact that I have an updated backup every 6 months without additional costs?&lt;/p&gt;\n\n&lt;p&gt;So I would setup a Amazon S3 Cloud sync task in TrueNAS to run every 6 months and voila? BUT&lt;/p&gt;\n\n&lt;p&gt;I counted that if I have to retrieve 80TB of data at their current rate it would cost $6200 USD in case of a major failure. This is double the price of a new server (that I currently cannot afford) where I could store all my data without any limitations.&lt;/p&gt;\n\n&lt;p&gt;I value my digital data which contains a lot of work and rare stuff. What people in my situation will do to backup hundred of TB of data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13pzys5", "is_robot_indexable": true, "report_reasons": null, "author": "igmyeongui", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13pzys5/amazon_s3_what_would_you_do_in_my_situation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13pzys5/amazon_s3_what_would_you_do_in_my_situation/", "subreddit_subscribers": 684094, "created_utc": 1684874205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't know if that's the right software to rip dvds, that's my first time and I would like to learn more about ripping physical datas. Also the movie i ripped doesn't have audio", "author_fullname": "t2_72f3pm64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm trying to RIP a DVD with VLC, but It seems like i can't extract the extras included with the movie", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pyqhr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684871468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if that&amp;#39;s the right software to rip dvds, that&amp;#39;s my first time and I would like to learn more about ripping physical datas. Also the movie i ripped doesn&amp;#39;t have audio&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13pyqhr", "is_robot_indexable": true, "report_reasons": null, "author": "bisn_moment", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13pyqhr/im_trying_to_rip_a_dvd_with_vlc_but_it_seems_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13pyqhr/im_trying_to_rip_a_dvd_with_vlc_but_it_seems_like/", "subreddit_subscribers": 684094, "created_utc": 1684871468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How would I get all the rapidgator links from this site? :\n\n[https://www.zorg.video/](https://www.zorg.video/) (old celebrity-clips)", "author_fullname": "t2_206b6g12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting all the links from a site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13pyfos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684870787.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How would I get all the rapidgator links from this site? :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.zorg.video/\"&gt;https://www.zorg.video/&lt;/a&gt; (old celebrity-clips)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13pyfos", "is_robot_indexable": true, "report_reasons": null, "author": "deggersen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13pyfos/getting_all_the_links_from_a_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13pyfos/getting_all_the_links_from_a_site/", "subreddit_subscribers": 684094, "created_utc": 1684870787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to store up to 2 TB of videos and photos in the cloud. Most are old media which I may want to view again in a few years. \n\nCurrently, I subscribe to BackBlaze's personal backup service, which I can use to sorta archive my media for a year. This obviously isn't the ideal solution to my dilemma, so I'm looking for alternatives.\n\nI googled and browsed around this sub a lot to find the answer to my question, but I wasn't too successful. I have found a TON of options, but not a lot of help deciding which option fits best.\n\nThe qBackup site seems to have nice price comparison charts which include most of the services I've seen mentioned while researching: [https://www.qualeed.com/en/qbackup/cloud-storage-comparison/](https://www.qualeed.com/en/qbackup/cloud-storage-comparison/)\n\nWhen I saw the Amazon S3 Glacier, I thought this might be my best option. Upon further inspection, the pricing became quite confusing. Even reading Reddit posts, it seems like the downside here is that you're going to pay a lot when retrieving your data. \n\nI also saw Google's Archive Storage, which again seems ideal, but the pricing gets confusing.\n\nJust to clarify my goals:\n\n* Store pictures, videos, and maybe files (around 2tb, with room for growth)\n* I may add new media I've incurred to the storage each month\n* It'd be great to be able to look at the stored media maybe a few times a year (for cheap or free), but I'm also not expecting this and am fine with only being able to retrieve it say once after 5 years for a fee", "author_fullname": "t2_ci7xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Choice for Long-Term Storage of Media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qgay5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684919289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to store up to 2 TB of videos and photos in the cloud. Most are old media which I may want to view again in a few years. &lt;/p&gt;\n\n&lt;p&gt;Currently, I subscribe to BackBlaze&amp;#39;s personal backup service, which I can use to sorta archive my media for a year. This obviously isn&amp;#39;t the ideal solution to my dilemma, so I&amp;#39;m looking for alternatives.&lt;/p&gt;\n\n&lt;p&gt;I googled and browsed around this sub a lot to find the answer to my question, but I wasn&amp;#39;t too successful. I have found a TON of options, but not a lot of help deciding which option fits best.&lt;/p&gt;\n\n&lt;p&gt;The qBackup site seems to have nice price comparison charts which include most of the services I&amp;#39;ve seen mentioned while researching: &lt;a href=\"https://www.qualeed.com/en/qbackup/cloud-storage-comparison/\"&gt;https://www.qualeed.com/en/qbackup/cloud-storage-comparison/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;When I saw the Amazon S3 Glacier, I thought this might be my best option. Upon further inspection, the pricing became quite confusing. Even reading Reddit posts, it seems like the downside here is that you&amp;#39;re going to pay a lot when retrieving your data. &lt;/p&gt;\n\n&lt;p&gt;I also saw Google&amp;#39;s Archive Storage, which again seems ideal, but the pricing gets confusing.&lt;/p&gt;\n\n&lt;p&gt;Just to clarify my goals:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Store pictures, videos, and maybe files (around 2tb, with room for growth)&lt;/li&gt;\n&lt;li&gt;I may add new media I&amp;#39;ve incurred to the storage each month&lt;/li&gt;\n&lt;li&gt;It&amp;#39;d be great to be able to look at the stored media maybe a few times a year (for cheap or free), but I&amp;#39;m also not expecting this and am fine with only being able to retrieve it say once after 5 years for a fee&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13qgay5", "is_robot_indexable": true, "report_reasons": null, "author": "MonzterSlayer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13qgay5/best_choice_for_longterm_storage_of_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13qgay5/best_choice_for_longterm_storage_of_media/", "subreddit_subscribers": 684094, "created_utc": 1684919289.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}