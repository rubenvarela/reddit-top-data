{"kind": "Listing", "data": {"after": "t3_13qlds6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have experience as a BI Developer / Analytics Engineer using dbt/airflow/SQL/Snowflake/BQ/python etc... I think I have all the concepts to understand it, but nothing online is explaining to me exactly what it is, can someone try and explain it to me in a way which I will understand?", "author_fullname": "t2_41nvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why can I not understand what DataBricks is? Can someone explain slowly?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qg3t1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 100, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 100, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684918600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience as a BI Developer / Analytics Engineer using dbt/airflow/SQL/Snowflake/BQ/python etc... I think I have all the concepts to understand it, but nothing online is explaining to me exactly what it is, can someone try and explain it to me in a way which I will understand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qg3t1", "is_robot_indexable": true, "report_reasons": null, "author": "wallyflops", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qg3t1/why_can_i_not_understand_what_databricks_is_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qg3t1/why_can_i_not_understand_what_databricks_is_can/", "subreddit_subscribers": 107104, "created_utc": 1684918600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I'm a data engineer working with the usual suspects Python, SQL (BigQuery), bit of Spark, Terraform, Power BI etc.\n\nWhat's happening is that I'll get a task whether from my manager, or others within the business e.g. I want to see this report. I find where the data is at, get into data warehouse, build a very simple report in Power BI for business user (analysts tied up doing whatever). This is what my day to day looks like:\n\n1. I get an \"urgent\" task.\n2. I drop current task to do urgent task.\n3. I get another \"urgent\" task.\n4. Repeat step 2 and 3.\n5. Get messages and/or email reminders and meeting requests from stakeholders, for updates, estimated completion dates, and the importance of said task (sometimes ignore or spend time formulating a response explaining the hold up).\n6. Stakeholder complains to manager about their task.\n7. Manager tells me to go back to task X, and complete as quickly as possible and return to \"urgent\" task X.\n8. Meeting to discuss another task.\n9. Go to step 1.\n\nThis leads to half-baked work and nagging from users.\n\nI'm not overwhelmed or stressed or anything (I don't think/feel I am anyways), the work isn't overly complicated or difficult, help is always available (kind of), I'm happy with the pay...I do like data engineering (love is a strong word hence like), I enjoy it. I've just become **bored**, to the point where when it's time work, I don't feel like doing ANYTHING. I can't get myself to type code, message anyone, find the bug, etc etc\n\nAnyone else been in this situation before? Am I doing something wrong? Am I missing something? If so, what?\n\nBrash, savage, direct, punishing feedback and comments are all welcome.", "author_fullname": "t2_4gzaf8mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting bored, who to blame?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qijjq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684926848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I&amp;#39;m a data engineer working with the usual suspects Python, SQL (BigQuery), bit of Spark, Terraform, Power BI etc.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s happening is that I&amp;#39;ll get a task whether from my manager, or others within the business e.g. I want to see this report. I find where the data is at, get into data warehouse, build a very simple report in Power BI for business user (analysts tied up doing whatever). This is what my day to day looks like:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I get an &amp;quot;urgent&amp;quot; task.&lt;/li&gt;\n&lt;li&gt;I drop current task to do urgent task.&lt;/li&gt;\n&lt;li&gt;I get another &amp;quot;urgent&amp;quot; task.&lt;/li&gt;\n&lt;li&gt;Repeat step 2 and 3.&lt;/li&gt;\n&lt;li&gt;Get messages and/or email reminders and meeting requests from stakeholders, for updates, estimated completion dates, and the importance of said task (sometimes ignore or spend time formulating a response explaining the hold up).&lt;/li&gt;\n&lt;li&gt;Stakeholder complains to manager about their task.&lt;/li&gt;\n&lt;li&gt;Manager tells me to go back to task X, and complete as quickly as possible and return to &amp;quot;urgent&amp;quot; task X.&lt;/li&gt;\n&lt;li&gt;Meeting to discuss another task.&lt;/li&gt;\n&lt;li&gt;Go to step 1.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This leads to half-baked work and nagging from users.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not overwhelmed or stressed or anything (I don&amp;#39;t think/feel I am anyways), the work isn&amp;#39;t overly complicated or difficult, help is always available (kind of), I&amp;#39;m happy with the pay...I do like data engineering (love is a strong word hence like), I enjoy it. I&amp;#39;ve just become &lt;strong&gt;bored&lt;/strong&gt;, to the point where when it&amp;#39;s time work, I don&amp;#39;t feel like doing ANYTHING. I can&amp;#39;t get myself to type code, message anyone, find the bug, etc etc&lt;/p&gt;\n\n&lt;p&gt;Anyone else been in this situation before? Am I doing something wrong? Am I missing something? If so, what?&lt;/p&gt;\n\n&lt;p&gt;Brash, savage, direct, punishing feedback and comments are all welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qijjq", "is_robot_indexable": true, "report_reasons": null, "author": "theoriginalmantooth", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qijjq/getting_bored_who_to_blame/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qijjq/getting_bored_who_to_blame/", "subreddit_subscribers": 107104, "created_utc": 1684926848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6jhkkc1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Engineer | Scientist | ML | Analyst over 11 sub-domains", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13qfean", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JHX0AqGSlKiuWZQh5_N437BZSFvSRJGp8Wj76kweGIo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684916065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fh129qkomq1b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fh129qkomq1b1.jpg?auto=webp&amp;v=enabled&amp;s=a6bad033e5e1283c6393ccb7e43d069b3aebd8bd", "width": 800, "height": 879}, "resolutions": [{"url": "https://preview.redd.it/fh129qkomq1b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f591e53cf2415893349f2d9b85cdca547b00165d", "width": 108, "height": 118}, {"url": "https://preview.redd.it/fh129qkomq1b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9db2d5f3cfc3df1121d0a1b3948dd748ffae3580", "width": 216, "height": 237}, {"url": "https://preview.redd.it/fh129qkomq1b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2557d53d1b1327f14ead551a2a1a6e0f1d21af15", "width": 320, "height": 351}, {"url": "https://preview.redd.it/fh129qkomq1b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c68be588f99e0be4a70a27a0d0d4dc99201f01f", "width": 640, "height": 703}], "variants": {}, "id": "CPjSAQ5St6V_hZc7ix6WRcrrIa6hFBn_rgMyjQcOaQI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13qfean", "is_robot_indexable": true, "report_reasons": null, "author": "Meta-Morpheus-New", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qfean/engineer_scientist_ml_analyst_over_11_subdomains/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fh129qkomq1b1.jpg", "subreddit_subscribers": 107104, "created_utc": 1684916065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nIf you've ever tried querying the Google Analytics 4 BigQuery export, you know how challenging it can be to pull simple metrics like sessions, users, transactions, etc. With so many dimensions and metrics to consider, it's not always easy to figure out the logic behind each one.\n\nThat's why I'm happy to introduce ga4sql.com \u2013 a free and user-friendly tool that simplifies the querying process for Google Analytics 4 data in BigQuery. It enables users to generate GA4 BigQuery queries without requiring any SQL knowledge. GA4 SQL can save you hours of writing complex code.\n\nPlease try it out and let me know your thoughts.\n\n[https://www.ga4sql.com/](https://www.ga4sql.com/)", "author_fullname": "t2_sbozqrz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a tool to generate GA4 BigQuery Queries without SQL Knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qm2th", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684935699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve ever tried querying the Google Analytics 4 BigQuery export, you know how challenging it can be to pull simple metrics like sessions, users, transactions, etc. With so many dimensions and metrics to consider, it&amp;#39;s not always easy to figure out the logic behind each one.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why I&amp;#39;m happy to introduce ga4sql.com \u2013 a free and user-friendly tool that simplifies the querying process for Google Analytics 4 data in BigQuery. It enables users to generate GA4 BigQuery queries without requiring any SQL knowledge. GA4 SQL can save you hours of writing complex code.&lt;/p&gt;\n\n&lt;p&gt;Please try it out and let me know your thoughts.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ga4sql.com/\"&gt;https://www.ga4sql.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?auto=webp&amp;v=enabled&amp;s=2fe8e0e544fe57d6bbcdc244bebdb0272b0604ef", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36f1e9f88c0200079f47f210b6d67e1d5c4f6c41", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce1f34c71825170b35204ad4e178ae6cb0579f2", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce591e1a0e67f92c7827d1058798c237184773c1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95c5ed1403f435931b24da1e92e18e333b8cf776", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43299b8a74706c1bbfdf0b2db5cd0f49b0376d0b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ViVp4fXIqRPuousYN9LoaOIYNverSUZQJDO9T8PPfwA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cae482cf05a411d5bdd4ed3d2e94da18673791ed", "width": 1080, "height": 567}], "variants": {}, "id": "hvJRjIh6k6RDOdxpiLMzvT4j95faVsQqytGhMaSzFF4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13qm2th", "is_robot_indexable": true, "report_reasons": null, "author": "ahmedali13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qm2th/i_built_a_tool_to_generate_ga4_bigquery_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qm2th/i_built_a_tool_to_generate_ga4_bigquery_queries/", "subreddit_subscribers": 107104, "created_utc": 1684935699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nHello!\n\n  \nWhat are some recommended resources, such as books, courses, and online platforms, to study and prepare for a system design interview for a data engineer position? \n\nSpecifically, I'm looking for resources that focus on data-related aspects like data format, data model, and handling large data sets. I've heard that system design questions for data engineering positions differ from traditional software engineering system design interviews, and I would appreciate any insights, suggestions, or experiences shared. \n\nThank you!", "author_fullname": "t2_widhrw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "System design prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qp8yb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684943210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;What are some recommended resources, such as books, courses, and online platforms, to study and prepare for a system design interview for a data engineer position? &lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m looking for resources that focus on data-related aspects like data format, data model, and handling large data sets. I&amp;#39;ve heard that system design questions for data engineering positions differ from traditional software engineering system design interviews, and I would appreciate any insights, suggestions, or experiences shared. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13qp8yb", "is_robot_indexable": true, "report_reasons": null, "author": "luigi_ce", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qp8yb/system_design_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qp8yb/system_design_prep/", "subreddit_subscribers": 107104, "created_utc": 1684943210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to fundamentally change our data architecture and am looking at modern solutions. However, I\u2019m looking for someone(s) that have been there done that and can make some recommendations.\n\nWhat would you all recommend as a first step? I have, so far, been looking for a consultant.", "author_fullname": "t2_4i4nzjk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qh6dx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684922366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to fundamentally change our data architecture and am looking at modern solutions. However, I\u2019m looking for someone(s) that have been there done that and can make some recommendations.&lt;/p&gt;\n\n&lt;p&gt;What would you all recommend as a first step? I have, so far, been looking for a consultant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qh6dx", "is_robot_indexable": true, "report_reasons": null, "author": "aussiebea", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qh6dx/data_architecture_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qh6dx/data_architecture_consulting/", "subreddit_subscribers": 107104, "created_utc": 1684922366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/a5oqed6hcs1b1.png?width=565&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=81947152bd8862200fee05812e3e30f7b0c74cbe", "author_fullname": "t2_x0wpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rude.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "media_metadata": {"a5oqed6hcs1b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/a5oqed6hcs1b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebaac79fb043c8479f4e70a4eb81efef2c7b722b"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/a5oqed6hcs1b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=591ef76b8191fd8d32addb6474a4e55be7ac40e9"}, {"y": 209, "x": 320, "u": "https://preview.redd.it/a5oqed6hcs1b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=900a60ef37c2fe4f50ad7939a9fe4f0b72e05241"}], "s": {"y": 370, "x": 565, "u": "https://preview.redd.it/a5oqed6hcs1b1.png?width=565&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=81947152bd8862200fee05812e3e30f7b0c74cbe"}, "id": "a5oqed6hcs1b1"}}, "name": "t3_13qmjex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4ITDqKX6WMMLtUg9u2urD_iCLGg2OBhcWJRXOvKLopk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684936760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a5oqed6hcs1b1.png?width=565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=81947152bd8862200fee05812e3e30f7b0c74cbe\"&gt;https://preview.redd.it/a5oqed6hcs1b1.png?width=565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=81947152bd8862200fee05812e3e30f7b0c74cbe&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13qmjex", "is_robot_indexable": true, "report_reasons": null, "author": "CingKan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13qmjex/rude/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qmjex/rude/", "subreddit_subscribers": 107104, "created_utc": 1684936760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you guys get paid for weekends/ non office hours on call support? My lead and manager say it's hardly 15 minutes of work but it rarely is", "author_fullname": "t2_6pqvjmo2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On call support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qjiou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684929593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys get paid for weekends/ non office hours on call support? My lead and manager say it&amp;#39;s hardly 15 minutes of work but it rarely is&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13qjiou", "is_robot_indexable": true, "report_reasons": null, "author": "awesomeausome", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qjiou/on_call_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qjiou/on_call_support/", "subreddit_subscribers": 107104, "created_utc": 1684929593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI\u2019ve got the green light to get a cloud setup for our data pipeline/sources but am flipping between databricks and snowflake. \n\nOur historical data is around 10 tb and we move around 100/200 million rows per month (or expect to when the process is working). \n\nWe have a running prefect instance (single node) and are at the stage of where to move the data to centralize. Right now we pipe to an on prem sql server but we want to move to the cloud. \n\nAt that volume I\u2019m leaning towards databricks + lake format but is that jumping the gun early on for not much existing modelling, which is more sql based. We don\u2019t do ML right now but there is interest to get there. We\u2019re also using dbt for some sources but are hoping to build the SST from it on cloud (which both can do).  Cost is a factor too. They don\u2019t want to pay crazy money as a public entity.  \n\nTwo things for me, A what\u2019s best for the org and me to not have a zoo to maintain and B what\u2019s going to be good for me to put on a resume to get a better job after.\n\nThanks!", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data source for 100 million monthly rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qpgr1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684943721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got the green light to get a cloud setup for our data pipeline/sources but am flipping between databricks and snowflake. &lt;/p&gt;\n\n&lt;p&gt;Our historical data is around 10 tb and we move around 100/200 million rows per month (or expect to when the process is working). &lt;/p&gt;\n\n&lt;p&gt;We have a running prefect instance (single node) and are at the stage of where to move the data to centralize. Right now we pipe to an on prem sql server but we want to move to the cloud. &lt;/p&gt;\n\n&lt;p&gt;At that volume I\u2019m leaning towards databricks + lake format but is that jumping the gun early on for not much existing modelling, which is more sql based. We don\u2019t do ML right now but there is interest to get there. We\u2019re also using dbt for some sources but are hoping to build the SST from it on cloud (which both can do).  Cost is a factor too. They don\u2019t want to pay crazy money as a public entity.  &lt;/p&gt;\n\n&lt;p&gt;Two things for me, A what\u2019s best for the org and me to not have a zoo to maintain and B what\u2019s going to be good for me to put on a resume to get a better job after.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13qpgr1", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qpgr1/data_source_for_100_million_monthly_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qpgr1/data_source_for_100_million_monthly_rows/", "subreddit_subscribers": 107104, "created_utc": 1684943721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which are the best patterns and open-source packages I should look at when considering the following\n\n**Data inputs:**\n\n\\- Event data streamed via Kafka\n\n\\- Some data enrichment required from databases\n\n\\- Some transformation and aggregations required post enrichment\n\n&amp;#x200B;\n\n**Data outputs:**\n\nDashboard (real-time is preferred because some of these events require human intervention)", "author_fullname": "t2_48nrgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time dashboards with streaming data coming from Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qq4ag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684945223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which are the best patterns and open-source packages I should look at when considering the following&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data inputs:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Event data streamed via Kafka&lt;/p&gt;\n\n&lt;p&gt;- Some data enrichment required from databases&lt;/p&gt;\n\n&lt;p&gt;- Some transformation and aggregations required post enrichment&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data outputs:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Dashboard (real-time is preferred because some of these events require human intervention)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qq4ag", "is_robot_indexable": true, "report_reasons": null, "author": "anupsurendran", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qq4ag/realtime_dashboards_with_streaming_data_coming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qq4ag/realtime_dashboards_with_streaming_data_coming/", "subreddit_subscribers": 107104, "created_utc": 1684945223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nAs a data analyst, sometimes I need to have multiple views in power BI for the same data. \n\nSo the main, highest level view (let\u2019s call it table 1) is grouped by fields A,B, and C. \n\nTable 2 is grouped by A,B,C, and D (a field that may not even appear in table 1. \n\nSo I create a key in both tables (A+B+C) and connect them using that, and voila! Filters from the dimension tables connected to Table 1 cross filter table 2 and everything seems to validate. \n\nThe thing is, all the advice for handling multiple facts say you should connect each fact independently to the dimensions, no one mentions this method. Is there something theoretically wrong with this? Will it affect performance? \n\nI feel like it really makes things easier as I don\u2019t need to recreate x amount of relationships from each fact I bring in to each dimension and it makes the model easier to understand. I can\u2019t help but cringe to myself thinking I must be doing something wrong every time I do it though\u2026", "author_fullname": "t2_5b4anizp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I think this is wrong but I do it anyway\u2026 what\u2019s the best way? (Fact to fact relationship)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qpnr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684944179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;As a data analyst, sometimes I need to have multiple views in power BI for the same data. &lt;/p&gt;\n\n&lt;p&gt;So the main, highest level view (let\u2019s call it table 1) is grouped by fields A,B, and C. &lt;/p&gt;\n\n&lt;p&gt;Table 2 is grouped by A,B,C, and D (a field that may not even appear in table 1. &lt;/p&gt;\n\n&lt;p&gt;So I create a key in both tables (A+B+C) and connect them using that, and voila! Filters from the dimension tables connected to Table 1 cross filter table 2 and everything seems to validate. &lt;/p&gt;\n\n&lt;p&gt;The thing is, all the advice for handling multiple facts say you should connect each fact independently to the dimensions, no one mentions this method. Is there something theoretically wrong with this? Will it affect performance? &lt;/p&gt;\n\n&lt;p&gt;I feel like it really makes things easier as I don\u2019t need to recreate x amount of relationships from each fact I bring in to each dimension and it makes the model easier to understand. I can\u2019t help but cringe to myself thinking I must be doing something wrong every time I do it though\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qpnr4", "is_robot_indexable": true, "report_reasons": null, "author": "4damantium", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qpnr4/i_think_this_is_wrong_but_i_do_it_anyway_whats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qpnr4/i_think_this_is_wrong_but_i_do_it_anyway_whats/", "subreddit_subscribers": 107104, "created_utc": 1684944179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have a couple of questions about COBOL, mainframes, and how it might play into a modern data stack. I know that there is a lot of chatter about how COBOL and mainframes are an issue worldwide given their age and how they are a major part of several mission critical systems.\n\nHere are my questions:\n\n1. Where is data on a COBOL system stored? Would it be in a database like SQL Server or Oracle? Or is it a different DB structure? I think I read something about flat files that it stores data in and reads? Here is this:\n\n\"The non-mainframe COBOL data is located mostly in proprietary file formats that other modern systems struggle to access, forcing developers to continue to actively maintain these systems.\"\n\nAny idea where mainframe COBOL data is located?\n\n2) If you wanted to integrate all of this data with data from other sources and presumably from other databases types like SQL Server, Oracle, snowflake, MongoDG, etc., how would you do that?\n\nThanks for your help!", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "COBOL Data Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qmtez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684937402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have a couple of questions about COBOL, mainframes, and how it might play into a modern data stack. I know that there is a lot of chatter about how COBOL and mainframes are an issue worldwide given their age and how they are a major part of several mission critical systems.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Where is data on a COBOL system stored? Would it be in a database like SQL Server or Oracle? Or is it a different DB structure? I think I read something about flat files that it stores data in and reads? Here is this:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;quot;The non-mainframe COBOL data is located mostly in proprietary file formats that other modern systems struggle to access, forcing developers to continue to actively maintain these systems.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Any idea where mainframe COBOL data is located?&lt;/p&gt;\n\n&lt;p&gt;2) If you wanted to integrate all of this data with data from other sources and presumably from other databases types like SQL Server, Oracle, snowflake, MongoDG, etc., how would you do that?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13qmtez", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qmtez/cobol_data_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qmtez/cobol_data_integration/", "subreddit_subscribers": 107104, "created_utc": 1684937402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6dyvdyxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a cost-effective image vector search engine with CLIP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13qe260", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PhNNOU3t7RHcdjzp1scDgqUQPKmEL3yREPvur1Wo0yc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684911471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "wasimlorgat.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://wasimlorgat.com/posts/image-vector-search.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?auto=webp&amp;v=enabled&amp;s=ce725d6262d8231b5fe124fe1af72b1621516b43", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f2874c17516a8b8ecd27089bee96683908386fb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dd0f8a9ed4a8ad3c2b7ddf6bb432ef5b8047a51", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3dfb38dc9908b669ac38b245bc622265f531414", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecdda31d1d6321ea69a7aa7327f22da307c452bf", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f62240e16f65e92ab8b903b6dd2b302138265de", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/LGcIQHmvZ2Icl-46MF8w_iBZjjFjvrLsxLEkhhXCrPY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07715bbbbeb50ca3f6d3775e1b86437e6b15ca69", "width": 1080, "height": 607}], "variants": {}, "id": "9vNR0Dtq7SWxDdNJw8UPWOaqShZ2EitpOfqPfGeIitc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13qe260", "is_robot_indexable": true, "report_reasons": null, "author": "seem-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qe260/building_a_costeffective_image_vector_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://wasimlorgat.com/posts/image-vector-search.html", "subreddit_subscribers": 107104, "created_utc": 1684911471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI am a computer engineering student currently working in a summer internship. I do not work with anyone considered a \"data engineer\" everyone works a sort of mixed role of programmers and planners and other random engineering things.\n\nAnyways so most of my time I am working on a project where we are designing and building a system that takes some sensor data from multiple sources and different databases parses them in python, pushes the data to a postgres database then we use a Nginx to host a Grafana front end to visualize the data in the postgres server. It may seem silly that I'm asking if this is considered data engineering but because I haven't been around anyone with that specific job description and this has been my only internship I don't know if that is what I am doing.\n\nAlso my career goal is move to a architect/manager position out of university so I was wondering if anyone had advice on how to make that move as soon as possible out of school.\n\nThanks you!", "author_fullname": "t2_xglu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does my internship qualify as Data Engineering experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q8f1d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684895111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I am a computer engineering student currently working in a summer internship. I do not work with anyone considered a &amp;quot;data engineer&amp;quot; everyone works a sort of mixed role of programmers and planners and other random engineering things.&lt;/p&gt;\n\n&lt;p&gt;Anyways so most of my time I am working on a project where we are designing and building a system that takes some sensor data from multiple sources and different databases parses them in python, pushes the data to a postgres database then we use a Nginx to host a Grafana front end to visualize the data in the postgres server. It may seem silly that I&amp;#39;m asking if this is considered data engineering but because I haven&amp;#39;t been around anyone with that specific job description and this has been my only internship I don&amp;#39;t know if that is what I am doing.&lt;/p&gt;\n\n&lt;p&gt;Also my career goal is move to a architect/manager position out of university so I was wondering if anyone had advice on how to make that move as soon as possible out of school.&lt;/p&gt;\n\n&lt;p&gt;Thanks you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13q8f1d", "is_robot_indexable": true, "report_reasons": null, "author": "xXninja_manXx", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13q8f1d/does_my_internship_qualify_as_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13q8f1d/does_my_internship_qualify_as_data_engineering/", "subreddit_subscribers": 107104, "created_utc": 1684895111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to get data from hubspot deals, i am unable to find the parameter used to get data on a specific data from 2023, the data i am getting is from 2022. I am very new to data engineering i desperately need to keep this job, apologies about noob question. \n\nThe code i used \n\n&amp;#x200B;\n\n  \n`import hubspot`  \n`from pprint import pprint`  \n`from hubspot.crm.deals import ApiException`  \n`client = hubspot.Client.create(access_token=\"pat-na1-0234b5dc-627f-4bad-887c-449363cdb8d9\")`  \n`try:`  \n`api_response = client.crm.deals.basic_api.get_page(limit=10, archived=False)`  \n`pprint(api_response)`  \n`except ApiException as e:`  \n `print(\"Exception when calling basic_api-&gt;get_page: %s\\n\" % e)`", "author_fullname": "t2_ue40fdfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to get data of specific date from hubspot api?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13qxhjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684961865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to get data from hubspot deals, i am unable to find the parameter used to get data on a specific data from 2023, the data i am getting is from 2022. I am very new to data engineering i desperately need to keep this job, apologies about noob question. &lt;/p&gt;\n\n&lt;p&gt;The code i used &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;import hubspot&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;from pprint import pprint&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;from hubspot.crm.deals import ApiException&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;client = hubspot.Client.create(access_token=&amp;quot;pat-na1-0234b5dc-627f-4bad-887c-449363cdb8d9&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;try:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;api_response = client.crm.deals.basic_api.get_page(limit=10, archived=False)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;pprint(api_response)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;except ApiException as e:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;print(&amp;quot;Exception when calling basic_api-&amp;gt;get_page: %s\\n&amp;quot; % e)&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qxhjy", "is_robot_indexable": true, "report_reasons": null, "author": "iamnotabaadperson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qxhjy/how_to_get_data_of_specific_date_from_hubspot_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qxhjy/how_to_get_data_of_specific_date_from_hubspot_api/", "subreddit_subscribers": 107104, "created_utc": 1684961865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently have two offers at hand which I am struggling to decide which one is a better role for me. Not sure if location makes a big difference but currently in Canada. I have seven years of data analyst and some data engineering experience in the finance industry and looking for change. I've done a  lot of work in my previous role with creating/managing data pipelines (Python), data visualization (Python-based dashboards and some Tableau), building process automation (Python), web scraping (Python), and data analysis (Python and SQL). I really am interested in pivoting my career towards an analytics engineering role.\n\nOne of positions is a Data Visualization Engineer role at an US cloud  services and security firm (medium-sized), and the other one is called Senior Technical Specialist in a big hospital.\n\nThe Data Viz Engineer role honestly seems like a glorified data analyst role, where most of your day consists of creating dashboards and conducting data analysis for upper management. Tech stack includes Tableau, Power BI, SQL, Python, and R. Remote and permanent role.\n\nThe Senior Technical Specialist role at the hospital involves systems operations, where you do a mix of programming, data analysis, and  application development. Lots of data pipeline management, as well as building, maintaining, and fixing bugs in applications. Some reporting work. Tech stack includes Python, SQL, R, Power BI, Azure, VBA, etc. Sounds like more of a data engineering position, which I am frankly far more interested in doing. It's a 1-year contract, hybrid, and pay is similar to other role.\n\nOf course my heart tells me go for the second role since it's more related to analytics engineering and I can use this experience to get into data engineering roles later down the line. However it is a publicly funded hospital so I assume the technology used by the team will not be as good as the tech firm. I would like to work in  a tech firm in the future, so it might be more difficult to jump to a tech firm from a hospital, than if I went with the cloud firm.\n\nWhat is the most reasonable choice to take?", "author_fullname": "t2_cp1ln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing between cloud company vs hospital?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13qxawu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684961455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have two offers at hand which I am struggling to decide which one is a better role for me. Not sure if location makes a big difference but currently in Canada. I have seven years of data analyst and some data engineering experience in the finance industry and looking for change. I&amp;#39;ve done a  lot of work in my previous role with creating/managing data pipelines (Python), data visualization (Python-based dashboards and some Tableau), building process automation (Python), web scraping (Python), and data analysis (Python and SQL). I really am interested in pivoting my career towards an analytics engineering role.&lt;/p&gt;\n\n&lt;p&gt;One of positions is a Data Visualization Engineer role at an US cloud  services and security firm (medium-sized), and the other one is called Senior Technical Specialist in a big hospital.&lt;/p&gt;\n\n&lt;p&gt;The Data Viz Engineer role honestly seems like a glorified data analyst role, where most of your day consists of creating dashboards and conducting data analysis for upper management. Tech stack includes Tableau, Power BI, SQL, Python, and R. Remote and permanent role.&lt;/p&gt;\n\n&lt;p&gt;The Senior Technical Specialist role at the hospital involves systems operations, where you do a mix of programming, data analysis, and  application development. Lots of data pipeline management, as well as building, maintaining, and fixing bugs in applications. Some reporting work. Tech stack includes Python, SQL, R, Power BI, Azure, VBA, etc. Sounds like more of a data engineering position, which I am frankly far more interested in doing. It&amp;#39;s a 1-year contract, hybrid, and pay is similar to other role.&lt;/p&gt;\n\n&lt;p&gt;Of course my heart tells me go for the second role since it&amp;#39;s more related to analytics engineering and I can use this experience to get into data engineering roles later down the line. However it is a publicly funded hospital so I assume the technology used by the team will not be as good as the tech firm. I would like to work in  a tech firm in the future, so it might be more difficult to jump to a tech firm from a hospital, than if I went with the cloud firm.&lt;/p&gt;\n\n&lt;p&gt;What is the most reasonable choice to take?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13qxawu", "is_robot_indexable": true, "report_reasons": null, "author": "rogue_lash", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qxawu/choosing_between_cloud_company_vs_hospital/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qxawu/choosing_between_cloud_company_vs_hospital/", "subreddit_subscribers": 107104, "created_utc": 1684961455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all \n\nIf there is a scenario you are facing corruption in some or all of your partitions in your datalake in S3, what would be the best setup to restore data to a previous point? \n\nIs there a way to restore to a previous state based on versioning, should there be a complete backup in another S3 bucket?", "author_fullname": "t2_8lbog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recovering from a delta-lake failures in S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qvco2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684956993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all &lt;/p&gt;\n\n&lt;p&gt;If there is a scenario you are facing corruption in some or all of your partitions in your datalake in S3, what would be the best setup to restore data to a previous point? &lt;/p&gt;\n\n&lt;p&gt;Is there a way to restore to a previous state based on versioning, should there be a complete backup in another S3 bucket?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qvco2", "is_robot_indexable": true, "report_reasons": null, "author": "AUGcodon", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qvco2/recovering_from_a_deltalake_failures_in_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qvco2/recovering_from_a_deltalake_failures_in_s3/", "subreddit_subscribers": 107104, "created_utc": 1684956993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to schedule some legacy code runs (mainly data processing with pandas) as a task on airflow (cloud composer).\n\nThe process needs 8gb of ram but composer workers configuration is far from that so I can\u2019t use the kubernetespodoperator directly and I can\u2019t resize the cluster because it\u2019s not worth for one dag that runs monthly.\n\nSo I thought about multiple choices : create new node pool, use cloud run, cloud functions, dataflow with pandas, vm \u2026\n\nBut I can\u2019t choose the right one and also the simplest one.\n\nI just want to have some sort of dag where I can provision the ram that I need and run my pandas script.\n\nDo you have experience with this ? Thanks in advance", "author_fullname": "t2_39gqkikb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Custome compute on Cloud Composer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qt4k8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684952023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to schedule some legacy code runs (mainly data processing with pandas) as a task on airflow (cloud composer).&lt;/p&gt;\n\n&lt;p&gt;The process needs 8gb of ram but composer workers configuration is far from that so I can\u2019t use the kubernetespodoperator directly and I can\u2019t resize the cluster because it\u2019s not worth for one dag that runs monthly.&lt;/p&gt;\n\n&lt;p&gt;So I thought about multiple choices : create new node pool, use cloud run, cloud functions, dataflow with pandas, vm \u2026&lt;/p&gt;\n\n&lt;p&gt;But I can\u2019t choose the right one and also the simplest one.&lt;/p&gt;\n\n&lt;p&gt;I just want to have some sort of dag where I can provision the ram that I need and run my pandas script.&lt;/p&gt;\n\n&lt;p&gt;Do you have experience with this ? Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qt4k8", "is_robot_indexable": true, "report_reasons": null, "author": "amkian", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qt4k8/custome_compute_on_cloud_composer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qt4k8/custome_compute_on_cloud_composer/", "subreddit_subscribers": 107104, "created_utc": 1684952023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically, I am trying to extract json files from websites like Draftkings and Fanduel. Draftkings was easy enough. All I had to do was use Chrome's Developer tools option and look at the network activity for the json. For other websites, however, it's not as easy. I was just trying to see if any other methods out there other than using something like Python's scrapy library.", "author_fullname": "t2_fbzay1sq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting JSON from webpages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qqzm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684947261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, I am trying to extract json files from websites like Draftkings and Fanduel. Draftkings was easy enough. All I had to do was use Chrome&amp;#39;s Developer tools option and look at the network activity for the json. For other websites, however, it&amp;#39;s not as easy. I was just trying to see if any other methods out there other than using something like Python&amp;#39;s scrapy library.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qqzm3", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Cookie892", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qqzm3/getting_json_from_webpages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qqzm3/getting_json_from_webpages/", "subreddit_subscribers": 107104, "created_utc": 1684947261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building a prototype system that will have many different types of textual documents that will have really varying metadata.\n\nI'd like to both be able to run analytics over the metadata and have full-text search capabilities.\n\nMy initial thinking has been to store the metadata in PostgreSQL and Elasticsearch (plus also the entire textual contents of the document Elasticsearch with metadata link to original bytes in S3) because I want to be able to hookup the metadata to a BI tool for analytics, and also do full-text search.\n\nI want to also have deep faceting abilities on the documents, which vary a lot between the documents. My questions\n\n* Any thoughts on the overall architecture?\n* I'm thinking of having distinct tables for DocumentTypeA, DocumentTypeB, etc but then just indexing into Elasticsearch as a generic \"Document.\" Thoughts on this?\n* If DocumentTypeA refers to AttributeZ, whats the best way of storing that in Elasticsearch to support faceting in a web UI? Do you just dump/nest \"attribute z\" inside the Document in elastic or only reference an ID? (seems like it could make search easier, but concerned about data duplication and attribute updates being a pain in the index)\n\n(if it helps, expecting about 20 different types of documents and order of magnitude of 10's of millions of total documents)", "author_fullname": "t2_319xs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technical architecture/database design question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qpu4j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684944574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a prototype system that will have many different types of textual documents that will have really varying metadata.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to both be able to run analytics over the metadata and have full-text search capabilities.&lt;/p&gt;\n\n&lt;p&gt;My initial thinking has been to store the metadata in PostgreSQL and Elasticsearch (plus also the entire textual contents of the document Elasticsearch with metadata link to original bytes in S3) because I want to be able to hookup the metadata to a BI tool for analytics, and also do full-text search.&lt;/p&gt;\n\n&lt;p&gt;I want to also have deep faceting abilities on the documents, which vary a lot between the documents. My questions&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Any thoughts on the overall architecture?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m thinking of having distinct tables for DocumentTypeA, DocumentTypeB, etc but then just indexing into Elasticsearch as a generic &amp;quot;Document.&amp;quot; Thoughts on this?&lt;/li&gt;\n&lt;li&gt;If DocumentTypeA refers to AttributeZ, whats the best way of storing that in Elasticsearch to support faceting in a web UI? Do you just dump/nest &amp;quot;attribute z&amp;quot; inside the Document in elastic or only reference an ID? (seems like it could make search easier, but concerned about data duplication and attribute updates being a pain in the index)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(if it helps, expecting about 20 different types of documents and order of magnitude of 10&amp;#39;s of millions of total documents)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qpu4j", "is_robot_indexable": true, "report_reasons": null, "author": "jaydub", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qpu4j/technical_architecturedatabase_design_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qpu4j/technical_architecturedatabase_design_question/", "subreddit_subscribers": 107104, "created_utc": 1684944574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi ! \n\nI'm thinking about a concept and would like some pointers where to look for solutions, and if the concept is any good. I'm not sure how to explain it well, so please ask questions if it's not clear but you feel you can help.\n\nWe have a lot of real world data (as everybody else apparently). We use it for different kinds of analysis, simulations etc. It happens quite frequently, that somebody discovers an issue in it - for ex. the computation used to persist one of the columns was not accurate, or there are missing rows. \n\nNow, what are the options ? Currently, we don't do much about it. We correct the computation - so starting from today, future points will be good. \n\nBut, what to do with past data ? Usually, you don't want to throw it, since it's mostly good. When we have the option to re-create it, we do. But you also need track all data that was dependent on it - I know Prefect / Dagster simplify this - but all use cases I see for now are all data that seems to be 'one-shot' or periodical. How that works with data that is generated daily ? Is it possible to say - okay, replay the daily pipelines dependent on said data, since 2023-01-01 ? \n\nIn cases when we can't, well, we just leave it - usually when the data is 'good enough'. But this, inevitably leads to a lot of time wasted in the future (ie, some other researcher spend 3 days, finding out the same initial issue). I would like to attach some 'quality indicator' for each data (or rather daily batch of data) - which we could use, to indicate what's the quality.\n\nAs an example, let's say we store orders, with a total price paid since 2020-01-01. Then, 2021-01-01 we realize we weren't including shipping costs.... I would somehow, like to let people using this data, that &lt;2021-01-01 the data may be inaccurate. Or allow to filter on it (like - give me stats only on data meeting some quality level).\n\nDoes all of this make any sense ? I feel like their must be some ways to manage that properly, I just can't find it (probably because I can't articulate it properly...). Any help really appreciated !", "author_fullname": "t2_k7juv3bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality indicators ? (metadata ?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qh8np", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684922562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi ! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about a concept and would like some pointers where to look for solutions, and if the concept is any good. I&amp;#39;m not sure how to explain it well, so please ask questions if it&amp;#39;s not clear but you feel you can help.&lt;/p&gt;\n\n&lt;p&gt;We have a lot of real world data (as everybody else apparently). We use it for different kinds of analysis, simulations etc. It happens quite frequently, that somebody discovers an issue in it - for ex. the computation used to persist one of the columns was not accurate, or there are missing rows. &lt;/p&gt;\n\n&lt;p&gt;Now, what are the options ? Currently, we don&amp;#39;t do much about it. We correct the computation - so starting from today, future points will be good. &lt;/p&gt;\n\n&lt;p&gt;But, what to do with past data ? Usually, you don&amp;#39;t want to throw it, since it&amp;#39;s mostly good. When we have the option to re-create it, we do. But you also need track all data that was dependent on it - I know Prefect / Dagster simplify this - but all use cases I see for now are all data that seems to be &amp;#39;one-shot&amp;#39; or periodical. How that works with data that is generated daily ? Is it possible to say - okay, replay the daily pipelines dependent on said data, since 2023-01-01 ? &lt;/p&gt;\n\n&lt;p&gt;In cases when we can&amp;#39;t, well, we just leave it - usually when the data is &amp;#39;good enough&amp;#39;. But this, inevitably leads to a lot of time wasted in the future (ie, some other researcher spend 3 days, finding out the same initial issue). I would like to attach some &amp;#39;quality indicator&amp;#39; for each data (or rather daily batch of data) - which we could use, to indicate what&amp;#39;s the quality.&lt;/p&gt;\n\n&lt;p&gt;As an example, let&amp;#39;s say we store orders, with a total price paid since 2020-01-01. Then, 2021-01-01 we realize we weren&amp;#39;t including shipping costs.... I would somehow, like to let people using this data, that &amp;lt;2021-01-01 the data may be inaccurate. Or allow to filter on it (like - give me stats only on data meeting some quality level).&lt;/p&gt;\n\n&lt;p&gt;Does all of this make any sense ? I feel like their must be some ways to manage that properly, I just can&amp;#39;t find it (probably because I can&amp;#39;t articulate it properly...). Any help really appreciated !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13qh8np", "is_robot_indexable": true, "report_reasons": null, "author": "TheAlchemist2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qh8np/data_quality_indicators_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qh8np/data_quality_indicators_metadata/", "subreddit_subscribers": 107104, "created_utc": 1684922562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for an orchestrator for a project, which runs multiple compute tasks on emr serverless and reads/writes data to hudi/iceberg or delta lake with emr-serverless instances.\nIs there one with built-in support instead of using boto3 syntax?", "author_fullname": "t2_11bm9f4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrator with built-in emr serverless support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q9tat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684899067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for an orchestrator for a project, which runs multiple compute tasks on emr serverless and reads/writes data to hudi/iceberg or delta lake with emr-serverless instances.\nIs there one with built-in support instead of using boto3 syntax?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13q9tat", "is_robot_indexable": true, "report_reasons": null, "author": "ar405", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13q9tat/orchestrator_with_builtin_emr_serverless_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13q9tat/orchestrator_with_builtin_emr_serverless_support/", "subreddit_subscribers": 107104, "created_utc": 1684899067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nNew to FiveTran and concerned about using up the contractual MARs.   I have a very large MySQL table (\\~200 million rows.)  I want to bring this to Snowflake.  We have FiveTran.  Currently we only a small subset of the records.    \n\n\n1. Can I create a MySQL view filtered down to on and after the date of the desired rows, and sync that view instead of the source table? \n2. If any detail of a specific row that has previously been loaded changes, does it get re-loaded and use up credits against MARs, and is there a way to prevent this if we are not interested in tracking ongoing changes to each row?  (and on that note, other than going to developers, does FiveTran allow us to determine whether this happens or not for a given table?)\n\nThanks a lot!", "author_fullname": "t2_up3nutlk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran sync question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qkfpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684931808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;New to FiveTran and concerned about using up the contractual MARs.   I have a very large MySQL table (~200 million rows.)  I want to bring this to Snowflake.  We have FiveTran.  Currently we only a small subset of the records.    &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can I create a MySQL view filtered down to on and after the date of the desired rows, and sync that view instead of the source table? &lt;/li&gt;\n&lt;li&gt;If any detail of a specific row that has previously been loaded changes, does it get re-loaded and use up credits against MARs, and is there a way to prevent this if we are not interested in tracking ongoing changes to each row?  (and on that note, other than going to developers, does FiveTran allow us to determine whether this happens or not for a given table?)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13qkfpq", "is_robot_indexable": true, "report_reasons": null, "author": "Exact_Attitude6041", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qkfpq/fivetran_sync_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qkfpq/fivetran_sync_question/", "subreddit_subscribers": 107104, "created_utc": 1684931808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im planning to build a datawarehouse \nInformation will come from two sqlservers and some excelfiles \nwhich tools do i need ? \ndo you suggest using dbt ? databricks ?\nis there any tutorials ?\n\nPlease advice and thanks", "author_fullname": "t2_5dm58cpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13q904b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684896763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im planning to build a datawarehouse \nInformation will come from two sqlservers and some excelfiles \nwhich tools do i need ? \ndo you suggest using dbt ? databricks ?\nis there any tutorials ?&lt;/p&gt;\n\n&lt;p&gt;Please advice and thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13q904b", "is_robot_indexable": true, "report_reasons": null, "author": "docmarte", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13q904b/build_a_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13q904b/build_a_datawarehouse/", "subreddit_subscribers": 107104, "created_utc": 1684896763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data observability is a collection of technologies and activities that allows data science teams to prevent problems from becoming severe business issues. \n\n[https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering](https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering)", "author_fullname": "t2_79p1h62w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13qlds6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684934098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data observability is a collection of technologies and activities that allows data science teams to prevent problems from becoming severe business issues. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering\"&gt;https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?auto=webp&amp;v=enabled&amp;s=6763ef0071a893ed732b2a289485d0bdf0e98618", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=506669e8aba350ec60db312a299d11d854854ce0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a68bb5121d235cf07cbe7a8cf9bbd4eec717f061", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c7b2aef8c79fed9b52ddfa1562b3c869e97076", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a26d98a4fc7fa34d512862b1611b96d81a02dd61", "width": 640, "height": 336}], "variants": {}, "id": "JGhC9b9qhHNJ4eh7-qMHVcYJNdZfz1K-5VoSz-ZvhQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13qlds6", "is_robot_indexable": true, "report_reasons": null, "author": "Shradha_Singh", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13qlds6/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13qlds6/data_observability_the_next_frontier_of_data/", "subreddit_subscribers": 107104, "created_utc": 1684934098.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}