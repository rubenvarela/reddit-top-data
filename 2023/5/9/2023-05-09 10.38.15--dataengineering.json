{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have any of you worked as a consultant? I really wonder if it would be nice. How long are your projects generally? Is it interesting to see many companies or are most tech stacks used not relevant? Are you actually doing data engineering work or does it more feel like you\u2019re an analyst or architect? I feel like it\u2019s interesting, but I also feel many companies are stuck with obsolete tools and it might feel like a waste of my time. I\u2019m in Europe btw.", "author_fullname": "t2_gzpboep7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working as a consultant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13c0wi7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683571633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have any of you worked as a consultant? I really wonder if it would be nice. How long are your projects generally? Is it interesting to see many companies or are most tech stacks used not relevant? Are you actually doing data engineering work or does it more feel like you\u2019re an analyst or architect? I feel like it\u2019s interesting, but I also feel many companies are stuck with obsolete tools and it might feel like a waste of my time. I\u2019m in Europe btw.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13c0wi7", "is_robot_indexable": true, "report_reasons": null, "author": "themouthoftruth", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13c0wi7/working_as_a_consultant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13c0wi7/working_as_a_consultant/", "subreddit_subscribers": 104656, "created_utc": 1683571633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Folks in the data engineering community like Zach Wilson have expressed that DE will change within the next 5 years or so because of AI, where the responsibilities of a DE will basically go into 2 buckets. One more focused on the business like data analysts and the other more technical like software engineers. I have a background in analytics and really thought that would lead to my first full time job, but I naturally got more and more into data engineering as I learned more. Do you think it\u2019s still worth it, for someone like me who got offered an entry level Data Engineering role, to stay in this field of Data Engineering or should I start looking into Data Analyst type roles? \n\nMy reasoning to accept the role would be to gain a lot of technical and business knowledge. Plus having a background in analytics and dashboards would also improve my skill set. Do you guys have any advice/career tips?", "author_fullname": "t2_9jq8g6tr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cb3xl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683595236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Folks in the data engineering community like Zach Wilson have expressed that DE will change within the next 5 years or so because of AI, where the responsibilities of a DE will basically go into 2 buckets. One more focused on the business like data analysts and the other more technical like software engineers. I have a background in analytics and really thought that would lead to my first full time job, but I naturally got more and more into data engineering as I learned more. Do you think it\u2019s still worth it, for someone like me who got offered an entry level Data Engineering role, to stay in this field of Data Engineering or should I start looking into Data Analyst type roles? &lt;/p&gt;\n\n&lt;p&gt;My reasoning to accept the role would be to gain a lot of technical and business knowledge. Plus having a background in analytics and dashboards would also improve my skill set. Do you guys have any advice/career tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13cb3xl", "is_robot_indexable": true, "report_reasons": null, "author": "WorldlyDirt5024", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13cb3xl/future_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13cb3xl/future_of_de/", "subreddit_subscribers": 104656, "created_utc": 1683595236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xamdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Leading Data Organizations Achieve Success: Prioritize People, Process, and Product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 51, "top_awarded_type": null, "hide_score": false, "name": "t3_13bpeqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/X8c2cXmQm9IBzo5IoWBm16vpQDiLrpMqX_H1pvvDGnc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683553148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/datamindedbe/how-leading-data-organizations-achieve-success-prioritize-people-process-and-product-472cc56fd095", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?auto=webp&amp;v=enabled&amp;s=923756c137c857853ea1576c20e5275623484a83", "width": 1200, "height": 442}, "resolutions": [{"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53bdaaa47126ffa0215f19f29d39a3116624e834", "width": 108, "height": 39}, {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7c0ac092528cdc1be4904ddc2331702dbb52269", "width": 216, "height": 79}, {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e374d1d97c7166f04bf5994d675471e69eb9b83", "width": 320, "height": 117}, {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0302413e183a6dd17e20351c02dda0c0cfd62bb5", "width": 640, "height": 235}, {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caf1be2bc3c474ccdb9b917b4d9040af138ff576", "width": 960, "height": 353}, {"url": "https://external-preview.redd.it/X7NO6r7Tf9XB1BFXyFF8JAfY1X8AoFyecR7NmWezGRA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05661f62da1741c56c7aa37d531b0c9df9646eb8", "width": 1080, "height": 397}], "variants": {}, "id": "l_FI4A3wAtWAb7Wyz9gf_AmQ9G6n_Qjw5u8UiTKv9q8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13bpeqx", "is_robot_indexable": true, "report_reasons": null, "author": "Joda5", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bpeqx/how_leading_data_organizations_achieve_success/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/datamindedbe/how-leading-data-organizations-achieve-success-prioritize-people-process-and-product-472cc56fd095", "subreddit_subscribers": 104656, "created_utc": 1683553148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars \u2013 Laziness and SQL Context.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13c2g8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ds8HBve1RDQuicuCq-JuovH-66LxyobnE5S7u74D4UA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683574919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/polars-laziness-and-sql-context/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?auto=webp&amp;v=enabled&amp;s=7248234bd8dd9ce1e3a99fee85846a8a42980015", "width": 1030, "height": 687}, "resolutions": [{"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ea31607c88c907185110d0c93d00b23f4509453", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=887bc5ded84ecd401d66c24794200dff494a5b71", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4490dedb52f85587fb4687184283f4cfc4dd801d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34f8c3e96e497b0d447f6714d51b98f96513cbfc", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ejSissQUjaE3P8qe6zsDeQhsydPBEWunr5lL9AUPQlE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24abba41481143e6d8c39b0c6453111fef7092e1", "width": 960, "height": 640}], "variants": {}, "id": "82mgm8mmVoe4JEI5jJQSxoov_B04NPE2qRmoIJODC3w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13c2g8x", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13c2g8x/polars_laziness_and_sql_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/polars-laziness-and-sql-context/", "subreddit_subscribers": 104656, "created_utc": 1683574919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "According to Andy Pavlo it is going to be the future of databases but is it real?\nhttps://twitter.com/andy_pavlo/status/1523666179247595520", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Meta's Velox execution engine going to disrupt big data science business market in coming years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13bnrwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683552420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683549270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to Andy Pavlo it is going to be the future of databases but is it real?\n&lt;a href=\"https://twitter.com/andy_pavlo/status/1523666179247595520\"&gt;https://twitter.com/andy_pavlo/status/1523666179247595520&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YjQZoiR4g8v5Yi3CFzQDnnKpgxKA4ELbhRoixq0mk6w.jpg?auto=webp&amp;v=enabled&amp;s=7bc7b9027eaad69c1e67994110815c2cade4c3d1", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/YjQZoiR4g8v5Yi3CFzQDnnKpgxKA4ELbhRoixq0mk6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26fa0a75dcffe7d96da154fb322a669832382000", "width": 108, "height": 108}], "variants": {}, "id": "Z_gIDiiDmTTOtMwcwYaaGEnFJjAHqPioNSlCLMvwBkQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13bnrwr", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bnrwr/is_metas_velox_execution_engine_going_to_disrupt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13bnrwr/is_metas_velox_execution_engine_going_to_disrupt/", "subreddit_subscribers": 104656, "created_utc": 1683549270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It seems almost everyday there is a new pipelining tool coming out for data engineering that appears to do the same as existing tools, but with a key few differences. And these can be really overwhelming especially because my mindset is \u2018I now have to learn this or else I\u2019ll be left behind\u2019 thinking. I wanna hear your thoughts on how you progress through your skills development. Do you learn them when they become a need? Or do you learn in advance just to try it out, or possibly so you can mention it during a job interview? I\u2019m specifically asking about tooling, not on theories because it can really become tiring.", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your learning strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13bymjs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683566759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems almost everyday there is a new pipelining tool coming out for data engineering that appears to do the same as existing tools, but with a key few differences. And these can be really overwhelming especially because my mindset is \u2018I now have to learn this or else I\u2019ll be left behind\u2019 thinking. I wanna hear your thoughts on how you progress through your skills development. Do you learn them when they become a need? Or do you learn in advance just to try it out, or possibly so you can mention it during a job interview? I\u2019m specifically asking about tooling, not on theories because it can really become tiring.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13bymjs", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bymjs/whats_your_learning_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13bymjs/whats_your_learning_strategy/", "subreddit_subscribers": 104656, "created_utc": 1683566759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6on5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why you should start a technical reading group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "name": "t3_13bro5p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6FrP-CdFHr-mQE_XbMD4xVZh1nxakbA-J8JWPJ7Czow.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683555626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/53db2860f2c9", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?auto=webp&amp;v=enabled&amp;s=80b2ba7b1dd3f95fe2ef4dd0f0d35caa7e0bf6ad", "width": 1046, "height": 666}, "resolutions": [{"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3591504a3124759e79dc55ee30edd53b02fd0d2", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8b944789d4fd7edd81650289e3538edff12b158", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e5ddadd53aff059f7aa2853d234b658ea3b62f29", "width": 320, "height": 203}, {"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76e3cfd7c2f0e197cb39164650f4506ca73b6a63", "width": 640, "height": 407}, {"url": "https://external-preview.redd.it/fsusQ-YE_pwQBfBV3-YSFLfjeugujAcbEzwb9Zy9ZRw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=27c4b633bb839e7a5d38b4e5ec0a6880ff62be38", "width": 960, "height": 611}], "variants": {}, "id": "GkcDdv1GjP3xziLwU2PYZ1AHN-5dTlJhHRsefMITEUU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13bro5p", "is_robot_indexable": true, "report_reasons": null, "author": "noodlesoup89", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bro5p/why_you_should_start_a_technical_reading_group/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/53db2860f2c9", "subreddit_subscribers": 104656, "created_utc": 1683555626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing the Atlas Kubernetes Operator: Manage database schemas with Kubernetes and Atlas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13bx99f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BulUfYRWUbEopz-iF-HFZjug7RUm7o7cD6ulHApzpaw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683563781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atlasgo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atlasgo.io/blog/2023/05/08/atlas-v011-kubernetes-operator", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?auto=webp&amp;v=enabled&amp;s=fb5e5b529c54bd83b7908e9765aa23679cdcbcb9", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ad797d3d85f8304c43dc6c5d5f381ad18af43d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=348a3f64e7a3e9a330dbb5a8d7d404b75ecd6e40", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d11d25fac3bb7914270833f4f993ed800fa60735", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6820df39e20938db1369ae8984ca804a36b406dd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=607fc3128291a81883ae059f02fa1105c764f0be", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/NeWb6f9K1hBBCD-A-C8tc5uRlLmTvXA8-TiKe6X93Wg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b7c492da2da4ef1e46fdc2fcf730d975b31817c", "width": 1080, "height": 607}], "variants": {}, "id": "LEjW0aWCgxoxPVnomMrIPRjGrE9BRmXFCBm6cdvV4dM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13bx99f", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bx99f/introducing_the_atlas_kubernetes_operator_manage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atlasgo.io/blog/2023/05/08/atlas-v011-kubernetes-operator", "subreddit_subscribers": 104656, "created_utc": 1683563781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in academia and I will be proposing to setup up multiple database engines (mysql, postgres, mssql) on a vm on aws. The installation of these databases will be used as a lab environment in which learners can practice to work on different sql engines without having to install anything locally. I don\u2019t expect more than 40 concurrent users at any point in time and less than 2000 users in total.\n\nI need help with the following:\n1. Only toy databases will be kept in each of these engines (&lt;50 mb), will a small machine with 4gb ram and 50gb hdd be ok?\n2. How do I administer these databases, I don\u2019t want to run any administrative sql commands, is there any opensource tool I can use to create users, grant privileges? This tool should work across db engines.\n3. What process can I use to populate databases, I can ask lecturers to provide .sql files for importing data or write scripts to do bulk copy. But is there any alternative?\n4. How do I monitor the health of databases and get alerts in case of too many open connections or ram usage? I don\u2019t want to write this functionality from scratch, are there such open source tools available?", "author_fullname": "t2_3o3jbkf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manage multiple databases on a VM.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13bn3rj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683547605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in academia and I will be proposing to setup up multiple database engines (mysql, postgres, mssql) on a vm on aws. The installation of these databases will be used as a lab environment in which learners can practice to work on different sql engines without having to install anything locally. I don\u2019t expect more than 40 concurrent users at any point in time and less than 2000 users in total.&lt;/p&gt;\n\n&lt;p&gt;I need help with the following:\n1. Only toy databases will be kept in each of these engines (&amp;lt;50 mb), will a small machine with 4gb ram and 50gb hdd be ok?\n2. How do I administer these databases, I don\u2019t want to run any administrative sql commands, is there any opensource tool I can use to create users, grant privileges? This tool should work across db engines.\n3. What process can I use to populate databases, I can ask lecturers to provide .sql files for importing data or write scripts to do bulk copy. But is there any alternative?\n4. How do I monitor the health of databases and get alerts in case of too many open connections or ram usage? I don\u2019t want to write this functionality from scratch, are there such open source tools available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13bn3rj", "is_robot_indexable": true, "report_reasons": null, "author": "gunnvant", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bn3rj/manage_multiple_databases_on_a_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13bn3rj/manage_multiple_databases_on_a_vm/", "subreddit_subscribers": 104656, "created_utc": 1683547605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How much data are you manually maintaining in your data warehouse? I think there are the obvious ones like ISO mapping tables and things like that. \nBut our team constantly gets asked to add in manually maintained list of customers that meet a certain criteria to add a flag on their account. \n\nI usually push back and say these things should be maintained in our CRM system and then we can pull it in. \nHow do other people handle this?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manually Maintaining Data in your Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cb8k1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683595568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How much data are you manually maintaining in your data warehouse? I think there are the obvious ones like ISO mapping tables and things like that. \nBut our team constantly gets asked to add in manually maintained list of customers that meet a certain criteria to add a flag on their account. &lt;/p&gt;\n\n&lt;p&gt;I usually push back and say these things should be maintained in our CRM system and then we can pull it in. \nHow do other people handle this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13cb8k1", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13cb8k1/manually_maintaining_data_in_your_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13cb8k1/manually_maintaining_data_in_your_data_warehouse/", "subreddit_subscribers": 104656, "created_utc": 1683595568.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone that has to read a lot of documentation I can definitely say the documentation at least is pretty low quality.\n\nBut yeah, is it just me or has anyone else struggled with Prefect 2 similarly? All these concepts and tiny out of context code snippets, there are barely any cohesive full examples in their documentation. I want to say that the abstractions they provide are ultimately productive but man...it takes some effort and deciphering to get through it.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just me or is Prefect 2 confusing as heck?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cebax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683603523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone that has to read a lot of documentation I can definitely say the documentation at least is pretty low quality.&lt;/p&gt;\n\n&lt;p&gt;But yeah, is it just me or has anyone else struggled with Prefect 2 similarly? All these concepts and tiny out of context code snippets, there are barely any cohesive full examples in their documentation. I want to say that the abstractions they provide are ultimately productive but man...it takes some effort and deciphering to get through it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13cebax", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13cebax/is_it_just_me_or_is_prefect_2_confusing_as_heck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13cebax/is_it_just_me_or_is_prefect_2_confusing_as_heck/", "subreddit_subscribers": 104656, "created_utc": 1683603523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "ARM-based   processors are known for matching performance of x86-based instance  types at a lower cost, since they consume far less energy for the same  performance. It\u2019s not surprising then that some companies, like [Honeycomb](https://www.honeycomb.io/blog/present-future-arm-aws-graviton-honeycomb), are switching their entire infrastructure to ARM.\n\nWe ran a number of [Dask](https://www.dask.org/?utm_source=medium&amp;utm_medium=dask-graviton) workloads on both x86- and ARM-based instance types and found costs were typically 20\u201330% lower when using ARM. We also tested out the latest generation of Amazon\u2019s ARM-based processors Graviton3 instance types and looked at performance for a compute-heavy workload using Dask and XGBoost.\n\n[https://medium.com/coiled-hq/how-well-does-dask-run-on-graviton-29d5d9c20279](https://medium.com/coiled-hq/how-well-does-dask-run-on-graviton-29d5d9c20279)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How well does Dask run on Graviton?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13bt5ul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683556983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ARM-based   processors are known for matching performance of x86-based instance  types at a lower cost, since they consume far less energy for the same  performance. It\u2019s not surprising then that some companies, like &lt;a href=\"https://www.honeycomb.io/blog/present-future-arm-aws-graviton-honeycomb\"&gt;Honeycomb&lt;/a&gt;, are switching their entire infrastructure to ARM.&lt;/p&gt;\n\n&lt;p&gt;We ran a number of &lt;a href=\"https://www.dask.org/?utm_source=medium&amp;amp;utm_medium=dask-graviton\"&gt;Dask&lt;/a&gt; workloads on both x86- and ARM-based instance types and found costs were typically 20\u201330% lower when using ARM. We also tested out the latest generation of Amazon\u2019s ARM-based processors Graviton3 instance types and looked at performance for a compute-heavy workload using Dask and XGBoost.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/coiled-hq/how-well-does-dask-run-on-graviton-29d5d9c20279\"&gt;https://medium.com/coiled-hq/how-well-does-dask-run-on-graviton-29d5d9c20279&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?auto=webp&amp;v=enabled&amp;s=36848d52a2405eb411af07bf158e05defbd8d960", "width": 5121, "height": 4012}, "resolutions": [{"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2d47faa089063535ac75c117610c04d1c69401b", "width": 108, "height": 84}, {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=232b7d430646660f2e3aa78f3400bfb122e26ef9", "width": 216, "height": 169}, {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b59ed69349cc6a334b27157f79568c9abf9f23db", "width": 320, "height": 250}, {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d4d7029fdefbd8f6ea5abd2ebe267cf5df2ca6e", "width": 640, "height": 501}, {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e07d12e91ee6deab46423c197da02a7b8e1979ce", "width": 960, "height": 752}, {"url": "https://external-preview.redd.it/DrBfqkzjvKdSXh_oovbJvp7bA_zp0jpeKEx-kYG75Z4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ceacedc1b125d30ef54290db8d5cf07252aaa9d", "width": 1080, "height": 846}], "variants": {}, "id": "RgYxhgS8dFH8kyPZC02Y57A12eDi7q92Ja7JKZ7FVzg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13bt5ul", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bt5ul/how_well_does_dask_run_on_graviton/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13bt5ul/how_well_does_dask_run_on_graviton/", "subreddit_subscribers": 104656, "created_utc": 1683556983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a intern at a big data analytics based company, I am assigned to do learning and development in my internship period but my manager is not that in touch with me and doesn't assign me any tasks. So can someone please tell me about some sample tasks to develop my understanding of pyspark and data analysis skills\n(my company mainly works on databricks using pyspark).", "author_fullname": "t2_71832foo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practice pyspark exercises", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cizzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683618564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a intern at a big data analytics based company, I am assigned to do learning and development in my internship period but my manager is not that in touch with me and doesn&amp;#39;t assign me any tasks. So can someone please tell me about some sample tasks to develop my understanding of pyspark and data analysis skills\n(my company mainly works on databricks using pyspark).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13cizzr", "is_robot_indexable": true, "report_reasons": null, "author": "rickmortbeth", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13cizzr/practice_pyspark_exercises/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13cizzr/practice_pyspark_exercises/", "subreddit_subscribers": 104656, "created_utc": 1683618564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, with all the suite of tools that aims at automating/streamlining various stages of pipeline development, how do you continue to deepen your foundational concepts (eg: change data capture, dimensional modeling etc)?", "author_fullname": "t2_77mz0n8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools vs Foundational concepts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ca6s0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683592747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, with all the suite of tools that aims at automating/streamlining various stages of pipeline development, how do you continue to deepen your foundational concepts (eg: change data capture, dimensional modeling etc)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ca6s0", "is_robot_indexable": true, "report_reasons": null, "author": "Programmer_Virtual", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ca6s0/tools_vs_foundational_concepts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ca6s0/tools_vs_foundational_concepts/", "subreddit_subscribers": 104656, "created_utc": 1683592747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI just joined a friend's early stage mobile app startup as their first data scientist, and I'm pretty new to the field- being new we know I won't do the best job, but I'm eager to learn. I need to set up a data science stack that's easy to work with and quick to set up, without overengineering things from the start- but I also want to lay a good foundation for future growth.\n\nOur data comes from the Apple App Store, Cloudinary, OneSignal, server backend, and ads on Facebook and TikTok. To start off, I'm  going to focus on analytics/ optimizing and monitoring metrics. Later moving into recsys ML for the core product.\n\nCan you help me with recommendations for:\n\n1. **ETL (Or ELT?)**: I've heard about Apache Airflow for ETL pipelines. Is it beginner-friendly? Any other tools you'd suggest? Nifi? Dagger? Luigi? Someone on r/datascience suggested prefect instead of airflow.\n2. **Data storage/lake/warehouse**: What's the best way to store structured and unstructured data? Amazon S3, Google Cloud Storage, Azure Blob Storage, or something else?\n3. **Dashboards**: I want to build interactive dashboards. Panel or Streamlit? What's easier and more flexible for a beginner? Any other tools I should consider?\n\nWhat am I missing and what else do I need to get started? Any good guides for best practices? I don't want to painfully reinvent the wheel.\n\nThanks!", "author_fullname": "t2_ao2xn8gj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data stack for a mobile app startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13c7xos", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683586925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I just joined a friend&amp;#39;s early stage mobile app startup as their first data scientist, and I&amp;#39;m pretty new to the field- being new we know I won&amp;#39;t do the best job, but I&amp;#39;m eager to learn. I need to set up a data science stack that&amp;#39;s easy to work with and quick to set up, without overengineering things from the start- but I also want to lay a good foundation for future growth.&lt;/p&gt;\n\n&lt;p&gt;Our data comes from the Apple App Store, Cloudinary, OneSignal, server backend, and ads on Facebook and TikTok. To start off, I&amp;#39;m  going to focus on analytics/ optimizing and monitoring metrics. Later moving into recsys ML for the core product.&lt;/p&gt;\n\n&lt;p&gt;Can you help me with recommendations for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;ETL (Or ELT?)&lt;/strong&gt;: I&amp;#39;ve heard about Apache Airflow for ETL pipelines. Is it beginner-friendly? Any other tools you&amp;#39;d suggest? Nifi? Dagger? Luigi? Someone on &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; suggested prefect instead of airflow.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data storage/lake/warehouse&lt;/strong&gt;: What&amp;#39;s the best way to store structured and unstructured data? Amazon S3, Google Cloud Storage, Azure Blob Storage, or something else?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dashboards&lt;/strong&gt;: I want to build interactive dashboards. Panel or Streamlit? What&amp;#39;s easier and more flexible for a beginner? Any other tools I should consider?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What am I missing and what else do I need to get started? Any good guides for best practices? I don&amp;#39;t want to painfully reinvent the wheel.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13c7xos", "is_robot_indexable": true, "report_reasons": null, "author": "taiiidan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13c7xos/data_stack_for_a_mobile_app_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13c7xos/data_stack_for_a_mobile_app_startup/", "subreddit_subscribers": 104656, "created_utc": 1683586925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I've been giving a dataset which for simplicity sake works like this with respect to measures:\n\n|ID|Employee|MeasureType|MeasureValue|\n|:-|:-|:-|:-|\n|1|Fred|Salary|100,000|\n|2|Fred|Sales|50,000|\n|3|Fred|VacationDays|20|\n\nI'm used to working with measures where each type would be a separate column like this:\n\n|ID|Employee|Salary|Sales|VacationDays|\n|:-|:-|:-|:-|:-|\n|1|Fred|100,000|50,000|20|\n\nShould I be transforming the first table into the second if I am trying to stick to a star schema approach? I'm using Tableau as my BI tool and will be working with more and more data from our financial system that provides exports structured in the first table example.\n\nThanks!", "author_fullname": "t2_5aprs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial/MIS Data and Star Schemas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13bsjt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683556428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been giving a dataset which for simplicity sake works like this with respect to measures:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID&lt;/th&gt;\n&lt;th align=\"left\"&gt;Employee&lt;/th&gt;\n&lt;th align=\"left\"&gt;MeasureType&lt;/th&gt;\n&lt;th align=\"left\"&gt;MeasureValue&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fred&lt;/td&gt;\n&lt;td align=\"left\"&gt;Salary&lt;/td&gt;\n&lt;td align=\"left\"&gt;100,000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fred&lt;/td&gt;\n&lt;td align=\"left\"&gt;Sales&lt;/td&gt;\n&lt;td align=\"left\"&gt;50,000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fred&lt;/td&gt;\n&lt;td align=\"left\"&gt;VacationDays&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I&amp;#39;m used to working with measures where each type would be a separate column like this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID&lt;/th&gt;\n&lt;th align=\"left\"&gt;Employee&lt;/th&gt;\n&lt;th align=\"left\"&gt;Salary&lt;/th&gt;\n&lt;th align=\"left\"&gt;Sales&lt;/th&gt;\n&lt;th align=\"left\"&gt;VacationDays&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fred&lt;/td&gt;\n&lt;td align=\"left\"&gt;100,000&lt;/td&gt;\n&lt;td align=\"left\"&gt;50,000&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Should I be transforming the first table into the second if I am trying to stick to a star schema approach? I&amp;#39;m using Tableau as my BI tool and will be working with more and more data from our financial system that provides exports structured in the first table example.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13bsjt9", "is_robot_indexable": true, "report_reasons": null, "author": "kaslokid", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13bsjt9/financialmis_data_and_star_schemas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13bsjt9/financialmis_data_and_star_schemas/", "subreddit_subscribers": 104656, "created_utc": 1683556428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have about 4 yoe mostly at one place. Current job is not working out so I\u2019m looking to leave. \n\nLast go around I had a lot of interviews (last summer) but I hear it\u2019s a little more scarce now. I haven\u2019t paid much attention so wondering what y\u2019all\u2019s experience has been for non-entry level roles this season?", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone currently hunting for their 2nd job? How\u2019s the market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13boa43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683550544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have about 4 yoe mostly at one place. Current job is not working out so I\u2019m looking to leave. &lt;/p&gt;\n\n&lt;p&gt;Last go around I had a lot of interviews (last summer) but I hear it\u2019s a little more scarce now. I haven\u2019t paid much attention so wondering what y\u2019all\u2019s experience has been for non-entry level roles this season?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13boa43", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13boa43/anyone_currently_hunting_for_their_2nd_job_hows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13boa43/anyone_currently_hunting_for_their_2nd_job_hows/", "subreddit_subscribers": 104656, "created_utc": 1683550544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! Currently dealing with a transaction data for a retail company. Some of the stores transaction become available late. What's your strategy to capture the most data? Do you re-pull data to do historical update constantly? Thanks for your suggestions! \nP.S. Goal is having the most updated version of all data in Redshift.", "author_fullname": "t2_bfz4zq58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update transaction tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13cddgd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683601002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! Currently dealing with a transaction data for a retail company. Some of the stores transaction become available late. What&amp;#39;s your strategy to capture the most data? Do you re-pull data to do historical update constantly? Thanks for your suggestions! \nP.S. Goal is having the most updated version of all data in Redshift.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13cddgd", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Ad_8085", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13cddgd/update_transaction_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13cddgd/update_transaction_tables/", "subreddit_subscribers": 104656, "created_utc": 1683601002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are currently 8 instances of ClickHouse databases being used by more than 20 people who are querying data for ad-hoc reporting using Redash, refreshing dashboards with multiple charts (Redash, Grafana, Metabase), monitoring product metrics with background queries, writing scripts running in the background and querying data. Due to the high load on the cluster, it sometimes gets overloaded. \n\nThis problem is likely common for data-driven companies, and therefore, solutions are being sought. Is there a solution available that can act as a proxy for a database, optimize incoming SQL queries on-the-fly, and provide more efficient access to the database, thereby reducing the load on the cluster? Alternatively, is there a solution that can analyze and materialize some views based on running queries and use cached data instead of querying data directly from the database?\n\nIf there are solutions available in this category, please provide recommendations.\n\nThanks!", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking solutions to optimize database workflow and reduce cluster load.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13c8l4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683588537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are currently 8 instances of ClickHouse databases being used by more than 20 people who are querying data for ad-hoc reporting using Redash, refreshing dashboards with multiple charts (Redash, Grafana, Metabase), monitoring product metrics with background queries, writing scripts running in the background and querying data. Due to the high load on the cluster, it sometimes gets overloaded. &lt;/p&gt;\n\n&lt;p&gt;This problem is likely common for data-driven companies, and therefore, solutions are being sought. Is there a solution available that can act as a proxy for a database, optimize incoming SQL queries on-the-fly, and provide more efficient access to the database, thereby reducing the load on the cluster? Alternatively, is there a solution that can analyze and materialize some views based on running queries and use cached data instead of querying data directly from the database?&lt;/p&gt;\n\n&lt;p&gt;If there are solutions available in this category, please provide recommendations.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13c8l4r", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13c8l4r/seeking_solutions_to_optimize_database_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13c8l4r/seeking_solutions_to_optimize_database_workflow/", "subreddit_subscribers": 104656, "created_utc": 1683588537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Short bio for myself. I am an electrical engineering grad who has worked as a power distribution project manager for two years. I honestly do not love my job and recently, as a hobby, I've been enjoying programming. I'm currently taking the CS50 Harvard class for computer science. When I was in school, I really loved MATLAB and modifying arrays in Python (for example, making a program where the compiler tells what is or is not a prime number). I'm sorry if this is a stupid question, but is data engineering right for me?", "author_fullname": "t2_6ngnfv6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will I have fun pursuing a data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13c8a6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683587757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Short bio for myself. I am an electrical engineering grad who has worked as a power distribution project manager for two years. I honestly do not love my job and recently, as a hobby, I&amp;#39;ve been enjoying programming. I&amp;#39;m currently taking the CS50 Harvard class for computer science. When I was in school, I really loved MATLAB and modifying arrays in Python (for example, making a program where the compiler tells what is or is not a prime number). I&amp;#39;m sorry if this is a stupid question, but is data engineering right for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13c8a6g", "is_robot_indexable": true, "report_reasons": null, "author": "Strange_Many_4851", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13c8a6g/will_i_have_fun_pursuing_a_data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13c8a6g/will_i_have_fun_pursuing_a_data_engineering_job/", "subreddit_subscribers": 104656, "created_utc": 1683587757.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}