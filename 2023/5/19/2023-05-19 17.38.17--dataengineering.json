{"kind": "Listing", "data": {"after": "t3_13l90fo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DBT will be reducing their headcount by 15% of their global team. This reduction will impact every function of the business. \n\nMy team had to migrate away from DBT after their price hike, so this is not surprising.\n\n\nhttps://www.getdbt.com/blog/dbt-labs-update-a-message-from-ceo-tristan-handy/", "author_fullname": "t2_qyoflfqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT lays off 15% of their staff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l9ur0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 240, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 240, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684441604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DBT will be reducing their headcount by 15% of their global team. This reduction will impact every function of the business. &lt;/p&gt;\n\n&lt;p&gt;My team had to migrate away from DBT after their price hike, so this is not surprising.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.getdbt.com/blog/dbt-labs-update-a-message-from-ceo-tristan-handy/\"&gt;https://www.getdbt.com/blog/dbt-labs-update-a-message-from-ceo-tristan-handy/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?auto=webp&amp;v=enabled&amp;s=d4169652ab7f36209622ee244f310aefe0cf8ce2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd185c71f8fd75a33c0c79555ab7aa66ff94f024", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10e2c53de9b2969366504c9ded514bbe1e2eb4d1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7634b43f18facd6b7a0eaa901c2b135c2c9f47cf", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=487560d27ca62339efe41270d29a0644753c4362", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43637abd63f6c913d8d643f155a22cfee21ab4eb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7eff2686e5c425ddf4ad53b33e6ccec820db7c7", "width": 1080, "height": 567}], "variants": {}, "id": "2FMzESMf4JTwwEXCI7l6BQ_Y4vxSjUVpLJpZ0tVaorg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l9ur0", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Sir78", "discussion_type": null, "num_comments": 136, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l9ur0/dbt_lays_off_15_of_their_staff/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l9ur0/dbt_lays_off_15_of_their_staff/", "subreddit_subscribers": 106208, "created_utc": 1684441604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to ask if there are any data engineering podcasts to listen while working :) \n\nI am willing to listen more opinions and discussions about emerging trends on Data &amp; AI as well ! \n\nThanks &lt;3", "author_fullname": "t2_ffabopog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Data Engineering Podcasts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lppxu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684486238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to ask if there are any data engineering podcasts to listen while working :) &lt;/p&gt;\n\n&lt;p&gt;I am willing to listen more opinions and discussions about emerging trends on Data &amp;amp; AI as well ! &lt;/p&gt;\n\n&lt;p&gt;Thanks &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13lppxu", "is_robot_indexable": true, "report_reasons": null, "author": "paolapardo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/", "subreddit_subscribers": 106208, "created_utc": 1684486238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This question is part of my upskilling strategy so any advice is appreciated.\nI want to hear about technologies that not anyone can learn and master and is really sought after and can make me a standout", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most advanced DE frameworks skills that DE employers value the most?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ltiiu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684500536.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684497823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This question is part of my upskilling strategy so any advice is appreciated.\nI want to hear about technologies that not anyone can learn and master and is really sought after and can make me a standout&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13ltiiu", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ltiiu/what_are_the_most_advanced_de_frameworks_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ltiiu/what_are_the_most_advanced_de_frameworks_skills/", "subreddit_subscribers": 106208, "created_utc": 1684497823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**2022:**\n\n* A declarative approach is being adopted everywhere. From Kubernetes (where code is infrastructure), to [orchestration as code](https://airbyte.com/blog/data-orchestration-trends), to [integration as code](https://airbyte.com/tutorials/configure-airbyte-with-python-dagster) with low-code approaches, it's present across all disciplines.\n* This same underlying approach has been observed with the [rise of the semantic layer](https://airbyte.com/blog/the-rise-of-the-semantic-layer-metrics-on-the-fly) (essentially a declarative approach to Metrics).\n* Metadata trends are consistently growing, with tools focused on data cataloging, data lineage, and data discovery.\n* [Rust](https://airbyte.com/blog/rust-for-data-engineering) is likely to be the future of performance-intensive applications in data, potentially taking the role that Spark occupies today.\n* Vector databases such as [duckdb](https://glossary.airbyte.com/term/duckdb/) have been adopted for handling small data. Newer ones are supporting the AI wave, with tools like Pinecone and Qdrant. Remember, AI is fundamentally a data game.\n* With regulations like GDPR and CCPA, privacy and governance are becoming more important in every company, regardless of size.\n\n**2023:**\n\n* [Data modeling](http://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-introduction) is making a comeback with the unveiling of the MDS. Amid the chaos that can occur when people start to work with complex data, modeling is proving helpful on all levels.\n* However, there's a challenge: many people in enterprises are struggling to [utilize the MDS effectively](https://airbyte.com/blog/modern-data-stack-struggle-of-enterprise-adoption).\n* AI, and particularly generative AI like ChatGPT, are still finding their footing in the data landscape. There's a lot of hype, but there's also a lot of potential waiting to be unlocked.\n* 2023 is shaping up to be the year of MDS bundling. There are [layoffs](https://www.reddit.com/r/dataengineering/comments/13l9ur0/dbt_lays_off_15_of_their_staff/) and consolidations happening (dbt [aquired](https://techcrunch.com/2023/02/08/dbt-acquires-transform/) Transform) across the MDS stack.\n\n&amp;#x200B;\n\nHi there,\n\nAs we continue to navigate through 2023, I wanted to take a moment to reflect on the trends we've seen in data engineering over the past year and discuss our predictions for the future.\n\nI've compiled a list of trends and observations from 2022 and 2023 so far (see above). What do you agree or disagree with? What are some other trends you've noticed, and what predictions would you make for the future of data engineering?\n\nI am looking forward to your thoughts as experts in the field.", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evolution and Trends of Data Engineering 2022/23", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lpd6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684502390.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684485060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;2022:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A declarative approach is being adopted everywhere. From Kubernetes (where code is infrastructure), to &lt;a href=\"https://airbyte.com/blog/data-orchestration-trends\"&gt;orchestration as code&lt;/a&gt;, to &lt;a href=\"https://airbyte.com/tutorials/configure-airbyte-with-python-dagster\"&gt;integration as code&lt;/a&gt; with low-code approaches, it&amp;#39;s present across all disciplines.&lt;/li&gt;\n&lt;li&gt;This same underlying approach has been observed with the &lt;a href=\"https://airbyte.com/blog/the-rise-of-the-semantic-layer-metrics-on-the-fly\"&gt;rise of the semantic layer&lt;/a&gt; (essentially a declarative approach to Metrics).&lt;/li&gt;\n&lt;li&gt;Metadata trends are consistently growing, with tools focused on data cataloging, data lineage, and data discovery.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://airbyte.com/blog/rust-for-data-engineering\"&gt;Rust&lt;/a&gt; is likely to be the future of performance-intensive applications in data, potentially taking the role that Spark occupies today.&lt;/li&gt;\n&lt;li&gt;Vector databases such as &lt;a href=\"https://glossary.airbyte.com/term/duckdb/\"&gt;duckdb&lt;/a&gt; have been adopted for handling small data. Newer ones are supporting the AI wave, with tools like Pinecone and Qdrant. Remember, AI is fundamentally a data game.&lt;/li&gt;\n&lt;li&gt;With regulations like GDPR and CCPA, privacy and governance are becoming more important in every company, regardless of size.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;2023:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"http://airbyte.com/blog/data-modeling-unsung-hero-data-engineering-introduction\"&gt;Data modeling&lt;/a&gt; is making a comeback with the unveiling of the MDS. Amid the chaos that can occur when people start to work with complex data, modeling is proving helpful on all levels.&lt;/li&gt;\n&lt;li&gt;However, there&amp;#39;s a challenge: many people in enterprises are struggling to &lt;a href=\"https://airbyte.com/blog/modern-data-stack-struggle-of-enterprise-adoption\"&gt;utilize the MDS effectively&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;AI, and particularly generative AI like ChatGPT, are still finding their footing in the data landscape. There&amp;#39;s a lot of hype, but there&amp;#39;s also a lot of potential waiting to be unlocked.&lt;/li&gt;\n&lt;li&gt;2023 is shaping up to be the year of MDS bundling. There are &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/13l9ur0/dbt_lays_off_15_of_their_staff/\"&gt;layoffs&lt;/a&gt; and consolidations happening (dbt &lt;a href=\"https://techcrunch.com/2023/02/08/dbt-acquires-transform/\"&gt;aquired&lt;/a&gt; Transform) across the MDS stack.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;As we continue to navigate through 2023, I wanted to take a moment to reflect on the trends we&amp;#39;ve seen in data engineering over the past year and discuss our predictions for the future.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve compiled a list of trends and observations from 2022 and 2023 so far (see above). What do you agree or disagree with? What are some other trends you&amp;#39;ve noticed, and what predictions would you make for the future of data engineering?&lt;/p&gt;\n\n&lt;p&gt;I am looking forward to your thoughts as experts in the field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?auto=webp&amp;v=enabled&amp;s=7ec56f99ed0536a9137d5c33b759b1182ff37fcb", "width": 1200, "height": 1069}, "resolutions": [{"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9326156bbafdfbe2af560a55c7dd090aedccae9e", "width": 108, "height": 96}, {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c38b9e7f09eaf51181e8cbbe966824aae768e5f", "width": 216, "height": 192}, {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54153cbe4b87547744c1a860b73b0519bb9d1123", "width": 320, "height": 285}, {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96e83e17399b6dd5be6c18c1970d061d7e222823", "width": 640, "height": 570}, {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db01c81b4765cada733504bcab210ef588f3a3a8", "width": 960, "height": 855}, {"url": "https://external-preview.redd.it/mNqIqg8CL7n3tMQfC_zYKLBIxf3_CEQvB8ZZ-Bbg5qc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47e33056529ea7394493aa3a213eaf50515b4040", "width": 1080, "height": 962}], "variants": {}, "id": "-E3Kx9LMqPOzKcEgyoOL6AUlpa2UhxV_VJ5sL8LJ1ao"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13lpd6v", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13lpd6v/evolution_and_trends_of_data_engineering_202223/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lpd6v/evolution_and_trends_of_data_engineering_202223/", "subreddit_subscribers": 106208, "created_utc": 1684485060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends, I'm well versed in the neighboring side of DE, that is Python + Airflow + GCP, which makes about 80% of my work. I'm looking forward to getting a spark job without any spark experience. How can I pivot?\n\nI already looked at internal jobs but we are decommissioning the spark clusters so there is little chance to use it. I can learn the basics from side projects but from what I experienced in interviews, side projects are not going to be enough.", "author_fullname": "t2_clsgf4j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I pivot myself to get a spark job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lfgd9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684455244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I&amp;#39;m well versed in the neighboring side of DE, that is Python + Airflow + GCP, which makes about 80% of my work. I&amp;#39;m looking forward to getting a spark job without any spark experience. How can I pivot?&lt;/p&gt;\n\n&lt;p&gt;I already looked at internal jobs but we are decommissioning the spark clusters so there is little chance to use it. I can learn the basics from side projects but from what I experienced in interviews, side projects are not going to be enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13lfgd9", "is_robot_indexable": true, "report_reasons": null, "author": "redditthrowaway0315", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lfgd9/how_can_i_pivot_myself_to_get_a_spark_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lfgd9/how_can_i_pivot_myself_to_get_a_spark_job/", "subreddit_subscribers": 106208, "created_utc": 1684455244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I will be moving to a new role at work in a few weeks where I will essentially be a one man data team. I have a good background in Python, SQL, Power BI and I just got my Azure Data Fundamentals certificate. In the meantime before I start the new role I\u2019d like to pick up some data engineering / ETL knowledge so I can be a bit more effective and cover my blind spots.I will not know what type or quantity of data is available until I start.  In the meantime I\u2019m looking for something relatively easy to pick up, perhaps equivalent to a ~10 hour udemy course. Right now I\u2019m completely overwhelmed by the amount of options available to me. Options I\u2019m looking at are:\n\n- Azure Data Factory or Synapse Analytics\n\n- Spark / Hadoop / Python implementation\n\n- Spark with Databricks\n\n- Airflow\n\n- DBT\n\n- Others?\n\nThoughts?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy to learn ETL solutions for a one man data team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lrov0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684492871.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684492520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I will be moving to a new role at work in a few weeks where I will essentially be a one man data team. I have a good background in Python, SQL, Power BI and I just got my Azure Data Fundamentals certificate. In the meantime before I start the new role I\u2019d like to pick up some data engineering / ETL knowledge so I can be a bit more effective and cover my blind spots.I will not know what type or quantity of data is available until I start.  In the meantime I\u2019m looking for something relatively easy to pick up, perhaps equivalent to a ~10 hour udemy course. Right now I\u2019m completely overwhelmed by the amount of options available to me. Options I\u2019m looking at are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Azure Data Factory or Synapse Analytics&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Spark / Hadoop / Python implementation&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Spark with Databricks&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Airflow&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;DBT&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Others?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lrov0", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lrov0/easy_to_learn_etl_solutions_for_a_one_man_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lrov0/easy_to_learn_etl_solutions_for_a_one_man_data/", "subreddit_subscribers": 106208, "created_utc": 1684492520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our company has developed a decentralize data mesh architecture with different projects having different AWS accounts and all data products being linked through a centralized data catalog.\n\nRight now, I'm working in a team building out use cases for the business. The long term plan is for the business to be able to support the data needs themself, but I really don't think we're anywhere close to that point yet. I'm fine working in a data mesh, but as things stand, it's really just going to be my team developing solutions, and if we stick to the decentralized approach, there are certain tools that we'll need to duplicate in each account we work in, for instance Airflow. *Technically*, this is also fine, but it seems super silly and expensive to duplicate an airflow environment multiple times, you'll lose the advantage of centralizing DAG runs in the Airflow UI, and you'll have cases where you spin up an Airflow environment to run a single DAG! One thought is to just centralize the DE toolings that my team build, I'm curious if there's any ideas here?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In a decentralized data mesh architecture, should data engineering tools be duplicated in each account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ld2aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684449196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our company has developed a decentralize data mesh architecture with different projects having different AWS accounts and all data products being linked through a centralized data catalog.&lt;/p&gt;\n\n&lt;p&gt;Right now, I&amp;#39;m working in a team building out use cases for the business. The long term plan is for the business to be able to support the data needs themself, but I really don&amp;#39;t think we&amp;#39;re anywhere close to that point yet. I&amp;#39;m fine working in a data mesh, but as things stand, it&amp;#39;s really just going to be my team developing solutions, and if we stick to the decentralized approach, there are certain tools that we&amp;#39;ll need to duplicate in each account we work in, for instance Airflow. &lt;em&gt;Technically&lt;/em&gt;, this is also fine, but it seems super silly and expensive to duplicate an airflow environment multiple times, you&amp;#39;ll lose the advantage of centralizing DAG runs in the Airflow UI, and you&amp;#39;ll have cases where you spin up an Airflow environment to run a single DAG! One thought is to just centralize the DE toolings that my team build, I&amp;#39;m curious if there&amp;#39;s any ideas here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ld2aj", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ld2aj/in_a_decentralized_data_mesh_architecture_should/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ld2aj/in_a_decentralized_data_mesh_architecture_should/", "subreddit_subscribers": 106208, "created_utc": 1684449196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI have been using Databricks workflow UI to create jobs and manage dependency. But it's too much of a manual effort to manage multiple tasks and jobs with no versioning support to show for it. I am thinking of exploring jobs API to achieve the same. Also I read ADF can be used for this. But I don't have any experience with ADF.\n\nWhat are pros and cons of using workflow API or ADF to schedule notebooks? What should I keep in mind before selecting any one of them? Are there any other options to achieve the same preferably which doesn't cost extra?", "author_fullname": "t2_wkq4zhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks jobs orchestration Workflow vs ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l65it", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684433250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have been using Databricks workflow UI to create jobs and manage dependency. But it&amp;#39;s too much of a manual effort to manage multiple tasks and jobs with no versioning support to show for it. I am thinking of exploring jobs API to achieve the same. Also I read ADF can be used for this. But I don&amp;#39;t have any experience with ADF.&lt;/p&gt;\n\n&lt;p&gt;What are pros and cons of using workflow API or ADF to schedule notebooks? What should I keep in mind before selecting any one of them? Are there any other options to achieve the same preferably which doesn&amp;#39;t cost extra?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13l65it", "is_robot_indexable": true, "report_reasons": null, "author": "the_aris", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l65it/databricks_jobs_orchestration_workflow_vs_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l65it/databricks_jobs_orchestration_workflow_vs_adf/", "subreddit_subscribers": 106208, "created_utc": 1684433250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll to keep this organized (I mostly succeeded) and not write a novel (I failed).\n\n**My Question / Request**\n\nWhat would you recommend / change / add to my current plans for someone who is in my position?\n\n**My situation:**\n\nI was laid off from my job as an electrical/controls engineer recently. I really did not like that career path. I realized too late that I would have preferred data engineering / software engineering / data science, etc. rather than electrical engineering. I really enjoy coding and working with data.\n\nI have no intention of being unemployed for long, but I am able to continue living normally off of savings for a long time, so I\u2019m using my unexpected free time to *finally* change my career path, focusing on data engineering. I\u2019ve wanted to do this for a while.\n\nI\u2019ve done a fair bit of research on the things I need to know and have already started learning from various online courses. (Ignore the inflated prices. Never pay full price for anything on Udemy.)\n\n**What I\u2019ve already learned (before being laid off):**\n\nPython, Pandas, some Numpy, and some visualization tools [from this course](https://www.udemy.com/course/python-for-machine-learning-data-science-masterclass/). I\u2019d like to finish learning the ML content that I\u2019ve already started, but that\u2019s not a priority right now.\n\n**What I\u2019m Currently learning:**\n\n* SQL [from this course](https://www.udemy.com/course/the-complete-sql-bootcamp/). Almost done.\n* Pyspark [from this course](https://www.udemy.com/course/pyspark-essentials-for-data-scientists-big-data-python/). Once again, I\u2019ll be skipping the ML stuff (for now) and I\u2019m just using the first sections of the course to get familiar with using Pyspark. I\u2019ll probably find a different source for learning about clustering and streaming. I do have a reason for choosing this course over the others.\n\n**Plan to learn next:**\n\n* Databricks, [probably from this course](https://www.udemy.com/course/databricks-certified-data-engineer-associate/) and then [this course](https://www.udemy.com/course/databricks-certified-data-engineer-professional/).\n* Any well known cloud based service. Probably AWS. Haven\u2019t picked a course yet.\n* DBT from the [education section of their website](https://courses.getdbt.com/collections/beginner).\n* Whatever else you all recommend\n\n**Other stuff:**\n\n\u201cYou learn by doing. Pick a project and do it.\u201d seems to be common advice here. I\u2019m already aware of this and have already chosen a couple of projects that I\u2019d like to work on. However, I have to start *somewhere*. Something more helpful would be a link to a good resource that I can use for a project, like a large collection of realistic datasets or anything else you can think of.\n\nI know that \u201centry level\u201d DE positions aren\u2019t exactly common (though I have found one or two in my state, with some caveats). If I have to choose an analyst position and work my way up to DE, that\u2019s fine \u2013 maybe even for the best. If that\u2019s something you think I should do, then any advice on how I should adjust my current plans would be helpful.\n\n&amp;#x200B;\n\nBtw, [Anki Cards](https://www.google.com/search?client=firefox-b-1-d&amp;q=ANKI+CARds) are fantastic and I wish I knew about them years ago. Really helping with my learning.", "author_fullname": "t2_ldflflc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you recommend / change / add to my current plans for someone who is in my position?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13lzk74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684511782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll to keep this organized (I mostly succeeded) and not write a novel (I failed).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Question / Request&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;What would you recommend / change / add to my current plans for someone who is in my position?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My situation:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I was laid off from my job as an electrical/controls engineer recently. I really did not like that career path. I realized too late that I would have preferred data engineering / software engineering / data science, etc. rather than electrical engineering. I really enjoy coding and working with data.&lt;/p&gt;\n\n&lt;p&gt;I have no intention of being unemployed for long, but I am able to continue living normally off of savings for a long time, so I\u2019m using my unexpected free time to &lt;em&gt;finally&lt;/em&gt; change my career path, focusing on data engineering. I\u2019ve wanted to do this for a while.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve done a fair bit of research on the things I need to know and have already started learning from various online courses. (Ignore the inflated prices. Never pay full price for anything on Udemy.)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I\u2019ve already learned (before being laid off):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Python, Pandas, some Numpy, and some visualization tools &lt;a href=\"https://www.udemy.com/course/python-for-machine-learning-data-science-masterclass/\"&gt;from this course&lt;/a&gt;. I\u2019d like to finish learning the ML content that I\u2019ve already started, but that\u2019s not a priority right now.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I\u2019m Currently learning:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL &lt;a href=\"https://www.udemy.com/course/the-complete-sql-bootcamp/\"&gt;from this course&lt;/a&gt;. Almost done.&lt;/li&gt;\n&lt;li&gt;Pyspark &lt;a href=\"https://www.udemy.com/course/pyspark-essentials-for-data-scientists-big-data-python/\"&gt;from this course&lt;/a&gt;. Once again, I\u2019ll be skipping the ML stuff (for now) and I\u2019m just using the first sections of the course to get familiar with using Pyspark. I\u2019ll probably find a different source for learning about clustering and streaming. I do have a reason for choosing this course over the others.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Plan to learn next:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Databricks, &lt;a href=\"https://www.udemy.com/course/databricks-certified-data-engineer-associate/\"&gt;probably from this course&lt;/a&gt; and then &lt;a href=\"https://www.udemy.com/course/databricks-certified-data-engineer-professional/\"&gt;this course&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;Any well known cloud based service. Probably AWS. Haven\u2019t picked a course yet.&lt;/li&gt;\n&lt;li&gt;DBT from the &lt;a href=\"https://courses.getdbt.com/collections/beginner\"&gt;education section of their website&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;Whatever else you all recommend&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Other stuff:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;\u201cYou learn by doing. Pick a project and do it.\u201d seems to be common advice here. I\u2019m already aware of this and have already chosen a couple of projects that I\u2019d like to work on. However, I have to start &lt;em&gt;somewhere&lt;/em&gt;. Something more helpful would be a link to a good resource that I can use for a project, like a large collection of realistic datasets or anything else you can think of.&lt;/p&gt;\n\n&lt;p&gt;I know that \u201centry level\u201d DE positions aren\u2019t exactly common (though I have found one or two in my state, with some caveats). If I have to choose an analyst position and work my way up to DE, that\u2019s fine \u2013 maybe even for the best. If that\u2019s something you think I should do, then any advice on how I should adjust my current plans would be helpful.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Btw, &lt;a href=\"https://www.google.com/search?client=firefox-b-1-d&amp;amp;q=ANKI+CARds\"&gt;Anki Cards&lt;/a&gt; are fantastic and I wish I knew about them years ago. Really helping with my learning.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lzk74", "is_robot_indexable": true, "report_reasons": null, "author": "Engineer086", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lzk74/what_would_you_recommend_change_add_to_my_current/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lzk74/what_would_you_recommend_change_add_to_my_current/", "subreddit_subscribers": 106208, "created_utc": 1684511782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any challenges faced while working with adf and azure databricks especially on any ecommerce projects", "author_fullname": "t2_5nx7csx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mention some challenges faced while working with azure databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ly7eo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684508860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any challenges faced while working with adf and azure databricks especially on any ecommerce projects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13ly7eo", "is_robot_indexable": true, "report_reasons": null, "author": "pavan449", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ly7eo/mention_some_challenges_faced_while_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ly7eo/mention_some_challenges_faced_while_working_with/", "subreddit_subscribers": 106208, "created_utc": 1684508860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm sorry if it's the most repetitive question or a need of advice.\n\nI'm currently an ETL developer with the skills below.\nSSIS\nT-SQL\nPOWER BI\n\nI'm not even sure if I can call myself a DE. If I'm not one. Please help me with the necessary \"Tech\" skills for one to become a DE.\n\nI have been searching for this for more than a week. I have also gone through a few roadmaps on youtube like the one that of the SeattleDataGuy. \n\nAny experienced DEs here, please help. I appreciate your taking the time to share details.\n\nThanks a lot.\n\nEdit: Any advice from those who made it to DE role from zero is also most welcome. Because I'm in the same situation where you once were.", "author_fullname": "t2_5prh8z7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice to start the DE career.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13m0epd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684514437.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684513623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sorry if it&amp;#39;s the most repetitive question or a need of advice.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an ETL developer with the skills below.\nSSIS\nT-SQL\nPOWER BI&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not even sure if I can call myself a DE. If I&amp;#39;m not one. Please help me with the necessary &amp;quot;Tech&amp;quot; skills for one to become a DE.&lt;/p&gt;\n\n&lt;p&gt;I have been searching for this for more than a week. I have also gone through a few roadmaps on youtube like the one that of the SeattleDataGuy. &lt;/p&gt;\n\n&lt;p&gt;Any experienced DEs here, please help. I appreciate your taking the time to share details.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot.&lt;/p&gt;\n\n&lt;p&gt;Edit: Any advice from those who made it to DE role from zero is also most welcome. Because I&amp;#39;m in the same situation where you once were.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13m0epd", "is_robot_indexable": true, "report_reasons": null, "author": "Mrmjix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13m0epd/need_advice_to_start_the_de_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13m0epd/need_advice_to_start_the_de_career/", "subreddit_subscribers": 106208, "created_utc": 1684513623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI work in healthcare research and I am trying to take zipped folders containing CSVs and then upload them to our SQL Server and I believe I have a faulty process for doing this, so I'm hoping this community can help. \n\nAt the end of the day, I just need the zipped CSVs to go into a SQL Server. Here is the situation.\n\nWe receive 11 zipped folders with CSVs from our data partners, one for each of the 11 research locations. Each folder contains 11 CSV files about various participant outcome information, for a total of 121 files, 11 files over 11 location folders. All 11 files are the same information, just for the respective site. \n\nFor example the zipped folder from SiteA has SiteAParticipantInfo.csv, SiteAParticipantOutcome.csv, SiteALocationInfo etc. And SiteB has SiteBParticipantInfo.csv, SiteBParticipantOutcome.csv, SiteBLocationInfo so on and so forth. Therefore I am:\n\n1. Unzipping the folders, or extracting the files\n2. Merging SiteAParticipantInfo, SiteBParticipantInfo, SiteCParticipantInfo,..., SiteKParticipantInfo into one large CSV\n3. Repeating the process for all 11 file types\n4. Uploading the merged file into SQL Server\n\nThe data is not that large (\\~30 GB) total, but the extracting and appending is taking much longer than I think it should. I have tried using Python with Pandas, but some files couldn't be read in because the storage was too high (&gt;2 GB), which seemed strange to me. So then I switched to the command prompt using the \"copy \\*csv\" function but it still took me 7 hours yesterday to append one type of file together using that method.\n\nOne important thing to consider is all of this data is stored on a secure VPN which I believe contributes to some of the slow computing times.\n\nDoes anyone have a suggestion? Thank you!", "author_fullname": "t2_4651cku9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with taking zipped files with CSVs, appending them together, and uploading them to SQL SERVER", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13lzkg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684511797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I work in healthcare research and I am trying to take zipped folders containing CSVs and then upload them to our SQL Server and I believe I have a faulty process for doing this, so I&amp;#39;m hoping this community can help. &lt;/p&gt;\n\n&lt;p&gt;At the end of the day, I just need the zipped CSVs to go into a SQL Server. Here is the situation.&lt;/p&gt;\n\n&lt;p&gt;We receive 11 zipped folders with CSVs from our data partners, one for each of the 11 research locations. Each folder contains 11 CSV files about various participant outcome information, for a total of 121 files, 11 files over 11 location folders. All 11 files are the same information, just for the respective site. &lt;/p&gt;\n\n&lt;p&gt;For example the zipped folder from SiteA has SiteAParticipantInfo.csv, SiteAParticipantOutcome.csv, SiteALocationInfo etc. And SiteB has SiteBParticipantInfo.csv, SiteBParticipantOutcome.csv, SiteBLocationInfo so on and so forth. Therefore I am:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unzipping the folders, or extracting the files&lt;/li&gt;\n&lt;li&gt;Merging SiteAParticipantInfo, SiteBParticipantInfo, SiteCParticipantInfo,..., SiteKParticipantInfo into one large CSV&lt;/li&gt;\n&lt;li&gt;Repeating the process for all 11 file types&lt;/li&gt;\n&lt;li&gt;Uploading the merged file into SQL Server&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The data is not that large (~30 GB) total, but the extracting and appending is taking much longer than I think it should. I have tried using Python with Pandas, but some files couldn&amp;#39;t be read in because the storage was too high (&amp;gt;2 GB), which seemed strange to me. So then I switched to the command prompt using the &amp;quot;copy *csv&amp;quot; function but it still took me 7 hours yesterday to append one type of file together using that method.&lt;/p&gt;\n\n&lt;p&gt;One important thing to consider is all of this data is stored on a secure VPN which I believe contributes to some of the slow computing times.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a suggestion? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lzkg4", "is_robot_indexable": true, "report_reasons": null, "author": "RtheSSQL", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lzkg4/need_help_with_taking_zipped_files_with_csvs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lzkg4/need_help_with_taking_zipped_files_with_csvs/", "subreddit_subscribers": 106208, "created_utc": 1684511797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the data engineers here who moved towards the data DevOps/ML Ops/tool fixers area: It's quite lonely bring at this intersection. Neither DevOps nor Data engineering areas seem relatable enough.\n\nWhat resources or communities do you follow?", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data DevOps resources/communities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13luq7a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684501018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data engineers here who moved towards the data DevOps/ML Ops/tool fixers area: It&amp;#39;s quite lonely bring at this intersection. Neither DevOps nor Data engineering areas seem relatable enough.&lt;/p&gt;\n\n&lt;p&gt;What resources or communities do you follow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13luq7a", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13luq7a/data_devops_resourcescommunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13luq7a/data_devops_resourcescommunities/", "subreddit_subscribers": 106208, "created_utc": 1684501018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the common data masking tools used to mask  Personally Identifiable Information or classified fields.   \nWhat are the most widely used tools. (preferably open source)", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Data masking tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lrwvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684493220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the common data masking tools used to mask  Personally Identifiable Information or classified fields.&lt;br/&gt;\nWhat are the most widely used tools. (preferably open source)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lrwvy", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lrwvy/common_data_masking_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lrwvy/common_data_masking_tools/", "subreddit_subscribers": 106208, "created_utc": 1684493220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Gcp certified people here , can you tell me some important topics that i can focus on if i need to pass the exam. Have 1 week preparation time left.\nPlease help.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gcp data engineer cert prep topics suggestions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lrkeh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684492129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gcp certified people here , can you tell me some important topics that i can focus on if i need to pass the exam. Have 1 week preparation time left.\nPlease help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lrkeh", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lrkeh/gcp_data_engineer_cert_prep_topics_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lrkeh/gcp_data_engineer_cert_prep_topics_suggestions/", "subreddit_subscribers": 106208, "created_utc": 1684492129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any specific use cases ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use cases :Does anyone have success story around using ADF ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lrakv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684491287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any specific use cases ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13lrakv", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lrakv/use_cases_does_anyone_have_success_story_around/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lrakv/use_cases_does_anyone_have_success_story_around/", "subreddit_subscribers": 106208, "created_utc": 1684491287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a 150 million row SQL table that gets another 1 million rows added to it each month. Each month, after that data is added, the whole table is extracted into a PowerPivot data model (3 hours). This 4GB Excel file then has to be downloaded (15 mins) and run by each individual client (30 mins) - the reason is because each client needs to be able to recalculate all 150 million rows according to their specifications. The columns cannot be pre calculated in SQL - there are thousands of combinations for the specifications, so a small set of columns must be recalculated by the user at the run time, after the specifications have been defined. \n\nThis pipeline works, the self contained Excel file is easy to maintain, easy to use, Pivot tables are very powerful, and everyone knows how to use Excel.\n\nHowever, each user having to download and run the file takes the best part of an hour. Also, having the data model on the user\u2019s machine is a security concern, and at some point the user is going to run out of space because the data model will be too big for their laptop.\n\nIs there a cloud based way to do this? It needs to have the general usability of Excel, but the power to dynamically recalculate 150m rows significantly faster than 30 minutes. Thanks in advance.", "author_fullname": "t2_foxxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a cloud-based platform that can help me do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lbc3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684445026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 150 million row SQL table that gets another 1 million rows added to it each month. Each month, after that data is added, the whole table is extracted into a PowerPivot data model (3 hours). This 4GB Excel file then has to be downloaded (15 mins) and run by each individual client (30 mins) - the reason is because each client needs to be able to recalculate all 150 million rows according to their specifications. The columns cannot be pre calculated in SQL - there are thousands of combinations for the specifications, so a small set of columns must be recalculated by the user at the run time, after the specifications have been defined. &lt;/p&gt;\n\n&lt;p&gt;This pipeline works, the self contained Excel file is easy to maintain, easy to use, Pivot tables are very powerful, and everyone knows how to use Excel.&lt;/p&gt;\n\n&lt;p&gt;However, each user having to download and run the file takes the best part of an hour. Also, having the data model on the user\u2019s machine is a security concern, and at some point the user is going to run out of space because the data model will be too big for their laptop.&lt;/p&gt;\n\n&lt;p&gt;Is there a cloud based way to do this? It needs to have the general usability of Excel, but the power to dynamically recalculate 150m rows significantly faster than 30 minutes. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lbc3x", "is_robot_indexable": true, "report_reasons": null, "author": "autonova3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lbc3x/is_there_a_cloudbased_platform_that_can_help_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lbc3x/is_there_a_cloudbased_platform_that_can_help_me/", "subreddit_subscribers": 106208, "created_utc": 1684445026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This might be a silly question but I have seen the suggestion that the first step in a dimensional design process is to \"Select the Business Process\".  We have a lot of data based on surveys.  So the process is, \"someone filled in a survey\", but this isn't going to elicit good feedback from the business on what they are looking to report on.  Am I being too niggly?", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling for Surveys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13laork", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684443534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a silly question but I have seen the suggestion that the first step in a dimensional design process is to &amp;quot;Select the Business Process&amp;quot;.  We have a lot of data based on surveys.  So the process is, &amp;quot;someone filled in a survey&amp;quot;, but this isn&amp;#39;t going to elicit good feedback from the business on what they are looking to report on.  Am I being too niggly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13laork", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13laork/data_modeling_for_surveys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13laork/data_modeling_for_surveys/", "subreddit_subscribers": 106208, "created_utc": 1684443534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have our dwh in sql server on prem. Reports are based on tableau data sources which are done by quering data from our dwh. Right now the refreshing of the tableau data sources is on a daily scheduled basis. I would like the data sources to be refreshed as soon as our daily etl run from sql server is finished. I was thinking of making an azure function python script for interacting with tableau api. What is the easiest way to trigger an azure function as a last step in a sql agent job such that i can also implement logging in sql server. Any other recommendations to trigger a python script from sql server is also welcome.", "author_fullname": "t2_6caal7yy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Infrastructure? Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13lzqab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684512133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have our dwh in sql server on prem. Reports are based on tableau data sources which are done by quering data from our dwh. Right now the refreshing of the tableau data sources is on a daily scheduled basis. I would like the data sources to be refreshed as soon as our daily etl run from sql server is finished. I was thinking of making an azure function python script for interacting with tableau api. What is the easiest way to trigger an azure function as a last step in a sql agent job such that i can also implement logging in sql server. Any other recommendations to trigger a python script from sql server is also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lzqab", "is_robot_indexable": true, "report_reasons": null, "author": "janus2527", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lzqab/infrastructure_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lzqab/infrastructure_question/", "subreddit_subscribers": 106208, "created_utc": 1684512133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is no way to extract excel stored on Sharepoint right now.  \nAfter some digging I found it can be done in 3 ways:  \n\n\n1. JDBC connector in databricks + parametrization of conn\n2. Moving files to cloud storage and reading it from there (Movement automated by Logic Apps/ Azure functions in case of Azure)\n3. Moving excel to workspace as a file and reading it as /dbfs/filestore/tables/my\\_excel.xlsx (in case of few files)\n\nAnyone has experience with this painful topic? Any emotional support :)?", "author_fullname": "t2_7mnlik68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting Sharepoint stored files to Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lx4gu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684506616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is no way to extract excel stored on Sharepoint right now.&lt;br/&gt;\nAfter some digging I found it can be done in 3 ways:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;JDBC connector in databricks + parametrization of conn&lt;/li&gt;\n&lt;li&gt;Moving files to cloud storage and reading it from there (Movement automated by Logic Apps/ Azure functions in case of Azure)&lt;/li&gt;\n&lt;li&gt;Moving excel to workspace as a file and reading it as /dbfs/filestore/tables/my_excel.xlsx (in case of few files)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anyone has experience with this painful topic? Any emotional support :)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lx4gu", "is_robot_indexable": true, "report_reasons": null, "author": "Astherol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lx4gu/extracting_sharepoint_stored_files_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lx4gu/extracting_sharepoint_stored_files_to_databricks/", "subreddit_subscribers": 106208, "created_utc": 1684506616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am strong in python, R, SQL coding wise. and use them all at work\n\nI currently use and move data between AWS, Databricks, and SQL Server.\n\ni pretty much manage a team that moves data from AWS where is we store our raw data to databricks and sql server where we do our data prep and processing work.  Then feed the data into a front end ui that we build that does different things from dashboarding to forecasting to simulations.\n\nI dont have a pure DE background, but am in a director level role due to my time in Datascience and analytics where i was involved in large scale DE projects and just was able to make the switch thru that\n\n&amp;#x200B;\n\nIve thought about learning Airflow.  But, am wondering if it is even worthwhile due to where ia m in my career as while i am hands on. its mostly done to help younger members of the team and i have strong coding skills so i jsut do things faster than them lol\n\n&amp;#x200B;\n\n so im wondering if  may be better off just learning more data management strategy? or even some data architecture which i have little knowledge on?\n\nWhat would you learn in my position?", "author_fullname": "t2_9q93psld7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth while for me to learn any new tech/skills in my position?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lsi0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684494975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am strong in python, R, SQL coding wise. and use them all at work&lt;/p&gt;\n\n&lt;p&gt;I currently use and move data between AWS, Databricks, and SQL Server.&lt;/p&gt;\n\n&lt;p&gt;i pretty much manage a team that moves data from AWS where is we store our raw data to databricks and sql server where we do our data prep and processing work.  Then feed the data into a front end ui that we build that does different things from dashboarding to forecasting to simulations.&lt;/p&gt;\n\n&lt;p&gt;I dont have a pure DE background, but am in a director level role due to my time in Datascience and analytics where i was involved in large scale DE projects and just was able to make the switch thru that&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ive thought about learning Airflow.  But, am wondering if it is even worthwhile due to where ia m in my career as while i am hands on. its mostly done to help younger members of the team and i have strong coding skills so i jsut do things faster than them lol&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;so im wondering if  may be better off just learning more data management strategy? or even some data architecture which i have little knowledge on?&lt;/p&gt;\n\n&lt;p&gt;What would you learn in my position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13lsi0q", "is_robot_indexable": true, "report_reasons": null, "author": "AntiquePassage7229", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lsi0q/is_it_worth_while_for_me_to_learn_any_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lsi0q/is_it_worth_while_for_me_to_learn_any_new/", "subreddit_subscribers": 106208, "created_utc": 1684494975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I own an IT startup and wanted to share some thoughts I have on data literacy. For my employees and me, data literacy holds significant personal importance, as it should for any IT company. IT specialists play a crucial role in transforming raw data into valuable insights. By promoting data literacy, they help foster a data-driven culture, empower employees to make informed decisions, and contribute to the overall success and competitiveness of the organization. We believe it\u2019s vital for them to view it from an individual perspective, taking into account its relevance in both work and life. The definition we use encompasses the ability to read, write, and communicate with data in context, which means it\u2019s not a one-size-fits-all proposition. To truly understand data literacy, we need to consider mindset, language, and skills, as well as people\u2019s attitudes and beliefs.\n\nThe concept of data literacy in context resonates with us because it highlights the need for personalization in the data literacy journey. A crucial aspect of this journey is securing executive buy-in. For example, our CEO recognizes the importance of data literacy for our organization, but other specialists may encounter resistance when trying to secure executive support for data upskilling initiatives. To tackle this challenge, we must effectively communicate the significance of data literacy and data upskilling.\n\n**TIP: Our specialists use a triangle mnemonic called the VIA model to explain any use case of data, which comprises three sets of terms: business value, information, and analysis. Experts in data governance, stewardship, and engineering excel in the \u201cI\u201d portion, while quants, developers, AI modelers, business intelligence experts, and analytics center of excellence professionals specialize in the \u201cA.\u201d Business stakeholders, process management, business analysts, and leaders, on the other hand, know the \u201cV\u201d or business value aspect best.**\n\nYou can read more about how we modeled data literacy behavior, piloted programs and scaled it at [https://ainsys.com/blog/2023/04/24/data-literacy/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_literacy](https://ainsys.com/blog/2023/04/24/data-literacy/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=data_literacy) I would greatly appreciate your feedback. DM me for more #digitaltransformation talks :)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach data literacy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lo3f8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684480866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I own an IT startup and wanted to share some thoughts I have on data literacy. For my employees and me, data literacy holds significant personal importance, as it should for any IT company. IT specialists play a crucial role in transforming raw data into valuable insights. By promoting data literacy, they help foster a data-driven culture, empower employees to make informed decisions, and contribute to the overall success and competitiveness of the organization. We believe it\u2019s vital for them to view it from an individual perspective, taking into account its relevance in both work and life. The definition we use encompasses the ability to read, write, and communicate with data in context, which means it\u2019s not a one-size-fits-all proposition. To truly understand data literacy, we need to consider mindset, language, and skills, as well as people\u2019s attitudes and beliefs.&lt;/p&gt;\n\n&lt;p&gt;The concept of data literacy in context resonates with us because it highlights the need for personalization in the data literacy journey. A crucial aspect of this journey is securing executive buy-in. For example, our CEO recognizes the importance of data literacy for our organization, but other specialists may encounter resistance when trying to secure executive support for data upskilling initiatives. To tackle this challenge, we must effectively communicate the significance of data literacy and data upskilling.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TIP: Our specialists use a triangle mnemonic called the VIA model to explain any use case of data, which comprises three sets of terms: business value, information, and analysis. Experts in data governance, stewardship, and engineering excel in the \u201cI\u201d portion, while quants, developers, AI modelers, business intelligence experts, and analytics center of excellence professionals specialize in the \u201cA.\u201d Business stakeholders, process management, business analysts, and leaders, on the other hand, know the \u201cV\u201d or business value aspect best.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;You can read more about how we modeled data literacy behavior, piloted programs and scaled it at &lt;a href=\"https://ainsys.com/blog/2023/04/24/data-literacy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_literacy\"&gt;https://ainsys.com/blog/2023/04/24/data-literacy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_literacy&lt;/a&gt; I would greatly appreciate your feedback. DM me for more #digitaltransformation talks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;v=enabled&amp;s=a857d06fc3f1362c48ce1ce4e18be17b3a3dc051", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13lo3f8", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lo3f8/how_to_approach_data_literacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lo3f8/how_to_approach_data_literacy/", "subreddit_subscribers": 106208, "created_utc": 1684480866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are migrating away from Google Analytics and need to look at options to backup all of our data.\nExport to BigQuery seems like the easiest to setup. However, as per the documentation \n\nWhen you initially link an Analytics reporting view to BigQuery, Analytics exports 13 months or 10 billion hits (whichever is smaller) of historical data to BigQuery.\n\nSo is it not possible to get data before that ? I would like to get all historical data backed up if possible.\nOur current volume is 700M per month", "author_fullname": "t2_7ltsqjwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Analytics (UA) Backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lny3h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684480408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are migrating away from Google Analytics and need to look at options to backup all of our data.\nExport to BigQuery seems like the easiest to setup. However, as per the documentation &lt;/p&gt;\n\n&lt;p&gt;When you initially link an Analytics reporting view to BigQuery, Analytics exports 13 months or 10 billion hits (whichever is smaller) of historical data to BigQuery.&lt;/p&gt;\n\n&lt;p&gt;So is it not possible to get data before that ? I would like to get all historical data backed up if possible.\nOur current volume is 700M per month&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lny3h", "is_robot_indexable": true, "report_reasons": null, "author": "GonzaloGatorade", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lny3h/google_analytics_ua_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lny3h/google_analytics_ua_backup/", "subreddit_subscribers": 106208, "created_utc": 1684480408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm fairly new to DE and engineering itself working in a startup our existing ETL Infra uses glue (hive/hudi) to create our datalake  and some cases lambda ! Now we have alot of request for real time data in data lake If people here can guide whats new and better for real time  and also how are people doing real-time analytics on datalake. As per my team they are thinking about CDC + glue streaming !Pls if you can guide me it will be a great help. THANKS in advance.", "author_fullname": "t2_arz03l52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real time data in datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lmwkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684476940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m fairly new to DE and engineering itself working in a startup our existing ETL Infra uses glue (hive/hudi) to create our datalake  and some cases lambda ! Now we have alot of request for real time data in data lake If people here can guide whats new and better for real time  and also how are people doing real-time analytics on datalake. As per my team they are thinking about CDC + glue streaming !Pls if you can guide me it will be a great help. THANKS in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13lmwkb", "is_robot_indexable": true, "report_reasons": null, "author": "sam-sinister", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13lmwkb/real_time_data_in_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13lmwkb/real_time_data_in_datalake/", "subreddit_subscribers": 106208, "created_utc": 1684476940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're very behind the curve right now and trying to modernize. We have access to PROD and it will be revoked when we finally start using CI/CD.\n\nWe've always deployed our python scripts directly to PROD.  \nWe don't license Anaconda and we don't license Docker.\n\nMy thinking was that we can create containers with it's own Python version and package versions using pyenv and venv.  \nAnother team member is packaging using setup tools and pip installs directly from our git repos.\n\nAny suggestions for best way to proceed and be forward-looking?", "author_fullname": "t2_g5gkx0d1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team deploy Python Apps in Prod?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13l90fo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684439642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re very behind the curve right now and trying to modernize. We have access to PROD and it will be revoked when we finally start using CI/CD.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve always deployed our python scripts directly to PROD.&lt;br/&gt;\nWe don&amp;#39;t license Anaconda and we don&amp;#39;t license Docker.&lt;/p&gt;\n\n&lt;p&gt;My thinking was that we can create containers with it&amp;#39;s own Python version and package versions using pyenv and venv.&lt;br/&gt;\nAnother team member is packaging using setup tools and pip installs directly from our git repos.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for best way to proceed and be forward-looking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13l90fo", "is_robot_indexable": true, "report_reasons": null, "author": "theCuriousDE", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13l90fo/how_does_your_team_deploy_python_apps_in_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13l90fo/how_does_your_team_deploy_python_apps_in_prod/", "subreddit_subscribers": 106208, "created_utc": 1684439642.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}