{"kind": "Listing", "data": {"after": "t3_13t7whi", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_668ljsnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "N\\A cell in the matrix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13sjnj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 263, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 263, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Uxvxf8vMIXimus4kbV2DKfMDEIIvwh6u4e50kZHiuXk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685122955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mp2q7amp792b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?auto=webp&amp;v=enabled&amp;s=dee4a473e430e633ac914a44fc3503e7d13a80b4", "width": 1169, "height": 1558}, "resolutions": [{"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fff0a3838d96effa9d14859972a41157d902ce5", "width": 108, "height": 143}, {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b7358d7b2c554d4e68d4ec776659ece26747877", "width": 216, "height": 287}, {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1070714ab7edb5913f25fea34520e6bfd8c34f20", "width": 320, "height": 426}, {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fe7fd6e781fb057fbf0e394ced4b1a88c101bac", "width": 640, "height": 852}, {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d2c348043acbfc37cdd7cea7915d0902590ced4", "width": 960, "height": 1279}, {"url": "https://preview.redd.it/mp2q7amp792b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6488c2075e0209a8debf023537b83524e681113", "width": 1080, "height": 1439}], "variants": {}, "id": "E098N-Q82Cuq3hr4hYi4Hxma8SxoXU3MSA_09X4b9lQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sjnj7", "is_robot_indexable": true, "report_reasons": null, "author": "guriraum420", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sjnj7/na_cell_in_the_matrix/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mp2q7amp792b1.jpg", "subreddit_subscribers": 910663, "created_utc": 1685122955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ap0s21sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Minimum 7 years exp the field and expertise in NLP for 70k-80k CAD contract job. This country and the market is a joke. Look at the JD. It\u2019s even comical.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"24iqz18wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75b252b7f11784e97c5d8ea34254fd561beda357"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bc2ffd25d826b757eb4c8164e92c1c47ef9a117"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=333bc670feb252698ba1132e2be26f5016fa0ff9"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c288dbc6bdbfd4060e18a76bddf80747ac7019f4"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31aeb900d56df4f3937583b66c4a09756c3e2f9e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20c4720e79337e40d28b1d8bdf9ccd9fe4413d4c"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4826cdc38fb49904304911cae96ba9a8804e9f62"}, "id": "24iqz18wud2b1"}, "y41h498wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3843dec749dab6d30d514b5cc7afa5aa1f2c0260"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=578aca1af2cbf1ca42804f592712d9f70a951692"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=593d63dde06a5e5585200d6d3ae090751745203b"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b431334d411d2715b80eee85678bbad928ae922"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8310115d2cd1304c9b7650d6c5474dd2673fc16e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77de997b9864d5949745c662b2f04bbe3150683a"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=543c5c761a4d64d99fc88f5530b39315043d56bc"}, "id": "y41h498wud2b1"}}, "name": "t3_13t8q2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 54, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "y41h498wud2b1", "id": 280365940}, {"media_id": "24iqz18wud2b1", "id": 280365941}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cnh8ZhdS2yjJETGCxh-kC9waEuTXS1W3rjRfmwdzhFM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685197178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13t8q2x", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "13t8q2x", "is_robot_indexable": true, "report_reasons": null, "author": "hootandahalf_", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t8q2x/minimum_7_years_exp_the_field_and_expertise_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13t8q2x", "subreddit_subscribers": 910663, "created_utc": 1685197178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m having a discussion soon with the head of data science within my company about opportunities on the team. I have no clue if it will actually happen or not but I\u2019m curious\u2014 is it common/customary to experience a salary change when changing teams? Or does every company do it differently? I\u2019m quite certain I make less than data scientists in my company and my current team is a completely different department from this new one.", "author_fullname": "t2_5bg0t3mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common to change salaries when transitioning internally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ssa2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685144840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m having a discussion soon with the head of data science within my company about opportunities on the team. I have no clue if it will actually happen or not but I\u2019m curious\u2014 is it common/customary to experience a salary change when changing teams? Or does every company do it differently? I\u2019m quite certain I make less than data scientists in my company and my current team is a completely different department from this new one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ssa2x", "is_robot_indexable": true, "report_reasons": null, "author": "ThrowRA-11789", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ssa2x/is_it_common_to_change_salaries_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ssa2x/is_it_common_to_change_salaries_when/", "subreddit_subscribers": 910663, "created_utc": 1685144840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pardon my genuine ignorance, I have no data science background, but I somehow ended up working with EPIC Clarity for the past 6 years. In my job, I pull a sample cohort with all of the independent variables and dependent variables according to criteria, and then pass it off to a statistician to do statistics stuff.\n\nI am not a statistician myself but I have general knowledge in statistics (MPH in epidemiology, so a bit less stats intensive than MS in biostats, but we learn the same things e.g. survival analysis, hazard ratios, odds ratios, logistics/linear/mixed regression, colinearity analysis, power calculations etc.), and so I just got into the job and started pulling a bunch of independent and dependent variables, and then run the predetermined statistics battery on them, and then get a final answer of a yes/no, or a statistical/predictive model, and that's it.\n\nI only just recently heard from other people who are data scientists or data analysts outside of my field, and I genuinely don't quite understand what a \"report\" actually is, and also, what does data visualization really do. With that said:\n\n\\- What is a report? Like, in data science, is a report the same thing as the results table in an academic paper? If that is the case, why do people write canned reports? I understand that people want to spot when there is a change recently, so that they can react to it, but wouldn't that be just an automatic thing that is triggered once a statistics threshold is triggered? Or do people look at a table before they  consider what they want to do next?\n\n\\- What is data visualization in data science? I get that graphs and charts are good for PR and impact, if you want to convince people but only have 3 seconds to do that. But why do people visualize data when all of the metrics' statistical significance are already derived? What is the data science's involvement in the visualization process? Because usually I just hand the estimates with the upper and lower limits to the med students, and they can do whatever they want on their poster, be it powerpoint or Microsoft paint or tableau or an auto CAD.", "author_fullname": "t2_3sb0qyjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Genuine (stupid) question: I have been coding in SQL on SSMS, SAS and health data for the past 6 years, but I genuinely don't understand what a report is, and why data visualization.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13svxjp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685162272.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685155404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pardon my genuine ignorance, I have no data science background, but I somehow ended up working with EPIC Clarity for the past 6 years. In my job, I pull a sample cohort with all of the independent variables and dependent variables according to criteria, and then pass it off to a statistician to do statistics stuff.&lt;/p&gt;\n\n&lt;p&gt;I am not a statistician myself but I have general knowledge in statistics (MPH in epidemiology, so a bit less stats intensive than MS in biostats, but we learn the same things e.g. survival analysis, hazard ratios, odds ratios, logistics/linear/mixed regression, colinearity analysis, power calculations etc.), and so I just got into the job and started pulling a bunch of independent and dependent variables, and then run the predetermined statistics battery on them, and then get a final answer of a yes/no, or a statistical/predictive model, and that&amp;#39;s it.&lt;/p&gt;\n\n&lt;p&gt;I only just recently heard from other people who are data scientists or data analysts outside of my field, and I genuinely don&amp;#39;t quite understand what a &amp;quot;report&amp;quot; actually is, and also, what does data visualization really do. With that said:&lt;/p&gt;\n\n&lt;p&gt;- What is a report? Like, in data science, is a report the same thing as the results table in an academic paper? If that is the case, why do people write canned reports? I understand that people want to spot when there is a change recently, so that they can react to it, but wouldn&amp;#39;t that be just an automatic thing that is triggered once a statistics threshold is triggered? Or do people look at a table before they  consider what they want to do next?&lt;/p&gt;\n\n&lt;p&gt;- What is data visualization in data science? I get that graphs and charts are good for PR and impact, if you want to convince people but only have 3 seconds to do that. But why do people visualize data when all of the metrics&amp;#39; statistical significance are already derived? What is the data science&amp;#39;s involvement in the visualization process? Because usually I just hand the estimates with the upper and lower limits to the med students, and they can do whatever they want on their poster, be it powerpoint or Microsoft paint or tableau or an auto CAD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13svxjp", "is_robot_indexable": true, "report_reasons": null, "author": "ianng555", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13svxjp/genuine_stupid_question_i_have_been_coding_in_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13svxjp/genuine_stupid_question_i_have_been_coding_in_sql/", "subreddit_subscribers": 910663, "created_utc": 1685155404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nSome background. Have been stuck (because of visa issue) in the same position and paygrade for 4 years. My role has evolved and matured but manager basically took the advantage of me being stuck and denied any promotion. \n\nBut finally got my GC and now I am can move out.  So the question is, is there any issue if I just put my last 2 years experience out of the 4 as a senior DS? Putting all 4 years in the same position feels like I didn't really progress which isn't really true.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How bad would it be showing part of my experience as senior DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13syc66", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685163194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background. Have been stuck (because of visa issue) in the same position and paygrade for 4 years. My role has evolved and matured but manager basically took the advantage of me being stuck and denied any promotion. &lt;/p&gt;\n\n&lt;p&gt;But finally got my GC and now I am can move out.  So the question is, is there any issue if I just put my last 2 years experience out of the 4 as a senior DS? Putting all 4 years in the same position feels like I didn&amp;#39;t really progress which isn&amp;#39;t really true.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13syc66", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13syc66/how_bad_would_it_be_showing_part_of_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13syc66/how_bad_would_it_be_showing_part_of_my_experience/", "subreddit_subscribers": 910663, "created_utc": 1685163194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_55dhr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring the Physics of Moving Bodies (using Numpy + Matplotlib)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13sl8tv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3NEF7DX3KEav2jYOIKgklHNfGisUArIIOETGoyDKGcI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685126948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/macmiles/exploring-dynamic-systems", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?auto=webp&amp;v=enabled&amp;s=5bed965d365ec7f6d35bcbca593335f405996e9f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48315fbb762dad5237b7044c86d30cf733d8bdbd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1271579e634fb58bc4d35ceafb0b51f9340870c5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f01944b5308b4f90d180116146add422593580c4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e74f7b208d58784194d1157ed41b12ebcd75d64", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ac51a75cc9177321309688630a0274182193d1d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/dihWydoBPnX2ft17B6bXiPh1CUApztmK_RvV0dP5IK8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a21985e2f2088a4022bfd963479c5ab679a9e22b", "width": 1080, "height": 540}], "variants": {}, "id": "_Oaa-CJmyVPNyoWc8iJG9Ev1BweX8ZldN38Ut_C-Xes"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sl8tv", "is_robot_indexable": true, "report_reasons": null, "author": "macmiles", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sl8tv/exploring_the_physics_of_moving_bodies_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/macmiles/exploring-dynamic-systems", "subreddit_subscribers": 910663, "created_utc": 1685126948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title, I am looking for in-depth references for A/B testing.\nI am hoping for a complex situation where A/B testing is appropriately implemented as a study guide.\nAny info is appreciated!\nTiA", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Question) any A/B testing references?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sw4s1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685156036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title, I am looking for in-depth references for A/B testing.\nI am hoping for a complex situation where A/B testing is appropriately implemented as a study guide.\nAny info is appreciated!\nTiA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sw4s1", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sw4s1/question_any_ab_testing_references/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sw4s1/question_any_ab_testing_references/", "subreddit_subscribers": 910663, "created_utc": 1685156036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Our story begins roughly two years ago, our protagonist a rosy-cheeked graduate eager to move into the adult world and make his fortune by any means necessary. Through a dash of skill, sprig of determination, and a heavy pour of knowing someone on the inside through the country club, he lands a job working for a multinational corporation in their data division, and what follows is a riveting tale of friends, foes and- ah fuck it, you guys are just here for the horror stories, right?\n\nAlso, if you recognize any of these experiences I write about here, please take this chance to remind yourself that you don't, and that silence is a virtue.\n\nMy role at this collection of uninspiring brands was analyst by name, but since so many things were fundamentally broken, I ended up sliding into an underpaid and unrecognized data engineering role, designing infrastructure, tools, and tables for other people to use for last-mile analysis work. The first group I joined was with a subsidiary division of the parent company which had just been recently acquired via buyout, and while the people I worked with were wonderful and will remember for the rest of my life, their infrastructure was woefully unprepared for the kind of reporting and analytical demands placed upon them by the parent company. Their single source of truth was an Oracle database that could only be queried (despite my repeated inquests towards direct backend access) through Oracle's awful, *awful* low-code drag-and-drop Scratch-reminiscent BI interface, which stored queries as XML and had no readily available way of doing more complex row-based calculations that were often needed for our analyses. Worsening the matter, there were simply **no connectors for automated data exfiltration**, meaning **every single resultset** that needed to be used outside the database (I.E. all of them) had to be manually downloaded as an Excel file (thus immediately violating all data integrity) and loaded into your analysis toolkit of choice, which, until I joined, was Excel. \n\nMy next several months were spent devising diabolical devices within Microsoft's awful spreadsheet software, ranging from fixing a very poorly-written lift-testing tool to replacing the very same tool with a custom-written regression testing suite (again, in Excel) to hopefully impart some statistical reliability into the otherwise largely unstructured and *ahem* bespoke analyses undertaken before. Our weekly reporting wasn't automated, and every report we made each team member was assigned a block of product categories to retrieve data for, hunt through for \"interesting statistics\", and manually write up bullet points about - all to be sent in an email to mid-level management, of which I'm sure was absolutely never read in any serious capacity.\n\nEventually I was stolen away by another team, and the problems only compounded from there. From this point onwards I was working directly with the parent company's database, which thankfully was in Snowflake and allowed me to query it directly from R, which made me very happy. Despite these advances in accessibility, the data within the myriad undocumented schemas and tables proved to be even worse to deal with than the clunky, albeit relatively clean, Oracle platform. We had several different sets of poorly named and confusing customer IDs across the entire database, with each customer having several different data profiles that would often outright conflict with one another, and no guidance on which to take as truth - we even imported third party demographic data from a certain credit reporting bureau that continually had discrepancies with our first-party data, and no effort was taken to reconcile our own records against this very expensive source that we were paying dearly for. Customer order data was a mess, with item data being stored inconsistently - sometimes breaking off modifiers into their own item, sometimes not, sometimes breaking out packs into individual items, often not, and many, many other egregious design decisions. Our gift cards were handled by a third party, who due to byzantine bureaucracy refused to provide us with a data share or API, forcing one poor soul on my team to use Selenium to automatically download CSVs from their database and load it into a team table. Retention was horrible, and over the course of the year I was with this team, we went through at least 4 managers - some lost via HR action, others leaving for greener pastures from what was obviously a failing system.\n\nThings weren't all bad. The front-line people there I met were all great people, many of which I still voluntarily talk to to this day and call friends, and the company knew how to throw a party - the bartenders at the quarterly office meetings poured *very* heavily. Accomodations were nice, parking plentiful, and everybody down to the front desk receptionist got an Aeron chair, which I sorely miss to this day. However, the experience taught me several painful lessons that inevitably led to my departure:\n\n * Garbage in, garbage out.  \n * Change is asked for from the bottom, but vetoed by the top. Even if you have floors full of very, very smart analysts begging for it (we did, roughly three) and a whole lot of money to do it, ($1B+ in profit for 2021) if your boss's boss doesn't want something to happen, it won't happen. Job satisfaction is determined strongly by whether those in the position to make a change listen to those asking for a change.  \n * Do it right the first time or forever regret it.  \n * Data quality doesn't mean shit if your table and db schemas are incomprehensible.  \n * Communication is important, and a lot of pain could have been alleviated if we had just had open channels with the data engineering team. \n * Don't be surprised when the analyst you're paying like an analyst and expecting to do engineer work leaves to get paid like an engineer.  \n\nI have since found a much better job with management that (mostly) listens, but the moral of the story is this - if you're stuck in a shitty job, you want change, and management doesn't, it's almost always better to simply pack up and find somewhere that respects you than to hit your head against a rock and hope it moves. Also, fuck Excel.", "author_fullname": "t2_8weiukvu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Year of Stress and Consternation (or, How Bad Data Governance Makes Everyone Miserable, a memoir)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sts6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685148970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our story begins roughly two years ago, our protagonist a rosy-cheeked graduate eager to move into the adult world and make his fortune by any means necessary. Through a dash of skill, sprig of determination, and a heavy pour of knowing someone on the inside through the country club, he lands a job working for a multinational corporation in their data division, and what follows is a riveting tale of friends, foes and- ah fuck it, you guys are just here for the horror stories, right?&lt;/p&gt;\n\n&lt;p&gt;Also, if you recognize any of these experiences I write about here, please take this chance to remind yourself that you don&amp;#39;t, and that silence is a virtue.&lt;/p&gt;\n\n&lt;p&gt;My role at this collection of uninspiring brands was analyst by name, but since so many things were fundamentally broken, I ended up sliding into an underpaid and unrecognized data engineering role, designing infrastructure, tools, and tables for other people to use for last-mile analysis work. The first group I joined was with a subsidiary division of the parent company which had just been recently acquired via buyout, and while the people I worked with were wonderful and will remember for the rest of my life, their infrastructure was woefully unprepared for the kind of reporting and analytical demands placed upon them by the parent company. Their single source of truth was an Oracle database that could only be queried (despite my repeated inquests towards direct backend access) through Oracle&amp;#39;s awful, &lt;em&gt;awful&lt;/em&gt; low-code drag-and-drop Scratch-reminiscent BI interface, which stored queries as XML and had no readily available way of doing more complex row-based calculations that were often needed for our analyses. Worsening the matter, there were simply &lt;strong&gt;no connectors for automated data exfiltration&lt;/strong&gt;, meaning &lt;strong&gt;every single resultset&lt;/strong&gt; that needed to be used outside the database (I.E. all of them) had to be manually downloaded as an Excel file (thus immediately violating all data integrity) and loaded into your analysis toolkit of choice, which, until I joined, was Excel. &lt;/p&gt;\n\n&lt;p&gt;My next several months were spent devising diabolical devices within Microsoft&amp;#39;s awful spreadsheet software, ranging from fixing a very poorly-written lift-testing tool to replacing the very same tool with a custom-written regression testing suite (again, in Excel) to hopefully impart some statistical reliability into the otherwise largely unstructured and &lt;em&gt;ahem&lt;/em&gt; bespoke analyses undertaken before. Our weekly reporting wasn&amp;#39;t automated, and every report we made each team member was assigned a block of product categories to retrieve data for, hunt through for &amp;quot;interesting statistics&amp;quot;, and manually write up bullet points about - all to be sent in an email to mid-level management, of which I&amp;#39;m sure was absolutely never read in any serious capacity.&lt;/p&gt;\n\n&lt;p&gt;Eventually I was stolen away by another team, and the problems only compounded from there. From this point onwards I was working directly with the parent company&amp;#39;s database, which thankfully was in Snowflake and allowed me to query it directly from R, which made me very happy. Despite these advances in accessibility, the data within the myriad undocumented schemas and tables proved to be even worse to deal with than the clunky, albeit relatively clean, Oracle platform. We had several different sets of poorly named and confusing customer IDs across the entire database, with each customer having several different data profiles that would often outright conflict with one another, and no guidance on which to take as truth - we even imported third party demographic data from a certain credit reporting bureau that continually had discrepancies with our first-party data, and no effort was taken to reconcile our own records against this very expensive source that we were paying dearly for. Customer order data was a mess, with item data being stored inconsistently - sometimes breaking off modifiers into their own item, sometimes not, sometimes breaking out packs into individual items, often not, and many, many other egregious design decisions. Our gift cards were handled by a third party, who due to byzantine bureaucracy refused to provide us with a data share or API, forcing one poor soul on my team to use Selenium to automatically download CSVs from their database and load it into a team table. Retention was horrible, and over the course of the year I was with this team, we went through at least 4 managers - some lost via HR action, others leaving for greener pastures from what was obviously a failing system.&lt;/p&gt;\n\n&lt;p&gt;Things weren&amp;#39;t all bad. The front-line people there I met were all great people, many of which I still voluntarily talk to to this day and call friends, and the company knew how to throw a party - the bartenders at the quarterly office meetings poured &lt;em&gt;very&lt;/em&gt; heavily. Accomodations were nice, parking plentiful, and everybody down to the front desk receptionist got an Aeron chair, which I sorely miss to this day. However, the experience taught me several painful lessons that inevitably led to my departure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Garbage in, garbage out.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Change is asked for from the bottom, but vetoed by the top. Even if you have floors full of very, very smart analysts begging for it (we did, roughly three) and a whole lot of money to do it, ($1B+ in profit for 2021) if your boss&amp;#39;s boss doesn&amp;#39;t want something to happen, it won&amp;#39;t happen. Job satisfaction is determined strongly by whether those in the position to make a change listen to those asking for a change.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Do it right the first time or forever regret it.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Data quality doesn&amp;#39;t mean shit if your table and db schemas are incomprehensible.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Communication is important, and a lot of pain could have been alleviated if we had just had open channels with the data engineering team. &lt;/li&gt;\n&lt;li&gt;Don&amp;#39;t be surprised when the analyst you&amp;#39;re paying like an analyst and expecting to do engineer work leaves to get paid like an engineer.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have since found a much better job with management that (mostly) listens, but the moral of the story is this - if you&amp;#39;re stuck in a shitty job, you want change, and management doesn&amp;#39;t, it&amp;#39;s almost always better to simply pack up and find somewhere that respects you than to hit your head against a rock and hope it moves. Also, fuck Excel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sts6c", "is_robot_indexable": true, "report_reasons": null, "author": "whereyougoingcityboy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sts6c/my_year_of_stress_and_consternation_or_how_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sts6c/my_year_of_stress_and_consternation_or_how_bad/", "subreddit_subscribers": 910663, "created_utc": 1685148970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I  understand that they have slightly different statistical definitions,  but many times they are correlated (e.g., the higher the better the  model).\n\nWhen using them as evaluation metrics (e.g., prediction v. target), how do we pick one metric over the other?\n\nWhat are practical examples where one metric is high and one metric is low and how do we interpret that?\n\nI  understand that negative correlation will have positive coefficient of  determination, but that is intuitive and makes the coefficient of  determination useless. That is, the correlation value contains more  information already by providing a plus or minus sign.\n\nI  understand that coefficient of determination is often (incorrectly)  defined as the square of the correlation, which may be misleading to how  it relates and is different in to Pearson's correlation as well.", "author_fullname": "t2_3rlzwxv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the practical difference for Pearson's correlation and coefficient of determination as model evaluation metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sl82r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685126894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I  understand that they have slightly different statistical definitions,  but many times they are correlated (e.g., the higher the better the  model).&lt;/p&gt;\n\n&lt;p&gt;When using them as evaluation metrics (e.g., prediction v. target), how do we pick one metric over the other?&lt;/p&gt;\n\n&lt;p&gt;What are practical examples where one metric is high and one metric is low and how do we interpret that?&lt;/p&gt;\n\n&lt;p&gt;I  understand that negative correlation will have positive coefficient of  determination, but that is intuitive and makes the coefficient of  determination useless. That is, the correlation value contains more  information already by providing a plus or minus sign.&lt;/p&gt;\n\n&lt;p&gt;I  understand that coefficient of determination is often (incorrectly)  defined as the square of the correlation, which may be misleading to how  it relates and is different in to Pearson&amp;#39;s correlation as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sl82r", "is_robot_indexable": true, "report_reasons": null, "author": "milkteaoppa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sl82r/what_is_the_practical_difference_for_pearsons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sl82r/what_is_the_practical_difference_for_pearsons/", "subreddit_subscribers": 910663, "created_utc": 1685126894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "isnt the purpose to remove the noise/ clean the noise ?\n\nfor [this comment](https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;utm_medium=web2x&amp;context=3), a suggestion for dealing with too many features was: ' Add two new features that are both just random noise.  '\n\ncan someone explain why ?", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why do we add random noise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t2hl8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685178193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;isnt the purpose to remove the noise/ clean the noise ?&lt;/p&gt;\n\n&lt;p&gt;for &lt;a href=\"https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;this comment&lt;/a&gt;, a suggestion for dealing with too many features was: &amp;#39; Add two new features that are both just random noise.  &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;can someone explain why ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t2hl8", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "subreddit_subscribers": 910663, "created_utc": 1685178193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wondering how other teams have managed this. \nWe\u2019re planning to test a heuristic pricing formula against existing calculations. I imagine we will go through a few versions before we get it right.\n\nFor consistency we want customers to see the formula they saw at initial quote if they come back. E.g. customer comes on Monday and saw version 0 of the formula. A week later we\u2019re now using version 1. But this customer comes back and for consistency we want them to see version 0. \n\nMy question is where are you storing these calculations? How are they retrieved? How are they parsed into a calculation?\n\nI think docker containers are overkill for something that is a bunch of pluses and multiplications\n\nBut say they come back a week later and we have", "author_fullname": "t2_14cd9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AB testing pricing formula versioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sj0or", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685121367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering how other teams have managed this. \nWe\u2019re planning to test a heuristic pricing formula against existing calculations. I imagine we will go through a few versions before we get it right.&lt;/p&gt;\n\n&lt;p&gt;For consistency we want customers to see the formula they saw at initial quote if they come back. E.g. customer comes on Monday and saw version 0 of the formula. A week later we\u2019re now using version 1. But this customer comes back and for consistency we want them to see version 0. &lt;/p&gt;\n\n&lt;p&gt;My question is where are you storing these calculations? How are they retrieved? How are they parsed into a calculation?&lt;/p&gt;\n\n&lt;p&gt;I think docker containers are overkill for something that is a bunch of pluses and multiplications&lt;/p&gt;\n\n&lt;p&gt;But say they come back a week later and we have&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sj0or", "is_robot_indexable": true, "report_reasons": null, "author": "Dosnox", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sj0or/ab_testing_pricing_formula_versioning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sj0or/ab_testing_pricing_formula_versioning/", "subreddit_subscribers": 910663, "created_utc": 1685121367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.", "author_fullname": "t2_dt4iludq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop course from the official site.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ynq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685192665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ynq", "is_robot_indexable": true, "report_reasons": null, "author": "y3snomaybe", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "subreddit_subscribers": 910663, "created_utc": 1685192665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think, maybe we can use them as baselines?", "author_fullname": "t2_lax5ak3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use automl libraries in your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sv74x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685153131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think, maybe we can use them as baselines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sv74x", "is_robot_indexable": true, "report_reasons": null, "author": "Waste_Necessary654", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sv74x/do_you_use_automl_libraries_in_your_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sv74x/do_you_use_automl_libraries_in_your_work/", "subreddit_subscribers": 910663, "created_utc": 1685153131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking to understand how a production scenarios , mainly Ops would look like in terms of cost/magnitude of complexity, in an enterprise setting. \n\nHas anyone come across a tutorial or guide to deploy an App or similar use case using MPT-7B? What suggestions, tips or experience do OGs have? \nHOW IMPRESSED ARE YOU GUYS WITH THE  100K context Length.", "author_fullname": "t2_6mfk9l5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the easiest and way to run MPT 7B model (preferably)at full context length?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sl0jp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685126368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to understand how a production scenarios , mainly Ops would look like in terms of cost/magnitude of complexity, in an enterprise setting. &lt;/p&gt;\n\n&lt;p&gt;Has anyone come across a tutorial or guide to deploy an App or similar use case using MPT-7B? What suggestions, tips or experience do OGs have? \nHOW IMPRESSED ARE YOU GUYS WITH THE  100K context Length.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sl0jp", "is_robot_indexable": true, "report_reasons": null, "author": "swappybizz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sl0jp/what_is_the_easiest_and_way_to_run_mpt_7b_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sl0jp/what_is_the_easiest_and_way_to_run_mpt_7b_model/", "subreddit_subscribers": 910663, "created_utc": 1685126368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ever since we had access to all this LLM's I've been trying to understand what \"generalization\" means.And I think it is one of the less defined concepts across all sciences, and sometimes they are even at odds with each other.\n\nOne example is how statistics treats generalization as this principle that is true for a great portion of the subset it analyses but not all, WHILE the linguistic definition of generalization says that IF the statement is NOT TRUE for even one of the items, then it cannot be considered a generalization.\n\nSo, in statistics what gives the quality of generalization is SPECIFICALLY not encompassing the totality of the group, while in linguistics is the opposite.\n\nWhat I see, is that Cognitive sciences and ML research is tending towards the linguistic definition, since the \"Tolman-Eichenbaum Machine\" explicitly alludes to these \"building blocks\" that help in the generalization of tasks.\n\nThe idea in TEM is that: the better the generalization is at grouping truth statements, the best the extrapolation will be.\n\nAnd now we give a new dimension to the concept of generalization... \"good and bad\" generalizations... but what is the limit? At which point a generalization is so bad that it stops being a generalization??...\n\nIn sociology people run away from generalizations, but my argument is:\n\nIf a generalization offends a specific group of people, OR, if it is visibly biased against or in favor of others, then it is:\n\na) An unrefined generalization. or\n\nb) A generalization that may be true(applicable) in frameworkA, but is not entirely true(not applicable) in frameworkB.\n\nAnd if any of both, or both are the case, then THAT generalization is simply NOT a generalization under the current framework we are working on, or simply a WRONG/unrefined \"generalization\" overall and we can safely say \"sorry, that is NOT a generalization.\".", "author_fullname": "t2_joabf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I love how the concept of \"generalization\" is not generalized in itself.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sustp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685153498.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685151970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever since we had access to all this LLM&amp;#39;s I&amp;#39;ve been trying to understand what &amp;quot;generalization&amp;quot; means.And I think it is one of the less defined concepts across all sciences, and sometimes they are even at odds with each other.&lt;/p&gt;\n\n&lt;p&gt;One example is how statistics treats generalization as this principle that is true for a great portion of the subset it analyses but not all, WHILE the linguistic definition of generalization says that IF the statement is NOT TRUE for even one of the items, then it cannot be considered a generalization.&lt;/p&gt;\n\n&lt;p&gt;So, in statistics what gives the quality of generalization is SPECIFICALLY not encompassing the totality of the group, while in linguistics is the opposite.&lt;/p&gt;\n\n&lt;p&gt;What I see, is that Cognitive sciences and ML research is tending towards the linguistic definition, since the &amp;quot;Tolman-Eichenbaum Machine&amp;quot; explicitly alludes to these &amp;quot;building blocks&amp;quot; that help in the generalization of tasks.&lt;/p&gt;\n\n&lt;p&gt;The idea in TEM is that: the better the generalization is at grouping truth statements, the best the extrapolation will be.&lt;/p&gt;\n\n&lt;p&gt;And now we give a new dimension to the concept of generalization... &amp;quot;good and bad&amp;quot; generalizations... but what is the limit? At which point a generalization is so bad that it stops being a generalization??...&lt;/p&gt;\n\n&lt;p&gt;In sociology people run away from generalizations, but my argument is:&lt;/p&gt;\n\n&lt;p&gt;If a generalization offends a specific group of people, OR, if it is visibly biased against or in favor of others, then it is:&lt;/p&gt;\n\n&lt;p&gt;a) An unrefined generalization. or&lt;/p&gt;\n\n&lt;p&gt;b) A generalization that may be true(applicable) in frameworkA, but is not entirely true(not applicable) in frameworkB.&lt;/p&gt;\n\n&lt;p&gt;And if any of both, or both are the case, then THAT generalization is simply NOT a generalization under the current framework we are working on, or simply a WRONG/unrefined &amp;quot;generalization&amp;quot; overall and we can safely say &amp;quot;sorry, that is NOT a generalization.&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sustp", "is_robot_indexable": true, "report_reasons": null, "author": "DelarkArms", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sustp/i_love_how_the_concept_of_generalization_is_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sustp/i_love_how_the_concept_of_generalization_is_not/", "subreddit_subscribers": 910663, "created_utc": 1685151970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys. I had taken up a few electives in DS during my undergraduate education but there was barely anything about a/b testing. I understand that it is quite an important concept for new hires to know. And soon I\u2019ll need to start applying for DS/DA summer internships as part of my masters course. \n\nI'm just wondering how I should start learning about it or if there is any material you would recommend to get me started. :)\n\nWhat other concepts would you recommend I get started on as a potential DS/DA interviewee?\n\nThank you!", "author_fullname": "t2_mjj6ub0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to start learning about A/B testing. How should I start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13tavq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685202710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I had taken up a few electives in DS during my undergraduate education but there was barely anything about a/b testing. I understand that it is quite an important concept for new hires to know. And soon I\u2019ll need to start applying for DS/DA summer internships as part of my masters course. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just wondering how I should start learning about it or if there is any material you would recommend to get me started. :)&lt;/p&gt;\n\n&lt;p&gt;What other concepts would you recommend I get started on as a potential DS/DA interviewee?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tavq4", "is_robot_indexable": true, "report_reasons": null, "author": "National-Aioli-1586", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tavq4/i_want_to_start_learning_about_ab_testing_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tavq4/i_want_to_start_learning_about_ab_testing_how/", "subreddit_subscribers": 910663, "created_utc": 1685202710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I've been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It's been a while since I've been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.", "author_fullname": "t2_9anx9qeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources to get more domain knowledge on biotech market research?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13t9xjg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I&amp;#39;ve been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It&amp;#39;s been a while since I&amp;#39;ve been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9xjg", "is_robot_indexable": true, "report_reasons": null, "author": "sommeilhotel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "subreddit_subscribers": 910663, "created_utc": 1685200270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?", "author_fullname": "t2_1bmmkdkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to remove 1 class from dataset if it's count is very small compared to others?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13t9tot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9tot", "is_robot_indexable": true, "report_reasons": null, "author": "The_artist_999", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "subreddit_subscribers": 910663, "created_utc": 1685200000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.\n\nMain characteristics:\n\n* Like DVC and Git LFS, integrates with Git itself.\n* Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.\n* Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of \\~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.\n* Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.\n* Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.\n* Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.\n\nLinks:\n\n* [https://news.ycombinator.com/item?id=35930895](https://news.ycombinator.com/item?id=35930895)\n* \\[no full checkout\\] [https://youtu.be/BxvVdB4-Aqc](https://youtu.be/BxvVdB4-Aqc)\n* [https://news.ycombinator.com/item?id=35806843](https://news.ycombinator.com/item?id=35806843)\n* \\[general intro\\] [https://youtu.be/J0L8-uUVayM](https://youtu.be/J0L8-uUVayM)\n\nThis paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.\n\nI built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.\n\nSome background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.\n\nI look forward to constructive feedback and suggestions!", "author_fullname": "t2_9mj1ygw0w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback needed: building Git for data that commits only diffs (for storage efficiency on large repositories), even without full checkouts of the datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ecd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685191175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.&lt;/p&gt;\n\n&lt;p&gt;Main characteristics:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Like DVC and Git LFS, integrates with Git itself.&lt;/li&gt;\n&lt;li&gt;Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of ~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.&lt;/li&gt;\n&lt;li&gt;Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35930895\"&gt;https://news.ycombinator.com/item?id=35930895&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[no full checkout] &lt;a href=\"https://youtu.be/BxvVdB4-Aqc\"&gt;https://youtu.be/BxvVdB4-Aqc&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35806843\"&gt;https://news.ycombinator.com/item?id=35806843&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[general intro] &lt;a href=\"https://youtu.be/J0L8-uUVayM\"&gt;https://youtu.be/J0L8-uUVayM&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.&lt;/p&gt;\n\n&lt;p&gt;I built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.&lt;/p&gt;\n\n&lt;p&gt;Some background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.&lt;/p&gt;\n\n&lt;p&gt;I look forward to constructive feedback and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ecd", "is_robot_indexable": true, "report_reasons": null, "author": "Usual-Maize1175", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "subreddit_subscribers": 910663, "created_utc": 1685191175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi I have 5 parameters a,b,c,d,e. in a google form survey I have asked 15 users to rank those parameters from 1 to 5 based on how much importance they feel those parameters are. Now finally from that data I need to find out the ranking of those parameters. I am planning to do a mean of their ranks. But is there a better way?", "author_fullname": "t2_4lla3yc9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create final ranking of parameters from the survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t1gk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685174311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I have 5 parameters a,b,c,d,e. in a google form survey I have asked 15 users to rank those parameters from 1 to 5 based on how much importance they feel those parameters are. Now finally from that data I need to find out the ranking of those parameters. I am planning to do a mean of their ranks. But is there a better way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t1gk2", "is_robot_indexable": true, "report_reasons": null, "author": "Buffalo_Monkey98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t1gk2/how_to_create_final_ranking_of_parameters_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t1gk2/how_to_create_final_ranking_of_parameters_from/", "subreddit_subscribers": 910663, "created_utc": 1685174311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working in the HR field, particularly talent acquisition. Looking to switch to data analytics. I have completed a PG diploma in business analytics. I need someone to guide me on how to move forward in transitioning my career and also to hold me accountable.", "author_fullname": "t2_eq52y7gu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a mentor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t0so9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685171752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working in the HR field, particularly talent acquisition. Looking to switch to data analytics. I have completed a PG diploma in business analytics. I need someone to guide me on how to move forward in transitioning my career and also to hold me accountable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t0so9", "is_robot_indexable": true, "report_reasons": null, "author": "Peaceful-rebel", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t0so9/looking_for_a_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t0so9/looking_for_a_mentor/", "subreddit_subscribers": 910663, "created_utc": 1685171752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9792cqxim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does python sets are not random when there are consecutive numbers or only have values of a single data type, but random with irregular values and data types?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13szape", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685166460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13szape", "is_robot_indexable": true, "report_reasons": null, "author": "Dipanshuz1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13szape/why_does_python_sets_are_not_random_when_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13szape/why_does_python_sets_are_not_random_when_there/", "subreddit_subscribers": 910663, "created_utc": 1685166460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have not worked with time series data since I took a class on it in school. This was a few years ago and I'll be looking for a new job soon. What books, youtube series, etc. do you all prefer?", "author_fullname": "t2_4wtukxgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your favorite resources for time series and forecasting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sx4yn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685159229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not worked with time series data since I took a class on it in school. This was a few years ago and I&amp;#39;ll be looking for a new job soon. What books, youtube series, etc. do you all prefer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sx4yn", "is_robot_indexable": true, "report_reasons": null, "author": "IndependentVillage1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sx4yn/what_are_your_favorite_resources_for_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sx4yn/what_are_your_favorite_resources_for_time_series/", "subreddit_subscribers": 910663, "created_utc": 1685159229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I made my first web app for data correlation from excel file online. If it will be useful for someone (who knows) check it :https://www.corrila.com/. I'll be appreciated for any feedback)", "author_fullname": "t2_udvhhdec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My first web app for data collection)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sm6fc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1685129266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "corrila.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I made my first web app for data correlation from excel file online. If it will be useful for someone (who knows) check it :&lt;a href=\"https://www.corrila.com/\"&gt;https://www.corrila.com/&lt;/a&gt;. I&amp;#39;ll be appreciated for any feedback)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.corrila.com/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sm6fc", "is_robot_indexable": true, "report_reasons": null, "author": "PieceSea1669", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sm6fc/my_first_web_app_for_data_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.corrila.com/", "subreddit_subscribers": 910663, "created_utc": 1685129266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have come across two different programs. \n\n1st. MS in Data Analytics for $10,000 for the whole program\n\n2nd. ISOM MS degree with AI track for $30,000k total program price. \n\nI\u2019m trying to know if this program is currently with the investment right in this time and age. I do have to say the quality between these two programs are might and day. The first program they source their content from data camp. But the price so good. And the second is university owned content from a well respected school. Any thoughts?", "author_fullname": "t2_8j9z7rn7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Masters Worth the Investment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t7whi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685195105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have come across two different programs. &lt;/p&gt;\n\n&lt;p&gt;1st. MS in Data Analytics for $10,000 for the whole program&lt;/p&gt;\n\n&lt;p&gt;2nd. ISOM MS degree with AI track for $30,000k total program price. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to know if this program is currently with the investment right in this time and age. I do have to say the quality between these two programs are might and day. The first program they source their content from data camp. But the price so good. And the second is university owned content from a well respected school. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t7whi", "is_robot_indexable": true, "report_reasons": null, "author": "Humble-Relative8291", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t7whi/is_a_masters_worth_the_investment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t7whi/is_a_masters_worth_the_investment/", "subreddit_subscribers": 910663, "created_utc": 1685195105.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}