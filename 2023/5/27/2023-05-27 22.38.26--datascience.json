{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ap0s21sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Minimum 7 years exp the field and expertise in NLP for 70k-80k CAD contract job. This country and the market is a joke. Look at the JD. It\u2019s even comical.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"24iqz18wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75b252b7f11784e97c5d8ea34254fd561beda357"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bc2ffd25d826b757eb4c8164e92c1c47ef9a117"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=333bc670feb252698ba1132e2be26f5016fa0ff9"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c288dbc6bdbfd4060e18a76bddf80747ac7019f4"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31aeb900d56df4f3937583b66c4a09756c3e2f9e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20c4720e79337e40d28b1d8bdf9ccd9fe4413d4c"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/24iqz18wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4826cdc38fb49904304911cae96ba9a8804e9f62"}, "id": "24iqz18wud2b1"}, "y41h498wud2b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3843dec749dab6d30d514b5cc7afa5aa1f2c0260"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=578aca1af2cbf1ca42804f592712d9f70a951692"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=593d63dde06a5e5585200d6d3ae090751745203b"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b431334d411d2715b80eee85678bbad928ae922"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8310115d2cd1304c9b7650d6c5474dd2673fc16e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77de997b9864d5949745c662b2f04bbe3150683a"}], "s": {"y": 2436, "x": 1125, "u": "https://preview.redd.it/y41h498wud2b1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=543c5c761a4d64d99fc88f5530b39315043d56bc"}, "id": "y41h498wud2b1"}}, "name": "t3_13t8q2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 179, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "y41h498wud2b1", "id": 280365940}, {"media_id": "24iqz18wud2b1", "id": 280365941}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 179, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cnh8ZhdS2yjJETGCxh-kC9waEuTXS1W3rjRfmwdzhFM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685197178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13t8q2x", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "13t8q2x", "is_robot_indexable": true, "report_reasons": null, "author": "hootandahalf_", "discussion_type": null, "num_comments": 116, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t8q2x/minimum_7_years_exp_the_field_and_expertise_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13t8q2x", "subreddit_subscribers": 910895, "created_utc": 1685197178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pardon my genuine ignorance, I have no data science background, but I somehow ended up working with EPIC Clarity for the past 6 years. In my job, I pull a sample cohort with all of the independent variables and dependent variables according to criteria, and then pass it off to a statistician to do statistics stuff.\n\nI am not a statistician myself but I have general knowledge in statistics (MPH in epidemiology, so a bit less stats intensive than MS in biostats, but we learn the same things e.g. survival analysis, hazard ratios, odds ratios, logistics/linear/mixed regression, colinearity analysis, power calculations etc.), and so I just got into the job and started pulling a bunch of independent and dependent variables, and then run the predetermined statistics battery on them, and then get a final answer of a yes/no, or a statistical/predictive model, and that's it.\n\nI only just recently heard from other people who are data scientists or data analysts outside of my field, and I genuinely don't quite understand what a \"report\" actually is, and also, what does data visualization really do. With that said:\n\n\\- What is a report? Like, in data science, is a report the same thing as the results table in an academic paper? If that is the case, why do people write canned reports? I understand that people want to spot when there is a change recently, so that they can react to it, but wouldn't that be just an automatic thing that is triggered once a statistics threshold is triggered? Or do people look at a table before they  consider what they want to do next?\n\n\\- What is data visualization in data science? I get that graphs and charts are good for PR and impact, if you want to convince people but only have 3 seconds to do that. But why do people visualize data when all of the metrics' statistical significance are already derived? What is the data science's involvement in the visualization process? Because usually I just hand the estimates with the upper and lower limits to the med students, and they can do whatever they want on their poster, be it powerpoint or Microsoft paint or tableau or an auto CAD.", "author_fullname": "t2_3sb0qyjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Genuine (stupid) question: I have been coding in SQL on SSMS, SAS and health data for the past 6 years, but I genuinely don't understand what a report is, and why data visualization.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13svxjp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685162272.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685155404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pardon my genuine ignorance, I have no data science background, but I somehow ended up working with EPIC Clarity for the past 6 years. In my job, I pull a sample cohort with all of the independent variables and dependent variables according to criteria, and then pass it off to a statistician to do statistics stuff.&lt;/p&gt;\n\n&lt;p&gt;I am not a statistician myself but I have general knowledge in statistics (MPH in epidemiology, so a bit less stats intensive than MS in biostats, but we learn the same things e.g. survival analysis, hazard ratios, odds ratios, logistics/linear/mixed regression, colinearity analysis, power calculations etc.), and so I just got into the job and started pulling a bunch of independent and dependent variables, and then run the predetermined statistics battery on them, and then get a final answer of a yes/no, or a statistical/predictive model, and that&amp;#39;s it.&lt;/p&gt;\n\n&lt;p&gt;I only just recently heard from other people who are data scientists or data analysts outside of my field, and I genuinely don&amp;#39;t quite understand what a &amp;quot;report&amp;quot; actually is, and also, what does data visualization really do. With that said:&lt;/p&gt;\n\n&lt;p&gt;- What is a report? Like, in data science, is a report the same thing as the results table in an academic paper? If that is the case, why do people write canned reports? I understand that people want to spot when there is a change recently, so that they can react to it, but wouldn&amp;#39;t that be just an automatic thing that is triggered once a statistics threshold is triggered? Or do people look at a table before they  consider what they want to do next?&lt;/p&gt;\n\n&lt;p&gt;- What is data visualization in data science? I get that graphs and charts are good for PR and impact, if you want to convince people but only have 3 seconds to do that. But why do people visualize data when all of the metrics&amp;#39; statistical significance are already derived? What is the data science&amp;#39;s involvement in the visualization process? Because usually I just hand the estimates with the upper and lower limits to the med students, and they can do whatever they want on their poster, be it powerpoint or Microsoft paint or tableau or an auto CAD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13svxjp", "is_robot_indexable": true, "report_reasons": null, "author": "ianng555", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13svxjp/genuine_stupid_question_i_have_been_coding_in_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13svxjp/genuine_stupid_question_i_have_been_coding_in_sql/", "subreddit_subscribers": 910895, "created_utc": 1685155404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m having a discussion soon with the head of data science within my company about opportunities on the team. I have no clue if it will actually happen or not but I\u2019m curious\u2014 is it common/customary to experience a salary change when changing teams? Or does every company do it differently? I\u2019m quite certain I make less than data scientists in my company and my current team is a completely different department from this new one.", "author_fullname": "t2_5bg0t3mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common to change salaries when transitioning internally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ssa2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685144840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m having a discussion soon with the head of data science within my company about opportunities on the team. I have no clue if it will actually happen or not but I\u2019m curious\u2014 is it common/customary to experience a salary change when changing teams? Or does every company do it differently? I\u2019m quite certain I make less than data scientists in my company and my current team is a completely different department from this new one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ssa2x", "is_robot_indexable": true, "report_reasons": null, "author": "ThrowRA-11789", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ssa2x/is_it_common_to_change_salaries_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ssa2x/is_it_common_to_change_salaries_when/", "subreddit_subscribers": 910895, "created_utc": 1685144840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nSome background. Have been stuck (because of visa issue) in the same position and paygrade for 4 years. My role has evolved and matured but manager basically took the advantage of me being stuck and denied any promotion. \n\nBut finally got my GC and now I am can move out.  So the question is, is there any issue if I just put my last 2 years experience out of the 4 as a senior DS? Putting all 4 years in the same position feels like I didn't really progress which isn't really true.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How bad would it be showing part of my experience as senior DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13syc66", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685163194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background. Have been stuck (because of visa issue) in the same position and paygrade for 4 years. My role has evolved and matured but manager basically took the advantage of me being stuck and denied any promotion. &lt;/p&gt;\n\n&lt;p&gt;But finally got my GC and now I am can move out.  So the question is, is there any issue if I just put my last 2 years experience out of the 4 as a senior DS? Putting all 4 years in the same position feels like I didn&amp;#39;t really progress which isn&amp;#39;t really true.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13syc66", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13syc66/how_bad_would_it_be_showing_part_of_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13syc66/how_bad_would_it_be_showing_part_of_my_experience/", "subreddit_subscribers": 910895, "created_utc": 1685163194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "isnt the purpose to remove the noise/ clean the noise ?\n\nfor [this comment](https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;utm_medium=web2x&amp;context=3), a suggestion for dealing with too many features was: ' Add two new features that are both just random noise.  '\n\ncan someone explain why ?", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why do we add random noise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t2hl8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685178193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;isnt the purpose to remove the noise/ clean the noise ?&lt;/p&gt;\n\n&lt;p&gt;for &lt;a href=\"https://www.reddit.com/r/datascience/comments/13rp23u/comment/jlne1ez/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;this comment&lt;/a&gt;, a suggestion for dealing with too many features was: &amp;#39; Add two new features that are both just random noise.  &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;can someone explain why ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t2hl8", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t2hl8/why_do_we_add_random_noise/", "subreddit_subscribers": 910895, "created_utc": 1685178193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Our story begins roughly two years ago, our protagonist a rosy-cheeked graduate eager to move into the adult world and make his fortune by any means necessary. Through a dash of skill, sprig of determination, and a heavy pour of knowing someone on the inside through the country club, he lands a job working for a multinational corporation in their data division, and what follows is a riveting tale of friends, foes and- ah fuck it, you guys are just here for the horror stories, right?\n\nAlso, if you recognize any of these experiences I write about here, please take this chance to remind yourself that you don't, and that silence is a virtue.\n\nMy role at this collection of uninspiring brands was analyst by name, but since so many things were fundamentally broken, I ended up sliding into an underpaid and unrecognized data engineering role, designing infrastructure, tools, and tables for other people to use for last-mile analysis work. The first group I joined was with a subsidiary division of the parent company which had just been recently acquired via buyout, and while the people I worked with were wonderful and will remember for the rest of my life, their infrastructure was woefully unprepared for the kind of reporting and analytical demands placed upon them by the parent company. Their single source of truth was an Oracle database that could only be queried (despite my repeated inquests towards direct backend access) through Oracle's awful, *awful* low-code drag-and-drop Scratch-reminiscent BI interface, which stored queries as XML and had no readily available way of doing more complex row-based calculations that were often needed for our analyses. Worsening the matter, there were simply **no connectors for automated data exfiltration**, meaning **every single resultset** that needed to be used outside the database (I.E. all of them) had to be manually downloaded as an Excel file (thus immediately violating all data integrity) and loaded into your analysis toolkit of choice, which, until I joined, was Excel. \n\nMy next several months were spent devising diabolical devices within Microsoft's awful spreadsheet software, ranging from fixing a very poorly-written lift-testing tool to replacing the very same tool with a custom-written regression testing suite (again, in Excel) to hopefully impart some statistical reliability into the otherwise largely unstructured and *ahem* bespoke analyses undertaken before. Our weekly reporting wasn't automated, and every report we made each team member was assigned a block of product categories to retrieve data for, hunt through for \"interesting statistics\", and manually write up bullet points about - all to be sent in an email to mid-level management, of which I'm sure was absolutely never read in any serious capacity.\n\nEventually I was stolen away by another team, and the problems only compounded from there. From this point onwards I was working directly with the parent company's database, which thankfully was in Snowflake and allowed me to query it directly from R, which made me very happy. Despite these advances in accessibility, the data within the myriad undocumented schemas and tables proved to be even worse to deal with than the clunky, albeit relatively clean, Oracle platform. We had several different sets of poorly named and confusing customer IDs across the entire database, with each customer having several different data profiles that would often outright conflict with one another, and no guidance on which to take as truth - we even imported third party demographic data from a certain credit reporting bureau that continually had discrepancies with our first-party data, and no effort was taken to reconcile our own records against this very expensive source that we were paying dearly for. Customer order data was a mess, with item data being stored inconsistently - sometimes breaking off modifiers into their own item, sometimes not, sometimes breaking out packs into individual items, often not, and many, many other egregious design decisions. Our gift cards were handled by a third party, who due to byzantine bureaucracy refused to provide us with a data share or API, forcing one poor soul on my team to use Selenium to automatically download CSVs from their database and load it into a team table. Retention was horrible, and over the course of the year I was with this team, we went through at least 4 managers - some lost via HR action, others leaving for greener pastures from what was obviously a failing system.\n\nThings weren't all bad. The front-line people there I met were all great people, many of which I still voluntarily talk to to this day and call friends, and the company knew how to throw a party - the bartenders at the quarterly office meetings poured *very* heavily. Accomodations were nice, parking plentiful, and everybody down to the front desk receptionist got an Aeron chair, which I sorely miss to this day. However, the experience taught me several painful lessons that inevitably led to my departure:\n\n * Garbage in, garbage out.  \n * Change is asked for from the bottom, but vetoed by the top. Even if you have floors full of very, very smart analysts begging for it (we did, roughly three) and a whole lot of money to do it, ($1B+ in profit for 2021) if your boss's boss doesn't want something to happen, it won't happen. Job satisfaction is determined strongly by whether those in the position to make a change listen to those asking for a change.  \n * Do it right the first time or forever regret it.  \n * Data quality doesn't mean shit if your table and db schemas are incomprehensible.  \n * Communication is important, and a lot of pain could have been alleviated if we had just had open channels with the data engineering team. \n * Don't be surprised when the analyst you're paying like an analyst and expecting to do engineer work leaves to get paid like an engineer.  \n\nI have since found a much better job with management that (mostly) listens, but the moral of the story is this - if you're stuck in a shitty job, you want change, and management doesn't, it's almost always better to simply pack up and find somewhere that respects you than to hit your head against a rock and hope it moves. Also, fuck Excel.", "author_fullname": "t2_8weiukvu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Year of Stress and Consternation (or, How Bad Data Governance Makes Everyone Miserable, a memoir)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sts6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685148970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our story begins roughly two years ago, our protagonist a rosy-cheeked graduate eager to move into the adult world and make his fortune by any means necessary. Through a dash of skill, sprig of determination, and a heavy pour of knowing someone on the inside through the country club, he lands a job working for a multinational corporation in their data division, and what follows is a riveting tale of friends, foes and- ah fuck it, you guys are just here for the horror stories, right?&lt;/p&gt;\n\n&lt;p&gt;Also, if you recognize any of these experiences I write about here, please take this chance to remind yourself that you don&amp;#39;t, and that silence is a virtue.&lt;/p&gt;\n\n&lt;p&gt;My role at this collection of uninspiring brands was analyst by name, but since so many things were fundamentally broken, I ended up sliding into an underpaid and unrecognized data engineering role, designing infrastructure, tools, and tables for other people to use for last-mile analysis work. The first group I joined was with a subsidiary division of the parent company which had just been recently acquired via buyout, and while the people I worked with were wonderful and will remember for the rest of my life, their infrastructure was woefully unprepared for the kind of reporting and analytical demands placed upon them by the parent company. Their single source of truth was an Oracle database that could only be queried (despite my repeated inquests towards direct backend access) through Oracle&amp;#39;s awful, &lt;em&gt;awful&lt;/em&gt; low-code drag-and-drop Scratch-reminiscent BI interface, which stored queries as XML and had no readily available way of doing more complex row-based calculations that were often needed for our analyses. Worsening the matter, there were simply &lt;strong&gt;no connectors for automated data exfiltration&lt;/strong&gt;, meaning &lt;strong&gt;every single resultset&lt;/strong&gt; that needed to be used outside the database (I.E. all of them) had to be manually downloaded as an Excel file (thus immediately violating all data integrity) and loaded into your analysis toolkit of choice, which, until I joined, was Excel. &lt;/p&gt;\n\n&lt;p&gt;My next several months were spent devising diabolical devices within Microsoft&amp;#39;s awful spreadsheet software, ranging from fixing a very poorly-written lift-testing tool to replacing the very same tool with a custom-written regression testing suite (again, in Excel) to hopefully impart some statistical reliability into the otherwise largely unstructured and &lt;em&gt;ahem&lt;/em&gt; bespoke analyses undertaken before. Our weekly reporting wasn&amp;#39;t automated, and every report we made each team member was assigned a block of product categories to retrieve data for, hunt through for &amp;quot;interesting statistics&amp;quot;, and manually write up bullet points about - all to be sent in an email to mid-level management, of which I&amp;#39;m sure was absolutely never read in any serious capacity.&lt;/p&gt;\n\n&lt;p&gt;Eventually I was stolen away by another team, and the problems only compounded from there. From this point onwards I was working directly with the parent company&amp;#39;s database, which thankfully was in Snowflake and allowed me to query it directly from R, which made me very happy. Despite these advances in accessibility, the data within the myriad undocumented schemas and tables proved to be even worse to deal with than the clunky, albeit relatively clean, Oracle platform. We had several different sets of poorly named and confusing customer IDs across the entire database, with each customer having several different data profiles that would often outright conflict with one another, and no guidance on which to take as truth - we even imported third party demographic data from a certain credit reporting bureau that continually had discrepancies with our first-party data, and no effort was taken to reconcile our own records against this very expensive source that we were paying dearly for. Customer order data was a mess, with item data being stored inconsistently - sometimes breaking off modifiers into their own item, sometimes not, sometimes breaking out packs into individual items, often not, and many, many other egregious design decisions. Our gift cards were handled by a third party, who due to byzantine bureaucracy refused to provide us with a data share or API, forcing one poor soul on my team to use Selenium to automatically download CSVs from their database and load it into a team table. Retention was horrible, and over the course of the year I was with this team, we went through at least 4 managers - some lost via HR action, others leaving for greener pastures from what was obviously a failing system.&lt;/p&gt;\n\n&lt;p&gt;Things weren&amp;#39;t all bad. The front-line people there I met were all great people, many of which I still voluntarily talk to to this day and call friends, and the company knew how to throw a party - the bartenders at the quarterly office meetings poured &lt;em&gt;very&lt;/em&gt; heavily. Accomodations were nice, parking plentiful, and everybody down to the front desk receptionist got an Aeron chair, which I sorely miss to this day. However, the experience taught me several painful lessons that inevitably led to my departure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Garbage in, garbage out.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Change is asked for from the bottom, but vetoed by the top. Even if you have floors full of very, very smart analysts begging for it (we did, roughly three) and a whole lot of money to do it, ($1B+ in profit for 2021) if your boss&amp;#39;s boss doesn&amp;#39;t want something to happen, it won&amp;#39;t happen. Job satisfaction is determined strongly by whether those in the position to make a change listen to those asking for a change.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Do it right the first time or forever regret it.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Data quality doesn&amp;#39;t mean shit if your table and db schemas are incomprehensible.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Communication is important, and a lot of pain could have been alleviated if we had just had open channels with the data engineering team. &lt;/li&gt;\n&lt;li&gt;Don&amp;#39;t be surprised when the analyst you&amp;#39;re paying like an analyst and expecting to do engineer work leaves to get paid like an engineer.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have since found a much better job with management that (mostly) listens, but the moral of the story is this - if you&amp;#39;re stuck in a shitty job, you want change, and management doesn&amp;#39;t, it&amp;#39;s almost always better to simply pack up and find somewhere that respects you than to hit your head against a rock and hope it moves. Also, fuck Excel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sts6c", "is_robot_indexable": true, "report_reasons": null, "author": "whereyougoingcityboy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sts6c/my_year_of_stress_and_consternation_or_how_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sts6c/my_year_of_stress_and_consternation_or_how_bad/", "subreddit_subscribers": 910895, "created_utc": 1685148970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title, I am looking for in-depth references for A/B testing.\nI am hoping for a complex situation where A/B testing is appropriately implemented as a study guide.\nAny info is appreciated!\nTiA", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Question) any A/B testing references?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sw4s1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685156036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title, I am looking for in-depth references for A/B testing.\nI am hoping for a complex situation where A/B testing is appropriately implemented as a study guide.\nAny info is appreciated!\nTiA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sw4s1", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sw4s1/question_any_ab_testing_references/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sw4s1/question_any_ab_testing_references/", "subreddit_subscribers": 910895, "created_utc": 1685156036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.", "author_fullname": "t2_dt4iludq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop course from the official site.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ynq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685192665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I wanted to check if anyone has taken the Apache Hadoop course from the official website of Hadoop (hadoop dot training). My employers wants me to take this course and get certified. Fully reimbursed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ynq", "is_robot_indexable": true, "report_reasons": null, "author": "y3snomaybe", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ynq/hadoop_course_from_the_official_site/", "subreddit_subscribers": 910895, "created_utc": 1685192665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think, maybe we can use them as baselines?", "author_fullname": "t2_lax5ak3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use automl libraries in your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sv74x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685153131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think, maybe we can use them as baselines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sv74x", "is_robot_indexable": true, "report_reasons": null, "author": "Waste_Necessary654", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sv74x/do_you_use_automl_libraries_in_your_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sv74x/do_you_use_automl_libraries_in_your_work/", "subreddit_subscribers": 910895, "created_utc": 1685153131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I've been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It's been a while since I've been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.", "author_fullname": "t2_9anx9qeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources to get more domain knowledge on biotech market research?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t9xjg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is mostly for any DA/DS who have been working in market research for biotech, pharmaceutical industries. I&amp;#39;ve been applying for jobs in these areas because I have a BS in general bio, and my MA is in social research and data analysis. It&amp;#39;s been a while since I&amp;#39;ve been involved in anything bio-related, so I wanted to know what the best resources are for learning about biotech and pharmaceutical market research.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9xjg", "is_robot_indexable": true, "report_reasons": null, "author": "sommeilhotel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9xjg/good_resources_to_get_more_domain_knowledge_on/", "subreddit_subscribers": 910895, "created_utc": 1685200270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ever since we had access to all this LLM's I've been trying to understand what \"generalization\" means.And I think it is one of the less defined concepts across all sciences, and sometimes they are even at odds with each other.\n\nOne example is how statistics treats generalization as this principle that is true for a great portion of the subset it analyses but not all, WHILE the linguistic definition of generalization says that IF the statement is NOT TRUE for even one of the items, then it cannot be considered a generalization.\n\nSo, in statistics what gives the quality of generalization is SPECIFICALLY not encompassing the totality of the group, while in linguistics is the opposite.\n\nWhat I see, is that Cognitive sciences and ML research is tending towards the linguistic definition, since the \"Tolman-Eichenbaum Machine\" explicitly alludes to these \"building blocks\" that help in the generalization of tasks.\n\nThe idea in TEM is that: the better the generalization is at grouping truth statements, the best the extrapolation will be.\n\nAnd now we give a new dimension to the concept of generalization... \"good and bad\" generalizations... but what is the limit? At which point a generalization is so bad that it stops being a generalization??...\n\nIn sociology people run away from generalizations, but my argument is:\n\nIf a generalization offends a specific group of people, OR, if it is visibly biased against or in favor of others, then it is:\n\na) An unrefined generalization. or\n\nb) A generalization that may be true(applicable) in frameworkA, but is not entirely true(not applicable) in frameworkB.\n\nAnd if any of both, or both are the case, then THAT generalization is simply NOT a generalization under the current framework we are working on, or simply a WRONG/unrefined \"generalization\" overall and we can safely say \"sorry, that is NOT a generalization.\".", "author_fullname": "t2_joabf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I love how the concept of \"generalization\" is not generalized in itself.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sustp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685153498.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685151970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever since we had access to all this LLM&amp;#39;s I&amp;#39;ve been trying to understand what &amp;quot;generalization&amp;quot; means.And I think it is one of the less defined concepts across all sciences, and sometimes they are even at odds with each other.&lt;/p&gt;\n\n&lt;p&gt;One example is how statistics treats generalization as this principle that is true for a great portion of the subset it analyses but not all, WHILE the linguistic definition of generalization says that IF the statement is NOT TRUE for even one of the items, then it cannot be considered a generalization.&lt;/p&gt;\n\n&lt;p&gt;So, in statistics what gives the quality of generalization is SPECIFICALLY not encompassing the totality of the group, while in linguistics is the opposite.&lt;/p&gt;\n\n&lt;p&gt;What I see, is that Cognitive sciences and ML research is tending towards the linguistic definition, since the &amp;quot;Tolman-Eichenbaum Machine&amp;quot; explicitly alludes to these &amp;quot;building blocks&amp;quot; that help in the generalization of tasks.&lt;/p&gt;\n\n&lt;p&gt;The idea in TEM is that: the better the generalization is at grouping truth statements, the best the extrapolation will be.&lt;/p&gt;\n\n&lt;p&gt;And now we give a new dimension to the concept of generalization... &amp;quot;good and bad&amp;quot; generalizations... but what is the limit? At which point a generalization is so bad that it stops being a generalization??...&lt;/p&gt;\n\n&lt;p&gt;In sociology people run away from generalizations, but my argument is:&lt;/p&gt;\n\n&lt;p&gt;If a generalization offends a specific group of people, OR, if it is visibly biased against or in favor of others, then it is:&lt;/p&gt;\n\n&lt;p&gt;a) An unrefined generalization. or&lt;/p&gt;\n\n&lt;p&gt;b) A generalization that may be true(applicable) in frameworkA, but is not entirely true(not applicable) in frameworkB.&lt;/p&gt;\n\n&lt;p&gt;And if any of both, or both are the case, then THAT generalization is simply NOT a generalization under the current framework we are working on, or simply a WRONG/unrefined &amp;quot;generalization&amp;quot; overall and we can safely say &amp;quot;sorry, that is NOT a generalization.&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sustp", "is_robot_indexable": true, "report_reasons": null, "author": "DelarkArms", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sustp/i_love_how_the_concept_of_generalization_is_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sustp/i_love_how_the_concept_of_generalization_is_not/", "subreddit_subscribers": 910895, "created_utc": 1685151970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI am involved in a data migration project. It is migrating from SAP to a newer version of SAP. I was notified we can choose what tool to use for analysis and I am wondering if anyone has suggestions. I am obviously overthinking this. Maybe some tools just aren't relevant for the project but I do want to learn more software as this is my first official role in data and I want to grow professionally. I do realize that to be a great data scientist, it's not just about having the right tools although that doesn't hurt.\n\n I am primarily interested in R, Python, SQL, and probably some HDFS for big data. I think I installed Hadoop correctly but probably need to learn how to run it. I used a different HDFS for a DS certificate I took. We used Hortonworks data platform for uploading and downloading files into Hadoop file system.\n\nI installed RStudio. I have Anaconda and that's got Spyder and Pycharm. I wanted to have the key Python packages like numpy and scikit-learn, tensorflow etc. I was watching some videos that suggested using Visual Studio Code. Tensorflow doesn't seem to be working on my Anaconda and not sure if it's due to security blocking access to downloading certain files.\n\nI tried installing RStudio on Anaconda but it was problematic and threads I've seen on Reddit say that using RStudio on Anaconda is a nightmare. Also read that Anaconda doesn't have the most recent version of it as well.\n\nMonths ago a colleague gave some installations so I have Postman and DBVisualizer installed (haven't used them yet). I think DBVisualizer should be sufficient for running SQL code but have read people suggesting other tools. I've used online compilers so have used postgresql.\n\nWhat do people use in their work and what would you want to use at your work?", "author_fullname": "t2_11ph6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for Open Source Tools to Use for Data Migration &amp; Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tfz9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685215732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am involved in a data migration project. It is migrating from SAP to a newer version of SAP. I was notified we can choose what tool to use for analysis and I am wondering if anyone has suggestions. I am obviously overthinking this. Maybe some tools just aren&amp;#39;t relevant for the project but I do want to learn more software as this is my first official role in data and I want to grow professionally. I do realize that to be a great data scientist, it&amp;#39;s not just about having the right tools although that doesn&amp;#39;t hurt.&lt;/p&gt;\n\n&lt;p&gt;I am primarily interested in R, Python, SQL, and probably some HDFS for big data. I think I installed Hadoop correctly but probably need to learn how to run it. I used a different HDFS for a DS certificate I took. We used Hortonworks data platform for uploading and downloading files into Hadoop file system.&lt;/p&gt;\n\n&lt;p&gt;I installed RStudio. I have Anaconda and that&amp;#39;s got Spyder and Pycharm. I wanted to have the key Python packages like numpy and scikit-learn, tensorflow etc. I was watching some videos that suggested using Visual Studio Code. Tensorflow doesn&amp;#39;t seem to be working on my Anaconda and not sure if it&amp;#39;s due to security blocking access to downloading certain files.&lt;/p&gt;\n\n&lt;p&gt;I tried installing RStudio on Anaconda but it was problematic and threads I&amp;#39;ve seen on Reddit say that using RStudio on Anaconda is a nightmare. Also read that Anaconda doesn&amp;#39;t have the most recent version of it as well.&lt;/p&gt;\n\n&lt;p&gt;Months ago a colleague gave some installations so I have Postman and DBVisualizer installed (haven&amp;#39;t used them yet). I think DBVisualizer should be sufficient for running SQL code but have read people suggesting other tools. I&amp;#39;ve used online compilers so have used postgresql.&lt;/p&gt;\n\n&lt;p&gt;What do people use in their work and what would you want to use at your work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tfz9k", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalDocSpock", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tfz9k/recommendations_for_open_source_tools_to_use_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tfz9k/recommendations_for_open_source_tools_to_use_for/", "subreddit_subscribers": 910895, "created_utc": 1685215732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?", "author_fullname": "t2_1bmmkdkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to remove 1 class from dataset if it's count is very small compared to others?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t9tot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685200000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset with 3 classes. Class 1 and 2 have over 1500 data in them each and the third class is exactly 1 data. Is it ok to remove the 3rd class?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t9tot", "is_robot_indexable": true, "report_reasons": null, "author": "The_artist_999", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t9tot/is_it_ok_to_remove_1_class_from_dataset_if_its/", "subreddit_subscribers": 910895, "created_utc": 1685200000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.\n\nMain characteristics:\n\n* Like DVC and Git LFS, integrates with Git itself.\n* Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.\n* Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of \\~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.\n* Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.\n* Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.\n* Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.\n\nLinks:\n\n* [https://news.ycombinator.com/item?id=35930895](https://news.ycombinator.com/item?id=35930895)\n* \\[no full checkout\\] [https://youtu.be/BxvVdB4-Aqc](https://youtu.be/BxvVdB4-Aqc)\n* [https://news.ycombinator.com/item?id=35806843](https://news.ycombinator.com/item?id=35806843)\n* \\[general intro\\] [https://youtu.be/J0L8-uUVayM](https://youtu.be/J0L8-uUVayM)\n\nThis paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.\n\nI built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.\n\nSome background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.\n\nI look forward to constructive feedback and suggestions!", "author_fullname": "t2_9mj1ygw0w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback needed: building Git for data that commits only diffs (for storage efficiency on large repositories), even without full checkouts of the datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t6ecd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685191175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would really appreciate feedback on a version control for tabular datasets I am building, the Data Manager.&lt;/p&gt;\n\n&lt;p&gt;Main characteristics:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Like DVC and Git LFS, integrates with Git itself.&lt;/li&gt;\n&lt;li&gt;Like DVC and Git LFS, can store large files on AWS S3 and link them in Git via an identifier.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, calculates and commits diffs only, at row, column, and cell level. For append scenarios, the commit will include new data only; for edits and deletes, a small diff is committed accordingly. With DVC and Git LFS, the entire dataset is committed again, instead: committing 1 MB of new data 1000 times to a 1 GB dataset yields more than 1 TB in DVC (a dataset that increases linearly in size between 1 GB and 2 GB, committed 1000 times, results in a repository of ~1.5 TB), whereas it sums to 2 GB (1 GB original dataset, plus 1000 times 1 MB changes) with the Data Manager.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the diffs for each commit remain visible directly in Git.&lt;/li&gt;\n&lt;li&gt;Unlike DVC and Git LFS, the Data Manager allows committing changes to datasets without full checkouts on localhost. You check out kilobytes and can append data to a dataset in a repository of hundreds of gigabytes. The changes on a no-full-checkout branch will need to be merged into another branch (on a machine that does operate with full checkouts, instead) to be validated, e.g., against adding a primary key that already exists.&lt;/li&gt;\n&lt;li&gt;Since the repositories will contain diff histories, snapshots of the datasets at a certain commit have to be recreated to be deployable. These can be automatically uploaded to S3 and labeled after the commit hash, via the Data Manager.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35930895\"&gt;https://news.ycombinator.com/item?id=35930895&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[no full checkout] &lt;a href=\"https://youtu.be/BxvVdB4-Aqc\"&gt;https://youtu.be/BxvVdB4-Aqc&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://news.ycombinator.com/item?id=35806843\"&gt;https://news.ycombinator.com/item?id=35806843&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;[general intro] &lt;a href=\"https://youtu.be/J0L8-uUVayM\"&gt;https://youtu.be/J0L8-uUVayM&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This paradigm enables hibernating or cleaning up history on S3 for old datasets, if these are deleted in Git and snapshots of earlier commits are no longer needed. Individual data entries can also be removed for GDPR compliance using versioning on S3 objects, orthogonal to git.&lt;/p&gt;\n\n&lt;p&gt;I built the Data Manager for a pain point I was experiencing: it was impossible to (1) uniquely identify and (2) make available behind an API multiple versions of a collection of datasets and config parameters, (3) without overburdening HDDs due to small, but frequent changes to any of the datasets in the repo and (4) while being able to see the diffs in git for each commit in order to enable collaborative discussions and reverting or further editing if necessary.&lt;/p&gt;\n\n&lt;p&gt;Some background: I am building natural language AI algorithms (a) easily retrainable on editable training datasets, meaning changes or deletions in the training data are reflected fast, without traces of past training and without retraining the entire language model (sounds impossible), and (b) that explain decisions back to individual training data.&lt;/p&gt;\n\n&lt;p&gt;I look forward to constructive feedback and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t6ecd", "is_robot_indexable": true, "report_reasons": null, "author": "Usual-Maize1175", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t6ecd/feedback_needed_building_git_for_data_that/", "subreddit_subscribers": 910895, "created_utc": 1685191175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have not worked with time series data since I took a class on it in school. This was a few years ago and I'll be looking for a new job soon. What books, youtube series, etc. do you all prefer?", "author_fullname": "t2_4wtukxgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your favorite resources for time series and forecasting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sx4yn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685159229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not worked with time series data since I took a class on it in school. This was a few years ago and I&amp;#39;ll be looking for a new job soon. What books, youtube series, etc. do you all prefer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sx4yn", "is_robot_indexable": true, "report_reasons": null, "author": "IndependentVillage1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sx4yn/what_are_your_favorite_resources_for_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sx4yn/what_are_your_favorite_resources_for_time_series/", "subreddit_subscribers": 910895, "created_utc": 1685159229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,   \n\n\nI'm a currently a data science student, and my professor has tasked my class to do some machine learning projects.   \n\n\nI guess it's fairly straightforward. Get a dataset, preprocess it, and make a prediction.   \n\n\nThe challenge is, the dataset size must be atleast 50Gb(gigabytes) and must be uploaded into an AWS S3 bucket and processed using the AWS EMR on EC2 clusters.   \n\n\n  \nI've been looking around the AWS data store and it's mostly biotech and geo science data.   \n\n\nI was wondering if any one knows of where I can find ones in the finance or business setting kind of data.   \n\n\nAny suggestions or advice will be greatly appreciated.   \nThank you!", "author_fullname": "t2_15cnt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset sources for Predictive Machine Learning (classifier or regressor)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13td0kd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685207978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a currently a data science student, and my professor has tasked my class to do some machine learning projects.   &lt;/p&gt;\n\n&lt;p&gt;I guess it&amp;#39;s fairly straightforward. Get a dataset, preprocess it, and make a prediction.   &lt;/p&gt;\n\n&lt;p&gt;The challenge is, the dataset size must be atleast 50Gb(gigabytes) and must be uploaded into an AWS S3 bucket and processed using the AWS EMR on EC2 clusters.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking around the AWS data store and it&amp;#39;s mostly biotech and geo science data.   &lt;/p&gt;\n\n&lt;p&gt;I was wondering if any one knows of where I can find ones in the finance or business setting kind of data.   &lt;/p&gt;\n\n&lt;p&gt;Any suggestions or advice will be greatly appreciated.&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13td0kd", "is_robot_indexable": true, "report_reasons": null, "author": "kaiserdx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13td0kd/dataset_sources_for_predictive_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13td0kd/dataset_sources_for_predictive_machine_learning/", "subreddit_subscribers": 910895, "created_utc": 1685207978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9792cqxim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does python sets are not random when there are consecutive numbers or only have values of a single data type, but random with irregular values and data types?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13szape", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685166460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13szape", "is_robot_indexable": true, "report_reasons": null, "author": "Dipanshuz1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13szape/why_does_python_sets_are_not_random_when_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13szape/why_does_python_sets_are_not_random_when_there/", "subreddit_subscribers": 910895, "created_utc": 1685166460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I would like to know what sort of approaches are used/ is best for forecasting short time series.\n\nI\u2019m currently looking at a market supply and price forecasting situation. Where I need to forecast the market supply and price on a daily basis. It seems like taking the historical average is a good approach. But I would like to know what else is out there.\n\nThank you.", "author_fullname": "t2_572nday0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Short Time Series Forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sz2gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685165645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I would like to know what sort of approaches are used/ is best for forecasting short time series.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently looking at a market supply and price forecasting situation. Where I need to forecast the market supply and price on a daily basis. It seems like taking the historical average is a good approach. But I would like to know what else is out there.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sz2gj", "is_robot_indexable": true, "report_reasons": null, "author": "allicrawley", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sz2gj/short_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sz2gj/short_time_series_forecasting/", "subreddit_subscribers": 910895, "created_utc": 1685165645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Impress my Boss with new excel skills using scholarship data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t4fiw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_s0vrfwa", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "analytics", "selftext": "Hello everyone,\n\nI recently have been taking the google analytics certificate in tandem with a beginner to advanced excel class on Udemy (Kyle Pew). I have access to a bunch of scholarship data that was recently cleaned to provide an eligible list of students for a committee to pick from. I have things like major, GPA, city, confirmation on if they submitted an essay or not, and things like this. I was wondering if you all had any ideas how I could use this data in excel and both impress or provide an actionable insight to my supervisor? \n\nBackground I\u2019m going for a promotion that involves being good at excel so I figured providing a concrete example without being asked would increase my chances of securing the position.\n\nThanks again!", "author_fullname": "t2_s0vrfwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Impress my Boss with new excel skills using scholarship data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/analytics", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t4eyg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685185739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685185243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently have been taking the google analytics certificate in tandem with a beginner to advanced excel class on Udemy (Kyle Pew). I have access to a bunch of scholarship data that was recently cleaned to provide an eligible list of students for a committee to pick from. I have things like major, GPA, city, confirmation on if they submitted an essay or not, and things like this. I was wondering if you all had any ideas how I could use this data in excel and both impress or provide an actionable insight to my supervisor? &lt;/p&gt;\n\n&lt;p&gt;Background I\u2019m going for a promotion that involves being good at excel so I figured providing a concrete example without being asked would increase my chances of securing the position.&lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "33eaa002-9772-11ed-8e4c-ceed5ac07d71", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rhz9", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t4eyg", "is_robot_indexable": true, "report_reasons": null, "author": "nitsed004", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "subreddit_subscribers": 134027, "created_utc": 1685185243.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685185293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t4fiw", "is_robot_indexable": true, "report_reasons": null, "author": "nitsed004", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13t4eyg", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t4fiw/how_to_impress_my_boss_with_new_excel_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/analytics/comments/13t4eyg/how_to_impress_my_boss_with_new_excel_skills/", "subreddit_subscribers": 910895, "created_utc": 1685185293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Curious about other people's experiences", "author_fullname": "t2_aakdy8le7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the biggest limitations and frustrations of existing no code data science solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13t11zh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685172734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about other people&amp;#39;s experiences&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13t11zh", "is_robot_indexable": true, "report_reasons": null, "author": "TipAccomplished1946", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13t11zh/what_are_the_biggest_limitations_and_frustrations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13t11zh/what_are_the_biggest_limitations_and_frustrations/", "subreddit_subscribers": 910895, "created_utc": 1685172734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently from a non IT background and in search of a course in data science. Recently while searching for one I got many reviews for LEARNBAY as the best bootcamp for data science. Can you guys please let me know if it's true, if not which is the better institute or bootcamp I should consider or should I just self learn and apply for a job. Please suggest.", "author_fullname": "t2_9q7tw2rq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best course for Data science and data analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13sqhfw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685140248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently from a non IT background and in search of a course in data science. Recently while searching for one I got many reviews for LEARNBAY as the best bootcamp for data science. Can you guys please let me know if it&amp;#39;s true, if not which is the better institute or bootcamp I should consider or should I just self learn and apply for a job. Please suggest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13sqhfw", "is_robot_indexable": true, "report_reasons": null, "author": "Top_Association_3739", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13sqhfw/best_course_for_data_science_and_data_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13sqhfw/best_course_for_data_science_and_data_analytics/", "subreddit_subscribers": 910895, "created_utc": 1685140248.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}