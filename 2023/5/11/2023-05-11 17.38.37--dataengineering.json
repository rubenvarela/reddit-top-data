{"kind": "Listing", "data": {"after": "t3_13eqgri", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e0g7bi32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ODD Platform - An open-source data discovery and observability service - v0.12 release", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13e939e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8_rR5nueHqKBb-m6RLCHaJCLyKPv_RID_aosGvaCv3U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683767609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/opendatadiscovery/odd-platform", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?auto=webp&amp;v=enabled&amp;s=063ca7faa19ae9c6cefb4b9c01ffd952401308d8", "width": 2560, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=538e5ee6dc44a636336b113a26f95be20b0ff17c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ac7551d2fa88247fe126c0082cf758b92987e25", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32e60d72a39a257797b0e1cb91a07b5dcaea8877", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0abed214bbb5149953ae02ec5d3740d3d841645a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f464f906a4270100726648a3d093d205df2fbdae", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pIhK-_EAg3VEJLU_CR8ftea3r36Hz_lADWLCIV2GgI4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f35a635fdbd00a6c4bd563a97ad5125707621afa", "width": 1080, "height": 540}], "variants": {}, "id": "v6VK-NUxLi_E1CB4P_ceItjNhC5nIfAh1ym2kEdKxMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13e939e", "is_robot_indexable": true, "report_reasons": null, "author": "DarronFeldstein", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e939e/odd_platform_an_opensource_data_discovery_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/opendatadiscovery/odd-platform", "subreddit_subscribers": 105001, "created_utc": 1683767609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "According to stack overflow survey 2022 Apache Spark is one of the highest paying technologies. But I am not sure if I can trust this survey. I am really afraid I will waste my time . So people with more experience could you please let me know if Apache Spark is high demanded and high paying skill? Will learning internals of it worth my time?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth learning Apache Spark in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eo3b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683813263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to stack overflow survey 2022 Apache Spark is one of the highest paying technologies. But I am not sure if I can trust this survey. I am really afraid I will waste my time . So people with more experience could you please let me know if Apache Spark is high demanded and high paying skill? Will learning internals of it worth my time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13eo3b3", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eo3b3/is_it_worth_learning_apache_spark_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eo3b3/is_it_worth_learning_apache_spark_in_2023/", "subreddit_subscribers": 105001, "created_utc": 1683813263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm nervous and not sure what to expect. The recruiter said I would go over a project I did in detail.  Full pipeline.  That shouldn't be too bad, but are they going to expect anything out of the ordinary? How should go about explaining something? I'm thinking of coming prepared with 2 or 3 pipelines that are very different.  I'm guessing there is an actual whiteboard involved? Idk", "author_fullname": "t2_1afmkbx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First ever white boarding session. Looking for advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13e2ze9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683752179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m nervous and not sure what to expect. The recruiter said I would go over a project I did in detail.  Full pipeline.  That shouldn&amp;#39;t be too bad, but are they going to expect anything out of the ordinary? How should go about explaining something? I&amp;#39;m thinking of coming prepared with 2 or 3 pipelines that are very different.  I&amp;#39;m guessing there is an actual whiteboard involved? Idk&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13e2ze9", "is_robot_indexable": true, "report_reasons": null, "author": "w_savage", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e2ze9/first_ever_white_boarding_session_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13e2ze9/first_ever_white_boarding_session_looking_for/", "subreddit_subscribers": 105001, "created_utc": 1683752179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we have a quite large RDS instance, MySQL 5.7, and its storage is \\~5-6TB.\n\nWe would like to perform a full dump of the data to S3, and we are comparing two options:\n\n* DMS \n* Apache Spark\n\n&amp;#x200B;\n\nWith DMS it is possible to perform a full snapshot on S3 in parquet format, and it takes 6-7 hours to do so with a 4 vCPU and 32 GB of memory. \n\nWith Spark, after 12 hours the snapshot is at 40-50% completion, with a 16 vCPU and 64GB of memory, in this case the snapshot is saved as json gzip (I could consider removing gzip compression, or using another codec like lz4, if you think gzip is a overhead that could drastically reduce CPU usage if removed).\n\n&amp;#x200B;\n\nWe would like to speed up the Spark implementation, also because we can slightly change the data format, a step that with DMS should be done after the full snapshot. (It's a simple column renaming/dropping, and wrapping some columns in a struct field, there are no expensive operations like joins or aggregations involved).\n\n&amp;#x200B;\n\nIs there anything that could be considered to speed up the Spark implementation? \n\n&amp;#x200B;\n\nThese are things I've already tested:\n\n* 4 queries when reading from the mysql tables, I use CRC32 % 4 of the primary key to define partitions to ingest.\n* FAIR scheduler of 4 FAIR  pools with the same weight and minShare of 2 cores, to avoid that the ingestion of a very large table keeps the others stuck\n* fetchSize is set to 10000", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS DMS vs Spark performances to dump mysql databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eejyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683784824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we have a quite large RDS instance, MySQL 5.7, and its storage is ~5-6TB.&lt;/p&gt;\n\n&lt;p&gt;We would like to perform a full dump of the data to S3, and we are comparing two options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DMS &lt;/li&gt;\n&lt;li&gt;Apache Spark&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;With DMS it is possible to perform a full snapshot on S3 in parquet format, and it takes 6-7 hours to do so with a 4 vCPU and 32 GB of memory. &lt;/p&gt;\n\n&lt;p&gt;With Spark, after 12 hours the snapshot is at 40-50% completion, with a 16 vCPU and 64GB of memory, in this case the snapshot is saved as json gzip (I could consider removing gzip compression, or using another codec like lz4, if you think gzip is a overhead that could drastically reduce CPU usage if removed).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We would like to speed up the Spark implementation, also because we can slightly change the data format, a step that with DMS should be done after the full snapshot. (It&amp;#39;s a simple column renaming/dropping, and wrapping some columns in a struct field, there are no expensive operations like joins or aggregations involved).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there anything that could be considered to speed up the Spark implementation? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;These are things I&amp;#39;ve already tested:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4 queries when reading from the mysql tables, I use CRC32 % 4 of the primary key to define partitions to ingest.&lt;/li&gt;\n&lt;li&gt;FAIR scheduler of 4 FAIR  pools with the same weight and minShare of 2 cores, to avoid that the ingestion of a very large table keeps the others stuck&lt;/li&gt;\n&lt;li&gt;fetchSize is set to 10000&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13eejyl", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13eejyl/aws_dms_vs_spark_performances_to_dump_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eejyl/aws_dms_vs_spark_performances_to_dump_mysql/", "subreddit_subscribers": 105001, "created_utc": 1683784824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have the trial right now, and want to take advantage of the free LinkedIn learning courses. I\u2019m still a beginner in data engineering, but I have python and SQL experience. Are there any courses that help familiarize with tools?", "author_fullname": "t2_62sz58k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any helpful LinkedIn learning courses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ebn70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683775115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have the trial right now, and want to take advantage of the free LinkedIn learning courses. I\u2019m still a beginner in data engineering, but I have python and SQL experience. Are there any courses that help familiarize with tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ebn70", "is_robot_indexable": true, "report_reasons": null, "author": "mangos5", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ebn70/are_there_any_helpful_linkedin_learning_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ebn70/are_there_any_helpful_linkedin_learning_courses/", "subreddit_subscribers": 105001, "created_utc": 1683775115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm new to Snowflake and facing a project with a huge amount of data (events and small files) with a need for freshness in the seconds to the minutes' timeframe (till to be determined by business).\n\n**What are the streaming capabilities Snowflake provides?** Do you suggest keeping most raw data outside it, since it's a lot and only ingest aggregations?\n\nIn any case, once data gets to it, and we need to ingest it and afterward aggregate it in secs to minutes timeframe, **does it offer enough out-of-the-box solutions, or am I better served with streaming tools out of its ecosystem** (Spark, Flink, maybe Benthos, maybe AWS Lambdas for simple event transformations, etc) before ingesting only the final results to Snowflake (or pointing external tables to them in S3)?", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake - what are the streaming capabilities it provides?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dxrg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683740359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m new to Snowflake and facing a project with a huge amount of data (events and small files) with a need for freshness in the seconds to the minutes&amp;#39; timeframe (till to be determined by business).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the streaming capabilities Snowflake provides?&lt;/strong&gt; Do you suggest keeping most raw data outside it, since it&amp;#39;s a lot and only ingest aggregations?&lt;/p&gt;\n\n&lt;p&gt;In any case, once data gets to it, and we need to ingest it and afterward aggregate it in secs to minutes timeframe, &lt;strong&gt;does it offer enough out-of-the-box solutions, or am I better served with streaming tools out of its ecosystem&lt;/strong&gt; (Spark, Flink, maybe Benthos, maybe AWS Lambdas for simple event transformations, etc) before ingesting only the final results to Snowflake (or pointing external tables to them in S3)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13dxrg3", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13dxrg3/snowflake_what_are_the_streaming_capabilities_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13dxrg3/snowflake_what_are_the_streaming_capabilities_it/", "subreddit_subscribers": 105001, "created_utc": 1683740359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not the first job post I've seen with something like this. \n\nCorrect me if I'm wrong, but didn't dbt only really take off in the last 3 years or so? It also said 7+ years as an analytics engineer. \n\nWhen you see job postings like this, do you facepalm?\n\nI'm aware that  version controlled data modeling existed prior to dbt, and the analytics engineer role existed prior to it's currently coined name.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I saw a job post asking for 7+ years of exp with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ep8an", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683815787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not the first job post I&amp;#39;ve seen with something like this. &lt;/p&gt;\n\n&lt;p&gt;Correct me if I&amp;#39;m wrong, but didn&amp;#39;t dbt only really take off in the last 3 years or so? It also said 7+ years as an analytics engineer. &lt;/p&gt;\n\n&lt;p&gt;When you see job postings like this, do you facepalm?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that  version controlled data modeling existed prior to dbt, and the analytics engineer role existed prior to it&amp;#39;s currently coined name.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ep8an", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13ep8an/i_saw_a_job_post_asking_for_7_years_of_exp_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ep8an/i_saw_a_job_post_asking_for_7_years_of_exp_with/", "subreddit_subscribers": 105001, "created_utc": 1683815787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT 101 - The Why And What Of ELT (Or The Why NOT Of ETL)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_13emfhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_U45ecsniw0MZrt-ZkYZLxVnPI3gypUtV0EbBdf7Z6w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683809263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/elt-101-the-why-and-what-of-elt-or-the-why-not-of-etl/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?auto=webp&amp;v=enabled&amp;s=3e7bfae807bd38392dd3184d8b1a3915ba9f9ca9", "width": 1600, "height": 760}, "resolutions": [{"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30d3adf67da4cbad7486c774839594a791b9b2df", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f34fa995012dcef46dc4f1270ad45833853d5b", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbad3936f082f45d25a5449d329719c2c5602479", "width": 320, "height": 152}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08509a10de100cc021f848d5d9cb69b7a6739c31", "width": 640, "height": 304}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cbefb17455f18c969587d37b615f0489e3bf4d1", "width": 960, "height": 456}, {"url": "https://external-preview.redd.it/8rWwt3FUaojz0tlHUxwtigOBRfo3jwbWPng6Ob0eK0A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a84e6285df65082ee41fdd428d75cf98f7cd46bb", "width": 1080, "height": 513}], "variants": {}, "id": "t-qdIuB2oxr3uBAIhIi3yYRHyT7VRP9u_r4wrrOLflk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13emfhj", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13emfhj/elt_101_the_why_and_what_of_elt_or_the_why_not_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/elt-101-the-why-and-what-of-elt-or-the-why-not-of-etl/", "subreddit_subscribers": 105001, "created_utc": 1683809263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand data modelling and what data model is best suited for a given architecture.\n\nExample: e-commerce data\n\nI have data currently sitting in Postgres using a 3NF model. This data is then extracted to Snowflake into a raw schema and then downstream, a staging layer is created (as views).\n\nWhat would be a suitable data model here? How should the further downstream layers be structured?\n\nThe data being extracted into snowflake is subject to change e.g. additional columns, deleted columns, modified columns, new tables.\n\nI've had a look at DV2.0 and it just seems overly complex, I can't understand why it would be used even at the staging layer.\n\nStar schema (Kimball) seems fine... but is this suitable? Given snowflake is columnar based, it seems like some form of wide tables make sense.\n\nThen inmon... I really don't understand this. Inmon is about having a normalized data set, but why would we do this in snowflake where we should be denormalizing for faster analytical queries?", "author_fullname": "t2_1sppt3lu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres to Snowflake - which data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13e2etq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683750935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand data modelling and what data model is best suited for a given architecture.&lt;/p&gt;\n\n&lt;p&gt;Example: e-commerce data&lt;/p&gt;\n\n&lt;p&gt;I have data currently sitting in Postgres using a 3NF model. This data is then extracted to Snowflake into a raw schema and then downstream, a staging layer is created (as views).&lt;/p&gt;\n\n&lt;p&gt;What would be a suitable data model here? How should the further downstream layers be structured?&lt;/p&gt;\n\n&lt;p&gt;The data being extracted into snowflake is subject to change e.g. additional columns, deleted columns, modified columns, new tables.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a look at DV2.0 and it just seems overly complex, I can&amp;#39;t understand why it would be used even at the staging layer.&lt;/p&gt;\n\n&lt;p&gt;Star schema (Kimball) seems fine... but is this suitable? Given snowflake is columnar based, it seems like some form of wide tables make sense.&lt;/p&gt;\n\n&lt;p&gt;Then inmon... I really don&amp;#39;t understand this. Inmon is about having a normalized data set, but why would we do this in snowflake where we should be denormalizing for faster analytical queries?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13e2etq", "is_robot_indexable": true, "report_reasons": null, "author": "soulstrikerr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e2etq/postgres_to_snowflake_which_data_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13e2etq/postgres_to_snowflake_which_data_model/", "subreddit_subscribers": 105001, "created_utc": 1683750935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this depends sometimes on the tool, language, or database being used, but just curious on data engineers\u2019 preferred styles.\n\nAlso what style did I miss? (ran out of options in the poll).\n\nThese two are missed:\n\nCapital\\_Snake\n\nALLUPPERCASE\n\n[View Poll](https://www.reddit.com/poll/13ed95o)", "author_fullname": "t2_t2wl82bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What case style does everyone use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ed95o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683780383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this depends sometimes on the tool, language, or database being used, but just curious on data engineers\u2019 preferred styles.&lt;/p&gt;\n\n&lt;p&gt;Also what style did I miss? (ran out of options in the poll).&lt;/p&gt;\n\n&lt;p&gt;These two are missed:&lt;/p&gt;\n\n&lt;p&gt;Capital_Snake&lt;/p&gt;\n\n&lt;p&gt;ALLUPPERCASE&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/13ed95o\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ed95o", "is_robot_indexable": true, "report_reasons": null, "author": "generic-d-engineer", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1684385183772, "options": [{"text": "camelCase", "id": "22975681"}, {"text": "snake_case", "id": "22975682"}, {"text": "CapitalCamel", "id": "22975683"}, {"text": "SCREAMING_SNAKE", "id": "22975684"}, {"text": "alllower", "id": "22975685"}, {"text": "LGCYCASE (legacy case - 8 chars max, all upper)", "id": "22975686"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 467, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ed95o/what_case_style_does_everyone_use/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/13ed95o/what_case_style_does_everyone_use/", "subreddit_subscribers": 105001, "created_utc": 1683780383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building a data engineer stack consisting of airflow, sparkpy/delta, jupyterlab, and great expectations in docker.\n\nIs it best practice to pull an image of these respective services into their own container or should I build an image using a requirements.txt file with Python and then start the services in a single container?", "author_fullname": "t2_b4yb48b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker question when building a data engineering stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13e6d0g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683760000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a data engineer stack consisting of airflow, sparkpy/delta, jupyterlab, and great expectations in docker.&lt;/p&gt;\n\n&lt;p&gt;Is it best practice to pull an image of these respective services into their own container or should I build an image using a requirements.txt file with Python and then start the services in a single container?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13e6d0g", "is_robot_indexable": true, "report_reasons": null, "author": "optionmonk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e6d0g/docker_question_when_building_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13e6d0g/docker_question_when_building_a_data_engineering/", "subreddit_subscribers": 105001, "created_utc": 1683760000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I read somewhere in reduced costs significantly but is Apache Iceberg really a game changer for big data companies?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Iceberg a disruption in big data and does it bring more profits to businesses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13e4f5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683755366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read somewhere in reduced costs significantly but is Apache Iceberg really a game changer for big data companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13e4f5h", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e4f5h/is_apache_iceberg_a_disruption_in_big_data_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13e4f5h/is_apache_iceberg_a_disruption_in_big_data_and/", "subreddit_subscribers": 105001, "created_utc": 1683755366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14v3ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semantic Understanding of SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 113, "top_awarded_type": null, "hide_score": false, "name": "t3_13e3wcw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VsYgedvozfzL2c17eZKV5Xhwd-bYT0j6VzD4WCXtT6k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683754184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/data-engineer-things/semantic-understanding-of-sql-300fe5a48ae7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?auto=webp&amp;v=enabled&amp;s=e626cf3b7f7290ab70ad140a64305828f1a0e24f", "width": 1200, "height": 970}, "resolutions": [{"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=299d9caaa5dc4260e25a8f82894b29ee9561781a", "width": 108, "height": 87}, {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a9e3239e04b915f2be8d4f6441848b5d554a1b9", "width": 216, "height": 174}, {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d8b3720c1393e7e0d3616c80829e8695decc377", "width": 320, "height": 258}, {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba4151200e21a739af3d87de98794de15d67ddee", "width": 640, "height": 517}, {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf4bf7111e0d839578519dd71d97da05bde2348b", "width": 960, "height": 776}, {"url": "https://external-preview.redd.it/jjmQR5YVlfwrcuhkzxi5aIiTzO6VPdzwV9p1NBpw43c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3de5332e5ecc74059b6b0da48e36603196328945", "width": 1080, "height": 873}], "variants": {}, "id": "yhf-NKFWvyex_6rZqHuRTwEqPI36J0NXypTOmVUOixk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13e3wcw", "is_robot_indexable": true, "report_reasons": null, "author": "s0ck_r4w", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e3wcw/semantic_understanding_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/data-engineer-things/semantic-understanding-of-sql-300fe5a48ae7", "subreddit_subscribers": 105001, "created_utc": 1683754184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been working in a Data Engineering role for about a year.  Before this role, I was in more of a software engineering role and worked heavily with Python and SQL.  The Data Engineering team I'm on now primarily uses Low/No Code Tools (Informatica and SSIS) and SQL. The team is currently working migrating all data integrations/pipelines to IICS.   Other parts of the company are currently using dbt, fivetran,  and AWS.  Our team plans to maybe start using dbt in the next couple months.  \n\nI was recently assigned a project to review an old legacy application used internally and redo it in IICS.  The actual application was way more bloated and complex then it should have been.  It basically just ran a couple stored procedures, did some transformations,  and called a couple APIs.  So kind perfect for some sort of orchestration.  \n\nHowever, we've ran into some issues that we have been unable to solve and even if we somehow get it to work, the actual solution is way more complex then it probably should be.  Doing at least part of this project in Python would be significantly easier.  \n\nSo that got me thinking.  I don't think there is any way the company will move away from IICS at this time.  It's got way too much support among the executives and most people on my team don't know python that well.  However, it's clear we will need more flexibility at times.  So why not introduce Airflow, Prefect, Mage, or Dagster and orchestrate everything there.  \n\nIf I had one of these tools, I could basically call an API to run what works in IICS then do what I need to do in python and call another API to finish up the task in IICS.  Calling an API in python is not hard and I'm fairly certain the team could handle that.  If we orchestrate everything in one of these tools I also think it might have some additional benefits for the organization.  \n\nMainly that we are currently using orchestration capabilities in not only IICS, but we are also using orchestration capabilities in dbt and fivetran.  This would allow us to orchestrate everything from a common interface and perhaps deliver some additional savings and better manage any dependencies that might come up. \n\nI've brought this idea up to management as a way to get past some our challenges, but it hasn't gone anywhere. Am I way off base here? Is this not a good way to leverage no code tools while still being able to have the flexibility of code when you need it? Does anybody else orchestrate no-code tools in this manner? What has been your experience?", "author_fullname": "t2_alh7gmjhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on an \"Orchestrate Everything in Code Approach\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13dxs5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683740407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working in a Data Engineering role for about a year.  Before this role, I was in more of a software engineering role and worked heavily with Python and SQL.  The Data Engineering team I&amp;#39;m on now primarily uses Low/No Code Tools (Informatica and SSIS) and SQL. The team is currently working migrating all data integrations/pipelines to IICS.   Other parts of the company are currently using dbt, fivetran,  and AWS.  Our team plans to maybe start using dbt in the next couple months.  &lt;/p&gt;\n\n&lt;p&gt;I was recently assigned a project to review an old legacy application used internally and redo it in IICS.  The actual application was way more bloated and complex then it should have been.  It basically just ran a couple stored procedures, did some transformations,  and called a couple APIs.  So kind perfect for some sort of orchestration.  &lt;/p&gt;\n\n&lt;p&gt;However, we&amp;#39;ve ran into some issues that we have been unable to solve and even if we somehow get it to work, the actual solution is way more complex then it probably should be.  Doing at least part of this project in Python would be significantly easier.  &lt;/p&gt;\n\n&lt;p&gt;So that got me thinking.  I don&amp;#39;t think there is any way the company will move away from IICS at this time.  It&amp;#39;s got way too much support among the executives and most people on my team don&amp;#39;t know python that well.  However, it&amp;#39;s clear we will need more flexibility at times.  So why not introduce Airflow, Prefect, Mage, or Dagster and orchestrate everything there.  &lt;/p&gt;\n\n&lt;p&gt;If I had one of these tools, I could basically call an API to run what works in IICS then do what I need to do in python and call another API to finish up the task in IICS.  Calling an API in python is not hard and I&amp;#39;m fairly certain the team could handle that.  If we orchestrate everything in one of these tools I also think it might have some additional benefits for the organization.  &lt;/p&gt;\n\n&lt;p&gt;Mainly that we are currently using orchestration capabilities in not only IICS, but we are also using orchestration capabilities in dbt and fivetran.  This would allow us to orchestrate everything from a common interface and perhaps deliver some additional savings and better manage any dependencies that might come up. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve brought this idea up to management as a way to get past some our challenges, but it hasn&amp;#39;t gone anywhere. Am I way off base here? Is this not a good way to leverage no code tools while still being able to have the flexibility of code when you need it? Does anybody else orchestrate no-code tools in this manner? What has been your experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13dxs5o", "is_robot_indexable": true, "report_reasons": null, "author": "DataFoundation", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13dxs5o/what_are_your_thoughts_on_an_orchestrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13dxs5o/what_are_your_thoughts_on_an_orchestrate/", "subreddit_subscribers": 105001, "created_utc": 1683740407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am a cloud and data architect who enjoys mentoring and guiding individuals in their data engineering careers. One common question I receive is, \"What resources should I use to learn?\" In my opinion, this is a personal preference, as everyone has their preferred method of consuming information.\n\nHowever, I am working on creating a free and accessible knowledge repository for learning data engineering. This repository will contain various types of resources, such as blogs, articles, videos, and free courses. Please note that all resources should be free and related to data engineering only.\n\nI would greatly appreciate your assistance in adding resources to this list. The link to the sheet can be found in the comments.\n\nThank you!", "author_fullname": "t2_rrbmofj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Learning Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqshf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683820379.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683819223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a cloud and data architect who enjoys mentoring and guiding individuals in their data engineering careers. One common question I receive is, &amp;quot;What resources should I use to learn?&amp;quot; In my opinion, this is a personal preference, as everyone has their preferred method of consuming information.&lt;/p&gt;\n\n&lt;p&gt;However, I am working on creating a free and accessible knowledge repository for learning data engineering. This repository will contain various types of resources, such as blogs, articles, videos, and free courses. Please note that all resources should be free and related to data engineering only.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your assistance in adding resources to this list. The link to the sheet can be found in the comments.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13eqshf", "is_robot_indexable": true, "report_reasons": null, "author": "Anishekkamal", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqshf/resources_for_learning_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqshf/resources_for_learning_data_engineering/", "subreddit_subscribers": 105001, "created_utc": 1683819223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working with a customer on a shared product table. We are wanting to use a shared table through databricks. The problem is we are in us-west-1, while they are in us-west-2. We do not want to incur egress charges. What can we do?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks shared table when users are in different aws regions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ea2fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683770428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with a customer on a shared product table. We are wanting to use a shared table through databricks. The problem is we are in us-west-1, while they are in us-west-2. We do not want to incur egress charges. What can we do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ea2fz", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ea2fz/databricks_shared_table_when_users_are_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ea2fz/databricks_shared_table_when_users_are_in/", "subreddit_subscribers": 105001, "created_utc": 1683770428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am researching the concept of how viable is sql for stream processing. I know platforms like flink allow java / python for stream processing but platform\u2019s like decodable gives sql for stream processing. \n\nAny thoughts on sql for stream processes &amp; data pipelines? TIA.", "author_fullname": "t2_ncy21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do u use decodable platform ? Or sql for streaming for data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13emmjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683809759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am researching the concept of how viable is sql for stream processing. I know platforms like flink allow java / python for stream processing but platform\u2019s like decodable gives sql for stream processing. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts on sql for stream processes &amp;amp; data pipelines? TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13emmjd", "is_robot_indexable": true, "report_reasons": null, "author": "nandyk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13emmjd/do_u_use_decodable_platform_or_sql_for_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13emmjd/do_u_use_decodable_platform_or_sql_for_streaming/", "subreddit_subscribers": 105001, "created_utc": 1683809759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nWe are building a job portal. For the MVP, we used airtable to connect with webflow and showcase a limited number of jobs.\n\nNow as we want to create a scalable database and pipeline for this, we have designed a flow for my ETL, where we are thinking of making use of Airtable's free version for LIVE jobs on the portal, as each base can have up to 1200 records, google sheets as a data warehouse to store all the extracted job IDs and expired 'required' jobs details.\n\nIMO, Making use of these tools will reduce the cost of database and data warehousing at the start of this journey. The major cost will come from hosting the server, running CRON jobs, and website hosting.\n\nThis is just our first draft, I'm open to changing things around as well.\n\nI have uploaded the image of the design and also added a link for excalidraw.\n\nAny feedback is appreciated! Thank you!\n\n[Excalidraw](https://excalidraw.com/#json=iHpRnQdJdo1Rnx9fH2GUc,H1YS7J1YDBbVl-j_TltZdQ)\n\n[Design](https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066)", "author_fullname": "t2_w4mta741", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need feedback on my Job portal data design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"abgo69agk6za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 30, "x": 108, "u": "https://preview.redd.it/abgo69agk6za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31d15a68a6b06d23986246d3695e63db8ad1616c"}, {"y": 61, "x": 216, "u": "https://preview.redd.it/abgo69agk6za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48826468eef0e462026c5080ff1028176804c30a"}, {"y": 90, "x": 320, "u": "https://preview.redd.it/abgo69agk6za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e08b1fc4431ea25a18fd887c5f94d151c358e24"}, {"y": 181, "x": 640, "u": "https://preview.redd.it/abgo69agk6za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4702ab3a8bf086b3a33560efce3c0ea406e1014"}, {"y": 272, "x": 960, "u": "https://preview.redd.it/abgo69agk6za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3e6ec9acf744f44a9e0f2964a41cd176b8bfc89"}, {"y": 307, "x": 1080, "u": "https://preview.redd.it/abgo69agk6za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7edd803edf342ac95a3ea7f7a6241c82ded7eacc"}], "s": {"y": 1489, "x": 5237, "u": "https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066"}, "id": "abgo69agk6za1"}}, "name": "t3_13ejhyz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RFe7lKONXGm5gHanEKf5xwe3R5oWQ-tMm5nqvMIEU04.jpg", "edited": 1683807712.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683801587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;We are building a job portal. For the MVP, we used airtable to connect with webflow and showcase a limited number of jobs.&lt;/p&gt;\n\n&lt;p&gt;Now as we want to create a scalable database and pipeline for this, we have designed a flow for my ETL, where we are thinking of making use of Airtable&amp;#39;s free version for LIVE jobs on the portal, as each base can have up to 1200 records, google sheets as a data warehouse to store all the extracted job IDs and expired &amp;#39;required&amp;#39; jobs details.&lt;/p&gt;\n\n&lt;p&gt;IMO, Making use of these tools will reduce the cost of database and data warehousing at the start of this journey. The major cost will come from hosting the server, running CRON jobs, and website hosting.&lt;/p&gt;\n\n&lt;p&gt;This is just our first draft, I&amp;#39;m open to changing things around as well.&lt;/p&gt;\n\n&lt;p&gt;I have uploaded the image of the design and also added a link for excalidraw.&lt;/p&gt;\n\n&lt;p&gt;Any feedback is appreciated! Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://excalidraw.com/#json=iHpRnQdJdo1Rnx9fH2GUc,H1YS7J1YDBbVl-j_TltZdQ\"&gt;Excalidraw&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/abgo69agk6za1.png?width=5237&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4aa6d1742c31d0d51f3d7d9eca53eb0589cd7066\"&gt;Design&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?auto=webp&amp;v=enabled&amp;s=4cb9a0b6a3c8009039410ca42972373ebe4befe1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37964420873f7e84e3f5d8604525926b3d4590f3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a39df796a0f0269b29d71df78b0243902aa390f4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71e56794186e08b61e6d091b6bd715ae0541cf11", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dd9bf8a74e0aad8c0bdc88192e88a1c3647957f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c59c5b3ccf4f9d8081c9acdf857b0a8edef344b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/2J89T5KT9dAVbLJ8EnbZOBf5Ln8jI2DQOa7ut9ed_OA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a64b85280885079bf70f1262c03a40cb3b6b0bd4", "width": 1080, "height": 567}], "variants": {}, "id": "eKi-lMrkzQ0Tkft-A4LwK4MR73Yf1HwofRQsC3tBE4w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ejhyz", "is_robot_indexable": true, "report_reasons": null, "author": "Ketonium10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ejhyz/need_feedback_on_my_job_portal_data_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ejhyz/need_feedback_on_my_job_portal_data_design/", "subreddit_subscribers": 105001, "created_utc": 1683801587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are Streamlit's editable dataframes?\ud83d\udccb\u00a0Editable dataframes are a new feature in Streamlit that allows users to interactively edit data tables.\ud83d\udc49 Users can click on cells and edit their contents, add or delete rows, and copy-paste data from other sources.\n\n\ud83d\udd11Key features include  \n\ud83d\uddff Bulk editing  \n\ud83d\uddc3\ufe0f Support for various data types  \n\ud83d\udd23 Automatic input validation\ud83d\udcb2Rich editing experience with \u2611\ufe0fcheckboxes and dropdowns.  \n\n\nhttps://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb\n\n[https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over](https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over)", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deeper dive into Streamlit editable dataframes on top of \u2744\ufe0fSnowflake with example code showing how to create \u270d\ufe0f data write-back application using Streamlit and Snowflake. Replace Google Sheets https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6kcdybzra5za1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fe15e81a5764c940d221c2ec1d683e3bae2da2c"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d21ab9394473652556d63f02e395e5d6010f3f4"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81d37d9b1795ac5872db915b0806c32c93f0a8b3"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d77f021bfcfba696084f17b4b66ac8607f67bfd"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b64efb4b7b5e045d3a4774a09bab2d35b639dc"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eea00ca04b03d6b71624818f4045dcdbb4b6e6e7"}], "s": {"y": 875, "x": 1920, "u": "https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb"}, "id": "6kcdybzra5za1"}}, "name": "t3_13eew3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MVdA8qI1kzF9voun5EtowBWzu3IS6ZBu8w3sGxh9GhQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683786031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are Streamlit&amp;#39;s editable dataframes?\ud83d\udccb\u00a0Editable dataframes are a new feature in Streamlit that allows users to interactively edit data tables.\ud83d\udc49 Users can click on cells and edit their contents, add or delete rows, and copy-paste data from other sources.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd11Key features include&lt;br/&gt;\n\ud83d\uddff Bulk editing&lt;br/&gt;\n\ud83d\uddc3\ufe0f Support for various data types&lt;br/&gt;\n\ud83d\udd23 Automatic input validation\ud83d\udcb2Rich editing experience with \u2611\ufe0fcheckboxes and dropdowns.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb\"&gt;https://preview.redd.it/6kcdybzra5za1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=83c1f7fe7529724d2df9b882eb5ac6825b765acb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over\"&gt;https://www.recordlydata.com/blog/streamlits-editable-dataframes-is-the-reign-of-google-sheets-over&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13eew3d", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eew3d/deeper_dive_into_streamlit_editable_dataframes_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eew3d/deeper_dive_into_streamlit_editable_dataframes_on/", "subreddit_subscribers": 105001, "created_utc": 1683786031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI stumbled across an interesting problem  regarding optimal structuring of customer data. I think I know how I would do this but would love your thoughts.\n\nCurrently we have a large (4 million+) customer table. Each customer has a broad number of possible attributes (up to 50+). The previous DE compiled all the possible attributes for each customer into a single column string. For example, each number is associated with a specific attribute so a customer could be assigned \u201c-1-14-45-50-\u201c which are 4 different attributes.\n\nSure, it works BUT is an intense process to search all these strings to find attributes. \n\nI probably would have set each attribute as separate column flags (0,1) but curious if anyone has a more efficient approach to structuring this fact data?", "author_fullname": "t2_9jpw3w38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling large number of categories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13e287x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683750523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I stumbled across an interesting problem  regarding optimal structuring of customer data. I think I know how I would do this but would love your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Currently we have a large (4 million+) customer table. Each customer has a broad number of possible attributes (up to 50+). The previous DE compiled all the possible attributes for each customer into a single column string. For example, each number is associated with a specific attribute so a customer could be assigned \u201c-1-14-45-50-\u201c which are 4 different attributes.&lt;/p&gt;\n\n&lt;p&gt;Sure, it works BUT is an intense process to search all these strings to find attributes. &lt;/p&gt;\n\n&lt;p&gt;I probably would have set each attribute as separate column flags (0,1) but curious if anyone has a more efficient approach to structuring this fact data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13e287x", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Razzmatazz7416", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13e287x/handling_large_number_of_categories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13e287x/handling_large_number_of_categories/", "subreddit_subscribers": 105001, "created_utc": 1683750523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I reviewed a data pipeline project that compares Louisville Metro expenditure data across fiscal years. The project utilized Terraform, a Prefect Docker container, and Google Cloud Storage/Big Query. I was impressed with the partitioning of data by fiscal year, fulfilling project requirements despite the dataset being less than 1GB. Clear instructions and a well-designed dashboard made it easy to navigate. Suggested future improvement is to include a script for downloading data directly from the original source to avoid excessive report generation. Kudos to everyone involved in DataTalksClub Data Engineering Zoomcamp 2023 and Louisville Open Data portal for public access to the data.\n\n[GitHub](https://github.com/Xanthus1/zoomcamp-louisville-data/tree/main)  \n\n\n\\#dezoomcamp", "author_fullname": "t2_52y1it67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review of Louisville Metro Expenditure Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13esll5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683823304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I reviewed a data pipeline project that compares Louisville Metro expenditure data across fiscal years. The project utilized Terraform, a Prefect Docker container, and Google Cloud Storage/Big Query. I was impressed with the partitioning of data by fiscal year, fulfilling project requirements despite the dataset being less than 1GB. Clear instructions and a well-designed dashboard made it easy to navigate. Suggested future improvement is to include a script for downloading data directly from the original source to avoid excessive report generation. Kudos to everyone involved in DataTalksClub Data Engineering Zoomcamp 2023 and Louisville Open Data portal for public access to the data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Xanthus1/zoomcamp-louisville-data/tree/main\"&gt;GitHub&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;#dezoomcamp&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13esll5", "is_robot_indexable": true, "report_reasons": null, "author": "Manny-97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13esll5/review_of_louisville_metro_expenditure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13esll5/review_of_louisville_metro_expenditure_data/", "subreddit_subscribers": 105001, "created_utc": 1683823304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, can someone help me in this problem?\n\nI'm using AWS glue that produces more than 5k small files by day, at the of the day I need to read all these files and unify it in one big larger file.\n\nI tried to use dropPartition from spark and repartition but without success\n\nhere is my block of code, I read from catalog and the data gots a lot of duplicated data when I write it in a new DF.\n\n`df = glueContext.create_dynamic_frame.from_options(connection_type=\"parquet\", connection_options={'paths': [path]})`\n\n`partitioned_df=df.toDF().withColumn('year_month_day',lit(20230407)).repartition('year_month_day')`\n\n`remove_dup_df = partitioned_df.dropDuplicates()`\n\n`partitioned_dynamic_df=DynamicFrame.fromDF(remove_dup_df,glueContext,\"partitioned_df\")`", "author_fullname": "t2_2j36teh6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data got duplicated when trying to unify small parquet files in one file [AWS Glue]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13esa59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683823977.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683822570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, can someone help me in this problem?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using AWS glue that produces more than 5k small files by day, at the of the day I need to read all these files and unify it in one big larger file.&lt;/p&gt;\n\n&lt;p&gt;I tried to use dropPartition from spark and repartition but without success&lt;/p&gt;\n\n&lt;p&gt;here is my block of code, I read from catalog and the data gots a lot of duplicated data when I write it in a new DF.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;df = glueContext.create_dynamic_frame.from_options(connection_type=&amp;quot;parquet&amp;quot;, connection_options={&amp;#39;paths&amp;#39;: [path]})&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;partitioned_df=df.toDF().withColumn(&amp;#39;year_month_day&amp;#39;,lit(20230407)).repartition(&amp;#39;year_month_day&amp;#39;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;remove_dup_df = partitioned_df.dropDuplicates()&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;partitioned_dynamic_df=DynamicFrame.fromDF(remove_dup_df,glueContext,&amp;quot;partitioned_df&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13esa59", "is_robot_indexable": true, "report_reasons": null, "author": "syzaak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13esa59/data_got_duplicated_when_trying_to_unify_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13esa59/data_got_duplicated_when_trying_to_unify_small/", "subreddit_subscribers": 105001, "created_utc": 1683822570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow data engineers.\n\nWe're currently poccing out Hudi to support our ML stack, and have been running it on EMR serverless. This went pretty smoothly in staging, however now we've shipped to prod the scale of things seems potentially off. \n\nJust wanted to get some ballpark figures from people doing similar stuff to check we are I'm the right area.\n\nSo our job is as simple as can be, it reads in some parquet and performs an upsert on a Hudi table. We're on the first phase of this project so it just reads and writes everything all the time.\n\nThe thing that's surprised me is the size of cluster needed to process a relatively small amount of data. We've got around 300gb of parquet in one table, and I've had to provision 1200vcpu, 4000gb of memory and 10000gb of storage. This seems insane to me, but anything lower and we get \"No space left on device\" errors. \n\nAny similar experiences, thoughts or info much appreciated!\n\nThanks", "author_fullname": "t2_r9ds5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Emr Serverless and Hudi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqpv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683819060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently poccing out Hudi to support our ML stack, and have been running it on EMR serverless. This went pretty smoothly in staging, however now we&amp;#39;ve shipped to prod the scale of things seems potentially off. &lt;/p&gt;\n\n&lt;p&gt;Just wanted to get some ballpark figures from people doing similar stuff to check we are I&amp;#39;m the right area.&lt;/p&gt;\n\n&lt;p&gt;So our job is as simple as can be, it reads in some parquet and performs an upsert on a Hudi table. We&amp;#39;re on the first phase of this project so it just reads and writes everything all the time.&lt;/p&gt;\n\n&lt;p&gt;The thing that&amp;#39;s surprised me is the size of cluster needed to process a relatively small amount of data. We&amp;#39;ve got around 300gb of parquet in one table, and I&amp;#39;ve had to provision 1200vcpu, 4000gb of memory and 10000gb of storage. This seems insane to me, but anything lower and we get &amp;quot;No space left on device&amp;quot; errors. &lt;/p&gt;\n\n&lt;p&gt;Any similar experiences, thoughts or info much appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13eqpv5", "is_robot_indexable": true, "report_reasons": null, "author": "hazza192837465", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqpv5/emr_serverless_and_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqpv5/emr_serverless_and_hudi/", "subreddit_subscribers": 105001, "created_utc": 1683819060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My current company uses Fivetran and it has mostly gone well, but I am moving to a new company soon and will probably need to make a decision on EL tooling.\n\nThe biggest thing that scares me about Fivetran is the MAR-based pricing, which I can definitely see blowing up at my current place over the next year or two. Especially as we start to add just the kinds of event and audit tables that would otherwise be useful in capturing and modeling historical data. My new place is a smaller, lean company so I don't want to set them up for exploding EL costs if avoidable.\n\nSo thoughts about Stitch vs. Fivetran specifically in these areas?  \n1) Production database syncs with CDC -- does Stitch do this well, is it performant? Does it actually capture all data changes or have people run into weird bugs? Stitch certainly looks much cheaper than Fivetran but I don't want to blunder into a \"you get what you pay for\" situation.  \n2) Any experiences using Stitch or Fivetran to capture Salesforce and NetSuite data? Does one of the tools seem more mature or performant in this area? Do they do a good job of capturing full history over time? Is it true that Fivetran will normalize to the extreme just to drive up MAR and cost on these API-based syncs?  \n\n\nThose are the two main questions. I see some general discussion but want to get into details if anyone has experience here. Much appreciated!", "author_fullname": "t2_ikd9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitch vs. Fivetran (some specific cases)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqh1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683818527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current company uses Fivetran and it has mostly gone well, but I am moving to a new company soon and will probably need to make a decision on EL tooling.&lt;/p&gt;\n\n&lt;p&gt;The biggest thing that scares me about Fivetran is the MAR-based pricing, which I can definitely see blowing up at my current place over the next year or two. Especially as we start to add just the kinds of event and audit tables that would otherwise be useful in capturing and modeling historical data. My new place is a smaller, lean company so I don&amp;#39;t want to set them up for exploding EL costs if avoidable.&lt;/p&gt;\n\n&lt;p&gt;So thoughts about Stitch vs. Fivetran specifically in these areas?&lt;br/&gt;\n1) Production database syncs with CDC -- does Stitch do this well, is it performant? Does it actually capture all data changes or have people run into weird bugs? Stitch certainly looks much cheaper than Fivetran but I don&amp;#39;t want to blunder into a &amp;quot;you get what you pay for&amp;quot; situation.&lt;br/&gt;\n2) Any experiences using Stitch or Fivetran to capture Salesforce and NetSuite data? Does one of the tools seem more mature or performant in this area? Do they do a good job of capturing full history over time? Is it true that Fivetran will normalize to the extreme just to drive up MAR and cost on these API-based syncs?  &lt;/p&gt;\n\n&lt;p&gt;Those are the two main questions. I see some general discussion but want to get into details if anyone has experience here. Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13eqh1h", "is_robot_indexable": true, "report_reasons": null, "author": "dlb8685", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqh1h/stitch_vs_fivetran_some_specific_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqh1h/stitch_vs_fivetran_some_specific_cases/", "subreddit_subscribers": 105001, "created_utc": 1683818527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512](https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build an integration hub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13eqgri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683818512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512\"&gt;https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?auto=webp&amp;v=enabled&amp;s=e0dcf65745f8f81ca40c6232048eba40042bbf0a", "width": 1200, "height": 685}, "resolutions": [{"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd2916bdbf4df71087bc2fd4a81cfe569b85627", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c4e2e0bee9f7fe0ef25a3c7c898f283313a17d4", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0c1d8204e15115c3870303acdc8ce061c110c1e", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55b7a318d94772320df353222cbe01861bf19c33", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b85f5b8d4c343988c05c7fa7c79f5c754af917", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1183da065c5cf2cc73a5ff0fe7fe2e74be20a4a", "width": 1080, "height": 616}], "variants": {}, "id": "a2iUTeqWmkO2QfQFQh8Uti-nGge_UVR1rRhDsRSJ5sk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13eqgri", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13eqgri/how_to_build_an_integration_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13eqgri/how_to_build_an_integration_hub/", "subreddit_subscribers": 105001, "created_utc": 1683818512.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}