{"kind": "Listing", "data": {"after": "t3_13gkanv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings fellow data hoarders, I recently have come across a channel on  youtube with a collection of several vintage documentaries, films, and television shows, predominantly hailing from the 1980s and early 1990s. As such the depth and niche quality of this collection is notable, presenting a fascinating  snapshot of a bygone era with a lot of media dealing with esoteric matters such as the uap phenomenon and adjacent topics. Interestingly, it appears that much of this material has been  meticulously restored from original VHS copies, contributing to its  rarity and underscoring the critical need for archiving. Given the  historical and cultural value of such content, coupled with its scarcity  in contemporary digital repositories, I strongly advocate for its  preservation. As we have become unfortunately aware the unpredictable nature of content hosting policies on platforms such  as YouTube further compounds the urgency of this endeavor, as the  channel might face an untimely takedown.\n\n&amp;#x200B;\n\nRegrettably, I'm currently unable to personally undertake the task of  backing up this unique channel due to limitations in my data storage  capabilities. However, I felt compelled to utilize this Free Post Friday  as a platform to disseminate this discovery amongst our community, in  the hope that it piques your interest and prompts collective action  towards preserving\n\n&amp;#x200B;\n\nThe channel in question :\n\n[https://www.youtube.com/@orphicunknown](https://www.youtube.com/@orphicunknown)", "author_fullname": "t2_cfkvcut4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collection of rare vintage documentaries, films, and television shows primarily from the 1980s and early 1990s.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fy7sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 208, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 208, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683928225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings fellow data hoarders, I recently have come across a channel on  youtube with a collection of several vintage documentaries, films, and television shows, predominantly hailing from the 1980s and early 1990s. As such the depth and niche quality of this collection is notable, presenting a fascinating  snapshot of a bygone era with a lot of media dealing with esoteric matters such as the uap phenomenon and adjacent topics. Interestingly, it appears that much of this material has been  meticulously restored from original VHS copies, contributing to its  rarity and underscoring the critical need for archiving. Given the  historical and cultural value of such content, coupled with its scarcity  in contemporary digital repositories, I strongly advocate for its  preservation. As we have become unfortunately aware the unpredictable nature of content hosting policies on platforms such  as YouTube further compounds the urgency of this endeavor, as the  channel might face an untimely takedown.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Regrettably, I&amp;#39;m currently unable to personally undertake the task of  backing up this unique channel due to limitations in my data storage  capabilities. However, I felt compelled to utilize this Free Post Friday  as a platform to disseminate this discovery amongst our community, in  the hope that it piques your interest and prompts collective action  towards preserving&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The channel in question :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/@orphicunknown\"&gt;https://www.youtube.com/@orphicunknown&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?auto=webp&amp;v=enabled&amp;s=e732428c48be6280c63f8ec3e5de5014871e4e07", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a21410c84841dc636a023b4fdc2bce512dafbbd4", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f56f0347eaa8a27b9a162561377e9d0a9da453fc", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76d062f35ee77c4d8480a47f46df67e3016dec9f", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e63b6ad213b9411693e158ce4abab5d37374dee8", "width": 640, "height": 640}], "variants": {}, "id": "KCdNu0XH7wrnSEywYvkr_n8L4W_P4un5VT9_xWskexc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fy7sv", "is_robot_indexable": true, "report_reasons": null, "author": "pizzawithlowram", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fy7sv/collection_of_rare_vintage_documentaries_films/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fy7sv/collection_of_rare_vintage_documentaries_films/", "subreddit_subscribers": 682293, "created_utc": 1683928225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ddi2z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "XeNTaX, game file format and hacking wiki and forum, considering shutting down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gbh6i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 167, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Archive?", "can_mod_post": false, "score": 167, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1683965775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forum.xentax.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forum.xentax.com/viewtopic.php?t=26759", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13gbh6i", "is_robot_indexable": true, "report_reasons": null, "author": "breakingcups", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gbh6i/xentax_game_file_format_and_hacking_wiki_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forum.xentax.com/viewtopic.php?t=26759", "subreddit_subscribers": 682293, "created_utc": 1683965775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "45Drives here back to get your input once again on the homelab server development.\n\nIf you missed the last two posts you can check out part one [here](https://www.reddit.com/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/) and part two [here](https://www.reddit.com/r/DataHoarder/comments/13c1m2s/followup_on_45drives_homelab_server_project_part_2/).  \n\nIn summary, we wish to create a data storage system that would bridge the gap between cheap home NAS boxes and our enterprise servers. We thought the best way to figure out what you wanted was to ask. So, we did, and we got a great response. Thanks to everybody that has given their input. So far, we\u2019ve heard the following:\n\n1. 2U or 4U form factor;\n2. strong interest in a chassis only model;\n3. 12 drives minimum;\n4. 3.5 drive slots with optional caddies for 2.5\n\nOur third question is about homelab networking. Network throughput is a critical factor in determining the choice of electronics in a storage server. If designing a storage-only system for enterprise use, any computing or memory capacity that gives performance that exceed the network\u2019s capacity is of little value, adding cost without performance. If other services are to be added to the server, that all changes of course.  It is trivial to build a server that can saturate a 1Gb/sec connection. It is easy to saturate 10Gb/sec as well, although it takes a little bit of effort to saturate 10Gb/sec with a single client transfer.   We have clients who have put out 100Gb/sec from a single server, but this is challenging.\n\nWhat we are wondering is what sort of network performance is of interest to the homelabs community?    1Gb/sec networking is dirt cheap, whereas 100 can really hurt the bank account. \n\nSo we ask:\n\na). What networking do you have in your homelab?\n\nb). What sort of data throughput would you like to achieve from your homelab server?\n\nThanks for reading this, and we appreciate any input you are willing to offer us", "author_fullname": "t2_hcrp0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Homelab Server Follow-up. 45Drives Here Looking For Your Input", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fvedc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": "", "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683921639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;45Drives here back to get your input once again on the homelab server development.&lt;/p&gt;\n\n&lt;p&gt;If you missed the last two posts you can check out part one &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/\"&gt;here&lt;/a&gt; and part two &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13c1m2s/followup_on_45drives_homelab_server_project_part_2/\"&gt;here&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;In summary, we wish to create a data storage system that would bridge the gap between cheap home NAS boxes and our enterprise servers. We thought the best way to figure out what you wanted was to ask. So, we did, and we got a great response. Thanks to everybody that has given their input. So far, we\u2019ve heard the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;2U or 4U form factor;&lt;/li&gt;\n&lt;li&gt;strong interest in a chassis only model;&lt;/li&gt;\n&lt;li&gt;12 drives minimum;&lt;/li&gt;\n&lt;li&gt;3.5 drive slots with optional caddies for 2.5&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our third question is about homelab networking. Network throughput is a critical factor in determining the choice of electronics in a storage server. If designing a storage-only system for enterprise use, any computing or memory capacity that gives performance that exceed the network\u2019s capacity is of little value, adding cost without performance. If other services are to be added to the server, that all changes of course.  It is trivial to build a server that can saturate a 1Gb/sec connection. It is easy to saturate 10Gb/sec as well, although it takes a little bit of effort to saturate 10Gb/sec with a single client transfer.   We have clients who have put out 100Gb/sec from a single server, but this is challenging.&lt;/p&gt;\n\n&lt;p&gt;What we are wondering is what sort of network performance is of interest to the homelabs community?    1Gb/sec networking is dirt cheap, whereas 100 can really hurt the bank account. &lt;/p&gt;\n\n&lt;p&gt;So we ask:&lt;/p&gt;\n\n&lt;p&gt;a). What networking do you have in your homelab?&lt;/p&gt;\n\n&lt;p&gt;b). What sort of data throughput would you like to achieve from your homelab server?&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading this, and we appreciate any input you are willing to offer us&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13fvedc", "is_robot_indexable": true, "report_reasons": null, "author": "cmcgean45", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13fvedc/homelab_server_followup_45drives_here_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fvedc/homelab_server_followup_45drives_here_looking_for/", "subreddit_subscribers": 682293, "created_utc": 1683921639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_tquddxmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "New Exos x18 18TB showing 16TB space? What could be the issue? Older 18TB working perfectly!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2z3inildllza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/2z3inildllza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=679a12017b143c54e751dd826442a7993efc75c7"}, {"y": 125, "x": 216, "u": "https://preview.redd.it/2z3inildllza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7099ac16cf5763fc6747b1aca6452f3dcda8c1cb"}, {"y": 186, "x": 320, "u": "https://preview.redd.it/2z3inildllza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db8a8ac4966dc11765cb22cd142617d854505ea0"}, {"y": 372, "x": 640, "u": "https://preview.redd.it/2z3inildllza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4217a779fe6fe51cb2cd9d502aa861f5441262f9"}, {"y": 558, "x": 960, "u": "https://preview.redd.it/2z3inildllza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e9739d710a37504f500abb12d2b1c8435192c8b"}, {"y": 627, "x": 1080, "u": "https://preview.redd.it/2z3inildllza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b22f5de99489d141e3f10be4fa01af0bbb119b2a"}], "s": {"y": 840, "x": 1445, "u": "https://preview.redd.it/2z3inildllza1.png?width=1445&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c8d4a8066b6f83ed1887d9cf044ca21b017b314d"}, "id": "2z3inildllza1"}, "lucn852yllza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/lucn852yllza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6f252c4b353a1f0a3227005750f60653e0e1a5"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/lucn852yllza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ebce4c1739c9aa69a633f71adc42997140ae2f6"}, {"y": 159, "x": 320, "u": "https://preview.redd.it/lucn852yllza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c976ea5f99f2e30e281e635bfeeabd4c42d36ae"}, {"y": 318, "x": 640, "u": "https://preview.redd.it/lucn852yllza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea15330baaffba0620cb2624eb03a6e1c2117a45"}, {"y": 477, "x": 960, "u": "https://preview.redd.it/lucn852yllza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6660578610ff73d304a8d643c7cf97f5ab8a92ca"}, {"y": 537, "x": 1080, "u": "https://preview.redd.it/lucn852yllza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dea1faf37eff47ccf57721001146ef3c49ee62f0"}], "s": {"y": 740, "x": 1488, "u": "https://preview.redd.it/lucn852yllza1.png?width=1488&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d0e8f32d0b6f5c911772c3c140cd80fb81aa7b4e"}, "id": "lucn852yllza1"}, "i1z1riqyllza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 91, "x": 108, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8862fbf3ef7e884caf8db018ca23a535276b066e"}, {"y": 182, "x": 216, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4d281c69ad87041b6edb93f8f5d6aa563a4cc54"}, {"y": 270, "x": 320, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15ff38cc3603444f9e7d9dd1582fe56c1248d491"}, {"y": 540, "x": 640, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25947d3b6d30270e9dc7ba78f49270aea764d81d"}, {"y": 810, "x": 960, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d4f92082da11fefac3eab543c66193e5129359a"}, {"y": 912, "x": 1080, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a56a2961adee4b48dc1d8627e4b65da978c7682"}], "s": {"y": 1044, "x": 1236, "u": "https://preview.redd.it/i1z1riqyllza1.png?width=1236&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fea80a1396bee5a018345e266f8f3cb5437ab09d"}, "id": "i1z1riqyllza1"}, "2y091ttyllza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 82, "x": 108, "u": "https://preview.redd.it/2y091ttyllza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73f1d0d50e1bdfbb26b15622f050833f788a5d4a"}, {"y": 165, "x": 216, "u": "https://preview.redd.it/2y091ttyllza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45e67e1f9090390eee12fcdfa725726a4eb26048"}, {"y": 244, "x": 320, "u": "https://preview.redd.it/2y091ttyllza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=610b87daa98738416c48079630881d16ba560e56"}, {"y": 489, "x": 640, "u": "https://preview.redd.it/2y091ttyllza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2af15d4499a598d8b5bd12837dd48884885c5bd"}, {"y": 733, "x": 960, "u": "https://preview.redd.it/2y091ttyllza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c8916865528383089f3c3bd0c830f110fa4a10e"}], "s": {"y": 755, "x": 988, "u": "https://preview.redd.it/2y091ttyllza1.png?width=988&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f132263b5cf999845da20831d40c17da92f6863b"}, "id": "2y091ttyllza1"}}, "name": "t3_13gh8sf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 65, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "2z3inildllza1", "id": 274634940}, {"media_id": "lucn852yllza1", "id": 274634941}, {"media_id": "i1z1riqyllza1", "id": 274634942}, {"media_id": "2y091ttyllza1", "id": 274634943}]}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UuHgYSARP-7K4di8uURHlBBgTka7OpkbRDplK5z9gDo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683983534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13gh8sf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gh8sf", "is_robot_indexable": true, "report_reasons": null, "author": "mad_ratzz", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gh8sf/new_exos_x18_18tb_showing_16tb_space_what_could/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13gh8sf", "subreddit_subscribers": 682293, "created_utc": 1683983534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife was wanting to pay for  for a cloud photo service, but looking at the price per GB, I feel like there has to be a cheaper and easier way. Is there like a NAS type system I could use? Sorry for the questions, I'm never done any of this type of stuff but I am fairly computer literate", "author_fullname": "t2_e1bhrebh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to create a mass photo storage system that can be accessed anywhere?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g6tj0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683951126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife was wanting to pay for  for a cloud photo service, but looking at the price per GB, I feel like there has to be a cheaper and easier way. Is there like a NAS type system I could use? Sorry for the questions, I&amp;#39;m never done any of this type of stuff but I am fairly computer literate&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g6tj0", "is_robot_indexable": true, "report_reasons": null, "author": "baseballandpcs", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g6tj0/is_there_a_way_to_create_a_mass_photo_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g6tj0/is_there_a_way_to_create_a_mass_photo_storage/", "subreddit_subscribers": 682293, "created_utc": 1683951126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just did a large transfer 16TB over to a new larger HDD. I used Teracopy and was wondering...\n\nWhen all files are selected on the source and the destination side and the folder/file sizes are exactly the same down to the byte...Is the verification process still necessary?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File sizes are exact down to the byte, Teracopy verification still necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g3zym", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683943032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just did a large transfer 16TB over to a new larger HDD. I used Teracopy and was wondering...&lt;/p&gt;\n\n&lt;p&gt;When all files are selected on the source and the destination side and the folder/file sizes are exactly the same down to the byte...Is the verification process still necessary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g3zym", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3zym/file_sizes_are_exact_down_to_the_byte_teracopy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3zym/file_sizes_are_exact_down_to_the_byte_teracopy/", "subreddit_subscribers": 682293, "created_utc": 1683943032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have multiple Reddit accounts from which I'd like to download all the saved and upvoted posts from. Also some subreddits that I'd like to archive.\n\nI think BDFR is the most robust with lots of different features, but it has some oddities. As I tried to download all my saved posts, it kept running into a \"duplicate comment\" error that caused it to stop downloading around 300 posts. If I re-ran it, it would also go through every single post and check if it's been downloaded (which would take like 10 minutes for 300 posts) and then fail at the same place.\n\nIs there any better alternative? Also how would I download my posts or a subreddit's posts if there are more than 1000 of them?", "author_fullname": "t2_13kdlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to download all Imgur Reddit posts beyond 1000 post limit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fy9x5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683928366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have multiple Reddit accounts from which I&amp;#39;d like to download all the saved and upvoted posts from. Also some subreddits that I&amp;#39;d like to archive.&lt;/p&gt;\n\n&lt;p&gt;I think BDFR is the most robust with lots of different features, but it has some oddities. As I tried to download all my saved posts, it kept running into a &amp;quot;duplicate comment&amp;quot; error that caused it to stop downloading around 300 posts. If I re-ran it, it would also go through every single post and check if it&amp;#39;s been downloaded (which would take like 10 minutes for 300 posts) and then fail at the same place.&lt;/p&gt;\n\n&lt;p&gt;Is there any better alternative? Also how would I download my posts or a subreddit&amp;#39;s posts if there are more than 1000 of them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fy9x5", "is_robot_indexable": true, "report_reasons": null, "author": "seahorsejoe", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fy9x5/best_way_to_download_all_imgur_reddit_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fy9x5/best_way_to_download_all_imgur_reddit_posts/", "subreddit_subscribers": 682293, "created_utc": 1683928366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With Reddit recently signaling it will paywall api access. I am curious to know, which is the last, full archive of Reddit. I feel that anything past 2022 would be a great historical document of the current era that I would save in my vault.", "author_fullname": "t2_msvx0qnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most recent, known, complete archive of all Reddit texts ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fusb9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683920155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With Reddit recently signaling it will paywall api access. I am curious to know, which is the last, full archive of Reddit. I feel that anything past 2022 would be a great historical document of the current era that I would save in my vault.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13fusb9", "is_robot_indexable": true, "report_reasons": null, "author": "transdimensionalmeme", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fusb9/what_is_the_most_recent_known_complete_archive_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fusb9/what_is_the_most_recent_known_complete_archive_of/", "subreddit_subscribers": 682293, "created_utc": 1683920155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ucst1pa3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We have backed up the world\u2019s largest comics shadow library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_13gn07s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hmXUnF_Q3dc-xFXtgtWStrwbNDsjn9dakdnqyIVwZlU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683997738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "annas-blog.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://annas-blog.org/backed-up-the-worlds-largest-comics-shadow-lib.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/40n9LDd7IdrWGJNvbmuthNDd_0fP0tbWFAPipHBCNPM.jpg?auto=webp&amp;v=enabled&amp;s=03095ab28bac0d537d47574e7e167893a3616e0c", "width": 513, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/40n9LDd7IdrWGJNvbmuthNDd_0fP0tbWFAPipHBCNPM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba14eba794b44a8f4b164b67200f60da5e4622ca", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/40n9LDd7IdrWGJNvbmuthNDd_0fP0tbWFAPipHBCNPM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1dc460c2dae35dc23a82f1e6cb7a776f2c5cd84d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/40n9LDd7IdrWGJNvbmuthNDd_0fP0tbWFAPipHBCNPM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81a9cf73b54b0655cc611cf2f5e5b762524a3912", "width": 320, "height": 168}], "variants": {}, "id": "PPuw_FdXbP9HAeq2KFtJRhMY2cwn9i3h5pWIQndrkBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gn07s", "is_robot_indexable": true, "report_reasons": null, "author": "AnnaArchivist", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gn07s/we_have_backed_up_the_worlds_largest_comics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://annas-blog.org/backed-up-the-worlds-largest-comics-shadow-lib.html", "subreddit_subscribers": 682293, "created_utc": 1683997738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can't resolve archive.is using Cloudflare's DNS. It works when using Google's DNS or Quad-9. \n\nAnyone else having this issue?\n\n    $ nslookup\n    &gt; server 8.8.8.8\n    Default server: 8.8.8.8\n    Address: 8.8.8.8#53\n    &gt; archive.is\n    Server:         8.8.8.8\n    Address:        8.8.8.8#53\n    \n    Non-authoritative answer:\n    Name:   archive.is\n    Address: 130.0.232.208\n    &gt; server 1.1.1.1\n    Default server: 1.1.1.1\n    Address: 1.1.1.1#53\n    &gt; archive.is\n    Server:         1.1.1.1\n    Address:        1.1.1.1#53\n    \n    Non-authoritative answer:\n    *** Can't find archive.is: No answer\n    &gt; server 9.9.9.9\n    Default server: 9.9.9.9\n    Address: 9.9.9.9#53\n    &gt; archive.is\n    Server:         9.9.9.9\n    Address:        9.9.9.9#53\n    \n    Non-authoritative answer:\n    Name:   archive.is\n    Address: 51.79.250.183\n    &gt; server 1.0.0.1\n    Default server: 1.0.0.1\n    Address: 1.0.0.1#53\n    &gt; archive.is\n    Server:         1.0.0.1\n    Address:        1.0.0.1#53\n    \n    Non-authoritative answer:\n    *** Can't find archive.is: No answer\n    &gt; ^D", "author_fullname": "t2_7srpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudflare DNS blocking archive.is?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g4htv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683944412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t resolve archive.is using Cloudflare&amp;#39;s DNS. It works when using Google&amp;#39;s DNS or Quad-9. &lt;/p&gt;\n\n&lt;p&gt;Anyone else having this issue?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ nslookup\n&amp;gt; server 8.8.8.8\nDefault server: 8.8.8.8\nAddress: 8.8.8.8#53\n&amp;gt; archive.is\nServer:         8.8.8.8\nAddress:        8.8.8.8#53\n\nNon-authoritative answer:\nName:   archive.is\nAddress: 130.0.232.208\n&amp;gt; server 1.1.1.1\nDefault server: 1.1.1.1\nAddress: 1.1.1.1#53\n&amp;gt; archive.is\nServer:         1.1.1.1\nAddress:        1.1.1.1#53\n\nNon-authoritative answer:\n*** Can&amp;#39;t find archive.is: No answer\n&amp;gt; server 9.9.9.9\nDefault server: 9.9.9.9\nAddress: 9.9.9.9#53\n&amp;gt; archive.is\nServer:         9.9.9.9\nAddress:        9.9.9.9#53\n\nNon-authoritative answer:\nName:   archive.is\nAddress: 51.79.250.183\n&amp;gt; server 1.0.0.1\nDefault server: 1.0.0.1\nAddress: 1.0.0.1#53\n&amp;gt; archive.is\nServer:         1.0.0.1\nAddress:        1.0.0.1#53\n\nNon-authoritative answer:\n*** Can&amp;#39;t find archive.is: No answer\n&amp;gt; ^D\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g4htv", "is_robot_indexable": true, "report_reasons": null, "author": "maomaocat", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g4htv/cloudflare_dns_blocking_archiveis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g4htv/cloudflare_dns_blocking_archiveis/", "subreddit_subscribers": 682293, "created_utc": 1683944412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_jrsci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google's weekly update says the new pooled storage causing the over quota messages is only for Business Starter accounts, not Enterprise Standard ones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gjlio", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1683989559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "workspaceupdates.googleblog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://workspaceupdates.googleblog.com/2023/05/release-notes-05-12-2023.html?m=1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gjlio", "is_robot_indexable": true, "report_reasons": null, "author": "erm_what_", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gjlio/googles_weekly_update_says_the_new_pooled_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://workspaceupdates.googleblog.com/2023/05/release-notes-05-12-2023.html?m=1", "subreddit_subscribers": 682293, "created_utc": 1683989559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for a way to archive some subreddits because of imgur. I've tried one method but it didn't work out for me at all. I got a 12tb hdd that i'm willing to fill up all the way.", "author_fullname": "t2_w94iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the easiest way to archive a subreddit's images/videos/galleries for someone who isn't good at commandline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g3wd9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683942755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a way to archive some subreddits because of imgur. I&amp;#39;ve tried one method but it didn&amp;#39;t work out for me at all. I got a 12tb hdd that i&amp;#39;m willing to fill up all the way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13g3wd9", "is_robot_indexable": true, "report_reasons": null, "author": "FuriousKimchi", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3wd9/whats_the_easiest_way_to_archive_a_subreddits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3wd9/whats_the_easiest_way_to_archive_a_subreddits/", "subreddit_subscribers": 682293, "created_utc": 1683942755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I'm looking into ways to encrypt my files.  \n I want to find something that can safely resist brute-force attacks. Is AES in 7zip a safe enough implementation?\n\nPersonally I use an alternative (NanaZip) currently. I would like to know if I'm not making a mistake attempting to encrypt using this program. I would want to keep my private data safe (my job requires this) and not compromise it because if improper implementation.\n\nOf course I can always compress and then encrypt my files separately. So I'm open for suggestions if there are any seriously more secure alternatives to this implementation of AES-256 (not less than 256).\n\nI suspect there could be even safer options. If the compromise would be speed this is not an issue. Of course only widely available options that wouldn't cause any burn. I don't suspect encryption alone would he an issue, since this should be standard now.", "author_fullname": "t2_vdfzva2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "7zip AES-256 &amp; File encryption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fwmmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683924500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m looking into ways to encrypt my files.&lt;br/&gt;\n I want to find something that can safely resist brute-force attacks. Is AES in 7zip a safe enough implementation?&lt;/p&gt;\n\n&lt;p&gt;Personally I use an alternative (NanaZip) currently. I would like to know if I&amp;#39;m not making a mistake attempting to encrypt using this program. I would want to keep my private data safe (my job requires this) and not compromise it because if improper implementation.&lt;/p&gt;\n\n&lt;p&gt;Of course I can always compress and then encrypt my files separately. So I&amp;#39;m open for suggestions if there are any seriously more secure alternatives to this implementation of AES-256 (not less than 256).&lt;/p&gt;\n\n&lt;p&gt;I suspect there could be even safer options. If the compromise would be speed this is not an issue. Of course only widely available options that wouldn&amp;#39;t cause any burn. I don&amp;#39;t suspect encryption alone would he an issue, since this should be standard now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fwmmi", "is_robot_indexable": true, "report_reasons": null, "author": "Secret_Lacerta", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fwmmi/7zip_aes256_file_encryption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fwmmi/7zip_aes256_file_encryption/", "subreddit_subscribers": 682293, "created_utc": 1683924500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,  \n\n\nMy friend passed few years ago and I need to archive his tweets before his account gets deleted (thanks elon). He was an artist so there is some media (his drawings) but I'd like to archive his entire profile even with his old posts, replies, retweets etc., and that's why I'd like to have some UI to read everything like it's on twitter.\n\nI've already used snscrape to get every tweet link, but I miss the \"visual representation of the data\". Do anyone of you know which tool can I use?\n\nThanks &lt;3", "author_fullname": "t2_9egzy7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with archiving my old friend's tweets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13gohrs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684001349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;My friend passed few years ago and I need to archive his tweets before his account gets deleted (thanks elon). He was an artist so there is some media (his drawings) but I&amp;#39;d like to archive his entire profile even with his old posts, replies, retweets etc., and that&amp;#39;s why I&amp;#39;d like to have some UI to read everything like it&amp;#39;s on twitter.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already used snscrape to get every tweet link, but I miss the &amp;quot;visual representation of the data&amp;quot;. Do anyone of you know which tool can I use?&lt;/p&gt;\n\n&lt;p&gt;Thanks &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "200TB (2x100TB) ZFS RAID6", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gohrs", "is_robot_indexable": true, "report_reasons": null, "author": "Arturro43", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13gohrs/help_with_archiving_my_old_friends_tweets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13gohrs/help_with_archiving_my_old_friends_tweets/", "subreddit_subscribers": 682293, "created_utc": 1684001349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TL:DR What is the best configuration for 4x16TB Exos drives plus 19x2TB HGST Drives in ZFS on TrueNAS SCALE?  \n\n\nSo, I currently have 16TB of data on my TrueNAS using the 2TB HGST drives  on 3x6 wide z2 VDEVS that are then synced to 2x16TB Exos drives in my main Windows PC (RAID 0) as a middle point to be backed up to Backblaze Personal. I've just got access to enough Google Drive storage (after seeing the recent Google Drive post here and realising I was on the wrong plan for my school) to be able to stop using Backblaze for my archive backup.  \n\n\nI'd already ordered an extra 2x16TB Exos drives before I got the Google Drive storage.  \n\n\nI have 10G ethernet on the TrueNAS and have been enjoying glorious speeds for video editing etc with the large number of drives. Now I have 4x16TB drives I was thinking of just setting up a mirrored VDEV with those, calling it a day, and enjoying the cheaper electricity costs buuuuut I can't just sit on 19 2TB drives and have half the speed I was enjoying before.  \n\n\nHow would you use the drives? It would be nice to retire the disk shelf and just have the Exos drives running off the motherboard SATA but part of me just wants to keep the shelf and the disks running.  \n\n\nHow can I best use the 19 extra drives to help saturate the LAN without adding too much danger to the data pool?   \n\n\nLove your work, by the way. This group has saved my life so many times....", "author_fullname": "t2_11fnzm13", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS Brain pain - Please give me a nudge in the right direction.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fzpas", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683931857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL:DR What is the best configuration for 4x16TB Exos drives plus 19x2TB HGST Drives in ZFS on TrueNAS SCALE?  &lt;/p&gt;\n\n&lt;p&gt;So, I currently have 16TB of data on my TrueNAS using the 2TB HGST drives  on 3x6 wide z2 VDEVS that are then synced to 2x16TB Exos drives in my main Windows PC (RAID 0) as a middle point to be backed up to Backblaze Personal. I&amp;#39;ve just got access to enough Google Drive storage (after seeing the recent Google Drive post here and realising I was on the wrong plan for my school) to be able to stop using Backblaze for my archive backup.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d already ordered an extra 2x16TB Exos drives before I got the Google Drive storage.  &lt;/p&gt;\n\n&lt;p&gt;I have 10G ethernet on the TrueNAS and have been enjoying glorious speeds for video editing etc with the large number of drives. Now I have 4x16TB drives I was thinking of just setting up a mirrored VDEV with those, calling it a day, and enjoying the cheaper electricity costs buuuuut I can&amp;#39;t just sit on 19 2TB drives and have half the speed I was enjoying before.  &lt;/p&gt;\n\n&lt;p&gt;How would you use the drives? It would be nice to retire the disk shelf and just have the Exos drives running off the motherboard SATA but part of me just wants to keep the shelf and the disks running.  &lt;/p&gt;\n\n&lt;p&gt;How can I best use the 19 extra drives to help saturate the LAN without adding too much danger to the data pool?   &lt;/p&gt;\n\n&lt;p&gt;Love your work, by the way. This group has saved my life so many times....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fzpas", "is_robot_indexable": true, "report_reasons": null, "author": "BerryJP", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fzpas/zfs_brain_pain_please_give_me_a_nudge_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fzpas/zfs_brain_pain_please_give_me_a_nudge_in_the/", "subreddit_subscribers": 682293, "created_utc": 1683931857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI have a full 8TB of movie rips on a hard drive (I am sure some of you are laughing right now...  but at the end of that day I might be able to *watch* at least a bit of my collection).\n\nBecause it's mostly nothing I couldn't get back, I have logged every file name inside an excel spreadsheet so that I could quickly recover everything if the drive failed - it's one thing to lose the data, it's another to not actually be sure of what is lost.\n\nSo far I have done this fair successfully.  I have copied the file names of every film and sorted them into decade sheets in Excel.  \n\nHowever it has all been done manually as well as the sorting into decade folder.\n\nFor example:\n\n&amp;#x200B;\n\n* Sheet 1:\n\n**1910s**\n\n*Out West (1918)*\n\n*Backstage (1919)*\n\n&amp;#x200B;\n\n* Sheet 2:\n\n**1920s**\n\n*Battleship Potemkin (1925)*\n\n*Faust (1926)*\n\n&amp;#x200B;\n\netc etc\n\n&amp;#x200B;\n\nHowever, I am wondering where else I can take this - I am wanting to know how, as my collection grows over time, whether I could add quickly include other features into the spreadsheet like the director of the film and other metadata like year of release to the spreadsheet and if there is another program that can do that. \n\nFor example:\n\n&amp;#x200B;\n\n|1910s|Director \\*(autopopulated)\\*|Main Actor \\*(autopopulated)\\*|\n|:-|:-|:-|\n|*Out West (1918)*|Buster Keaton|Buster Keaton|\n|*Backstage (1919)*|*Buster Keaton*|Buster Keaton|\n\n&amp;#x200B;\n\nAdditionally, whether there is a program that can auto place:\n\n&gt;1910s movies into `1910s folder`  \n&gt;  \n&gt;1920s into `1920s folder`   \n&gt;  \n&gt;etc.\n\n&amp;#x200B;\n\nIdeas and suggestions for how to assist with the organizing of my horrible hoarding disease would be great!", "author_fullname": "t2_nexio2e9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Taking stock of all the movies I have", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g3iil", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683941675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a full 8TB of movie rips on a hard drive (I am sure some of you are laughing right now...  but at the end of that day I might be able to &lt;em&gt;watch&lt;/em&gt; at least a bit of my collection).&lt;/p&gt;\n\n&lt;p&gt;Because it&amp;#39;s mostly nothing I couldn&amp;#39;t get back, I have logged every file name inside an excel spreadsheet so that I could quickly recover everything if the drive failed - it&amp;#39;s one thing to lose the data, it&amp;#39;s another to not actually be sure of what is lost.&lt;/p&gt;\n\n&lt;p&gt;So far I have done this fair successfully.  I have copied the file names of every film and sorted them into decade sheets in Excel.  &lt;/p&gt;\n\n&lt;p&gt;However it has all been done manually as well as the sorting into decade folder.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sheet 1:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;1910s&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Out West (1918)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Backstage (1919)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sheet 2:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;1920s&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Battleship Potemkin (1925)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Faust (1926)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;etc etc&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, I am wondering where else I can take this - I am wanting to know how, as my collection grows over time, whether I could add quickly include other features into the spreadsheet like the director of the film and other metadata like year of release to the spreadsheet and if there is another program that can do that. &lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;1910s&lt;/th&gt;\n&lt;th align=\"left\"&gt;Director *(autopopulated)*&lt;/th&gt;\n&lt;th align=\"left\"&gt;Main Actor *(autopopulated)*&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Out West (1918)&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Backstage (1919)&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Buster Keaton&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, whether there is a program that can auto place:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;1910s movies into &lt;code&gt;1910s folder&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;1920s into &lt;code&gt;1920s folder&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ideas and suggestions for how to assist with the organizing of my horrible hoarding disease would be great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g3iil", "is_robot_indexable": true, "report_reasons": null, "author": "Warm-Sugar3726", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3iil/taking_stock_of_all_the_movies_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3iil/taking_stock_of_all_the_movies_i_have/", "subreddit_subscribers": 682293, "created_utc": 1683941675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "current firmware is 20221022, worried about being unable to use 3rd party toner cartridges.   HPs website doesn't list prior firmware so I was hoping someone here may have saved an older firmware download.", "author_fullname": "t2_vbtme", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking older firmware for HP Laser Printer M477fnw", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g31gq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683940392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;current firmware is 20221022, worried about being unable to use 3rd party toner cartridges.   HPs website doesn&amp;#39;t list prior firmware so I was hoping someone here may have saved an older firmware download.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g31gq", "is_robot_indexable": true, "report_reasons": null, "author": "sdp1981", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g31gq/seeking_older_firmware_for_hp_laser_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g31gq/seeking_older_firmware_for_hp_laser_printer/", "subreddit_subscribers": 682293, "created_utc": 1683940392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "2 years ago, I digitized a couple of private video VHS tapes from 2000 to 2005. I just rewatched some footage and noticed some \"errors\". They only happen rarely and I think they happen when the camera was moved a bit quicker. It is nothing like this: [https://www.youtube.com/watch?v=JDu9QJY5ShE](https://www.youtube.com/watch?v=JDu9QJY5ShE)\n\nThe errors last like 5-10 frames.\n\nGallery of some frames: [https://imgur.com/a/MUTibd2](https://imgur.com/a/MUTibd2)\n\nI just want to make sure there was nothing wrong in my digitizing process. I used the original VHS recorder from back then and a rather cheap \"analog-to-digital\" converter via USB and OBS with no fancy settings I think. The errors happen very rarely and I guess they were caused at capturing time.", "author_fullname": "t2_1i4adnqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VHS tapes digitized. Are these normal \"image errors\" from back then?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gip53", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683987243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;2 years ago, I digitized a couple of private video VHS tapes from 2000 to 2005. I just rewatched some footage and noticed some &amp;quot;errors&amp;quot;. They only happen rarely and I think they happen when the camera was moved a bit quicker. It is nothing like this: &lt;a href=\"https://www.youtube.com/watch?v=JDu9QJY5ShE\"&gt;https://www.youtube.com/watch?v=JDu9QJY5ShE&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The errors last like 5-10 frames.&lt;/p&gt;\n\n&lt;p&gt;Gallery of some frames: &lt;a href=\"https://imgur.com/a/MUTibd2\"&gt;https://imgur.com/a/MUTibd2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I just want to make sure there was nothing wrong in my digitizing process. I used the original VHS recorder from back then and a rather cheap &amp;quot;analog-to-digital&amp;quot; converter via USB and OBS with no fancy settings I think. The errors happen very rarely and I guess they were caused at capturing time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kvpcD3HNu_nGDPz0mkXOxuBTzB-mDNICy1NTaMTz434.jpg?auto=webp&amp;v=enabled&amp;s=ccb6b433f3e7215dd1eb8a076ccc95f0d0d0731a", "width": 720, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/kvpcD3HNu_nGDPz0mkXOxuBTzB-mDNICy1NTaMTz434.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8453cb3200698fe399c64746e42d498705dc37a2", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/kvpcD3HNu_nGDPz0mkXOxuBTzB-mDNICy1NTaMTz434.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ffe63f731caedc95825e478714034a1522b3491b", "width": 216, "height": 172}, {"url": "https://external-preview.redd.it/kvpcD3HNu_nGDPz0mkXOxuBTzB-mDNICy1NTaMTz434.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9bf4c671bfb9d3f7fd2def6cc730a0a3b180a9e", "width": 320, "height": 256}, {"url": "https://external-preview.redd.it/kvpcD3HNu_nGDPz0mkXOxuBTzB-mDNICy1NTaMTz434.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57b35c5a8fc554204d3fbc942a1312c3790be5ae", "width": 640, "height": 512}], "variants": {}, "id": "63drhBqKzVbSQ--_fYOPYsD8-pXJy-xlpFhSuoOwdl8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gip53", "is_robot_indexable": true, "report_reasons": null, "author": "Stromkompressor", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gip53/vhs_tapes_digitized_are_these_normal_image_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13gip53/vhs_tapes_digitized_are_these_normal_image_errors/", "subreddit_subscribers": 682293, "created_utc": 1683987243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I\u2019m considering buying helium filled HDDs for my home NAS, but I\u2019m little bit afraid of the helium filling longevity. I\u2019m unable to find any real data about longevity of those disks. I know that the warranty is 5 years, but is it realistic for them to last for 7 or even 10 years (before the helium escapes from the enclosure)? \nIs it worth it to go with helium filled HDDs, or is it better to sty conservative and rather choose classic air filled HDDs?\nI would be grateful, if anybody here could share their experience with helium filled drives.\nThanks", "author_fullname": "t2_51m9k164", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the lifespan of helium filled HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fumdp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683919773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m considering buying helium filled HDDs for my home NAS, but I\u2019m little bit afraid of the helium filling longevity. I\u2019m unable to find any real data about longevity of those disks. I know that the warranty is 5 years, but is it realistic for them to last for 7 or even 10 years (before the helium escapes from the enclosure)? \nIs it worth it to go with helium filled HDDs, or is it better to sty conservative and rather choose classic air filled HDDs?\nI would be grateful, if anybody here could share their experience with helium filled drives.\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fumdp", "is_robot_indexable": true, "report_reasons": null, "author": "kiwwi24_PSVR", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fumdp/what_is_the_lifespan_of_helium_filled_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fumdp/what_is_the_lifespan_of_helium_filled_hdds/", "subreddit_subscribers": 682293, "created_utc": 1683919773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Please share if you do", "author_fullname": "t2_6m84ad7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Know any Windows hash tool that supports xxh3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g05i1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683932953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please share if you do&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g05i1", "is_robot_indexable": true, "report_reasons": null, "author": "Jungy1eong", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g05i1/know_any_windows_hash_tool_that_supports_xxh3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g05i1/know_any_windows_hash_tool_that_supports_xxh3/", "subreddit_subscribers": 682293, "created_utc": 1683932953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a Drobo 5D3 that I've been using for 5 years or so and quite liked it, even if it was a bit finnicky at times.  That being said, aside from it being time for an upgrade we all know where Drobo is going, so the sooner I can get off it the better.\n\nI'm looking for a DAS as so far the Drobo is populated with standard desktop drives that I don't trust running 24/7 in a NAS, and I already have a NAS project I'm building with a bunch of  smaller NAS drives.\n\nI'd like to be able to use it with both my M1 Mac and Windows PCs, so would prefer a hardware RAID solution.  I'd also like to have it be Thunderbolt and 10GB/s USB-C compatible -- M1 Mac has Thunderbolt and, while the current PC doesn't my planned upgrade will have Thunderbolt.\n\nI have 5 drives in the Drobo and 3 more drives new in box, so 8 bay would be fantastic but smaller is also fine.\n\nSo far I've seen the following:\n\n[OWC Thunderbay 8](https://www.amazon.com/OWC-ThunderBay-8-Bay-External-Thunderbolt/dp/B084S3S8JC?spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUFCMVgzMlZXR0JZU1kmZW5jcnlwdGVkSWQ9QTA4Njc3ODlCVlU5UzNVRzVNREgmZW5jcnlwdGVkQWRJZD1BMDk4NjQyMDFaQ0Y3R0FBRE9DR0gmd2lkZ2V0TmFtZT1zcF9hdGYmYWN0aW9uPWNsaWNrUmVkaXJlY3QmZG9Ob3RMb2dDbGljaz10cnVl&amp;linkId=e5455e043ae2e9f5ce392b051ea24ac8&amp;language=en_US) \\-- SoftRAID but at least it is cross platform\n\n[TerraMaster D5](https://www.amazon.com/TerraMaster-Thunderbolt-Professional-Grade-External-Enclosure/dp/B07BHMCWMS?spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUFQM1NLTDA0TDQ3MTgmZW5jcnlwdGVkSWQ9QTA2ODMwMTQxTDVBM01YNkRTMllFJmVuY3J5cHRlZEFkSWQ9QTAzOTAwNTIxUkU2TlhBSkVQTEpDJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ&amp;linkId=4bc4c586cd1c3d9e72f91ad0ef379829&amp;language=en_US)\n\nAny other thoughts?", "author_fullname": "t2_3sdmz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drobo DAS alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13gp4ec", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684002902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a Drobo 5D3 that I&amp;#39;ve been using for 5 years or so and quite liked it, even if it was a bit finnicky at times.  That being said, aside from it being time for an upgrade we all know where Drobo is going, so the sooner I can get off it the better.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a DAS as so far the Drobo is populated with standard desktop drives that I don&amp;#39;t trust running 24/7 in a NAS, and I already have a NAS project I&amp;#39;m building with a bunch of  smaller NAS drives.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to use it with both my M1 Mac and Windows PCs, so would prefer a hardware RAID solution.  I&amp;#39;d also like to have it be Thunderbolt and 10GB/s USB-C compatible -- M1 Mac has Thunderbolt and, while the current PC doesn&amp;#39;t my planned upgrade will have Thunderbolt.&lt;/p&gt;\n\n&lt;p&gt;I have 5 drives in the Drobo and 3 more drives new in box, so 8 bay would be fantastic but smaller is also fine.&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve seen the following:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/OWC-ThunderBay-8-Bay-External-Thunderbolt/dp/B084S3S8JC?spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUFCMVgzMlZXR0JZU1kmZW5jcnlwdGVkSWQ9QTA4Njc3ODlCVlU5UzNVRzVNREgmZW5jcnlwdGVkQWRJZD1BMDk4NjQyMDFaQ0Y3R0FBRE9DR0gmd2lkZ2V0TmFtZT1zcF9hdGYmYWN0aW9uPWNsaWNrUmVkaXJlY3QmZG9Ob3RMb2dDbGljaz10cnVl&amp;amp;linkId=e5455e043ae2e9f5ce392b051ea24ac8&amp;amp;language=en_US\"&gt;OWC Thunderbay 8&lt;/a&gt; -- SoftRAID but at least it is cross platform&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/TerraMaster-Thunderbolt-Professional-Grade-External-Enclosure/dp/B07BHMCWMS?spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUFQM1NLTDA0TDQ3MTgmZW5jcnlwdGVkSWQ9QTA2ODMwMTQxTDVBM01YNkRTMllFJmVuY3J5cHRlZEFkSWQ9QTAzOTAwNTIxUkU2TlhBSkVQTEpDJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ&amp;amp;linkId=4bc4c586cd1c3d9e72f91ad0ef379829&amp;amp;language=en_US\"&gt;TerraMaster D5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any other thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gp4ec", "is_robot_indexable": true, "report_reasons": null, "author": "fuzzycuffs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gp4ec/drobo_das_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13gp4ec/drobo_das_alternative/", "subreddit_subscribers": 682293, "created_utc": 1684002902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there.\n\n\nI need to backup mostly photos if that matters. videos, text files comes next, and everything else later.\n\n\nCurrently I have them separated in folders which I don't ever touch but there's few folders where I just add one or two photos every once in a while.\n\nNow when I backup them I select all and paste into my backup location and then I keep on clicking on skip that, skip that, skip these, when only I need to backup new ones. \n\n\nWindows 10 x64 pro. Source: sata hdd, Destination: usb 3.0 to sata dock hdd.\n\n\nSuggestions on software which will keep track only new files and backup those?\n\n\n**EDIT: solved. I'll just use windows file history**", "author_fullname": "t2_ghruo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Software]Need to simply backup files.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gm7o0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683999746.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683995843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there.&lt;/p&gt;\n\n&lt;p&gt;I need to backup mostly photos if that matters. videos, text files comes next, and everything else later.&lt;/p&gt;\n\n&lt;p&gt;Currently I have them separated in folders which I don&amp;#39;t ever touch but there&amp;#39;s few folders where I just add one or two photos every once in a while.&lt;/p&gt;\n\n&lt;p&gt;Now when I backup them I select all and paste into my backup location and then I keep on clicking on skip that, skip that, skip these, when only I need to backup new ones. &lt;/p&gt;\n\n&lt;p&gt;Windows 10 x64 pro. Source: sata hdd, Destination: usb 3.0 to sata dock hdd.&lt;/p&gt;\n\n&lt;p&gt;Suggestions on software which will keep track only new files and backup those?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT: solved. I&amp;#39;ll just use windows file history&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2TB+4TB+16TB+6TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gm7o0", "is_robot_indexable": true, "report_reasons": null, "author": "Svetimsalis", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13gm7o0/softwareneed_to_simply_backup_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13gm7o0/softwareneed_to_simply_backup_files/", "subreddit_subscribers": 682293, "created_utc": 1683995843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am thinking on getting myself a off the shelf NAS since I don't have access to an old PC. In this case either the Synology 923+ or QNAP TS-464. Still trying to decide which one is better for my need as a NAS and plex/jellyfin server. \n\nNow for the drives I am currently debating between two options either buying HDD enclosures and shucking them or buying recertified HDD from Serverpartdeals.\n\nWhich one should I go with?", "author_fullname": "t2_mkw8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one is better? Buying and shucking drives or recertified drives from a reputable seller?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g1yd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683937472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking on getting myself a off the shelf NAS since I don&amp;#39;t have access to an old PC. In this case either the Synology 923+ or QNAP TS-464. Still trying to decide which one is better for my need as a NAS and plex/jellyfin server. &lt;/p&gt;\n\n&lt;p&gt;Now for the drives I am currently debating between two options either buying HDD enclosures and shucking them or buying recertified HDD from Serverpartdeals.&lt;/p&gt;\n\n&lt;p&gt;Which one should I go with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g1yd8", "is_robot_indexable": true, "report_reasons": null, "author": "TheUnluckyGamer13", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g1yd8/which_one_is_better_buying_and_shucking_drives_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g1yd8/which_one_is_better_buying_and_shucking_drives_or/", "subreddit_subscribers": 682293, "created_utc": 1683937472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Whenever i want to acces my external ssd on my phone it sometimes works and sometimes not. Ive allready checked if that happens if the phone battery is below 50% but doesnt seem to be. Anyone knows why ?", "author_fullname": "t2_am2g29s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connecting external ssd to android phone works randomly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fuqbf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683920026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whenever i want to acces my external ssd on my phone it sometimes works and sometimes not. Ive allready checked if that happens if the phone battery is below 50% but doesnt seem to be. Anyone knows why ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fuqbf", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Insect54", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fuqbf/connecting_external_ssd_to_android_phone_works/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fuqbf/connecting_external_ssd_to_android_phone_works/", "subreddit_subscribers": 682293, "created_utc": 1683920026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nPlease could someone help me? I have 3 drives connected on the network, Windows 11. I would like those drives to sync completely with an external USB drive that I have connected.\n\nIs that possible? I don't want it to just back up, I want it to sync e.g. if I delete a file from the network drive, it is deleted from the USB drive.\n\n&amp;#x200B;\n\n(seen these recommended on another post, would one of these work and is one better than the other?  \n\nRCLONE\n\nROBOCOPY\n\nFreeFileSync\n\nSyncthing)\n\n&amp;#x200B;\n\nThanks\n\nJames", "author_fullname": "t2_7g4uo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync network share drives with USB hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gkanv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683991307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Please could someone help me? I have 3 drives connected on the network, Windows 11. I would like those drives to sync completely with an external USB drive that I have connected.&lt;/p&gt;\n\n&lt;p&gt;Is that possible? I don&amp;#39;t want it to just back up, I want it to sync e.g. if I delete a file from the network drive, it is deleted from the USB drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(seen these recommended on another post, would one of these work and is one better than the other?  &lt;/p&gt;\n\n&lt;p&gt;RCLONE&lt;/p&gt;\n\n&lt;p&gt;ROBOCOPY&lt;/p&gt;\n\n&lt;p&gt;FreeFileSync&lt;/p&gt;\n\n&lt;p&gt;Syncthing)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;James&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13gkanv", "is_robot_indexable": true, "report_reasons": null, "author": "skadseye", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13gkanv/sync_network_share_drives_with_usb_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13gkanv/sync_network_share_drives_with_usb_hard_drive/", "subreddit_subscribers": 682293, "created_utc": 1683991307.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}