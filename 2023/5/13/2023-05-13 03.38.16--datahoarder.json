{"kind": "Listing", "data": {"after": "t3_13fwt18", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_kdiljn5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Google Workspace unlimited storage: it's over.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lv3s8ofqwbza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 113, "x": 108, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce5a0298519881a0615c96d04b02e9cee6241433"}, {"y": 226, "x": 216, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9577da1e082ae19f8be9da2af334e9391b595f8f"}, {"y": 334, "x": 320, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef1a6da423dddcb48e995b9dab084026206403fe"}, {"y": 669, "x": 640, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8564368924be81f376581c88cce23bb414fc849a"}, {"y": 1004, "x": 960, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45c7d0792829a7cf9e3ffefb38eaf55414ee109d"}, {"y": 1130, "x": 1080, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4a4a5e2751b002fb9e0485106c5e9843475a3db"}], "s": {"y": 1612, "x": 1540, "u": "https://preview.redd.it/lv3s8ofqwbza1.png?width=1540&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=800860d16c0acce857e6433dfbf64fc37cc685d9"}, "id": "lv3s8ofqwbza1"}, "cmwruommwbza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 113, "x": 108, "u": "https://preview.redd.it/cmwruommwbza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66dbf390f5cccfc2e49068dd9765e12c7819c5d9"}, {"y": 226, "x": 216, "u": "https://preview.redd.it/cmwruommwbza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc2e6f7502d0dfa5b491e288c0f2ffa3c82f9864"}, {"y": 334, "x": 320, "u": "https://preview.redd.it/cmwruommwbza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a63dd56f536bfb9d501191f31273577968caac4"}, {"y": 669, "x": 640, "u": "https://preview.redd.it/cmwruommwbza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1d580f281ae00a8404f4a44fc1776565081a619"}, {"y": 1004, "x": 960, "u": "https://preview.redd.it/cmwruommwbza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e25dbc7775654e51a59cc57715fe49f696b726db"}, {"y": 1130, "x": 1080, "u": "https://preview.redd.it/cmwruommwbza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1f5edfa69ed2196c3b3c114141ac00fd6b44ee9"}], "s": {"y": 1348, "x": 1288, "u": "https://preview.redd.it/cmwruommwbza1.png?width=1288&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=626cd64ed845ac7438b7d3600e0340d8054cf76c"}, "id": "cmwruommwbza1"}}, "name": "t3_13fasuz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 903, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "cmwruommwbza1", "id": 274140095}, {"media_id": "lv3s8ofqwbza1", "id": 274140096}]}, "link_flair_text": "News", "can_mod_post": false, "score": 903, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EahAuh22naLz9CG2_-gd_6iIyjcQh4wxc7H4PDdofmQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683866052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13fasuz", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fasuz", "is_robot_indexable": true, "report_reasons": null, "author": "skylabspiral", "discussion_type": null, "num_comments": 644, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fasuz/google_workspace_unlimited_storage_its_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13fasuz", "subreddit_subscribers": 682221, "created_utc": 1683866052.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8yc0fwzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Budibase, an open-source platform for building apps on top of SQL, REST, Google Sheets, now ships with a powerful spreadsheet-like grid, Active Directory Sync / SCIM, and more.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13fyrcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mIDY1xHvhTBXibpuuQnqEUiBryRcKZGQXQ4to0mIy1E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683929545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nlhuqymk5hza1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nlhuqymk5hza1.png?auto=webp&amp;v=enabled&amp;s=293abe921a16c1ea0e7980e2778892a8cf4a556e", "width": 1656, "height": 930}, "resolutions": [{"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=076deb928686940eb835c471b3b9153b4e4b2b46", "width": 108, "height": 60}, {"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c415bff77f9ef47d1ad9aababb1e9a377925e881", "width": 216, "height": 121}, {"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc2e62f677f62fa72f25455f5e80c93a25ee7dab", "width": 320, "height": 179}, {"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c39d91e81f5b6e7ee73f59523efc3ba126d45398", "width": 640, "height": 359}, {"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6dbec5b8025e7dd47b2ebeaa37069dc202d47798", "width": 960, "height": 539}, {"url": "https://preview.redd.it/nlhuqymk5hza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=367653927db4b2610d1c676ecf829a5b12cc5a4c", "width": 1080, "height": 606}], "variants": {}, "id": "iNLHm20tPcbkHJ2xdSIaTyfrCl8ax14QI2FLZhMsOiM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fyrcc", "is_robot_indexable": true, "report_reasons": null, "author": "jo_ranamo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fyrcc/budibase_an_opensource_platform_for_building_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nlhuqymk5hza1.png", "subreddit_subscribers": 682221, "created_utc": 1683929545.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings fellow data hoarders, I recently have come across a channel on  youtube with a collection of several vintage documentaries, films, and television shows, predominantly hailing from the 1980s and early 1990s. As such the depth and niche quality of this collection is notable, presenting a fascinating  snapshot of a bygone era with a lot of media dealing with esoteric matters such as the uap phenomenon and adjacent topics. Interestingly, it appears that much of this material has been  meticulously restored from original VHS copies, contributing to its  rarity and underscoring the critical need for archiving. Given the  historical and cultural value of such content, coupled with its scarcity  in contemporary digital repositories, I strongly advocate for its  preservation. As we have become unfortunately aware the unpredictable nature of content hosting policies on platforms such  as YouTube further compounds the urgency of this endeavor, as the  channel might face an untimely takedown.\n\n&amp;#x200B;\n\nRegrettably, I'm currently unable to personally undertake the task of  backing up this unique channel due to limitations in my data storage  capabilities. However, I felt compelled to utilize this Free Post Friday  as a platform to disseminate this discovery amongst our community, in  the hope that it piques your interest and prompts collective action  towards preserving\n\n&amp;#x200B;\n\nThe channel in question :\n\n[https://www.youtube.com/@orphicunknown](https://www.youtube.com/@orphicunknown)", "author_fullname": "t2_cfkvcut4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collection of rare vintage documentaries, films, and television shows primarily from the 1980s and early 1990s.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fy7sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683928225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings fellow data hoarders, I recently have come across a channel on  youtube with a collection of several vintage documentaries, films, and television shows, predominantly hailing from the 1980s and early 1990s. As such the depth and niche quality of this collection is notable, presenting a fascinating  snapshot of a bygone era with a lot of media dealing with esoteric matters such as the uap phenomenon and adjacent topics. Interestingly, it appears that much of this material has been  meticulously restored from original VHS copies, contributing to its  rarity and underscoring the critical need for archiving. Given the  historical and cultural value of such content, coupled with its scarcity  in contemporary digital repositories, I strongly advocate for its  preservation. As we have become unfortunately aware the unpredictable nature of content hosting policies on platforms such  as YouTube further compounds the urgency of this endeavor, as the  channel might face an untimely takedown.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Regrettably, I&amp;#39;m currently unable to personally undertake the task of  backing up this unique channel due to limitations in my data storage  capabilities. However, I felt compelled to utilize this Free Post Friday  as a platform to disseminate this discovery amongst our community, in  the hope that it piques your interest and prompts collective action  towards preserving&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The channel in question :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/@orphicunknown\"&gt;https://www.youtube.com/@orphicunknown&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?auto=webp&amp;v=enabled&amp;s=e732428c48be6280c63f8ec3e5de5014871e4e07", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a21410c84841dc636a023b4fdc2bce512dafbbd4", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f56f0347eaa8a27b9a162561377e9d0a9da453fc", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76d062f35ee77c4d8480a47f46df67e3016dec9f", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/KppPQ9IwyKXexNS0k82sXLl40qBoMhq3O6CvEM0j_kk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e63b6ad213b9411693e158ce4abab5d37374dee8", "width": 640, "height": 640}], "variants": {}, "id": "KCdNu0XH7wrnSEywYvkr_n8L4W_P4un5VT9_xWskexc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fy7sv", "is_robot_indexable": true, "report_reasons": null, "author": "pizzawithlowram", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fy7sv/collection_of_rare_vintage_documentaries_films/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fy7sv/collection_of_rare_vintage_documentaries_films/", "subreddit_subscribers": 682221, "created_utc": 1683928225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "45Drives here back to get your input once again on the homelab server development.\n\nIf you missed the last two posts you can check out part one [here](https://www.reddit.com/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/) and part two [here](https://www.reddit.com/r/DataHoarder/comments/13c1m2s/followup_on_45drives_homelab_server_project_part_2/).  \n\nIn summary, we wish to create a data storage system that would bridge the gap between cheap home NAS boxes and our enterprise servers. We thought the best way to figure out what you wanted was to ask. So, we did, and we got a great response. Thanks to everybody that has given their input. So far, we\u2019ve heard the following:\n\n1. 2U or 4U form factor;\n2. strong interest in a chassis only model;\n3. 12 drives minimum;\n4. 3.5 drive slots with optional caddies for 2.5\n\nOur third question is about homelab networking. Network throughput is a critical factor in determining the choice of electronics in a storage server. If designing a storage-only system for enterprise use, any computing or memory capacity that gives performance that exceed the network\u2019s capacity is of little value, adding cost without performance. If other services are to be added to the server, that all changes of course.  It is trivial to build a server that can saturate a 1Gb/sec connection. It is easy to saturate 10Gb/sec as well, although it takes a little bit of effort to saturate 10Gb/sec with a single client transfer.   We have clients who have put out 100Gb/sec from a single server, but this is challenging.\n\nWhat we are wondering is what sort of network performance is of interest to the homelabs community?    1Gb/sec networking is dirt cheap, whereas 100 can really hurt the bank account. \n\nSo we ask:\n\na). What networking do you have in your homelab?\n\nb). What sort of data throughput would you like to achieve from your homelab server?\n\nThanks for reading this, and we appreciate any input you are willing to offer us", "author_fullname": "t2_hcrp0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Homelab Server Follow-up. 45Drives Here Looking For Your Input", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fvedc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": "", "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683921639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;45Drives here back to get your input once again on the homelab server development.&lt;/p&gt;\n\n&lt;p&gt;If you missed the last two posts you can check out part one &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/\"&gt;here&lt;/a&gt; and part two &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13c1m2s/followup_on_45drives_homelab_server_project_part_2/\"&gt;here&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;In summary, we wish to create a data storage system that would bridge the gap between cheap home NAS boxes and our enterprise servers. We thought the best way to figure out what you wanted was to ask. So, we did, and we got a great response. Thanks to everybody that has given their input. So far, we\u2019ve heard the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;2U or 4U form factor;&lt;/li&gt;\n&lt;li&gt;strong interest in a chassis only model;&lt;/li&gt;\n&lt;li&gt;12 drives minimum;&lt;/li&gt;\n&lt;li&gt;3.5 drive slots with optional caddies for 2.5&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our third question is about homelab networking. Network throughput is a critical factor in determining the choice of electronics in a storage server. If designing a storage-only system for enterprise use, any computing or memory capacity that gives performance that exceed the network\u2019s capacity is of little value, adding cost without performance. If other services are to be added to the server, that all changes of course.  It is trivial to build a server that can saturate a 1Gb/sec connection. It is easy to saturate 10Gb/sec as well, although it takes a little bit of effort to saturate 10Gb/sec with a single client transfer.   We have clients who have put out 100Gb/sec from a single server, but this is challenging.&lt;/p&gt;\n\n&lt;p&gt;What we are wondering is what sort of network performance is of interest to the homelabs community?    1Gb/sec networking is dirt cheap, whereas 100 can really hurt the bank account. &lt;/p&gt;\n\n&lt;p&gt;So we ask:&lt;/p&gt;\n\n&lt;p&gt;a). What networking do you have in your homelab?&lt;/p&gt;\n\n&lt;p&gt;b). What sort of data throughput would you like to achieve from your homelab server?&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading this, and we appreciate any input you are willing to offer us&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13fvedc", "is_robot_indexable": true, "report_reasons": null, "author": "cmcgean45", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13fvedc/homelab_server_followup_45drives_here_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fvedc/homelab_server_followup_45drives_here_looking_for/", "subreddit_subscribers": 682221, "created_utc": 1683921639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With Reddit recently signaling it will paywall api access. I am curious to know, which is the last, full archive of Reddit. I feel that anything past 2022 would be a great historical document of the current era that I would save in my vault.", "author_fullname": "t2_msvx0qnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most recent, known, complete archive of all Reddit texts ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fusb9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683920155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With Reddit recently signaling it will paywall api access. I am curious to know, which is the last, full archive of Reddit. I feel that anything past 2022 would be a great historical document of the current era that I would save in my vault.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13fusb9", "is_robot_indexable": true, "report_reasons": null, "author": "transdimensionalmeme", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fusb9/what_is_the_most_recent_known_complete_archive_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fusb9/what_is_the_most_recent_known_complete_archive_of/", "subreddit_subscribers": 682221, "created_utc": 1683920155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have multiple Reddit accounts from which I'd like to download all the saved and upvoted posts from. Also some subreddits that I'd like to archive.\n\nI think BDFR is the most robust with lots of different features, but it has some oddities. As I tried to download all my saved posts, it kept running into a \"duplicate comment\" error that caused it to stop downloading around 300 posts. If I re-ran it, it would also go through every single post and check if it's been downloaded (which would take like 10 minutes for 300 posts) and then fail at the same place.\n\nIs there any better alternative? Also how would I download my posts or a subreddit's posts if there are more than 1000 of them?", "author_fullname": "t2_13kdlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to download all Imgur Reddit posts beyond 1000 post limit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fy9x5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683928366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have multiple Reddit accounts from which I&amp;#39;d like to download all the saved and upvoted posts from. Also some subreddits that I&amp;#39;d like to archive.&lt;/p&gt;\n\n&lt;p&gt;I think BDFR is the most robust with lots of different features, but it has some oddities. As I tried to download all my saved posts, it kept running into a &amp;quot;duplicate comment&amp;quot; error that caused it to stop downloading around 300 posts. If I re-ran it, it would also go through every single post and check if it&amp;#39;s been downloaded (which would take like 10 minutes for 300 posts) and then fail at the same place.&lt;/p&gt;\n\n&lt;p&gt;Is there any better alternative? Also how would I download my posts or a subreddit&amp;#39;s posts if there are more than 1000 of them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fy9x5", "is_robot_indexable": true, "report_reasons": null, "author": "seahorsejoe", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fy9x5/best_way_to_download_all_imgur_reddit_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fy9x5/best_way_to_download_all_imgur_reddit_posts/", "subreddit_subscribers": 682221, "created_utc": 1683928366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "looking for a program that can go through all my images videos files in general and either read them or whatever method it uses to verify if the files are corrupted or not. thats about it. ive searched google ive searched reddit. not getting an answer ", "author_fullname": "t2_ao2zg7ye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a program that can check files for corruption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fs8v6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683914729.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683914161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;looking for a program that can go through all my images videos files in general and either read them or whatever method it uses to verify if the files are corrupted or not. thats about it. ive searched google ive searched reddit. not getting an answer &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fs8v6", "is_robot_indexable": true, "report_reasons": null, "author": "Souleaterblaze_0117", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fs8v6/is_there_a_program_that_can_check_files_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fs8v6/is_there_a_program_that_can_check_files_for/", "subreddit_subscribers": 682221, "created_utc": 1683914161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I noticed this option a few minutes ago. Anyone else seen it? Is there a significant difference to the normal  1080p option? Have yet to pull the trigger on YT premium. \ud83d\ude05\n\nhttps://preview.redd.it/pnek4q5uzdza1.png?width=424&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f2498426c352df4d9fe6ee521974ffb0becc492e\n\nAdditional details:\n\nLink to the video: [https://youtu.be/yK4mTN3B1d8](https://youtu.be/yK4mTN3B1d8)  \n\n\nThanks to u/Isacx123 for sharing how to get the higher bitrate stream by using the `--extractor-args \"youtube:player_client=default,ios\"` with yt-dlp. \ud83d\ude01\ud83d\udd25\n\n&amp;#x200B;", "author_fullname": "t2_9vo91a1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enhanced bitrate option on YouTube Premium", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pnek4q5uzdza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/pnek4q5uzdza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d14c648ca2bfff7c900ccd59bd0e2eec5b7d1c21"}, {"y": 243, "x": 216, "u": "https://preview.redd.it/pnek4q5uzdza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6dee85c198ee1226b8dadb98dd932f7959e3b83"}, {"y": 360, "x": 320, "u": "https://preview.redd.it/pnek4q5uzdza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c0257a4e8d873499c8695752b8fb607d861200b"}], "s": {"y": 478, "x": 424, "u": "https://preview.redd.it/pnek4q5uzdza1.png?width=424&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f2498426c352df4d9fe6ee521974ffb0becc492e"}, "id": "pnek4q5uzdza1"}}, "name": "t3_13fimxm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/yK4mTN3B1d8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/yK4mTN3B1d8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID\"&gt;&lt;/iframe&gt;", "author_name": "Pixid", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/yK4mTN3B1d8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Pixid"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/yK4mTN3B1d8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13fimxm", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A6OXlK5CvXOLjDrSpOuZf7XmOiztP-DW7P_ilQe6D_g.jpg", "edited": 1683899742.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683891483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I noticed this option a few minutes ago. Anyone else seen it? Is there a significant difference to the normal  1080p option? Have yet to pull the trigger on YT premium. \ud83d\ude05&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pnek4q5uzdza1.png?width=424&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f2498426c352df4d9fe6ee521974ffb0becc492e\"&gt;https://preview.redd.it/pnek4q5uzdza1.png?width=424&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f2498426c352df4d9fe6ee521974ffb0becc492e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Additional details:&lt;/p&gt;\n\n&lt;p&gt;Link to the video: &lt;a href=\"https://youtu.be/yK4mTN3B1d8\"&gt;https://youtu.be/yK4mTN3B1d8&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Thanks to &lt;a href=\"/u/Isacx123\"&gt;u/Isacx123&lt;/a&gt; for sharing how to get the higher bitrate stream by using the &lt;code&gt;--extractor-args &amp;quot;youtube:player_client=default,ios&amp;quot;&lt;/code&gt; with yt-dlp. \ud83d\ude01\ud83d\udd25&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0KPYRYAs9UI2QEsOWAeejMSRNhHQJ5K_YaKy7hNk-2s.jpg?auto=webp&amp;v=enabled&amp;s=99e181bbad2bc6a5fbf6942b34097517d06791b4", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/0KPYRYAs9UI2QEsOWAeejMSRNhHQJ5K_YaKy7hNk-2s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0085f92934eab84328fb590a936d818d2d266b83", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/0KPYRYAs9UI2QEsOWAeejMSRNhHQJ5K_YaKy7hNk-2s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc1f54152331e7033c62223de41bb4d2b0bffa84", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/0KPYRYAs9UI2QEsOWAeejMSRNhHQJ5K_YaKy7hNk-2s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f99ee11076a85aa8c3813c31b6a351ad9d991cfc", "width": 320, "height": 240}], "variants": {}, "id": "sD7Y8uzBm4uu2M_ihnQrNQNkzCa4_Xndi2ILJK3nshY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13fimxm", "is_robot_indexable": true, "report_reasons": null, "author": "danlim93", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fimxm/enhanced_bitrate_option_on_youtube_premium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fimxm/enhanced_bitrate_option_on_youtube_premium/", "subreddit_subscribers": 682221, "created_utc": 1683891483.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/yK4mTN3B1d8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"\ub0a8\ub9e4 \uc0ac\uc774 \uc228\uc740 \uc790\ub9e4 \ucc3e\uae30 (feat. \uce74\ub9ac\ub098)\uff5cPIXID\"&gt;&lt;/iframe&gt;", "author_name": "Pixid", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/yK4mTN3B1d8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Pixid"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I'm looking into ways to encrypt my files.  \n I want to find something that can safely resist brute-force attacks. Is AES in 7zip a safe enough implementation?\n\nPersonally I use an alternative (NanaZip) currently. I would like to know if I'm not making a mistake attempting to encrypt using this program. I would want to keep my private data safe (my job requires this) and not compromise it because if improper implementation.\n\nOf course I can always compress and then encrypt my files separately. So I'm open for suggestions if there are any seriously more secure alternatives to this implementation of AES-256 (not less than 256).\n\nI suspect there could be even safer options. If the compromise would be speed this is not an issue. Of course only widely available options that wouldn't cause any burn. I don't suspect encryption alone would he an issue, since this should be standard now.", "author_fullname": "t2_vdfzva2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "7zip AES-256 &amp; File encryption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fwmmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683924500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m looking into ways to encrypt my files.&lt;br/&gt;\n I want to find something that can safely resist brute-force attacks. Is AES in 7zip a safe enough implementation?&lt;/p&gt;\n\n&lt;p&gt;Personally I use an alternative (NanaZip) currently. I would like to know if I&amp;#39;m not making a mistake attempting to encrypt using this program. I would want to keep my private data safe (my job requires this) and not compromise it because if improper implementation.&lt;/p&gt;\n\n&lt;p&gt;Of course I can always compress and then encrypt my files separately. So I&amp;#39;m open for suggestions if there are any seriously more secure alternatives to this implementation of AES-256 (not less than 256).&lt;/p&gt;\n\n&lt;p&gt;I suspect there could be even safer options. If the compromise would be speed this is not an issue. Of course only widely available options that wouldn&amp;#39;t cause any burn. I don&amp;#39;t suspect encryption alone would he an issue, since this should be standard now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fwmmi", "is_robot_indexable": true, "report_reasons": null, "author": "Secret_Lacerta", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fwmmi/7zip_aes256_file_encryption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fwmmi/7zip_aes256_file_encryption/", "subreddit_subscribers": 682221, "created_utc": 1683924500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just did a large transfer 16TB over to a new larger HDD. I used Teracopy and was wondering...\n\nWhen all files are selected on the source and the destination side and the folder/file sizes are exactly the same down to the byte...Is the verification process still necessary?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File sizes are exact down to the byte, Teracopy verification still necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13g3zym", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683943032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just did a large transfer 16TB over to a new larger HDD. I used Teracopy and was wondering...&lt;/p&gt;\n\n&lt;p&gt;When all files are selected on the source and the destination side and the folder/file sizes are exactly the same down to the byte...Is the verification process still necessary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g3zym", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3zym/file_sizes_are_exact_down_to_the_byte_teracopy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3zym/file_sizes_are_exact_down_to_the_byte_teracopy/", "subreddit_subscribers": 682221, "created_utc": 1683943032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TL:DR What is the best configuration for 4x16TB Exos drives plus 19x2TB HGST Drives in ZFS on TrueNAS SCALE?  \n\n\nSo, I currently have 16TB of data on my TrueNAS using the 2TB HGST drives  on 3x6 wide z2 VDEVS that are then synced to 2x16TB Exos drives in my main Windows PC (RAID 0) as a middle point to be backed up to Backblaze Personal. I've just got access to enough Google Drive storage (after seeing the recent Google Drive post here and realising I was on the wrong plan for my school) to be able to stop using Backblaze for my archive backup.  \n\n\nI'd already ordered an extra 2x16TB Exos drives before I got the Google Drive storage.  \n\n\nI have 10G ethernet on the TrueNAS and have been enjoying glorious speeds for video editing etc with the large number of drives. Now I have 4x16TB drives I was thinking of just setting up a mirrored VDEV with those, calling it a day, and enjoying the cheaper electricity costs buuuuut I can't just sit on 19 2TB drives and have half the speed I was enjoying before.  \n\n\nHow would you use the drives? It would be nice to retire the disk shelf and just have the Exos drives running off the motherboard SATA but part of me just wants to keep the shelf and the disks running.  \n\n\nHow can I best use the 19 extra drives to help saturate the LAN without adding too much danger to the data pool?   \n\n\nLove your work, by the way. This group has saved my life so many times....", "author_fullname": "t2_11fnzm13", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS Brain pain - Please give me a nudge in the right direction.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fzpas", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683931857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL:DR What is the best configuration for 4x16TB Exos drives plus 19x2TB HGST Drives in ZFS on TrueNAS SCALE?  &lt;/p&gt;\n\n&lt;p&gt;So, I currently have 16TB of data on my TrueNAS using the 2TB HGST drives  on 3x6 wide z2 VDEVS that are then synced to 2x16TB Exos drives in my main Windows PC (RAID 0) as a middle point to be backed up to Backblaze Personal. I&amp;#39;ve just got access to enough Google Drive storage (after seeing the recent Google Drive post here and realising I was on the wrong plan for my school) to be able to stop using Backblaze for my archive backup.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d already ordered an extra 2x16TB Exos drives before I got the Google Drive storage.  &lt;/p&gt;\n\n&lt;p&gt;I have 10G ethernet on the TrueNAS and have been enjoying glorious speeds for video editing etc with the large number of drives. Now I have 4x16TB drives I was thinking of just setting up a mirrored VDEV with those, calling it a day, and enjoying the cheaper electricity costs buuuuut I can&amp;#39;t just sit on 19 2TB drives and have half the speed I was enjoying before.  &lt;/p&gt;\n\n&lt;p&gt;How would you use the drives? It would be nice to retire the disk shelf and just have the Exos drives running off the motherboard SATA but part of me just wants to keep the shelf and the disks running.  &lt;/p&gt;\n\n&lt;p&gt;How can I best use the 19 extra drives to help saturate the LAN without adding too much danger to the data pool?   &lt;/p&gt;\n\n&lt;p&gt;Love your work, by the way. This group has saved my life so many times....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fzpas", "is_robot_indexable": true, "report_reasons": null, "author": "BerryJP", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fzpas/zfs_brain_pain_please_give_me_a_nudge_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fzpas/zfs_brain_pain_please_give_me_a_nudge_in_the/", "subreddit_subscribers": 682221, "created_utc": 1683931857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi so I\u2019m trying to make sure I never lose my storage and I cant figure out what else I would back up onto other than a NAS with HDDs or SSDs. What else exists that I can back up onto?", "author_fullname": "t2_j00y7vzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In the 321 Rule, for 2, what other media are there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fs2xz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683913778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi so I\u2019m trying to make sure I never lose my storage and I cant figure out what else I would back up onto other than a NAS with HDDs or SSDs. What else exists that I can back up onto?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fs2xz", "is_robot_indexable": true, "report_reasons": null, "author": "wnabi", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fs2xz/in_the_321_rule_for_2_what_other_media_are_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fs2xz/in_the_321_rule_for_2_what_other_media_are_there/", "subreddit_subscribers": 682221, "created_utc": 1683913778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for a way to archive some subreddits because of imgur. I've tried one method but it didn't work out for me at all. I got a 12tb hdd that i'm willing to fill up all the way.", "author_fullname": "t2_w94iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the easiest way to archive a subreddit's images/videos/galleries for someone who isn't good at commandline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13g3wd9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683942755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a way to archive some subreddits because of imgur. I&amp;#39;ve tried one method but it didn&amp;#39;t work out for me at all. I got a 12tb hdd that i&amp;#39;m willing to fill up all the way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13g3wd9", "is_robot_indexable": true, "report_reasons": null, "author": "FuriousKimchi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3wd9/whats_the_easiest_way_to_archive_a_subreddits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3wd9/whats_the_easiest_way_to_archive_a_subreddits/", "subreddit_subscribers": 682221, "created_utc": 1683942755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I signed up for Dropbox Business Advanced. I already used Dropbox for cloud storage/photo backups but I wanted to back up my full unRAID array offsite and I wanted a fast cloud storage provide that could grow with me for a flat fee. So far I'm pretty happy. I'm running my data up to it with Arq backup fully encrypted. Does anyone else have any thoughts about this solution? Any other users of Business Advanced around here with input? Thanks!", "author_fullname": "t2_da8xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox Business Advanced", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13frl9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683912653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I signed up for Dropbox Business Advanced. I already used Dropbox for cloud storage/photo backups but I wanted to back up my full unRAID array offsite and I wanted a fast cloud storage provide that could grow with me for a flat fee. So far I&amp;#39;m pretty happy. I&amp;#39;m running my data up to it with Arq backup fully encrypted. Does anyone else have any thoughts about this solution? Any other users of Business Advanced around here with input? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "23 TB Unraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13frl9r", "is_robot_indexable": true, "report_reasons": null, "author": "mackid1993", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13frl9r/dropbox_business_advanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13frl9r/dropbox_business_advanced/", "subreddit_subscribers": 682221, "created_utc": 1683912653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can't resolve archive.is using Cloudflare's DNS. It works when using Google's DNS or Quad-9. \n\nAnyone else having this issue?\n\n    $ nslookup\n    &gt; server 8.8.8.8\n    Default server: 8.8.8.8\n    Address: 8.8.8.8#53\n    &gt; archive.is\n    Server:         8.8.8.8\n    Address:        8.8.8.8#53\n    \n    Non-authoritative answer:\n    Name:   archive.is\n    Address: 130.0.232.208\n    &gt; server 1.1.1.1\n    Default server: 1.1.1.1\n    Address: 1.1.1.1#53\n    &gt; archive.is\n    Server:         1.1.1.1\n    Address:        1.1.1.1#53\n    \n    Non-authoritative answer:\n    *** Can't find archive.is: No answer\n    &gt; server 9.9.9.9\n    Default server: 9.9.9.9\n    Address: 9.9.9.9#53\n    &gt; archive.is\n    Server:         9.9.9.9\n    Address:        9.9.9.9#53\n    \n    Non-authoritative answer:\n    Name:   archive.is\n    Address: 51.79.250.183\n    &gt; server 1.0.0.1\n    Default server: 1.0.0.1\n    Address: 1.0.0.1#53\n    &gt; archive.is\n    Server:         1.0.0.1\n    Address:        1.0.0.1#53\n    \n    Non-authoritative answer:\n    *** Can't find archive.is: No answer\n    &gt; ^D", "author_fullname": "t2_7srpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudflare DNS blocking archive.is?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13g4htv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683944412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t resolve archive.is using Cloudflare&amp;#39;s DNS. It works when using Google&amp;#39;s DNS or Quad-9. &lt;/p&gt;\n\n&lt;p&gt;Anyone else having this issue?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ nslookup\n&amp;gt; server 8.8.8.8\nDefault server: 8.8.8.8\nAddress: 8.8.8.8#53\n&amp;gt; archive.is\nServer:         8.8.8.8\nAddress:        8.8.8.8#53\n\nNon-authoritative answer:\nName:   archive.is\nAddress: 130.0.232.208\n&amp;gt; server 1.1.1.1\nDefault server: 1.1.1.1\nAddress: 1.1.1.1#53\n&amp;gt; archive.is\nServer:         1.1.1.1\nAddress:        1.1.1.1#53\n\nNon-authoritative answer:\n*** Can&amp;#39;t find archive.is: No answer\n&amp;gt; server 9.9.9.9\nDefault server: 9.9.9.9\nAddress: 9.9.9.9#53\n&amp;gt; archive.is\nServer:         9.9.9.9\nAddress:        9.9.9.9#53\n\nNon-authoritative answer:\nName:   archive.is\nAddress: 51.79.250.183\n&amp;gt; server 1.0.0.1\nDefault server: 1.0.0.1\nAddress: 1.0.0.1#53\n&amp;gt; archive.is\nServer:         1.0.0.1\nAddress:        1.0.0.1#53\n\nNon-authoritative answer:\n*** Can&amp;#39;t find archive.is: No answer\n&amp;gt; ^D\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g4htv", "is_robot_indexable": true, "report_reasons": null, "author": "maomaocat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g4htv/cloudflare_dns_blocking_archiveis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g4htv/cloudflare_dns_blocking_archiveis/", "subreddit_subscribers": 682221, "created_utc": 1683944412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "current firmware is 20221022, worried about being unable to use 3rd party toner cartridges.   HPs website doesn't list prior firmware so I was hoping someone here may have saved an older firmware download.", "author_fullname": "t2_vbtme", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking older firmware for HP Laser Printer M477fnw", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g31gq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683940392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;current firmware is 20221022, worried about being unable to use 3rd party toner cartridges.   HPs website doesn&amp;#39;t list prior firmware so I was hoping someone here may have saved an older firmware download.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g31gq", "is_robot_indexable": true, "report_reasons": null, "author": "sdp1981", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g31gq/seeking_older_firmware_for_hp_laser_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g31gq/seeking_older_firmware_for_hp_laser_printer/", "subreddit_subscribers": 682221, "created_utc": 1683940392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am thinking on getting myself a off the shelf NAS since I don't have access to an old PC. In this case either the Synology 923+ or QNAP TS-464. Still trying to decide which one is better for my need as a NAS and plex/jellyfin server. \n\nNow for the drives I am currently debating between two options either buying HDD enclosures and shucking them or buying recertified HDD from Serverpartdeals.\n\nWhich one should I go with?", "author_fullname": "t2_mkw8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one is better? Buying and shucking drives or recertified drives from a reputable seller?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g1yd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683937472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking on getting myself a off the shelf NAS since I don&amp;#39;t have access to an old PC. In this case either the Synology 923+ or QNAP TS-464. Still trying to decide which one is better for my need as a NAS and plex/jellyfin server. &lt;/p&gt;\n\n&lt;p&gt;Now for the drives I am currently debating between two options either buying HDD enclosures and shucking them or buying recertified HDD from Serverpartdeals.&lt;/p&gt;\n\n&lt;p&gt;Which one should I go with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g1yd8", "is_robot_indexable": true, "report_reasons": null, "author": "TheUnluckyGamer13", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g1yd8/which_one_is_better_buying_and_shucking_drives_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g1yd8/which_one_is_better_buying_and_shucking_drives_or/", "subreddit_subscribers": 682221, "created_utc": 1683937472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,  \n\n\nI recently bought a  **Pioneer DVR-RT602H-S**  on Ebay that said it was functioning fine. I've recorded a lot of VHS-C with an VHS C to VHJS adapter to DVDs in the past with similar recorders but just want to make sure Im not doing anything wrong with this device.\n\n&amp;#x200B;\n\nI manage to record the DVD RW but it seems that there is no video signal, just the audio. Does the VHS DVD Recorder device need to be plugged into a TV to function probably? I thought the Autocopy should work fine but just want to make sure it isn't some kind of user error before I return the device as I got it for a good price.\n\n&amp;#x200B;\n\nAny help or advice would be greatly appreciated!", "author_fullname": "t2_8oai8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VHS-C to DVD Recorder Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13frqes", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683912971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,  &lt;/p&gt;\n\n&lt;p&gt;I recently bought a  &lt;strong&gt;Pioneer DVR-RT602H-S&lt;/strong&gt;  on Ebay that said it was functioning fine. I&amp;#39;ve recorded a lot of VHS-C with an VHS C to VHJS adapter to DVDs in the past with similar recorders but just want to make sure Im not doing anything wrong with this device.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I manage to record the DVD RW but it seems that there is no video signal, just the audio. Does the VHS DVD Recorder device need to be plugged into a TV to function probably? I thought the Autocopy should work fine but just want to make sure it isn&amp;#39;t some kind of user error before I return the device as I got it for a good price.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help or advice would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13frqes", "is_robot_indexable": true, "report_reasons": null, "author": "Seyss05", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13frqes/vhsc_to_dvd_recorder_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13frqes/vhsc_to_dvd_recorder_issue/", "subreddit_subscribers": 682221, "created_utc": 1683912971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nSo I keep freaking out over the thought of one day losing my entire media library and other things I want to save because a hard drive just zaps out and dies. What can I do to prevent that? If I get a NAS, if my media library is 16TB, if I get another 16TB can I basically just clone it? What if both die? etc\n\nPlease help. Do I get a NAS or do I go with cloud storage? I really want an end all be all solution that doesn't crash and burn as soon as a minor inconvenience happens (NAS or a singular individual drive breaks etc)\n\nAlso side question, would it be better or less taxing on the drives / NAS to run a Plex server off the NAS or store the media on the NAS and run it off different separate hardware?", "author_fullname": "t2_j00y7vzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS for backing up and hosting media? Or cloud storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fqxqo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683911191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;So I keep freaking out over the thought of one day losing my entire media library and other things I want to save because a hard drive just zaps out and dies. What can I do to prevent that? If I get a NAS, if my media library is 16TB, if I get another 16TB can I basically just clone it? What if both die? etc&lt;/p&gt;\n\n&lt;p&gt;Please help. Do I get a NAS or do I go with cloud storage? I really want an end all be all solution that doesn&amp;#39;t crash and burn as soon as a minor inconvenience happens (NAS or a singular individual drive breaks etc)&lt;/p&gt;\n\n&lt;p&gt;Also side question, would it be better or less taxing on the drives / NAS to run a Plex server off the NAS or store the media on the NAS and run it off different separate hardware?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fqxqo", "is_robot_indexable": true, "report_reasons": null, "author": "wnabi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fqxqo/nas_for_backing_up_and_hosting_media_or_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fqxqo/nas_for_backing_up_and_hosting_media_or_cloud/", "subreddit_subscribers": 682221, "created_utc": 1683911191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi fellow datahoarders,\nso I looked through Google search and couldn't find that much in my search. Most of it was either people this size either had a knowledge on how to back up properly, or to just use a single large disk drive. I guess mine is pretty simple, but just wanted to double check before doing stuff.\n\nCurrent setup: 4 data disks + 2 parity in snapraid + merger FS config. Currently backup up to two large disks.\n\nI'm thinking of going with borgmatic, but this probably applies to other backup software. \n\nThe question: Since the current data set is such a large amount. I assume the backup target would need to be drive pool of some sorts (probs gonna use zfs)? Or how would the configuration for the backup machine look like?\n\nThanks!", "author_fullname": "t2_xva8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup 30+ TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fh1gd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683886981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow datahoarders,\nso I looked through Google search and couldn&amp;#39;t find that much in my search. Most of it was either people this size either had a knowledge on how to back up properly, or to just use a single large disk drive. I guess mine is pretty simple, but just wanted to double check before doing stuff.&lt;/p&gt;\n\n&lt;p&gt;Current setup: 4 data disks + 2 parity in snapraid + merger FS config. Currently backup up to two large disks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of going with borgmatic, but this probably applies to other backup software. &lt;/p&gt;\n\n&lt;p&gt;The question: Since the current data set is such a large amount. I assume the backup target would need to be drive pool of some sorts (probs gonna use zfs)? Or how would the configuration for the backup machine look like?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fh1gd", "is_robot_indexable": true, "report_reasons": null, "author": "zarcommander", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fh1gd/backup_30_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fh1gd/backup_30_tb/", "subreddit_subscribers": 682221, "created_utc": 1683886981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7gfl67ac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pulled my card a little to hard and some paint chipped off will that effect my sd card\u2019s life? It still works", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_13g5edd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GtewDL9dS1YmNoSoGde7wjfB2_JFXExxrk4c8n-EOFE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683946949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wc6q8lhu2kza1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?auto=webp&amp;v=enabled&amp;s=325431efd2c5d7ba1c3b502e4084fb7311c7905e", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=543b82c9d6fa98667c8d732fa72a08c2c58cff19", "width": 108, "height": 144}, {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e73ec900b5a1fd68924b31698ce00be81e7b3d3b", "width": 216, "height": 288}, {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11e76bfd1a87106a5cc96b68a81fda7b4ad3846c", "width": 320, "height": 426}, {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbdd1718df0c7b4391c6f669a6ab5844da8a910b", "width": 640, "height": 853}, {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=735c1bd69885a5aabf020468fc5e5faec6c2be98", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/wc6q8lhu2kza1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f321b80b4e8b95e73218c7f9f2b321acf1c9d9f2", "width": 1080, "height": 1440}], "variants": {}, "id": "mCduma86otbUIHAhNMLIWmwNJT1qLSyPLRRmeVCACN4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g5edd", "is_robot_indexable": true, "report_reasons": null, "author": "Oceanstreasure", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g5edd/pulled_my_card_a_little_to_hard_and_some_paint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wc6q8lhu2kza1.jpg", "subreddit_subscribers": 682221, "created_utc": 1683946949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI have a full 8TB of movie rips on a hard drive (I am sure some of you are laughing right now...  but at the end of that day I might be able to *watch* at least a bit of my collection).\n\nBecause it's mostly nothing I couldn't get back, I have logged every file name inside an excel spreadsheet so that I could quickly recover everything if the drive failed - it's one thing to lose the data, it's another to not actually be sure of what is lost.\n\nSo far I have done this fair successfully.  I have copied the file names of every film and sorted them into decade sheets in Excel.  \n\nHowever it has all been done manually as well as the sorting into decade folder.\n\nFor example:\n\n&amp;#x200B;\n\n* Sheet 1:\n\n**1910s**\n\n*Out West (1918)*\n\n*Backstage (1919)*\n\n&amp;#x200B;\n\n* Sheet 2:\n\n**1920s**\n\n*Battleship Potemkin (1925)*\n\n*Faust (1926)*\n\n&amp;#x200B;\n\netc etc\n\n&amp;#x200B;\n\nHowever, I am wondering where else I can take this - I am wanting to know how, as my collection grows over time, whether I could add quickly include other features into the spreadsheet like the director of the film and other metadata like year of release to the spreadsheet and if there is another program that can do that. \n\nFor example:\n\n&amp;#x200B;\n\n|1910s|Director \\*(autopopulated)\\*|Main Actor \\*(autopopulated)\\*|\n|:-|:-|:-|\n|*Out West (1918)*|Buster Keaton|Buster Keaton|\n|*Backstage (1919)*|*Buster Keaton*|Buster Keaton|\n\n&amp;#x200B;\n\nAdditionally, whether there is a program that can auto place:\n\n&gt;1910s movies into `1910s folder`  \n&gt;  \n&gt;1920s into `1920s folder`   \n&gt;  \n&gt;etc.\n\n&amp;#x200B;\n\nIdeas and suggestions for how to assist with the organizing of my horrible hoarding disease would be great!", "author_fullname": "t2_nexio2e9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Taking stock of all the movies I have", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g3iil", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683941675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a full 8TB of movie rips on a hard drive (I am sure some of you are laughing right now...  but at the end of that day I might be able to &lt;em&gt;watch&lt;/em&gt; at least a bit of my collection).&lt;/p&gt;\n\n&lt;p&gt;Because it&amp;#39;s mostly nothing I couldn&amp;#39;t get back, I have logged every file name inside an excel spreadsheet so that I could quickly recover everything if the drive failed - it&amp;#39;s one thing to lose the data, it&amp;#39;s another to not actually be sure of what is lost.&lt;/p&gt;\n\n&lt;p&gt;So far I have done this fair successfully.  I have copied the file names of every film and sorted them into decade sheets in Excel.  &lt;/p&gt;\n\n&lt;p&gt;However it has all been done manually as well as the sorting into decade folder.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sheet 1:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;1910s&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Out West (1918)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Backstage (1919)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sheet 2:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;1920s&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Battleship Potemkin (1925)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Faust (1926)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;etc etc&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, I am wondering where else I can take this - I am wanting to know how, as my collection grows over time, whether I could add quickly include other features into the spreadsheet like the director of the film and other metadata like year of release to the spreadsheet and if there is another program that can do that. &lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;1910s&lt;/th&gt;\n&lt;th align=\"left\"&gt;Director *(autopopulated)*&lt;/th&gt;\n&lt;th align=\"left\"&gt;Main Actor *(autopopulated)*&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Out West (1918)&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Backstage (1919)&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Buster Keaton&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Buster Keaton&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, whether there is a program that can auto place:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;1910s movies into &lt;code&gt;1910s folder&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;1920s into &lt;code&gt;1920s folder&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ideas and suggestions for how to assist with the organizing of my horrible hoarding disease would be great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g3iil", "is_robot_indexable": true, "report_reasons": null, "author": "Warm-Sugar3726", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g3iil/taking_stock_of_all_the_movies_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g3iil/taking_stock_of_all_the_movies_i_have/", "subreddit_subscribers": 682221, "created_utc": 1683941675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Please share if you do", "author_fullname": "t2_6m84ad7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Know any Windows hash tool that supports xxh3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g05i1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683932953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please share if you do&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13g05i1", "is_robot_indexable": true, "report_reasons": null, "author": "Jungy1eong", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13g05i1/know_any_windows_hash_tool_that_supports_xxh3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13g05i1/know_any_windows_hash_tool_that_supports_xxh3/", "subreddit_subscribers": 682221, "created_utc": 1683932953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Fellow data hoarders,\n\nMy 5 tb hard drive is at its end of life. CrystalDiskInfo has it marked as bad. Read, Write operations were sluggish. This is for my D drive.\n\nIn a desperate attempt, I ordered a Manufactured Recertified Western Digital 16 TB from [serverpartsdeals.com [click me]](https://serverpartdeals.com/collections/hard-drives/products/western-digital-ultrastar-dc-hc550-wuh721816ale6l4-0f38462-16tb-7-2k-rpm-sata-6gb-s-512e-512mb-3-5-se-manufacturer-recertified-hdd) \n\nWhat tools and command line commands do you recommend I use to test this sucker? The only things I've heard of is badblocks(without knowing how to do or how to use it), western digital hard drive utility .\n\nAlso, should I use Macrium Reflect or should I use EaseUS to make a clone for this hard drive with many bad sectors? Any specific platform or program you recommend to boot on a USB to accomplish the cloning task? Is there a way i can go about setting the new drive as a D drive as if a swap of hard drives did not occur (I know how to setup path letters, but I want the computer to resume as if nothing ever happened)", "author_fullname": "t2_87ymo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got a MFR Recert WD 16 TB. How to test?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fy9en", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683928330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fellow data hoarders,&lt;/p&gt;\n\n&lt;p&gt;My 5 tb hard drive is at its end of life. CrystalDiskInfo has it marked as bad. Read, Write operations were sluggish. This is for my D drive.&lt;/p&gt;\n\n&lt;p&gt;In a desperate attempt, I ordered a Manufactured Recertified Western Digital 16 TB from &lt;a href=\"https://serverpartdeals.com/collections/hard-drives/products/western-digital-ultrastar-dc-hc550-wuh721816ale6l4-0f38462-16tb-7-2k-rpm-sata-6gb-s-512e-512mb-3-5-se-manufacturer-recertified-hdd\"&gt;serverpartsdeals.com [click me]&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;What tools and command line commands do you recommend I use to test this sucker? The only things I&amp;#39;ve heard of is badblocks(without knowing how to do or how to use it), western digital hard drive utility .&lt;/p&gt;\n\n&lt;p&gt;Also, should I use Macrium Reflect or should I use EaseUS to make a clone for this hard drive with many bad sectors? Any specific platform or program you recommend to boot on a USB to accomplish the cloning task? Is there a way i can go about setting the new drive as a D drive as if a swap of hard drives did not occur (I know how to setup path letters, but I want the computer to resume as if nothing ever happened)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?auto=webp&amp;v=enabled&amp;s=fd9e3b3baba1678ae4ec9d6f14d4ae4d7f36f1dd", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e08ca8bbd82b23584c33e32d6eb1a0d89be1a507", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1452add0560d8e0bd0cdf34c9b5dcb3c61e2728", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=732b3d0fdd5a09c3e52c1d114af54cfa91e61239", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f93be84a41d387abac2ee5f338b226a5501f307", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b13bdfee96160ded3f62b774fc81ef9f7878eaf0", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/KvLukrnW-t-H96yQYq4PtgiJbc99qGWAPDcN54XOypU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9673a55f0566a9e1abc2b02782e8daadd9487af1", "width": 1080, "height": 1080}], "variants": {}, "id": "FqmvgEW76Kyr-1LX5XRWeyyD3IqCjTYGSs3Z-oaq80Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fy9en", "is_robot_indexable": true, "report_reasons": null, "author": "QuickWick", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fy9en/just_got_a_mfr_recert_wd_16_tb_how_to_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fy9en/just_got_a_mfr_recert_wd_16_tb_how_to_test/", "subreddit_subscribers": 682221, "created_utc": 1683928330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI am currently pursuing  a machine learning project that involves videos. For that purpose I wanted to download videos from YouTube using PyTube. After some reading online ([here](https://www.reddit.com/r/learnpython/comments/ef0czg/how_does_pytube_work/), [here](https://www.quora.com/Is-downloading-YouTube-videos-legal-Doesnt-YouTube-lose-out-on-advertising-revenue-this-way), [here](https://www.videoconverterfactory.com/tips/is-it-legal-to-download-youtube-videos.html)), my conclusion was  that as long that I won't upload those videos on another site (or at all), it should be fine.  \n\nAt first I could download videos, but after some time I started to get the same error each time I tried to download a video: \n\n`Traceback (most recent call last):`  \n  `File \"D:\\Practicals\\Python\\ML\\youtube\\temp.py\", line 11, in &lt;module&gt;`  \n`strm=video.streams.filter(res=\"720p\")`  \n`^^^^^^^^^^^^^`  \n  `File \"D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py\", line 296, in streams`  \n`return StreamQuery(self.fmt_streams)`  \n`^^^^^^^^^^^^^^^^`  \n  `File \"D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py\", line 176, in fmt_streams`  \n`stream_manifest = extract.apply_descrambler(self.streaming_data)`  \n`^^^^^^^^^^^^^^^^^^^`  \n  `File \"D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py\", line 161, in streaming_data`  \n`return self.vid_info['streamingData']`  \n`~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^`  \n`KeyError: 'streamingData'`\n\nAfter some search, it seems that if I would modify `YouTube(URL)` to  `YouTube(URL, use_oauth=True, allow_oauth_cache=True)` then it would work.\n\n&amp;#x200B;\n\nThe issue is, that adding these option actually means that I add, as an authentication method, a number that is unique to my personal laptop.  \n\nNow, it looks sketchy af, so I paused any download for now. Any comment on that? Do I totally misinterpret  the meaning of this authentication? \n\nThanks!", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Legality of PyTube [2023]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fwt18", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683924897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am currently pursuing  a machine learning project that involves videos. For that purpose I wanted to download videos from YouTube using PyTube. After some reading online (&lt;a href=\"https://www.reddit.com/r/learnpython/comments/ef0czg/how_does_pytube_work/\"&gt;here&lt;/a&gt;, &lt;a href=\"https://www.quora.com/Is-downloading-YouTube-videos-legal-Doesnt-YouTube-lose-out-on-advertising-revenue-this-way\"&gt;here&lt;/a&gt;, &lt;a href=\"https://www.videoconverterfactory.com/tips/is-it-legal-to-download-youtube-videos.html\"&gt;here&lt;/a&gt;), my conclusion was  that as long that I won&amp;#39;t upload those videos on another site (or at all), it should be fine.  &lt;/p&gt;\n\n&lt;p&gt;At first I could download videos, but after some time I started to get the same error each time I tried to download a video: &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Traceback (most recent call last):&lt;/code&gt;&lt;br/&gt;\n  &lt;code&gt;File &amp;quot;D:\\Practicals\\Python\\ML\\youtube\\temp.py&amp;quot;, line 11, in &amp;lt;module&amp;gt;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;strm=video.streams.filter(res=&amp;quot;720p&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;^^^^^^^^^^^^^&lt;/code&gt;&lt;br/&gt;\n  &lt;code&gt;File &amp;quot;D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py&amp;quot;, line 296, in streams&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;return StreamQuery(self.fmt_streams)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;^^^^^^^^^^^^^^^^&lt;/code&gt;&lt;br/&gt;\n  &lt;code&gt;File &amp;quot;D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py&amp;quot;, line 176, in fmt_streams&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;stream_manifest = extract.apply_descrambler(self.streaming_data)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;^^^^^^^^^^^^^^^^^^^&lt;/code&gt;&lt;br/&gt;\n  &lt;code&gt;File &amp;quot;D:\\Python311\\Lib\\site-packages\\pytube\\__main__.py&amp;quot;, line 161, in streaming_data&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;return self.vid_info[&amp;#39;streamingData&amp;#39;]&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;KeyError: &amp;#39;streamingData&amp;#39;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;After some search, it seems that if I would modify &lt;code&gt;YouTube(URL)&lt;/code&gt; to  &lt;code&gt;YouTube(URL, use_oauth=True, allow_oauth_cache=True)&lt;/code&gt; then it would work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The issue is, that adding these option actually means that I add, as an authentication method, a number that is unique to my personal laptop.  &lt;/p&gt;\n\n&lt;p&gt;Now, it looks sketchy af, so I paused any download for now. Any comment on that? Do I totally misinterpret  the meaning of this authentication? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FZuwt3f-LnCvO4_GPkQrgBdJ5uKLiG3s0ZH7tRxxIcw.jpg?auto=webp&amp;v=enabled&amp;s=022a5d5ea72a81a8a0ba27409cfa17408f9173f3", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/FZuwt3f-LnCvO4_GPkQrgBdJ5uKLiG3s0ZH7tRxxIcw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fe1c37844eb84164a92521180acbf29fa9aac93", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/FZuwt3f-LnCvO4_GPkQrgBdJ5uKLiG3s0ZH7tRxxIcw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff99b19ba08b1fbc2016fd3238be289f0122cdc0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/FZuwt3f-LnCvO4_GPkQrgBdJ5uKLiG3s0ZH7tRxxIcw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7608dc5f799f6e60ce4391e54e3d0557e018abe0", "width": 320, "height": 168}], "variants": {}, "id": "KZ5MH9ttjhaAKFnwo5Uq3gbLeRN1e4W-P5Vld8MMiVg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13fwt18", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13fwt18/legality_of_pytube_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13fwt18/legality_of_pytube_2023/", "subreddit_subscribers": 682221, "created_utc": 1683924897.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}