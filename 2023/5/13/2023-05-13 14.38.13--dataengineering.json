{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I try to be super open and receptive to feedback if someone has a better  more efficient way of doing things. I take notes obsessively or ask plenty questions.\n\nWhen we do a code review someone who more junior than me corrects my code or says it can be improved somewhere. \n\nIt isn\u2019t overly pedantic corrections that junior people get into. However I do feel that little bit of insecurity that you aren\u2019t good enough technically or that you lose respect if don\u2019t shine in your logic.  \n\nYou can\u2019t be a chef and not know how to cook a meal.\n\nOne thing I find, is it lights a bit of fire in your belly. If you\u2019re expected to be a team lead you cannot be bad technically. It pushed self development.\n\nHow do you manage junior correcting you without coming across as overly submissive and still have their respect?", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle junior people who are better than you in terms of technical ability?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fmd1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 149, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 149, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683900743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I try to be super open and receptive to feedback if someone has a better  more efficient way of doing things. I take notes obsessively or ask plenty questions.&lt;/p&gt;\n\n&lt;p&gt;When we do a code review someone who more junior than me corrects my code or says it can be improved somewhere. &lt;/p&gt;\n\n&lt;p&gt;It isn\u2019t overly pedantic corrections that junior people get into. However I do feel that little bit of insecurity that you aren\u2019t good enough technically or that you lose respect if don\u2019t shine in your logic.  &lt;/p&gt;\n\n&lt;p&gt;You can\u2019t be a chef and not know how to cook a meal.&lt;/p&gt;\n\n&lt;p&gt;One thing I find, is it lights a bit of fire in your belly. If you\u2019re expected to be a team lead you cannot be bad technically. It pushed self development.&lt;/p&gt;\n\n&lt;p&gt;How do you manage junior correcting you without coming across as overly submissive and still have their respect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fmd1h", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fmd1h/how_do_you_handle_junior_people_who_are_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fmd1h/how_do_you_handle_junior_people_who_are_better/", "subreddit_subscribers": 105316, "created_utc": 1683900743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, i feel like a caveman discovering fire.  Apologies if this is something which is generally know, but just in case this helps anyone else with a typical SQL limitation.\n\nI've just found out that on Snowflake you can do a \"SELECT *\" query and exclude specific column. for example:\n\n SELECT * EXCLUDE (field1, field2...) from tableName;\n\n I feel like ive been wanting this for YEARS in SQL but didn't know Snowflake had it! \n\nFor me personally, It works as a shorthand way of making checksums for very wide tables when I'm having to implement SCD2/CDC without a usable date check field. Such as:\n\nSELECT id, HASH(*) AS checksum FROM (SELECT * EXCLUDE (field1, fields2...) FROM tableName );", "author_fullname": "t2_4smhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake SELECT * EXCLUDE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gckaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683969388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i feel like a caveman discovering fire.  Apologies if this is something which is generally know, but just in case this helps anyone else with a typical SQL limitation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just found out that on Snowflake you can do a &amp;quot;SELECT *&amp;quot; query and exclude specific column. for example:&lt;/p&gt;\n\n&lt;p&gt;SELECT * EXCLUDE (field1, field2...) from tableName;&lt;/p&gt;\n\n&lt;p&gt;I feel like ive been wanting this for YEARS in SQL but didn&amp;#39;t know Snowflake had it! &lt;/p&gt;\n\n&lt;p&gt;For me personally, It works as a shorthand way of making checksums for very wide tables when I&amp;#39;m having to implement SCD2/CDC without a usable date check field. Such as:&lt;/p&gt;\n\n&lt;p&gt;SELECT id, HASH(*) AS checksum FROM (SELECT * EXCLUDE (field1, fields2...) FROM tableName );&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13gckaq", "is_robot_indexable": true, "report_reasons": null, "author": "andyby2k26", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13gckaq/snowflake_select_exclude/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13gckaq/snowflake_select_exclude/", "subreddit_subscribers": 105316, "created_utc": 1683969388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've only been using trino for about a month now in a practical sense but I have really grown to love it. It's a really nice way of joining datasets across databases. \n\nI've been pulling data outta parquet files in s3 (hive/glue) then joining them with a postgres instance. Works wonderfully. It's been working so well that I even got the green light from my boss to start using it in production. \n\nI don't see many folks use it here, which makes me wonder what obvious flaw in missing. Would anyone care to help me understand what it's barriers to adoption have been?\n\nUpdate: thanks for all the support guys", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experiences with trino? What am I missing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ftlcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683927517.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683917336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve only been using trino for about a month now in a practical sense but I have really grown to love it. It&amp;#39;s a really nice way of joining datasets across databases. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been pulling data outta parquet files in s3 (hive/glue) then joining them with a postgres instance. Works wonderfully. It&amp;#39;s been working so well that I even got the green light from my boss to start using it in production. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see many folks use it here, which makes me wonder what obvious flaw in missing. Would anyone care to help me understand what it&amp;#39;s barriers to adoption have been?&lt;/p&gt;\n\n&lt;p&gt;Update: thanks for all the support guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13ftlcp", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ftlcp/experiences_with_trino_what_am_i_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ftlcp/experiences_with_trino_what_am_i_missing/", "subreddit_subscribers": 105316, "created_utc": 1683917336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nTrying to maybe switch to data engineering from data science. I use vs code. Would you guys can recommend me an IDE and some extensions I can use for data engineering.\n\nI apologize if the question is dumb or doesn\u2019t make deme so any input is appreciated.", "author_fullname": "t2_5cb0c4v0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best IDE for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g08hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683933150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Trying to maybe switch to data engineering from data science. I use vs code. Would you guys can recommend me an IDE and some extensions I can use for data engineering.&lt;/p&gt;\n\n&lt;p&gt;I apologize if the question is dumb or doesn\u2019t make deme so any input is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13g08hr", "is_robot_indexable": true, "report_reasons": null, "author": "jfhurtado89", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13g08hr/best_ide_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13g08hr/best_ide_for_data_engineering/", "subreddit_subscribers": 105316, "created_utc": 1683933150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm planning to find a course or some training material online to re-learn about Spark. I never was that proficient with it because the internals of it went over my head (RDDs), but I need to refresh myself with Spark for an upcoming interview. \n\nIs Spark 3 pretty dominant? It's not an issue of Python 2 vs 3 like when Python3 was initially released, right? If anyone has any good suggestions on learning materials, I'd love to hear them! I was hoping to find something like a Docker container online that I could re-use, but was going to spin up something on AWS to just play with.", "author_fullname": "t2_1k8fjdz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to refresh myself on some Spark (specifically PySpark) over the next week after not using it for 6 years - should I go with Spark 3 or is Spark 2 still common?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fzayq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683930878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning to find a course or some training material online to re-learn about Spark. I never was that proficient with it because the internals of it went over my head (RDDs), but I need to refresh myself with Spark for an upcoming interview. &lt;/p&gt;\n\n&lt;p&gt;Is Spark 3 pretty dominant? It&amp;#39;s not an issue of Python 2 vs 3 like when Python3 was initially released, right? If anyone has any good suggestions on learning materials, I&amp;#39;d love to hear them! I was hoping to find something like a Docker container online that I could re-use, but was going to spin up something on AWS to just play with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fzayq", "is_robot_indexable": true, "report_reasons": null, "author": "jbnpoc", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fzayq/need_to_refresh_myself_on_some_spark_specifically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fzayq/need_to_refresh_myself_on_some_spark_specifically/", "subreddit_subscribers": 105316, "created_utc": 1683930878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for books that can help with learning database internals. Specifically the core components that makes up a database and how to implements.\n\nThe book should probably cover the query engine parts (sql parsing, query plans etc) and the persistence part.", "author_fullname": "t2_3euic3tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation on Database internals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13foyk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683906878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for books that can help with learning database internals. Specifically the core components that makes up a database and how to implements.&lt;/p&gt;\n\n&lt;p&gt;The book should probably cover the query engine parts (sql parsing, query plans etc) and the persistence part.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13foyk5", "is_robot_indexable": true, "report_reasons": null, "author": "finlaydotweber", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13foyk5/book_recommendation_on_database_internals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13foyk5/book_recommendation_on_database_internals/", "subreddit_subscribers": 105316, "created_utc": 1683906878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm taking kind of a DE role on a project. I have a couple people trying to do some data science, and they need data from a database I'm familiar with, but they are not.\n\nI'm getting them data by connecting different tables together, it's not something that's just automatically available.\n\nSo I'm doing OK communicating how the data links and what is/is not available, but I'm wondering if there are tools or techniques I could use to better communicate?", "author_fullname": "t2_eet0u6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you use/how do you communicate what/how data is available?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g4zs8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683945793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m taking kind of a DE role on a project. I have a couple people trying to do some data science, and they need data from a database I&amp;#39;m familiar with, but they are not.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m getting them data by connecting different tables together, it&amp;#39;s not something that&amp;#39;s just automatically available.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m doing OK communicating how the data links and what is/is not available, but I&amp;#39;m wondering if there are tools or techniques I could use to better communicate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13g4zs8", "is_robot_indexable": true, "report_reasons": null, "author": "NotnotNeo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13g4zs8/what_tools_do_you_usehow_do_you_communicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13g4zs8/what_tools_do_you_usehow_do_you_communicate/", "subreddit_subscribers": 105316, "created_utc": 1683945793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[No engineers want to maintain the legacy code base and now I know why.](https://preview.redd.it/uhldex4mbgza1.png?width=628&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fc47a003d1c5e3b6f27e38e553f5028fb8088ca3)", "author_fullname": "t2_pai1g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I challenge you to have more group by columns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 117, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uhldex4mbgza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 90, "x": 108, "u": "https://preview.redd.it/uhldex4mbgza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fa617f1a2eeba28d8dfc65a3c8d9039117c014f"}, {"y": 181, "x": 216, "u": "https://preview.redd.it/uhldex4mbgza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95886e572ed92444d7b71abdfe4f396b0040e324"}, {"y": 268, "x": 320, "u": "https://preview.redd.it/uhldex4mbgza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e1486481d8e86ab645548eed7947bb70f1bc454"}], "s": {"y": 527, "x": 628, "u": "https://preview.redd.it/uhldex4mbgza1.png?width=628&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fc47a003d1c5e3b6f27e38e553f5028fb8088ca3"}, "id": "uhldex4mbgza1"}}, "name": "t3_13ful9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NZh779OQC5RI5ghIb_rB7atYCeDpjCAgcL_r46naRYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683919692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uhldex4mbgza1.png?width=628&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fc47a003d1c5e3b6f27e38e553f5028fb8088ca3\"&gt;No engineers want to maintain the legacy code base and now I know why.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13ful9o", "is_robot_indexable": true, "report_reasons": null, "author": "JakeModeler", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ful9o/i_challenge_you_to_have_more_group_by_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ful9o/i_challenge_you_to_have_more_group_by_columns/", "subreddit_subscribers": 105316, "created_utc": 1683919692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently using Airflow to orchestrate some tasks in our data pipeline (such as hitting a remote endpoint to fetch data). My task is a bash command that executes a Python script with lots of parameters (SFTP information, our data warehouse information). This feels like a poor pattern, and I was hoping to get some advice on what a better way of doing this is. Ideally, I'd like a solution that I could run locally as a standalone command, but could also be easily called by Airflow remotely.  \n\n\nTo be clear, I am not hardcoding sensitive information like access credentials as parameters. I fetch them from Airflow's Variable manager.  \n\n\nThank you!", "author_fullname": "t2_l16rampa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a better parameter passing pattern? (Airflow)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fqcbc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683909938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently using Airflow to orchestrate some tasks in our data pipeline (such as hitting a remote endpoint to fetch data). My task is a bash command that executes a Python script with lots of parameters (SFTP information, our data warehouse information). This feels like a poor pattern, and I was hoping to get some advice on what a better way of doing this is. Ideally, I&amp;#39;d like a solution that I could run locally as a standalone command, but could also be easily called by Airflow remotely.  &lt;/p&gt;\n\n&lt;p&gt;To be clear, I am not hardcoding sensitive information like access credentials as parameters. I fetch them from Airflow&amp;#39;s Variable manager.  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fqcbc", "is_robot_indexable": true, "report_reasons": null, "author": "Busy-Pie-4468", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fqcbc/suggestions_for_a_better_parameter_passing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fqcbc/suggestions_for_a_better_parameter_passing/", "subreddit_subscribers": 105316, "created_utc": 1683909938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have done my B.Tech in Computer Science and was always interested in the Big Data / Data Science domain. The company in which I got placed on campus put me into the SAP ERP department as a Software Engineer.\n\nI have almost 2 years of experience in SAP ABAP domain. Now I really wish to switch to Data Engineering only. I have started learning and practising on the skills such as Hadoop, Scala, Hive, etc.\n\nMy question is - How can I take benefit of my 2 years of non-DE experience and grab good opportunities in DE field ?\nWhat all transferrable skills can I show in the interviews? \nWhat all DE projects should be there on my resume so that it looks a strong one?", "author_fullname": "t2_vc4vqd0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch from SAP ABAP to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g6z69", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683951610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have done my B.Tech in Computer Science and was always interested in the Big Data / Data Science domain. The company in which I got placed on campus put me into the SAP ERP department as a Software Engineer.&lt;/p&gt;\n\n&lt;p&gt;I have almost 2 years of experience in SAP ABAP domain. Now I really wish to switch to Data Engineering only. I have started learning and practising on the skills such as Hadoop, Scala, Hive, etc.&lt;/p&gt;\n\n&lt;p&gt;My question is - How can I take benefit of my 2 years of non-DE experience and grab good opportunities in DE field ?\nWhat all transferrable skills can I show in the interviews? \nWhat all DE projects should be there on my resume so that it looks a strong one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13g6z69", "is_robot_indexable": true, "report_reasons": null, "author": "Mango4305", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13g6z69/switch_from_sap_abap_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13g6z69/switch_from_sap_abap_to_data_engineering/", "subreddit_subscribers": 105316, "created_utc": 1683951610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I already have about 5 years of experience in data engineering and devops, as well as an MS in CS.\n\n\n\n\n\nWith the job market not so great where I am, it seems like it would be worth it gaining valuable experience at my current job while doing Coursera courses in my free time.  My theory is that companies are now being more careful hiring candidates who are an exact match for the job description, instead of hiring engineers from other fields who taught themselves Python and SQL.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are online courses/certificates seen for experienced engineers applying for jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fv0bk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1683920905.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683920696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already have about 5 years of experience in data engineering and devops, as well as an MS in CS.&lt;/p&gt;\n\n&lt;p&gt;With the job market not so great where I am, it seems like it would be worth it gaining valuable experience at my current job while doing Coursera courses in my free time.  My theory is that companies are now being more careful hiring candidates who are an exact match for the job description, instead of hiring engineers from other fields who taught themselves Python and SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13fv0bk", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fv0bk/how_are_online_coursescertificates_seen_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fv0bk/how_are_online_coursescertificates_seen_for/", "subreddit_subscribers": 105316, "created_utc": 1683920696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all, \n\nI'm currently a data engineer having some problems with making sure I can trust my data, things like schema changes, heavy outliers, bull shit fields, (and many other things). Do any of yall have this issue ? How do yall currently solve it ?", "author_fullname": "t2_2urj7hkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trust with data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fw6ck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683923447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer having some problems with making sure I can trust my data, things like schema changes, heavy outliers, bull shit fields, (and many other things). Do any of yall have this issue ? How do yall currently solve it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fw6ck", "is_robot_indexable": true, "report_reasons": null, "author": "sman1235678", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fw6ck/trust_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fw6ck/trust_with_data/", "subreddit_subscribers": 105316, "created_utc": 1683923447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI\u2019m a Marketing Data Engineer. Right now, my company utilizes 3rd party solutions for customer attribution, such as Google Analytics. Recently we\u2019ve had a push to improve completeness and accuracy, and thereby audibility, of our customer attribution data. This drive comes from a huge uplift in the amount of reporting and analytics we\u2019re doing to learn more about our users and where they come from.\n\nMy idea is that we record the ID of the individual ad-click once customers arrive to our website, and then use our server to query the advertising network for data on that click. Data such as country, time, the ad that it belongs to, etc, and it\u2019ll get stored in our database. \n\nHowever, I\u2019m not really sure if something like this should be combined with existing infrastructure, like our reporting database, or if it should be a standalone data source. Our reporting database doesn\u2019t currently use any external sources to augment its data, and we actually reload the entire reporting database daily. So I\u2019m not sure incorporating 3rd party API calls into that is a good idea.\n\nI\u2019d like to know what some existing solutions are elsewhere and hopefully get some ideas rolling for myself. Is a typical relational database fine for this, or perhaps a graph database would be more future-proof if we wanted to expect into some deeper attribution concepts. I\u2019m not sure what the best call is at this stage.\n\nWhat do you do at your company? How do you manage the volume of attribution data as well? Thanks in advance!!", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company process customer attribution data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fu79o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683918766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a Marketing Data Engineer. Right now, my company utilizes 3rd party solutions for customer attribution, such as Google Analytics. Recently we\u2019ve had a push to improve completeness and accuracy, and thereby audibility, of our customer attribution data. This drive comes from a huge uplift in the amount of reporting and analytics we\u2019re doing to learn more about our users and where they come from.&lt;/p&gt;\n\n&lt;p&gt;My idea is that we record the ID of the individual ad-click once customers arrive to our website, and then use our server to query the advertising network for data on that click. Data such as country, time, the ad that it belongs to, etc, and it\u2019ll get stored in our database. &lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m not really sure if something like this should be combined with existing infrastructure, like our reporting database, or if it should be a standalone data source. Our reporting database doesn\u2019t currently use any external sources to augment its data, and we actually reload the entire reporting database daily. So I\u2019m not sure incorporating 3rd party API calls into that is a good idea.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to know what some existing solutions are elsewhere and hopefully get some ideas rolling for myself. Is a typical relational database fine for this, or perhaps a graph database would be more future-proof if we wanted to expect into some deeper attribution concepts. I\u2019m not sure what the best call is at this stage.&lt;/p&gt;\n\n&lt;p&gt;What do you do at your company? How do you manage the volume of attribution data as well? Thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fu79o", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fu79o/how_does_your_company_process_customer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fu79o/how_does_your_company_process_customer/", "subreddit_subscribers": 105316, "created_utc": 1683918766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Views will be critical to understand what the community thinks about Apache Iceberg and whether it can dethrone Parquet.", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats the view on Apache Iceberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gevpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683976817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Views will be critical to understand what the community thinks about Apache Iceberg and whether it can dethrone Parquet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13gevpu", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13gevpu/whats_the_view_on_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13gevpu/whats_the_view_on_apache_iceberg/", "subreddit_subscribers": 105316, "created_utc": 1683976817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have fully running Pyflink code snippet to read from Kafka using the new Flink DataStream (KafkaSource) API and just print out the output to console or write it out to a file. Most of the examples and the official Flink [GitHub](https://github.com/apache/flink/blob/master/flink-python/pyflink/examples/datastream/connectors/kafka_json_format.py)are using the old API (FlinkKafkaConsumer).\n\nI've tried different scenarios but non worked out for me. I do believe I'm not allowed to post any errors or debug logs here.", "author_fullname": "t2_ejsqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyflink : Flink DataStream (KafkaSource) API to consume from Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gde1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683972067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have fully running Pyflink code snippet to read from Kafka using the new Flink DataStream (KafkaSource) API and just print out the output to console or write it out to a file. Most of the examples and the official Flink &lt;a href=\"https://github.com/apache/flink/blob/master/flink-python/pyflink/examples/datastream/connectors/kafka_json_format.py\"&gt;GitHub&lt;/a&gt;are using the old API (FlinkKafkaConsumer).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried different scenarios but non worked out for me. I do believe I&amp;#39;m not allowed to post any errors or debug logs here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?auto=webp&amp;v=enabled&amp;s=c1e43f645194f53789ad93187b39d4ae3c2ede13", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab0bc364f634ee682b4d1fb5e9d14998b2899cd2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=444b27540db2626fba3565ece051766cad02a46f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43e81a99e6730e1a5e539a0f8d5550ce963d048e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5855ed18716cf803999a8a09b53ed6cbdd77bb7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28d94202cd238d16ad1492b77efa589df39523b5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/25pyiGJwiTwA5W0TgGctqvmIaKT1PcbRJ2eH3Lpk2dc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1beab7de72cda29204027d92a0cdd821fa1b5146", "width": 1080, "height": 540}], "variants": {}, "id": "6EJ_i6aTCAq_3HGPqBO99gN9jfXCOUppGLxN8kINyfE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13gde1j", "is_robot_indexable": true, "report_reasons": null, "author": "Matar86", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13gde1j/pyflink_flink_datastream_kafkasource_api_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13gde1j/pyflink_flink_datastream_kafkasource_api_to/", "subreddit_subscribers": 105316, "created_utc": 1683972067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26](https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI-Powered Accommodation Search: Harnessing the Power of Hadoop, MongoDB, Spark, GPT-3, React, and Flask", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v6n37u9r7fza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1c26591cf51b4899063a4de4e1cf4b840a736a5"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee43fa19a842bcae6fe04781993c81a1b272b249"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb13942a173c081a9b073041d17c3e4414ce988e"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cec9f8763636cde8dd4dc1ec9c60aabeca45c538"}, {"y": 704, "x": 960, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e868a51316e71aea5b378773510e791f30ed04c6"}, {"y": 792, "x": 1080, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f0bccc366557812792c49bd33a830bda20b1b8c"}], "s": {"y": 1467, "x": 2000, "u": "https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155"}, "id": "v6n37u9r7fza1"}}, "name": "t3_13folyf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PY6rjNfYT2Nc_9EMr7ennoEXXscCEW2aZ7NF7zXYfZI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1683906076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26\"&gt;https://medium.com/@stefentaime_10958/ai-powered-accommodation-search-harnessing-the-power-of-hadoop-mongodb-spark-gpt-3-react-and-7e0bfc41bf26&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155\"&gt;https://preview.redd.it/v6n37u9r7fza1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f17fd77917838657d0311b23a8f4fdaa80f41155&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?auto=webp&amp;v=enabled&amp;s=b7d104e02301de6fdb1116e8ca11edf5927b1a31", "width": 1200, "height": 880}, "resolutions": [{"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58ad0ac5dd4dbef4e371d78585bc84f701a35919", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caea697455dcd7239ae98c0bd0fdb20a06bf8eb4", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=979a805dcd52927812fac9b54ed10767836551ac", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f266f195aa451fd20beca5af9a54e84bc793d701", "width": 640, "height": 469}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf7fa9c1efde6971bd29aba5a04e7843f84e7745", "width": 960, "height": 704}, {"url": "https://external-preview.redd.it/1lZoiKTdXJXl__5aQUHK3mcSD2AUN9L2LJNesQzNss4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=deefa11b543ad95610e1b55ca055ad6196473259", "width": 1080, "height": 792}], "variants": {}, "id": "iyM2CVIuoHRTdQ0EUrh1AW7Wm9uKzAJrNHLmek4I76c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "13folyf", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13folyf/aipowered_accommodation_search_harnessing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13folyf/aipowered_accommodation_search_harnessing_the/", "subreddit_subscribers": 105316, "created_utc": 1683906076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zipping up the Lambda Architecture for Faster Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": true, "name": "t3_13ghkba", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sQ54rV8ipJeeJHTOhq67zpL_hM7oCMhggXTIET_fCDs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683984378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@ApacheDoris/zipping-up-the-lambda-architecture-for-faster-performance-62ea2f5c5194", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/heBWqW91jvioXojXDKG07wW11-zg3R3Dp8w4NSXAIuc.jpg?auto=webp&amp;v=enabled&amp;s=c167cab4be9beaebb7a68a47e1a39502ca0b94ab", "width": 797, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/heBWqW91jvioXojXDKG07wW11-zg3R3Dp8w4NSXAIuc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f66184515fce510b833f7623e17f30a792f0f53", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/heBWqW91jvioXojXDKG07wW11-zg3R3Dp8w4NSXAIuc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8777e7da7363698934678774f63fcaf358735b9d", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/heBWqW91jvioXojXDKG07wW11-zg3R3Dp8w4NSXAIuc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=438d6f168a3b3a421cfcaacbff08e602a5291a91", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/heBWqW91jvioXojXDKG07wW11-zg3R3Dp8w4NSXAIuc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49ed8140b02700164d2da78553aa6efbc2606cb4", "width": 640, "height": 385}], "variants": {}, "id": "fLhO4wjTRvua6KG3Ji7pJosaGrBDEr6hfv2DsyoYfeQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13ghkba", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ghkba/zipping_up_the_lambda_architecture_for_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@ApacheDoris/zipping-up-the-lambda-architecture-for-faster-performance-62ea2f5c5194", "subreddit_subscribers": 105316, "created_utc": 1683984378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I might be a bit on the OCD side of automate-everything, document-everyday   \n\n\nbut why is it so difficult to source and validate definitions on Google Play Console data?   \n\n\nI kinda feel the same about Apple app store but it looks like it's improved a lot since.   \n\n\nPlease - if anyone has a clear link for first-time downloads and can explain why I don't see any unique installs as a metric coming in via Fivetran, assist this helpless mob please.", "author_fullname": "t2_12aw2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Maybe my standards are too high but where is the easy to use Google Play Console data definitions for connectors like Fivetran?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gfeil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683978405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I might be a bit on the OCD side of automate-everything, document-everyday   &lt;/p&gt;\n\n&lt;p&gt;but why is it so difficult to source and validate definitions on Google Play Console data?   &lt;/p&gt;\n\n&lt;p&gt;I kinda feel the same about Apple app store but it looks like it&amp;#39;s improved a lot since.   &lt;/p&gt;\n\n&lt;p&gt;Please - if anyone has a clear link for first-time downloads and can explain why I don&amp;#39;t see any unique installs as a metric coming in via Fivetran, assist this helpless mob please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13gfeil", "is_robot_indexable": true, "report_reasons": null, "author": "Resili3nce", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13gfeil/maybe_my_standards_are_too_high_but_where_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13gfeil/maybe_my_standards_are_too_high_but_where_is_the/", "subreddit_subscribers": 105316, "created_utc": 1683978405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transformation use case - Apache Spark and Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_13getuh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BJlyj54fP3pnJd-whJ4ziAGNapdvHhDdDGFxeXHybfI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1683976653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decube.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://decube.substack.com/p/data-transformation-use-case-apache", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?auto=webp&amp;v=enabled&amp;s=1d0d6736396b7d384cf3acecc89a96415f900057", "width": 1080, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0caba2f1338ede2b183c249cb20e46f3274dad14", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6f80aa4f0984391947baf3040a2339ef90b1cfe", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3480123c04259da19fd2984399924737a34a3d41", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1effd640097fda211b2b634389c967f2f085459", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=566dabcd0e9db6192335eb543db802638068dbe2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/X-j_n6SwRn9FX8ZO2u48KpVG0PqBul6-6N45aPfjL74.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a81c60b0bd84a1f3e04c4d76c81a21e10abfc86", "width": 1080, "height": 720}], "variants": {}, "id": "kSo6ngTkqQOn1v_7SH0XgZJUTxnGHmY_bWywS-kyy-Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13getuh", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13getuh/data_transformation_use_case_apache_spark_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://decube.substack.com/p/data-transformation-use-case-apache", "subreddit_subscribers": 105316, "created_utc": 1683976653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been a developer for the past couple of years and now i am interested in learning more about the internals of database systems. I figure one of the best place to start is to do a deep dive into SQL, from a technical point of view - so understanding the syntax and semantics, and understanding the query engine bit and how a database system takes the sql, and parse it into things like query plan.\n\nSo to start with this, I looked into SQL parsing and found this library https://github.com/sqlparser-rs/sqlparser-rs\n\nI ran the example but using a much simpler query, basically this\n\n```\nuse sqlparser::dialect::GenericDialect;\nuse sqlparser::parser::Parser;\n\nlet sql = \"SELECT * from table_1\";\n\nlet dialect = GenericDialect {}; // or AnsiDialect, or your own dialect ...\n\nlet ast = Parser::parse_sql(&amp;dialect, sql).unwrap();\n\nprintln!(\"AST: {:?}\", ast);\n```\n\nAnd the output was \n\n```\nAST: [Query(Query { with: None, body: Select(Select { distinct: false, top: None, projection: [Wildcard(WildcardAdditionalOptions { opt_exclude: None, opt_except: None, opt_rename: None, opt_replace: None })], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: \"table_1\", quote_style: None }]), alias: None, args: None, with_hints: [] }, joins: [] }], lateral_views: [], selection: None, group_by: [], cluster_by: [], distribute_by: [], sort_by: [], having: None, qualify: None }), order_by: [], limit: None, offset: None, fetch: None, locks: [] })]\n```\n\nNow this is where my question starts, I know this is an AST, but I don't know what this means. Specifically\n\n1. I don't know how to read this and make meaning out of it\n2. I don't understand what I can do with it. Can I modify it? Can I transform it\n3. I don't understand how to know if it is valid or not\n4. I do not understand what a database system use a data-structure like this and what to do with it next\n\nSo obviously a newbie questions, but will appreciate if I can get some early guidelines to help in this learning path.", "author_fullname": "t2_3euic3tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding the SQL AST and what can be done with it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13g4odx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683944918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a developer for the past couple of years and now i am interested in learning more about the internals of database systems. I figure one of the best place to start is to do a deep dive into SQL, from a technical point of view - so understanding the syntax and semantics, and understanding the query engine bit and how a database system takes the sql, and parse it into things like query plan.&lt;/p&gt;\n\n&lt;p&gt;So to start with this, I looked into SQL parsing and found this library &lt;a href=\"https://github.com/sqlparser-rs/sqlparser-rs\"&gt;https://github.com/sqlparser-rs/sqlparser-rs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I ran the example but using a much simpler query, basically this&lt;/p&gt;\n\n&lt;p&gt;```\nuse sqlparser::dialect::GenericDialect;\nuse sqlparser::parser::Parser;&lt;/p&gt;\n\n&lt;p&gt;let sql = &amp;quot;SELECT * from table_1&amp;quot;;&lt;/p&gt;\n\n&lt;p&gt;let dialect = GenericDialect {}; // or AnsiDialect, or your own dialect ...&lt;/p&gt;\n\n&lt;p&gt;let ast = Parser::parse_sql(&amp;amp;dialect, sql).unwrap();&lt;/p&gt;\n\n&lt;p&gt;println!(&amp;quot;AST: {:?}&amp;quot;, ast);\n```&lt;/p&gt;\n\n&lt;p&gt;And the output was &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\nAST: [Query(Query { with: None, body: Select(Select { distinct: false, top: None, projection: [Wildcard(WildcardAdditionalOptions { opt_exclude: None, opt_except: None, opt_rename: None, opt_replace: None })], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: &amp;quot;table_1&amp;quot;, quote_style: None }]), alias: None, args: None, with_hints: [] }, joins: [] }], lateral_views: [], selection: None, group_by: [], cluster_by: [], distribute_by: [], sort_by: [], having: None, qualify: None }), order_by: [], limit: None, offset: None, fetch: None, locks: [] })]\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Now this is where my question starts, I know this is an AST, but I don&amp;#39;t know what this means. Specifically&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I don&amp;#39;t know how to read this and make meaning out of it&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t understand what I can do with it. Can I modify it? Can I transform it&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t understand how to know if it is valid or not&lt;/li&gt;\n&lt;li&gt;I do not understand what a database system use a data-structure like this and what to do with it next&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So obviously a newbie questions, but will appreciate if I can get some early guidelines to help in this learning path.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?auto=webp&amp;v=enabled&amp;s=01dc42a713bf2ca503be0a4f3df3f368c4f6a887", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a8122f8e93c1cd7f6503f05708631de45569a36", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c173b3b04200205f38902a7031a671f7bcb5cc4e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9fbe6ad353ebea97f667a7bb1c0bbcec86c7e89", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f94cf3be72ff82c55f79a6ee3db949c2206cc2d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e34757b09449450608608954ae3112d1f1a6bfb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/V3PM5nvOR5WBWSu1ksIrNZL9HZIM66yVvO8V9HW9t8M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b0264c47143d48cbc904a506a8fb0d32e18c98e", "width": 1080, "height": 540}], "variants": {}, "id": "AV09gWKDTDR7b6ABHItXQ923EQUcAe0AlunP1u3GmdE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13g4odx", "is_robot_indexable": true, "report_reasons": null, "author": "finlaydotweber", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13g4odx/understanding_the_sql_ast_and_what_can_be_done/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13g4odx/understanding_the_sql_ast_and_what_can_be_done/", "subreddit_subscribers": 105316, "created_utc": 1683944918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have completed 100 days of python by Angela Yu. I am still struggling on how to upskill python for data engineering. Should I just focus on boto3 and pandas? What makes a data engineer strong in python? Does anyone have advice or courses to take?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fvcd9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683921504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have completed 100 days of python by Angela Yu. I am still struggling on how to upskill python for data engineering. Should I just focus on boto3 and pandas? What makes a data engineer strong in python? Does anyone have advice or courses to take?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13fvcd9", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fvcd9/python_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fvcd9/python_advice/", "subreddit_subscribers": 105316, "created_utc": 1683921504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone has any insight or experience using [Pivot](https://pivotcomputing.io/platform) to manage their DBT instance.  \n\n\nI am a one-man shop, using VS Code to write my code, mainly, and DBT cloud to run jobs on a schedule.  Each work off the same repository.  \n\n\nI'd like to use a more robust scheduler, but don't have the bandwidth to start learning Airflow.  Pivot looks more cost effective, and a good change from the free dbt Cloud offering.  \n\n\nThoughts?  Thanks, in advance, y'all.", "author_fullname": "t2_1ow2e6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Thoughts on Pivot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13fpkgd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1683908201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone has any insight or experience using &lt;a href=\"https://pivotcomputing.io/platform\"&gt;Pivot&lt;/a&gt; to manage their DBT instance.  &lt;/p&gt;\n\n&lt;p&gt;I am a one-man shop, using VS Code to write my code, mainly, and DBT cloud to run jobs on a schedule.  Each work off the same repository.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to use a more robust scheduler, but don&amp;#39;t have the bandwidth to start learning Airflow.  Pivot looks more cost effective, and a good change from the free dbt Cloud offering.  &lt;/p&gt;\n\n&lt;p&gt;Thoughts?  Thanks, in advance, y&amp;#39;all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?auto=webp&amp;v=enabled&amp;s=9ed9a5a7a7e99641a1e29a48e651f1103dab8e55", "width": 536, "height": 537}, "resolutions": [{"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f636c7dfde8c4e3617150d24ec7d827b99d5883c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c87c0bda2d9e0ff6c2b375c9833139b96432a0c", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/3GqTMzgOsQamk5HHX9YgfonfYj7xNju68sYZSZbEK3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb450abb15a673312ef31fca522853976fb6de40", "width": 320, "height": 320}], "variants": {}, "id": "e3zEncRW_tf7BAkQRULi2gaGkk_bcxRhTYI24wwtQjA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Head of BI", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fpkgd", "is_robot_indexable": true, "report_reasons": null, "author": "Cat_Phish", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13fpkgd/any_thoughts_on_pivot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fpkgd/any_thoughts_on_pivot/", "subreddit_subscribers": 105316, "created_utc": 1683908201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any experience/recommendations on a greenfield build for a **financial** data warehouse stack? \n\nExample of the high level current process is in the image but basically the scope is to extract data from all billing, payment and operational systems that have financial information, transform them into both P&amp;L facts/dims and Journal Entries to integrate directly into Netsuite. \n\nVolume is over 1M a month in transactions, currently have snowflake with some basic connectors but I'm not married to anything! \n\nhttps://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9", "author_fullname": "t2_vl7599r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial Data Warehouse Stack - Greenfield", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1xfq6wmbqeza1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ad90a44e06254f983a02437c202d3f579c55d2b"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7dfc27f5231781976a47021147e9fa047377b10"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2d77a0a658270bf3fe46411a6fa835d4b428137"}, {"y": 298, "x": 640, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5386ef7aec7d776fbf1cb0f5314981ca463cfd05"}, {"y": 447, "x": 960, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db1eb2a94857f2d64ba641eade64a0df8495dc48"}, {"y": 502, "x": 1080, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c664f191e93c907e4ae04fde551270edd55bd08a"}], "s": {"y": 556, "x": 1194, "u": "https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9"}, "id": "1xfq6wmbqeza1"}}, "name": "t3_13fm7zf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/7khzCnkKqOLoAFzoG-uNWMZQVFlnP_vH4T-FrlGTOE4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683900408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any experience/recommendations on a greenfield build for a &lt;strong&gt;financial&lt;/strong&gt; data warehouse stack? &lt;/p&gt;\n\n&lt;p&gt;Example of the high level current process is in the image but basically the scope is to extract data from all billing, payment and operational systems that have financial information, transform them into both P&amp;amp;L facts/dims and Journal Entries to integrate directly into Netsuite. &lt;/p&gt;\n\n&lt;p&gt;Volume is over 1M a month in transactions, currently have snowflake with some basic connectors but I&amp;#39;m not married to anything! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9\"&gt;https://preview.redd.it/1xfq6wmbqeza1.png?width=1194&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70d9db2f8e57b7bfd22c64422b0336d7df803de9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13fm7zf", "is_robot_indexable": true, "report_reasons": null, "author": "Hopeful_Tutor3549", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13fm7zf/financial_data_warehouse_stack_greenfield/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13fm7zf/financial_data_warehouse_stack_greenfield/", "subreddit_subscribers": 105316, "created_utc": 1683900408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am really confused if I should become a DE or there are better career options?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why become a data engineer in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13gb4g2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1683964612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am really confused if I should become a DE or there are better career options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13gb4g2", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13gb4g2/why_become_a_data_engineer_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13gb4g2/why_become_a_data_engineer_in_2023/", "subreddit_subscribers": 105316, "created_utc": 1683964612.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}