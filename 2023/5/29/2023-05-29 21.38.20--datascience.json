{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If you\u2019ve recently scored a job and happy with it, please give us a snapshot of your background and the role that you\u2019ve landed.", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sick of the Career doom and gloom- if you\u2019ve recently scored a job tell us about it. Keen to hear some positive experiences!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uqs5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 139, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 139, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685355425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you\u2019ve recently scored a job and happy with it, please give us a snapshot of your background and the role that you\u2019ve landed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uqs5p", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uqs5p/sick_of_the_career_doom_and_gloom_if_youve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uqs5p/sick_of_the_career_doom_and_gloom_if_youve/", "subreddit_subscribers": 912611, "created_utc": 1685355425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.   \n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?   \nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don't really would like to do another Msc or a Phd. Is my worry correct or not necessarily?   \nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?", "author_fullname": "t2_dfmfjyei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I worked in DS jobs closely connected to business but I strongly dislike that and want to work in more technical jobs. What are some areas I could explore? And how to transition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ucq03", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 96, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 96, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685311958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.&lt;br/&gt;\n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?&lt;br/&gt;\nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don&amp;#39;t really would like to do another Msc or a Phd. Is my worry correct or not necessarily?&lt;br/&gt;\nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ucq03", "is_robot_indexable": true, "report_reasons": null, "author": "TheManveru", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "subreddit_subscribers": 912611, "created_utc": 1685311958.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Senior DS and hiring managers, how are you finding the job market right now? Is it the same for DS jobs as SDE jobs? Is the job market for lower positions saturated with new grads and laid-off experienced folk? \n\nWould you see yourself getting an interview call for the position you are holding right now? Do degrees matter more than experience? What would you like to see in a candidate to make the hiring decision easier for you?", "author_fullname": "t2_875mxmzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does it look from the other side for hiring currently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ul5oa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685335736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Senior DS and hiring managers, how are you finding the job market right now? Is it the same for DS jobs as SDE jobs? Is the job market for lower positions saturated with new grads and laid-off experienced folk? &lt;/p&gt;\n\n&lt;p&gt;Would you see yourself getting an interview call for the position you are holding right now? Do degrees matter more than experience? What would you like to see in a candidate to make the hiring decision easier for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ul5oa", "is_robot_indexable": true, "report_reasons": null, "author": "dark-ascension", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ul5oa/how_does_it_look_from_the_other_side_for_hiring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ul5oa/how_does_it_look_from_the_other_side_for_hiring/", "subreddit_subscribers": 912611, "created_utc": 1685335736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with imbalanced datetime data in Pandas? Any techniques for resampling or handling irregular time intervals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uu2kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685364733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uu2kw", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uu2kw/how_do_you_deal_with_imbalanced_datetime_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uu2kw/how_do_you_deal_with_imbalanced_datetime_data_in/", "subreddit_subscribers": 912611, "created_utc": 1685364733.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering about that, specially on the midst of discussions about remote x return to the office. Do your organization measure hours spent on tasks/projects? Amount of money saved because a project was successfully implemented?", "author_fullname": "t2_7e27w7hg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your organization measure productivity of data analyst/scientists? Wich model do you think would be more effective?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uvq7k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685368743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering about that, specially on the midst of discussions about remote x return to the office. Do your organization measure hours spent on tasks/projects? Amount of money saved because a project was successfully implemented?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uvq7k", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Wave356", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uvq7k/how_does_your_organization_measure_productivity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uvq7k/how_does_your_organization_measure_productivity/", "subreddit_subscribers": 912611, "created_utc": 1685368743.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 29 May, 2023 - 05 Jun, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uk8qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685332890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uk8qw", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uk8qw/weekly_entering_transitioning_thread_29_may_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/13uk8qw/weekly_entering_transitioning_thread_29_may_2023/", "subreddit_subscribers": 912611, "created_utc": 1685332890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a Computer Vision engineer, working mostly with classification and object detection problems. Work is quite demanding so whatever time I get, I try to search for new stuff happening in Computer Vision/Deep Learning space.\n\nI usually rely on LinkedIn, Twitter and Reddit. At times I find good stuff while scrolling but not always.\n\nI really want few fixed sources (3-4 sites maybe?) which keeps me somewhat up to date in this space. I know it's very difficult to stay 100% upto date.\n\nAlso, not limiting the space to only classification and object detection, it can be any area in Computer Vision (Zero shot learning, new Optimizers, survey papers, LLM + CV, etc)\n\nFew sources I refer to apart from above (not very regular though)\n\n1. Papers with code\n2. Arxiv\n3. Meta/Google blogs\n\nLooking for guidance and help \ud83d\ude4f", "author_fullname": "t2_8sex2y19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance to stay somewhat up-to date", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13v1uah", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685383217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Computer Vision engineer, working mostly with classification and object detection problems. Work is quite demanding so whatever time I get, I try to search for new stuff happening in Computer Vision/Deep Learning space.&lt;/p&gt;\n\n&lt;p&gt;I usually rely on LinkedIn, Twitter and Reddit. At times I find good stuff while scrolling but not always.&lt;/p&gt;\n\n&lt;p&gt;I really want few fixed sources (3-4 sites maybe?) which keeps me somewhat up to date in this space. I know it&amp;#39;s very difficult to stay 100% upto date.&lt;/p&gt;\n\n&lt;p&gt;Also, not limiting the space to only classification and object detection, it can be any area in Computer Vision (Zero shot learning, new Optimizers, survey papers, LLM + CV, etc)&lt;/p&gt;\n\n&lt;p&gt;Few sources I refer to apart from above (not very regular though)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Papers with code&lt;/li&gt;\n&lt;li&gt;Arxiv&lt;/li&gt;\n&lt;li&gt;Meta/Google blogs&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking for guidance and help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v1uah", "is_robot_indexable": true, "report_reasons": null, "author": "Public-Mechanic-5476", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v1uah/guidance_to_stay_somewhat_upto_date/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v1uah/guidance_to_stay_somewhat_upto_date/", "subreddit_subscribers": 912611, "created_utc": 1685383217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey ya'll, \n\nCan you find DS jobs that are more stats focused, and how?\n\nTransitioning from academic research to DS, and while I'm good with data manipulation and statistics, we never used NNs in my training and, tbh, I'm not super interested in getting into it right now. I like statistical models, and I feel like there are still a lot of them I want to learn/get a chance to use.", "author_fullname": "t2_rzuzjxcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stats-focused jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13v01t3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685378892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey ya&amp;#39;ll, &lt;/p&gt;\n\n&lt;p&gt;Can you find DS jobs that are more stats focused, and how?&lt;/p&gt;\n\n&lt;p&gt;Transitioning from academic research to DS, and while I&amp;#39;m good with data manipulation and statistics, we never used NNs in my training and, tbh, I&amp;#39;m not super interested in getting into it right now. I like statistical models, and I feel like there are still a lot of them I want to learn/get a chance to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v01t3", "is_robot_indexable": true, "report_reasons": null, "author": "empirical-sadboy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v01t3/statsfocused_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v01t3/statsfocused_jobs/", "subreddit_subscribers": 912611, "created_utc": 1685378892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9792cqxim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In Python Operator Precedence , all operators if i exclude priority are solved from left to right except (exponent) ? is there Any specific Reasons behind it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13v1x18", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685383377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v1x18", "is_robot_indexable": true, "report_reasons": null, "author": "Dipanshuz1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v1x18/in_python_operator_precedence_all_operators_if_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v1x18/in_python_operator_precedence_all_operators_if_i/", "subreddit_subscribers": 912611, "created_utc": 1685383377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am a new immigrant to Canada who is trying to find Data Scientist opportunities in this brutal market. I have around 4+ years of relevant experience and a Master's degree in engineering from my home country under my belt. I am working at a small company currently. However, I am finding it hard to move to a better/bigger opportunity. I was able to get to the final rounds of interviews at the handful of companies and at least 3 of the opportunities I lost to folks having Master's from Canadian University which makes me wonder if I should go back to university. At the same time I am not sure whether I am ready for such big commitment (time and finance wise) at this point in my life. I see these online Master's programs. Can someone tell me how valuable are they in the job market?", "author_fullname": "t2_b63krvaxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would Masters from American/Canadian University help me find a better opportunity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13v5o3j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685392277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a new immigrant to Canada who is trying to find Data Scientist opportunities in this brutal market. I have around 4+ years of relevant experience and a Master&amp;#39;s degree in engineering from my home country under my belt. I am working at a small company currently. However, I am finding it hard to move to a better/bigger opportunity. I was able to get to the final rounds of interviews at the handful of companies and at least 3 of the opportunities I lost to folks having Master&amp;#39;s from Canadian University which makes me wonder if I should go back to university. At the same time I am not sure whether I am ready for such big commitment (time and finance wise) at this point in my life. I see these online Master&amp;#39;s programs. Can someone tell me how valuable are they in the job market?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v5o3j", "is_robot_indexable": true, "report_reasons": null, "author": "ExcuseNo6720", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v5o3j/would_masters_from_americancanadian_university/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v5o3j/would_masters_from_americancanadian_university/", "subreddit_subscribers": 912611, "created_utc": 1685392277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nI'm a mathematician/process/statistical modeller working in agricultural/environmental science. Our company has invested in Snowflake for data storage and R for data analysis. However I am finding that the volumes of data are becoming a bit more than can be comfortably handled in R on a single PC (we're in Windows 10). I am looking for options for data visualisation, extraction, cleaning, statistical modelling that don't require downloading the data and/or having it in memory. I don't really understand the IT side of data science very well, but two options look like Spark(lyr) and Snowpark.\n\nAny suggestions or advice or experience you can share?\n\nThanks!", "author_fullname": "t2_221frg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tools for modelling (e.g. lm, gam) high res time series data in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13v4g8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685389404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a mathematician/process/statistical modeller working in agricultural/environmental science. Our company has invested in Snowflake for data storage and R for data analysis. However I am finding that the volumes of data are becoming a bit more than can be comfortably handled in R on a single PC (we&amp;#39;re in Windows 10). I am looking for options for data visualisation, extraction, cleaning, statistical modelling that don&amp;#39;t require downloading the data and/or having it in memory. I don&amp;#39;t really understand the IT side of data science very well, but two options look like Spark(lyr) and Snowpark.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or advice or experience you can share?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v4g8l", "is_robot_indexable": true, "report_reasons": null, "author": "si_wo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v4g8l/best_tools_for_modelling_eg_lm_gam_high_res_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v4g8l/best_tools_for_modelling_eg_lm_gam_high_res_time/", "subreddit_subscribers": 912611, "created_utc": 1685389404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR need advice on the job search optimization problem of getting hired quickly without compromising too much.\n\nI recently got laid off by my employer, and time is not on my side. Unfortunately, I didn't manage my time efficiently in the beginning, and ended up burning through* a couple of weeks in wrapping up administrative formalities, securing insurance, and exploring options to pause the clock (to no avail). Now, I only have around 40 days left before I lose my immigration status.\n\nI'm urgently looking for opportunities as an Applied/Data/Research Scientist or Machine Learning Engineer/Researcher, or related roles that require a Master's degree plus two to three years of experience. I hold a Master's degree from a prestigious MSDS program and have gained a diverse range of internship and work experiences, including at academic and tech R&amp;D labs, non-profits, and early-stage startups. Over the past seven years, I have focused on Al/CV/DL/DS/ML/NLP, with all my coursework, projects, publications, and work experience aligned with these domains. However, I lack full-time work experience with a recognizable brand on my resume.\n\n  \nWhile I have a preference for the aforementioned roles, I am also open to positions like Business Analyst and Data Analyst/Engineer. I have confidence in my abilities to excel in rigorous interview loops, having performed well in the past (even though I declined the offers). However, given the time constraints, waiting for callbacks is not a luxury I can afford, especially considering that interview processes themselves can take up to a month.\n\n  \nConsidering my situation, I understand the need to be flexible, but I'm trying to hold out a little longer without compromising on more than one of the following:\n\n* Relocating\n* Taking a pay cut\n* Technical rigor (specifically in ML/Stats)\n\n  \nHowever, I\u2019m well aware of my circumstances, and am no more than a week or so out on loosening my standards further. I have, also, thus far focused on quality rather than quantity in my job applications. By that I mean I tailor my resume specific to each role\u2019s job description and strive to obtain referrals from my network to establish direct contact with hiring managers or recruiters. Alternatively, when applying through LinkedIn, I reach out to them directly to ensure greater likelihood of my resume being looked at by a pair of eyes, and general prompt attention to and review of my application. But I'm unsure if this approach is the most effective, and I'm considering shifting gears to mass cold applications using a generic resume (I have some strategies and scripts to assist me with that).\n\nI would greatly appreciate any advice, thoughts, or insights that can assist me in my endeavor. Additionally, I would be grateful if you could spare some time to provide feedback on my base resume (please comment if you're so willing and I'll reach out to you via DM). \n\nThank you all for your support and guidance!", "author_fullname": "t2_628ffgtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Job Application Advice for a US Non-Citizen with a Ticking Clock", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uut5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685367499.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685366545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR need advice on the job search optimization problem of getting hired quickly without compromising too much.&lt;/p&gt;\n\n&lt;p&gt;I recently got laid off by my employer, and time is not on my side. Unfortunately, I didn&amp;#39;t manage my time efficiently in the beginning, and ended up burning through* a couple of weeks in wrapping up administrative formalities, securing insurance, and exploring options to pause the clock (to no avail). Now, I only have around 40 days left before I lose my immigration status.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m urgently looking for opportunities as an Applied/Data/Research Scientist or Machine Learning Engineer/Researcher, or related roles that require a Master&amp;#39;s degree plus two to three years of experience. I hold a Master&amp;#39;s degree from a prestigious MSDS program and have gained a diverse range of internship and work experiences, including at academic and tech R&amp;amp;D labs, non-profits, and early-stage startups. Over the past seven years, I have focused on Al/CV/DL/DS/ML/NLP, with all my coursework, projects, publications, and work experience aligned with these domains. However, I lack full-time work experience with a recognizable brand on my resume.&lt;/p&gt;\n\n&lt;p&gt;While I have a preference for the aforementioned roles, I am also open to positions like Business Analyst and Data Analyst/Engineer. I have confidence in my abilities to excel in rigorous interview loops, having performed well in the past (even though I declined the offers). However, given the time constraints, waiting for callbacks is not a luxury I can afford, especially considering that interview processes themselves can take up to a month.&lt;/p&gt;\n\n&lt;p&gt;Considering my situation, I understand the need to be flexible, but I&amp;#39;m trying to hold out a little longer without compromising on more than one of the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Relocating&lt;/li&gt;\n&lt;li&gt;Taking a pay cut&lt;/li&gt;\n&lt;li&gt;Technical rigor (specifically in ML/Stats)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;However, I\u2019m well aware of my circumstances, and am no more than a week or so out on loosening my standards further. I have, also, thus far focused on quality rather than quantity in my job applications. By that I mean I tailor my resume specific to each role\u2019s job description and strive to obtain referrals from my network to establish direct contact with hiring managers or recruiters. Alternatively, when applying through LinkedIn, I reach out to them directly to ensure greater likelihood of my resume being looked at by a pair of eyes, and general prompt attention to and review of my application. But I&amp;#39;m unsure if this approach is the most effective, and I&amp;#39;m considering shifting gears to mass cold applications using a generic resume (I have some strategies and scripts to assist me with that).&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any advice, thoughts, or insights that can assist me in my endeavor. Additionally, I would be grateful if you could spare some time to provide feedback on my base resume (please comment if you&amp;#39;re so willing and I&amp;#39;ll reach out to you via DM). &lt;/p&gt;\n\n&lt;p&gt;Thank you all for your support and guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uut5k", "is_robot_indexable": true, "report_reasons": null, "author": "pro_memory_maker", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uut5k/seeking_job_application_advice_for_a_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uut5k/seeking_job_application_advice_for_a_us/", "subreddit_subscribers": 912611, "created_utc": 1685366545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. \n\nWhat's the minimum amount of data needed for reliable results? Even if I don't have enough data, should I run the model anyway?\n\nI have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?\n\nPlease share your experiences, rule-of-thumb guidelines, and any relevant resources. \n\nThanks.", "author_fullname": "t2_s6n4mlrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trajectory model - enough data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uh97w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685324071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the minimum amount of data needed for reliable results? Even if I don&amp;#39;t have enough data, should I run the model anyway?&lt;/p&gt;\n\n&lt;p&gt;I have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?&lt;/p&gt;\n\n&lt;p&gt;Please share your experiences, rule-of-thumb guidelines, and any relevant resources. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uh97w", "is_robot_indexable": true, "report_reasons": null, "author": "metalhead_nerd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "subreddit_subscribers": 912611, "created_utc": 1685324071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, mew blog post about how to create a a 20-line python script that lets ChatGPT answer questions on any PDF\n\n[https://medium.com/@pancemarko/talk-to-any-pdf-with-chatgpt-in-20-lines-of-code-66562f1b65bd](https://medium.com/@pancemarko/talk-to-any-pdf-with-chatgpt-in-20-lines-of-code-66562f1b65bd)", "author_fullname": "t2_g7d85dlg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Talk to any PDF in 20 lines of code using langchain and python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13v1d3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685382010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, mew blog post about how to create a a 20-line python script that lets ChatGPT answer questions on any PDF&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@pancemarko/talk-to-any-pdf-with-chatgpt-in-20-lines-of-code-66562f1b65bd\"&gt;https://medium.com/@pancemarko/talk-to-any-pdf-with-chatgpt-in-20-lines-of-code-66562f1b65bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13v1d3i", "is_robot_indexable": true, "report_reasons": null, "author": "mpance_89", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13v1d3i/talk_to_any_pdf_in_20_lines_of_code_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13v1d3i/talk_to_any_pdf_in_20_lines_of_code_using/", "subreddit_subscribers": 912611, "created_utc": 1685382010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any one who's learning machine learning from Andrew Ng's Machine Learning Specialization on Coursera?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uwz7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_hcgjj0xo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnmachinelearning", "selftext": "I'm looking to connect with peers who are new to machine learning. More specifically, if someone is learning from Andrew Ng's Specialization on Coursera.\n\nI'm new to this and still figuring out a direction to take, but as much as I'm learning things, I'm starting to realize the vastness and diversity of this field, and it would be great if we (beginners) could connect with one another and share useful insights and learn together and have an environment for learning.\n\nSince there is too much to learn, of course not each one of us will learn everything, but it will be useful to know people who know things that we don't. I can setup a discord community or anything else as suggested.\n\nIt will be great to learn and share together.", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any one who's learning machine learning from Andrew Ng's Machine Learning Specialization on Coursera?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnmachinelearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uvnos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685368573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to connect with peers who are new to machine learning. More specifically, if someone is learning from Andrew Ng&amp;#39;s Specialization on Coursera.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to this and still figuring out a direction to take, but as much as I&amp;#39;m learning things, I&amp;#39;m starting to realize the vastness and diversity of this field, and it would be great if we (beginners) could connect with one another and share useful insights and learn together and have an environment for learning.&lt;/p&gt;\n\n&lt;p&gt;Since there is too much to learn, of course not each one of us will learn everything, but it will be useful to know people who know things that we don&amp;#39;t. I can setup a discord community or anything else as suggested.&lt;/p&gt;\n\n&lt;p&gt;It will be great to learn and share together.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3cqa1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uvnos", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnmachinelearning/comments/13uvnos/any_one_whos_learning_machine_learning_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnmachinelearning/comments/13uvnos/any_one_whos_learning_machine_learning_from/", "subreddit_subscribers": 301534, "created_utc": 1685368573.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1685371773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnmachinelearning/comments/13uvnos/any_one_whos_learning_machine_learning_from/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uwz7f", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13uvnos", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uwz7f/any_one_whos_learning_machine_learning_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnmachinelearning/comments/13uvnos/any_one_whos_learning_machine_learning_from/", "subreddit_subscribers": 912611, "created_utc": 1685371773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, PandasAI came out lately. For those who don't know, it's a python AI tool that is similar to ChatGPT except it generates figures and dataframes. I don't know if it also can run statistical tests or build regression models.\n\nI was wondering if there is a similar tool for R or if anyone is developing one for R.\n\nThank you!\n\nHere's the link to the repo for PandasAI if anyone's interested:  [gventuri/pandas-ai: Pandas AI is a Python library that integrates generative artificial intelligence capabilities into Pandas, making dataframes conversational (github.com)](https://github.com/gventuri/pandas-ai) ", "author_fullname": "t2_2ve4vyvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool like pandas-ai, but for R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uljnn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685336953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, PandasAI came out lately. For those who don&amp;#39;t know, it&amp;#39;s a python AI tool that is similar to ChatGPT except it generates figures and dataframes. I don&amp;#39;t know if it also can run statistical tests or build regression models.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is a similar tool for R or if anyone is developing one for R.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the repo for PandasAI if anyone&amp;#39;s interested:  &lt;a href=\"https://github.com/gventuri/pandas-ai\"&gt;gventuri/pandas-ai: Pandas AI is a Python library that integrates generative artificial intelligence capabilities into Pandas, making dataframes conversational (github.com)&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?auto=webp&amp;v=enabled&amp;s=6d402f7cce549ac1e2a6e89015892f8eb798ccae", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c15f212a765236b8acf2fb8aa7992cd1b2e2bea", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48621938f4e0707140b0a8cac8ede610b85b7585", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faebc473fcbf50bdbc1698d20a716d394f96d941", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7281794355c7fd112d94974abe9b3debd9ce7293", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b22910d5a65c098da1c79f7dbc1e09cdc78071b0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d776a3ba07ebc4c8c691978268b705950efb9c25", "width": 1080, "height": 540}], "variants": {}, "id": "BDaZUcmk3RERmdPy23Eg77E3CAJPXVwpUFehg3_99RM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uljnn", "is_robot_indexable": true, "report_reasons": null, "author": "statius9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uljnn/is_there_a_tool_like_pandasai_but_for_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uljnn/is_there_a_tool_like_pandasai_but_for_r/", "subreddit_subscribers": 912611, "created_utc": 1685336953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone,\n\nI have a dataset named A that has 2020 years data about the unique patient id, claim date, disease code and 15 columns which contains the individual costs. Similarly I have the data for 2021 and 2022. What I want to check is in a given year, if a patient has a certain disease (Eg: disease\\_code = 72148) I want to get the cost of this patient 30 days before this disease occurring (the total cost which is the sum of all 15 columns) and also their total costs 12 months after the disease. I want this cost breakdown for each patient in two different columns (namely 30\\_days\\_prior and  12\\_months after). The claim through date is the date we are looking at. If I want to write a SQL query that has to do it, how can I do it? I am really lost at the moment. \n\nThank You.", "author_fullname": "t2_4h6cb2jt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help with this.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ukzvy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685335214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I have a dataset named A that has 2020 years data about the unique patient id, claim date, disease code and 15 columns which contains the individual costs. Similarly I have the data for 2021 and 2022. What I want to check is in a given year, if a patient has a certain disease (Eg: disease_code = 72148) I want to get the cost of this patient 30 days before this disease occurring (the total cost which is the sum of all 15 columns) and also their total costs 12 months after the disease. I want this cost breakdown for each patient in two different columns (namely 30_days_prior and  12_months after). The claim through date is the date we are looking at. If I want to write a SQL query that has to do it, how can I do it? I am really lost at the moment. &lt;/p&gt;\n\n&lt;p&gt;Thank You.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ukzvy", "is_robot_indexable": true, "report_reasons": null, "author": "ricky1435", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ukzvy/please_help_with_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ukzvy/please_help_with_this/", "subreddit_subscribers": 912611, "created_utc": 1685335214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "289k Medium Articles at Your Fingertips! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13upwky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_k7f68ffu", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "datasets", "selftext": "Hello everyone! \ud83d\udc4b\n\nI'm thrilled to share an exciting update with all of you today. We've just completed a remarkable data project, and the result is nothing short of extraordinary. Introducing our **colossal dataset of 289k Medium Articles!** \ud83c\udf89\ud83d\udd25\n\nDataset Overview: \n\nThis incredible collection is the culmination of our meticulous efforts, as we scoured **35 different publications**, capturing the evolution of their articles **from inception to 26 May 2023**. Imagine the vast wealth of knowledge waiting to be explored!\n\nWhat's in the Dataset?\n\nContained within a **convenient 1.7GB zip file**, the dataset is organized into 35 folders, each corresponding to a specific Medium publication. Dive into these folders, and you'll discover **thousands of JSON files packed with article-related information,** including titles, authors, word counts, reading times, claps, comments, publication details, and much more. It's a data enthusiast's dream come true! \ud83e\udd13\ud83d\udca1\n\nUnleashing the Power of Metadata:\n\nBut wait, there's more! We've gone the extra mile to provide you with comprehensive metadata for each article. From the text itself to markups, embeds, links, and other contextual information, this dataset empowers you to delve into the nuances of content and unlock deeper insights. The possibilities are endless! \ud83d\udcc4\ud83d\udd0d\u2728\n\nFueling Research and Innovation:\n\nWhether you're a data scientist, a researcher, or an innovator, this dataset is a game-changer. It opens up new avenues for groundbreaking research in natural language processing, content analysis, user behavior patterns, and more. Let your curiosity run wild and see where this treasure trove of knowledge takes you! \ud83d\ude80\ud83d\udd2c\ud83d\udca5\n\nHow to Get Access:\n\nIf you're as excited as we are about this dataset, we'd love to share it with you. Simply reach out to us at [**nishu@mediumapi.com**](mailto:nishu@mediumapi.com)**,** and our team will guide you through the process of obtaining this   \ninvaluable resource. Let's embark on a journey of discovery together!  \ud83d\udce7\ud83d\udcbb\n\nResponsible Data Usage:\n\nWith great data comes great responsibility. We kindly request that all users utilize this dataset strictly for research purposes and in accordance with Medium's terms and conditions. Let's maintain ethical   \ndata practices and respect the intellectual property rights of content creators. \ud83d\ude4f\ud83d\udd12\n\nJoin the Knowledge Revolution:\n\nWe believe that knowledge should be shared and accessible to all. This dataset represents a major step toward democratizing information and fostering innovation. Together, we can push the boundaries of what's possible and create a brighter future. Join us on this thrilling   \nadventure! \ud83c\udf0d\ud83d\udcaa\ud83d\udca1\n\nLet's ignite a spark of discovery, unravel hidden insights, and propel the world of research and innovation forward. Reach out, grab your slice of this remarkable dataset, and embark on a journey that will redefine the limits of knowledge!", "author_fullname": "t2_k7f68ffu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "289k Medium Articles at Your Fingertips! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datasets", "hidden": false, "pwls": 6, "link_flair_css_class": "dataset", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13upmn3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "dataset", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685351451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thrilled to share an exciting update with all of you today. We&amp;#39;ve just completed a remarkable data project, and the result is nothing short of extraordinary. Introducing our &lt;strong&gt;colossal dataset of 289k Medium Articles!&lt;/strong&gt; \ud83c\udf89\ud83d\udd25&lt;/p&gt;\n\n&lt;p&gt;Dataset Overview: &lt;/p&gt;\n\n&lt;p&gt;This incredible collection is the culmination of our meticulous efforts, as we scoured &lt;strong&gt;35 different publications&lt;/strong&gt;, capturing the evolution of their articles &lt;strong&gt;from inception to 26 May 2023&lt;/strong&gt;. Imagine the vast wealth of knowledge waiting to be explored!&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s in the Dataset?&lt;/p&gt;\n\n&lt;p&gt;Contained within a &lt;strong&gt;convenient 1.7GB zip file&lt;/strong&gt;, the dataset is organized into 35 folders, each corresponding to a specific Medium publication. Dive into these folders, and you&amp;#39;ll discover &lt;strong&gt;thousands of JSON files packed with article-related information,&lt;/strong&gt; including titles, authors, word counts, reading times, claps, comments, publication details, and much more. It&amp;#39;s a data enthusiast&amp;#39;s dream come true! \ud83e\udd13\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Unleashing the Power of Metadata:&lt;/p&gt;\n\n&lt;p&gt;But wait, there&amp;#39;s more! We&amp;#39;ve gone the extra mile to provide you with comprehensive metadata for each article. From the text itself to markups, embeds, links, and other contextual information, this dataset empowers you to delve into the nuances of content and unlock deeper insights. The possibilities are endless! \ud83d\udcc4\ud83d\udd0d\u2728&lt;/p&gt;\n\n&lt;p&gt;Fueling Research and Innovation:&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a data scientist, a researcher, or an innovator, this dataset is a game-changer. It opens up new avenues for groundbreaking research in natural language processing, content analysis, user behavior patterns, and more. Let your curiosity run wild and see where this treasure trove of knowledge takes you! \ud83d\ude80\ud83d\udd2c\ud83d\udca5&lt;/p&gt;\n\n&lt;p&gt;How to Get Access:&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re as excited as we are about this dataset, we&amp;#39;d love to share it with you. Simply reach out to us at [&lt;strong&gt;&lt;a href=\"mailto:nishu@mediumapi.com\"&gt;nishu@mediumapi.com&lt;/a&gt;&lt;/strong&gt;](mailto:&lt;a href=\"mailto:nishu@mediumapi.com\"&gt;nishu@mediumapi.com&lt;/a&gt;)&lt;strong&gt;,&lt;/strong&gt; and our team will guide you through the process of obtaining this&lt;br/&gt;\ninvaluable resource. Let&amp;#39;s embark on a journey of discovery together!  \ud83d\udce7\ud83d\udcbb&lt;/p&gt;\n\n&lt;p&gt;Responsible Data Usage:&lt;/p&gt;\n\n&lt;p&gt;With great data comes great responsibility. We kindly request that all users utilize this dataset strictly for research purposes and in accordance with Medium&amp;#39;s terms and conditions. Let&amp;#39;s maintain ethical&lt;br/&gt;\ndata practices and respect the intellectual property rights of content creators. \ud83d\ude4f\ud83d\udd12&lt;/p&gt;\n\n&lt;p&gt;Join the Knowledge Revolution:&lt;/p&gt;\n\n&lt;p&gt;We believe that knowledge should be shared and accessible to all. This dataset represents a major step toward democratizing information and fostering innovation. Together, we can push the boundaries of what&amp;#39;s possible and create a brighter future. Join us on this thrilling&lt;br/&gt;\nadventure! \ud83c\udf0d\ud83d\udcaa\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s ignite a spark of discovery, unravel hidden insights, and propel the world of research and innovation forward. Reach out, grab your slice of this remarkable dataset, and embark on a journey that will redefine the limits of knowledge!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f074feb2-5bcd-11e6-8c1d-0e0220cd4035", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r97t", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13upmn3", "is_robot_indexable": true, "report_reasons": null, "author": "medium-api", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "subreddit_subscribers": 175475, "created_utc": 1685351451.0, "num_crossposts": 8, "media": null, "is_video": false}], "created": 1685352468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13upwky", "is_robot_indexable": true, "report_reasons": null, "author": "medium-api", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13upmn3", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13upwky/289k_medium_articles_at_your_fingertips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "subreddit_subscribers": 912611, "created_utc": 1685352468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " [AI can make anyone a programmer and has 'closed the digital divide,' Nvidia CEO says (msn.com)](https://www.msn.com/en-us/news/technology/ai-can-make-anyone-a-programmer-and-has-closed-the-digital-divide-nvidia-ceo-says/ar-AA1bQEpy?ocid=msedgntp&amp;cvid=d27127da82a845338ad9eaff606d88ad&amp;ei=12)", "author_fullname": "t2_mhq1fk2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Be ready to become redundant, my friends!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uz0at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685376496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.msn.com/en-us/news/technology/ai-can-make-anyone-a-programmer-and-has-closed-the-digital-divide-nvidia-ceo-says/ar-AA1bQEpy?ocid=msedgntp&amp;amp;cvid=d27127da82a845338ad9eaff606d88ad&amp;amp;ei=12\"&gt;AI can make anyone a programmer and has &amp;#39;closed the digital divide,&amp;#39; Nvidia CEO says (msn.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?auto=webp&amp;v=enabled&amp;s=4fd5a465ef6884a699546255c5b1f065a0c2ae94", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8335b5aff76a8a44013e49785baa69f16df60eda", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d39c64d4d17724aa5982a870a50699a94ba321f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fae4b47ac00a340de82b5931ff02f4e05acd59c7", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=787ef96d59748261eac27a7fa7939695acc44213", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14a915db0e62679a369f28f6d3715b042b18af41", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/t0B9HdJVGQbKMbPem1LwxFlKGRjllmk57ssU_d-yNYM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=693d14a00db03f0ecf5f29cc97654a48be5a894d", "width": 1080, "height": 567}], "variants": {}, "id": "Yks1kNIZZyehXek9_Lb9rvfuh5ojLWJZhip2uAIR5TI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uz0at", "is_robot_indexable": true, "report_reasons": null, "author": "green_data2022", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uz0at/be_ready_to_become_redundant_my_friends/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uz0at/be_ready_to_become_redundant_my_friends/", "subreddit_subscribers": 912611, "created_utc": 1685376496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does it worth to buy IPAD. I am a roster worker has to travel a lot. So it is not convenient to travel with laptop all the time. \nAdditional question?if u only use laptop to ur work, which do u prefer Windows or IOS?", "author_fullname": "t2_uiqgltfs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you effectively use your IPAD to your data analysis/science/visualization work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uppnb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.31, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685351751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it worth to buy IPAD. I am a roster worker has to travel a lot. So it is not convenient to travel with laptop all the time. \nAdditional question?if u only use laptop to ur work, which do u prefer Windows or IOS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uppnb", "is_robot_indexable": true, "report_reasons": null, "author": "Justrandomdude2", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uppnb/how_do_you_effectively_use_your_ipad_to_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uppnb/how_do_you_effectively_use_your_ipad_to_your_data/", "subreddit_subscribers": 912611, "created_utc": 1685351751.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}