{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: i have worked as a Full-stack(react, node, python, devops in aws) developer for a year doing freelance and the last 6 months i've been working as a data engineer for 12k/year, i'm from south america and here is not that bad of a salary. i've read papers on ML since 2018 and even develop a lot of models thru the years, i did a ML bootcamp and lately i jumped on the LLM hype train and developed some tools with it(doing proompt engineering, i have also made a dataset of results for a tool capable LLM to fine-tune when i get the necessary access to the compute i need), i feel stuck in my career right now and dont feel as ready(technically speaking) to jump for a job in ML although is an area i cannot keep out of my head, what do you recommend?", "author_fullname": "t2_64irsilo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which job do you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u3c3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685288262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: i have worked as a Full-stack(react, node, python, devops in aws) developer for a year doing freelance and the last 6 months i&amp;#39;ve been working as a data engineer for 12k/year, i&amp;#39;m from south america and here is not that bad of a salary. i&amp;#39;ve read papers on ML since 2018 and even develop a lot of models thru the years, i did a ML bootcamp and lately i jumped on the LLM hype train and developed some tools with it(doing proompt engineering, i have also made a dataset of results for a tool capable LLM to fine-tune when i get the necessary access to the compute i need), i feel stuck in my career right now and dont feel as ready(technically speaking) to jump for a job in ML although is an area i cannot keep out of my head, what do you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u3c3v", "is_robot_indexable": true, "report_reasons": null, "author": "Guzhi", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u3c3v/which_job_do_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u3c3v/which_job_do_you_recommend/", "subreddit_subscribers": 911909, "created_utc": 1685288262.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got laid off from my data science job a month ago. The job search has been brutal. I\u2019ve only had about four phone screens and two first round interviews after about 100 job applications. I\u2019ve been rejected from everything and have zero leads right now.\n\nI had my job for a little over a year, but it was not a very prominent company, so I don\u2019t think it looks that impressive on my resume. I think I\u2019ve done pretty well in my interviews so far so I suspect I\u2019m being rejected due to them finding out I was laid off. If they ask about my reason for leaving my last job, what should I say? Maybe I can make something up that sounds better.\n\nWhat is the easiest way to stand out? I don\u2019t have much of a portfolio and no publications. Which projects should I work on? I need to get hired fast because Im in a lot of student debt and have a huge lease, so Im not looking to do any long term projects. I\u2019d also love to collaborate with someone if possible.", "author_fullname": "t2_4c31z7fw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laid off data science looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u9dl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685303458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got laid off from my data science job a month ago. The job search has been brutal. I\u2019ve only had about four phone screens and two first round interviews after about 100 job applications. I\u2019ve been rejected from everything and have zero leads right now.&lt;/p&gt;\n\n&lt;p&gt;I had my job for a little over a year, but it was not a very prominent company, so I don\u2019t think it looks that impressive on my resume. I think I\u2019ve done pretty well in my interviews so far so I suspect I\u2019m being rejected due to them finding out I was laid off. If they ask about my reason for leaving my last job, what should I say? Maybe I can make something up that sounds better.&lt;/p&gt;\n\n&lt;p&gt;What is the easiest way to stand out? I don\u2019t have much of a portfolio and no publications. Which projects should I work on? I need to get hired fast because Im in a lot of student debt and have a huge lease, so Im not looking to do any long term projects. I\u2019d also love to collaborate with someone if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u9dl3", "is_robot_indexable": true, "report_reasons": null, "author": "CharliDelReyJepsen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u9dl3/laid_off_data_science_looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u9dl3/laid_off_data_science_looking_for_advice/", "subreddit_subscribers": 911909, "created_utc": 1685303458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data scientist and finished university some years ago. I studied math, and during my course I was exposed to some introductions to probability, inference, regression, multivariate analysis, etc. But never dived deep into any of these topics. Now I want to go back to statistics and improve my understanding. Some topics I would like to go back are, for instance, stochastic processes, time series, bayesian statistics. \n\nBecause of that, I want to buy a book that I could improve my understanding and refer to when in need of refreshing some topics that I am already familiar.   \nWhat I don't want is to need to buy various different books for each area. I would prefer to have one encompassing more or less everything I need to know as a typical data scientist. Is there such a thing? Do you have any recommendations? I found this 'Practical Statistics for Data Scientists', can someone recommend it?", "author_fullname": "t2_dfmfjyei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice of good statistics textbooks for reference on intermediate level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u7kql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685298828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data scientist and finished university some years ago. I studied math, and during my course I was exposed to some introductions to probability, inference, regression, multivariate analysis, etc. But never dived deep into any of these topics. Now I want to go back to statistics and improve my understanding. Some topics I would like to go back are, for instance, stochastic processes, time series, bayesian statistics. &lt;/p&gt;\n\n&lt;p&gt;Because of that, I want to buy a book that I could improve my understanding and refer to when in need of refreshing some topics that I am already familiar.&lt;br/&gt;\nWhat I don&amp;#39;t want is to need to buy various different books for each area. I would prefer to have one encompassing more or less everything I need to know as a typical data scientist. Is there such a thing? Do you have any recommendations? I found this &amp;#39;Practical Statistics for Data Scientists&amp;#39;, can someone recommend it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u7kql", "is_robot_indexable": true, "report_reasons": null, "author": "TheManveru", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u7kql/advice_of_good_statistics_textbooks_for_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u7kql/advice_of_good_statistics_textbooks_for_reference/", "subreddit_subscribers": 911909, "created_utc": 1685298828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.   \n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?   \nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don't really would like to do another Msc or a Phd. Is my worry correct or not necessarily?   \nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?", "author_fullname": "t2_dfmfjyei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I worked in DS jobs closely connected to business but I strongly dislike that and want to work in more technical jobs. What are some areas I could explore? And how to transition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ucq03", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685311958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.&lt;br/&gt;\n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?&lt;br/&gt;\nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don&amp;#39;t really would like to do another Msc or a Phd. Is my worry correct or not necessarily?&lt;br/&gt;\nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ucq03", "is_robot_indexable": true, "report_reasons": null, "author": "TheManveru", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "subreddit_subscribers": 911909, "created_utc": 1685311958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a master's in Economics. Know C++ and Python.", "author_fullname": "t2_7tq2r4myz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My (23M) joining at my first job has been deferred by 3 months. What skills can I gain in this time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tycmy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685273871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a master&amp;#39;s in Economics. Know C++ and Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tycmy", "is_robot_indexable": true, "report_reasons": null, "author": "rawandakawasaki", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tycmy/my_23m_joining_at_my_first_job_has_been_deferred/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tycmy/my_23m_joining_at_my_first_job_has_been_deferred/", "subreddit_subscribers": 911909, "created_utc": 1685273871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97o87945r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any specific reason behind keys in dictionaries are always immutable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13twslh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685268726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13twslh", "is_robot_indexable": true, "report_reasons": null, "author": "asquare-buzz", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13twslh/is_there_any_specific_reason_behind_keys_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13twslh/is_there_any_specific_reason_behind_keys_in/", "subreddit_subscribers": 911909, "created_utc": 1685268726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone. I have 2 YOE in data science/machine learning and after a gap year I encounter a new potential job  doing science computation. It was inside a stable, traditional industry company's scientific department. The job will be doing C++ and Python development on their Linux-foundation donated open source repo, heavy math and  little ML will be involved.  I think the job have some benefits:\n\n\\- good wlb\n\n\\- less hassle with meetings, business stakeholders, etc. \n\n\\-pure tech, good for some areas of development\n\nBut I worry:\n\n\\- deviate from \"mainstream\" of data sciecne, say NLP, transformers, CV, etc.\n\n\\- deviate from big data and cloud computing\n\n\\- deviate from business sense \n\nWill this job bind me too hard with their open-source will make me hard to switch jobs later on? Dear senior data folks, what do you think?", "author_fullname": "t2_12dg2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Career Advice]Open-source scientific programmer job prospect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u8kg1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685301428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I have 2 YOE in data science/machine learning and after a gap year I encounter a new potential job  doing science computation. It was inside a stable, traditional industry company&amp;#39;s scientific department. The job will be doing C++ and Python development on their Linux-foundation donated open source repo, heavy math and  little ML will be involved.  I think the job have some benefits:&lt;/p&gt;\n\n&lt;p&gt;- good wlb&lt;/p&gt;\n\n&lt;p&gt;- less hassle with meetings, business stakeholders, etc. &lt;/p&gt;\n\n&lt;p&gt;-pure tech, good for some areas of development&lt;/p&gt;\n\n&lt;p&gt;But I worry:&lt;/p&gt;\n\n&lt;p&gt;- deviate from &amp;quot;mainstream&amp;quot; of data sciecne, say NLP, transformers, CV, etc.&lt;/p&gt;\n\n&lt;p&gt;- deviate from big data and cloud computing&lt;/p&gt;\n\n&lt;p&gt;- deviate from business sense &lt;/p&gt;\n\n&lt;p&gt;Will this job bind me too hard with their open-source will make me hard to switch jobs later on? Dear senior data folks, what do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u8kg1", "is_robot_indexable": true, "report_reasons": null, "author": "zjplab", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u8kg1/career_adviceopensource_scientific_programmer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u8kg1/career_adviceopensource_scientific_programmer_job/", "subreddit_subscribers": 911909, "created_utc": 1685301428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks, \n\nI discovered his channel a few weeks ago and found it interesting (though controversial). He argues that the only path to Machine learning or data engineering is through data analyst and seems to hate on data scientists.\n\nI could not find any credentials (LinkedIn or anything that proves what he claims; i.e. he has years of experience in machine learning, data engineering and in the data space)\n\nMany people (though at my postgrad level) showed me that there are many paths leading to data science, ML engineering, and data engineering but perhaps I'm mistaken or delusional.\n\nAny thoughts?\n\nCheers,", "author_fullname": "t2_161fpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on the data janitor? (YouTube channel)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tw1bl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685265971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, &lt;/p&gt;\n\n&lt;p&gt;I discovered his channel a few weeks ago and found it interesting (though controversial). He argues that the only path to Machine learning or data engineering is through data analyst and seems to hate on data scientists.&lt;/p&gt;\n\n&lt;p&gt;I could not find any credentials (LinkedIn or anything that proves what he claims; i.e. he has years of experience in machine learning, data engineering and in the data space)&lt;/p&gt;\n\n&lt;p&gt;Many people (though at my postgrad level) showed me that there are many paths leading to data science, ML engineering, and data engineering but perhaps I&amp;#39;m mistaken or delusional.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tw1bl", "is_robot_indexable": true, "report_reasons": null, "author": "Inquation", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tw1bl/what_are_your_thoughts_on_the_data_janitor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tw1bl/what_are_your_thoughts_on_the_data_janitor/", "subreddit_subscribers": 911909, "created_utc": 1685265971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. \n\nWhat's the minimum amount of data needed for reliable results? Even if I don't have enough data, should I run the model anyway?\n\nI have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?\n\nPlease share your experiences, rule-of-thumb guidelines, and any relevant resources. \n\nThanks.", "author_fullname": "t2_s6n4mlrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trajectory model - enough data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13uh97w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685324071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the minimum amount of data needed for reliable results? Even if I don&amp;#39;t have enough data, should I run the model anyway?&lt;/p&gt;\n\n&lt;p&gt;I have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?&lt;/p&gt;\n\n&lt;p&gt;Please share your experiences, rule-of-thumb guidelines, and any relevant resources. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uh97w", "is_robot_indexable": true, "report_reasons": null, "author": "metalhead_nerd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "subreddit_subscribers": 911909, "created_utc": 1685324071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nThis semester I start to learn deep learning course and seem like my laptop cannot have enough ram and GPU to support that. Is there any cloud service that I can train my model for more than 24 hours?\n\nThank for your advice", "author_fullname": "t2_alz74kl7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suitable cloud service to learn deep learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u7kgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685298808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;This semester I start to learn deep learning course and seem like my laptop cannot have enough ram and GPU to support that. Is there any cloud service that I can train my model for more than 24 hours?&lt;/p&gt;\n\n&lt;p&gt;Thank for your advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u7kgp", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Might5303", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u7kgp/suitable_cloud_service_to_learn_deep_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u7kgp/suitable_cloud_service_to_learn_deep_learning/", "subreddit_subscribers": 911909, "created_utc": 1685298808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. Wondering on your preferred modality for running computations on a complex dataset. The choices at this stage are:\n\n1. Structure SQL queries for exactly the data needed from the DB, to draw into a central dashboard/reporting mechanism (proprietary design), or\n2. Download relevant chunks of the data as dataframes, and manipulate in real time (i.e. backend) to get the desired computed result.\n\nAs an example, if someone wanted to know the demographics of their primary clients, we could either:\n\na. Structure a SQL query that computes the mode gender, median age, type of qualification, etc, based on each user's unique ID and pass the results directly to the reporting mechanism, or\n\nb. Gather dataframes at the beginning (i.e. start-up of the online system) that include relevant variables for any type of analysis for reporting, and based on the requirements at the specific point in the system process compute the outcome (e.g. demographics), through filtering and other methods.\n\nI know one is likely to be more performant than the other.\n\nThe requirements are: to interrogate big data, with JIT output to users, with the capability to zoom in/out of particular clusters, deal with lag from the central data processing system, de-identify PII data, and handle concurrent queries on large data with a high degree of traffic.\n\nIf you were approaching this, I'd be curious on your preferred mode of analysis, and reasons.", "author_fullname": "t2_vv6vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling methodology - SQL or dataframes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u5k9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685293688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Wondering on your preferred modality for running computations on a complex dataset. The choices at this stage are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Structure SQL queries for exactly the data needed from the DB, to draw into a central dashboard/reporting mechanism (proprietary design), or&lt;/li&gt;\n&lt;li&gt;Download relevant chunks of the data as dataframes, and manipulate in real time (i.e. backend) to get the desired computed result.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As an example, if someone wanted to know the demographics of their primary clients, we could either:&lt;/p&gt;\n\n&lt;p&gt;a. Structure a SQL query that computes the mode gender, median age, type of qualification, etc, based on each user&amp;#39;s unique ID and pass the results directly to the reporting mechanism, or&lt;/p&gt;\n\n&lt;p&gt;b. Gather dataframes at the beginning (i.e. start-up of the online system) that include relevant variables for any type of analysis for reporting, and based on the requirements at the specific point in the system process compute the outcome (e.g. demographics), through filtering and other methods.&lt;/p&gt;\n\n&lt;p&gt;I know one is likely to be more performant than the other.&lt;/p&gt;\n\n&lt;p&gt;The requirements are: to interrogate big data, with JIT output to users, with the capability to zoom in/out of particular clusters, deal with lag from the central data processing system, de-identify PII data, and handle concurrent queries on large data with a high degree of traffic.&lt;/p&gt;\n\n&lt;p&gt;If you were approaching this, I&amp;#39;d be curious on your preferred mode of analysis, and reasons.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u5k9x", "is_robot_indexable": true, "report_reasons": null, "author": "ryanblumenow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u5k9x/modelling_methodology_sql_or_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u5k9x/modelling_methodology_sql_or_dataframes/", "subreddit_subscribers": 911909, "created_utc": 1685293688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just started a data science internship, and my small team's first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). \n\nStandard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don't know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you're not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.\n\nMy idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. \n\nHas anyone tried this network-based fuzzy matching? Does it even sound promising? \n\n(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I'm encouraged to experiment for the sake of learning, even if it's a little less time efficient. We also have a VM to use over the summer for free.)", "author_fullname": "t2_hdmiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "String distance based network for fuzzy matching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u4sd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685293119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685291834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started a data science internship, and my small team&amp;#39;s first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). &lt;/p&gt;\n\n&lt;p&gt;Standard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don&amp;#39;t know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you&amp;#39;re not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.&lt;/p&gt;\n\n&lt;p&gt;My idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this network-based fuzzy matching? Does it even sound promising? &lt;/p&gt;\n\n&lt;p&gt;(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I&amp;#39;m encouraged to experiment for the sake of learning, even if it&amp;#39;s a little less time efficient. We also have a VM to use over the summer for free.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u4sd7", "is_robot_indexable": true, "report_reasons": null, "author": "ChiefWilliam", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "subreddit_subscribers": 911909, "created_utc": 1685291834.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plakakia (tiles in Greek) is an image tiling library I made for quickly generating tiles from images. It would be great if people try it and give some feedback / raise issues on github. It's the first open-source library I ever made, so hopefully I learn from more experienced people.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13ttxk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_f8vtd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jje0KypwRW1CZuUVf5fmUp4TjijHWX006uJQRoOfzHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "computervision", "selftext": "", "author_fullname": "t2_f8vtd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plakakia (tiles in Greek) is an image tiling library I made for quickly generating tiles from images. It would be great if people try it and give some feedback / raise issues on github. It's the first open-source library I ever made, so hopefully I learn from more experienced people.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/computervision", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13ttw5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help: Project", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jje0KypwRW1CZuUVf5fmUp4TjijHWX006uJQRoOfzHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685257674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/kalfasyan/plakakia", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?auto=webp&amp;v=enabled&amp;s=408f42ad808e7887c97319065899b45754642e22", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35ffdc2e0ca4535ef2c01f7d30ec67827e1aa04e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14c6d204c3ea3dd5eac4909b42d07566d79d41d7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8dfd359f5dc5e8e29397b2cdbcb152674360c19", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab0a47a6e9ddf7d1473dcb4a7cb5bf21b316374b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93bc21cb125eca0c524f3c3ca8a367ba6fda9816", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8eda96665172ca30582491c032561f6bf71355", "width": 1080, "height": 540}], "variants": {}, "id": "79VUq2fR1LDm9Y69p5syIxmh7Dt3myfwPlIgKHhoqC8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2be07b9a-850c-11eb-9ef0-0e67fd476361", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2rfzn", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#fdff99", "id": "13ttw5o", "is_robot_indexable": true, "report_reasons": null, "author": "kalfasyan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/computervision/comments/13ttw5o/plakakia_tiles_in_greek_is_an_image_tiling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/kalfasyan/plakakia", "subreddit_subscribers": 75313, "created_utc": 1685257674.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1685257822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/kalfasyan/plakakia", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?auto=webp&amp;v=enabled&amp;s=408f42ad808e7887c97319065899b45754642e22", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35ffdc2e0ca4535ef2c01f7d30ec67827e1aa04e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14c6d204c3ea3dd5eac4909b42d07566d79d41d7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8dfd359f5dc5e8e29397b2cdbcb152674360c19", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab0a47a6e9ddf7d1473dcb4a7cb5bf21b316374b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93bc21cb125eca0c524f3c3ca8a367ba6fda9816", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aZ1ac-4ZS7b-tM4MvYU8DOxn1hJEkw83HLiAqXivxi8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8eda96665172ca30582491c032561f6bf71355", "width": 1080, "height": 540}], "variants": {}, "id": "79VUq2fR1LDm9Y69p5syIxmh7Dt3myfwPlIgKHhoqC8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ttxk4", "is_robot_indexable": true, "report_reasons": null, "author": "kalfasyan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13ttw5o", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ttxk4/plakakia_tiles_in_greek_is_an_image_tiling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/kalfasyan/plakakia", "subreddit_subscribers": 911909, "created_utc": 1685257822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Seeking some advice. My background is MBBS (non EU/UK) with a MSc in Health Policy (UK), with 4 years experience in clinical healthcare (Non EU/UK). Got an offer to pursue MSc in Health Data Science at reputable school in the UK (UCL). \n\nBeen working like crazy in my clinical work in my country (non EU/UK) and paid peanuts and my current MSc doesnt help to secure a job (policy role is not as much and also paid peanuts) in the UK. \n\nI have a good grasp of Python, R and SQL and statistics (i.e Bayesian, Regression etc) with deep interest of pivoting into the data industry - the closest field would be health-related data industry. Been applying for data roles where I have tweaked my resume to increase the odds from best practices, but to no avail.\n\nAlso listed my projects, own github, some microcerts in the resume (Google Data Analytics, AWS Associate, Python R certs) - still not impressive enough to land an interview.\n\nShould I pursue another msc in the Health DS for to help for the switch or is there other professional certifications / ways to increase the odds of landing an analyst role?\n\nAny input is deeply appreciated\n\nP/s: education funding is not much of an issue", "author_fullname": "t2_4eaj44o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To pursue MSc or not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13ugymt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685323219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeking some advice. My background is MBBS (non EU/UK) with a MSc in Health Policy (UK), with 4 years experience in clinical healthcare (Non EU/UK). Got an offer to pursue MSc in Health Data Science at reputable school in the UK (UCL). &lt;/p&gt;\n\n&lt;p&gt;Been working like crazy in my clinical work in my country (non EU/UK) and paid peanuts and my current MSc doesnt help to secure a job (policy role is not as much and also paid peanuts) in the UK. &lt;/p&gt;\n\n&lt;p&gt;I have a good grasp of Python, R and SQL and statistics (i.e Bayesian, Regression etc) with deep interest of pivoting into the data industry - the closest field would be health-related data industry. Been applying for data roles where I have tweaked my resume to increase the odds from best practices, but to no avail.&lt;/p&gt;\n\n&lt;p&gt;Also listed my projects, own github, some microcerts in the resume (Google Data Analytics, AWS Associate, Python R certs) - still not impressive enough to land an interview.&lt;/p&gt;\n\n&lt;p&gt;Should I pursue another msc in the Health DS for to help for the switch or is there other professional certifications / ways to increase the odds of landing an analyst role?&lt;/p&gt;\n\n&lt;p&gt;Any input is deeply appreciated&lt;/p&gt;\n\n&lt;p&gt;P/s: education funding is not much of an issue&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ugymt", "is_robot_indexable": true, "report_reasons": null, "author": "minetella", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ugymt/to_pursue_msc_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ugymt/to_pursue_msc_or_not/", "subreddit_subscribers": 911909, "created_utc": 1685323219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " The year 2022 marked a turning point for GitHub and all its users, with the announcement of the general availability of two revolutionary services for developers: [GitHub Codespaces](https://github.com/features/codespaces?WT.mc_id=academic-84100-cacaste) and [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-84100-cacaste). A Codespace is a development environment hosted in the cloud and accessible via a web browser through one click, with the same graphical interface as the local Visual Studio Code IDE. GitHub Copilot is an AI-empowered pair programmer that offers autocomplete-style suggestions as you code in different programming languages (like Python, C++, Javascript, and more). But to give you a deeper understanding of what these services are and how you could benefit from them, let me tell you a story, or better two. \n\n[https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/](https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/)", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub Codespaces and GitHub Copilot: 2 Stories, Thousands of Possibilities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1ofs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685283823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The year 2022 marked a turning point for GitHub and all its users, with the announcement of the general availability of two revolutionary services for developers: &lt;a href=\"https://github.com/features/codespaces?WT.mc_id=academic-84100-cacaste\"&gt;GitHub Codespaces&lt;/a&gt; and &lt;a href=\"https://github.com/features/copilot?WT.mc_id=academic-84100-cacaste\"&gt;GitHub Copilot&lt;/a&gt;. A Codespace is a development environment hosted in the cloud and accessible via a web browser through one click, with the same graphical interface as the local Visual Studio Code IDE. GitHub Copilot is an AI-empowered pair programmer that offers autocomplete-style suggestions as you code in different programming languages (like Python, C++, Javascript, and more). But to give you a deeper understanding of what these services are and how you could benefit from them, let me tell you a story, or better two. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/\"&gt;https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?auto=webp&amp;v=enabled&amp;s=7ce90db687ca0f86c17fd0ff7978646ac7db7601", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d75463d336230de4082441ed5258047d1078c24", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9db1551060e1c89205de74a3c6dcdf9cd9816bb2", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5eff77272b9e28ed0d7308f09ac6c5b1359bb3d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c23caf3336f44df2fc8954e9f4aad2998941f0e8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb1cc48c7835c1b15f67144d3c97f48b41f57146", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3a75ea4cbcaa4480031140f39c114f7ea9b39a2", "width": 1080, "height": 567}], "variants": {}, "id": "x4QFD-xYyfgJ7ON1BuJLj7-BFqcX_7bv2xsvBGMcc1g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u1ofs", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u1ofs/github_codespaces_and_github_copilot_2_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u1ofs/github_codespaces_and_github_copilot_2_stories/", "subreddit_subscribers": 911909, "created_utc": 1685283823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a CS grad. I'm becoming more and more worried about AI and what it would mean for my future as I never really was interested in anything other than CS before and now that a lot of job roles are at risk because of AI. I really want to be a DS, but I'm not sure if it would be worth it if going down that path is risky.", "author_fullname": "t2_nybcq2yv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This might be a dumb question but can AI replace data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13uhegn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.31, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685324490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a CS grad. I&amp;#39;m becoming more and more worried about AI and what it would mean for my future as I never really was interested in anything other than CS before and now that a lot of job roles are at risk because of AI. I really want to be a DS, but I&amp;#39;m not sure if it would be worth it if going down that path is risky.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uhegn", "is_robot_indexable": true, "report_reasons": null, "author": "ladywinterbear", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uhegn/this_might_be_a_dumb_question_but_can_ai_replace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uhegn/this_might_be_a_dumb_question_but_can_ai_replace/", "subreddit_subscribers": 911909, "created_utc": 1685324490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone point me in the direction of YouTuber Earnings Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tul8g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mm3s3evo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "datasets", "selftext": "I am doing a project and would like to use earnings of top YouTube channels. I have found some datasets on Kaggle but need more detail on annual earnings. If any of you know where I could find that data or could post the datasets, data, or source here that would be amazing. Thank you!", "author_fullname": "t2_mm3s3evo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone point me in the direction of YouTuber Earnings Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datasets", "hidden": false, "pwls": 6, "link_flair_css_class": "dataset", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tuks6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "dataset", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685260310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing a project and would like to use earnings of top YouTube channels. I have found some datasets on Kaggle but need more detail on annual earnings. If any of you know where I could find that data or could post the datasets, data, or source here that would be amazing. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f074feb2-5bcd-11e6-8c1d-0e0220cd4035", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r97t", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tuks6", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Garlic1170", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "subreddit_subscribers": 175426, "created_utc": 1685260310.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1685260361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tul8g", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Garlic1170", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13tuks6", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tul8g/can_anyone_point_me_in_the_direction_of_youtuber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/datasets/comments/13tuks6/can_anyone_point_me_in_the_direction_of_youtuber/", "subreddit_subscribers": 911909, "created_utc": 1685260361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement an activity tracker for my Reddit account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tu8b7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5hpv694y", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "developersIndia", "selftext": "I am looking to implement an activity tracker dashboard-like thing that gives me updates about comments counts, comment content, and upvotes made on my posts. I went through the functionality of PRAW and Reddit API documentation and understood that there is no direct endpoint to ask for updates.   \n\n\nNow the possible method is to store post IDs for each of my posts, and continuously poll via API to get status updates on these posts. But doing this for each post one by one will be lot time-consuming process. How can I optimize this process? Like how should I divide my tasks into multiprocessing processes  such that changes are reflected on my dashboard in minimum amount of time.", "author_fullname": "t2_5hpv694y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement an activity tracker for my Reddit account?", "link_flair_richtext": [{"e": "text", "t": "Help"}], "subreddit_name_prefixed": "r/developersIndia", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tu79e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685258849.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to implement an activity tracker dashboard-like thing that gives me updates about comments counts, comment content, and upvotes made on my posts. I went through the functionality of PRAW and Reddit API documentation and understood that there is no direct endpoint to ask for updates.   &lt;/p&gt;\n\n&lt;p&gt;Now the possible method is to store post IDs for each of my posts, and continuously poll via API to get status updates on these posts. But doing this for each post one by one will be lot time-consuming process. How can I optimize this process? Like how should I divide my tasks into multiprocessing processes  such that changes are reflected on my dashboard in minimum amount of time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ec36207e-3d06-11ea-8944-0ee745817ba1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2dfnk0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#373c3f", "id": "13tu79e", "is_robot_indexable": true, "report_reasons": null, "author": "mili_19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "subreddit_subscribers": 220787, "created_utc": 1685258849.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1685258969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tu8b7", "is_robot_indexable": true, "report_reasons": null, "author": "mili_19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13tu79e", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tu8b7/how_to_implement_an_activity_tracker_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/developersIndia/comments/13tu79e/how_to_implement_an_activity_tracker_for_my/", "subreddit_subscribers": 911909, "created_utc": 1685258969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Speech is one of the most natural and fundamental modes of human communication. In today\u2019s digital landscape \u2013where audio and video content proliferate across the web and within enterprises\u2014 leveraging automated speech AI is paramount, and can make content more accessible, as well as opening the door to greater analysis and insights.\u00a0\u00a0\n\nAzure Speech Services offer cutting-edge speech recognition and synthesis technology as well as a comprehensive suite of tools that you can leverage to transform how we communicate with machines and access information. In this post, we will explore key scenarios for implementing our Azure AI in your enterprise, and some of our most innovative Azure Speech features.\u00a0\n\n[https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/](https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/)", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking the Power of Voice: Enhance Your Applications with Azure Speech Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1rje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685284065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Speech is one of the most natural and fundamental modes of human communication. In today\u2019s digital landscape \u2013where audio and video content proliferate across the web and within enterprises\u2014 leveraging automated speech AI is paramount, and can make content more accessible, as well as opening the door to greater analysis and insights.\u00a0\u00a0&lt;/p&gt;\n\n&lt;p&gt;Azure Speech Services offer cutting-edge speech recognition and synthesis technology as well as a comprehensive suite of tools that you can leverage to transform how we communicate with machines and access information. In this post, we will explore key scenarios for implementing our Azure AI in your enterprise, and some of our most innovative Azure Speech features.\u00a0&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/\"&gt;https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?auto=webp&amp;v=enabled&amp;s=875e1e0518f7397734d64fd5d3249689f24e9882", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0cc8ffe325285617a565183db0ffe28901195f61", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49aa20a7a383686b9a50239d11cd6cd40babe589", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21d8228289e51d76883855da317d13138e0207c2", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5546c69e2bae07aa4976b24646fff35dfe0b174f", "width": 640, "height": 300}], "variants": {}, "id": "D-2-tlED6dP2-lgf-NHf309v2q1t0rQ1bf6agM1iqXk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u1rje", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u1rje/unlocking_the_power_of_voice_enhance_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u1rje/unlocking_the_power_of_voice_enhance_your/", "subreddit_subscribers": 911909, "created_utc": 1685284065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to learn how to webscrape from  [WNBA Stats | Players Traditional](https://stats.wnba.com/players/traditional/?sort=PTS&amp;dir=-1&amp;Season=2023&amp;SeasonType=Regular%20Season) . I've done very little webscraping, I've only been able to do scrape from ESPN or basketball reference. This is the code I used, but I have no idea how to adapt to this website, or if this website would even allow webscraping using the method that I did.  Any help would be greatly appreciated.\n\n\\------\n\nimport pandas as pd\n\nimport requests\n\nimport json\n\nfrom time import sleep\n\n \n\ndef get\\_data(page: int):\n\nheaders = {\n\n'authority': '[site.web.api.espn.com](https://site.web.api.espn.com)',\n\n'accept': '\\*/\\*',\n\n'accept-language': 'en-US,en;q=0.9',\n\n'origin': '[https://www.espn.com](https://www.espn.com)',\n\n'referer': '[https://www.espn.com/](https://www.espn.com/)',\n\n'sec-ch-ua': '\"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Microsoft Edge\";v=\"110\"',\n\n'sec-ch-ua-mobile': '?0',\n\n'sec-ch-ua-platform': '\"Windows\"',\n\n'sec-fetch-dest': 'empty',\n\n'sec-fetch-mode': 'cors',\n\n'sec-fetch-site': 'same-site',\n\n'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.49',\n\n}\n\n \n\nparams = {\n\n'region': 'us',\n\n'lang': 'en',\n\n'contentorigin': 'espn',\n\n'isqualified': 'true',\n\n'page': f'{page}',\n\n'limit': '50',\n\n'sort': 'offensive.avgPoints:desc',\n\n'conference': '4',\n\n}\n\n \n\nresponse = requests.get(\n\nurl='[https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\\\](https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\)\n\nregion=us&amp;lang=en&amp;contentorigin=espn&amp;isqualified=true&amp;page=2&amp;limit=50&amp;sort=offensive.avgPoints%3Adesc&amp;conference=4',\n\nheaders=headers,\n\nparams=params\n\n).json()\n\n \n\nreturn response\n\n&amp;#x200B;\n\ndef parse\\_json():\n\ndata = \\[\\]\n\nfor i in range(1,4):\n\njsonData = get\\_data(page=i)\n\nathletes = jsonData\\[\"athletes\"\\]\n\nfor athlete in athletes:\n\n\n\nname = athlete\\[\"athlete\"\\]\\[\"displayName\"\\]\n\nteamName = athlete\\['athlete'\\]\\['teamShortName'\\]\n\n\n\n\n\n\n\n\n\ngames\\_minutes\\_points = athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[0:2\\]\\\\\n\n\\+\\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[0\\]\\]\n\n\n\nrebounds\\_assists = \\[athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[12\\]\\]\\\\\n\n\\+ \\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[10\\]\\]\n\n\n\ntov\\_perg = \\[athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[11\\]\\]\n\n\n\nfouls\\_perg = \\[athlete\\['categories'\\]\\[0\\]\\['totals'\\]\\[2\\]\\]\n\n&amp;#x200B;\n\nsteals\\_blocks = athlete\\['categories'\\]\\[2\\]\\['totals'\\]\\[0:2\\]\n\n&amp;#x200B;\n\nshooting\\_totals = athlete\\['categories'\\]\\[1\\]\\['totals'\\]\\[1:10\\]\n\n\n\ntotals = games\\_minutes\\_points + rebounds\\_assists+steals\\_blocks\\\\\n\n\\+tov\\_perg+fouls\\_perg+shooting\\_totals\n\n\n\n\\# totals = athlete\\[\"categories\"\\]\\[1\\]\\[\"totals\"\\]\n\n\n\nplayer\\_position = athlete\\['athlete'\\]\\['position'\\]\\['name'\\]\n\nrank = athlete\\[\"categories\"\\]\\[1\\]\\[\"ranks\"\\]\\[0\\]\n\ndata.append(\n\n{\n\n\"name\": name,\n\n\"teamName\": teamName,\n\n\"position\": athlete\\['athlete'\\]\\['position'\\]\\['name'\\],\n\n\"totals\": totals,\n\n\"rank\": rank\n\n}\n\n)\n\nprint(f\"\\[INFO\\] {i}/3 processed\")\n\nsleep(3)\n\n \n\n \n\nwith open(\"jsonData.json\", \"w\", encoding =\"utf-8\") as file:\n\njson.dump(data, file, indent=4, ensure\\_ascii=False)\n\n \n\n \n\n \n\ndef main():\n\nparse\\_json()\n\n \n\n \n\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n\nmain()", "author_fullname": "t2_44ezd8dp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webscraping for Basketball (WNBA)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13tr7gm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685247661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn how to webscrape from  &lt;a href=\"https://stats.wnba.com/players/traditional/?sort=PTS&amp;amp;dir=-1&amp;amp;Season=2023&amp;amp;SeasonType=Regular%20Season\"&gt;WNBA Stats | Players Traditional&lt;/a&gt; . I&amp;#39;ve done very little webscraping, I&amp;#39;ve only been able to do scrape from ESPN or basketball reference. This is the code I used, but I have no idea how to adapt to this website, or if this website would even allow webscraping using the method that I did.  Any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;------&lt;/p&gt;\n\n&lt;p&gt;import pandas as pd&lt;/p&gt;\n\n&lt;p&gt;import requests&lt;/p&gt;\n\n&lt;p&gt;import json&lt;/p&gt;\n\n&lt;p&gt;from time import sleep&lt;/p&gt;\n\n&lt;p&gt;def get_data(page: int):&lt;/p&gt;\n\n&lt;p&gt;headers = {&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;authority&amp;#39;: &amp;#39;&lt;a href=\"https://site.web.api.espn.com\"&gt;site.web.api.espn.com&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;accept&amp;#39;: &amp;#39;*/*&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;accept-language&amp;#39;: &amp;#39;en-US,en;q=0.9&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;origin&amp;#39;: &amp;#39;&lt;a href=\"https://www.espn.com\"&gt;https://www.espn.com&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;referer&amp;#39;: &amp;#39;&lt;a href=\"https://www.espn.com/\"&gt;https://www.espn.com/&lt;/a&gt;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua&amp;#39;: &amp;#39;&amp;quot;Chromium&amp;quot;;v=&amp;quot;110&amp;quot;, &amp;quot;Not A(Brand&amp;quot;;v=&amp;quot;24&amp;quot;, &amp;quot;Microsoft Edge&amp;quot;;v=&amp;quot;110&amp;quot;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua-mobile&amp;#39;: &amp;#39;?0&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-ch-ua-platform&amp;#39;: &amp;#39;&amp;quot;Windows&amp;quot;&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-dest&amp;#39;: &amp;#39;empty&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-mode&amp;#39;: &amp;#39;cors&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sec-fetch-site&amp;#39;: &amp;#39;same-site&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;user-agent&amp;#39;: &amp;#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.49&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;params = {&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;region&amp;#39;: &amp;#39;us&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;lang&amp;#39;: &amp;#39;en&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;contentorigin&amp;#39;: &amp;#39;espn&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;isqualified&amp;#39;: &amp;#39;true&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;page&amp;#39;: f&amp;#39;{page}&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;limit&amp;#39;: &amp;#39;50&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;sort&amp;#39;: &amp;#39;offensive.avgPoints:desc&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;conference&amp;#39;: &amp;#39;4&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;response = requests.get(&lt;/p&gt;\n\n&lt;p&gt;url=&amp;#39;[&lt;a href=\"https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?%5C%5C%5D(https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?%5C)\"&gt;https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\\\](https://site.web.api.espn.com/apis/common/v3/sports/basketball/womens-college-basketball/statistics/byathlete?\\)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;region=us&amp;amp;lang=en&amp;amp;contentorigin=espn&amp;amp;isqualified=true&amp;amp;page=2&amp;amp;limit=50&amp;amp;sort=offensive.avgPoints%3Adesc&amp;amp;conference=4&amp;#39;,&lt;/p&gt;\n\n&lt;p&gt;headers=headers,&lt;/p&gt;\n\n&lt;p&gt;params=params&lt;/p&gt;\n\n&lt;p&gt;).json()&lt;/p&gt;\n\n&lt;p&gt;return response&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;def parse_json():&lt;/p&gt;\n\n&lt;p&gt;data = []&lt;/p&gt;\n\n&lt;p&gt;for i in range(1,4):&lt;/p&gt;\n\n&lt;p&gt;jsonData = get_data(page=i)&lt;/p&gt;\n\n&lt;p&gt;athletes = jsonData[&amp;quot;athletes&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;for athlete in athletes:&lt;/p&gt;\n\n&lt;p&gt;name = athlete[&amp;quot;athlete&amp;quot;][&amp;quot;displayName&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;teamName = athlete[&amp;#39;athlete&amp;#39;][&amp;#39;teamShortName&amp;#39;]&lt;/p&gt;\n\n&lt;p&gt;games_minutes_points = athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][0:2]\\&lt;/p&gt;\n\n&lt;p&gt;+[athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][0]]&lt;/p&gt;\n\n&lt;p&gt;rebounds_assists = [athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][12]]\\&lt;/p&gt;\n\n&lt;p&gt;+ [athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][10]]&lt;/p&gt;\n\n&lt;p&gt;tov_perg = [athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][11]]&lt;/p&gt;\n\n&lt;p&gt;fouls_perg = [athlete[&amp;#39;categories&amp;#39;][0][&amp;#39;totals&amp;#39;][2]]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;steals_blocks = athlete[&amp;#39;categories&amp;#39;][2][&amp;#39;totals&amp;#39;][0:2]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;shooting_totals = athlete[&amp;#39;categories&amp;#39;][1][&amp;#39;totals&amp;#39;][1:10]&lt;/p&gt;\n\n&lt;p&gt;totals = games_minutes_points + rebounds_assists+steals_blocks\\&lt;/p&gt;\n\n&lt;p&gt;+tov_perg+fouls_perg+shooting_totals&lt;/p&gt;\n\n&lt;p&gt;# totals = athlete[&amp;quot;categories&amp;quot;][1][&amp;quot;totals&amp;quot;]&lt;/p&gt;\n\n&lt;p&gt;player_position = athlete[&amp;#39;athlete&amp;#39;][&amp;#39;position&amp;#39;][&amp;#39;name&amp;#39;]&lt;/p&gt;\n\n&lt;p&gt;rank = athlete[&amp;quot;categories&amp;quot;][1][&amp;quot;ranks&amp;quot;][0]&lt;/p&gt;\n\n&lt;p&gt;data.append(&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;name&amp;quot;: name,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;teamName&amp;quot;: teamName,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;position&amp;quot;: athlete[&amp;#39;athlete&amp;#39;][&amp;#39;position&amp;#39;][&amp;#39;name&amp;#39;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;totals&amp;quot;: totals,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;rank&amp;quot;: rank&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;print(f&amp;quot;[INFO] {i}/3 processed&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;sleep(3)&lt;/p&gt;\n\n&lt;p&gt;with open(&amp;quot;jsonData.json&amp;quot;, &amp;quot;w&amp;quot;, encoding =&amp;quot;utf-8&amp;quot;) as file:&lt;/p&gt;\n\n&lt;p&gt;json.dump(data, file, indent=4, ensure_ascii=False)&lt;/p&gt;\n\n&lt;p&gt;def main():&lt;/p&gt;\n\n&lt;p&gt;parse_json()&lt;/p&gt;\n\n&lt;p&gt;if __name__ == &amp;quot;__main__&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;main()&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13tr7gm", "is_robot_indexable": true, "report_reasons": null, "author": "FinancialSundew", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13tr7gm/webscraping_for_basketball_wnba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13tr7gm/webscraping_for_basketball_wnba/", "subreddit_subscribers": 911909, "created_utc": 1685247661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a raw biometric data where I get employee punch in time and in parallel to that I have employees shift details. Now with these two table how I can Identify last in early exit early in late out. Kindly suggest some logic to do so", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Attendance report ETL process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u66ot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685295228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a raw biometric data where I get employee punch in time and in parallel to that I have employees shift details. Now with these two table how I can Identify last in early exit early in late out. Kindly suggest some logic to do so&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u66ot", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u66ot/attendance_report_etl_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u66ot/attendance_report_etl_process/", "subreddit_subscribers": 911909, "created_utc": 1685295228.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}