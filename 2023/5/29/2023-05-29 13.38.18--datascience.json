{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.   \n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?   \nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don't really would like to do another Msc or a Phd. Is my worry correct or not necessarily?   \nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?", "author_fullname": "t2_dfmfjyei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I worked in DS jobs closely connected to business but I strongly dislike that and want to work in more technical jobs. What are some areas I could explore? And how to transition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ucq03", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685311958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on my second DS job. The first one was in a bank. And right now I work in a tech company in the airline industry. Both of them were very connected to business (I was basically forecasting revenue in both), but this makes me bored to death. I would like to work in a place where knowing math, programming, or domain knowledge would be more important than business rules.&lt;br/&gt;\n I feel that working on more technical problems would make me happier. My first thoughts go to computer vision, and maybe something like bioinformatics. What are other fields worth exploring?&lt;br/&gt;\nWhat worries me about that is how to transition. My background is math and I am afraid I would have to go back to university to be able to transition out of business jobs. But I don&amp;#39;t really would like to do another Msc or a Phd. Is my worry correct or not necessarily?&lt;br/&gt;\nWhat about compensation? I have an intuition that business DS jobs should pay more than purely technical ones. Is that correct?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ucq03", "is_robot_indexable": true, "report_reasons": null, "author": "TheManveru", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ucq03/i_worked_in_ds_jobs_closely_connected_to_business/", "subreddit_subscribers": 912271, "created_utc": 1685311958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got laid off from my data science job a month ago. The job search has been brutal. I\u2019ve only had about four phone screens and two first round interviews after about 100 job applications. I\u2019ve been rejected from everything and have zero leads right now.\n\nI had my job for a little over a year, but it was not a very prominent company, so I don\u2019t think it looks that impressive on my resume. I think I\u2019ve done pretty well in my interviews so far so I suspect I\u2019m being rejected due to them finding out I was laid off. If they ask about my reason for leaving my last job, what should I say? Maybe I can make something up that sounds better.\n\nWhat is the easiest way to stand out? I don\u2019t have much of a portfolio and no publications. Which projects should I work on? I need to get hired fast because Im in a lot of student debt and have a huge lease, so Im not looking to do any long term projects. I\u2019d also love to collaborate with someone if possible.", "author_fullname": "t2_4c31z7fw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laid off data science looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u9dl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685303458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got laid off from my data science job a month ago. The job search has been brutal. I\u2019ve only had about four phone screens and two first round interviews after about 100 job applications. I\u2019ve been rejected from everything and have zero leads right now.&lt;/p&gt;\n\n&lt;p&gt;I had my job for a little over a year, but it was not a very prominent company, so I don\u2019t think it looks that impressive on my resume. I think I\u2019ve done pretty well in my interviews so far so I suspect I\u2019m being rejected due to them finding out I was laid off. If they ask about my reason for leaving my last job, what should I say? Maybe I can make something up that sounds better.&lt;/p&gt;\n\n&lt;p&gt;What is the easiest way to stand out? I don\u2019t have much of a portfolio and no publications. Which projects should I work on? I need to get hired fast because Im in a lot of student debt and have a huge lease, so Im not looking to do any long term projects. I\u2019d also love to collaborate with someone if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u9dl3", "is_robot_indexable": true, "report_reasons": null, "author": "CharliDelReyJepsen", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u9dl3/laid_off_data_science_looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u9dl3/laid_off_data_science_looking_for_advice/", "subreddit_subscribers": 912271, "created_utc": 1685303458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Senior DS and hiring managers, how are you finding the job market right now? Is it the same for DS jobs as SDE jobs? Is the job market for lower positions saturated with new grads and laid-off experienced folk? \n\nWould you see yourself getting an interview call for the position you are holding right now? Do degrees matter more than experience? What would you like to see in a candidate to make the hiring decision easier for you?", "author_fullname": "t2_875mxmzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does it look from the other side for hiring currently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ul5oa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685335736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Senior DS and hiring managers, how are you finding the job market right now? Is it the same for DS jobs as SDE jobs? Is the job market for lower positions saturated with new grads and laid-off experienced folk? &lt;/p&gt;\n\n&lt;p&gt;Would you see yourself getting an interview call for the position you are holding right now? Do degrees matter more than experience? What would you like to see in a candidate to make the hiring decision easier for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ul5oa", "is_robot_indexable": true, "report_reasons": null, "author": "dark-ascension", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ul5oa/how_does_it_look_from_the_other_side_for_hiring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ul5oa/how_does_it_look_from_the_other_side_for_hiring/", "subreddit_subscribers": 912271, "created_utc": 1685335736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: i have worked as a Full-stack(react, node, python, devops in aws) developer for a year doing freelance and the last 6 months i've been working as a data engineer for 12k/year, i'm from south america and here is not that bad of a salary. i've read papers on ML since 2018 and even develop a lot of models thru the years, i did a ML bootcamp and lately i jumped on the LLM hype train and developed some tools with it(doing proompt engineering, i have also made a dataset of results for a tool capable LLM to fine-tune when i get the necessary access to the compute i need), i feel stuck in my career right now and dont feel as ready(technically speaking) to jump for a job in ML although is an area i cannot keep out of my head, what do you recommend?", "author_fullname": "t2_64irsilo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which job do you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u3c3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685288262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: i have worked as a Full-stack(react, node, python, devops in aws) developer for a year doing freelance and the last 6 months i&amp;#39;ve been working as a data engineer for 12k/year, i&amp;#39;m from south america and here is not that bad of a salary. i&amp;#39;ve read papers on ML since 2018 and even develop a lot of models thru the years, i did a ML bootcamp and lately i jumped on the LLM hype train and developed some tools with it(doing proompt engineering, i have also made a dataset of results for a tool capable LLM to fine-tune when i get the necessary access to the compute i need), i feel stuck in my career right now and dont feel as ready(technically speaking) to jump for a job in ML although is an area i cannot keep out of my head, what do you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u3c3v", "is_robot_indexable": true, "report_reasons": null, "author": "Guzhi", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u3c3v/which_job_do_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u3c3v/which_job_do_you_recommend/", "subreddit_subscribers": 912271, "created_utc": 1685288262.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data scientist and finished university some years ago. I studied math, and during my course I was exposed to some introductions to probability, inference, regression, multivariate analysis, etc. But never dived deep into any of these topics. Now I want to go back to statistics and improve my understanding. Some topics I would like to go back are, for instance, stochastic processes, time series, bayesian statistics. \n\nBecause of that, I want to buy a book that I could improve my understanding and refer to when in need of refreshing some topics that I am already familiar.   \nWhat I don't want is to need to buy various different books for each area. I would prefer to have one encompassing more or less everything I need to know as a typical data scientist. Is there such a thing? Do you have any recommendations? I found this 'Practical Statistics for Data Scientists', can someone recommend it?", "author_fullname": "t2_dfmfjyei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice of good statistics textbooks for reference on intermediate level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u7kql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685298828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data scientist and finished university some years ago. I studied math, and during my course I was exposed to some introductions to probability, inference, regression, multivariate analysis, etc. But never dived deep into any of these topics. Now I want to go back to statistics and improve my understanding. Some topics I would like to go back are, for instance, stochastic processes, time series, bayesian statistics. &lt;/p&gt;\n\n&lt;p&gt;Because of that, I want to buy a book that I could improve my understanding and refer to when in need of refreshing some topics that I am already familiar.&lt;br/&gt;\nWhat I don&amp;#39;t want is to need to buy various different books for each area. I would prefer to have one encompassing more or less everything I need to know as a typical data scientist. Is there such a thing? Do you have any recommendations? I found this &amp;#39;Practical Statistics for Data Scientists&amp;#39;, can someone recommend it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u7kql", "is_robot_indexable": true, "report_reasons": null, "author": "TheManveru", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u7kql/advice_of_good_statistics_textbooks_for_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u7kql/advice_of_good_statistics_textbooks_for_reference/", "subreddit_subscribers": 912271, "created_utc": 1685298828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If you\u2019ve recently scored a job and happy with it, please give us a snapshot of your background and the role that you\u2019ve landed.", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sick of the Career doom and gloom- if you\u2019ve recently scored a job tell us about it. Keen to hear some positive experiences!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uqs5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685355425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you\u2019ve recently scored a job and happy with it, please give us a snapshot of your background and the role that you\u2019ve landed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uqs5p", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uqs5p/sick_of_the_career_doom_and_gloom_if_youve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uqs5p/sick_of_the_career_doom_and_gloom_if_youve/", "subreddit_subscribers": 912271, "created_utc": 1685355425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone. I have 2 YOE in data science/machine learning and after a gap year I encounter a new potential job  doing science computation. It was inside a stable, traditional industry company's scientific department. The job will be doing C++ and Python development on their Linux-foundation donated open source repo, heavy math and  little ML will be involved.  I think the job have some benefits:\n\n\\- good wlb\n\n\\- less hassle with meetings, business stakeholders, etc. \n\n\\-pure tech, good for some areas of development\n\nBut I worry:\n\n\\- deviate from \"mainstream\" of data sciecne, say NLP, transformers, CV, etc.\n\n\\- deviate from big data and cloud computing\n\n\\- deviate from business sense \n\nWill this job bind me too hard with their open-source will make me hard to switch jobs later on? Dear senior data folks, what do you think?", "author_fullname": "t2_12dg2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Career Advice]Open-source scientific programmer job prospect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u8kg1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685301428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I have 2 YOE in data science/machine learning and after a gap year I encounter a new potential job  doing science computation. It was inside a stable, traditional industry company&amp;#39;s scientific department. The job will be doing C++ and Python development on their Linux-foundation donated open source repo, heavy math and  little ML will be involved.  I think the job have some benefits:&lt;/p&gt;\n\n&lt;p&gt;- good wlb&lt;/p&gt;\n\n&lt;p&gt;- less hassle with meetings, business stakeholders, etc. &lt;/p&gt;\n\n&lt;p&gt;-pure tech, good for some areas of development&lt;/p&gt;\n\n&lt;p&gt;But I worry:&lt;/p&gt;\n\n&lt;p&gt;- deviate from &amp;quot;mainstream&amp;quot; of data sciecne, say NLP, transformers, CV, etc.&lt;/p&gt;\n\n&lt;p&gt;- deviate from big data and cloud computing&lt;/p&gt;\n\n&lt;p&gt;- deviate from business sense &lt;/p&gt;\n\n&lt;p&gt;Will this job bind me too hard with their open-source will make me hard to switch jobs later on? Dear senior data folks, what do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u8kg1", "is_robot_indexable": true, "report_reasons": null, "author": "zjplab", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u8kg1/career_adviceopensource_scientific_programmer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u8kg1/career_adviceopensource_scientific_programmer_job/", "subreddit_subscribers": 912271, "created_utc": 1685301428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just started a data science internship, and my small team's first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). \n\nStandard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don't know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you're not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.\n\nMy idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. \n\nHas anyone tried this network-based fuzzy matching? Does it even sound promising? \n\n(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I'm encouraged to experiment for the sake of learning, even if it's a little less time efficient. We also have a VM to use over the summer for free.)", "author_fullname": "t2_hdmiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "String distance based network for fuzzy matching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u4sd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685293119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685291834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started a data science internship, and my small team&amp;#39;s first task is to a solve a fuzzy matching problem in one of their datasets: the same organizations (~15k) are referred to with different strings across entries (~125k). &lt;/p&gt;\n\n&lt;p&gt;Standard solution is to make a dictionary of known/parent entities, and calculate string distance (e.g. levenshtein, jaro-winkler, jaccard) between each dictionary entry and each observed entry in the data, then classify observed entries to parent entities based on a string distance threshold. Cool. But (a) still requires a lot of manual oversight (what if you don&amp;#39;t know the true list of parent entities?), (b) by only looking at distances between the dictionary entities and observed entries you&amp;#39;re not capitalizing on a lot of information in the data, (c) our client already uses this method and wants to further automate/improve their fuzzy matching process.&lt;/p&gt;\n\n&lt;p&gt;My idea: What if you took string distances between all possible pairs of observed entries, and used them as the edge-weights in a network where each observed entry is a node? Then you could plot the network to visually identify clusters that might indicate parent entities, and could maybe even use community detection or block modelling on the text network to automatically cluster observed entries to (model-predicted) parent entities. &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this network-based fuzzy matching? Does it even sound promising? &lt;/p&gt;\n\n&lt;p&gt;(Important context: my internship is funded by a data science fellowship from my uni, so unlike a normal job or internship I&amp;#39;m encouraged to experiment for the sake of learning, even if it&amp;#39;s a little less time efficient. We also have a VM to use over the summer for free.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u4sd7", "is_robot_indexable": true, "report_reasons": null, "author": "ChiefWilliam", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u4sd7/string_distance_based_network_for_fuzzy_matching/", "subreddit_subscribers": 912271, "created_utc": 1685291834.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with imbalanced datetime data in Pandas? Any techniques for resampling or handling irregular time intervals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13uu2kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685364733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uu2kw", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uu2kw/how_do_you_deal_with_imbalanced_datetime_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uu2kw/how_do_you_deal_with_imbalanced_datetime_data_in/", "subreddit_subscribers": 912271, "created_utc": 1685364733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 29 May, 2023 - 05 Jun, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uk8qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685332890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uk8qw", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uk8qw/weekly_entering_transitioning_thread_29_may_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/13uk8qw/weekly_entering_transitioning_thread_29_may_2023/", "subreddit_subscribers": 912271, "created_utc": 1685332890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. \n\nWhat's the minimum amount of data needed for reliable results? Even if I don't have enough data, should I run the model anyway?\n\nI have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?\n\nPlease share your experiences, rule-of-thumb guidelines, and any relevant resources. \n\nThanks.", "author_fullname": "t2_s6n4mlrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trajectory model - enough data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uh97w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685324071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a group-based multivariate trajectory model (GBMT) using the gbmt R package by Magrini and need your input on sample size requirements. My aim is to understand how trajectories change after treatment. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the minimum amount of data needed for reliable results? Even if I don&amp;#39;t have enough data, should I run the model anyway?&lt;/p&gt;\n\n&lt;p&gt;I have longitudinal data with multiple time points and want to assess the effects of treatment on trajectory patterns. Should I exclude individuals who have data at only one time point?&lt;/p&gt;\n\n&lt;p&gt;Please share your experiences, rule-of-thumb guidelines, and any relevant resources. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uh97w", "is_robot_indexable": true, "report_reasons": null, "author": "metalhead_nerd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uh97w/trajectory_model_enough_data/", "subreddit_subscribers": 912271, "created_utc": 1685324071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. Wondering on your preferred modality for running computations on a complex dataset. The choices at this stage are:\n\n1. Structure SQL queries for exactly the data needed from the DB, to draw into a central dashboard/reporting mechanism (proprietary design), or\n2. Download relevant chunks of the data as dataframes, and manipulate in real time (i.e. backend) to get the desired computed result.\n\nAs an example, if someone wanted to know the demographics of their primary clients, we could either:\n\na. Structure a SQL query that computes the mode gender, median age, type of qualification, etc, based on each user's unique ID and pass the results directly to the reporting mechanism, or\n\nb. Gather dataframes at the beginning (i.e. start-up of the online system) that include relevant variables for any type of analysis for reporting, and based on the requirements at the specific point in the system process compute the outcome (e.g. demographics), through filtering and other methods.\n\nI know one is likely to be more performant than the other.\n\nThe requirements are: to interrogate big data, with JIT output to users, with the capability to zoom in/out of particular clusters, deal with lag from the central data processing system, de-identify PII data, and handle concurrent queries on large data with a high degree of traffic.\n\nIf you were approaching this, I'd be curious on your preferred mode of analysis, and reasons.", "author_fullname": "t2_vv6vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling methodology - SQL or dataframes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u5k9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685293688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Wondering on your preferred modality for running computations on a complex dataset. The choices at this stage are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Structure SQL queries for exactly the data needed from the DB, to draw into a central dashboard/reporting mechanism (proprietary design), or&lt;/li&gt;\n&lt;li&gt;Download relevant chunks of the data as dataframes, and manipulate in real time (i.e. backend) to get the desired computed result.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As an example, if someone wanted to know the demographics of their primary clients, we could either:&lt;/p&gt;\n\n&lt;p&gt;a. Structure a SQL query that computes the mode gender, median age, type of qualification, etc, based on each user&amp;#39;s unique ID and pass the results directly to the reporting mechanism, or&lt;/p&gt;\n\n&lt;p&gt;b. Gather dataframes at the beginning (i.e. start-up of the online system) that include relevant variables for any type of analysis for reporting, and based on the requirements at the specific point in the system process compute the outcome (e.g. demographics), through filtering and other methods.&lt;/p&gt;\n\n&lt;p&gt;I know one is likely to be more performant than the other.&lt;/p&gt;\n\n&lt;p&gt;The requirements are: to interrogate big data, with JIT output to users, with the capability to zoom in/out of particular clusters, deal with lag from the central data processing system, de-identify PII data, and handle concurrent queries on large data with a high degree of traffic.&lt;/p&gt;\n\n&lt;p&gt;If you were approaching this, I&amp;#39;d be curious on your preferred mode of analysis, and reasons.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u5k9x", "is_robot_indexable": true, "report_reasons": null, "author": "ryanblumenow", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u5k9x/modelling_methodology_sql_or_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u5k9x/modelling_methodology_sql_or_dataframes/", "subreddit_subscribers": 912271, "created_utc": 1685293688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone,\n\nI have a dataset named A that has 2020 years data about the unique patient id, claim date, disease code and 15 columns which contains the individual costs. Similarly I have the data for 2021 and 2022. What I want to check is in a given year, if a patient has a certain disease (Eg: disease\\_code = 72148) I want to get the cost of this patient 30 days before this disease occurring (the total cost which is the sum of all 15 columns) and also their total costs 12 months after the disease. I want this cost breakdown for each patient in two different columns (namely 30\\_days\\_prior and  12\\_months after). The claim through date is the date we are looking at. If I want to write a SQL query that has to do it, how can I do it? I am really lost at the moment. \n\nThank You.", "author_fullname": "t2_4h6cb2jt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help with this.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ukzvy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685335214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I have a dataset named A that has 2020 years data about the unique patient id, claim date, disease code and 15 columns which contains the individual costs. Similarly I have the data for 2021 and 2022. What I want to check is in a given year, if a patient has a certain disease (Eg: disease_code = 72148) I want to get the cost of this patient 30 days before this disease occurring (the total cost which is the sum of all 15 columns) and also their total costs 12 months after the disease. I want this cost breakdown for each patient in two different columns (namely 30_days_prior and  12_months after). The claim through date is the date we are looking at. If I want to write a SQL query that has to do it, how can I do it? I am really lost at the moment. &lt;/p&gt;\n\n&lt;p&gt;Thank You.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ukzvy", "is_robot_indexable": true, "report_reasons": null, "author": "ricky1435", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ukzvy/please_help_with_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ukzvy/please_help_with_this/", "subreddit_subscribers": 912271, "created_utc": 1685335214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nThis semester I start to learn deep learning course and seem like my laptop cannot have enough ram and GPU to support that. Is there any cloud service that I can train my model for more than 24 hours?\n\nThank for your advice", "author_fullname": "t2_alz74kl7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suitable cloud service to learn deep learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u7kgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685298808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;This semester I start to learn deep learning course and seem like my laptop cannot have enough ram and GPU to support that. Is there any cloud service that I can train my model for more than 24 hours?&lt;/p&gt;\n\n&lt;p&gt;Thank for your advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u7kgp", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Might5303", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u7kgp/suitable_cloud_service_to_learn_deep_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u7kgp/suitable_cloud_service_to_learn_deep_learning/", "subreddit_subscribers": 912271, "created_utc": 1685298808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "289k Medium Articles at Your Fingertips! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13upwky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_k7f68ffu", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "datasets", "selftext": "Hello everyone! \ud83d\udc4b\n\nI'm thrilled to share an exciting update with all of you today. We've just completed a remarkable data project, and the result is nothing short of extraordinary. Introducing our **colossal dataset of 289k Medium Articles!** \ud83c\udf89\ud83d\udd25\n\nDataset Overview: \n\nThis incredible collection is the culmination of our meticulous efforts, as we scoured **35 different publications**, capturing the evolution of their articles **from inception to 26 May 2023**. Imagine the vast wealth of knowledge waiting to be explored!\n\nWhat's in the Dataset?\n\nContained within a **convenient 1.7GB zip file**, the dataset is organized into 35 folders, each corresponding to a specific Medium publication. Dive into these folders, and you'll discover **thousands of JSON files packed with article-related information,** including titles, authors, word counts, reading times, claps, comments, publication details, and much more. It's a data enthusiast's dream come true! \ud83e\udd13\ud83d\udca1\n\nUnleashing the Power of Metadata:\n\nBut wait, there's more! We've gone the extra mile to provide you with comprehensive metadata for each article. From the text itself to markups, embeds, links, and other contextual information, this dataset empowers you to delve into the nuances of content and unlock deeper insights. The possibilities are endless! \ud83d\udcc4\ud83d\udd0d\u2728\n\nFueling Research and Innovation:\n\nWhether you're a data scientist, a researcher, or an innovator, this dataset is a game-changer. It opens up new avenues for groundbreaking research in natural language processing, content analysis, user behavior patterns, and more. Let your curiosity run wild and see where this treasure trove of knowledge takes you! \ud83d\ude80\ud83d\udd2c\ud83d\udca5\n\nHow to Get Access:\n\nIf you're as excited as we are about this dataset, we'd love to share it with you. Simply reach out to us at [**nishu@mediumapi.com**](mailto:nishu@mediumapi.com)**,** and our team will guide you through the process of obtaining this   \ninvaluable resource. Let's embark on a journey of discovery together!  \ud83d\udce7\ud83d\udcbb\n\nResponsible Data Usage:\n\nWith great data comes great responsibility. We kindly request that all users utilize this dataset strictly for research purposes and in accordance with Medium's terms and conditions. Let's maintain ethical   \ndata practices and respect the intellectual property rights of content creators. \ud83d\ude4f\ud83d\udd12\n\nJoin the Knowledge Revolution:\n\nWe believe that knowledge should be shared and accessible to all. This dataset represents a major step toward democratizing information and fostering innovation. Together, we can push the boundaries of what's possible and create a brighter future. Join us on this thrilling   \nadventure! \ud83c\udf0d\ud83d\udcaa\ud83d\udca1\n\nLet's ignite a spark of discovery, unravel hidden insights, and propel the world of research and innovation forward. Reach out, grab your slice of this remarkable dataset, and embark on a journey that will redefine the limits of knowledge!", "author_fullname": "t2_k7f68ffu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "289k Medium Articles at Your Fingertips! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datasets", "hidden": false, "pwls": 6, "link_flair_css_class": "dataset", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13upmn3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "dataset", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685351451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thrilled to share an exciting update with all of you today. We&amp;#39;ve just completed a remarkable data project, and the result is nothing short of extraordinary. Introducing our &lt;strong&gt;colossal dataset of 289k Medium Articles!&lt;/strong&gt; \ud83c\udf89\ud83d\udd25&lt;/p&gt;\n\n&lt;p&gt;Dataset Overview: &lt;/p&gt;\n\n&lt;p&gt;This incredible collection is the culmination of our meticulous efforts, as we scoured &lt;strong&gt;35 different publications&lt;/strong&gt;, capturing the evolution of their articles &lt;strong&gt;from inception to 26 May 2023&lt;/strong&gt;. Imagine the vast wealth of knowledge waiting to be explored!&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s in the Dataset?&lt;/p&gt;\n\n&lt;p&gt;Contained within a &lt;strong&gt;convenient 1.7GB zip file&lt;/strong&gt;, the dataset is organized into 35 folders, each corresponding to a specific Medium publication. Dive into these folders, and you&amp;#39;ll discover &lt;strong&gt;thousands of JSON files packed with article-related information,&lt;/strong&gt; including titles, authors, word counts, reading times, claps, comments, publication details, and much more. It&amp;#39;s a data enthusiast&amp;#39;s dream come true! \ud83e\udd13\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Unleashing the Power of Metadata:&lt;/p&gt;\n\n&lt;p&gt;But wait, there&amp;#39;s more! We&amp;#39;ve gone the extra mile to provide you with comprehensive metadata for each article. From the text itself to markups, embeds, links, and other contextual information, this dataset empowers you to delve into the nuances of content and unlock deeper insights. The possibilities are endless! \ud83d\udcc4\ud83d\udd0d\u2728&lt;/p&gt;\n\n&lt;p&gt;Fueling Research and Innovation:&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a data scientist, a researcher, or an innovator, this dataset is a game-changer. It opens up new avenues for groundbreaking research in natural language processing, content analysis, user behavior patterns, and more. Let your curiosity run wild and see where this treasure trove of knowledge takes you! \ud83d\ude80\ud83d\udd2c\ud83d\udca5&lt;/p&gt;\n\n&lt;p&gt;How to Get Access:&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re as excited as we are about this dataset, we&amp;#39;d love to share it with you. Simply reach out to us at [&lt;strong&gt;&lt;a href=\"mailto:nishu@mediumapi.com\"&gt;nishu@mediumapi.com&lt;/a&gt;&lt;/strong&gt;](mailto:&lt;a href=\"mailto:nishu@mediumapi.com\"&gt;nishu@mediumapi.com&lt;/a&gt;)&lt;strong&gt;,&lt;/strong&gt; and our team will guide you through the process of obtaining this&lt;br/&gt;\ninvaluable resource. Let&amp;#39;s embark on a journey of discovery together!  \ud83d\udce7\ud83d\udcbb&lt;/p&gt;\n\n&lt;p&gt;Responsible Data Usage:&lt;/p&gt;\n\n&lt;p&gt;With great data comes great responsibility. We kindly request that all users utilize this dataset strictly for research purposes and in accordance with Medium&amp;#39;s terms and conditions. Let&amp;#39;s maintain ethical&lt;br/&gt;\ndata practices and respect the intellectual property rights of content creators. \ud83d\ude4f\ud83d\udd12&lt;/p&gt;\n\n&lt;p&gt;Join the Knowledge Revolution:&lt;/p&gt;\n\n&lt;p&gt;We believe that knowledge should be shared and accessible to all. This dataset represents a major step toward democratizing information and fostering innovation. Together, we can push the boundaries of what&amp;#39;s possible and create a brighter future. Join us on this thrilling&lt;br/&gt;\nadventure! \ud83c\udf0d\ud83d\udcaa\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s ignite a spark of discovery, unravel hidden insights, and propel the world of research and innovation forward. Reach out, grab your slice of this remarkable dataset, and embark on a journey that will redefine the limits of knowledge!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f074feb2-5bcd-11e6-8c1d-0e0220cd4035", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r97t", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13upmn3", "is_robot_indexable": true, "report_reasons": null, "author": "medium-api", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "subreddit_subscribers": 175457, "created_utc": 1685351451.0, "num_crossposts": 8, "media": null, "is_video": false}], "created": 1685352468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datasets", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13upwky", "is_robot_indexable": true, "report_reasons": null, "author": "medium-api", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13upmn3", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13upwky/289k_medium_articles_at_your_fingertips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/datasets/comments/13upmn3/289k_medium_articles_at_your_fingertips/", "subreddit_subscribers": 912271, "created_utc": 1685352468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2nmafout", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for 150 tech professionals to mentor interested mentees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13upoit", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/zMzfccSWmUMcrIR3S0b_Rc7qPL4hnFVPXWKMGG8fej0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685351644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/michelle-naa-odarley-lawson-218894215_mentor-diversityandinclusion-volunteer-activity-7068875298624131072-e2vm?utm_source=share&amp;utm_medium=member_ios", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QhB1jsK8LPVf-6XhyxE7-WZCleIgbKmUxNpDXPmz2jk.jpg?auto=webp&amp;v=enabled&amp;s=336fc645a568550123b518c5dd54b70178e0570c", "width": 800, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/QhB1jsK8LPVf-6XhyxE7-WZCleIgbKmUxNpDXPmz2jk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=220d4fbbc23b4a0a5a94698f75125494005fe439", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QhB1jsK8LPVf-6XhyxE7-WZCleIgbKmUxNpDXPmz2jk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=324b98053748db08100ef10e8b6e36c4ea4c9bbb", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/QhB1jsK8LPVf-6XhyxE7-WZCleIgbKmUxNpDXPmz2jk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64a6ae84f03999652bdf7581fe02e59c1435f0fc", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/QhB1jsK8LPVf-6XhyxE7-WZCleIgbKmUxNpDXPmz2jk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f493e3639ed77ba357dcfd149b8b5022da1d4a1a", "width": 640, "height": 640}], "variants": {}, "id": "aDFK5_X0jS4sVfi3-PmA0fE4kBzoEzNTz5s3nbclbM4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "13upoit", "is_robot_indexable": true, "report_reasons": null, "author": "mich5250", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13upoit/looking_for_150_tech_professionals_to_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/michelle-naa-odarley-lawson-218894215_mentor-diversityandinclusion-volunteer-activity-7068875298624131072-e2vm?utm_source=share&amp;utm_medium=member_ios", "subreddit_subscribers": 912271, "created_utc": 1685351644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, PandasAI came out lately. For those who don't know, it's a python AI tool that is similar to ChatGPT except it generates figures and dataframes. I don't know if it also can run statistical tests or build regression models.\n\nI was wondering if there is a similar tool for R or if anyone is developing one for R.\n\nThank you!\n\nHere's the link to the repo for PandasAI if anyone's interested:  [gventuri/pandas-ai: Pandas AI is a Python library that integrates generative artificial intelligence capabilities into Pandas, making dataframes conversational (github.com)](https://github.com/gventuri/pandas-ai) ", "author_fullname": "t2_2ve4vyvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool like pandas-ai, but for R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uljnn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685336953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, PandasAI came out lately. For those who don&amp;#39;t know, it&amp;#39;s a python AI tool that is similar to ChatGPT except it generates figures and dataframes. I don&amp;#39;t know if it also can run statistical tests or build regression models.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is a similar tool for R or if anyone is developing one for R.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the repo for PandasAI if anyone&amp;#39;s interested:  &lt;a href=\"https://github.com/gventuri/pandas-ai\"&gt;gventuri/pandas-ai: Pandas AI is a Python library that integrates generative artificial intelligence capabilities into Pandas, making dataframes conversational (github.com)&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?auto=webp&amp;v=enabled&amp;s=6d402f7cce549ac1e2a6e89015892f8eb798ccae", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c15f212a765236b8acf2fb8aa7992cd1b2e2bea", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48621938f4e0707140b0a8cac8ede610b85b7585", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faebc473fcbf50bdbc1698d20a716d394f96d941", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7281794355c7fd112d94974abe9b3debd9ce7293", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b22910d5a65c098da1c79f7dbc1e09cdc78071b0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HjBkwrVICGlhr8BPAC6gzTYEKlWjfnD7Ze37iUkR4ZE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d776a3ba07ebc4c8c691978268b705950efb9c25", "width": 1080, "height": 540}], "variants": {}, "id": "BDaZUcmk3RERmdPy23Eg77E3CAJPXVwpUFehg3_99RM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uljnn", "is_robot_indexable": true, "report_reasons": null, "author": "statius9", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uljnn/is_there_a_tool_like_pandasai_but_for_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uljnn/is_there_a_tool_like_pandasai_but_for_r/", "subreddit_subscribers": 912271, "created_utc": 1685336953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " The year 2022 marked a turning point for GitHub and all its users, with the announcement of the general availability of two revolutionary services for developers: [GitHub Codespaces](https://github.com/features/codespaces?WT.mc_id=academic-84100-cacaste) and [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-84100-cacaste). A Codespace is a development environment hosted in the cloud and accessible via a web browser through one click, with the same graphical interface as the local Visual Studio Code IDE. GitHub Copilot is an AI-empowered pair programmer that offers autocomplete-style suggestions as you code in different programming languages (like Python, C++, Javascript, and more). But to give you a deeper understanding of what these services are and how you could benefit from them, let me tell you a story, or better two. \n\n[https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/](https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/)", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub Codespaces and GitHub Copilot: 2 Stories, Thousands of Possibilities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1ofs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685283823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The year 2022 marked a turning point for GitHub and all its users, with the announcement of the general availability of two revolutionary services for developers: &lt;a href=\"https://github.com/features/codespaces?WT.mc_id=academic-84100-cacaste\"&gt;GitHub Codespaces&lt;/a&gt; and &lt;a href=\"https://github.com/features/copilot?WT.mc_id=academic-84100-cacaste\"&gt;GitHub Copilot&lt;/a&gt;. A Codespace is a development environment hosted in the cloud and accessible via a web browser through one click, with the same graphical interface as the local Visual Studio Code IDE. GitHub Copilot is an AI-empowered pair programmer that offers autocomplete-style suggestions as you code in different programming languages (like Python, C++, Javascript, and more). But to give you a deeper understanding of what these services are and how you could benefit from them, let me tell you a story, or better two. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/\"&gt;https://opendatascience.com/github-codespaces-and-github-copilot-2-stories-thousands-of-possibilities/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?auto=webp&amp;v=enabled&amp;s=7ce90db687ca0f86c17fd0ff7978646ac7db7601", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d75463d336230de4082441ed5258047d1078c24", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9db1551060e1c89205de74a3c6dcdf9cd9816bb2", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5eff77272b9e28ed0d7308f09ac6c5b1359bb3d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c23caf3336f44df2fc8954e9f4aad2998941f0e8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb1cc48c7835c1b15f67144d3c97f48b41f57146", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/06MyJ4PQF9URQXCDjXDRgPLQ5AKjP1QNujxrVWCi_UY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3a75ea4cbcaa4480031140f39c114f7ea9b39a2", "width": 1080, "height": 567}], "variants": {}, "id": "x4QFD-xYyfgJ7ON1BuJLj7-BFqcX_7bv2xsvBGMcc1g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u1ofs", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u1ofs/github_codespaces_and_github_copilot_2_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u1ofs/github_codespaces_and_github_copilot_2_stories/", "subreddit_subscribers": 912271, "created_utc": 1685283823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does it worth to buy IPAD. I am a roster worker has to travel a lot. So it is not convenient to travel with laptop all the time. \nAdditional question?if u only use laptop to ur work, which do u prefer Windows or IOS?", "author_fullname": "t2_uiqgltfs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you effectively use your IPAD to your data analysis/science/visualization work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13uppnb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685351751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it worth to buy IPAD. I am a roster worker has to travel a lot. So it is not convenient to travel with laptop all the time. \nAdditional question?if u only use laptop to ur work, which do u prefer Windows or IOS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13uppnb", "is_robot_indexable": true, "report_reasons": null, "author": "Justrandomdude2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13uppnb/how_do_you_effectively_use_your_ipad_to_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13uppnb/how_do_you_effectively_use_your_ipad_to_your_data/", "subreddit_subscribers": 912271, "created_utc": 1685351751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Speech is one of the most natural and fundamental modes of human communication. In today\u2019s digital landscape \u2013where audio and video content proliferate across the web and within enterprises\u2014 leveraging automated speech AI is paramount, and can make content more accessible, as well as opening the door to greater analysis and insights.\u00a0\u00a0\n\nAzure Speech Services offer cutting-edge speech recognition and synthesis technology as well as a comprehensive suite of tools that you can leverage to transform how we communicate with machines and access information. In this post, we will explore key scenarios for implementing our Azure AI in your enterprise, and some of our most innovative Azure Speech features.\u00a0\n\n[https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/](https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/)", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking the Power of Voice: Enhance Your Applications with Azure Speech Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u1rje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685284065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Speech is one of the most natural and fundamental modes of human communication. In today\u2019s digital landscape \u2013where audio and video content proliferate across the web and within enterprises\u2014 leveraging automated speech AI is paramount, and can make content more accessible, as well as opening the door to greater analysis and insights.\u00a0\u00a0&lt;/p&gt;\n\n&lt;p&gt;Azure Speech Services offer cutting-edge speech recognition and synthesis technology as well as a comprehensive suite of tools that you can leverage to transform how we communicate with machines and access information. In this post, we will explore key scenarios for implementing our Azure AI in your enterprise, and some of our most innovative Azure Speech features.\u00a0&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/\"&gt;https://opendatascience.com/unlocking-the-power-of-voice-enhance-your-applications-with-azure-speech-services/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?auto=webp&amp;v=enabled&amp;s=875e1e0518f7397734d64fd5d3249689f24e9882", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0cc8ffe325285617a565183db0ffe28901195f61", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49aa20a7a383686b9a50239d11cd6cd40babe589", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21d8228289e51d76883855da317d13138e0207c2", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/LMlV6RzaWhFI45aeIyv-MaAk5HmiduWzyu7j1ltlUOo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5546c69e2bae07aa4976b24646fff35dfe0b174f", "width": 640, "height": 300}], "variants": {}, "id": "D-2-tlED6dP2-lgf-NHf309v2q1t0rQ1bf6agM1iqXk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u1rje", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u1rje/unlocking_the_power_of_voice_enhance_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u1rje/unlocking_the_power_of_voice_enhance_your/", "subreddit_subscribers": 912271, "created_utc": 1685284065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a raw biometric data where I get employee punch in time and in parallel to that I have employees shift details. Now with these two table how I can Identify last in early exit early in late out. Kindly suggest some logic to do so", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Attendance report ETL process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13u66ot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685295228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a raw biometric data where I get employee punch in time and in parallel to that I have employees shift details. Now with these two table how I can Identify last in early exit early in late out. Kindly suggest some logic to do so&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13u66ot", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13u66ot/attendance_report_etl_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13u66ot/attendance_report_etl_process/", "subreddit_subscribers": 912271, "created_utc": 1685295228.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}