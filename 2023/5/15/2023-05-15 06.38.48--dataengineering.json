{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_76fvluuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE's when a new job uses a different cloud platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13hebz5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 138, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 138, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aXF_s_0TbGZ_b6GiRUD8cuCIYiGvR0sGT-VeW5mxcJU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684076149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/szesjdra9tza1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/szesjdra9tza1.png?auto=webp&amp;v=enabled&amp;s=97a7a234a1fb89096fc8b25829f3a83b825ce669", "width": 800, "height": 600}, "resolutions": [{"url": "https://preview.redd.it/szesjdra9tza1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=706b0e986cc6ad4706b30636de07d80edf600751", "width": 108, "height": 81}, {"url": "https://preview.redd.it/szesjdra9tza1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=654ea07ba1763899ef2239f3cbcda2f983851d92", "width": 216, "height": 162}, {"url": "https://preview.redd.it/szesjdra9tza1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db01d98c882be03433ebbd756bc728e45daa50e8", "width": 320, "height": 240}, {"url": "https://preview.redd.it/szesjdra9tza1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ece7d6375cca563383ec102d0abefdbacaded33a", "width": 640, "height": 480}], "variants": {}, "id": "U5cr1AKQ2F8uMX5OSqGr7IVYFhLoHIsY4mCjdRMX-mc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "13hebz5", "is_robot_indexable": true, "report_reasons": null, "author": "notGaruda1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hebz5/des_when_a_new_job_uses_a_different_cloud_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/szesjdra9tza1.png", "subreddit_subscribers": 105535, "created_utc": 1684076149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im currently a DE at a tech company working in the Marketing Optimization domain. I honestly like my company and we use all the modern data stack including a CDP and a rETL tool. Seems to be the best place to learn since that\u2019s were all the money is. BUT i found this marketing jargon and stuff really boring lol. The only other \u201cdomain\u201d in my company for DEs is in manufacturing and supply chain which seems even more boring imo lol.\n\nAnyone here working in some interesting companies or domains? I honestly prefer financial data but refuse to work in a bank (again lol). Mainly looking for tech companies. \n\nAny info or experience would be highly appreciated!", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any fun domains in tech to work in as DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hbvf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684069860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im currently a DE at a tech company working in the Marketing Optimization domain. I honestly like my company and we use all the modern data stack including a CDP and a rETL tool. Seems to be the best place to learn since that\u2019s were all the money is. BUT i found this marketing jargon and stuff really boring lol. The only other \u201cdomain\u201d in my company for DEs is in manufacturing and supply chain which seems even more boring imo lol.&lt;/p&gt;\n\n&lt;p&gt;Anyone here working in some interesting companies or domains? I honestly prefer financial data but refuse to work in a bank (again lol). Mainly looking for tech companies. &lt;/p&gt;\n\n&lt;p&gt;Any info or experience would be highly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13hbvf6", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hbvf6/any_fun_domains_in_tech_to_work_in_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hbvf6/any_fun_domains_in_tech_to_work_in_as_de/", "subreddit_subscribers": 105535, "created_utc": 1684069860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI recently had the opportunity to run a workshop at ODSC East, focusing on using PySpark for Natural Language Processing (NLP). Had a great time explaining PySpark's fundamentals and exploring the Spark NLP library.\n\nThe workshop included hands-on coding exercises like sentiment analysis and entity recognition using pre-trained models and word embeddings, all running on Databricks' community edition.\n\nFor anyone interested, I've made the Jupyter notebooks from the workshop available, complete with instructions to get them up and running on Databricks. You can find them here: [https://github.com/analyticalmonk/pyspark\\_nlp\\_workshop](https://github.com/analyticalmonk/pyspark_nlp_workshop).\n\n  \nShoutout to John Snow Labs for their great work on the [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) library.  \nI'd love to hear your thoughts or answer any questions you might have about the workshop or PySpark and NLP in general. :)", "author_fullname": "t2_1171b3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark for NLP Workshop - Materials and Jupyter Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hfb8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684079495.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684078564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I recently had the opportunity to run a workshop at ODSC East, focusing on using PySpark for Natural Language Processing (NLP). Had a great time explaining PySpark&amp;#39;s fundamentals and exploring the Spark NLP library.&lt;/p&gt;\n\n&lt;p&gt;The workshop included hands-on coding exercises like sentiment analysis and entity recognition using pre-trained models and word embeddings, all running on Databricks&amp;#39; community edition.&lt;/p&gt;\n\n&lt;p&gt;For anyone interested, I&amp;#39;ve made the Jupyter notebooks from the workshop available, complete with instructions to get them up and running on Databricks. You can find them here: &lt;a href=\"https://github.com/analyticalmonk/pyspark_nlp_workshop\"&gt;https://github.com/analyticalmonk/pyspark_nlp_workshop&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Shoutout to John Snow Labs for their great work on the &lt;a href=\"https://github.com/JohnSnowLabs/spark-nlp\"&gt;Spark NLP&lt;/a&gt; library.&lt;br/&gt;\nI&amp;#39;d love to hear your thoughts or answer any questions you might have about the workshop or PySpark and NLP in general. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?auto=webp&amp;v=enabled&amp;s=aacbfe486bcd099dea13e2b31617882a7621ecd8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae0906d084ce39cc4a1e6c82575ce67392a5cef1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d85b236535faaa6b6f8928086cf097e68de483f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0562f8c990a9d8349c25e5fae40862a43c567083", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50070244664687af71e97ab47d850ba6e60b3942", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02d34f8eb4afbdd06f8f148a5ee3a68c64fc5bd2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/tE9knVIjUOxPYaG9-AzfitdGTWDQi8qw4hcqw1qecCo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=370c8e164aa2b7285733face3d3c3c38450db9d2", "width": 1080, "height": 540}], "variants": {}, "id": "vSwGF6288EPc8W7vWwtWOVdr9nQHkeef-D5BBxBYJpY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "13hfb8a", "is_robot_indexable": true, "report_reasons": null, "author": "analyticalmonk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hfb8a/pyspark_for_nlp_workshop_materials_and_jupyter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hfb8a/pyspark_for_nlp_workshop_materials_and_jupyter/", "subreddit_subscribers": 105535, "created_utc": 1684078564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it's one of these posts again... but I'm torn between those two and would like to get some opinions.\n\nI want to learn both someday however, I can't decide which one I should go to first. I plan to move and work from abroad (SEA) next year, either by going into contracting or being employed by a company that allows me to work abroad full-time, and want to build a stack that gives me the best chances to get work. Currently, both are high in demand and I feel getting a solid foundation in one of both will help me set myself up to fulfill my goals. \n\nThat being said, I've recently tended to go into Snowflake as it's the most popular data warehouse solution, and coming from an RDBMS background getting into data warehousing, Snowflake seemed to be the choice to go. Also from posts like these https://www.reddit.com/r/dataengineering/comments/wcw0nt/what_is_in_your_data_stack_thread/ where it seems like ~80% of DEs use Snowflake as their DWH solutions, I thought Snowflake is the dominant solution.\n\nHowever, I've noticed a lot of comments on various posts suggesting to just learn Databricks to make money and be highly in demand. This would also align with my plan to build out my poor Python skills (eg pyspark) and get more into Spark.\n\nSo, regarding the fact that it would make more sense to get deeper into either one and build a solid foundation within the next few months, plus from my current employer, I get certifications and further training paid and I want to make use of that, which one would you choose or recommend to go into first to have the best chances landing contracting gigs or being employed remotely?", "author_fullname": "t2_goblmmss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Snowflake or Databricks regarding career advancement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hk4al", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684093422.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684090400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s one of these posts again... but I&amp;#39;m torn between those two and would like to get some opinions.&lt;/p&gt;\n\n&lt;p&gt;I want to learn both someday however, I can&amp;#39;t decide which one I should go to first. I plan to move and work from abroad (SEA) next year, either by going into contracting or being employed by a company that allows me to work abroad full-time, and want to build a stack that gives me the best chances to get work. Currently, both are high in demand and I feel getting a solid foundation in one of both will help me set myself up to fulfill my goals. &lt;/p&gt;\n\n&lt;p&gt;That being said, I&amp;#39;ve recently tended to go into Snowflake as it&amp;#39;s the most popular data warehouse solution, and coming from an RDBMS background getting into data warehousing, Snowflake seemed to be the choice to go. Also from posts like these &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/wcw0nt/what_is_in_your_data_stack_thread/\"&gt;https://www.reddit.com/r/dataengineering/comments/wcw0nt/what_is_in_your_data_stack_thread/&lt;/a&gt; where it seems like ~80% of DEs use Snowflake as their DWH solutions, I thought Snowflake is the dominant solution.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve noticed a lot of comments on various posts suggesting to just learn Databricks to make money and be highly in demand. This would also align with my plan to build out my poor Python skills (eg pyspark) and get more into Spark.&lt;/p&gt;\n\n&lt;p&gt;So, regarding the fact that it would make more sense to get deeper into either one and build a solid foundation within the next few months, plus from my current employer, I get certifications and further training paid and I want to make use of that, which one would you choose or recommend to go into first to have the best chances landing contracting gigs or being employed remotely?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13hk4al", "is_robot_indexable": true, "report_reasons": null, "author": "JobGott", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hk4al/learning_snowflake_or_databricks_regarding_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hk4al/learning_snowflake_or_databricks_regarding_career/", "subreddit_subscribers": 105535, "created_utc": 1684090400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_15bgjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Made a puzzle for data geeks \ud83e\udd13", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hf9k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1684078454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "funfordevs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://funfordevs.com/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13hf9k6", "is_robot_indexable": true, "report_reasons": null, "author": "siddharthnibjiya", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hf9k6/made_a_puzzle_for_data_geeks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://funfordevs.com/", "subreddit_subscribers": 105535, "created_utc": 1684078454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \n\nOur data is mostly in BigQuery and is around 1TB give or take. What cloud based tools other than dbt can be used for transformation and aggregation with all the features of dbt ?\n\nThanks!", "author_fullname": "t2_dtq1w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data transformation tools other than DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13he7yf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684075869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;Our data is mostly in BigQuery and is around 1TB give or take. What cloud based tools other than dbt can be used for transformation and aggregation with all the features of dbt ?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13he7yf", "is_robot_indexable": true, "report_reasons": null, "author": "perpetually_phi", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13he7yf/data_transformation_tools_other_than_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13he7yf/data_transformation_tools_other_than_dbt/", "subreddit_subscribers": 105535, "created_utc": 1684075869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nNot sure if there is an easy way to do this. I have a SELECT statement. I want to use it to either append the results to a table in Snowflake, or to create the table using the defined fields / field types and then insert the data into the table.\n\nIs there an easy way to do this?\n\nKinda 'CREATE TABLE IF NOT EXISTS OR INSERT INTO...'\n\n&amp;#x200B;\n\nEdit: I was thinking about a \n\nCREATE TABLE IF NOT EXISTS some\\_table AS SELECT a, b, c FROM xyz LIMIT 0;\n\nINSERT INTO some\\_table SELECT a, b, c FROM xyz;", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake / Python : Create table if not exists from SELECT, else append with same SELECT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13h6kks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684053296.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684052635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;Not sure if there is an easy way to do this. I have a SELECT statement. I want to use it to either append the results to a table in Snowflake, or to create the table using the defined fields / field types and then insert the data into the table.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to do this?&lt;/p&gt;\n\n&lt;p&gt;Kinda &amp;#39;CREATE TABLE IF NOT EXISTS OR INSERT INTO...&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I was thinking about a &lt;/p&gt;\n\n&lt;p&gt;CREATE TABLE IF NOT EXISTS some_table AS SELECT a, b, c FROM xyz LIMIT 0;&lt;/p&gt;\n\n&lt;p&gt;INSERT INTO some_table SELECT a, b, c FROM xyz;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13h6kks", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13h6kks/snowflake_python_create_table_if_not_exists_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13h6kks/snowflake_python_create_table_if_not_exists_from/", "subreddit_subscribers": 105535, "created_utc": 1684052635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3297c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM meets SQL; developing ChatGPT Plugins in dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13he4lp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ca75Tly8_h5SHlp6vS7ptT3OHJJFcBlWmy83D76FG_w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684075630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jinjat.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://jinjat.com/blog/develop-chatgpt-plugins-with-sql-using-jinjat", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?auto=webp&amp;v=enabled&amp;s=cf9e4548f859727950a5f6ffad2997b1d0597253", "width": 1588, "height": 892}, "resolutions": [{"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74b6722e13ec5d19192a1f87515b400ccb1912ce", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d63bda156b7fa7d4c0f32642a7ad077bc982b13", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78565b589eabc1f2151242f2a1c66718c0b26436", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99bd980985d0b124f5131c2b1900996ef411b757", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9edcb8cf841d94d5dc038458fe812898b05f1ac", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/mC24g1tcbPK5MydR89jjfsn5-_iKOuq7PUZt9IqFPO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da85c8bf9646bebe4926a03048bad0ba8f2fd050", "width": 1080, "height": 606}], "variants": {}, "id": "7FJ9CGvCl-NAcgjBp5EGRnVa08pU1OwkWtzhIEUbMJ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13he4lp", "is_robot_indexable": true, "report_reasons": null, "author": "Buremba", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13he4lp/llm_meets_sql_developing_chatgpt_plugins_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://jinjat.com/blog/develop-chatgpt-plugins-with-sql-using-jinjat", "subreddit_subscribers": 105535, "created_utc": 1684075630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, we\u2019re using Azure, and my boss is asking me how we can leverage Azure Premium Blob Storage across our stack. We use a variety of tools. I\u2019m not seeing very many blogs out there. I\u2019m curious how others are using it to see what patterns we should be thinking about.", "author_fullname": "t2_1resd6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Premium Blob Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13htopt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684114419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, we\u2019re using Azure, and my boss is asking me how we can leverage Azure Premium Blob Storage across our stack. We use a variety of tools. I\u2019m not seeing very many blogs out there. I\u2019m curious how others are using it to see what patterns we should be thinking about.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13htopt", "is_robot_indexable": true, "report_reasons": null, "author": "sgski2010", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13htopt/azure_premium_blob_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13htopt/azure_premium_blob_storage/", "subreddit_subscribers": 105535, "created_utc": 1684114419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am the sole data engineer on my department. There are a DA and a soon-to-be DS with me dealing with data regarding a single product from a big company I work for. The rest of the department are developers or product analysts, without much experience with data.\n\nI've migrated from a junior level software engineering job to data engineering not too long ago, and haven't had much training or contact with other data professionals. To this day, I've been constructing ETLs with the good old pandas that I've learnt on my own, deploying it with a scheduling service my company offers to IT people, and that's about it. I'm still refining my technical abilities.\n\nRecently, I caught myself thinking about a way to automatically document and change our BigQuery table schemas. Whenever I'm about to release a new ETL, I create the table manually, and I'm kind of fed up of doing this by hand. The problem is I haven't got a single clue on how I could do this, how people in our area do this, what tools I could use, if there's even a name/concept/term for what I want to do, and so on.\n\nMy current idea was to create a simple GitHub repo and document schemas (and stored procedures, maybe?) and somehow, implement an automated process to change the schemas directly from there. But it feels a bit \"not too professional\", if that makes any sense?\n\nI was wondering if any of you could give me some insight, advices, or share your experiences with it. I'm sorry for not using too many technical jargon - as I said, I'm exploring data engineering kind of on my own so far.\n\nThank you in advance!", "author_fullname": "t2_vu4ea5ec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I document and/or automate schema changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hgbul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684081047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am the sole data engineer on my department. There are a DA and a soon-to-be DS with me dealing with data regarding a single product from a big company I work for. The rest of the department are developers or product analysts, without much experience with data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve migrated from a junior level software engineering job to data engineering not too long ago, and haven&amp;#39;t had much training or contact with other data professionals. To this day, I&amp;#39;ve been constructing ETLs with the good old pandas that I&amp;#39;ve learnt on my own, deploying it with a scheduling service my company offers to IT people, and that&amp;#39;s about it. I&amp;#39;m still refining my technical abilities.&lt;/p&gt;\n\n&lt;p&gt;Recently, I caught myself thinking about a way to automatically document and change our BigQuery table schemas. Whenever I&amp;#39;m about to release a new ETL, I create the table manually, and I&amp;#39;m kind of fed up of doing this by hand. The problem is I haven&amp;#39;t got a single clue on how I could do this, how people in our area do this, what tools I could use, if there&amp;#39;s even a name/concept/term for what I want to do, and so on.&lt;/p&gt;\n\n&lt;p&gt;My current idea was to create a simple GitHub repo and document schemas (and stored procedures, maybe?) and somehow, implement an automated process to change the schemas directly from there. But it feels a bit &amp;quot;not too professional&amp;quot;, if that makes any sense?&lt;/p&gt;\n\n&lt;p&gt;I was wondering if any of you could give me some insight, advices, or share your experiences with it. I&amp;#39;m sorry for not using too many technical jargon - as I said, I&amp;#39;m exploring data engineering kind of on my own so far.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13hgbul", "is_robot_indexable": true, "report_reasons": null, "author": "AdamantPadThai", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/13hgbul/how_should_i_document_andor_automate_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hgbul/how_should_i_document_andor_automate_schema/", "subreddit_subscribers": 105535, "created_utc": 1684081047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "GCP bigquery recently announced the cdc feature(via stream write API). see [Real-time CDC replication into BigQuery | Google Cloud Blog](https://cloud.google.com/blog/products/data-analytics/real-time-cdc-replication-bigquery)\nMy question is, with this feature, can we view BigQuery as a lakehouse and apply [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) on it?", "author_fullname": "t2_22f1tgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we apply Medallion Architecture on BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hdayd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684073572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GCP bigquery recently announced the cdc feature(via stream write API). see &lt;a href=\"https://cloud.google.com/blog/products/data-analytics/real-time-cdc-replication-bigquery\"&gt;Real-time CDC replication into BigQuery | Google Cloud Blog&lt;/a&gt;\nMy question is, with this feature, can we view BigQuery as a lakehouse and apply &lt;a href=\"https://www.databricks.com/glossary/medallion-architecture\"&gt;Medallion Architecture&lt;/a&gt; on it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?auto=webp&amp;v=enabled&amp;s=2bb423580e49d6864e3715f6654632d558a7d49c", "width": 2500, "height": 1232}, "resolutions": [{"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48579d8f753ce69b5f1b8ae0af753906892694f5", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1386d91cb1dd393b161dbfe57a97c27025c38f1", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c6c56995d10243a604293adda8ea07608cc4e59", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf7551884fe67c86f8908209089a05249b1c74ee", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07368c03b392acb2c54be0f5f3abda104f59aff0", "width": 960, "height": 473}, {"url": "https://external-preview.redd.it/AGcjPNSZNVF2pFc4CUhjCAKemCb21B_K6EBD1q4MueY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d94a8dee7f54cbfd6516eef96347cfa5a61ec285", "width": 1080, "height": 532}], "variants": {}, "id": "wcoegTgls8vDT7sU2cRo3smh6WlMonA1_OjrS3a-3OQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13hdayd", "is_robot_indexable": true, "report_reasons": null, "author": "kk17forever", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hdayd/can_we_apply_medallion_architecture_on_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hdayd/can_we_apply_medallion_architecture_on_bigquery/", "subreddit_subscribers": 105535, "created_utc": 1684073572.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "`select max(modified) from &lt;tablename&gt;` = slow.\n\n- Vendor source system: MySql 5.7.1 (nice and dated, pain). Read-only access.\n\n- Table indexes: id and created column, but not modified\n\nDealing with a table where fetching the latest modified date from the source system takes over a minute. It's a big boi and the modified column doesn't have an index since it can change up to a year after the original record is created &amp; is a column that is frequently updated.\n\nOptions I've exhausted:\n\n- Information schema? Nope, innodb table update date timestamp column is null because this version of MySQL has a bug. Pain, no option to get vendor to upgrade.. literally to 5.7.2 where it's fixed. \n\n- Restricting the lookup for max(modified) by grabbing\n    `select max(modified) \n    from tablename \n    where created &gt; (select datesub(max(created), interval 10 day) from tablename)`\n\nbut then after digging further, found that records can be updated damn near a year after they were originally created\n\n- Fetching checksum of the table, but this was a dumb pathway and obviously slow lol\n\nAny weird tricks you guys might have up your sleeve? I'd love for the vendor to just... update MySQL so I could just go fetch it from information_schema but that currently is not an option. We're pretty much restricted to query methods of CDC here.", "author_fullname": "t2_b6m8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fetching max(modified) date from a big table is slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hqo7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684122779.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684106439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;select max(modified) from &amp;lt;tablename&amp;gt;&lt;/code&gt; = slow.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Vendor source system: MySql 5.7.1 (nice and dated, pain). Read-only access.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Table indexes: id and created column, but not modified&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dealing with a table where fetching the latest modified date from the source system takes over a minute. It&amp;#39;s a big boi and the modified column doesn&amp;#39;t have an index since it can change up to a year after the original record is created &amp;amp; is a column that is frequently updated.&lt;/p&gt;\n\n&lt;p&gt;Options I&amp;#39;ve exhausted:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Information schema? Nope, innodb table update date timestamp column is null because this version of MySQL has a bug. Pain, no option to get vendor to upgrade.. literally to 5.7.2 where it&amp;#39;s fixed. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Restricting the lookup for max(modified) by grabbing\n&lt;code&gt;select max(modified) \nfrom tablename \nwhere created &amp;gt; (select datesub(max(created), interval 10 day) from tablename)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;but then after digging further, found that records can be updated damn near a year after they were originally created&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fetching checksum of the table, but this was a dumb pathway and obviously slow lol&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any weird tricks you guys might have up your sleeve? I&amp;#39;d love for the vendor to just... update MySQL so I could just go fetch it from information_schema but that currently is not an option. We&amp;#39;re pretty much restricted to query methods of CDC here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13hqo7i", "is_robot_indexable": true, "report_reasons": null, "author": "anchoricex", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hqo7i/fetching_maxmodified_date_from_a_big_table_is_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hqo7i/fetching_maxmodified_date_from_a_big_table_is_slow/", "subreddit_subscribers": 105535, "created_utc": 1684106439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r1ahxly5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating Healthcare Data Pipelines using Ascend platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_13h9l5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/729wPsWjklI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Automating Healthcare Data Pipelines with Sarwat Fatima\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Automating Healthcare Data Pipelines with Sarwat Fatima", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/729wPsWjklI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Automating Healthcare Data Pipelines with Sarwat Fatima\"&gt;&lt;/iframe&gt;", "author_name": "Ascend", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/729wPsWjklI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Ascend-io-data"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/729wPsWjklI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Automating Healthcare Data Pipelines with Sarwat Fatima\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/13h9l5n", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1bZOWKF6smtZVzCtLLEuXqnmxTYEcPGA6tRP4055qVI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684063068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/729wPsWjklI", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZKR8c-wtdt6gkNFjx_7XgVreUlMLuMGGXZ6nm3qWuaU.jpg?auto=webp&amp;v=enabled&amp;s=2061757c685072cd2e471ebd5ee542b19a44d753", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ZKR8c-wtdt6gkNFjx_7XgVreUlMLuMGGXZ6nm3qWuaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8dc421295c405a576c024558297abae813eba104", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ZKR8c-wtdt6gkNFjx_7XgVreUlMLuMGGXZ6nm3qWuaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a019fd5164f1e1525ee423807e1cab095763aaa8", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ZKR8c-wtdt6gkNFjx_7XgVreUlMLuMGGXZ6nm3qWuaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cc6864538aacab57df98b25960dce32b27650a7", "width": 320, "height": 240}], "variants": {}, "id": "T2L67Uvg1lkw-OLAA5nu8urIdqMffjIcGgpsCo99cYY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13h9l5n", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Meringue6544", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13h9l5n/automating_healthcare_data_pipelines_using_ascend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/729wPsWjklI", "subreddit_subscribers": 105535, "created_utc": 1684063068.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Automating Healthcare Data Pipelines with Sarwat Fatima", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/729wPsWjklI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Automating Healthcare Data Pipelines with Sarwat Fatima\"&gt;&lt;/iframe&gt;", "author_name": "Ascend", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/729wPsWjklI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Ascend-io-data"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI am currently applying for data engineering jobs and I have been invited for a job interview at 2 companies. One is a scale up company specializing in risk modeling for airlines and the second is a big corporation specializing in the construction business. Two nice companies but totally different corporate structures. \n\nI want to learn as much as possible with respect to data engineering. Which of these two companies should I choose if I pass the interview rounds to realize my ambitions?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scale-up or corporate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hkx7x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684092414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am currently applying for data engineering jobs and I have been invited for a job interview at 2 companies. One is a scale up company specializing in risk modeling for airlines and the second is a big corporation specializing in the construction business. Two nice companies but totally different corporate structures. &lt;/p&gt;\n\n&lt;p&gt;I want to learn as much as possible with respect to data engineering. Which of these two companies should I choose if I pass the interview rounds to realize my ambitions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13hkx7x", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hkx7x/scaleup_or_corporate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hkx7x/scaleup_or_corporate/", "subreddit_subscribers": 105535, "created_utc": 1684092414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "context: i realized that most de jobs are about working in the pipeline using tools like sql,spark,flume,airflow,etc. But usage of these tools hasnt interested me. Should I explore data infrastructure? And before I do ,i want to know what exactly data infra is.", "author_fullname": "t2_am0vw0tw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build vs Use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hfvaz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684079952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;context: i realized that most de jobs are about working in the pipeline using tools like sql,spark,flume,airflow,etc. But usage of these tools hasnt interested me. Should I explore data infrastructure? And before I do ,i want to know what exactly data infra is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13hfvaz", "is_robot_indexable": true, "report_reasons": null, "author": "Nice-Restaurant2454", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hfvaz/build_vs_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hfvaz/build_vs_use/", "subreddit_subscribers": 105535, "created_utc": 1684079952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello engineers,\n\nI work for a start-up style ecommerce company with a large amount of traffic and revenue. We're aiming to become more data-oriented and start taking CRO seriously. Our data is severly lacking - we have issues with our GA properties, often the data we see on analytics is wrong (eg a product will say it has no revenue, when we know on our CRM it does), integrations seem not to work properly, and feels impossible to discern information from. We had someone who was working on it to both fix our broken data issues and build a usable dashboard on Looker studio, but the task seems beyond them. Our company is scaling and we are implementing A/B testing, heatmaps analysis, etc, and simply I'd like to be able to analyse our user activity. It seems like it should be simple, but we've faced roadblock after roadblock!\n\nSo, we are considering starting from fresh. I've been tasked with hiring someone to fix up our Data, and I barely know where to start. I've gathered I need a Data engineer, and that what we are looking for is concerning ETL and big data, but beyond that, I'm lost. Can anyone advise me on what I actually need, and whether it can all be done in GA4? I'm tired of going in circles!\n\nYours,\n\nA confused but determined creative.", "author_fullname": "t2_adgm2h29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please advise this confused marketing manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hc7ti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684071088.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684070779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello engineers,&lt;/p&gt;\n\n&lt;p&gt;I work for a start-up style ecommerce company with a large amount of traffic and revenue. We&amp;#39;re aiming to become more data-oriented and start taking CRO seriously. Our data is severly lacking - we have issues with our GA properties, often the data we see on analytics is wrong (eg a product will say it has no revenue, when we know on our CRM it does), integrations seem not to work properly, and feels impossible to discern information from. We had someone who was working on it to both fix our broken data issues and build a usable dashboard on Looker studio, but the task seems beyond them. Our company is scaling and we are implementing A/B testing, heatmaps analysis, etc, and simply I&amp;#39;d like to be able to analyse our user activity. It seems like it should be simple, but we&amp;#39;ve faced roadblock after roadblock!&lt;/p&gt;\n\n&lt;p&gt;So, we are considering starting from fresh. I&amp;#39;ve been tasked with hiring someone to fix up our Data, and I barely know where to start. I&amp;#39;ve gathered I need a Data engineer, and that what we are looking for is concerning ETL and big data, but beyond that, I&amp;#39;m lost. Can anyone advise me on what I actually need, and whether it can all be done in GA4? I&amp;#39;m tired of going in circles!&lt;/p&gt;\n\n&lt;p&gt;Yours,&lt;/p&gt;\n\n&lt;p&gt;A confused but determined creative.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13hc7ti", "is_robot_indexable": true, "report_reasons": null, "author": "raelelel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hc7ti/please_advise_this_confused_marketing_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hc7ti/please_advise_this_confused_marketing_manager/", "subreddit_subscribers": 105535, "created_utc": 1684070779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a product manager of a corporate data product that reports sales data for multiple drug stores across the US. It usually takes a sprint (2 weeks in our case) to integrate a new pharmacy chain or add new columns/measures or even enable existing columns for newly onboarded chains. Our stack is mostly msft - adf/synapse/aas/pbi + airflow. My team consists of 4 senior DEs (all full FTE) and adding another team members probably won't increase our throughput due to possible admin issues.\n\n**What can I do to automate engineering to get the work done faster?** I was thinking about running a POC to figure out how to employ more parametrization so they don't hardcode everything, doing some sensible defaults when onboarding new pharmacy chains or finding a way to go low code/no code so our support can do most of the easy repetitive work instead of DEs. \n\nI know I'm not providing too much info here and I'm also not the most technical PM but I was hoping some of you went through this journey already and got some tips?", "author_fullname": "t2_9k7spbrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate DE for data products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13hpkiz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684103640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a product manager of a corporate data product that reports sales data for multiple drug stores across the US. It usually takes a sprint (2 weeks in our case) to integrate a new pharmacy chain or add new columns/measures or even enable existing columns for newly onboarded chains. Our stack is mostly msft - adf/synapse/aas/pbi + airflow. My team consists of 4 senior DEs (all full FTE) and adding another team members probably won&amp;#39;t increase our throughput due to possible admin issues.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What can I do to automate engineering to get the work done faster?&lt;/strong&gt; I was thinking about running a POC to figure out how to employ more parametrization so they don&amp;#39;t hardcode everything, doing some sensible defaults when onboarding new pharmacy chains or finding a way to go low code/no code so our support can do most of the easy repetitive work instead of DEs. &lt;/p&gt;\n\n&lt;p&gt;I know I&amp;#39;m not providing too much info here and I&amp;#39;m also not the most technical PM but I was hoping some of you went through this journey already and got some tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13hpkiz", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonWRQ", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13hpkiz/how_to_automate_de_for_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13hpkiz/how_to_automate_de_for_data_products/", "subreddit_subscribers": 105535, "created_utc": 1684103640.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}