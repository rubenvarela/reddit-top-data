{"kind": "Listing", "data": {"after": "t3_13lze97", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Unlimited is back on the menu I guess. They won't ever regret this!", "author_fullname": "t2_8oo0spok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter Blue now allowing 8gb files. Now we will see how quickly an rclone backend is made.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13m7iif", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 2327, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 2327, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5X386JX-OkXKtuV-9hSr3j2_Kb6qxOv9k3fFF3Y4tQQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684529785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unlimited is back on the menu I guess. They won&amp;#39;t ever regret this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/2pd6UQ9.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?auto=webp&amp;v=enabled&amp;s=8b3f7be0e935d8e7217009d2515fbfacd767bf65", "width": 1080, "height": 1350}, "resolutions": [{"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b5cfe672be10c2af204b8fa63fb861909f6de0", "width": 108, "height": 135}, {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d2344376b7f56280912ce5f9377a1fceee7ab3c", "width": 216, "height": 270}, {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0489f7b1daa4f4cb6aae58553bab910811a48367", "width": 320, "height": 400}, {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c69cf1be18442d726a100957e8927a3686cb219f", "width": 640, "height": 800}, {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97bf552a37d4069431e9ff98e88a075565466146", "width": 960, "height": 1200}, {"url": "https://external-preview.redd.it/bKbBpZu30iY_r86jsz4LyUnyh0BhLYzh7OOrqE_eH3U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4fb3b03b4986d655200c1d00206d3b331cc8654", "width": 1080, "height": 1350}], "variants": {}, "id": "4ViPkwFLg9QXAMfYHpFAp6LdHy2sD6XjwkzPgJU4H40"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m7iif", "is_robot_indexable": true, "report_reasons": null, "author": "tamaleconjurer", "discussion_type": null, "num_comments": 192, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m7iif/twitter_blue_now_allowing_8gb_files_now_we_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/2pd6UQ9.jpg", "subreddit_subscribers": 683594, "created_utc": 1684529785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_tlrlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disney to remove dozens of series from Disney+ on May 26th", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13lwuhp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 511, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 511, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9x9vB_01tDatW6AH2D_iGzlpUWi08ghTVEv7i17i96w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684506056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "deadline.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://deadline.com/2023/05/disney-remove-series-streaming-disney-plus-hulu-big-shot-willow-y-dollface-turner-hooch-pistol-1235372512/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?auto=webp&amp;v=enabled&amp;s=8bd3dec33564ba41f489e139bd0dd59ca8068d13", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=849ead53f79c4a2b9e9e29bbcd3f04313d8505f6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f08429d88dba537ac56ef233565f0369e35bcf4f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93f5ff36051c36eeb12968b63c50f9b6c1addac5", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f0bbdb7e2a5a2db61b1e3dfc7e74e6227e4a61c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/qN7hX6w0Qel7k3lRUitz0ePcHVyI4a4-2hS9Ac1rCTk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f51f3ba4ef4c2de3e2d6d21543ef5d1a60282ba", "width": 960, "height": 540}], "variants": {}, "id": "UfbpEpwCeLiC9ncuaD79bAGbBex4hN2nERy3nDyEoXU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13lwuhp", "is_robot_indexable": true, "report_reasons": null, "author": "Loosel", "discussion_type": null, "num_comments": 212, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lwuhp/disney_to_remove_dozens_of_series_from_disney_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://deadline.com/2023/05/disney-remove-series-streaming-disney-plus-hulu-big-shot-willow-y-dollface-turner-hooch-pistol-1235372512/", "subreddit_subscribers": 683594, "created_utc": 1684506056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just wanted to admit my addiction. I just calculated that I have 264TB of drives currently spinning in my 2 NASes. Plus I have two boxes of older drives I'm no longer using but could be. Need to find a home for them.\n\nHello, I'm a data hoarder and I have problem.\n\nHave a nice weekend.", "author_fullname": "t2_60ovyaiwi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Admitted Addict with 264TB of Drives Currently Spinning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m9cak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684534169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just wanted to admit my addiction. I just calculated that I have 264TB of drives currently spinning in my 2 NASes. Plus I have two boxes of older drives I&amp;#39;m no longer using but could be. Need to find a home for them.&lt;/p&gt;\n\n&lt;p&gt;Hello, I&amp;#39;m a data hoarder and I have problem.&lt;/p&gt;\n\n&lt;p&gt;Have a nice weekend.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13m9cak", "is_robot_indexable": true, "report_reasons": null, "author": "TheAndorianWay", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m9cak/admitted_addict_with_264tb_of_drives_currently/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m9cak/admitted_addict_with_264tb_of_drives_currently/", "subreddit_subscribers": 683594, "created_utc": 1684534169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Haven't seen any posts here about it.\n\nIt seams Snap inc aquired them sometime in 2020 and has since fired all the people at Gfycat, which has been left to rot.  \nhttps://finance.yahoo.com/news/meta-fights-overturn-uk-order-171627927.html (NOTE: Giphy is not Gfycat)\n\nIf you have any gifs you like your able to access them without HTTPS for now.\n\nGfycat and Imgur make up a big chunk of gifs on pre v.reddit.", "author_fullname": "t2_he7fl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rip Gfycat, site does not look to be maintained anymore, HTTPS Certificate has now expired.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13mjaw5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684563015.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684561517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Haven&amp;#39;t seen any posts here about it.&lt;/p&gt;\n\n&lt;p&gt;It seams Snap inc aquired them sometime in 2020 and has since fired all the people at Gfycat, which has been left to rot.&lt;br/&gt;\n&lt;a href=\"https://finance.yahoo.com/news/meta-fights-overturn-uk-order-171627927.html\"&gt;https://finance.yahoo.com/news/meta-fights-overturn-uk-order-171627927.html&lt;/a&gt; (NOTE: Giphy is not Gfycat)&lt;/p&gt;\n\n&lt;p&gt;If you have any gifs you like your able to access them without HTTPS for now.&lt;/p&gt;\n\n&lt;p&gt;Gfycat and Imgur make up a big chunk of gifs on pre v.reddit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?auto=webp&amp;v=enabled&amp;s=6317919dbd2e0a2665346930f35883a74f87c6c9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=776e6bb651e151f55735bf74bf7b29f6a994243b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89611055f8bd95fc9933a6ca21c1a5b354454ae4", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96d26f6d6f82082a730049030aa746ddfb9d5718", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ed0773bea228748e67e87f1d93b43c4222fad50", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4d7aa104bfc055dd2dcdc213bcd9fd3d5dc5ea4", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/wqOSlV67UfIbFjA93a8nsIzQL-ZmyVzDsFtjSMbz0ok.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7512c74eabbf4fdc3093003ff6477328148fd8a", "width": 1080, "height": 1080}], "variants": {}, "id": "MdFv645wtpH_zNFT-WTtCInxpB2Q6gHJUVv69F5XDiY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5 x 3.6TiB, Recently started backing up too.", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13mjaw5", "is_robot_indexable": true, "report_reasons": null, "author": "jacksalssome", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13mjaw5/rip_gfycat_site_does_not_look_to_be_maintained/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13mjaw5/rip_gfycat_site_does_not_look_to_be_maintained/", "subreddit_subscribers": 683594, "created_utc": 1684561517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I apologize if this is the wrong place to post this, I've just been trying to find some information on it. I had a script and a downloading software that ripped files off [gofile.io](https://gofile.io), and it worked up until very recently. Now I'm running into problems with their API where using `getContent` will just return an error saying `notPremium`\n\nMy best guesstimation is that they updated their API to not allow guest accounts to use the API or something. Can anyone confirm if this is the case? Or did the API just change?\n\nIn case anyone was wondering, the key `websiteToken`'s value changed, once I updated that all was hunky dory", "author_fullname": "t2_lciwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was gofile.io updated recently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m9zig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684543691.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684535648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize if this is the wrong place to post this, I&amp;#39;ve just been trying to find some information on it. I had a script and a downloading software that ripped files off &lt;a href=\"https://gofile.io\"&gt;gofile.io&lt;/a&gt;, and it worked up until very recently. Now I&amp;#39;m running into problems with their API where using &lt;code&gt;getContent&lt;/code&gt; will just return an error saying &lt;code&gt;notPremium&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;My best guesstimation is that they updated their API to not allow guest accounts to use the API or something. Can anyone confirm if this is the case? Or did the API just change?&lt;/p&gt;\n\n&lt;p&gt;In case anyone was wondering, the key &lt;code&gt;websiteToken&lt;/code&gt;&amp;#39;s value changed, once I updated that all was hunky dory&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/15iKdzMfbU4Xs1YsdGZg8160uEYXMwO5hQgNl-mJFcE.jpg?auto=webp&amp;v=enabled&amp;s=6fd816c982f6bef137109dfdb40de4e2a44d5555", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/15iKdzMfbU4Xs1YsdGZg8160uEYXMwO5hQgNl-mJFcE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ce4c7d85db273a0816c593d7bcc58f62ba995b3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/15iKdzMfbU4Xs1YsdGZg8160uEYXMwO5hQgNl-mJFcE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1bb7a4e61b9ac1a212a147b1c204a9f837aadfa", "width": 216, "height": 216}], "variants": {}, "id": "P72-qNVDQz9IQup33lcHelC7VWeDlP-tmQH36GyvRv8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m9zig", "is_robot_indexable": true, "report_reasons": null, "author": "TheOneScroogeMcDuck", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m9zig/was_gofileio_updated_recently/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m9zig/was_gofileio_updated_recently/", "subreddit_subscribers": 683594, "created_utc": 1684535648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My cousin took her personal laptop at work and the IT guy from her work added an additional sata ssd. Her system was still on during lunch, she went to some other room and voila all her personal data is deleted from the primary m.2 nvme ssd which has the windows OS. She kept all her marriage, first child's photos and videos in a folder on the desktop (yeah big mistake) and there was no backup. One of her colleagues who is supposedly jealous of her did this. Anyways her husband bought recuva software and tried to recover the data. It showed almost all of the file names but most say cannot be recovered. The one's which showed green icon are recovered and most show like half of the photo and just black for the rest.\n\nThe primary m.2 nvme ssd is like 500gb in capacity and almost all of it is empty. I have told them to disconnect it from the internet and not to copy or install anything. They have kept the laptop powered on. They are from a small town and no professional data recovery centers are there. They contacted one center which is in other state but he is asking for $800 usd which will be non refundable in case nothing is recovered. Plus he said that he will need the laptop for atleast 10 days.\n\nIs there any software or any other way through which we can recover some of the data if not all?\n\nHope you guys don't mind me asking, but what are the names of the data recovery softwares used by professionals? Are they sold to retail customers?\n\nWhen these data recovery softwares are run, do they hurt a ssd's health?", "author_fullname": "t2_6zywxuin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need guidance on data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lwg7l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684505224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My cousin took her personal laptop at work and the IT guy from her work added an additional sata ssd. Her system was still on during lunch, she went to some other room and voila all her personal data is deleted from the primary m.2 nvme ssd which has the windows OS. She kept all her marriage, first child&amp;#39;s photos and videos in a folder on the desktop (yeah big mistake) and there was no backup. One of her colleagues who is supposedly jealous of her did this. Anyways her husband bought recuva software and tried to recover the data. It showed almost all of the file names but most say cannot be recovered. The one&amp;#39;s which showed green icon are recovered and most show like half of the photo and just black for the rest.&lt;/p&gt;\n\n&lt;p&gt;The primary m.2 nvme ssd is like 500gb in capacity and almost all of it is empty. I have told them to disconnect it from the internet and not to copy or install anything. They have kept the laptop powered on. They are from a small town and no professional data recovery centers are there. They contacted one center which is in other state but he is asking for $800 usd which will be non refundable in case nothing is recovered. Plus he said that he will need the laptop for atleast 10 days.&lt;/p&gt;\n\n&lt;p&gt;Is there any software or any other way through which we can recover some of the data if not all?&lt;/p&gt;\n\n&lt;p&gt;Hope you guys don&amp;#39;t mind me asking, but what are the names of the data recovery softwares used by professionals? Are they sold to retail customers?&lt;/p&gt;\n\n&lt;p&gt;When these data recovery softwares are run, do they hurt a ssd&amp;#39;s health?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "award_81cf5c92-8500-498c-9c94-3e4034cece0a", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=d480674cac39cfd00fb7f2bcb2dca08bde3ea20a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=26a606f2cd07ae19f81e02351c19ca516c19c156", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=49ac7349e652d9dd96fb12949271de1d88eb4aa7", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=5ccffd26141775968bbac3b8fb7508b3104d5967", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=92d87db9692a365022eb58c15fc727bb44e2b86d", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Staring into the abyss and it's staring right back", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Dread", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=d480674cac39cfd00fb7f2bcb2dca08bde3ea20a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=26a606f2cd07ae19f81e02351c19ca516c19c156", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=49ac7349e652d9dd96fb12949271de1d88eb4aa7", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=5ccffd26141775968bbac3b8fb7508b3104d5967", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=92d87db9692a365022eb58c15fc727bb44e2b86d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/nvfe4gyawnf51_Dread.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13lwg7l", "is_robot_indexable": true, "report_reasons": null, "author": "somuchtolearn007", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lwg7l/need_guidance_on_data_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13lwg7l/need_guidance_on_data_recovery/", "subreddit_subscribers": 683594, "created_utc": 1684505224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_9w1ryk11p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "My two Unmanic instances have been doing a great job keeping some storage free until I build my NAS!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 113, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zcy93u0r1v0b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1e09126383a4de5f2504d7beeed68e57c9656cc"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8e32e1e610d059ff662524cc9d4c5a9e4cc8fa1"}, {"y": 259, "x": 320, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02eabf1ce6d7dcf8b3b287018bbb1cece8a3d320"}, {"y": 518, "x": 640, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfb4cc145227df5cdf5207b50bf506aefd6c644a"}, {"y": 777, "x": 960, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f7a9cf1ba4f68db2b4e42e63b44b912a2f3961e"}, {"y": 874, "x": 1080, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f77c50601927a97777342f9d41ee6b7ec0d13985"}], "s": {"y": 1075, "x": 1327, "u": "https://preview.redd.it/zcy93u0r1v0b1.png?width=1327&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=04bc38e6e84a9417fa2282d924c4b587e6c58ebc"}, "id": "zcy93u0r1v0b1"}, "r89cgdjp1v0b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 86, "x": 108, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2244c7b4d5ad875eed2ee97c9324c59ba5a30cf2"}, {"y": 173, "x": 216, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29924e1d01d51bda019d1507868971e7f2f83039"}, {"y": 257, "x": 320, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cba74d8caef2303b28311f7b4cdb33218f77c6b3"}, {"y": 515, "x": 640, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9444dfe43524bff1c1eb0d871028d7059ac6b540"}, {"y": 772, "x": 960, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0620b093cb0ffccb1cdb3d1cc7aa92d602334873"}, {"y": 869, "x": 1080, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31b7c46045bdee8fe88dd12b0f5a6afc1ece960f"}], "s": {"y": 1070, "x": 1329, "u": "https://preview.redd.it/r89cgdjp1v0b1.png?width=1329&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=074a6029edb3981d9b5f50d7272eec35f71fb079"}, "id": "r89cgdjp1v0b1"}}, "name": "t3_13m93ie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "zcy93u0r1v0b1", "id": 277242289}, {"media_id": "r89cgdjp1v0b1", "id": 277242290}]}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/sjCIlT9PSLQq5uAd4godcEeD2xCHKCoZpmU315GEfhQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684533613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13m93ie", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m93ie", "is_robot_indexable": true, "report_reasons": null, "author": "Dan6erbond2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m93ie/my_two_unmanic_instances_have_been_doing_a_great/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13m93ie", "subreddit_subscribers": 683594, "created_utc": 1684533613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_is1i3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2 brand new drive failures in 1 week -- 18TB drive curse, thank god for ZFS or I'd have lost it all", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13m8gn6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/u2lvLklq7UPr0dhEyQTGEaXjjMo1H71KymFEjqQQUBo.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684532055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wffm6z7ywu0b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wffm6z7ywu0b1.jpg?auto=webp&amp;v=enabled&amp;s=d812ae7706a36d66544f3864f89bc62ffac3776a", "width": 500, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/wffm6z7ywu0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fffeff32f03520563d90f4c96fab451ea6dc8b82", "width": 108, "height": 108}, {"url": "https://preview.redd.it/wffm6z7ywu0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f24c742b1dcaff6eb6a2bdb9d90158912fc17eea", "width": 216, "height": 216}, {"url": "https://preview.redd.it/wffm6z7ywu0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2854dccb3a515ad2bc4c8019ceed0bffba08600", "width": 320, "height": 320}], "variants": {}, "id": "1FXqnH2PEq-UTa9fcOcrccEo2ysMChYsK6w1sNsMa1U"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "114TB ZFS ", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m8gn6", "is_robot_indexable": true, "report_reasons": null, "author": "hex00110", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13m8gn6/2_brand_new_drive_failures_in_1_week_18tb_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wffm6z7ywu0b1.jpg", "subreddit_subscribers": 683594, "created_utc": 1684532055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all!\n\nI wanted to make sure I had a backup of my personal GitHub account with all my repositories, but didn't want to self-host Gitea and set up a script for syncing my account just for the sake of backup.\n\nSo I created a simple program that runs in a container, that will back up all your repositories to a compressed tar file and quickly (multi-processed). I already added it to my nightly backup job :)\n\nYou can pass multiple parameters such as whether you want to include forks you made of other repos, as well as an exclusion list for repos you don't want to back up.\n\nLet me know if you have any feedback!\n\n[https://github.com/orellazri/github-backup/](https://github.com/orellazri/github-backup/)", "author_fullname": "t2_i36uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a tool to back up your GitHub account repos to a compressed archive file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lyp4o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684509905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I wanted to make sure I had a backup of my personal GitHub account with all my repositories, but didn&amp;#39;t want to self-host Gitea and set up a script for syncing my account just for the sake of backup.&lt;/p&gt;\n\n&lt;p&gt;So I created a simple program that runs in a container, that will back up all your repositories to a compressed tar file and quickly (multi-processed). I already added it to my nightly backup job :)&lt;/p&gt;\n\n&lt;p&gt;You can pass multiple parameters such as whether you want to include forks you made of other repos, as well as an exclusion list for repos you don&amp;#39;t want to back up.&lt;/p&gt;\n\n&lt;p&gt;Let me know if you have any feedback!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/orellazri/github-backup/\"&gt;https://github.com/orellazri/github-backup/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?auto=webp&amp;v=enabled&amp;s=8dd7ffc2b26eb6d55853645f98b9b133f1c022b4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6112edbcf2130b527286b0f97aac1111a3ad0ed8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fa5534df2efc48e04a0bca8bcf54df32238ccd6", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cadc4044b13c48b3411bb522566ddbb98cb4399", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b0c41667c6db8b378927549608bb719d5c0cd9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2647be131dd86b2c0da3225ae818823e81b3acb1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/leoe90qxtKS2SGAIP_qhTcOQXIIfYITMYQLfSpB9kPM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32c8b207845249cacdec8578109553d12e4958b7", "width": 1080, "height": 540}], "variants": {}, "id": "em3kyWvOCjQv9d2uqUj51tggATwJRTEwKw2pctaO5Hg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13lyp4o", "is_robot_indexable": true, "report_reasons": null, "author": "Ryiseld", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lyp4o/i_created_a_tool_to_back_up_your_github_account/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13lyp4o/i_created_a_tool_to_back_up_your_github_account/", "subreddit_subscribers": 683594, "created_utc": 1684509905.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been exploiting the unenforced drive limits on Google Drive for the past few years to do cloud backups.  With them cracking down on the limits now I want to just get rid of everything in my drive and look for an alternative.  Problem is, my backup software has uploaded what is probably millions of small files and there doesn't seem to be any quick or easy way to delete all of them.  I've gone into \"Manage Apps\" and removed the backup software and chose the option to delete all associated files but that hasn't changed the amount of data Gdrive is reporting as used.  To clarify, there is nothing in \"My Drive\", it all appears on the Storage tab of the Gdrive web interface.\n\nIs there any quick and easy way to wipe out all that data or am I stuck going through page after page deleting the files one page at a time?", "author_fullname": "t2_aclgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I wipe my Google Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lvu4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684503767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been exploiting the unenforced drive limits on Google Drive for the past few years to do cloud backups.  With them cracking down on the limits now I want to just get rid of everything in my drive and look for an alternative.  Problem is, my backup software has uploaded what is probably millions of small files and there doesn&amp;#39;t seem to be any quick or easy way to delete all of them.  I&amp;#39;ve gone into &amp;quot;Manage Apps&amp;quot; and removed the backup software and chose the option to delete all associated files but that hasn&amp;#39;t changed the amount of data Gdrive is reporting as used.  To clarify, there is nothing in &amp;quot;My Drive&amp;quot;, it all appears on the Storage tab of the Gdrive web interface.&lt;/p&gt;\n\n&lt;p&gt;Is there any quick and easy way to wipe out all that data or am I stuck going through page after page deleting the files one page at a time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13lvu4d", "is_robot_indexable": true, "report_reasons": null, "author": "Davel23", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lvu4d/how_do_i_wipe_my_google_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13lvu4d/how_do_i_wipe_my_google_drive/", "subreddit_subscribers": 683594, "created_utc": 1684503767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi as I was revising for exams this morning I decided to get the book version of a revision guide I had bought in print; after logging in and redeeming the book, I wondered if i could rip the raw jpeg files from the reader on the site; to my suprise all of their assets are pratically in an open directory for example the book I've just ripped [https://resources.pearsonactivelearn.com/r00/r0061/r006175/r00617502/current/OPS/images/GEOG\\_REV\\_GCSE\\_3782-013.jpg](https://resources.pearsonactivelearn.com/r00/r0061/r006175/r00617502/current/OPS/images/GEOG_REV_GCSE_3782-013.jpg)\n\nfrom here it's just a matter of automating an iterative download of each individual page. I wondered would anybody be interested in helping me retrieve all the books from this site our at least provide some advice on how I can scan their directories for the base urls of other books on the site\n\nthanks in advance\n\nnote: cross-post with r/Piracy; thought this community would be more geared towards a greater detailed answer", "author_fullname": "t2_c46yt4ca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scarping ebooks from resources.pearsonactivelearn.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ml5x2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684567835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi as I was revising for exams this morning I decided to get the book version of a revision guide I had bought in print; after logging in and redeeming the book, I wondered if i could rip the raw jpeg files from the reader on the site; to my suprise all of their assets are pratically in an open directory for example the book I&amp;#39;ve just ripped &lt;a href=\"https://resources.pearsonactivelearn.com/r00/r0061/r006175/r00617502/current/OPS/images/GEOG_REV_GCSE_3782-013.jpg\"&gt;https://resources.pearsonactivelearn.com/r00/r0061/r006175/r00617502/current/OPS/images/GEOG_REV_GCSE_3782-013.jpg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;from here it&amp;#39;s just a matter of automating an iterative download of each individual page. I wondered would anybody be interested in helping me retrieve all the books from this site our at least provide some advice on how I can scan their directories for the base urls of other books on the site&lt;/p&gt;\n\n&lt;p&gt;thanks in advance&lt;/p&gt;\n\n&lt;p&gt;note: cross-post with &lt;a href=\"/r/Piracy\"&gt;r/Piracy&lt;/a&gt;; thought this community would be more geared towards a greater detailed answer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?auto=webp&amp;v=enabled&amp;s=ffabc79d0b91fa265aad2f0313fce4922b00f6e9", "width": 1241, "height": 1754}, "resolutions": [{"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22e202a63d7ebe5e4ac9c771d0f139ae5476485c", "width": 108, "height": 152}, {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89a44befca418b3f7b2d6e06a29b64a707f50bd6", "width": 216, "height": 305}, {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=169603e7d72506ba66a34e1a9e28bb6dab4b0be1", "width": 320, "height": 452}, {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbc644a65585ce1c1db79567d688b431465b4178", "width": 640, "height": 904}, {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aee98eff3b7879856a839701499e9db290e1e4f", "width": 960, "height": 1356}, {"url": "https://external-preview.redd.it/A_k9XLSmcfj7pctsfT485YCrGGjE5KuUQC62RDM-nfI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe2aacc00bab9850bed4f0b500a125a9cc484a34", "width": 1080, "height": 1526}], "variants": {}, "id": "Ja6fX4zhfViY7m3tSN9RRTkme5sXt6JFP9bItBTqbXY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ml5x2", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic_Employer443", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13ml5x2/scarping_ebooks_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ml5x2/scarping_ebooks_from/", "subreddit_subscribers": 683594, "created_utc": 1684567835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What is the reasonable sequential read speed for say a 2 platter 4 head 2TB HDD with cache disabled?\n\nBecause the three WD DC HA210 ( HUS722T2TALA604 ) that I am burning-in for new pool behave very weirdly. I see a flat line around 27MB/s throughout entire capacity. No they are not connected via USB, lol. I expected \\~95MB/s falling off approaching the egde of platters, unless it is even lower with only 4 heads.Test bench ATM is Supermicro C236, Win10 Safe boot, Victoria 5.37, API mode.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/m4ms9me98v0b1.jpg?width=1091&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=86affc589bbe9cee69b912e494b2a80a6bbc4cd5", "author_fullname": "t2_5r2am89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strange no cache read speeds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 127, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m4ms9me98v0b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 98, "x": 108, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53fd78587cb0dc62bd55aef3c83ba570ef9e81ed"}, {"y": 196, "x": 216, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66ec12cf86234b756c2acb8e8bbfb2ad327b0058"}, {"y": 290, "x": 320, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21e1246149d8cd30129de90791cfad9e1041084a"}, {"y": 580, "x": 640, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0911c7a1390c20718276692d3b4462d129314a7b"}, {"y": 871, "x": 960, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e606ae48f624139749c4ed82ed6edbb9edd081c"}, {"y": 980, "x": 1080, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6894f1ebbd1b96a6decdaabaddee5c577763675"}], "s": {"y": 990, "x": 1091, "u": "https://preview.redd.it/m4ms9me98v0b1.jpg?width=1091&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=86affc589bbe9cee69b912e494b2a80a6bbc4cd5"}, "id": "m4ms9me98v0b1"}}, "name": "t3_13m9sbp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/DwDpDrMIl18YCJ2OUc6fr1e0CNAsnBQoY-ITQ4fGPr8.jpg", "edited": 1684535900.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684535192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the reasonable sequential read speed for say a 2 platter 4 head 2TB HDD with cache disabled?&lt;/p&gt;\n\n&lt;p&gt;Because the three WD DC HA210 ( HUS722T2TALA604 ) that I am burning-in for new pool behave very weirdly. I see a flat line around 27MB/s throughout entire capacity. No they are not connected via USB, lol. I expected ~95MB/s falling off approaching the egde of platters, unless it is even lower with only 4 heads.Test bench ATM is Supermicro C236, Win10 Safe boot, Victoria 5.37, API mode.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m4ms9me98v0b1.jpg?width=1091&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=86affc589bbe9cee69b912e494b2a80a6bbc4cd5\"&gt;https://preview.redd.it/m4ms9me98v0b1.jpg?width=1091&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=86affc589bbe9cee69b912e494b2a80a6bbc4cd5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m9sbp", "is_robot_indexable": true, "report_reasons": null, "author": "InQuize", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m9sbp/strange_no_cache_read_speeds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m9sbp/strange_no_cache_read_speeds/", "subreddit_subscribers": 683594, "created_utc": 1684535192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m6uvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684528210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13m6uvi", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m6uvi/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/13m6uvi/datahoarder_discussion/", "subreddit_subscribers": 683594, "created_utc": 1684528210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With the recent changes around image hosting websites in general what in your opinion are good self hosted alternatives? \n\nI am basically looking for a piece of software that allows you to upload an image and automatically generates easy to access link to it. I know you can achieve similar functionality with say Nextcloud however sharing images from Nextcloud publicly is hard, Nextcloud wasn\u2019t really built for this. Are there any alternatives that are purposeful built for this? \n\nI have a short domain, good hosting and plenty of storage to build this. However I am unable to find good reviews around specific software for this. \n\nThank you in advance for your input!", "author_fullname": "t2_jijjmnms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ImgBB/imgur self hosted alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13mixkl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684560319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the recent changes around image hosting websites in general what in your opinion are good self hosted alternatives? &lt;/p&gt;\n\n&lt;p&gt;I am basically looking for a piece of software that allows you to upload an image and automatically generates easy to access link to it. I know you can achieve similar functionality with say Nextcloud however sharing images from Nextcloud publicly is hard, Nextcloud wasn\u2019t really built for this. Are there any alternatives that are purposeful built for this? &lt;/p&gt;\n\n&lt;p&gt;I have a short domain, good hosting and plenty of storage to build this. However I am unable to find good reviews around specific software for this. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "100TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13mixkl", "is_robot_indexable": true, "report_reasons": null, "author": "clickbg", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13mixkl/imgbbimgur_self_hosted_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13mixkl/imgbbimgur_self_hosted_alternative/", "subreddit_subscribers": 683594, "created_utc": 1684560319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using a [WD Elements](https://9to5toys.com/wp-content/uploads/sites/5/2013/09/wd-3tb-elements-usb-hd1.jpg?w=655) for the last decade as a backup drive. It's been fantastic, but recently I've run out of space and needed to upgrade. \n\n10 years have passed since I bought it, and some technology has obviously changed, so I was excited to get my Seagate Expansion Desktop in and switch over\u2014but there was one problem.\n\nThe drive was loud. So loud in fact that it was unusable to me.\n\nI looked online and found similar people complaining about the same thing. I even looked at Western Digital drives again and see the same thing happening there too (though I'm not sure how much the relative noise difference is). I've done some reading here and I've noticed this is a problem that comes up a lot, many people complaining about the noise of their drive and the answer just is that's considered normal.\n\nAre all modern-day external drives really loud now, or is it possible that I and all these other people just had bad luck with our drives? To put it into perspective, that old WD Drive is silent when idle and is only heard when it's reading or writing, and even then it's not that bad. That Seagate drive is unbearable in comparison when I'm at the same distance away from it; I think the opening vents in the plastic mould might have something to do with this.\n\nAlso, does anyone have experience using a hard drive enclosure with something like a WD Red? I'm considering that if this new WD Elements I've ordered doesn't act like I'm hoping for as a last resort.", "author_fullname": "t2_bmy0fwife", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have external hard drives become louder in the last decade?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m7zpg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1684530923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using a &lt;a href=\"https://9to5toys.com/wp-content/uploads/sites/5/2013/09/wd-3tb-elements-usb-hd1.jpg?w=655\"&gt;WD Elements&lt;/a&gt; for the last decade as a backup drive. It&amp;#39;s been fantastic, but recently I&amp;#39;ve run out of space and needed to upgrade. &lt;/p&gt;\n\n&lt;p&gt;10 years have passed since I bought it, and some technology has obviously changed, so I was excited to get my Seagate Expansion Desktop in and switch over\u2014but there was one problem.&lt;/p&gt;\n\n&lt;p&gt;The drive was loud. So loud in fact that it was unusable to me.&lt;/p&gt;\n\n&lt;p&gt;I looked online and found similar people complaining about the same thing. I even looked at Western Digital drives again and see the same thing happening there too (though I&amp;#39;m not sure how much the relative noise difference is). I&amp;#39;ve done some reading here and I&amp;#39;ve noticed this is a problem that comes up a lot, many people complaining about the noise of their drive and the answer just is that&amp;#39;s considered normal.&lt;/p&gt;\n\n&lt;p&gt;Are all modern-day external drives really loud now, or is it possible that I and all these other people just had bad luck with our drives? To put it into perspective, that old WD Drive is silent when idle and is only heard when it&amp;#39;s reading or writing, and even then it&amp;#39;s not that bad. That Seagate drive is unbearable in comparison when I&amp;#39;m at the same distance away from it; I think the opening vents in the plastic mould might have something to do with this.&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone have experience using a hard drive enclosure with something like a WD Red? I&amp;#39;m considering that if this new WD Elements I&amp;#39;ve ordered doesn&amp;#39;t act like I&amp;#39;m hoping for as a last resort.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EzQ_h58NsCCD-aHmL7tpLKmrKjYlxBOZmZdt4YgLCeg.jpg?auto=webp&amp;v=enabled&amp;s=d8e4b727a452ec0fa83140f62030d28b95e0e4ac", "width": 655, "height": 513}, "resolutions": [{"url": "https://external-preview.redd.it/EzQ_h58NsCCD-aHmL7tpLKmrKjYlxBOZmZdt4YgLCeg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d16aa23698fefcc41ad547303bdb01eaa2bab1e4", "width": 108, "height": 84}, {"url": "https://external-preview.redd.it/EzQ_h58NsCCD-aHmL7tpLKmrKjYlxBOZmZdt4YgLCeg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4d5062588b630c8e56acf764ba6c84f27cc19fc", "width": 216, "height": 169}, {"url": "https://external-preview.redd.it/EzQ_h58NsCCD-aHmL7tpLKmrKjYlxBOZmZdt4YgLCeg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6755463feaf13cef5a7fc227d5734a660cccf53a", "width": 320, "height": 250}, {"url": "https://external-preview.redd.it/EzQ_h58NsCCD-aHmL7tpLKmrKjYlxBOZmZdt4YgLCeg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e93c3725d42906320a42e72baac6566380b0db0", "width": 640, "height": 501}], "variants": {}, "id": "Xs8H8v-N_828Z3KZPK_7cYEoOFt9giEVmTgHe1r-Qmw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m7zpg", "is_robot_indexable": true, "report_reasons": null, "author": "HomersApe", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m7zpg/have_external_hard_drives_become_louder_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m7zpg/have_external_hard_drives_become_louder_in_the/", "subreddit_subscribers": 683594, "created_utc": 1684530923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_gc8ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any idea where to find the longer drive rails on the left? Older Areca/Proware 64-bay DAS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_13m2usq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/6gAacV9HltJw0nDor6qhm56pyMshykwmgKZsuxcQUr0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1684519103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/d2mxpzweut0b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?auto=webp&amp;v=enabled&amp;s=4cf4f0ed92e20e843ea5474c72ec88f331b6e06e", "width": 3645, "height": 1886}, "resolutions": [{"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0a80e917723f255150efe2503852f5062238f1a", "width": 108, "height": 55}, {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fabaa9b89d78da4d7e95d2f61cf9d1c0871dc2d0", "width": 216, "height": 111}, {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34e2643f068b32824cb52c08d038a5e60a630afc", "width": 320, "height": 165}, {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5b959c884170f9d358c0192db57326b20b7e2d8", "width": 640, "height": 331}, {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ab8dd0ccb6279f67070ba9e808ae0002aaca28e", "width": 960, "height": 496}, {"url": "https://preview.redd.it/d2mxpzweut0b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c5813216b95f7b3543b71c0fa802fcf89425bdc", "width": 1080, "height": 558}], "variants": {}, "id": "FL5239R-BFvS1AR0gk0XNvIuwJfsGBO2JkEvCDKay1E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m2usq", "is_robot_indexable": true, "report_reasons": null, "author": "ripsfo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m2usq/any_idea_where_to_find_the_longer_drive_rails_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/d2mxpzweut0b1.jpg", "subreddit_subscribers": 683594, "created_utc": 1684519103.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI have a DS1821+ with x8 16TB drives plus x2 (mismatched) SSD drives for caching which are a Samsung Evo 970 500GB and a Sandisk WDS500G2B0C 500GB.\n\nIf i upgraded the SSD's for bigger ones and matching ones (1TB or 2TB), will this make any difference in performance?\n\nFor reference, the files on the drive are mainly .mp4 files that are used for video editing direct from the NAS via 10GB ethernet plus some photos that I use direct from NAS again Photoshop etc.\n\nQuite happy with the performance now but just wondered if an SSD drive would make things even better.", "author_fullname": "t2_8zytwi0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bigger SSD cache drives make a difference on big NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ltda4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684497449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have a DS1821+ with x8 16TB drives plus x2 (mismatched) SSD drives for caching which are a Samsung Evo 970 500GB and a Sandisk WDS500G2B0C 500GB.&lt;/p&gt;\n\n&lt;p&gt;If i upgraded the SSD&amp;#39;s for bigger ones and matching ones (1TB or 2TB), will this make any difference in performance?&lt;/p&gt;\n\n&lt;p&gt;For reference, the files on the drive are mainly .mp4 files that are used for video editing direct from the NAS via 10GB ethernet plus some photos that I use direct from NAS again Photoshop etc.&lt;/p&gt;\n\n&lt;p&gt;Quite happy with the performance now but just wondered if an SSD drive would make things even better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ltda4", "is_robot_indexable": true, "report_reasons": null, "author": "Monk_Significant", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ltda4/bigger_ssd_cache_drives_make_a_difference_on_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ltda4/bigger_ssd_cache_drives_make_a_difference_on_big/", "subreddit_subscribers": 683594, "created_utc": 1684497449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Gigabyte b550m k board, I already used the x1 slot for 2.5gb card.  I was looking at HBA cards, but not sure what will fit the PCIe 3 x16 slot or what can be used.  I have 2 x 4tb drives.  The max drives I could see myself having is 6 in there. (2 x 3.5in HDD and 2 x 2.5in SSD)  So I think I would need 6 ports.", "author_fullname": "t2_6x45k53cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCIe 3.0 x4 or x8 HBA card - suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13maz3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684539353.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684538010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Gigabyte b550m k board, I already used the x1 slot for 2.5gb card.  I was looking at HBA cards, but not sure what will fit the PCIe 3 x16 slot or what can be used.  I have 2 x 4tb drives.  The max drives I could see myself having is 6 in there. (2 x 3.5in HDD and 2 x 2.5in SSD)  So I think I would need 6 ports.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13maz3a", "is_robot_indexable": true, "report_reasons": null, "author": "supercamlabs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13maz3a/pcie_30_x4_or_x8_hba_card_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13maz3a/pcie_30_x4_or_x8_hba_card_suggestions/", "subreddit_subscribers": 683594, "created_utc": 1684538010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Apologies if this isn't the right forum, but it is free post Friday sooooo..\n\nTo get to it, I run a specialized archive website of digital historical documents focused specifically on telecommunications. Over the years I've scanned a few hundred thousand pages. However, I've been lucky enough to have access to the large scale scanners with automatic document feeders with ledger (11x17\") sized support at my job.\n\nUnfortunately I was laid off a couple weeks ago and no longer have this access. It's likely that whatever I do next will have much less access to an office that would have a high capacity scanner.\n\nSo I'm thinking about acquiring something for home use. I have literally hundreds of thousands of pages of documents in the long term queue. Specifications would be:\n\n* Supports up to 11x17\" ledger pages\n* Double sided scanning\n* Color, grey scale, and black and white\n* 400 dpi but 600 dpi as an option is preferable\n* Scan to PDF\n* Both automatic document feeder and platen scanning (some documents are close to 100 years old and sheet feeding them is a bad idea)\n* Preferably scan to something like Google Drive but scanning to e-mail is perfectly fine\n\nSearching around, a lot of these things seem to be pretty standard. The big sticking point for me seems to be the ledger sized support. A lot of these documents actually have fold outs that are larger than that, so I sometimes have to merge images, but having to do that with just letter or legal sized images is not fun.\n\nFor price range I'm willing to get into the low thousands. I've come across a few potential options but haven't had much luck finding reliable reviews. So any hands on personal experience that can be shared is valuable. Thanks!", "author_fullname": "t2_5xfq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Free-Post Friday!] Recommendations for high volume document scanners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m5u6i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684525792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this isn&amp;#39;t the right forum, but it is free post Friday sooooo..&lt;/p&gt;\n\n&lt;p&gt;To get to it, I run a specialized archive website of digital historical documents focused specifically on telecommunications. Over the years I&amp;#39;ve scanned a few hundred thousand pages. However, I&amp;#39;ve been lucky enough to have access to the large scale scanners with automatic document feeders with ledger (11x17&amp;quot;) sized support at my job.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately I was laid off a couple weeks ago and no longer have this access. It&amp;#39;s likely that whatever I do next will have much less access to an office that would have a high capacity scanner.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m thinking about acquiring something for home use. I have literally hundreds of thousands of pages of documents in the long term queue. Specifications would be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Supports up to 11x17&amp;quot; ledger pages&lt;/li&gt;\n&lt;li&gt;Double sided scanning&lt;/li&gt;\n&lt;li&gt;Color, grey scale, and black and white&lt;/li&gt;\n&lt;li&gt;400 dpi but 600 dpi as an option is preferable&lt;/li&gt;\n&lt;li&gt;Scan to PDF&lt;/li&gt;\n&lt;li&gt;Both automatic document feeder and platen scanning (some documents are close to 100 years old and sheet feeding them is a bad idea)&lt;/li&gt;\n&lt;li&gt;Preferably scan to something like Google Drive but scanning to e-mail is perfectly fine&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Searching around, a lot of these things seem to be pretty standard. The big sticking point for me seems to be the ledger sized support. A lot of these documents actually have fold outs that are larger than that, so I sometimes have to merge images, but having to do that with just letter or legal sized images is not fun.&lt;/p&gt;\n\n&lt;p&gt;For price range I&amp;#39;m willing to get into the low thousands. I&amp;#39;ve come across a few potential options but haven&amp;#39;t had much luck finding reliable reviews. So any hands on personal experience that can be shared is valuable. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m5u6i", "is_robot_indexable": true, "report_reasons": null, "author": "bg-j38", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m5u6i/freepost_friday_recommendations_for_high_volume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m5u6i/freepost_friday_recommendations_for_high_volume/", "subreddit_subscribers": 683594, "created_utc": 1684525792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bottom text.", "author_fullname": "t2_3ta0ift9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roblox blocks third-party apps these days. Is it still not possible again to rip assets like music and 3D models from Roblox games?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m5o64", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684525398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bottom text.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m5o64", "is_robot_indexable": true, "report_reasons": null, "author": "throwagayaccount93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m5o64/roblox_blocks_thirdparty_apps_these_days_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m5o64/roblox_blocks_thirdparty_apps_these_days_is_it/", "subreddit_subscribers": 683594, "created_utc": 1684525398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How well does WD direct ship these drives?  I've been reading they just throw the electrostatic bag into a big shipping box that can be thrown/move around during shipping?  If I buy the drive in a retail store it comes in a nice secure retail small box/package.  Would love to buy direct because their prices are good, but I don't want to get a drive that has been shaking around loose in a big box.", "author_fullname": "t2_80s831t1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Direct Red Plus - Shipping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lzk2m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684533709.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684511775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How well does WD direct ship these drives?  I&amp;#39;ve been reading they just throw the electrostatic bag into a big shipping box that can be thrown/move around during shipping?  If I buy the drive in a retail store it comes in a nice secure retail small box/package.  Would love to buy direct because their prices are good, but I don&amp;#39;t want to get a drive that has been shaking around loose in a big box.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13lzk2m", "is_robot_indexable": true, "report_reasons": null, "author": "onkyouser777", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lzk2m/wd_direct_red_plus_shipping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13lzk2m/wd_direct_red_plus_shipping/", "subreddit_subscribers": 683594, "created_utc": 1684511775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As title says, I have 4x8TB drives in my NAS right now, and I'm kinda getting full. I considered just swapping out one or two of the drives with larger ones, rebuilding the RAID, but then I'd just have spare 8TB drives laying around.\n\nI think a better option would be for me to just get a new NAS box with more bays and just add more drives that way. I've been kinda wanting to get rid of this NAS anyway since the CPU in it is a bit slow on transcoding videos.\n\nMy main concern is, should I even go with upgrading to a box with more bays or should I just swap out the drives I do have and just keep my current NAS?\n\nSecond concern and probably a really newbie question: What kind of issues might I run into if I do get a new NAS box to put these current drives into, since they are in RAID 5 already? Would a new NAS just see the RAID like normal or do I have to do a particular setup before I take the drives out of the old one? I'm not sure if I'm going to stick with an Asustor brand NAS if I do upgrade the box or if I should go with something else. I'm trying to get the best bang for my buck too so its not like I have unlimited budget.\n\nAny help would be appreciated!", "author_fullname": "t2_iv30x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on upgrading NAS, from Asustor 4-bay with 4x8TB drives in RAID 5", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ls273", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684493680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title says, I have 4x8TB drives in my NAS right now, and I&amp;#39;m kinda getting full. I considered just swapping out one or two of the drives with larger ones, rebuilding the RAID, but then I&amp;#39;d just have spare 8TB drives laying around.&lt;/p&gt;\n\n&lt;p&gt;I think a better option would be for me to just get a new NAS box with more bays and just add more drives that way. I&amp;#39;ve been kinda wanting to get rid of this NAS anyway since the CPU in it is a bit slow on transcoding videos.&lt;/p&gt;\n\n&lt;p&gt;My main concern is, should I even go with upgrading to a box with more bays or should I just swap out the drives I do have and just keep my current NAS?&lt;/p&gt;\n\n&lt;p&gt;Second concern and probably a really newbie question: What kind of issues might I run into if I do get a new NAS box to put these current drives into, since they are in RAID 5 already? Would a new NAS just see the RAID like normal or do I have to do a particular setup before I take the drives out of the old one? I&amp;#39;m not sure if I&amp;#39;m going to stick with an Asustor brand NAS if I do upgrade the box or if I should go with something else. I&amp;#39;m trying to get the best bang for my buck too so its not like I have unlimited budget.&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ls273", "is_robot_indexable": true, "report_reasons": null, "author": "ryohazuki224", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ls273/advice_on_upgrading_nas_from_asustor_4bay_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ls273/advice_on_upgrading_nas_from_asustor_4bay_with/", "subreddit_subscribers": 683594, "created_utc": 1684493680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just installed a new 8TB Western Digital Blue hard drive, CrystalDisk was showing \"Good\", the first try I did was to write a 54GB file to it and so far so good. Then I copied that file from there to another hard drive and in the middle of the copy it stopped. I got a \"cannot read from disk or source file\" warning. Checking CrystalDisk shows yellow \"Caution\" \"Current pending sector count\". Do I keep it or do a return to Amazon?", "author_fullname": "t2_j51tv19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Amazon hard drive shows \"Caution\" on CrystalDisk \"Current pending sector count\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m7fyj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684529609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just installed a new 8TB Western Digital Blue hard drive, CrystalDisk was showing &amp;quot;Good&amp;quot;, the first try I did was to write a 54GB file to it and so far so good. Then I copied that file from there to another hard drive and in the middle of the copy it stopped. I got a &amp;quot;cannot read from disk or source file&amp;quot; warning. Checking CrystalDisk shows yellow &amp;quot;Caution&amp;quot; &amp;quot;Current pending sector count&amp;quot;. Do I keep it or do a return to Amazon?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m7fyj", "is_robot_indexable": true, "report_reasons": null, "author": "Gediman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m7fyj/new_amazon_hard_drive_shows_caution_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m7fyj/new_amazon_hard_drive_shows_caution_on/", "subreddit_subscribers": 683594, "created_utc": 1684529609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 53K Unmapped tracks out of 330K, so I would like to move them out of Lidarr without deleting them. The list shows all the paths, so it's a matter of minutes to make a move script, but I cannot just save/copy/export the entire list, only the visible portion.\n\nI have tried Data Miner and No Coding Data Scraper extensions, but the first doesn't allow to set a mouse scroll page (Lidarr has no Next/Previous page button, only slider) and the second has actually  extracted all the data, but costs a lot to allow export for this single task, and anyway crashes as soon as I click Yes to add credits (if I understand correctly, this would cost me 103$).\n\nAlternatively, is there any expert that can tell me how to extract Unmapped track paths from lidarr.db? I have opened it with DB Browser (SQL Lite), but I have no idea how to use it.\n\n\\[for those unaware, Lidarr is a selfhosted application to automate music albums download\\]\n\nEDIT I have asked already on /lidarr but got no useful answer", "author_fullname": "t2_fv3kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to scrape Lidarr data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13m35l3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1684520306.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684519742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 53K Unmapped tracks out of 330K, so I would like to move them out of Lidarr without deleting them. The list shows all the paths, so it&amp;#39;s a matter of minutes to make a move script, but I cannot just save/copy/export the entire list, only the visible portion.&lt;/p&gt;\n\n&lt;p&gt;I have tried Data Miner and No Coding Data Scraper extensions, but the first doesn&amp;#39;t allow to set a mouse scroll page (Lidarr has no Next/Previous page button, only slider) and the second has actually  extracted all the data, but costs a lot to allow export for this single task, and anyway crashes as soon as I click Yes to add credits (if I understand correctly, this would cost me 103$).&lt;/p&gt;\n\n&lt;p&gt;Alternatively, is there any expert that can tell me how to extract Unmapped track paths from lidarr.db? I have opened it with DB Browser (SQL Lite), but I have no idea how to use it.&lt;/p&gt;\n\n&lt;p&gt;[for those unaware, Lidarr is a selfhosted application to automate music albums download]&lt;/p&gt;\n\n&lt;p&gt;EDIT I have asked already on /lidarr but got no useful answer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13m35l3", "is_robot_indexable": true, "report_reasons": null, "author": "janaxhell", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13m35l3/any_way_to_scrape_lidarr_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13m35l3/any_way_to_scrape_lidarr_data/", "subreddit_subscribers": 683594, "created_utc": 1684519742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased two 2TB 990 Pros for my laptops so I can just hoard all my games rather than redownloading them all the time. I queued up 1.2TB would of downloads for the first drive and it started to download at 140MBps. After about an hour, I noticed the speeds dropped down to 45MBps. And then about an hour after that, down to 25-30MBps. The drive temps as reported by Samsung and HWmonitor64 showed 58c.\n\nI ended the test and ran the Samsung benchmark. after 30seconds the first half finished and the Reads looked normal, but once the writes finished it showed 1400MB/s for the sequential write vs the 6500 it showed when I first connected the drive. \n\nWhen I switch my downloads to the 2nd drive, the same exact thing happened. Everything was good for about an hour and then the same exact results. Now I tried my desktop that has a 1TB 980Pro and queued up 400GB worth of downloads and didn't see this issue. I am not sure if it did just not run long enough but I feel the 990 would have shown the issue already. I am not sure if these 990 Pros may have an issue or what could be going on. Does anyone have any ideas?", "author_fullname": "t2_4dx9vii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Possible 990 Pro issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13lze97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1684511428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased two 2TB 990 Pros for my laptops so I can just hoard all my games rather than redownloading them all the time. I queued up 1.2TB would of downloads for the first drive and it started to download at 140MBps. After about an hour, I noticed the speeds dropped down to 45MBps. And then about an hour after that, down to 25-30MBps. The drive temps as reported by Samsung and HWmonitor64 showed 58c.&lt;/p&gt;\n\n&lt;p&gt;I ended the test and ran the Samsung benchmark. after 30seconds the first half finished and the Reads looked normal, but once the writes finished it showed 1400MB/s for the sequential write vs the 6500 it showed when I first connected the drive. &lt;/p&gt;\n\n&lt;p&gt;When I switch my downloads to the 2nd drive, the same exact thing happened. Everything was good for about an hour and then the same exact results. Now I tried my desktop that has a 1TB 980Pro and queued up 400GB worth of downloads and didn&amp;#39;t see this issue. I am not sure if it did just not run long enough but I feel the 990 would have shown the issue already. I am not sure if these 990 Pros may have an issue or what could be going on. Does anyone have any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13lze97", "is_robot_indexable": true, "report_reasons": null, "author": "PersonSuitTV", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13lze97/possible_990_pro_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13lze97/possible_990_pro_issue/", "subreddit_subscribers": 683594, "created_utc": 1684511428.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}