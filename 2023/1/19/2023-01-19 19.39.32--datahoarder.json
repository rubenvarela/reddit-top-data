{"kind": "Listing", "data": {"after": "t3_10fkkti", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_58xlq9lt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi guys snapped a pic of a small chunk of the archive at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10flhh0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1118, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1118, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uCsghC61rTa3ua7DtVclaeQQNWvcIwix_JmM9jXKy0A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674083518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6hjvojgsdxca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?auto=webp&amp;v=enabled&amp;s=434fd73b09c44036fa55297c242d7460da5051c2", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56dfb7a3db798f3f9a6c8f7aed602119f5fde1f1", "width": 108, "height": 144}, {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb5cfe8bcdae41378fcb645044f6d7c0c450c7b6", "width": 216, "height": 288}, {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac04fb1249df6194e34677ea76919b52098d9c7e", "width": 320, "height": 426}, {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1740f306025cc87984b900ddf5e5234062305751", "width": 640, "height": 853}, {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92660aff9f9136b6b3a4debcc9bd527cabb564b8", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/6hjvojgsdxca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=904321e36aad08114f785187edad1c44a7ba055b", "width": 1080, "height": 1440}], "variants": {}, "id": "z_ItEOqUCpJVcXhv78U40-kIn4ToewLNK_Ssgoi_GSo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10flhh0", "is_robot_indexable": true, "report_reasons": null, "author": "bees422", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10flhh0/hi_guys_snapped_a_pic_of_a_small_chunk_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6hjvojgsdxca1.jpg", "subreddit_subscribers": 666569, "created_utc": 1674083518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_87fk0klp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Finally preparing for a \"time-warp\" from a [2c/2t/4GB RAM/16TB RAW] to a [22c/44t/256GB RAM/256TB RAW/8TB NVME CACHE] (hope HBA will handle that at reasonable speeds). HOME SEEDBOX INCOMING!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tuw5e3ljhwca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9aa6ed03778ed117bb7c070b8715ef5e6095a83"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f62ce2b97ea4ccb86c06cd2eb5d22cba56d2dbb3"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e571b1d0d8b5e15b10591541397df8ddb69d308"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0faeddc87dbbfe54637ce3fe4778efca36a41a93"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18b50478ecf55591e3587e2d95df72d4888504e6"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98aea858b5ad0940e4343247ca88af99088dd5ad"}], "s": {"y": 1536, "x": 2048, "u": "https://preview.redd.it/tuw5e3ljhwca1.png?width=2048&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=05e1a32a4d596921e83fea05a18719e0634662e0"}, "id": "tuw5e3ljhwca1"}, "b72ptvtjhwca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f43a255c16bd7ce60f12ecd383523eef7b91ef5"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5eb8e32ac8ad35fa183516652694e38ca7b9b5f"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8de3d9f64cbbf95c6311bee6b59b52bca1ece241"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=455f8f997193f982280311f5694c8693d7a892d9"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d04eb0fb0ebc851fad0bf251af381bfce0dac2d2"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ccc5b0a5a5cde30a3d9753fa3034385eaafffc1"}], "s": {"y": 2048, "x": 1536, "u": "https://preview.redd.it/b72ptvtjhwca1.png?width=1536&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6478ec959e2ef8584d0fb803e2a05895d53ba7ad"}, "id": "b72ptvtjhwca1"}, "f2gd3zrniwca1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=853568e031178e920d8e9aede29f981e061a43e1"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ea7868ee7275abe886a4c3f166622d7870ce434"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f7c0e7b2778a348ef0464d853d4ae216f0c7f04"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bce3c541169ed8fe4f37b6f1bd0b46ba8c102e36"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a4c6ce748e357590e414c3e3f52c9a00e32956a"}], "s": {"y": 1280, "x": 960, "u": "https://preview.redd.it/f2gd3zrniwca1.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c61e3ae5b2df957a45fa88778285031e465e741e"}, "id": "f2gd3zrniwca1"}}, "name": "t3_10fogue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 41, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "MOBO + CPU + RAM", "media_id": "tuw5e3ljhwca1", "id": 231239208}, {"caption": "With cooling.", "media_id": "f2gd3zrniwca1", "id": 231239209}, {"caption": "BIOS INFO MAXED OUT", "media_id": "b72ptvtjhwca1", "id": 231239210}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SdYrjF6yikCck2lOc6ZCgn5u7HxT0kmcnB-lx--u2uE.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674091173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10fogue", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB RAIDZ2 + SEEDBOX IN PROGRESS", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fogue", "is_robot_indexable": true, "report_reasons": null, "author": "lodufqa", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10fogue/finally_preparing_for_a_timewarp_from_a_2c2t4gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10fogue", "subreddit_subscribers": 666569, "created_utc": 1674091173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7uxqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The 32TB Micron 9400 Pro is a Beast PCIe Gen4 NVMe SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "name": "t3_10fl1jj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/giDkAnHs8-RyQOhT0Lb0yRwd_zMXNsd47MLQe1cxbKg.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674082465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "servethehome.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.servethehome.com/32tb-micron-9400-is-a-beast-pcie-gen4-nvme-ssd/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YYdMFqhx4LErm0DKb5qZakzdHFITcBr4WBULaGPIruY.jpg?auto=webp&amp;v=enabled&amp;s=5ebb314309384a9047b5855a5fb8023a200171ba", "width": 800, "height": 549}, "resolutions": [{"url": "https://external-preview.redd.it/YYdMFqhx4LErm0DKb5qZakzdHFITcBr4WBULaGPIruY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f247159193f2f06e8beefbaed79c1a69d800dfcb", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/YYdMFqhx4LErm0DKb5qZakzdHFITcBr4WBULaGPIruY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be50e4b409357f5a57a8df559d6f974400813efa", "width": 216, "height": 148}, {"url": "https://external-preview.redd.it/YYdMFqhx4LErm0DKb5qZakzdHFITcBr4WBULaGPIruY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12a563f41508f14cbbe0d2749cc84e5633fae698", "width": 320, "height": 219}, {"url": "https://external-preview.redd.it/YYdMFqhx4LErm0DKb5qZakzdHFITcBr4WBULaGPIruY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f00d714beb4815be619aa77e6b35cebc84e3485a", "width": 640, "height": 439}], "variants": {}, "id": "p_RasrzgScaapyiGeGNEdVCnTrP28ThrI2Zr2kNnWPU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "11 TB + Cloud", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fl1jj", "is_robot_indexable": true, "report_reasons": null, "author": "N19h7m4r3", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10fl1jj/the_32tb_micron_9400_pro_is_a_beast_pcie_gen4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.servethehome.com/32tb-micron-9400-is-a-beast-pcie-gen4-nvme-ssd/", "subreddit_subscribers": 666569, "created_utc": 1674082465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few people who are looking to assist me with my media data hoarding. What I'm looking for is either something simple I can setup on my linux server or maybe another online service that would make it easy for people to dump files into that I can retrieve later. Files are going to be bigger than can easily be emailed back and forth. \n\nIn the old days, I would have setup an anonymous FTP server but I'm not sure if that is consider secure enough anymore. Any ideas of what I could use?", "author_fullname": "t2_441hr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for ideas of how people can share files with me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g0k6o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674131530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few people who are looking to assist me with my media data hoarding. What I&amp;#39;m looking for is either something simple I can setup on my linux server or maybe another online service that would make it easy for people to dump files into that I can retrieve later. Files are going to be bigger than can easily be emailed back and forth. &lt;/p&gt;\n\n&lt;p&gt;In the old days, I would have setup an anonymous FTP server but I&amp;#39;m not sure if that is consider secure enough anymore. Any ideas of what I could use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10g0k6o", "is_robot_indexable": true, "report_reasons": null, "author": "jmricker", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10g0k6o/looking_for_ideas_of_how_people_can_share_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10g0k6o/looking_for_ideas_of_how_people_can_share_files/", "subreddit_subscribers": 666569, "created_utc": 1674131530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title.", "author_fullname": "t2_cbhs4xvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you download the US Census? Since it's a government thing, doesn't it have to be freely available to the public? I also heard that you could look up census records, but I could not find a download link. Any help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fvid5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674112790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "enterprisegoogledriveunlimited(i work at a school)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fvid5", "is_robot_indexable": true, "report_reasons": null, "author": "GoryRamsy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10fvid5/can_you_download_the_us_census_since_its_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fvid5/can_you_download_the_us_census_since_its_a/", "subreddit_subscribers": 666569, "created_utc": 1674112790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I read somewhere that this belief was proved to be false in recent studies. But is it?", "author_fullname": "t2_s4dgpy65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do SSD drives really lose data if left unpowered for too long?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fn86x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674087887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read somewhere that this belief was proved to be false in recent studies. But is it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fn86x", "is_robot_indexable": true, "report_reasons": null, "author": "Mundane_Practice1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fn86x/do_ssd_drives_really_lose_data_if_left_unpowered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fn86x/do_ssd_drives_really_lose_data_if_left_unpowered/", "subreddit_subscribers": 666569, "created_utc": 1674087887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the UK, and looking at WD's site and comparing red plus, pro, gold and ultrastar, the absolute best price/TB is around \u00a323/TB. \n\nWD prices on Amazon are as bad or worse. Seagate exos are solid/TB but I've heard they're as loud as it gets.\n\nI did want a nice 5 year warranty so I could have any dead drives replaced easily, but when the 20TB WD elements/easystore are on offer for \u00a314.50/TB, is it ever actually worth not shucking?", "author_fullname": "t2_1gpxw7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucking Vs Warranty.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fhrps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674073711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the UK, and looking at WD&amp;#39;s site and comparing red plus, pro, gold and ultrastar, the absolute best price/TB is around \u00a323/TB. &lt;/p&gt;\n\n&lt;p&gt;WD prices on Amazon are as bad or worse. Seagate exos are solid/TB but I&amp;#39;ve heard they&amp;#39;re as loud as it gets.&lt;/p&gt;\n\n&lt;p&gt;I did want a nice 5 year warranty so I could have any dead drives replaced easily, but when the 20TB WD elements/easystore are on offer for \u00a314.50/TB, is it ever actually worth not shucking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fhrps", "is_robot_indexable": true, "report_reasons": null, "author": "Plebius-Maximus", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fhrps/shucking_vs_warranty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fhrps/shucking_vs_warranty/", "subreddit_subscribers": 666569, "created_utc": 1674073711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vh1y5ccs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to get DVDShrink (or dvd to iso equivalent) to only analyze the first XX% of the disc? There are so many DVDs I have that I want to rip, but the last few segments (often just special features) prevent me from doing so.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10fhcft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mfNPzruYe4eVic0qTIyvjYie-BRRwVumoJsoxSf85Lo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674072689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/f01pgbqlhwca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/f01pgbqlhwca1.jpg?auto=webp&amp;v=enabled&amp;s=646417ddab1f098509539e67e25591937b993edf", "width": 750, "height": 1334}, "resolutions": [{"url": "https://preview.redd.it/f01pgbqlhwca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac8ff2e081180267fc633404e4b97c842f2ab20d", "width": 108, "height": 192}, {"url": "https://preview.redd.it/f01pgbqlhwca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c0e4cae25580fb783113c318bc5b48c8aedc7de", "width": 216, "height": 384}, {"url": "https://preview.redd.it/f01pgbqlhwca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65837b8301ed7df04c651e82781583ec3e64c46d", "width": 320, "height": 569}, {"url": "https://preview.redd.it/f01pgbqlhwca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb14406d585924726e07acc8a24bbb0b727510fc", "width": 640, "height": 1138}], "variants": {}, "id": "_JzGiZn7aPBiisEtnGolJ5CO5wL27CA44a3I58zlhik"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fhcft", "is_robot_indexable": true, "report_reasons": null, "author": "RaccoonEyesPapi", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fhcft/is_there_a_way_to_get_dvdshrink_or_dvd_to_iso/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/f01pgbqlhwca1.jpg", "subreddit_subscribers": 666569, "created_utc": 1674072689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, with Enjin announcing their shutdown, I've become very keen on creating an offline archive of a forum I ran with some friends for about 8 years.  It's a Tapatalk forum, so it's thankfully not going anywhere (for now), but there are a ton of fond memories in there I'd hate to lose.  I don't really know much about data archiving, so can anyone point me to a good place to start for a project like this?", "author_fullname": "t2_jgno0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Total Forum Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10g939c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674152711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, with Enjin announcing their shutdown, I&amp;#39;ve become very keen on creating an offline archive of a forum I ran with some friends for about 8 years.  It&amp;#39;s a Tapatalk forum, so it&amp;#39;s thankfully not going anywhere (for now), but there are a ton of fond memories in there I&amp;#39;d hate to lose.  I don&amp;#39;t really know much about data archiving, so can anyone point me to a good place to start for a project like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10g939c", "is_robot_indexable": true, "report_reasons": null, "author": "itsshenanigans", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10g939c/total_forum_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10g939c/total_forum_archive/", "subreddit_subscribers": 666569, "created_utc": 1674152711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nFirst time writing here so bear with me.\n\nI have a site with some videos, and I scraped all the links for videos I want to download. Now I have collection of 400 direct links, something like that.\n\nWhat would be the best way to download all the videos ? Python script or is there some easier way, also I wouldn't like for the site owner to notice I'm downloading/scraping stuff, so that's also a factor. \n\nThank you", "author_fullname": "t2_t6oxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy method for mass video downloading", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fzbyc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674127549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;First time writing here so bear with me.&lt;/p&gt;\n\n&lt;p&gt;I have a site with some videos, and I scraped all the links for videos I want to download. Now I have collection of 400 direct links, something like that.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to download all the videos ? Python script or is there some easier way, also I wouldn&amp;#39;t like for the site owner to notice I&amp;#39;m downloading/scraping stuff, so that&amp;#39;s also a factor. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fzbyc", "is_robot_indexable": true, "report_reasons": null, "author": "murdafeelin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fzbyc/easy_method_for_mass_video_downloading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fzbyc/easy_method_for_mass_video_downloading/", "subreddit_subscribers": 666569, "created_utc": 1674127549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do you guys deal with a show where every source has a different episode/season order? For example, Plex screwed up the episode order of *Dirty Jobs* even though Sonarr named and organized the episodes \"correctly\" , or at least the episode titles match the contents of the show. Both IMDB and The TVDB show that it has 10 seasons, but TMDB shows that it has 11 seasons.\n\nSonarr uses the TVDB to name the files, but after checking my Plex config it uses *Plex TV Series* to get the metadata. This has led to a mess of confusion and out of order episodes. Especially with a show with a lot of episodes like Dirty Jobs. It has also completely borked MythBusters, which has always been a nightmare. \n\nFrom what I can see on the TVDB, it doesn't look like their default ordering is correct. Their *Aired Order* shows that S01 only has 6 episodes, but S02 has 45 episodes. S01E01 aired on 7/26/05 and S01 ended on 8/30/05 but S02E01 airs on 9/27/05 and continues with weekly episodes until S02E16 which aired on 1/31/06. It picks back up with S02E17 on 3/7/06, airs two more weekly episodes, with S02E19 being the last in 3/21/06. It then takes a long break until 6/13/06 which is when S02E20 aired. It then continues with (almost) weekly episodes until S02E45 which aired on 3/20/07. I would think that everything up until S02E19 would part of Season 1 and the three month break is the normal wait time for a new season, which would mean that S02E20 would actually be S02E01. The TVDB also has an \"Alternate Order\" for the show, which has a completely different S01 than the above, even a different pilot episode. In this Alternate Order S01 has 34 episodes and ends on 9/5/06\n\nTMDB seems to have the same episode order as The TVDB, but they disagree on what season those episodes are part of. TMDB says that S01 has 13 episodes, beginning on 7/26/05 and at S01E06 which aired on 8/30/05 it breaks for a month until S01E07 airs on 9/27/05. It then continues weekly until S01E13 airs on 11/8/05.\n\nI just looked up *List of Dirty Jobs Episodes* on Wikipedia and that agrees with The TVDB, stating that S01 only has 6 episodes. It also says the show has *three* pilot episodes and that Season 2 starts a month after Season 1 ends, which is odd. \n\nIMDB agrees with TMDB, mostly, but it puts the specials in there as they aired, and not in Season 0 like TMDB does (The TVDB only has the pilots in there as e19, 20, and 21) , so they're out of sync at the end of S01 because three specials aired, so IMDB says that S01 ends with E16 on 12/27/05\n\nAs you can see, this leads to a gigantic clusterfuck of me not knowing where to go from here since no list agrees with the other exactly. I'm tempted to just change the Plex agent to The TVDB and be done with it, but I do want things to be in the correct order.", "author_fullname": "t2_4td6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to organize a show when every source (IMDB, TMDB, TVDB) has a different order?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmom7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674086508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you guys deal with a show where every source has a different episode/season order? For example, Plex screwed up the episode order of &lt;em&gt;Dirty Jobs&lt;/em&gt; even though Sonarr named and organized the episodes &amp;quot;correctly&amp;quot; , or at least the episode titles match the contents of the show. Both IMDB and The TVDB show that it has 10 seasons, but TMDB shows that it has 11 seasons.&lt;/p&gt;\n\n&lt;p&gt;Sonarr uses the TVDB to name the files, but after checking my Plex config it uses &lt;em&gt;Plex TV Series&lt;/em&gt; to get the metadata. This has led to a mess of confusion and out of order episodes. Especially with a show with a lot of episodes like Dirty Jobs. It has also completely borked MythBusters, which has always been a nightmare. &lt;/p&gt;\n\n&lt;p&gt;From what I can see on the TVDB, it doesn&amp;#39;t look like their default ordering is correct. Their &lt;em&gt;Aired Order&lt;/em&gt; shows that S01 only has 6 episodes, but S02 has 45 episodes. S01E01 aired on 7/26/05 and S01 ended on 8/30/05 but S02E01 airs on 9/27/05 and continues with weekly episodes until S02E16 which aired on 1/31/06. It picks back up with S02E17 on 3/7/06, airs two more weekly episodes, with S02E19 being the last in 3/21/06. It then takes a long break until 6/13/06 which is when S02E20 aired. It then continues with (almost) weekly episodes until S02E45 which aired on 3/20/07. I would think that everything up until S02E19 would part of Season 1 and the three month break is the normal wait time for a new season, which would mean that S02E20 would actually be S02E01. The TVDB also has an &amp;quot;Alternate Order&amp;quot; for the show, which has a completely different S01 than the above, even a different pilot episode. In this Alternate Order S01 has 34 episodes and ends on 9/5/06&lt;/p&gt;\n\n&lt;p&gt;TMDB seems to have the same episode order as The TVDB, but they disagree on what season those episodes are part of. TMDB says that S01 has 13 episodes, beginning on 7/26/05 and at S01E06 which aired on 8/30/05 it breaks for a month until S01E07 airs on 9/27/05. It then continues weekly until S01E13 airs on 11/8/05.&lt;/p&gt;\n\n&lt;p&gt;I just looked up &lt;em&gt;List of Dirty Jobs Episodes&lt;/em&gt; on Wikipedia and that agrees with The TVDB, stating that S01 only has 6 episodes. It also says the show has &lt;em&gt;three&lt;/em&gt; pilot episodes and that Season 2 starts a month after Season 1 ends, which is odd. &lt;/p&gt;\n\n&lt;p&gt;IMDB agrees with TMDB, mostly, but it puts the specials in there as they aired, and not in Season 0 like TMDB does (The TVDB only has the pilots in there as e19, 20, and 21) , so they&amp;#39;re out of sync at the end of S01 because three specials aired, so IMDB says that S01 ends with E16 on 12/27/05&lt;/p&gt;\n\n&lt;p&gt;As you can see, this leads to a gigantic clusterfuck of me not knowing where to go from here since no list agrees with the other exactly. I&amp;#39;m tempted to just change the Plex agent to The TVDB and be done with it, but I do want things to be in the correct order.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "92TB RAIDZ2 + 16.4TB RAIDZ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fmom7", "is_robot_indexable": true, "report_reasons": null, "author": "brando56894", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10fmom7/how_to_organize_a_show_when_every_source_imdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fmom7/how_to_organize_a_show_when_every_source_imdb/", "subreddit_subscribers": 666569, "created_utc": 1674086508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was trying to transfer a video file in Windows via cut and paste, had a system hang, and the process was interrupted. I now have what seems to be two parts of the file in the source and destination directories; both files have the same size, but none of them are really fully usable. I'm assuming it's because it was a cut and paste operation so I have part of the video in the original directory and the other part of the video in the destination directory.\n\nI think I'll probably be more cautious and use copy+paste instead from now on... but is there any way I can salvage this file, or am I SOL?", "author_fullname": "t2_ldqp9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there anything I can do about an interrupted cut and paste?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fg018", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674069516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to transfer a video file in Windows via cut and paste, had a system hang, and the process was interrupted. I now have what seems to be two parts of the file in the source and destination directories; both files have the same size, but none of them are really fully usable. I&amp;#39;m assuming it&amp;#39;s because it was a cut and paste operation so I have part of the video in the original directory and the other part of the video in the destination directory.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;ll probably be more cautious and use copy+paste instead from now on... but is there any way I can salvage this file, or am I SOL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fg018", "is_robot_indexable": true, "report_reasons": null, "author": "BrawlerAce", "discussion_type": null, "num_comments": 18, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fg018/is_there_anything_i_can_do_about_an_interrupted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fg018/is_there_anything_i_can_do_about_an_interrupted/", "subreddit_subscribers": 666569, "created_utc": 1674069516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's the opinion on the new LTO-9 tape format. If you were considering using tape for cold archival storage of 300+ TB, would you trust the new LTO-9 or stick with the established LTO-8? Sometimes newer means flakey, and older means \"all the bugs are worked out\". So, fancy new vs old reliable... Opinions?", "author_fullname": "t2_9b5e9ok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO 8 or 9?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g4cco", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674141692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the opinion on the new LTO-9 tape format. If you were considering using tape for cold archival storage of 300+ TB, would you trust the new LTO-9 or stick with the established LTO-8? Sometimes newer means flakey, and older means &amp;quot;all the bugs are worked out&amp;quot;. So, fancy new vs old reliable... Opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10g4cco", "is_robot_indexable": true, "report_reasons": null, "author": "ProjectBlu", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10g4cco/lto_8_or_9/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10g4cco/lto_8_or_9/", "subreddit_subscribers": 666569, "created_utc": 1674141692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just purchased a Dell MD1200 and after reading all of the next information online I'm somewhat concerned about drive compatibility. I will be connecting it to my current server which is a Dell R720 with a Perc H730 and a SAS expander with external ports. I plan on filling it up with 14TB SAS 3 drives, probably mixed brands\n\nI've heard from some poeple that the MD1200 only works with dells drives while others claim they have no issue or they drives work fine and they just get a warning because the drives certified but they continue to work fine.\nI've also seen some people state that there is a 2TB limit as well but from what I've read that's a limitation of the RAID card not the MD1200.\n\nSo is there anyone here with an MD1200 that has tested it with 3rd party 10TB+ SAS drives?", "author_fullname": "t2_ymehjtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dell PowerVault MD1200 Drive Compatibility?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fv9gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674111853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just purchased a Dell MD1200 and after reading all of the next information online I&amp;#39;m somewhat concerned about drive compatibility. I will be connecting it to my current server which is a Dell R720 with a Perc H730 and a SAS expander with external ports. I plan on filling it up with 14TB SAS 3 drives, probably mixed brands&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard from some poeple that the MD1200 only works with dells drives while others claim they have no issue or they drives work fine and they just get a warning because the drives certified but they continue to work fine.\nI&amp;#39;ve also seen some people state that there is a 2TB limit as well but from what I&amp;#39;ve read that&amp;#39;s a limitation of the RAID card not the MD1200.&lt;/p&gt;\n\n&lt;p&gt;So is there anyone here with an MD1200 that has tested it with 3rd party 10TB+ SAS drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fv9gj", "is_robot_indexable": true, "report_reasons": null, "author": "DeanbonianTheGreat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fv9gj/dell_powervault_md1200_drive_compatibility/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fv9gj/dell_powervault_md1200_drive_compatibility/", "subreddit_subscribers": 666569, "created_utc": 1674111853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\n\nmy use cases will be mass storage for my 3D stuff, photos backup and Jellyfin media server. Im planning to get a Synology 920+\n\n\u00a0\n\nI plan to get 4 4TB hard drives. Or will 2 TB do?\n\n\u00a0\n\nMy Media Server wont be huge but i have no idea how a normal 100-200 movie+tv show media storage takes on size?\n\n\u00a0\n\nanyway, my PC runs for like 16 hours a day so the NAS will be on for that long.  What drives should i get, Normal or special NAS drives. And which brand?", "author_fullname": "t2_sweiham8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Normal or NAS drives for Home NAS/Media server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ftgjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674105798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my use cases will be mass storage for my 3D stuff, photos backup and Jellyfin media server. Im planning to get a Synology 920+&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;I plan to get 4 4TB hard drives. Or will 2 TB do?&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;My Media Server wont be huge but i have no idea how a normal 100-200 movie+tv show media storage takes on size?&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;anyway, my PC runs for like 16 hours a day so the NAS will be on for that long.  What drives should i get, Normal or special NAS drives. And which brand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ftgjq", "is_robot_indexable": true, "report_reasons": null, "author": "SamiUso", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ftgjq/normal_or_nas_drives_for_home_nasmedia_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ftgjq/normal_or_nas_drives_for_home_nasmedia_server/", "subreddit_subscribers": 666569, "created_utc": 1674105798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking a them for file storage and also seems there's some good stuff on there, but they don't take pre-paid credit cards. Usually, companies that don't take pre-paid cards do so because they want to make it difficult if not impossible to cancel, and a lot of the reviews about Rapid Gator support that.", "author_fullname": "t2_d920v2p4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have an experiece with Rapidgator?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fo1vs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674090070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking a them for file storage and also seems there&amp;#39;s some good stuff on there, but they don&amp;#39;t take pre-paid credit cards. Usually, companies that don&amp;#39;t take pre-paid cards do so because they want to make it difficult if not impossible to cancel, and a lot of the reviews about Rapid Gator support that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10fo1vs", "is_robot_indexable": true, "report_reasons": null, "author": "TheFlyingDonuts", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fo1vs/anyone_have_an_experiece_with_rapidgator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fo1vs/anyone_have_an_experiece_with_rapidgator/", "subreddit_subscribers": 666569, "created_utc": 1674090070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This year is the aluminum anniversary (10 years) of my Synology DS1813+. It\u2019s an amazing unit and still going strong. Just curious if I should budget for upgrading to a newer one soon or follow the mantra of \u201cif it ain\u2019t broke, don\u2019t fix it\u201d?", "author_fullname": "t2_6n134", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 year old Synology OK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fnzhm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674089918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This year is the aluminum anniversary (10 years) of my Synology DS1813+. It\u2019s an amazing unit and still going strong. Just curious if I should budget for upgrading to a newer one soon or follow the mantra of \u201cif it ain\u2019t broke, don\u2019t fix it\u201d?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fnzhm", "is_robot_indexable": true, "report_reasons": null, "author": "I_Am_Rook", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fnzhm/10_year_old_synology_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fnzhm/10_year_old_synology_ok/", "subreddit_subscribers": 666569, "created_utc": 1674089918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Last night my 18tb Seagate Exos starting making a noise as seen in the video: https://streamable.com/0l5ggb\n\nThe drive only makes that noise when the drive is at 0 percent usage and not being accessed As soon as I access the drive the sound goes away. I am not very experienced with troubleshooting harddrives, but if the drive is failing I would like to RMA asap since I have only had the drive  for 1 year.\n\nSMART report: https://smartreport.tiiny.site/\n\nIs the drive failing? Is there anything I can do to further test or stop the device from making this noise?", "author_fullname": "t2_1kd2d3y7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience with the Seagate Exos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ffsos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674069033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last night my 18tb Seagate Exos starting making a noise as seen in the video: &lt;a href=\"https://streamable.com/0l5ggb\"&gt;https://streamable.com/0l5ggb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The drive only makes that noise when the drive is at 0 percent usage and not being accessed As soon as I access the drive the sound goes away. I am not very experienced with troubleshooting harddrives, but if the drive is failing I would like to RMA asap since I have only had the drive  for 1 year.&lt;/p&gt;\n\n&lt;p&gt;SMART report: &lt;a href=\"https://smartreport.tiiny.site/\"&gt;https://smartreport.tiiny.site/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is the drive failing? Is there anything I can do to further test or stop the device from making this noise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?auto=webp&amp;v=enabled&amp;s=41ae4dbd2e29b68569e323b168366d21c74369a6", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5b70194b72e3b7a6bd0b11cd5f7dcfd9f18f613", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c354c91453fe9f2499142b85836a006c9668f1e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a5b04bac3c680b1088f251899c680f770a8357d", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=335126b1f5bdcf166940f636a02373c4efa25838", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97d589a8447a97872ddd32f1a89fb2b0f5d011ec", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/UOpVMxxHcFuhdxb0DkRpb0V20yOdpITZmEEQ9-3QE_0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec99a84f4f17635d9dd1ea77767aa9eb43cd9e6c", "width": 1080, "height": 607}], "variants": {}, "id": "KJ3E6F5Y2PtA_BClAxzxLb0ayUtRWFzFuqbHBpriJJo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ffsos", "is_robot_indexable": true, "report_reasons": null, "author": "swpstkr_", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ffsos/any_experience_with_the_seagate_exos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ffsos/any_experience_with_the_seagate_exos/", "subreddit_subscribers": 666569, "created_utc": 1674069033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks,\n\nI work at an AD/PR agency and am looking to export as many contacts from one of our (paid subscription - allows unlimited exports) data providers.\n\nWe use two different data providers (Muckrack and Meltwater) and my boss wants to save a complete set of backup data contacts for 2023.\n\nDoes anyone have advice on the fastest/simplest way to export the information?\n\nThanks!", "author_fullname": "t2_e49mluc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "250k+ contacts for export", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10g9fvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674153479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I work at an AD/PR agency and am looking to export as many contacts from one of our (paid subscription - allows unlimited exports) data providers.&lt;/p&gt;\n\n&lt;p&gt;We use two different data providers (Muckrack and Meltwater) and my boss wants to save a complete set of backup data contacts for 2023.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have advice on the fastest/simplest way to export the information?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10g9fvw", "is_robot_indexable": true, "report_reasons": null, "author": "reddit4ever12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10g9fvw/250k_contacts_for_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10g9fvw/250k_contacts_for_export/", "subreddit_subscribers": 666569, "created_utc": 1674153479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not entirely sure if this is the correct subreddit and this may well get deleted, but I read the rules and I shall try my luck here. So in March of 2005 there was a flash game called \"Nevashut\" and it was created to market pringles. The game's goal was to convince the store clerk (Sanjeev) to give you 5 cans of pringles. You did this by typing in things and he would react accordingly. Anyway this game has basically been wiped off the internet, with no way of playing it. Things such as the swf and xml files are archived, but not the in game videos (flv); which were crucial to play the game. I have contacted everyone credited but to no avail. So my question is if anybody has information on this game? Anything helps.", "author_fullname": "t2_bwgh29ti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old Flash Game - Not available at all on the internet. Hoping someone has some information on it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g613t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674145695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not entirely sure if this is the correct subreddit and this may well get deleted, but I read the rules and I shall try my luck here. So in March of 2005 there was a flash game called &amp;quot;Nevashut&amp;quot; and it was created to market pringles. The game&amp;#39;s goal was to convince the store clerk (Sanjeev) to give you 5 cans of pringles. You did this by typing in things and he would react accordingly. Anyway this game has basically been wiped off the internet, with no way of playing it. Things such as the swf and xml files are archived, but not the in game videos (flv); which were crucial to play the game. I have contacted everyone credited but to no avail. So my question is if anybody has information on this game? Anything helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10g613t", "is_robot_indexable": true, "report_reasons": null, "author": "NoBicycle7726", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10g613t/old_flash_game_not_available_at_all_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10g613t/old_flash_game_not_available_at_all_on_the/", "subreddit_subscribers": 666569, "created_utc": 1674145695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two drobo systems totalling about 32TB. I'll be upgrading them soon, but in the meantime about 1.5TB of that is the really crucial stuff that I would like to have cloud storage and syncing for.\n\nThe files are held on said Drobo's, which are older USB, no- network versions and are attached to my big desktop PC in the house. This has the full collection of this set of files, all categorised into folders, which is shared to cloud storage.\n\nI then have a collection of laptops for various purposes (Job 1, Job 1 backup, Job 2, one to use around the house, etc etc) and these sync with specific folders from this cloud storage. Some have the majority of the collection because they\u2019re used for a wide range of things, some only very specific folders because that\u2019s all they\u2019re used for.\n\nI\u2019ve messed about with a few different providers: wasabi back in the very early days, one drive and dropbox mostly because people sometimes share files with me through these, but for the vast majority of the time I used google drive to sync and share all of this. It provided the cloud storage and linked everything together so wherever changes were made, they then migrated out to all of the other systems. While it had a few issues here and there, mostly it worked fine\u2026.until they revamped it all a year or two ago and made it work with a virtual drive system, breaking some of the software I used.\n\nAfter searching through alternatives I decided to give Mega a go, which I\u2019ve run for the past year or so. About 6 months ago I noticed that some audio files were missing from my player, and after searching discovered the sync client had decided to randomly delete a pile of files. Turns out that it had been deleting very occasional files here and there for a while, but I only noticed because it deleted a particularly big batch on this occasion which became obvious. I recovered them from the trash and backed them all up, and thought I understood why this had happened so I decided to stick with it and proceed with caution.\n\nHowever I\u2019ve just discovered last night it deleted another huge batch of files, 47GB this time, including a handful of folders with some important work documents in them. I was again able to recover them thankfully (they\u2019d have been gone for good if I hadn\u2019t noticed for 30 days) but even so I\u2019ve lost the directory structure as they were all just dumped into trash, so I\u2019m going to have to spend ages sorting it all out again.\n\nSo I\u2019m done with Mega and need an alternative. While the actual cloud backup part is a bonus for me, it\u2019s really the syncing features between all of the PCs/Laptops that I\u2019m interested in, so looking for people\u2019s recommendations.\n\nThis needs to be realtime backups, so that as soon as I save new files or edit things it\u2019s uploaded to the cloud as fast as my online connection will allow, and then migrated out to the other systems. All done with local, offline storage not accessing the files from the cloud.\n\nAnd it needs to handle file conflicts gracefully. There will be times when the laptops may be used in places I have no internet connection, so if changes are made or there are versioning issues with documents when a system finally does get back online, it needs to deal with this without freaking out and causing lost data.\n\nNeeds to be able to handle a large storage space with lots of documents without crawling to a halt, and it would be nice if it handled scanning the file directory in a sensible way too. Some of the systems seemed to constantly want to scan through the whole thing every time a single document was updated, which is a lot of time/bandwidth/resources, and a lot of wear on drives.\n\nWe all like fast upload/download speeds, and other features like proper client side encryption and zero-knowledge storage, syncing of memory sticks and removable drives when they\u2019re detected etc would be a bonus, but really the core syncing between the desktop and laptops is what my focus is.", "author_fullname": "t2_grih747", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud storage with the best sync/mirroring features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fxhg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674120537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two drobo systems totalling about 32TB. I&amp;#39;ll be upgrading them soon, but in the meantime about 1.5TB of that is the really crucial stuff that I would like to have cloud storage and syncing for.&lt;/p&gt;\n\n&lt;p&gt;The files are held on said Drobo&amp;#39;s, which are older USB, no- network versions and are attached to my big desktop PC in the house. This has the full collection of this set of files, all categorised into folders, which is shared to cloud storage.&lt;/p&gt;\n\n&lt;p&gt;I then have a collection of laptops for various purposes (Job 1, Job 1 backup, Job 2, one to use around the house, etc etc) and these sync with specific folders from this cloud storage. Some have the majority of the collection because they\u2019re used for a wide range of things, some only very specific folders because that\u2019s all they\u2019re used for.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve messed about with a few different providers: wasabi back in the very early days, one drive and dropbox mostly because people sometimes share files with me through these, but for the vast majority of the time I used google drive to sync and share all of this. It provided the cloud storage and linked everything together so wherever changes were made, they then migrated out to all of the other systems. While it had a few issues here and there, mostly it worked fine\u2026.until they revamped it all a year or two ago and made it work with a virtual drive system, breaking some of the software I used.&lt;/p&gt;\n\n&lt;p&gt;After searching through alternatives I decided to give Mega a go, which I\u2019ve run for the past year or so. About 6 months ago I noticed that some audio files were missing from my player, and after searching discovered the sync client had decided to randomly delete a pile of files. Turns out that it had been deleting very occasional files here and there for a while, but I only noticed because it deleted a particularly big batch on this occasion which became obvious. I recovered them from the trash and backed them all up, and thought I understood why this had happened so I decided to stick with it and proceed with caution.&lt;/p&gt;\n\n&lt;p&gt;However I\u2019ve just discovered last night it deleted another huge batch of files, 47GB this time, including a handful of folders with some important work documents in them. I was again able to recover them thankfully (they\u2019d have been gone for good if I hadn\u2019t noticed for 30 days) but even so I\u2019ve lost the directory structure as they were all just dumped into trash, so I\u2019m going to have to spend ages sorting it all out again.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019m done with Mega and need an alternative. While the actual cloud backup part is a bonus for me, it\u2019s really the syncing features between all of the PCs/Laptops that I\u2019m interested in, so looking for people\u2019s recommendations.&lt;/p&gt;\n\n&lt;p&gt;This needs to be realtime backups, so that as soon as I save new files or edit things it\u2019s uploaded to the cloud as fast as my online connection will allow, and then migrated out to the other systems. All done with local, offline storage not accessing the files from the cloud.&lt;/p&gt;\n\n&lt;p&gt;And it needs to handle file conflicts gracefully. There will be times when the laptops may be used in places I have no internet connection, so if changes are made or there are versioning issues with documents when a system finally does get back online, it needs to deal with this without freaking out and causing lost data.&lt;/p&gt;\n\n&lt;p&gt;Needs to be able to handle a large storage space with lots of documents without crawling to a halt, and it would be nice if it handled scanning the file directory in a sensible way too. Some of the systems seemed to constantly want to scan through the whole thing every time a single document was updated, which is a lot of time/bandwidth/resources, and a lot of wear on drives.&lt;/p&gt;\n\n&lt;p&gt;We all like fast upload/download speeds, and other features like proper client side encryption and zero-knowledge storage, syncing of memory sticks and removable drives when they\u2019re detected etc would be a bonus, but really the core syncing between the desktop and laptops is what my focus is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fxhg2", "is_robot_indexable": true, "report_reasons": null, "author": "kevinmcdonough", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fxhg2/cloud_storage_with_the_best_syncmirroring_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fxhg2/cloud_storage_with_the_best_syncmirroring_features/", "subreddit_subscribers": 666569, "created_utc": 1674120537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As a photography hobbyist, I have a growing collection of photos (1.5TB and growing).\n\nI currently have this stored on a 2TB Seagate Barracuda and I take a semi-regular manual backup onto a 2nd matching drive. The trouble is that my PC case is far too big, so I want a smaller solution, using a smaller case and then external storage. I don\u2019t need a NAS or server, just external storage.\n\nI am thinking of getting a DAS with 4/5 bays fitted with some 6/8TB drives and possibly running a software based RAID 5 to give me more speed, a bit of redundancy, and then using a single large external HDD as a backup solution.\n\nDoes this seem like a reasonable option?", "author_fullname": "t2_nutyb4co", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DAS + backup recommendations.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fx8bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674119552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a photography hobbyist, I have a growing collection of photos (1.5TB and growing).&lt;/p&gt;\n\n&lt;p&gt;I currently have this stored on a 2TB Seagate Barracuda and I take a semi-regular manual backup onto a 2nd matching drive. The trouble is that my PC case is far too big, so I want a smaller solution, using a smaller case and then external storage. I don\u2019t need a NAS or server, just external storage.&lt;/p&gt;\n\n&lt;p&gt;I am thinking of getting a DAS with 4/5 bays fitted with some 6/8TB drives and possibly running a software based RAID 5 to give me more speed, a bit of redundancy, and then using a single large external HDD as a backup solution.&lt;/p&gt;\n\n&lt;p&gt;Does this seem like a reasonable option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fx8bn", "is_robot_indexable": true, "report_reasons": null, "author": "Makin-Sawdust", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fx8bn/das_backup_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fx8bn/das_backup_recommendations/", "subreddit_subscribers": 666569, "created_utc": 1674119552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Think of it as backup", "author_fullname": "t2_umytgvvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have an extra HDD ready to be installed into PC, should I do that or keep it somewhere safe in an event of circuit frying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fwqq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674117623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Think of it as backup&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "17TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fwqq7", "is_robot_indexable": true, "report_reasons": null, "author": "ElonTastical", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10fwqq7/i_have_an_extra_hdd_ready_to_be_installed_into_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fwqq7/i_have_an_extra_hdd_ready_to_be_installed_into_pc/", "subreddit_subscribers": 666569, "created_utc": 1674117623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It seems my small fan bases use discord as a sort of wiki, but these discord are also largely unarchived. This problem saddens me, are there any groups currently trying to archive discord? And is there any information out there about this problem, I have already seen archiveteams wiki entry.", "author_fullname": "t2_185vh3m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking to understand more about this problem of many discord servers being completely unarchived, do any of yall know stuff about this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fl9hu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674082989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems my small fan bases use discord as a sort of wiki, but these discord are also largely unarchived. This problem saddens me, are there any groups currently trying to archive discord? And is there any information out there about this problem, I have already seen archiveteams wiki entry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fl9hu", "is_robot_indexable": true, "report_reasons": null, "author": "FutureTIwinner", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fl9hu/looking_to_understand_more_about_this_problem_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fl9hu/looking_to_understand_more_about_this_problem_of/", "subreddit_subscribers": 666569, "created_utc": 1674082989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\nI\u2019m beginning my journey into data hoarding, so I would like to ask you for help on choosing redundancy method.\nI have 5 drives:\n- 2x Ironwolf 8TB,\n- 2x WD Red 4TB,\n- 1x Seagate Barracuda 2TB.\n\nCurrently I\u2019m using Ironwolf 8TB as my place to store photos, videos, backups and my family stuff and Rsync that to second 8TB Ironwolf everyday. What is more I\u2019m using 2TB Barracuda for downloaded media that I don\u2019t care losing.\nNow I would like to involve WD Reds into the process. What way should I go?\nOptions I see:\n1. Use MergerFS to merge one 8TB and one 4TB, then RSync data to secondary drives.\n2. Use MergerFS to merge 8TB and 2x 4TB drives into one and keep one 8TB as parity drive for Snapraid.\n3. Use Raid1 on disk pairs, I\u2019m not fan of that as I think parity calculation on the fly is not needed in my case as data changes infrequently.\n\nWhat seems the most reasonable? Which one will give me the greatest protection? Which one will produce the lowest downtime in case of drive death?", "author_fullname": "t2_3l6v2tv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rsync, Snapraid + Mergerfs or", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fkkti", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674081334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI\u2019m beginning my journey into data hoarding, so I would like to ask you for help on choosing redundancy method.\nI have 5 drives:\n- 2x Ironwolf 8TB,\n- 2x WD Red 4TB,\n- 1x Seagate Barracuda 2TB.&lt;/p&gt;\n\n&lt;p&gt;Currently I\u2019m using Ironwolf 8TB as my place to store photos, videos, backups and my family stuff and Rsync that to second 8TB Ironwolf everyday. What is more I\u2019m using 2TB Barracuda for downloaded media that I don\u2019t care losing.\nNow I would like to involve WD Reds into the process. What way should I go?\nOptions I see:\n1. Use MergerFS to merge one 8TB and one 4TB, then RSync data to secondary drives.\n2. Use MergerFS to merge 8TB and 2x 4TB drives into one and keep one 8TB as parity drive for Snapraid.\n3. Use Raid1 on disk pairs, I\u2019m not fan of that as I think parity calculation on the fly is not needed in my case as data changes infrequently.&lt;/p&gt;\n\n&lt;p&gt;What seems the most reasonable? Which one will give me the greatest protection? Which one will produce the lowest downtime in case of drive death?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10fkkti", "is_robot_indexable": true, "report_reasons": null, "author": "Kamoooool", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10fkkti/rsync_snapraid_mergerfs_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10fkkti/rsync_snapraid_mergerfs_or/", "subreddit_subscribers": 666569, "created_utc": 1674081334.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}