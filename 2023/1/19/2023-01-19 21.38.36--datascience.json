{"kind": "Listing", "data": {"after": "t3_10g27ch", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h9ygk2wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is this for a Data Analysis roadmap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmj6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 350, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 350, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CVmsTgeCjiTuwbp3XPCXFPFEMmz8ogdpelYhXQi6ON4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674086133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0wl7i4x14wca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?auto=webp&amp;v=enabled&amp;s=4e053d88c9aad550b5b92153b2a30f526a81a663", "width": 1440, "height": 754}, "resolutions": [{"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=202ee5909ec768da1be94892f4e1555c8939f14d", "width": 108, "height": 56}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daa27539712a8597401d7f83b814f58822fd7d35", "width": 216, "height": 113}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c5453eed46a24f3adf33d8a029df2f2dfa80471", "width": 320, "height": 167}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a79a968d69f5942597a397c4afeb0e21b91f80d7", "width": 640, "height": 335}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33bf8700cd92470cb36f4ba6d802460adf8b4a59", "width": 960, "height": 502}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39e6ef9951cfc2e4046f016f695e1f5b42ef0dc1", "width": 1080, "height": 565}], "variants": {}, "id": "IQ-0tJHyd9OWcCBUyAQ1UCwHV7rpRHVyuIpGGo3o1Z8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmj6h", "is_robot_indexable": true, "report_reasons": null, "author": "twenni7", "discussion_type": null, "num_comments": 146, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmj6h/how_is_this_for_a_data_analysis_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0wl7i4x14wca1.jpg", "subreddit_subscribers": 838812, "created_utc": 1674086133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Expected to see atleast a few posts about layoffs at Amazon and Microsoft that happened today...?\n\nI was one of them, laid off from Amazon after 2.5 years there. Anybody else here in the same boat?\n\nAnyway iv been thinking about how this all went down and what I'd do differently to future proof my career.. will share a longer post tomorrow. Today's been a long day.\n\n\n\nUpdate 1- just getting started and will slowly reply to comments..I'm generally upbeat about the turn of events and that's why I said it warrants a separate post I'll hopefully write today. \n\nFor now, here is my outlook moving forward- I plan on focusing on work life balance, following my interests and building my personal portfolio. \nI'm lucky enough  to not have immediate financial worry, the larger issue is my H1B visa. But I have options..\n\nThe larger impact this has had in my outlook towards my career and how my employer doesn't define it. \n\nPs-I'll be sharing my journey on twitter if folks want to follow (@sangyh2).\n\n\nUpdate 2: for other folks laid off or needing a resume review or interview tips, I can help. Ping me here or on twitter.", "author_fullname": "t2_4m1ivn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "layoffs at big tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fv6hv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 244, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 244, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674150773.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674111578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Expected to see atleast a few posts about layoffs at Amazon and Microsoft that happened today...?&lt;/p&gt;\n\n&lt;p&gt;I was one of them, laid off from Amazon after 2.5 years there. Anybody else here in the same boat?&lt;/p&gt;\n\n&lt;p&gt;Anyway iv been thinking about how this all went down and what I&amp;#39;d do differently to future proof my career.. will share a longer post tomorrow. Today&amp;#39;s been a long day.&lt;/p&gt;\n\n&lt;p&gt;Update 1- just getting started and will slowly reply to comments..I&amp;#39;m generally upbeat about the turn of events and that&amp;#39;s why I said it warrants a separate post I&amp;#39;ll hopefully write today. &lt;/p&gt;\n\n&lt;p&gt;For now, here is my outlook moving forward- I plan on focusing on work life balance, following my interests and building my personal portfolio. \nI&amp;#39;m lucky enough  to not have immediate financial worry, the larger issue is my H1B visa. But I have options..&lt;/p&gt;\n\n&lt;p&gt;The larger impact this has had in my outlook towards my career and how my employer doesn&amp;#39;t define it. &lt;/p&gt;\n\n&lt;p&gt;Ps-I&amp;#39;ll be sharing my journey on twitter if folks want to follow (@sangyh2).&lt;/p&gt;\n\n&lt;p&gt;Update 2: for other folks laid off or needing a resume review or interview tips, I can help. Ping me here or on twitter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fv6hv", "is_robot_indexable": true, "report_reasons": null, "author": "sang89", "discussion_type": null, "num_comments": 121, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fv6hv/layoffs_at_big_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fv6hv/layoffs_at_big_tech/", "subreddit_subscribers": 838812, "created_utc": 1674111578.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6me67nru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We can quibble over the alignments, but I strongly assert that Excel is Chaotic Evil", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 109, "top_awarded_type": null, "hide_score": false, "name": "t3_10gawmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 145, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/s6UIeGhcgbFCT_iZW5u3xXOROaoo1HOIBBbN6dNSoM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674156907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dmqqbqjay1da1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dmqqbqjay1da1.png?auto=webp&amp;v=enabled&amp;s=ae812618aa50b78d4a051020e31f90e54c225334", "width": 1842, "height": 1443}, "resolutions": [{"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53b3035311fb8ee8b90dca3cf12b666a03f6a25e", "width": 108, "height": 84}, {"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d589b802f6e04ab9ee97425f161a75ad665ea1a", "width": 216, "height": 169}, {"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1db1d0ab47f9192b8c1d3c5d552b3d400ea0769c", "width": 320, "height": 250}, {"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c7fcd6bb5f3541bdcec5d6cffbf8046d44f4cf7", "width": 640, "height": 501}, {"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f816725f8da697ca6f8109cc34e0912a43fa8acb", "width": 960, "height": 752}, {"url": "https://preview.redd.it/dmqqbqjay1da1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6884ecbb8a3b1c16c980fde509bfbfd9c9f84ed8", "width": 1080, "height": 846}], "variants": {}, "id": "dO3sO0Hoi-f3woRhS53BEgSPtkj0kYGv9-CGdwnXAys"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gawmi", "is_robot_indexable": true, "report_reasons": null, "author": "bugprof2020", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gawmi/we_can_quibble_over_the_alignments_but_i_strongly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dmqqbqjay1da1.png", "subreddit_subscribers": 838812, "created_utc": 1674156907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812)\n\nThe rumor mill is buzzing around the release of GPT-4.\n\nPeople are predicting the model will have 100 trillion parameters. That\u2019s a *trillion* with a \u201ct\u201d.\n\nThe often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.\n\nSure, OpenAI\u2019s new brainchild will certainly be mind-bending and language models have been getting bigger \u2014 fast!\n\nBut this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).\n\n*Let\u2019s go!*\n\nTraining 100 Trillion Parameters\n\nThe creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \\[1\\].\n\nTraining a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.\n\nSo, where is this rumor coming from?\n\nThe Source Of The Rumor:\n\nIt turns out OpenAI itself might be the source of it.\n\nIn August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): \u201cFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters\u201d.\n\nA the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.\n\nThings have changed a lot since then!\n\nTo understand what happened we first need to look at how people decide the number of parameters in a model.\n\nDeciding The Number Of Parameters:\n\nThe enormous hunger for resources typically makes it feasible to train an LLM only once.\n\nIn practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.\n\n*But there\u2019s a catch!*\n\nMost research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.\n\nWith LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.\n\nTherefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.\n\nThis process can very noisy and the community\u2019s understanding has evolved a lot over the last few years.\n\nWhat People Used To Think About Scaling LLMs\n\nIn 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: \u201cScaling Laws For Neural Language Models\u201d.\n\nThey observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.\n\nSo far so good. But they made two other observations, which resulted in the model size ballooning rapidly.\n\n1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.\n2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.\n\nHence, it seemed as if the way to improve performance was to scale models faster than the dataset size \\[2\\].\n\nAnd that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.\n\nBut the bigger models failed to deliver on the promise.\n\n*Read on to learn why!*\n\nWhat We know About Scaling Models Today\n\nIt turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.\n\nThis was published in DeepMind\u2019s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): \u201cTraining Compute-Optimal Large Language Models\u201d\n\nThe researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.\n\nThe findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.\n\nTo verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.\n\nChinchilla outperforms GPT-3 and other much larger models by a fair margin \\[3\\].\n\nThis was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.\n\n*So What Will Happen?*\n\nWhat GPT-4 Might Look Like:\n\nTo properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \\[1\\].\n\nSo, here is what GPT-4 could look like:\n\n* Similar size to GPT-3, but trained optimally on 10x more data\n* \u200b[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound\n* Output conditioned on document chunks from a memory bank that the model has access to during prediction \\[4\\]\n* Doubled context size allows longer predictions before the model starts going off the rails\u200b\n\nRegardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.\n\nWhatever it will look like, I am sure it will be amazing and we can all be excited about the release.\n\nSuch exciting times to be alive!\n\nIf you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** \u2b55, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)\n\n**References:**\n\n\\[1\\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21\n\n\\[2\\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,\u2026 &amp; D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint\n\n\\[3\\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.\n\n\\[4\\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver", "author_fullname": "t2_az3v2qdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 Will Be 500x Smaller Than People Think - Here Is Why", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"t6m0epzlgyca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0a29a7b132523bf64a92a5debe78d843d581ab7"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d79bbd9721656b1fa4b174c903bd2c193b57d71"}, {"y": 199, "x": 320, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d6def614c56adebf27b9024ce78effd4d8986ce"}], "s": {"y": 358, "x": 575, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812"}, "id": "t6m0epzlgyca1"}}, "name": "t3_10fw1a3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/oKXeVsr9RETPpHUqhlmM3n7Z-8rZHnuRMLMx36JHz9k.jpg", "edited": 1674128747.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674114864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812\"&gt;Number Of Parameters GPT-3 vs. GPT-4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The rumor mill is buzzing around the release of GPT-4.&lt;/p&gt;\n\n&lt;p&gt;People are predicting the model will have 100 trillion parameters. That\u2019s a &lt;em&gt;trillion&lt;/em&gt; with a \u201ct\u201d.&lt;/p&gt;\n\n&lt;p&gt;The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.&lt;/p&gt;\n\n&lt;p&gt;Sure, OpenAI\u2019s new brainchild will certainly be mind-bending and language models have been getting bigger \u2014 fast!&lt;/p&gt;\n\n&lt;p&gt;But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Let\u2019s go!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Training 100 Trillion Parameters&lt;/p&gt;\n\n&lt;p&gt;The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone [1].&lt;/p&gt;\n\n&lt;p&gt;Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.&lt;/p&gt;\n\n&lt;p&gt;So, where is this rumor coming from?&lt;/p&gt;\n\n&lt;p&gt;The Source Of The Rumor:&lt;/p&gt;\n\n&lt;p&gt;It turns out OpenAI itself might be the source of it.&lt;/p&gt;\n\n&lt;p&gt;In August 2021 the CEO of Cerebras told &lt;a href=\"https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/\"&gt;wired&lt;/a&gt;: \u201cFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters\u201d.&lt;/p&gt;\n\n&lt;p&gt;A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.&lt;/p&gt;\n\n&lt;p&gt;Things have changed a lot since then!&lt;/p&gt;\n\n&lt;p&gt;To understand what happened we first need to look at how people decide the number of parameters in a model.&lt;/p&gt;\n\n&lt;p&gt;Deciding The Number Of Parameters:&lt;/p&gt;\n\n&lt;p&gt;The enormous hunger for resources typically makes it feasible to train an LLM only once.&lt;/p&gt;\n\n&lt;p&gt;In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;But there\u2019s a catch!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.&lt;/p&gt;\n\n&lt;p&gt;With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.&lt;/p&gt;\n\n&lt;p&gt;Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.&lt;/p&gt;\n\n&lt;p&gt;This process can very noisy and the community\u2019s understanding has evolved a lot over the last few years.&lt;/p&gt;\n\n&lt;p&gt;What People Used To Think About Scaling LLMs&lt;/p&gt;\n\n&lt;p&gt;In 2020, a team of researchers from OpenAI released a &lt;a href=\"https://arxiv.org/pdf/2001.08361.pdf\"&gt;paper&lt;/a&gt; called: \u201cScaling Laws For Neural Language Models\u201d.&lt;/p&gt;\n\n&lt;p&gt;They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.&lt;/p&gt;\n\n&lt;p&gt;So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.&lt;/li&gt;\n&lt;li&gt;Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size [2].&lt;/p&gt;\n\n&lt;p&gt;And that is what people did. The models got larger and larger with GPT-3 (175B), &lt;a href=\"https://arxiv.org/pdf/2112.11446.pdf\"&gt;Gopher&lt;/a&gt; (280B), &lt;a href=\"https://arxiv.org/pdf/2201.11990\"&gt;Megatron-Turing NLG&lt;/a&gt; (530B) just to name a few.&lt;/p&gt;\n\n&lt;p&gt;But the bigger models failed to deliver on the promise.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Read on to learn why!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;What We know About Scaling Models Today&lt;/p&gt;\n\n&lt;p&gt;It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.&lt;/p&gt;\n\n&lt;p&gt;This was published in DeepMind\u2019s 2022 &lt;a href=\"https://arxiv.org/pdf/2203.15556.pdf\"&gt;paper&lt;/a&gt;: \u201cTraining Compute-Optimal Large Language Models\u201d&lt;/p&gt;\n\n&lt;p&gt;The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.&lt;/p&gt;\n\n&lt;p&gt;The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.&lt;/p&gt;\n\n&lt;p&gt;To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.&lt;/p&gt;\n\n&lt;p&gt;Chinchilla outperforms GPT-3 and other much larger models by a fair margin [3].&lt;/p&gt;\n\n&lt;p&gt;This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;So What Will Happen?&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;What GPT-4 Might Look Like:&lt;/p&gt;\n\n&lt;p&gt;To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model [1].&lt;/p&gt;\n\n&lt;p&gt;So, here is what GPT-4 could look like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Similar size to GPT-3, but trained optimally on 10x more data&lt;/li&gt;\n&lt;li&gt;\u200b&lt;a href=\"https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley\"&gt;Multi-modal&lt;/a&gt; outputting text, images, and sound&lt;/li&gt;\n&lt;li&gt;Output conditioned on document chunks from a memory bank that the model has access to during prediction [4]&lt;/li&gt;\n&lt;li&gt;Doubled context size allows longer predictions before the model starts going off the rails\u200b&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.&lt;/p&gt;\n\n&lt;p&gt;Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.&lt;/p&gt;\n\n&lt;p&gt;Such exciting times to be alive!&lt;/p&gt;\n\n&lt;p&gt;If you got down here, thank you! It was a privilege to make this for you. At &lt;strong&gt;TheDecoding&lt;/strong&gt; \u2b55, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. &lt;a href=\"https://thedecoding.net/\"&gt;Click here to sign up!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;[1] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, &lt;a href=\"https://arxiv.org/abs/2104.04473\"&gt;Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM&lt;/a&gt; (2021), SC21&lt;/p&gt;\n\n&lt;p&gt;[2] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,\u2026 &amp;amp; D. Amodei, &lt;a href=\"https://arxiv.org/abs/2001.08361\"&gt;Scaling laws for neural language model&lt;/a&gt;s (2020), arxiv preprint&lt;/p&gt;\n\n&lt;p&gt;[3] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, &lt;a href=\"https://arxiv.org/abs/2203.15556\"&gt;Training Compute-Optimal Large Language Models&lt;/a&gt; (2022). &lt;em&gt;arXiv preprint arXiv:2203.15556&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;[4] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, &lt;a href=\"https://arxiv.org/abs/2112.04426\"&gt;Improving language models by retrieving from trillions of tokens&lt;/a&gt; (2021). &lt;em&gt;arXiv preprint arXiv:2112.04426&lt;/em&gt;.Vancouver&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?auto=webp&amp;v=enabled&amp;s=be39d060ca2c05f2cd27b7b61b7bf6690cb15ddb", "width": 1280, "height": 670}, "resolutions": [{"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bec379d156a2cf39b26fe375096430d4d7df2572", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e503dfdef5894c436698e6141578531d476ce09e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=134c5d684b101c24dfc07edb1632e55a52d79d42", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b783721b8a5e3962893f6d158579ba8c0bc17703", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=296f711f9dd76c942237fa48cacd46275585e5f3", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/fbvSgNQP8xl1hxjuo6NA3KvQqOiPCPtdBe4kUPMzLJI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b71e2bfa4c3a837389079594837f83ca64eaf4d", "width": 1080, "height": 565}], "variants": {}, "id": "FJ053FDSFfsh6o6KSSofP-rsAoIxz6ay9T4Lo_O08O8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fw1a3", "is_robot_indexable": true, "report_reasons": null, "author": "LesleyFair", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fw1a3/gpt4_will_be_500x_smaller_than_people_think_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fw1a3/gpt4_will_be_500x_smaller_than_people_think_here/", "subreddit_subscribers": 838812, "created_utc": 1674114864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vhx54ulr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving direct text extraction from PDFs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmi2u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P-TF2fexSPks2f7mLdY-R1tDKddDsv87LN-bTZuP4Eo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674086053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "sensible.so", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.sensible.so/blog/solving-direct-text-extraction-from-pdfs?utm_campaign=Data%20Science&amp;utm_source=reddit&amp;utm_medium=paidsocial&amp;utm_content=post", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?auto=webp&amp;v=enabled&amp;s=e63d76bee822e8077be465dcebe1406f781cf370", "width": 3148, "height": 1967}, "resolutions": [{"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6938ffe2c20efc56e04e354ab6ecb745b4f47617", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb3e88f1a86f8820cac1fb235a9a06bd1a6dfc31", "width": 216, "height": 134}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2988fabb4a01426faa97da84861dc60e4bf9c52", "width": 320, "height": 199}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf53dfb477c0af4ca3f741b98fe9bb8db0565fd0", "width": 640, "height": 399}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=127413c342534d75fa591a60fd69ea21dbbbdf38", "width": 960, "height": 599}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37eba81e2007ca7a887e5961e8ae7f873f319332", "width": 1080, "height": 674}], "variants": {}, "id": "ew5_lxhvSkLjVhIJzdo-GYDgbVhhT5z3DNOKS5rmLUs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmi2u", "is_robot_indexable": true, "report_reasons": null, "author": "usesensible", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmi2u/solving_direct_text_extraction_from_pdfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.sensible.so/blog/solving-direct-text-extraction-from-pdfs?utm_campaign=Data%20Science&amp;utm_source=reddit&amp;utm_medium=paidsocial&amp;utm_content=post", "subreddit_subscribers": 838812, "created_utc": 1674086053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The more and more I apply, the more I see \u201centry level\u201d roles in data analytics are in fact not entry level and usually need, at a minimum, 1 year of experience. That said, what actual entry level roles are good to start in that have good opportunities for moving into data analytics? (Other than data entry)", "author_fullname": "t2_16n8a1d7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Entry Level Roles are Good for Bridging Into Data Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fn4bo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674087606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The more and more I apply, the more I see \u201centry level\u201d roles in data analytics are in fact not entry level and usually need, at a minimum, 1 year of experience. That said, what actual entry level roles are good to start in that have good opportunities for moving into data analytics? (Other than data entry)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10fn4bo", "is_robot_indexable": true, "report_reasons": null, "author": "jordanar189", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fn4bo/what_entry_level_roles_are_good_for_bridging_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fn4bo/what_entry_level_roles_are_good_for_bridging_into/", "subreddit_subscribers": 838812, "created_utc": 1674087606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title", "author_fullname": "t2_rc5lfgnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone here transitioned from Data Scientist to Data Engineer? What was your motivation, and do you regret the move now, or are you happier as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fpmi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674094398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fpmi2", "is_robot_indexable": true, "report_reasons": null, "author": "Subject_Ad_9680", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fpmi2/has_anyone_here_transitioned_from_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fpmi2/has_anyone_here_transitioned_from_data_scientist/", "subreddit_subscribers": 838812, "created_utc": 1674094398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_i049nix9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have good resources for applications of data science for sports betting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmdk3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674085733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmdk3", "is_robot_indexable": true, "report_reasons": null, "author": "vizualizing123", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmdk3/anyone_have_good_resources_for_applications_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fmdk3/anyone_have_good_resources_for_applications_of/", "subreddit_subscribers": 838812, "created_utc": 1674085733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_sm7aw2mc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does working as data scientist affect your physical/mental health in any way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g205h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674135741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g205h", "is_robot_indexable": true, "report_reasons": null, "author": "bababooeey917", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g205h/does_working_as_data_scientist_affect_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10g205h/does_working_as_data_scientist_affect_your/", "subreddit_subscribers": 838812, "created_utc": 1674135741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I found a lot topics on reddit and in general with the title \"R vs Python\", which one should I choose / learn / stick with etc.\n\nI learned both languages and used per project always one of them. However I wonder how much of you use for a single project both languages? To be more concrete:\n\n* **R** for the whole cleaning, preprocessing and explorative data analysis part (and nice ggplots). Also for feature engineering and feature selection.\n* **Python** for everything that follows: Machine learning model training, tuning, evaluating and deploying.\n\nWhy R for the preprocessing, EDA and feature engineering? -&gt; Because working with tidyverse + ggplot is really fast and nice. I'm much more quicker than with Pandas/Matplotlib/Seaborn. Statistical functions are pretty good supported there. Also generating PDF/HTML reports work well.\n\nWhy Python for everything else? -&gt; Because ML like Deep Learning has better support there. Also the deploying part (APIs etc.) are better supported in terms of libraries/frameworks etc.\n\n[View Poll](https://www.reddit.com/poll/10fk64d)", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use R for EDA and Python for machine learning + deploying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fk64d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674080343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a lot topics on reddit and in general with the title &amp;quot;R vs Python&amp;quot;, which one should I choose / learn / stick with etc.&lt;/p&gt;\n\n&lt;p&gt;I learned both languages and used per project always one of them. However I wonder how much of you use for a single project both languages? To be more concrete:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;R&lt;/strong&gt; for the whole cleaning, preprocessing and explorative data analysis part (and nice ggplots). Also for feature engineering and feature selection.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; for everything that follows: Machine learning model training, tuning, evaluating and deploying.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Why R for the preprocessing, EDA and feature engineering? -&amp;gt; Because working with tidyverse + ggplot is really fast and nice. I&amp;#39;m much more quicker than with Pandas/Matplotlib/Seaborn. Statistical functions are pretty good supported there. Also generating PDF/HTML reports work well.&lt;/p&gt;\n\n&lt;p&gt;Why Python for everything else? -&amp;gt; Because ML like Deep Learning has better support there. Also the deploying part (APIs etc.) are better supported in terms of libraries/frameworks etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10fk64d\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "10fk64d", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674339543370, "options": [{"text": "R only", "id": "21097469"}, {"text": "Python only", "id": "21097470"}, {"text": "R for EDA and Python afterwards", "id": "21097471"}, {"text": "Other. See comment...", "id": "21097472"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 544, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fk64d/do_you_use_r_for_eda_and_python_for_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/10fk64d/do_you_use_r_for_eda_and_python_for_machine/", "subreddit_subscribers": 838812, "created_utc": 1674080343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n    \nso I landed my first interview for junior data science position.\nAs a prerequisite for the first interview, they asked me to do a project.\nThey provided me with the dataset (100k+ inputs) and they want me to\nextract conclusions from the dataset by using a data-driven approach and \nalgorithms. \nI have done a few projects in college but right now I'm stuck, not sure what to do.\n    \nHow should I clean the data? Out of 20 columns, \nonly 2 columns are missing data on like 500 rows out of 100k.\nThe third column has like 50k of unknown value.\nDo I remove whole rows where data is missing or do I only skip those rows when it comes to statistics about those columns in particular?\n    \nI'm not sure what kinds of conclusions to draw from the dataset.\nShould I just structure the data and make some graphs, or should I go \nall out and make some predictions on the dataset? \n    \n    \nTLDR: I have an interview for a junior DS position. How to clean data, and should I do some predictions on data, or only graphs and statistics?", "author_fullname": "t2_tv2fyu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips on how to prepare project for the interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10gbzcj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674159413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;so I landed my first interview for junior data science position.\nAs a prerequisite for the first interview, they asked me to do a project.\nThey provided me with the dataset (100k+ inputs) and they want me to\nextract conclusions from the dataset by using a data-driven approach and \nalgorithms. \nI have done a few projects in college but right now I&amp;#39;m stuck, not sure what to do.&lt;/p&gt;\n\n&lt;p&gt;How should I clean the data? Out of 20 columns, \nonly 2 columns are missing data on like 500 rows out of 100k.\nThe third column has like 50k of unknown value.\nDo I remove whole rows where data is missing or do I only skip those rows when it comes to statistics about those columns in particular?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what kinds of conclusions to draw from the dataset.\nShould I just structure the data and make some graphs, or should I go \nall out and make some predictions on the dataset? &lt;/p&gt;\n\n&lt;p&gt;TLDR: I have an interview for a junior DS position. How to clean data, and should I do some predictions on data, or only graphs and statistics?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gbzcj", "is_robot_indexable": true, "report_reasons": null, "author": "CherryGG2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gbzcj/any_tips_on_how_to_prepare_project_for_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gbzcj/any_tips_on_how_to_prepare_project_for_the/", "subreddit_subscribers": 838812, "created_utc": 1674159413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi First of all, thank you for all you are sharing here; it has helped me a lot.\n\nI am an electronic engineer and data science has really caught my attention. I was using basic things in my current job (cleaning, preprocessing, and statistics only) and in the last few months I have been learning from many courses about a variety of algorithms, some basic neural nets, and so on. \n\nAt first, I tried (unsuccessfully) taking notes in Qmarkdown/Obsidian, but the effort and time it took made me comment or document the code better (why I chose that x theorem, conclusions, etc.). \n\nI tried to \"organize\" this information (I use Python notebooks) but I have multiple ways of saving code depending on the source (GitHub for personal, Colab GDrive for Udemy, Kaggle, etc.). So when I tried to find, for example, X code for X theorem, it is not easy to find because I have the same in multiple files, for example.  At that moment, I thought, \"Why am I not taking notes?\" \n\n Thank you once again (yes maybe too long); I think it is too personal in some point, but I really think what works (or not) for you will help me.\n\nRegards\n\nSebastian", "author_fullname": "t2_mlbmqqp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool you use for \"save\" or access to all what are you learning in these years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10gbx0w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674159264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi First of all, thank you for all you are sharing here; it has helped me a lot.&lt;/p&gt;\n\n&lt;p&gt;I am an electronic engineer and data science has really caught my attention. I was using basic things in my current job (cleaning, preprocessing, and statistics only) and in the last few months I have been learning from many courses about a variety of algorithms, some basic neural nets, and so on. &lt;/p&gt;\n\n&lt;p&gt;At first, I tried (unsuccessfully) taking notes in Qmarkdown/Obsidian, but the effort and time it took made me comment or document the code better (why I chose that x theorem, conclusions, etc.). &lt;/p&gt;\n\n&lt;p&gt;I tried to &amp;quot;organize&amp;quot; this information (I use Python notebooks) but I have multiple ways of saving code depending on the source (GitHub for personal, Colab GDrive for Udemy, Kaggle, etc.). So when I tried to find, for example, X code for X theorem, it is not easy to find because I have the same in multiple files, for example.  At that moment, I thought, &amp;quot;Why am I not taking notes?&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Thank you once again (yes maybe too long); I think it is too personal in some point, but I really think what works (or not) for you will help me.&lt;/p&gt;\n\n&lt;p&gt;Regards&lt;/p&gt;\n\n&lt;p&gt;Sebastian&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gbx0w", "is_robot_indexable": true, "report_reasons": null, "author": "Sebita82", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gbx0w/what_tool_you_use_for_save_or_access_to_all_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gbx0w/what_tool_you_use_for_save_or_access_to_all_what/", "subreddit_subscribers": 838812, "created_utc": 1674159264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I come from a Ms degree in economic history(took Calculus III, Linear Algebra, Diff equations.) graduated 10 years ago, with a thesis that relied heavily on econometrics(STATA, SPSS). I currently work as a Digital Marketer doing PPC, Paid Social and SEO. And I am looking to dive deeper into Digital Marketing with more Data oriented approaches. Self thought myself(Coursera, Youtube) python language and I am currently very comfortable doing DA on python.(Incredibly insightful, almost feels like superpower for a Marketer, cohort analysis etc.).  \nWhat **education path** do **recommend** to be able to **apply** more **advanced data modeling** on customer behavior, and possibly **land a job** as **marketing Analyst** ?\n\n1. Elite University bootcamps? Reviews say that they are rather scammy, and taught by 3rd party institutions.\n2. Coursera Edx? Feels like they scratch the surface, and you have to figure it out yourself, also not too appreciated by recruiters.\n3. Udacity, Datacamp, Ironhack ... ? Same as MOOCs or are they better?\n4. Actual Masters Degree? All universities are asking for &gt; 50.000USD\n\nWith endless online choices, scam program advertiser, and also nonsense posters on social media(even on reddit) I am confused who to believe.\n\n  \nAny insight is highly appreciated.", "author_fullname": "t2_27k9kc92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digital Marketer, looking to switch into Marketing Analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gashk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674156621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from a Ms degree in economic history(took Calculus III, Linear Algebra, Diff equations.) graduated 10 years ago, with a thesis that relied heavily on econometrics(STATA, SPSS). I currently work as a Digital Marketer doing PPC, Paid Social and SEO. And I am looking to dive deeper into Digital Marketing with more Data oriented approaches. Self thought myself(Coursera, Youtube) python language and I am currently very comfortable doing DA on python.(Incredibly insightful, almost feels like superpower for a Marketer, cohort analysis etc.).&lt;br/&gt;\nWhat &lt;strong&gt;education path&lt;/strong&gt; do &lt;strong&gt;recommend&lt;/strong&gt; to be able to &lt;strong&gt;apply&lt;/strong&gt; more &lt;strong&gt;advanced data modeling&lt;/strong&gt; on customer behavior, and possibly &lt;strong&gt;land a job&lt;/strong&gt; as &lt;strong&gt;marketing Analyst&lt;/strong&gt; ?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Elite University bootcamps? Reviews say that they are rather scammy, and taught by 3rd party institutions.&lt;/li&gt;\n&lt;li&gt;Coursera Edx? Feels like they scratch the surface, and you have to figure it out yourself, also not too appreciated by recruiters.&lt;/li&gt;\n&lt;li&gt;Udacity, Datacamp, Ironhack ... ? Same as MOOCs or are they better?&lt;/li&gt;\n&lt;li&gt;Actual Masters Degree? All universities are asking for &amp;gt; 50.000USD&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;With endless online choices, scam program advertiser, and also nonsense posters on social media(even on reddit) I am confused who to believe.&lt;/p&gt;\n\n&lt;p&gt;Any insight is highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gashk", "is_robot_indexable": true, "report_reasons": null, "author": "Avedis77", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gashk/digital_marketer_looking_to_switch_into_marketing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gashk/digital_marketer_looking_to_switch_into_marketing/", "subreddit_subscribers": 838812, "created_utc": 1674156621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in taking a local, human-run workflow and moving it to an automated cloud workflow. I have a seemingly solid grasp of the individual components; it's the design choices and integration (at a high level) that I'm thinking about here. (Also, I see Rule 7, but this seems a bit abstract for what usually works well on SO.)\n\nI have some code, mostly in notebooks, that pulls data from a few sources (e.g., scraping, APIs), preps it, and writes it out. Then, in other notebooks, I read it in and do some analysis.\n\nHere's what I'm thinking so far:\n\n- Retrieval: Serverless functions (i.e. Azure Functions). I haven't used it, but it seems straightforward to kick these off on a timer and pass it on.\n- Pre-processing: Serverless functions to clean the data for storage, with output inserted into a DB.\n    - Q: Should this be integrated to the prior step? It's highly-structured data, so it may not need a lot of maintenance on its own.\n    - Q: If not, should I pass data in here with a queue or some other cloud functionality, or use file storage and a trigger?\n- Storage: Persistent SQL DBMS as a service.\n- Front end: TBD (web interface), but essentially abstracted from the backend, because it queries the general purpose data storage (and makes analytic-specific transformations either within query or after retrieval).\n\nGeneral questions:\n\n1. Are there good resources on the big picture view? Most of my searching has turned up material on the individual components.\n1. This project (somewhat of a proof of concept) is on the smaller side (1-2GB of data), so are there simplifications that work well at that scale?\n1. Is there an easy way to have these components deploy from a Github repo? For example, when I push a commit, I'd like the serverless functions to use that newest version.\n\nHappy for any advice, ideas, and links to things I can read up on. Thanks!", "author_fullname": "t2_ggtvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to split data pipeline components for cloud workflow.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gamiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674156237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in taking a local, human-run workflow and moving it to an automated cloud workflow. I have a seemingly solid grasp of the individual components; it&amp;#39;s the design choices and integration (at a high level) that I&amp;#39;m thinking about here. (Also, I see Rule 7, but this seems a bit abstract for what usually works well on SO.)&lt;/p&gt;\n\n&lt;p&gt;I have some code, mostly in notebooks, that pulls data from a few sources (e.g., scraping, APIs), preps it, and writes it out. Then, in other notebooks, I read it in and do some analysis.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m thinking so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Retrieval: Serverless functions (i.e. Azure Functions). I haven&amp;#39;t used it, but it seems straightforward to kick these off on a timer and pass it on.&lt;/li&gt;\n&lt;li&gt;Pre-processing: Serverless functions to clean the data for storage, with output inserted into a DB.\n\n&lt;ul&gt;\n&lt;li&gt;Q: Should this be integrated to the prior step? It&amp;#39;s highly-structured data, so it may not need a lot of maintenance on its own.&lt;/li&gt;\n&lt;li&gt;Q: If not, should I pass data in here with a queue or some other cloud functionality, or use file storage and a trigger?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Storage: Persistent SQL DBMS as a service.&lt;/li&gt;\n&lt;li&gt;Front end: TBD (web interface), but essentially abstracted from the backend, because it queries the general purpose data storage (and makes analytic-specific transformations either within query or after retrieval).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;General questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are there good resources on the big picture view? Most of my searching has turned up material on the individual components.&lt;/li&gt;\n&lt;li&gt;This project (somewhat of a proof of concept) is on the smaller side (1-2GB of data), so are there simplifications that work well at that scale?&lt;/li&gt;\n&lt;li&gt;Is there an easy way to have these components deploy from a Github repo? For example, when I push a commit, I&amp;#39;d like the serverless functions to use that newest version.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Happy for any advice, ideas, and links to things I can read up on. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gamiv", "is_robot_indexable": true, "report_reasons": null, "author": "jkiley", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gamiv/how_to_split_data_pipeline_components_for_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gamiv/how_to_split_data_pipeline_components_for_cloud/", "subreddit_subscribers": 838812, "created_utc": 1674156237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all, \n\nI'm tasked with the following:\n\nAt our attraction, you can either pay for day admission or become a member for unlimited visits within that year. Is there a point where one cannibalizes the other? Should we keep pushing for more members or cap it at a certain point?\n\nOn the surface, this sounds like an easy question, however, I'm getting lost in pulling my data. From 2018 - now I can pull everything and am currently thinking I'm pulling too much data. Should I be looking at this question through a different lens?", "author_fullname": "t2_125oer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Member vs Admission Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g76rn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674148389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m tasked with the following:&lt;/p&gt;\n\n&lt;p&gt;At our attraction, you can either pay for day admission or become a member for unlimited visits within that year. Is there a point where one cannibalizes the other? Should we keep pushing for more members or cap it at a certain point?&lt;/p&gt;\n\n&lt;p&gt;On the surface, this sounds like an easy question, however, I&amp;#39;m getting lost in pulling my data. From 2018 - now I can pull everything and am currently thinking I&amp;#39;m pulling too much data. Should I be looking at this question through a different lens?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g76rn", "is_robot_indexable": true, "report_reasons": null, "author": "Roux85", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g76rn/member_vs_admission_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10g76rn/member_vs_admission_analysis/", "subreddit_subscribers": 838812, "created_utc": 1674148389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Entry level roles for return offer interns at my previous company were mostly data analyst roles. Meaning lots of SQL, tableau, etc. These were considered junior analyst roles, straight out of college with a BS. However, if a junior were to get a few years of experience, would they be able to transition into more technical, modeling heavy roles? Even if the modeling is just building regression models, do junior analysts get to \u201cmove up\u201d to this? Or would they need a MS in statistics or data science to move up to more technical roles?", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do junior analysts (new grad) get more technical roles with experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g3z8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674140801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Entry level roles for return offer interns at my previous company were mostly data analyst roles. Meaning lots of SQL, tableau, etc. These were considered junior analyst roles, straight out of college with a BS. However, if a junior were to get a few years of experience, would they be able to transition into more technical, modeling heavy roles? Even if the modeling is just building regression models, do junior analysts get to \u201cmove up\u201d to this? Or would they need a MS in statistics or data science to move up to more technical roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g3z8h", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g3z8h/do_junior_analysts_new_grad_get_more_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10g3z8h/do_junior_analysts_new_grad_get_more_technical/", "subreddit_subscribers": 838812, "created_utc": 1674140801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vlm3e49r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Salon Austin | Register now for Feb 21-22, 2023!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10fyupe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wls6_Lc4I1XIBWBgl5NfQobRNmZhG6aLcStotOI4LNc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674125846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datascience.salon", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datascience.salon/austin/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?auto=webp&amp;v=enabled&amp;s=2fd8c0e478cb9db2c05fbca52559891591cfe300", "width": 1200, "height": 670}, "resolutions": [{"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dca0e3e54d0b037b61613847f2caa12f5e034d6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7229982904622376093f7e92e6b9399f51a4d881", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6605f57a687eb2623dd4c60ac8d60e95dc9f2af5", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d21924108f47c6a57b54ce3b725785f581e7f34", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b478f1cd733d03ca972e865e83703fa3a0e163d", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/cn1wUNwkDY83ip49vAi2jx_IPY0GFGDiycx8O40SZ3E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5873d821c6a745e043daadb2293b6fcf09f86ec7", "width": 1080, "height": 603}], "variants": {}, "id": "u-QSdfxHRPV2o-l4U7jIJLvih6on5ZBhyFxrZNNxcaU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fyupe", "is_robot_indexable": true, "report_reasons": null, "author": "DataStjepan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fyupe/data_science_salon_austin_register_now_for_feb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datascience.salon/austin/", "subreddit_subscribers": 838812, "created_utc": 1674125846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Luckily, my employer has a program that will pay for 100% of a masters degree (I have an unrelated bachelors degree). Unfortunately, none of the options of degrees are for CS, CE or SWE. I am assuming that I am better off choosing one of these degrees and finding a way to become a SWE rather than paying/taking out loans just so that my masters degree says CS on it. As such, out of these two which would be a better pick? I keep seeing that DS likely has more crossover but the CIS degree happens to have 9 credits of specialization in which I can chose \u201csoftware development\u201d. TYIA.", "author_fullname": "t2_rt8wg1hc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science or Computer Information Systems Degree for SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fvjs9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674112936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Luckily, my employer has a program that will pay for 100% of a masters degree (I have an unrelated bachelors degree). Unfortunately, none of the options of degrees are for CS, CE or SWE. I am assuming that I am better off choosing one of these degrees and finding a way to become a SWE rather than paying/taking out loans just so that my masters degree says CS on it. As such, out of these two which would be a better pick? I keep seeing that DS likely has more crossover but the CIS degree happens to have 9 credits of specialization in which I can chose \u201csoftware development\u201d. TYIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fvjs9", "is_robot_indexable": true, "report_reasons": null, "author": "Cheesy-Royale", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fvjs9/data_science_or_computer_information_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fvjs9/data_science_or_computer_information_systems/", "subreddit_subscribers": 838812, "created_utc": 1674112936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to apply a set of data transformations automatically. Split columns, apply a formula, etc; Ideally, in excel. How could I \u201ccopy paste\u201d the method? \n\nIf not excel, is there another program to use? \n\nThanks", "author_fullname": "t2_2f2zz72s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apply transformations automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fs7q3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674101924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to apply a set of data transformations automatically. Split columns, apply a formula, etc; Ideally, in excel. How could I \u201ccopy paste\u201d the method? &lt;/p&gt;\n\n&lt;p&gt;If not excel, is there another program to use? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fs7q3", "is_robot_indexable": true, "report_reasons": null, "author": "anon67543", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fs7q3/apply_transformations_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fs7q3/apply_transformations_automatically/", "subreddit_subscribers": 838812, "created_utc": 1674101924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title\n\nI'm currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I'm developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB's to Azure and add them to elastic pools - nothing crazy.\n\nI'm currently working on my MS in DS while working full time. It's quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp; Finance.\n\nI've been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I'm extremely interested in and I was ecstatic to find out I got an interview. Below are the general job duties:\n\n* Identifying and implementing optimal cloud-based solutions, including team education and training\n* Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance\n* Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science\n* Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures\n* Orchestrating and automating cloud operations and processes\n* Collaborating with stakeholders across the business to balance competing objectives\n* Working with third-party vendors to meet business requirements.\n\nAs I mentioned before, I don't have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide's, but nothing in terms of actual development.\n\nI had my first interview yesterday as a general screening to see my fit for the role and I think it went very well. I answered everything honestly and my resume doesn't make it seem like I'm more qualified than I actually am.\n\nToday I received multiple calls from the company asking if I saw their email and if I had time for a second interview today. The hiring manager told me their emails sometimes end up in spam/junk folders - which is exactly where it ended up. Long story short, I have another interview in 3 hours. I knew after yesterdays interview that they were very interested based on our conversations.\n\nHypothetically - lets say they give me an offer:\n\n* Firstly, does it seem like I have imposter syndrome? I worry that I'm just not qualified for this job and I won't deliver what they expect\n* Do I continue my MS if I'm getting legitimate experience as a Cloud Engineer?\n* If I do continue my MS, am I going to be able to manage the workload with this new role?\n* The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?\n\nThank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Crisis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10gbid4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674158319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I&amp;#39;m developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB&amp;#39;s to Azure and add them to elastic pools - nothing crazy.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on my MS in DS while working full time. It&amp;#39;s quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp;amp; Finance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I&amp;#39;m extremely interested in and I was ecstatic to find out I got an interview. Below are the general job duties:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identifying and implementing optimal cloud-based solutions, including team education and training&lt;/li&gt;\n&lt;li&gt;Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance&lt;/li&gt;\n&lt;li&gt;Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science&lt;/li&gt;\n&lt;li&gt;Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures&lt;/li&gt;\n&lt;li&gt;Orchestrating and automating cloud operations and processes&lt;/li&gt;\n&lt;li&gt;Collaborating with stakeholders across the business to balance competing objectives&lt;/li&gt;\n&lt;li&gt;Working with third-party vendors to meet business requirements.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As I mentioned before, I don&amp;#39;t have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide&amp;#39;s, but nothing in terms of actual development.&lt;/p&gt;\n\n&lt;p&gt;I had my first interview yesterday as a general screening to see my fit for the role and I think it went very well. I answered everything honestly and my resume doesn&amp;#39;t make it seem like I&amp;#39;m more qualified than I actually am.&lt;/p&gt;\n\n&lt;p&gt;Today I received multiple calls from the company asking if I saw their email and if I had time for a second interview today. The hiring manager told me their emails sometimes end up in spam/junk folders - which is exactly where it ended up. Long story short, I have another interview in 3 hours. I knew after yesterdays interview that they were very interested based on our conversations.&lt;/p&gt;\n\n&lt;p&gt;Hypothetically - lets say they give me an offer:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Firstly, does it seem like I have imposter syndrome? I worry that I&amp;#39;m just not qualified for this job and I won&amp;#39;t deliver what they expect&lt;/li&gt;\n&lt;li&gt;Do I continue my MS if I&amp;#39;m getting legitimate experience as a Cloud Engineer?&lt;/li&gt;\n&lt;li&gt;If I do continue my MS, am I going to be able to manage the workload with this new role?&lt;/li&gt;\n&lt;li&gt;The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10gbid4", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gbid4/career_crisis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gbid4/career_crisis/", "subreddit_subscribers": 838812, "created_utc": 1674158319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I just graduated with a Masters in CS with a 3.8 over a month ago and have been applying for work all over only to fall on the \"3 years for entry level\" bullshit that hiring people think it's more important than my 6 years CS of university studying. I have done a pay GA a count that as work experience and from my university's career services say my resume is solid. \n\nEdit: I don't mean to sound entitled. This is just a background of my situation. Please focus on the company in question.\n\nI got a chance at smoothstack. Who says that they can help but offer $60k year 1 and $70k year 2. I feel on the fence since they offer this also to people with Bachelors degrees and boot camp graduates, which feels belittling honestly for someone who has a Masters. I also hear mix reviews about them, but one of a guy in his car saying it wasn't worth it, and better to do an internship, because they lock you in a 2 year contract and you have to pay a large fee yo exit it. So it sounds like a scam, but I don't know. \n\nShould I go for it or pass and keep looking?\n\nEdit: I focused on AI and Data Science during my Masters if you're wondering why I posted this in the subreddit.", "author_fullname": "t2_1j7bda2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is smoothstack worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gamne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674159880.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674156247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just graduated with a Masters in CS with a 3.8 over a month ago and have been applying for work all over only to fall on the &amp;quot;3 years for entry level&amp;quot; bullshit that hiring people think it&amp;#39;s more important than my 6 years CS of university studying. I have done a pay GA a count that as work experience and from my university&amp;#39;s career services say my resume is solid. &lt;/p&gt;\n\n&lt;p&gt;Edit: I don&amp;#39;t mean to sound entitled. This is just a background of my situation. Please focus on the company in question.&lt;/p&gt;\n\n&lt;p&gt;I got a chance at smoothstack. Who says that they can help but offer $60k year 1 and $70k year 2. I feel on the fence since they offer this also to people with Bachelors degrees and boot camp graduates, which feels belittling honestly for someone who has a Masters. I also hear mix reviews about them, but one of a guy in his car saying it wasn&amp;#39;t worth it, and better to do an internship, because they lock you in a 2 year contract and you have to pay a large fee yo exit it. So it sounds like a scam, but I don&amp;#39;t know. &lt;/p&gt;\n\n&lt;p&gt;Should I go for it or pass and keep looking?&lt;/p&gt;\n\n&lt;p&gt;Edit: I focused on AI and Data Science during my Masters if you&amp;#39;re wondering why I posted this in the subreddit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10gamne", "is_robot_indexable": true, "report_reasons": null, "author": "CrunchyAl", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10gamne/is_smoothstack_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10gamne/is_smoothstack_worth_it/", "subreddit_subscribers": 838812, "created_utc": 1674156247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3zq1qeno", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some questions to anticipate for an entry level data analyst phone screen interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g765q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674148347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10g765q", "is_robot_indexable": true, "report_reasons": null, "author": "dontcry2022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g765q/what_are_some_questions_to_anticipate_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10g765q/what_are_some_questions_to_anticipate_for_an/", "subreddit_subscribers": 838812, "created_utc": 1674148347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ppqk0e3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing a Single SQLite Query to mimic a R program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10g4rcd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w4sz0v2GYVqgPewnjZsgRjzJkTlzFpUsew4M8esOr9w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674142706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stackoverflow.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://stackoverflow.com/questions/75174575/writing-a-single-sqlite-query-to-mimic-an-r-program", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g4rcd", "is_robot_indexable": true, "report_reasons": null, "author": "Kamal_Ata_Turk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g4rcd/writing_a_single_sqlite_query_to_mimic_a_r_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stackoverflow.com/questions/75174575/writing-a-single-sqlite-query-to-mimic-an-r-program", "subreddit_subscribers": 838812, "created_utc": 1674142706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Of all the states of a DS project, I seemed to enjoy modelling and it's subsequent deployment, monitoring etc. the most. I don't think fresh grads are taken for this role. So what do you think will be ideal for me to start my career with if I ultimately aim to go in that direction? \n\n\nData Engineering- Is practically software engineering working with data. Also will know the data really well. May have some Spark, SQL and Cloud experience which will come in handy.\n\nBackend Developer- Is fine with me but I have zero interest in frontend and it's hard to get only backend jobs (that too in Flask/Django). Also fear that ultimately will move away from my ML career.\n\nData Analyst- Don't think this is optimal. Correct me if I'm wrong.\n\nThese are all my understandings. Please share your more experienced ones.\n\n\nI can't become a Data Scientist now because practically all job listings require a Masters' which I can't pursue due to financial and time constraints now.\n\nThank you.", "author_fullname": "t2_5wcskabr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which career to start with if I love the deployment aspects of models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g2l5j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674137273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Of all the states of a DS project, I seemed to enjoy modelling and it&amp;#39;s subsequent deployment, monitoring etc. the most. I don&amp;#39;t think fresh grads are taken for this role. So what do you think will be ideal for me to start my career with if I ultimately aim to go in that direction? &lt;/p&gt;\n\n&lt;p&gt;Data Engineering- Is practically software engineering working with data. Also will know the data really well. May have some Spark, SQL and Cloud experience which will come in handy.&lt;/p&gt;\n\n&lt;p&gt;Backend Developer- Is fine with me but I have zero interest in frontend and it&amp;#39;s hard to get only backend jobs (that too in Flask/Django). Also fear that ultimately will move away from my ML career.&lt;/p&gt;\n\n&lt;p&gt;Data Analyst- Don&amp;#39;t think this is optimal. Correct me if I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;These are all my understandings. Please share your more experienced ones.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t become a Data Scientist now because practically all job listings require a Masters&amp;#39; which I can&amp;#39;t pursue due to financial and time constraints now.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g2l5j", "is_robot_indexable": true, "report_reasons": null, "author": "debadri3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g2l5j/which_career_to_start_with_if_i_love_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10g2l5j/which_career_to_start_with_if_i_love_the/", "subreddit_subscribers": 838812, "created_utc": 1674137273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_u4lyl0qh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Data Science Trends and Predictions 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10g27ch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674136274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "uk.sganalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://uk.sganalytics.com//blog/top-data-science-trends-and-predictions/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10g27ch", "is_robot_indexable": true, "report_reasons": null, "author": "Sanskar250", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10g27ch/current_data_science_trends_and_predictions_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://uk.sganalytics.com//blog/top-data-science-trends-and-predictions/", "subreddit_subscribers": 838812, "created_utc": 1674136274.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}