{"kind": "Listing", "data": {"after": "t3_10fjnz2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h9ygk2wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is this for a Data Analysis roadmap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmj6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 185, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 185, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CVmsTgeCjiTuwbp3XPCXFPFEMmz8ogdpelYhXQi6ON4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674086133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0wl7i4x14wca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?auto=webp&amp;v=enabled&amp;s=4e053d88c9aad550b5b92153b2a30f526a81a663", "width": 1440, "height": 754}, "resolutions": [{"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=202ee5909ec768da1be94892f4e1555c8939f14d", "width": 108, "height": 56}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daa27539712a8597401d7f83b814f58822fd7d35", "width": 216, "height": 113}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c5453eed46a24f3adf33d8a029df2f2dfa80471", "width": 320, "height": 167}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a79a968d69f5942597a397c4afeb0e21b91f80d7", "width": 640, "height": 335}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33bf8700cd92470cb36f4ba6d802460adf8b4a59", "width": 960, "height": 502}, {"url": "https://preview.redd.it/0wl7i4x14wca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39e6ef9951cfc2e4046f016f695e1f5b42ef0dc1", "width": 1080, "height": 565}], "variants": {}, "id": "IQ-0tJHyd9OWcCBUyAQ1UCwHV7rpRHVyuIpGGo3o1Z8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmj6h", "is_robot_indexable": true, "report_reasons": null, "author": "twenni7", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmj6h/how_is_this_for_a_data_analysis_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0wl7i4x14wca1.jpg", "subreddit_subscribers": 838631, "created_utc": 1674086133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If the only other programming language that I know is python, then how much SQL do I need to be good at which would be sufficient for a entry level job in any data science role?", "author_fullname": "t2_l9s40z26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much SQL do I need to know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fci6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674061422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If the only other programming language that I know is python, then how much SQL do I need to be good at which would be sufficient for a entry level job in any data science role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fci6c", "is_robot_indexable": true, "report_reasons": null, "author": "SpottedDickEater", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fci6c/how_much_sql_do_i_need_to_know/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fci6c/how_much_sql_do_i_need_to_know/", "subreddit_subscribers": 838631, "created_utc": 1674061422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Expected to see atleast a few posts about layoffs at Amazon and Microsoft that happened today...?\n\nI was one of them, laid off from Amazon after 2.5 years there. Anybody else here in the same boat?\n\nAnyway iv been thinking about how this all went down and what is do differently to future proof my careers.. will share a longer post tomorrow. Today's been a long day.", "author_fullname": "t2_4m1ivn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "layoffs at big tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fv6hv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674111578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Expected to see atleast a few posts about layoffs at Amazon and Microsoft that happened today...?&lt;/p&gt;\n\n&lt;p&gt;I was one of them, laid off from Amazon after 2.5 years there. Anybody else here in the same boat?&lt;/p&gt;\n\n&lt;p&gt;Anyway iv been thinking about how this all went down and what is do differently to future proof my careers.. will share a longer post tomorrow. Today&amp;#39;s been a long day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fv6hv", "is_robot_indexable": true, "report_reasons": null, "author": "sang89", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fv6hv/layoffs_at_big_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fv6hv/layoffs_at_big_tech/", "subreddit_subscribers": 838631, "created_utc": 1674111578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vhx54ulr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving direct text extraction from PDFs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmi2u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P-TF2fexSPks2f7mLdY-R1tDKddDsv87LN-bTZuP4Eo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674086053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "sensible.so", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.sensible.so/blog/solving-direct-text-extraction-from-pdfs?utm_campaign=Data%20Science&amp;utm_source=reddit&amp;utm_medium=paidsocial&amp;utm_content=post", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?auto=webp&amp;v=enabled&amp;s=e63d76bee822e8077be465dcebe1406f781cf370", "width": 3148, "height": 1967}, "resolutions": [{"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6938ffe2c20efc56e04e354ab6ecb745b4f47617", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb3e88f1a86f8820cac1fb235a9a06bd1a6dfc31", "width": 216, "height": 134}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2988fabb4a01426faa97da84861dc60e4bf9c52", "width": 320, "height": 199}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf53dfb477c0af4ca3f741b98fe9bb8db0565fd0", "width": 640, "height": 399}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=127413c342534d75fa591a60fd69ea21dbbbdf38", "width": 960, "height": 599}, {"url": "https://external-preview.redd.it/QINO6Yi2aZa8WtTVpQeCSu4TF42Ku9GCInm354sHZss.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37eba81e2007ca7a887e5961e8ae7f873f319332", "width": 1080, "height": 674}], "variants": {}, "id": "ew5_lxhvSkLjVhIJzdo-GYDgbVhhT5z3DNOKS5rmLUs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmi2u", "is_robot_indexable": true, "report_reasons": null, "author": "usesensible", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmi2u/solving_direct_text_extraction_from_pdfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.sensible.so/blog/solving-direct-text-extraction-from-pdfs?utm_campaign=Data%20Science&amp;utm_source=reddit&amp;utm_medium=paidsocial&amp;utm_content=post", "subreddit_subscribers": 838631, "created_utc": 1674086053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The more and more I apply, the more I see \u201centry level\u201d roles in data analytics are in fact not entry level and usually need, at a minimum, 1 year of experience. That said, what actual entry level roles are good to start in that have good opportunities for moving into data analytics? (Other than data entry)", "author_fullname": "t2_16n8a1d7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Entry Level Roles are Good for Bridging Into Data Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fn4bo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674087606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The more and more I apply, the more I see \u201centry level\u201d roles in data analytics are in fact not entry level and usually need, at a minimum, 1 year of experience. That said, what actual entry level roles are good to start in that have good opportunities for moving into data analytics? (Other than data entry)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10fn4bo", "is_robot_indexable": true, "report_reasons": null, "author": "jordanar189", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fn4bo/what_entry_level_roles_are_good_for_bridging_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fn4bo/what_entry_level_roles_are_good_for_bridging_into/", "subreddit_subscribers": 838631, "created_utc": 1674087606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been doing some work with a startup for a few years now...paid hourly at $60/hr, but not many hours as I'm pretty fast and the work I'd easy. Now the opportunity has come up for me to work for equity rather than a wage. They will likely offer 1% or 2%. Similar companies have sold for between $10M and $20M. I'm wondering if anyone here has done something similar, if you have any tips/suggestions, if you know how it would work with a buyout, and anything else if think I should know. From my simple perspective if I had 1% and it sold for $20M that would be $200k (which is about my TC in my regular job). Don't get me wrong $200k is a good chunk of change, but it's also not guaranteed and I might not paid until anywhere from a year from now to ten years from now. This company cannot be the next twitter or Facebook or anything so o think the $20M valuation is probably the max. \n\n\nAny advice is appreciated\n\nEdit...also to clarify confusion the alternative is not a full time salary at $60/hr. That's the wage I make doing work for the company--it is contract work now and it is not my primary job. I suspect I would work about 400 hr/year for equity or 300 hr/yr paid", "author_fullname": "t2_aa663", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working for equity instead of salary/wage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fajje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1674061913.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674056805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing some work with a startup for a few years now...paid hourly at $60/hr, but not many hours as I&amp;#39;m pretty fast and the work I&amp;#39;d easy. Now the opportunity has come up for me to work for equity rather than a wage. They will likely offer 1% or 2%. Similar companies have sold for between $10M and $20M. I&amp;#39;m wondering if anyone here has done something similar, if you have any tips/suggestions, if you know how it would work with a buyout, and anything else if think I should know. From my simple perspective if I had 1% and it sold for $20M that would be $200k (which is about my TC in my regular job). Don&amp;#39;t get me wrong $200k is a good chunk of change, but it&amp;#39;s also not guaranteed and I might not paid until anywhere from a year from now to ten years from now. This company cannot be the next twitter or Facebook or anything so o think the $20M valuation is probably the max. &lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated&lt;/p&gt;\n\n&lt;p&gt;Edit...also to clarify confusion the alternative is not a full time salary at $60/hr. That&amp;#39;s the wage I make doing work for the company--it is contract work now and it is not my primary job. I suspect I would work about 400 hr/year for equity or 300 hr/yr paid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fajje", "is_robot_indexable": true, "report_reasons": null, "author": "PBandJammm", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fajje/working_for_equity_instead_of_salarywage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fajje/working_for_equity_instead_of_salarywage/", "subreddit_subscribers": 838631, "created_utc": 1674056805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If so, I would like to hear about your journey. I\u2019m a 3rd year medical student in the US and trying to find out as much information as I can about a possible transition into DS.", "author_fullname": "t2_39s7scwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone made the switch from medicine to DS and are successful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fh9yp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674072528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so, I would like to hear about your journey. I\u2019m a 3rd year medical student in the US and trying to find out as much information as I can about a possible transition into DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fh9yp", "is_robot_indexable": true, "report_reasons": null, "author": "ImaCPAMD", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fh9yp/has_anyone_made_the_switch_from_medicine_to_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fh9yp/has_anyone_made_the_switch_from_medicine_to_ds/", "subreddit_subscribers": 838631, "created_utc": 1674072528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title", "author_fullname": "t2_rc5lfgnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone here transitioned from Data Scientist to Data Engineer? What was your motivation, and do you regret the move now, or are you happier as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fpmi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674094398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fpmi2", "is_robot_indexable": true, "report_reasons": null, "author": "Subject_Ad_9680", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fpmi2/has_anyone_here_transitioned_from_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fpmi2/has_anyone_here_transitioned_from_data_scientist/", "subreddit_subscribers": 838631, "created_utc": 1674094398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Recently while doing an analysis on a practice project I noticed some features were too highly correlated after I engineered them. To my understanding, if features are too highly correlated, they might hinder a model\u2019s performance (since they look more like dependent than independent variables).\n\nSince learning about feature engineering, I\u2019ve had the intuition somehow there\u2019s a way feature engineering can cause collinearity between the created variables and the existing ones if certain principles aren\u2019t considered. But I haven\u2019t been able to identify under which circumstances.\n\nThe background or question itself might be wrong, but: is there a way feature engineering could cause collinearity? If so, how can this happen and how to avoid it?", "author_fullname": "t2_74oj0fqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could feature engineering cause collinearity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fh30i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674072063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently while doing an analysis on a practice project I noticed some features were too highly correlated after I engineered them. To my understanding, if features are too highly correlated, they might hinder a model\u2019s performance (since they look more like dependent than independent variables).&lt;/p&gt;\n\n&lt;p&gt;Since learning about feature engineering, I\u2019ve had the intuition somehow there\u2019s a way feature engineering can cause collinearity between the created variables and the existing ones if certain principles aren\u2019t considered. But I haven\u2019t been able to identify under which circumstances.&lt;/p&gt;\n\n&lt;p&gt;The background or question itself might be wrong, but: is there a way feature engineering could cause collinearity? If so, how can this happen and how to avoid it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fh30i", "is_robot_indexable": true, "report_reasons": null, "author": "marco_camilo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fh30i/could_feature_engineering_cause_collinearity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fh30i/could_feature_engineering_cause_collinearity/", "subreddit_subscribers": 838631, "created_utc": 1674072063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_i049nix9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have good resources for applications of data science for sports betting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fmdk3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674085733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fmdk3", "is_robot_indexable": true, "report_reasons": null, "author": "vizualizing123", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fmdk3/anyone_have_good_resources_for_applications_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fmdk3/anyone_have_good_resources_for_applications_of/", "subreddit_subscribers": 838631, "created_utc": 1674085733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812)\n\nThe rumor mill is buzzing around the release of GPT-4.\n\nPeople are predicting the model will have 100 trillion parameters. That\u2019s a *trillion* with a \u201ct\u201d.\n\nThe often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.\n\nSure, OpenAI\u2019s new brainchild will certainly be mind-bending and language models have been getting bigger \u2014 fast!\n\nBut this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).\n\n*Let\u2019s go!*\n\nTraining 100 Trillion Parameters\n\nThe creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \\[1\\].\n\nTraining a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.\n\nSo, where is this rumor coming from?\n\nThe Source Of The Rumor:\n\nIt turns out OpenAI itself might be the source of it.\n\nIn August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): \u201cFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters\u201d.\n\nA the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.\n\nThings have changed a lot since then!\n\nTo understand what happened we first need to look at how people decide the number of parameters in a model.\n\nDeciding The Number Of Parameters:\n\nThe enormous hunger for resources typically makes it feasible to train an LLM only once.\n\nIn practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.\n\n*But there\u2019s a catch!*\n\nMost research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.\n\nWith LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.\n\nTherefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.\n\nThis process can very noisy and the community\u2019s understanding has evolved a lot over the last few years.\n\nWhat People Used To Think About Scaling LLMs\n\nIn 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: \u201cScaling Laws For Neural Language Models\u201d.\n\nThey observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.\n\nSo far so good. But they made two other observations, which resulted in the model size ballooning rapidly.\n\n1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.\n2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.\n\nHence, it seemed as if the way to improve performance was to scale models faster than the dataset size \\[2\\].\n\nAnd that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.\n\nBut the bigger models failed to deliver on the promise.\n\n*Read on to learn why!*\n\nWhat We know About Scaling Models Today\n\nIt turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.\n\nThis was published in DeepMind\u2019s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): \u201cTraining Compute-Optimal Large Language Models\u201d\n\nThe researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.\n\nThe findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.\n\nTo verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.\n\nChinchilla outperforms GPT-3 and other much larger models by a fair margin \\[3\\].\n\nThis was a great breakthrough!  \nThe model is not just better, but its smaller size makes inference cheaper and finetuning easier.\n\n*So What Will Happen?*\n\nWhat GPT-4 Might Look Like:\n\nTo properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \\[1\\].\n\nSo, here is what GPT-4 could look like:\n\n* Similar size to GPT-3, but trained optimally on 10x more data\n* \u200b[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound\n* Output conditioned on document chunks from a memory bank that the model has access to during prediction \\[4\\]\n* Doubled context size allows longer predictions before the model starts going off the rails\u200b\n\nRegardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.\n\nWhatever it will look like, I am sure it will be amazing and we can all be excited about the release.\n\nSuch exciting times to be alive!\n\nAs always, I really enjoyed making this for you and I sincerely hope you found it useful!\n\nWould you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** \u2b55.\n\nI send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)\n\n**References:**\n\n\\[1\\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21\n\n\\[2\\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,\u2026 &amp; D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint\n\n\\[3\\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.\n\n\\[4\\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver", "author_fullname": "t2_az3v2qdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 Will Be 500x Smaller Than People Think - Here Is Why", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": true, "media_metadata": {"t6m0epzlgyca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0a29a7b132523bf64a92a5debe78d843d581ab7"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d79bbd9721656b1fa4b174c903bd2c193b57d71"}, {"y": 199, "x": 320, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d6def614c56adebf27b9024ce78effd4d8986ce"}], "s": {"y": 358, "x": 575, "u": "https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812"}, "id": "t6m0epzlgyca1"}}, "name": "t3_10fw1a3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/U1lIevxBGm-047N-NNsz6n_Uj8HJ9catEG1qKavgd_0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674114864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t6m0epzlgyca1.png?width=575&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812\"&gt;Number Of Parameters GPT-3 vs. GPT-4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The rumor mill is buzzing around the release of GPT-4.&lt;/p&gt;\n\n&lt;p&gt;People are predicting the model will have 100 trillion parameters. That\u2019s a &lt;em&gt;trillion&lt;/em&gt; with a \u201ct\u201d.&lt;/p&gt;\n\n&lt;p&gt;The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.&lt;/p&gt;\n\n&lt;p&gt;Sure, OpenAI\u2019s new brainchild will certainly be mind-bending and language models have been getting bigger \u2014 fast!&lt;/p&gt;\n\n&lt;p&gt;But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Let\u2019s go!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Training 100 Trillion Parameters&lt;/p&gt;\n\n&lt;p&gt;The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone [1].&lt;/p&gt;\n\n&lt;p&gt;Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.&lt;/p&gt;\n\n&lt;p&gt;So, where is this rumor coming from?&lt;/p&gt;\n\n&lt;p&gt;The Source Of The Rumor:&lt;/p&gt;\n\n&lt;p&gt;It turns out OpenAI itself might be the source of it.&lt;/p&gt;\n\n&lt;p&gt;In August 2021 the CEO of Cerebras told &lt;a href=\"https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/\"&gt;wired&lt;/a&gt;: \u201cFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters\u201d.&lt;/p&gt;\n\n&lt;p&gt;A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.&lt;/p&gt;\n\n&lt;p&gt;Things have changed a lot since then!&lt;/p&gt;\n\n&lt;p&gt;To understand what happened we first need to look at how people decide the number of parameters in a model.&lt;/p&gt;\n\n&lt;p&gt;Deciding The Number Of Parameters:&lt;/p&gt;\n\n&lt;p&gt;The enormous hunger for resources typically makes it feasible to train an LLM only once.&lt;/p&gt;\n\n&lt;p&gt;In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;But there\u2019s a catch!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.&lt;/p&gt;\n\n&lt;p&gt;With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.&lt;/p&gt;\n\n&lt;p&gt;Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.&lt;/p&gt;\n\n&lt;p&gt;This process can very noisy and the community\u2019s understanding has evolved a lot over the last few years.&lt;/p&gt;\n\n&lt;p&gt;What People Used To Think About Scaling LLMs&lt;/p&gt;\n\n&lt;p&gt;In 2020, a team of researchers from OpenAI released a &lt;a href=\"https://arxiv.org/pdf/2001.08361.pdf\"&gt;paper&lt;/a&gt; called: \u201cScaling Laws For Neural Language Models\u201d.&lt;/p&gt;\n\n&lt;p&gt;They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.&lt;/p&gt;\n\n&lt;p&gt;So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.&lt;/li&gt;\n&lt;li&gt;Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size [2].&lt;/p&gt;\n\n&lt;p&gt;And that is what people did. The models got larger and larger with GPT-3 (175B), &lt;a href=\"https://arxiv.org/pdf/2112.11446.pdf\"&gt;Gopher&lt;/a&gt; (280B), &lt;a href=\"https://arxiv.org/pdf/2201.11990\"&gt;Megatron-Turing NLG&lt;/a&gt; (530B) just to name a few.&lt;/p&gt;\n\n&lt;p&gt;But the bigger models failed to deliver on the promise.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Read on to learn why!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;What We know About Scaling Models Today&lt;/p&gt;\n\n&lt;p&gt;It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.&lt;/p&gt;\n\n&lt;p&gt;This was published in DeepMind\u2019s 2022 &lt;a href=\"https://arxiv.org/pdf/2203.15556.pdf\"&gt;paper&lt;/a&gt;: \u201cTraining Compute-Optimal Large Language Models\u201d&lt;/p&gt;\n\n&lt;p&gt;The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.&lt;/p&gt;\n\n&lt;p&gt;The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.&lt;/p&gt;\n\n&lt;p&gt;To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.&lt;/p&gt;\n\n&lt;p&gt;Chinchilla outperforms GPT-3 and other much larger models by a fair margin [3].&lt;/p&gt;\n\n&lt;p&gt;This was a great breakthrough!&lt;br/&gt;\nThe model is not just better, but its smaller size makes inference cheaper and finetuning easier.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;So What Will Happen?&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;What GPT-4 Might Look Like:&lt;/p&gt;\n\n&lt;p&gt;To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model [1].&lt;/p&gt;\n\n&lt;p&gt;So, here is what GPT-4 could look like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Similar size to GPT-3, but trained optimally on 10x more data&lt;/li&gt;\n&lt;li&gt;\u200b&lt;a href=\"https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley\"&gt;Multi-modal&lt;/a&gt; outputting text, images, and sound&lt;/li&gt;\n&lt;li&gt;Output conditioned on document chunks from a memory bank that the model has access to during prediction [4]&lt;/li&gt;\n&lt;li&gt;Doubled context size allows longer predictions before the model starts going off the rails\u200b&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.&lt;/p&gt;\n\n&lt;p&gt;Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.&lt;/p&gt;\n\n&lt;p&gt;Such exciting times to be alive!&lt;/p&gt;\n\n&lt;p&gt;As always, I really enjoyed making this for you and I sincerely hope you found it useful!&lt;/p&gt;\n\n&lt;p&gt;Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for &lt;strong&gt;The Decoding&lt;/strong&gt; \u2b55.&lt;/p&gt;\n\n&lt;p&gt;I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. &lt;a href=\"https://thedecoding.net/\"&gt;Click here to sign up!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;[1] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, &lt;a href=\"https://arxiv.org/abs/2104.04473\"&gt;Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM&lt;/a&gt; (2021), SC21&lt;/p&gt;\n\n&lt;p&gt;[2] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,\u2026 &amp;amp; D. Amodei, &lt;a href=\"https://arxiv.org/abs/2001.08361\"&gt;Scaling laws for neural language model&lt;/a&gt;s (2020), arxiv preprint&lt;/p&gt;\n\n&lt;p&gt;[3] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, &lt;a href=\"https://arxiv.org/abs/2203.15556\"&gt;Training Compute-Optimal Large Language Models&lt;/a&gt; (2022). &lt;em&gt;arXiv preprint arXiv:2203.15556&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;[4] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, &lt;a href=\"https://arxiv.org/abs/2112.04426\"&gt;Improving language models by retrieving from trillions of tokens&lt;/a&gt; (2021). &lt;em&gt;arXiv preprint arXiv:2112.04426&lt;/em&gt;.Vancouver&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fw1a3", "is_robot_indexable": true, "report_reasons": null, "author": "LesleyFair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fw1a3/gpt4_will_be_500x_smaller_than_people_think_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fw1a3/gpt4_will_be_500x_smaller_than_people_think_here/", "subreddit_subscribers": 838631, "created_utc": 1674114864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to apply a set of data transformations automatically. Split columns, apply a formula, etc; Ideally, in excel. How could I \u201ccopy paste\u201d the method? \n\nIf not excel, is there another program to use? \n\nThanks", "author_fullname": "t2_2f2zz72s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apply transformations automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fs7q3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674101924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to apply a set of data transformations automatically. Split columns, apply a formula, etc; Ideally, in excel. How could I \u201ccopy paste\u201d the method? &lt;/p&gt;\n\n&lt;p&gt;If not excel, is there another program to use? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fs7q3", "is_robot_indexable": true, "report_reasons": null, "author": "anon67543", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fs7q3/apply_transformations_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fs7q3/apply_transformations_automatically/", "subreddit_subscribers": 838631, "created_utc": 1674101924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I found a lot topics on reddit and in general with the title \"R vs Python\", which one should I choose / learn / stick with etc.\n\nI learned both languages and used per project always one of them. However I wonder how much of you use for a single project both languages? To be more concrete:\n\n* **R** for the whole cleaning, preprocessing and explorative data analysis part (and nice ggplots). Also for feature engineering and feature selection.\n* **Python** for everything that follows: Machine learning model training, tuning, evaluating and deploying.\n\nWhy R for the preprocessing, EDA and feature engineering? -&gt; Because working with tidyverse + ggplot is really fast and nice. I'm much more quicker than with Pandas/Matplotlib/Seaborn. Statistical functions are pretty good supported there. Also generating PDF/HTML reports work well.\n\nWhy Python for everything else? -&gt; Because ML like Deep Learning has better support there. Also the deploying part (APIs etc.) are better supported in terms of libraries/frameworks etc.\n\n[View Poll](https://www.reddit.com/poll/10fk64d)", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use R for EDA and Python for machine learning + deploying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fk64d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674080343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a lot topics on reddit and in general with the title &amp;quot;R vs Python&amp;quot;, which one should I choose / learn / stick with etc.&lt;/p&gt;\n\n&lt;p&gt;I learned both languages and used per project always one of them. However I wonder how much of you use for a single project both languages? To be more concrete:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;R&lt;/strong&gt; for the whole cleaning, preprocessing and explorative data analysis part (and nice ggplots). Also for feature engineering and feature selection.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; for everything that follows: Machine learning model training, tuning, evaluating and deploying.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Why R for the preprocessing, EDA and feature engineering? -&amp;gt; Because working with tidyverse + ggplot is really fast and nice. I&amp;#39;m much more quicker than with Pandas/Matplotlib/Seaborn. Statistical functions are pretty good supported there. Also generating PDF/HTML reports work well.&lt;/p&gt;\n\n&lt;p&gt;Why Python for everything else? -&amp;gt; Because ML like Deep Learning has better support there. Also the deploying part (APIs etc.) are better supported in terms of libraries/frameworks etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10fk64d\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "10fk64d", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674339543370, "options": [{"text": "R only", "id": "21097469"}, {"text": "Python only", "id": "21097470"}, {"text": "R for EDA and Python afterwards", "id": "21097471"}, {"text": "Other. See comment...", "id": "21097472"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 383, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fk64d/do_you_use_r_for_eda_and_python_for_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/10fk64d/do_you_use_r_for_eda_and_python_for_machine/", "subreddit_subscribers": 838631, "created_utc": 1674080343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to machine learning and don't know if I should learn R or Python is enough?", "author_fullname": "t2_qsc9jb1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth learning R for machine learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ff6dw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674067569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to machine learning and don&amp;#39;t know if I should learn R or Python is enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ff6dw", "is_robot_indexable": true, "report_reasons": null, "author": "crn4t", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ff6dw/is_it_worth_learning_r_for_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ff6dw/is_it_worth_learning_r_for_machine_learning/", "subreddit_subscribers": 838631, "created_utc": 1674067569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to write a script to find unusual words or phrases in a corpus of text. The words part can be done using TF-IDF with the help of a word frequency dataset I found online. But for the phrases part, I am trying to use PMI with the help of a word collocation dataset, yet I could not find any. Any suggestions?", "author_fullname": "t2_7x4uc3sb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset for Point Mutual Information (or Similar)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fd5ge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674062911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to write a script to find unusual words or phrases in a corpus of text. The words part can be done using TF-IDF with the help of a word frequency dataset I found online. But for the phrases part, I am trying to use PMI with the help of a word collocation dataset, yet I could not find any. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fd5ge", "is_robot_indexable": true, "report_reasons": null, "author": "Ivan_Law_Kin_Chau", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fd5ge/dataset_for_point_mutual_information_or_similar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fd5ge/dataset_for_point_mutual_information_or_similar/", "subreddit_subscribers": 838631, "created_utc": 1674062911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've written to the mods but haven't heard back.\n\nThe current state seems unfinished and not up-to-date, so I'm not sure what I should make of it as a resource.\n\nAre there any posts by the mods that address the state of the FAQ? I searched but maybe I missed it.\nAlso, have there ever been plans to allow edits for all users?\n\nMany thanks.", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any plans to update the FAQ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f3yrn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674037180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve written to the mods but haven&amp;#39;t heard back.&lt;/p&gt;\n\n&lt;p&gt;The current state seems unfinished and not up-to-date, so I&amp;#39;m not sure what I should make of it as a resource.&lt;/p&gt;\n\n&lt;p&gt;Are there any posts by the mods that address the state of the FAQ? I searched but maybe I missed it.\nAlso, have there ever been plans to allow edits for all users?&lt;/p&gt;\n\n&lt;p&gt;Many thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10f3yrn", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10f3yrn/are_there_any_plans_to_update_the_faq/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10f3yrn/are_there_any_plans_to_update_the_faq/", "subreddit_subscribers": 838631, "created_utc": 1674037180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Luckily, my employer has a program that will pay for 100% of a masters degree (I have an unrelated bachelors degree). Unfortunately, none of the options of degrees are for CS, CE or SWE. I am assuming that I am better off choosing one of these degrees and finding a way to become a SWE rather than paying/taking out loans just so that my masters degree says CS on it. As such, out of these two which would be a better pick? I keep seeing that DS likely has more crossover but the CIS degree happens to have 9 credits of specialization in which I can chose \u201csoftware development\u201d. TYIA.", "author_fullname": "t2_rt8wg1hc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science or Computer Information Systems Degree for SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fvjs9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674112936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Luckily, my employer has a program that will pay for 100% of a masters degree (I have an unrelated bachelors degree). Unfortunately, none of the options of degrees are for CS, CE or SWE. I am assuming that I am better off choosing one of these degrees and finding a way to become a SWE rather than paying/taking out loans just so that my masters degree says CS on it. As such, out of these two which would be a better pick? I keep seeing that DS likely has more crossover but the CIS degree happens to have 9 credits of specialization in which I can chose \u201csoftware development\u201d. TYIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fvjs9", "is_robot_indexable": true, "report_reasons": null, "author": "Cheesy-Royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fvjs9/data_science_or_computer_information_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fvjs9/data_science_or_computer_information_systems/", "subreddit_subscribers": 838631, "created_utc": 1674112936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, does anyone here have any experience working in consulting?\n\n- does consulting for a big or small company have an affect on work environment?\n\n- do you work on challenging/interesting projects?\n\n\n- what\u2019s the pay like compared to normal DS work?\n\n\n- would you recommend consulting for someone just starting their career?\n\n\nThanks in advance!", "author_fullname": "t2_9mx4u3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is it like to work in consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fpy9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674095302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, does anyone here have any experience working in consulting?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;does consulting for a big or small company have an affect on work environment?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;do you work on challenging/interesting projects?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;what\u2019s the pay like compared to normal DS work?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;would you recommend consulting for someone just starting their career?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fpy9m", "is_robot_indexable": true, "report_reasons": null, "author": "Vnix7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fpy9m/what_is_it_like_to_work_in_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fpy9m/what_is_it_like_to_work_in_consulting/", "subreddit_subscribers": 838631, "created_utc": 1674095302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to understand what the most common workflows and issues are in the current Data Science ecosystem so I\u2019m curious to hear what the thoughts here are. \n\nWhat do you find is the most difficult aspect of developing models? What makes it hard? Are there any tools that alleviate those problems? \n\nThanks!", "author_fullname": "t2_9z4gqfsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you find to be the hardest part in your Data Science workflows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fnpg8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674089513.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674089155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand what the most common workflows and issues are in the current Data Science ecosystem so I\u2019m curious to hear what the thoughts here are. &lt;/p&gt;\n\n&lt;p&gt;What do you find is the most difficult aspect of developing models? What makes it hard? Are there any tools that alleviate those problems? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fnpg8", "is_robot_indexable": true, "report_reasons": null, "author": "TheNovicePhilomath", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fnpg8/what_do_you_find_to_be_the_hardest_part_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fnpg8/what_do_you_find_to_be_the_hardest_part_in_your/", "subreddit_subscribers": 838631, "created_utc": 1674089155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\n&amp;#x200B;\n\nWas wondering if there are any recommended structures to approach learning SQL + Tableau to get the interview ready. What are some topics or projects that are most useful to cover?\n\nThanks in advance!", "author_fullname": "t2_iwzmmpyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning SQL and Tableau from the ground up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ffr8e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674068936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Was wondering if there are any recommended structures to approach learning SQL + Tableau to get the interview ready. What are some topics or projects that are most useful to cover?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ffr8e", "is_robot_indexable": true, "report_reasons": null, "author": "According-Essay9475", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ffr8e/learning_sql_and_tableau_from_the_ground_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ffr8e/learning_sql_and_tableau_from_the_ground_up/", "subreddit_subscribers": 838631, "created_utc": 1674068936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone \n\nI'm a bit new to python classification models, but at my job managers want a classification model to predict churn (withdrawal from an active stock of customers), but the data they provide is extremely unbalanced (97% of customers active, 3% retired customers), I'm reading about undersampling and oversampling, but in your opinion, what is the best step to deal with that type of model?", "author_fullname": "t2_ve857cgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u00bfHow to deal with extremely unbalanced classification model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fczbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674062504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit new to python classification models, but at my job managers want a classification model to predict churn (withdrawal from an active stock of customers), but the data they provide is extremely unbalanced (97% of customers active, 3% retired customers), I&amp;#39;m reading about undersampling and oversampling, but in your opinion, what is the best step to deal with that type of model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fczbo", "is_robot_indexable": true, "report_reasons": null, "author": "AFO-100", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fczbo/how_to_deal_with_extremely_unbalanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fczbo/how_to_deal_with_extremely_unbalanced/", "subreddit_subscribers": 838631, "created_utc": 1674062504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_903k40ag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data science degrees held at a higher caliber over business analytics degrees?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fuing", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674109267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fuing", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible-Cry-495", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fuing/are_data_science_degrees_held_at_a_higher_caliber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fuing/are_data_science_degrees_held_at_a_higher_caliber/", "subreddit_subscribers": 838631, "created_utc": 1674109267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi I\u2019m starting a job as a Tech consultant (in the data field) this upcoming summer and plan to stay there for a couple of years. Eventually, I would like to become a data scientist. I didn\u2019t major in any math/statistics major in college (Information Technology) so don\u2019t have much prior knowledge other then minimal python/sql knowledge. I also am planning to do masters in data analytics/data science after two years of my job. What are the most important things to learn? And is doing the masters worth especially considering I won\u2019t have prior education in data science other than self-learn?", "author_fullname": "t2_6fw26uqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi I\u2019m trying to switch my career path to data science and have about two years to learn as much as I can", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ft65u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674104865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m starting a job as a Tech consultant (in the data field) this upcoming summer and plan to stay there for a couple of years. Eventually, I would like to become a data scientist. I didn\u2019t major in any math/statistics major in college (Information Technology) so don\u2019t have much prior knowledge other then minimal python/sql knowledge. I also am planning to do masters in data analytics/data science after two years of my job. What are the most important things to learn? And is doing the masters worth especially considering I won\u2019t have prior education in data science other than self-learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ft65u", "is_robot_indexable": true, "report_reasons": null, "author": "sockdude10", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ft65u/hi_im_trying_to_switch_my_career_path_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ft65u/hi_im_trying_to_switch_my_career_path_to_data/", "subreddit_subscribers": 838631, "created_utc": 1674104865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_qsc9jb1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much knowledge do you have to have to get your first job in ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ft29w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674104525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ft29w", "is_robot_indexable": true, "report_reasons": null, "author": "crn4t", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ft29w/how_much_knowledge_do_you_have_to_have_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ft29w/how_much_knowledge_do_you_have_to_have_to_get/", "subreddit_subscribers": 838631, "created_utc": 1674104525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We combined image captioning using CLIP and image generation using the Hugging Face Stable Diffusion model to create an image de-identifier modeled after the game of telephone,\u00a0[Imafake](https://hubs.la/Q01wrX4l0)! All you have to do is upload an image, convert it to a caption, then convert that caption to an image with a few clicks! You can also play with the parameters of the diffusion model depending on how gnarly you want your resulting image to be. And caution, they can get rather gnarly, but that\u2019s what makes it fun :) Thoughts and your own generated images welcome!!\n\nhttps://preview.redd.it/ct6263mejvca1.jpg?width=1276&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6321342e1720290b7cad637cb958425e8c503b46", "author_fullname": "t2_uck476wk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We used Stable Diffusion to create a game of image telephone that can de-identify images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ct6263mejvca1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4ab2eeca6ac574a5a979c3aa3d15b8b00fdddfa"}, {"y": 97, "x": 216, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84817713acb3d5ab034556caa8e2d7547974ee1a"}, {"y": 144, "x": 320, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b08fbe713d42ecae9a5d38b560bf073e7980f51"}, {"y": 288, "x": 640, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7011b1365b9c1da2b52911592dd67e9f7d6c5607"}, {"y": 432, "x": 960, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a485e824f885973336875449dc0afeb6e7efc0a"}, {"y": 486, "x": 1080, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49832c2d0be4b1647b96a79301e162c36432c171"}], "s": {"y": 575, "x": 1276, "u": "https://preview.redd.it/ct6263mejvca1.jpg?width=1276&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6321342e1720290b7cad637cb958425e8c503b46"}, "id": "ct6263mejvca1"}}, "name": "t3_10fjnz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eQhqV4_zLRynvPYMTJFyXdE5ID9ibDNv1rKu8tx3-JA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674079202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We combined image captioning using CLIP and image generation using the Hugging Face Stable Diffusion model to create an image de-identifier modeled after the game of telephone,\u00a0&lt;a href=\"https://hubs.la/Q01wrX4l0\"&gt;Imafake&lt;/a&gt;! All you have to do is upload an image, convert it to a caption, then convert that caption to an image with a few clicks! You can also play with the parameters of the diffusion model depending on how gnarly you want your resulting image to be. And caution, they can get rather gnarly, but that\u2019s what makes it fun :) Thoughts and your own generated images welcome!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ct6263mejvca1.jpg?width=1276&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6321342e1720290b7cad637cb958425e8c503b46\"&gt;https://preview.redd.it/ct6263mejvca1.jpg?width=1276&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6321342e1720290b7cad637cb958425e8c503b46&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10fjnz2", "is_robot_indexable": true, "report_reasons": null, "author": "Djinn_Tonic4DataSci", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10fjnz2/we_used_stable_diffusion_to_create_a_game_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10fjnz2/we_used_stable_diffusion_to_create_a_game_of/", "subreddit_subscribers": 838631, "created_utc": 1674079202.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}