{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ec0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seems like astronomer quietly laid off 20%", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 44, "top_awarded_type": null, "hide_score": false, "name": "t3_1041369", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "ups": 169, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 169, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Rq3tQTuon_x0D3gcWbR6BhAKt-fwmgL_vf0CpFaIGfQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672931012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8cdbcg7t6aaa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8cdbcg7t6aaa1.jpg?auto=webp&amp;s=9caccdfd4087c21d8f44722bb72e7b04aeee5833", "width": 826, "height": 262}, "resolutions": [{"url": "https://preview.redd.it/8cdbcg7t6aaa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c5fa4be7d0ca0e6d8eeabc05485afc81dc70cfa", "width": 108, "height": 34}, {"url": "https://preview.redd.it/8cdbcg7t6aaa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cae95eb3133108b12216ac2970525b36facfbef3", "width": 216, "height": 68}, {"url": "https://preview.redd.it/8cdbcg7t6aaa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfa3262c678ec1fd5fd40bdb9a16e372785608b9", "width": 320, "height": 101}, {"url": "https://preview.redd.it/8cdbcg7t6aaa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c29b98e6d3915d6854111531090c2f424355b3ce", "width": 640, "height": 203}], "variants": {}, "id": "5kCs9draxkLO05Fz6K42BxwSnQEG2kMSmOF0AO9uXhE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1041369", "is_robot_indexable": true, "report_reasons": null, "author": "mistanervous", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1041369/seems_like_astronomer_quietly_laid_off_20/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8cdbcg7t6aaa1.jpg", "subreddit_subscribers": 85312, "created_utc": 1672931012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally switched jobs. \nMy previous company was TCS, the management was toxic and I got burnt out trying to prove my worth to stay on a good project. I was moved from project to project without any feedback and pushed around at their will. I tried to get my hands on development work but they kept pulling me out of it, only to make me manage ops. As they dint have anyone else who would stick there and the senior who was the lead, and my mentor initially, ended up creating a huge dependency on himself and no one saw. Until he went on vacation and things blew up, I was pulled in and had to handle it. \n\nI finally put my papers down and started my new job this year. I\u2019m a full time DE from an data ops/dev role. \nIt\u2019s my second day on the job and I\u2019ve been assigned a project and I\u2019m expected to be the only person doing 100% of the ELT migration. The person who I\u2019m suppose to work with on the same project, will be at 50% availability. She even mentioned she hadn\u2019t even worked on the project for the past three months as there were budget cuts and they did not allocate hours. The principle lead mentioned they might be losing money too, but that\u2019s not something I should worry about. I\u2019m assigned to migrate the ETL and that\u2019s it. \nThe situation is, I\u2019ve never developed something from scratch as my old job was a very controlled environment and not enough room to explore. \n\nI have cold feet and I\u2019m freaking out that they might fire me. A little extreme I know. But yeah. \nAlso, I don\u2019t know why I\u2019m hesitant to mention I have just 3 years of experience and I might need more guidance. \nI\u2019ve been belittle/gaslit for asking questions/being honest in my previous role. I\u2019m just scared I might be over sharing and people might take advantage. \n\n\nCan I just tell them I need some handholding to quicken my pace of learning and how things are done there? \nThoughts?", "author_fullname": "t2_2b4iqu2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DE, third day on the job. Need advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103xjn5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672922845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672920959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally switched jobs. \nMy previous company was TCS, the management was toxic and I got burnt out trying to prove my worth to stay on a good project. I was moved from project to project without any feedback and pushed around at their will. I tried to get my hands on development work but they kept pulling me out of it, only to make me manage ops. As they dint have anyone else who would stick there and the senior who was the lead, and my mentor initially, ended up creating a huge dependency on himself and no one saw. Until he went on vacation and things blew up, I was pulled in and had to handle it. &lt;/p&gt;\n\n&lt;p&gt;I finally put my papers down and started my new job this year. I\u2019m a full time DE from an data ops/dev role. \nIt\u2019s my second day on the job and I\u2019ve been assigned a project and I\u2019m expected to be the only person doing 100% of the ELT migration. The person who I\u2019m suppose to work with on the same project, will be at 50% availability. She even mentioned she hadn\u2019t even worked on the project for the past three months as there were budget cuts and they did not allocate hours. The principle lead mentioned they might be losing money too, but that\u2019s not something I should worry about. I\u2019m assigned to migrate the ETL and that\u2019s it. \nThe situation is, I\u2019ve never developed something from scratch as my old job was a very controlled environment and not enough room to explore. &lt;/p&gt;\n\n&lt;p&gt;I have cold feet and I\u2019m freaking out that they might fire me. A little extreme I know. But yeah. \nAlso, I don\u2019t know why I\u2019m hesitant to mention I have just 3 years of experience and I might need more guidance. \nI\u2019ve been belittle/gaslit for asking questions/being honest in my previous role. I\u2019m just scared I might be over sharing and people might take advantage. &lt;/p&gt;\n\n&lt;p&gt;Can I just tell them I need some handholding to quicken my pace of learning and how things are done there? \nThoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103xjn5", "is_robot_indexable": true, "report_reasons": null, "author": "Shrey_aa", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103xjn5/new_de_third_day_on_the_job_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103xjn5/new_de_third_day_on_the_job_need_advice/", "subreddit_subscribers": 85312, "created_utc": 1672920959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer: I\u2019m a developer advocate for an open source project - lakeFS. \n\nWe\u2019ve planned to put together an in-person \u201cData engineering Job prep event\u201c in San Francisco. It will have engineering managers, tech recruiters and lead engineering folks from companies like Databricks, Confluent, Apple and other big tech.\n\nWhat questions would you like to ask them? In terms of interview prep strategies or navigating career as a DE or anything else at all.\n\nPS: It is of course open for all DEs. DM me if you\u2019d like to attend so I can share the invite.", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In the current job market, what questions do you have for a data engineering manager, a lead data engineer and tech recruiter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10493n9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672967119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672950273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I\u2019m a developer advocate for an open source project - lakeFS. &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve planned to put together an in-person \u201cData engineering Job prep event\u201c in San Francisco. It will have engineering managers, tech recruiters and lead engineering folks from companies like Databricks, Confluent, Apple and other big tech.&lt;/p&gt;\n\n&lt;p&gt;What questions would you like to ask them? In terms of interview prep strategies or navigating career as a DE or anything else at all.&lt;/p&gt;\n\n&lt;p&gt;PS: It is of course open for all DEs. DM me if you\u2019d like to attend so I can share the invite.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10493n9", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10493n9/in_the_current_job_market_what_questions_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10493n9/in_the_current_job_market_what_questions_do_you/", "subreddit_subscribers": 85312, "created_utc": 1672950273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw a few people mentioning polars here so I decided to learn more about it. It seems like a great tool, kind of a middle ground between pandas/plain python and spark, so I was wondering why it isn't widely used, is there a catch?", "author_fullname": "t2_4jwhs15h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104660l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672943305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a few people mentioning polars here so I decided to learn more about it. It seems like a great tool, kind of a middle ground between pandas/plain python and spark, so I was wondering why it isn&amp;#39;t widely used, is there a catch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "104660l", "is_robot_indexable": true, "report_reasons": null, "author": "blukitteh", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104660l/polars/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104660l/polars/", "subreddit_subscribers": 85312, "created_utc": 1672943305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Big Spatial Data Visualization using DeckGL - In this tutorial, we will explain how to process UK-Accidents\\(1.5 Million Points\\) spatial data using python and visualize it using DeckGL](https://preview.redd.it/l2atljbwucaa1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e8ed893773f9038a5dd9225099dc8262d98ca1a8)\n\n[Big Spatial Data Visualization using DeckGL - In this tutorial, we will explain how to process UK-Accidents(1.5 Million Points) spatial data using python and visualize it using DeckGL](https://spatial-dev.guru/2023/01/05/big-data-visualization-using-deckgl/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Spatial Data Visualization using DeckGL - In this tutorial, we will explain how to process UK-Accidents(1.5 Million Points) spatial data using python and visualize it using DeckGL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l2atljbwucaa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17b99ecaddce05973184dda444fd4f91e29a1dab"}, {"y": 109, "x": 216, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b95914d2dbfd6f6b1a27d886efa7564aca7fc3d2"}, {"y": 161, "x": 320, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d15af3e79aafb02c1e44e36dd242ca0a4b5297f5"}, {"y": 323, "x": 640, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b60712dd46ca1fb6757455004e0b8cb4b89ec53a"}, {"y": 485, "x": 960, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=277704986778738d0669a2e963858fced4179ead"}], "s": {"y": 518, "x": 1024, "u": "https://preview.redd.it/l2atljbwucaa1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e8ed893773f9038a5dd9225099dc8262d98ca1a8"}, "id": "l2atljbwucaa1"}}, "name": "t3_104lcmw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DO1nvu2_cqOhz0tr7pNro1ifAjlsQrOYOCY9Tigh_vQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672981341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/l2atljbwucaa1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e8ed893773f9038a5dd9225099dc8262d98ca1a8\"&gt;Big Spatial Data Visualization using DeckGL - In this tutorial, we will explain how to process UK-Accidents(1.5 Million Points) spatial data using python and visualize it using DeckGL&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/01/05/big-data-visualization-using-deckgl/\"&gt;Big Spatial Data Visualization using DeckGL - In this tutorial, we will explain how to process UK-Accidents(1.5 Million Points) spatial data using python and visualize it using DeckGL&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "104lcmw", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104lcmw/big_spatial_data_visualization_using_deckgl_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104lcmw/big_spatial_data_visualization_using_deckgl_in/", "subreddit_subscribers": 85312, "created_utc": 1672981341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Open Data Stack Distilled into Four Core Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_103zu09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2ajpPS6veXqWmg8f9djTdJVDAKnRNq8eVbmpy8-sCig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672927804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/modern-open-data-stack-four-core-tools", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?auto=webp&amp;s=733aeaaf9b17d43b3de1595ac9bcb898ba75e744", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65467720e335007785102a63e38dc6b07d02ea85", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3074fd739a527eeedabb4f13b4b04e50ac32caf9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1504c7a8ea6504bf79bc932ed23c9e1bc43331e3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c9e75459c76583745a1fd0db215ce1f52b215e0", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7936cd86a4b64e315c7adfbd7fa0d47c3086b9f9", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/17sBHLx4YLbselUyG7PKzQqETbtD-PUNKK84bceP8Os.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=63570d066a2ed690259de1421af29f29a162e911", "width": 1080, "height": 565}], "variants": {}, "id": "vJ1-bkFSvNuLeq_Tor2lRbc754CQZnFtnwXnVs0qfNY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "103zu09", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103zu09/the_open_data_stack_distilled_into_four_core_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/modern-open-data-stack-four-core-tools", "subreddit_subscribers": 85312, "created_utc": 1672927804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is looking at Palantir Foundry, and the consultants told us the storage is this Atlas DB thing: [https://palantir.github.io/atlasdb/html/index.html](https://palantir.github.io/atlasdb/html/index.html).\n\nI honestly haven't seen k/v databases used outside of things like s3/buckets and website backend type stuff. Lots of read/write but not exactly analytical queries. \n\nAnyone use Cassandra or K/V databases in an analytical setting?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cassandra or K/V Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104mncm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672985445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is looking at Palantir Foundry, and the consultants told us the storage is this Atlas DB thing: &lt;a href=\"https://palantir.github.io/atlasdb/html/index.html\"&gt;https://palantir.github.io/atlasdb/html/index.html&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I honestly haven&amp;#39;t seen k/v databases used outside of things like s3/buckets and website backend type stuff. Lots of read/write but not exactly analytical queries. &lt;/p&gt;\n\n&lt;p&gt;Anyone use Cassandra or K/V databases in an analytical setting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "104mncm", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104mncm/cassandra_or_kv_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104mncm/cassandra_or_kv_databases/", "subreddit_subscribers": 85312, "created_utc": 1672985445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am applying internally for a Data Engineer role that recently opened up at my company. \n\nThe hiring manager for the role, a Sr. DE, is encouraging me to apply. I am currently a Sr. BA with a couple years of experience with SQL (on the Analytics side) with very little professional experience with Python. \n\nI expect to be afforded at minimum a courtesy interview (since that\u2019s typically standard for internal applicants).\n\nAll things above considered, what in your advice should be the 5-10 things/concepts/skills I should focus on (cram) to better prepare for the interview within a month?", "author_fullname": "t2_ry76f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104ff8w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672965097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am applying internally for a Data Engineer role that recently opened up at my company. &lt;/p&gt;\n\n&lt;p&gt;The hiring manager for the role, a Sr. DE, is encouraging me to apply. I am currently a Sr. BA with a couple years of experience with SQL (on the Analytics side) with very little professional experience with Python. &lt;/p&gt;\n\n&lt;p&gt;I expect to be afforded at minimum a courtesy interview (since that\u2019s typically standard for internal applicants).&lt;/p&gt;\n\n&lt;p&gt;All things above considered, what in your advice should be the 5-10 things/concepts/skills I should focus on (cram) to better prepare for the interview within a month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "104ff8w", "is_robot_indexable": true, "report_reasons": null, "author": "CosmicNightmare", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104ff8w/interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104ff8w/interview_prep/", "subreddit_subscribers": 85312, "created_utc": 1672965097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DE community! We have started migrating the platform sources into the Redshift Data Warehouse, and for the modeling approach, we use Star Schema.\n\nOur end-users are analysts/BI teams, who are used to the relational databases or at least have some aggregated tables with the external id field that refers to the other aggregated table id-s, and as we create the fact tables there have been consistent requests to add into the fact tables FK to the other fact tables.\n\nTo avoid this anti-pattern, so far we have tried to present the showcases about star schema and dimensional modeling, communicated with the end users to figure out the use cases to try to bring all the needed facts into one table in the marts, or add a large number of the related facts into the fact table whenever it was possible.\n\nHowever, there still are cases where we have two related fact tables that need to be joined together on the data-mart layer (on top of the fact/dimension tables)  for reporting purposes, sometimes they have different granularity or do not represent the same entity, so bringing all the facts together would be either, impossible without some kind of a bridge (it's many-to-many between some of these tables), or just flawed from the business context.\n\nAs we can't really add into a fact table the other fact table FK-s, what do you think is the decent approach here?", "author_fullname": "t2_gwqijajo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Related fact tables in Star Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104b1t9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672954805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DE community! We have started migrating the platform sources into the Redshift Data Warehouse, and for the modeling approach, we use Star Schema.&lt;/p&gt;\n\n&lt;p&gt;Our end-users are analysts/BI teams, who are used to the relational databases or at least have some aggregated tables with the external id field that refers to the other aggregated table id-s, and as we create the fact tables there have been consistent requests to add into the fact tables FK to the other fact tables.&lt;/p&gt;\n\n&lt;p&gt;To avoid this anti-pattern, so far we have tried to present the showcases about star schema and dimensional modeling, communicated with the end users to figure out the use cases to try to bring all the needed facts into one table in the marts, or add a large number of the related facts into the fact table whenever it was possible.&lt;/p&gt;\n\n&lt;p&gt;However, there still are cases where we have two related fact tables that need to be joined together on the data-mart layer (on top of the fact/dimension tables)  for reporting purposes, sometimes they have different granularity or do not represent the same entity, so bringing all the facts together would be either, impossible without some kind of a bridge (it&amp;#39;s many-to-many between some of these tables), or just flawed from the business context.&lt;/p&gt;\n\n&lt;p&gt;As we can&amp;#39;t really add into a fact table the other fact table FK-s, what do you think is the decent approach here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "104b1t9", "is_robot_indexable": true, "report_reasons": null, "author": "orm_the_stalker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104b1t9/related_fact_tables_in_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104b1t9/related_fact_tables_in_star_schema/", "subreddit_subscribers": 85312, "created_utc": 1672954805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am using DataBricks and the workspace I am using has Unity Catalog enabled.\n\nHowever, in the 'Data' section, I still see a `hive_metastore` catalog under the Catalogs section.  What is this?\n\nAre all databases and tables that are created under this catalog governed/controlled by \"Hive Metastore\" logic and not Unity Catalog?", "author_fullname": "t2_995jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In Databricks, can someone explain what the \"hive_metastore\" catalog is? And how does this differ from Unity Catalog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104aoia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672953945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using DataBricks and the workspace I am using has Unity Catalog enabled.&lt;/p&gt;\n\n&lt;p&gt;However, in the &amp;#39;Data&amp;#39; section, I still see a &lt;code&gt;hive_metastore&lt;/code&gt; catalog under the Catalogs section.  What is this?&lt;/p&gt;\n\n&lt;p&gt;Are all databases and tables that are created under this catalog governed/controlled by &amp;quot;Hive Metastore&amp;quot; logic and not Unity Catalog?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "104aoia", "is_robot_indexable": true, "report_reasons": null, "author": "foxmag86", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104aoia/in_databricks_can_someone_explain_what_the_hive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104aoia/in_databricks_can_someone_explain_what_the_hive/", "subreddit_subscribers": 85312, "created_utc": 1672953945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c7c8zdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks vs. AWS EMR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_1049ey1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/r7Pl6WKMTUeeVbTJbVaYTKsCHiCsVzmtdhmHcWM6jZM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672950988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/claimsforce/lakehouse-databricks-vs-aws-emr-87e30c00b791", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?auto=webp&amp;s=5a9959968d40c7ff861c4e5b79faeff3f457ea5b", "width": 1200, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb94bcd8f592672f118a649cc7dac905f598bbb5", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d72bb818cf5a0f735dffeb3416b3aab540ebde2b", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80b556873983bd95cecf02bfd926232962718fb7", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=42de410b2f568b24ba3d1b3c6523fcacd2bc27dd", "width": 640, "height": 419}, {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5f247eef578d84b72aef014fec6a396bbb229797", "width": 960, "height": 628}, {"url": "https://external-preview.redd.it/mkm9nFKAobu1-OIoF3aV7pdM8AJiTFX4aI-MWAKGZBw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a85a2901a5b0df7d98c584f561b1baa85ab8e89", "width": 1080, "height": 707}], "variants": {}, "id": "OjpQyixKuIkWJQvq_tOtsqxovBv-yMEhZZk2Y_pYec0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1049ey1", "is_robot_indexable": true, "report_reasons": null, "author": "heyimsinged", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1049ey1/databricks_vs_aws_emr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/claimsforce/lakehouse-databricks-vs-aws-emr-87e30c00b791", "subreddit_subscribers": 85312, "created_utc": 1672950988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nIf you're interested in learning data engineering, there are some excellent online resources available to you. Here are my top picks:\n\n1. Coursera: Coursera offers a variety of data engineering courses from top universities and companies, such as Johns Hopkins University and Google.\n2. edX: edX is a non-profit MOOC provider founded by Harvard and MIT, and it offers a range of data engineering courses as well.\n3. Dataquest: Dataquest is an online platform that teaches data science and data engineering through interactive coding challenges and projects.\n4. Data Engineering Bootcamp: This bootcamp, offered by Trilogy Education Services in partnership with top universities, is a full-time, immersive program that teaches students the skills they need to become data engineers.\n5. Kaggle: Kaggle is a popular platform for data science and machine learning competitions, and it also has a number of resources and tutorials for learning data engineering.\n\nI hope these resources are helpful as you start your journey in data engineering! If you have any other recommendations, please feel free to share them in the comments.\n\nFor a more detail insight, check [https://medium.com/p/720cb18cc2c6](https://medium.com/p/720cb18cc2c6)", "author_fullname": "t2_7obzgfpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Top Online Resources for Learning Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1044ef5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672939058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in learning data engineering, there are some excellent online resources available to you. Here are my top picks:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Coursera: Coursera offers a variety of data engineering courses from top universities and companies, such as Johns Hopkins University and Google.&lt;/li&gt;\n&lt;li&gt;edX: edX is a non-profit MOOC provider founded by Harvard and MIT, and it offers a range of data engineering courses as well.&lt;/li&gt;\n&lt;li&gt;Dataquest: Dataquest is an online platform that teaches data science and data engineering through interactive coding challenges and projects.&lt;/li&gt;\n&lt;li&gt;Data Engineering Bootcamp: This bootcamp, offered by Trilogy Education Services in partnership with top universities, is a full-time, immersive program that teaches students the skills they need to become data engineers.&lt;/li&gt;\n&lt;li&gt;Kaggle: Kaggle is a popular platform for data science and machine learning competitions, and it also has a number of resources and tutorials for learning data engineering.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I hope these resources are helpful as you start your journey in data engineering! If you have any other recommendations, please feel free to share them in the comments.&lt;/p&gt;\n\n&lt;p&gt;For a more detail insight, check &lt;a href=\"https://medium.com/p/720cb18cc2c6\"&gt;https://medium.com/p/720cb18cc2c6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1044ef5", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Psychology-2407", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1044ef5/the_top_online_resources_for_learning_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1044ef5/the_top_online_resources_for_learning_data/", "subreddit_subscribers": 85312, "created_utc": 1672939058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I stumbled upon [https://github.com/pola-rs/polars/pull/5175](https://github.com/pola-rs/polars/pull/5175) which is merged but I can't find any documentation or examples to invoke `polars-cli`. Does anyone know if this feature is live?\n\n(If it is, this might completely replace any use case I was planning to use `duckdb` for...)", "author_fullname": "t2_3i0xn3gy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know if polars has a cli?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_104pak3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672995080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I stumbled upon &lt;a href=\"https://github.com/pola-rs/polars/pull/5175\"&gt;https://github.com/pola-rs/polars/pull/5175&lt;/a&gt; which is merged but I can&amp;#39;t find any documentation or examples to invoke &lt;code&gt;polars-cli&lt;/code&gt;. Does anyone know if this feature is live?&lt;/p&gt;\n\n&lt;p&gt;(If it is, this might completely replace any use case I was planning to use &lt;code&gt;duckdb&lt;/code&gt; for...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?auto=webp&amp;s=255cdb87c03eb466662355e9577645b57ac80681", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d47595ca117f8c2ce488e57dd0e6b761f6f0dca1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2349680cc0caefee19942a9eb4ffa2876e4fdee7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bd9c3e64d11001e57bd11cac5bfbd4e3d0569e4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc32be5262a84523304d78f479d5d3fc309dc782", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=da29e6cba5c95fa95805b35d1d00b1107f071091", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nePsGIPEROTJbaCgk4pT9P-oY-VDiVNPrnGbOC8FRGE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a9b3bd69e2b956d85bdec7f1b87df38e9ad2ee60", "width": 1080, "height": 540}], "variants": {}, "id": "7TR_RjUZEuKFQfA9f2YpxmtFu-Q7Q2_89v5MzGyVfSg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "104pak3", "is_robot_indexable": true, "report_reasons": null, "author": "ddanieltan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104pak3/does_anyone_know_if_polars_has_a_cli/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104pak3/does_anyone_know_if_polars_has_a_cli/", "subreddit_subscribers": 85312, "created_utc": 1672995080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4qx35pk2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any thoughts or advice would be greatly appreciated!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_104jt6m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C_1xpNuJuHfZZTAVmbH6Wbsaf2pYcMOLdmRw5mVSMkg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672976808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lyw349zehcaa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lyw349zehcaa1.jpg?auto=webp&amp;s=31ab97c57be62d78b1b0df98fb7ea0dea9d07e4b", "width": 791, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/lyw349zehcaa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=345191d06c5de716d480ee82a3d89d786260d585", "width": 108, "height": 139}, {"url": "https://preview.redd.it/lyw349zehcaa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4660a8ad2714dbf79e0c39304e55ce560ed4b7cf", "width": 216, "height": 279}, {"url": "https://preview.redd.it/lyw349zehcaa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddb0bd94ac49ab72f752154bc5bdfbbeb64c23de", "width": 320, "height": 414}, {"url": "https://preview.redd.it/lyw349zehcaa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ab533e922a4e16c6e3a458a4df2439628985315", "width": 640, "height": 828}], "variants": {}, "id": "CZnHMWge9rPxtqB0qxVWATunbKATH-CMwP7nxJz7wE0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "104jt6m", "is_robot_indexable": true, "report_reasons": null, "author": "waldo_92", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104jt6m/any_thoughts_or_advice_would_be_greatly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lyw349zehcaa1.jpg", "subreddit_subscribers": 85312, "created_utc": 1672976808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello, I believe we are experiencing an infrastructure issue when trying to extract data from SAP using COPY DATA in ADF. Large tables are timing out and we are unable to get a preview of some specific tables. Has anyone else encountered this problem and found a solution? We have tried breaking the data down by document and date, but it has not helped. Most of us think this is an infrastructure issue, but it's always worth double checking. Do you have any suggestions for efficiently extracting data from SAP on a daily basis? Thank you for your help.", "author_fullname": "t2_ed8nwd3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Infrastructure Issues with Extracting Data from SAP using COPY DATA in ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104jcsa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672975527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I believe we are experiencing an infrastructure issue when trying to extract data from SAP using COPY DATA in ADF. Large tables are timing out and we are unable to get a preview of some specific tables. Has anyone else encountered this problem and found a solution? We have tried breaking the data down by document and date, but it has not helped. Most of us think this is an infrastructure issue, but it&amp;#39;s always worth double checking. Do you have any suggestions for efficiently extracting data from SAP on a daily basis? Thank you for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "104jcsa", "is_robot_indexable": true, "report_reasons": null, "author": "Similar-Public-8486", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104jcsa/infrastructure_issues_with_extracting_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104jcsa/infrastructure_issues_with_extracting_data_from/", "subreddit_subscribers": 85312, "created_utc": 1672975527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you manage around tech debt and the increased LOE that exists in a heavily indebted environment?\n\nObviously this is most environments except for new development, but most customers have a hard time understanding LOE, or even how tech debt exacerbates the challenge of an environment.", "author_fullname": "t2_eblvtun2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tech Debt and LOE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104hlyo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672970762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you manage around tech debt and the increased LOE that exists in a heavily indebted environment?&lt;/p&gt;\n\n&lt;p&gt;Obviously this is most environments except for new development, but most customers have a hard time understanding LOE, or even how tech debt exacerbates the challenge of an environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "104hlyo", "is_robot_indexable": true, "report_reasons": null, "author": "Glotto_Gold", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104hlyo/tech_debt_and_loe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104hlyo/tech_debt_and_loe/", "subreddit_subscribers": 85312, "created_utc": 1672970762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.projectpro.io/project/project-demo?source=start&amp;uri=www.projectpro.io/project-use-case/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery](https://www.projectpro.io/project/project-demo?source=start&amp;uri=www.projectpro.io/project-use-case/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery)", "author_fullname": "t2_1tvygx68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone tried ProjectPro?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1046g0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672943964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.projectpro.io/project/project-demo?source=start&amp;amp;uri=www.projectpro.io/project-use-case/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery\"&gt;https://www.projectpro.io/project/project-demo?source=start&amp;amp;uri=www.projectpro.io/project-use-case/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1046g0q", "is_robot_indexable": true, "report_reasons": null, "author": "platypus9perry", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1046g0q/has_anyone_tried_projectpro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1046g0q/has_anyone_tried_projectpro/", "subreddit_subscribers": 85312, "created_utc": 1672943964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear all,\n\nI'm in the process of studying Kimball's Data Warehouse Toolkit, trying to understand how to model my company's data, and I'm stuck at the following.\n\nOur product is ferry tickets &amp; related services: when booking from our website, you can plan your vacation and buy all of the items below in one single package:\n\n- passenger ferry tickets \n- vehicle ferry tickets \n- Travel insurance\n- Some other services that I ommit for simplicity\n\nFor example one can login and choose 2 passenger tickets, 1 vehicle ticket &amp; travel insurance all in one take, checkout and pay for all of them as a package.\n\nNow suppose that we want to model the process of selling the above goods and we decide to go with the finest granularity possible, i.e. each row in our fact table is one of the above items, along with purchase date, and amount for each item, etc.\n\nThe problem is that different categories of items have different dimensionality. For instance, a ferry ticket has the ferry operator as a dimension, but the travel insurance doesn't. Or, a passenger ticket has a dimension of \"ticket class\" (e.g. \"deck\", \"regular cabin\", \"lux cabin\") whereas the vehicle ticket doesn't.\n\nWhat are my options here? Different fact tables for each item category sounds like an overkill, right? My guess is that this would be similar to modelling retail of very different kind of goods, with different dimentionality.\n\nAny thoughts and advice would be highly appreciated!\n\nThank you in advance!", "author_fullname": "t2_dxh8y1bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling: creating fact tables with different types of facts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1040as1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672929051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the process of studying Kimball&amp;#39;s Data Warehouse Toolkit, trying to understand how to model my company&amp;#39;s data, and I&amp;#39;m stuck at the following.&lt;/p&gt;\n\n&lt;p&gt;Our product is ferry tickets &amp;amp; related services: when booking from our website, you can plan your vacation and buy all of the items below in one single package:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;passenger ferry tickets &lt;/li&gt;\n&lt;li&gt;vehicle ferry tickets &lt;/li&gt;\n&lt;li&gt;Travel insurance&lt;/li&gt;\n&lt;li&gt;Some other services that I ommit for simplicity&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For example one can login and choose 2 passenger tickets, 1 vehicle ticket &amp;amp; travel insurance all in one take, checkout and pay for all of them as a package.&lt;/p&gt;\n\n&lt;p&gt;Now suppose that we want to model the process of selling the above goods and we decide to go with the finest granularity possible, i.e. each row in our fact table is one of the above items, along with purchase date, and amount for each item, etc.&lt;/p&gt;\n\n&lt;p&gt;The problem is that different categories of items have different dimensionality. For instance, a ferry ticket has the ferry operator as a dimension, but the travel insurance doesn&amp;#39;t. Or, a passenger ticket has a dimension of &amp;quot;ticket class&amp;quot; (e.g. &amp;quot;deck&amp;quot;, &amp;quot;regular cabin&amp;quot;, &amp;quot;lux cabin&amp;quot;) whereas the vehicle ticket doesn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;What are my options here? Different fact tables for each item category sounds like an overkill, right? My guess is that this would be similar to modelling retail of very different kind of goods, with different dimentionality.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts and advice would be highly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1040as1", "is_robot_indexable": true, "report_reasons": null, "author": "aWhaleNamedFreddie", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1040as1/data_modelling_creating_fact_tables_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1040as1/data_modelling_creating_fact_tables_with/", "subreddit_subscribers": 85312, "created_utc": 1672929051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're building pipelines for ingesting data from our SaaS application services to the data warehouse.\n\nEarly on we decided we don't want to do CDC as it couples the data warehouse to internal implementations, it is hard to enforce schema evolution and it requires the data warehouse team to have deep understanding of internal models of services.\n\nWe want to align the teams that work on the application on sending their data in kafka events. Maybe something similar to data products concept in data mesh (but not necessarily go all in on data mesh).\n\nWe tell them - every time you update an entity, send the full entity to the data warehouse. This way we can control the schema, we can decouple it from the internal representation of entities.\n\nWhen it works - it works great.\n\nBut the concept fails when:\n\n1. The team is doing a **partial update**. For example, it is using a document db to store user entities. It receives an \\`AddressChanged\\` event for a user and updates only the address field of the user. There is no point when the full user object is loaded in memory. The team does not want to read the entire document before the update because it will introduce race conditions and performance degradation. (this is maybe the easiest problem since we can maybe solve it by changing our pipelines to merge updates but we feel it will make the pipelines less robust and more complicated to maintain)\n2. The team is doing **bulk updates**. For example, the team is using a relational database and uses \\`UPDATE WHERE\\` to update a bulk of entities. The code might even not know which entities were updated without doing another expensive query and loading all the updated data.\n3. Troubleshooting and **manual updates** \\- let's say it is Saturday night and there's a P0 incident and to solve it someone had to manually update the database. How does the data warehouse gets notified? \n\nHas anyone here encountered similar problems? How did you solve them?", "author_fullname": "t2_20muts76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle partial updates and bulk updates in the source systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103zpjs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672927464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re building pipelines for ingesting data from our SaaS application services to the data warehouse.&lt;/p&gt;\n\n&lt;p&gt;Early on we decided we don&amp;#39;t want to do CDC as it couples the data warehouse to internal implementations, it is hard to enforce schema evolution and it requires the data warehouse team to have deep understanding of internal models of services.&lt;/p&gt;\n\n&lt;p&gt;We want to align the teams that work on the application on sending their data in kafka events. Maybe something similar to data products concept in data mesh (but not necessarily go all in on data mesh).&lt;/p&gt;\n\n&lt;p&gt;We tell them - every time you update an entity, send the full entity to the data warehouse. This way we can control the schema, we can decouple it from the internal representation of entities.&lt;/p&gt;\n\n&lt;p&gt;When it works - it works great.&lt;/p&gt;\n\n&lt;p&gt;But the concept fails when:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The team is doing a &lt;strong&gt;partial update&lt;/strong&gt;. For example, it is using a document db to store user entities. It receives an `AddressChanged` event for a user and updates only the address field of the user. There is no point when the full user object is loaded in memory. The team does not want to read the entire document before the update because it will introduce race conditions and performance degradation. (this is maybe the easiest problem since we can maybe solve it by changing our pipelines to merge updates but we feel it will make the pipelines less robust and more complicated to maintain)&lt;/li&gt;\n&lt;li&gt;The team is doing &lt;strong&gt;bulk updates&lt;/strong&gt;. For example, the team is using a relational database and uses `UPDATE WHERE` to update a bulk of entities. The code might even not know which entities were updated without doing another expensive query and loading all the updated data.&lt;/li&gt;\n&lt;li&gt;Troubleshooting and &lt;strong&gt;manual updates&lt;/strong&gt; - let&amp;#39;s say it is Saturday night and there&amp;#39;s a P0 incident and to solve it someone had to manually update the database. How does the data warehouse gets notified? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone here encountered similar problems? How did you solve them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103zpjs", "is_robot_indexable": true, "report_reasons": null, "author": "daramasala", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103zpjs/how_to_handle_partial_updates_and_bulk_updates_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103zpjs/how_to_handle_partial_updates_and_bulk_updates_in/", "subreddit_subscribers": 85312, "created_utc": 1672927464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm interested in pursuing a career in data engineering with a specialization in healthcare data.  I understand that I'd need to be proficient in Python and SQL to satisfy the minimum requirements, but I was wondering if someone could shed some light on data engineering  in the healthcare field.  I've provided some background information and a few questions I have below.  Sorry for any formatting issues,  I'm typing on my mobile.  TIA \n\n\nBackground:\n\nCurrent occupation: backend developer\n\nSkills: java (primary), some python, basic SQL, docker, k8s, starting to learn AWS tools, CI/CD\n\nSector:  finance\n\nYears of experience: 3\n\nLocation: US\n\nDegree:  BAAS (Bachelors of Applied Arts and Sciences)\n\n\nQuestions:\n\n1.  Is the healthcare field hard to get into?\n\n2.  Should I go back to school for a post-bacc degree or possibly a masters in health information systems?\n\n3.  What does a typical day look like?\n\n4.  Is the tech stack generally older?\n\n5.  How's the pay?\n\n6.  How's the job security?\n\n7.  Is remote work possible?\n\n8.  Any particular skills/topics I should learn?", "author_fullname": "t2_5sscegp1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE in healthcare", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103wpc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672920831.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672918045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in pursuing a career in data engineering with a specialization in healthcare data.  I understand that I&amp;#39;d need to be proficient in Python and SQL to satisfy the minimum requirements, but I was wondering if someone could shed some light on data engineering  in the healthcare field.  I&amp;#39;ve provided some background information and a few questions I have below.  Sorry for any formatting issues,  I&amp;#39;m typing on my mobile.  TIA &lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;Current occupation: backend developer&lt;/p&gt;\n\n&lt;p&gt;Skills: java (primary), some python, basic SQL, docker, k8s, starting to learn AWS tools, CI/CD&lt;/p&gt;\n\n&lt;p&gt;Sector:  finance&lt;/p&gt;\n\n&lt;p&gt;Years of experience: 3&lt;/p&gt;\n\n&lt;p&gt;Location: US&lt;/p&gt;\n\n&lt;p&gt;Degree:  BAAS (Bachelors of Applied Arts and Sciences)&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is the healthcare field hard to get into?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should I go back to school for a post-bacc degree or possibly a masters in health information systems?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What does a typical day look like?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is the tech stack generally older?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How&amp;#39;s the pay?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How&amp;#39;s the job security?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is remote work possible?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any particular skills/topics I should learn?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "103wpc1", "is_robot_indexable": true, "report_reasons": null, "author": "the_plants_are_here", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103wpc1/de_in_healthcare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103wpc1/de_in_healthcare/", "subreddit_subscribers": 85312, "created_utc": 1672918045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lineage: Just a Feature or Something Else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "name": "t3_1047ecp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Vu4uok1NmrMLHLVHKWSUdN54ktVc2JwII5WoCJ1_jc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672946230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/data-lineage-just-a-feature-or-something-else-24b60e924186", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/160wFYR6YeO7f8L2mlvv4w2bd9bICXGQqGc3pnTgDc0.jpg?auto=webp&amp;s=0fbeae8e183de812e11a45498dbbe5663f39a2db", "width": 801, "height": 464}, "resolutions": [{"url": "https://external-preview.redd.it/160wFYR6YeO7f8L2mlvv4w2bd9bICXGQqGc3pnTgDc0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=29f567ab482494512080382b94fd4c54eecc55fe", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/160wFYR6YeO7f8L2mlvv4w2bd9bICXGQqGc3pnTgDc0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4144aa184bea7be8e8a3252f4e805825d67186c7", "width": 216, "height": 125}, {"url": "https://external-preview.redd.it/160wFYR6YeO7f8L2mlvv4w2bd9bICXGQqGc3pnTgDc0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6060cf992218464fe09a2f89a9fc4c25a3c8414d", "width": 320, "height": 185}, {"url": "https://external-preview.redd.it/160wFYR6YeO7f8L2mlvv4w2bd9bICXGQqGc3pnTgDc0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40831eae2e5dcc3975818880d3e98953c564d043", "width": 640, "height": 370}], "variants": {}, "id": "k569DWNuFnpiQjB1XUyrBger0-sqzYGl9WLOUDJzxD0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1047ecp", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1047ecp/data_lineage_just_a_feature_or_something_else/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/data-lineage-just-a-feature-or-something-else-24b60e924186", "subreddit_subscribers": 85312, "created_utc": 1672946230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys.\n\nWhat books do you recommend for start working with Scala in Databricks/Spark?\n\nBooks that can be used to cover the basics and move on in Scala programming.", "author_fullname": "t2_fhdo3edw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala books 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103xxe1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672922223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys.&lt;/p&gt;\n\n&lt;p&gt;What books do you recommend for start working with Scala in Databricks/Spark?&lt;/p&gt;\n\n&lt;p&gt;Books that can be used to cover the basics and move on in Scala programming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "103xxe1", "is_robot_indexable": true, "report_reasons": null, "author": "nevesgn", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103xxe1/scala_books_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103xxe1/scala_books_2023/", "subreddit_subscribers": 85312, "created_utc": 1672922223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was trying to drop a table cause I enjoy the rush of losing something. But I've been typing DRIP Table a lot and keep getting syntax errors. So if I had to code a DRIP TABLE statement, what would it do?", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would the query \"DRIP TABLE\" do if it exists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10411vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672930926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to drop a table cause I enjoy the rush of losing something. But I&amp;#39;ve been typing DRIP Table a lot and keep getting syntax errors. So if I had to code a DRIP TABLE statement, what would it do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10411vq", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10411vq/what_would_the_query_drip_table_do_if_it_exists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10411vq/what_would_the_query_drip_table_do_if_it_exists/", "subreddit_subscribers": 85312, "created_utc": 1672930926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It is only 4 days into the new year. Amazon lays off 18k folks; Astronomer lays off 20% of its workforce. Salesforce joins in too; And so is Compass. This is not the first, and certainly not the last layoff of the season!\n\nWith tech companies laying off folks in troves, it is getting highly competitive to stand out in the job application. I graduated in May 2020 and it was definitely one of the worst times to graduate, thanks Covid. There was hiring freeze everywhere. Scary times!\n\nIt took me a while but I learnt to leverage LinkedIn extensively and landed my job at Apple as well.\n\nShared my LinkedIn strategy in a blog. I hope it helps you or someone in your network.\n\nBlog link: https://medium.com/@vinodhini-sd/leverage-linkedin-for-effective-job-search-part-i-2726132fbe3c", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You are using LinkedIn the wrong way for job search!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_104ltsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672982809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is only 4 days into the new year. Amazon lays off 18k folks; Astronomer lays off 20% of its workforce. Salesforce joins in too; And so is Compass. This is not the first, and certainly not the last layoff of the season!&lt;/p&gt;\n\n&lt;p&gt;With tech companies laying off folks in troves, it is getting highly competitive to stand out in the job application. I graduated in May 2020 and it was definitely one of the worst times to graduate, thanks Covid. There was hiring freeze everywhere. Scary times!&lt;/p&gt;\n\n&lt;p&gt;It took me a while but I learnt to leverage LinkedIn extensively and landed my job at Apple as well.&lt;/p&gt;\n\n&lt;p&gt;Shared my LinkedIn strategy in a blog. I hope it helps you or someone in your network.&lt;/p&gt;\n\n&lt;p&gt;Blog link: &lt;a href=\"https://medium.com/@vinodhini-sd/leverage-linkedin-for-effective-job-search-part-i-2726132fbe3c\"&gt;https://medium.com/@vinodhini-sd/leverage-linkedin-for-effective-job-search-part-i-2726132fbe3c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?auto=webp&amp;s=d88ce584456758d35b5dcc19fa7e50e4317a50b5", "width": 1024, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcec83b65b817d2da195580c4fa38bbc42f8b400", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc4302361cbb9cbd4509762d2099e6dd2cd67074", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3263bc84dc2453971d600e0a175cbe0c4614ec08", "width": 320, "height": 156}, {"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=32e292c02e4678b1affeb4fa2245dafb1aa9fe9a", "width": 640, "height": 312}, {"url": "https://external-preview.redd.it/WDPBsaqpc6ll2jIYbU-uIPa097Nqa0R261wAYvOxKW0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=243ad447fb54491ad1bb2cdd9843d5cb65b3d6b0", "width": 960, "height": 468}], "variants": {}, "id": "YLJGExlS4sSIbaDDQ6JeN8THvxik-jNiFo6gVGisEZs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "104ltsp", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/104ltsp/you_are_using_linkedin_the_wrong_way_for_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/104ltsp/you_are_using_linkedin_the_wrong_way_for_job/", "subreddit_subscribers": 85312, "created_utc": 1672982809.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}