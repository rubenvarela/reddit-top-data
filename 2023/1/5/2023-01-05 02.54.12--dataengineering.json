{"kind": "Listing", "data": {"after": "t3_103clkv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a2zxqic6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meltano can now run any Airbyte source connector thanks to a community contribution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1039njv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yanii5NteK25H5LV0gyfgeycmLXX6ot1nn0-48RvJsA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672853981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/meltano-community-contribution-enables-running-over-200-airbyte-connectors/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?auto=webp&amp;s=c281f7f1f173c9d757c14c22bd02904df6bbe926", "width": 2048, "height": 1365}, "resolutions": [{"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=542e31c66973c837670c355c9b39789836012881", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a0f1441845dca9f1f291d639b7b6bef2b15e3f7b", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f28b7d959f0f9abe9b78874b258d5d2db84e826e", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9dcf2528426908213926e342fd45708c44169b5", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=39a2699a04982e2cfa4c07fb50348c5629825b3f", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/ADIADkUMY_u_XuXeGZiVpmQJhh6FSfiFqFik4iKF_pM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=354068f1be19deb6fe35dee8f01873f6817f072a", "width": 1080, "height": 719}], "variants": {}, "id": "UaWSMIAUKV85uXdc7bNp-jFBUuKP9UuqUorN-KPwqrg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1039njv", "is_robot_indexable": true, "report_reasons": null, "author": "tayloramurphy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1039njv/meltano_can_now_run_any_airbyte_source_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/meltano-community-contribution-enables-running-over-200-airbyte-connectors/", "subreddit_subscribers": 85188, "created_utc": 1672853981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The two books are regularly mentioned as must-reads for DE's ; but they're pretty long, and some parts are outdated. What parts are still important to read for someone who wants to get into the field, has a technical data background, but doesn't want to read 1000 odd pages?\n\n&amp;#x200B;\n\nAlso, would you recommend any other books? specifically any with practice problems?", "author_fullname": "t2_80ytrhvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What parts of \"the data warehouse toolkit\" and \"designing data intensive applications\" are important to read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103j5cq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672875912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The two books are regularly mentioned as must-reads for DE&amp;#39;s ; but they&amp;#39;re pretty long, and some parts are outdated. What parts are still important to read for someone who wants to get into the field, has a technical data background, but doesn&amp;#39;t want to read 1000 odd pages?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, would you recommend any other books? specifically any with practice problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103j5cq", "is_robot_indexable": true, "report_reasons": null, "author": "Particular-Bet-1828", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103j5cq/what_parts_of_the_data_warehouse_toolkit_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103j5cq/what_parts_of_the_data_warehouse_toolkit_and/", "subreddit_subscribers": 85188, "created_utc": 1672875912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a DE, most of the times, we are struggling to keep up with the hard deadlines of the businesses and end up putting together bare-bones pipelines  that don\u2019t always follow the best practices. \n\nHow do you as a team tackle the tech debt, and also implement best practices? \n\nDo you have specific sprints quarterly or early to deal with these?", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you clear tech debt and implement software engineering best practices in your data workflows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103ezjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672866242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DE, most of the times, we are struggling to keep up with the hard deadlines of the businesses and end up putting together bare-bones pipelines  that don\u2019t always follow the best practices. &lt;/p&gt;\n\n&lt;p&gt;How do you as a team tackle the tech debt, and also implement best practices? &lt;/p&gt;\n\n&lt;p&gt;Do you have specific sprints quarterly or early to deal with these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103ezjm", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103ezjm/how_do_you_clear_tech_debt_and_implement_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103ezjm/how_do_you_clear_tech_debt_and_implement_software/", "subreddit_subscribers": 85188, "created_utc": 1672866242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI want to refresh my SQL skills for an upcoming Internship in Data Engineering and learn some advanced topics.\n\nWhat resources do you recommend for someone, who already knows some basics? \n\nIs Leetcode / Hackerrank suitable?", "author_fullname": "t2_jgn9fqry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way / source to refresh SQL and learn advanced topics for an upcoming internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1030pcr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672829680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I want to refresh my SQL skills for an upcoming Internship in Data Engineering and learn some advanced topics.&lt;/p&gt;\n\n&lt;p&gt;What resources do you recommend for someone, who already knows some basics? &lt;/p&gt;\n\n&lt;p&gt;Is Leetcode / Hackerrank suitable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1030pcr", "is_robot_indexable": true, "report_reasons": null, "author": "mar-lor", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1030pcr/best_way_source_to_refresh_sql_and_learn_advanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1030pcr/best_way_source_to_refresh_sql_and_learn_advanced/", "subreddit_subscribers": 85188, "created_utc": 1672829680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently started a new job as a business analyst. I\u2019m from a strong statistical and coding background, but only did a few basic units about database design, modelling and management, so my knowledge is quite limited and my terminology may be a little less technical. \n\nIt is my first job out of uni, and seem to have been thrown into the deep end. My team leader told me that during my first month I\u2019d be helping him by converting the existing architecture into data marts. \n\nI had never heard of data marts before so decided to do some research. From what I can see, it involves collecting data from various sources and formatting it, and then creating a collective database and then generating datasets out of the database as per business requirements. He said our goal is to then use the resulting datasets to generate reports on Power BI. \n\nFrom what I understood about the present architecture, data is extracted from the company software using a specific tool, which is then stored into a SQL database with different tables for different departments, which is then called upon to generate power BI reports. These tables also contain historical data.\n\nAm i correct in assuming that when we move to a data mart based approach, we would instead only have the more recent pertinent data fed to the reporting tools, and it would possibly contain fewer tables, allowing for improved performance, while the historical data would be stored in the data warehouse for analytics and machine learning purposes?", "author_fullname": "t2_9i23t85r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5 data marts and how they fit into reporting and analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102v6fl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672810458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently started a new job as a business analyst. I\u2019m from a strong statistical and coding background, but only did a few basic units about database design, modelling and management, so my knowledge is quite limited and my terminology may be a little less technical. &lt;/p&gt;\n\n&lt;p&gt;It is my first job out of uni, and seem to have been thrown into the deep end. My team leader told me that during my first month I\u2019d be helping him by converting the existing architecture into data marts. &lt;/p&gt;\n\n&lt;p&gt;I had never heard of data marts before so decided to do some research. From what I can see, it involves collecting data from various sources and formatting it, and then creating a collective database and then generating datasets out of the database as per business requirements. He said our goal is to then use the resulting datasets to generate reports on Power BI. &lt;/p&gt;\n\n&lt;p&gt;From what I understood about the present architecture, data is extracted from the company software using a specific tool, which is then stored into a SQL database with different tables for different departments, which is then called upon to generate power BI reports. These tables also contain historical data.&lt;/p&gt;\n\n&lt;p&gt;Am i correct in assuming that when we move to a data mart based approach, we would instead only have the more recent pertinent data fed to the reporting tools, and it would possibly contain fewer tables, allowing for improved performance, while the historical data would be stored in the data warehouse for analytics and machine learning purposes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "102v6fl", "is_robot_indexable": true, "report_reasons": null, "author": "faxgebofk2451", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/102v6fl/eli5_data_marts_and_how_they_fit_into_reporting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/102v6fl/eli5_data_marts_and_how_they_fit_into_reporting/", "subreddit_subscribers": 85188, "created_utc": 1672810458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked in a couple of projects with the title of Big Data/ Hadoop developer. During this time , I have worked to set up data pipelines, building the framework for the same - to consume the data multiple sources , perform ETL operations and provide the data to end user (data scientists or input feed to a different app). I am currently for a similar set up but which is completely on AWS.\n\nThe tech stack I have mainly worked with: spark, hive , python, unix, shell scripts, sql, HDFS, CDH,CICD, Docker.\n\nAWS stack: EMR, EKS, airflow, lambda, s3, Athena,sqs \n\nI have development experience, but wouldn\u2019t say I have worked with a very object oriented and structured programing.\n\nI sort of feel like I am going with the flow, but don\u2019t have enough idea on how should I progress and the path that I should choose.\nI see that a lot of different job titles have similar requirement. \n\nPlease advise on which area/skillset I should focus on and the kind of jobs I should look for.", "author_fullname": "t2_4ewnsti5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some guidance on career path.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102z9vh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672824837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked in a couple of projects with the title of Big Data/ Hadoop developer. During this time , I have worked to set up data pipelines, building the framework for the same - to consume the data multiple sources , perform ETL operations and provide the data to end user (data scientists or input feed to a different app). I am currently for a similar set up but which is completely on AWS.&lt;/p&gt;\n\n&lt;p&gt;The tech stack I have mainly worked with: spark, hive , python, unix, shell scripts, sql, HDFS, CDH,CICD, Docker.&lt;/p&gt;\n\n&lt;p&gt;AWS stack: EMR, EKS, airflow, lambda, s3, Athena,sqs &lt;/p&gt;\n\n&lt;p&gt;I have development experience, but wouldn\u2019t say I have worked with a very object oriented and structured programing.&lt;/p&gt;\n\n&lt;p&gt;I sort of feel like I am going with the flow, but don\u2019t have enough idea on how should I progress and the path that I should choose.\nI see that a lot of different job titles have similar requirement. &lt;/p&gt;\n\n&lt;p&gt;Please advise on which area/skillset I should focus on and the kind of jobs I should look for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "102z9vh", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous_Tax_2911", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/102z9vh/need_some_guidance_on_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/102z9vh/need_some_guidance_on_career_path/", "subreddit_subscribers": 85188, "created_utc": 1672824837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is part 1 of an amazing episode we recorded with Arjun and Frank. Talking about Materialize, the technology on which low latency incremental materialization is based on and what it takes to build a product on top of a technology. \n\nOne of the best episodes we had so far, make sure to check it!\n\n[https://datastackshow.com/podcast/materialize-origins-a-timely-dataflow-story-with-arjun-narayan-and-frank-mcsherry/](https://datastackshow.com/podcast/materialize-origins-a-timely-dataflow-story-with-arjun-narayan-and-frank-mcsherry/)", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Arjun Narayan and Frank McSherry Talking about Materialize and Timely Dataflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103i38k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672873404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is part 1 of an amazing episode we recorded with Arjun and Frank. Talking about Materialize, the technology on which low latency incremental materialization is based on and what it takes to build a product on top of a technology. &lt;/p&gt;\n\n&lt;p&gt;One of the best episodes we had so far, make sure to check it!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datastackshow.com/podcast/materialize-origins-a-timely-dataflow-story-with-arjun-narayan-and-frank-mcsherry/\"&gt;https://datastackshow.com/podcast/materialize-origins-a-timely-dataflow-story-with-arjun-narayan-and-frank-mcsherry/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?auto=webp&amp;s=56ae6913b6f7de5c324bfdffc75f7f84afd44f39", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7023376789bc866810a8553914dfa3d297ebfc65", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04ba6e4e9ab84659874eafb0e0075b6388f447ba", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6cecd9e330bd5544b9a5c997121e36d9846c4dfc", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=44ea216d54a28b3c8adce8d7c0f593be948edefc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d721d5ff89f366bed6d972456a2d24922a118e61", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/xRssCC1DrhB726t1EqWWgxRj0kh4tIX0mEwjBUUtIZY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=409aa1809d3531309524842a75de1e67ff593095", "width": 1080, "height": 607}], "variants": {}, "id": "YOd5mOBpzsexj2GJIPxAWvPJ5gaa66EkKbvUVlXUfZY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "103i38k", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103i38k/arjun_narayan_and_frank_mcsherry_talking_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103i38k/arjun_narayan_and_frank_mcsherry_talking_about/", "subreddit_subscribers": 85188, "created_utc": 1672873404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hoping there are a few buding Spark/Delta/Hive experts on here. \n\nI've created a load of external Delta tables through Spark and registered them in a Hive metastore. So far so good, I can refer to them in my Jupyter/VS Code notebooks via {database_name}.{table_name} SQL queries. I can't, though, run queries against them through the Hive CLI or Dbeaver. I've installed the auxillary Hive connector jars from delta.io but it's still not working. The documentation for the connectors suggests it won't be possible? Hive can't read Delta tables created by Spark? This seems bonkers to me. I thought Delta was an open format. Same issue for JDBC connection through Dbeaver. So the only way to browse/query my Delta tables are through Spark?", "author_fullname": "t2_2bglroyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta table question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103b21j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672866915.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672857166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping there are a few buding Spark/Delta/Hive experts on here. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve created a load of external Delta tables through Spark and registered them in a Hive metastore. So far so good, I can refer to them in my Jupyter/VS Code notebooks via {database_name}.{table_name} SQL queries. I can&amp;#39;t, though, run queries against them through the Hive CLI or Dbeaver. I&amp;#39;ve installed the auxillary Hive connector jars from delta.io but it&amp;#39;s still not working. The documentation for the connectors suggests it won&amp;#39;t be possible? Hive can&amp;#39;t read Delta tables created by Spark? This seems bonkers to me. I thought Delta was an open format. Same issue for JDBC connection through Dbeaver. So the only way to browse/query my Delta tables are through Spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103b21j", "is_robot_indexable": true, "report_reasons": null, "author": "H0twax", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103b21j/delta_table_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103b21j/delta_table_question/", "subreddit_subscribers": 85188, "created_utc": 1672857166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI would like to determine which cloud platform to use by doing an cost determination exercise on all 3. i want to start with Azure. How do I go about doing the costing?", "author_fullname": "t2_5zlk5o8b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I go about determining the cost of a cloud platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102wuin", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672815955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I would like to determine which cloud platform to use by doing an cost determination exercise on all 3. i want to start with Azure. How do I go about doing the costing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "102wuin", "is_robot_indexable": true, "report_reasons": null, "author": "AggravatingWish1019", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/102wuin/how_do_i_go_about_determining_the_cost_of_a_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/102wuin/how_do_i_go_about_determining_the_cost_of_a_cloud/", "subreddit_subscribers": 85188, "created_utc": 1672815955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was last fully employed as a DE two years ago but took off due to a surgery that was a very long recovery, had to get a re-surgery done and I'm just getting over the depression related to all of it.  Before this I had 8 years of experience.\n\nI am wondering if it's a hard job market to get back into right now due to the recession, or if hopefully it's the opposite and companies are still looking for employees in this area.  I've checked in with old colleagues and there doesn't seem to be much new technology that I would need to get up to speed on.", "author_fullname": "t2_cb9rpnop", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How's the job market right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103kw8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672880326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was last fully employed as a DE two years ago but took off due to a surgery that was a very long recovery, had to get a re-surgery done and I&amp;#39;m just getting over the depression related to all of it.  Before this I had 8 years of experience.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if it&amp;#39;s a hard job market to get back into right now due to the recession, or if hopefully it&amp;#39;s the opposite and companies are still looking for employees in this area.  I&amp;#39;ve checked in with old colleagues and there doesn&amp;#39;t seem to be much new technology that I would need to get up to speed on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "103kw8y", "is_robot_indexable": true, "report_reasons": null, "author": "sammessa789", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103kw8y/hows_the_job_market_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103kw8y/hows_the_job_market_right_now/", "subreddit_subscribers": 85188, "created_utc": 1672880326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I want to share the Kubeflow tutorial (Machine Learning Operations on Kubernetes), and usage scenarios that I created as projects for myself. I know that Kubeflow is a detailed topic to learn in a short term, so I gathered useful information and create sample general usage scenarios of Kubeflow.\n\nThis repo covers Kubeflow Environment with LABs: Kubeflow GUI, Jupyter Notebooks running on Kubernetes Pod, Kubeflow Pipeline, KALE (Kubeflow Automated PipeLines Engine), KATIB (AutoML: Finding Best Hyperparameter Values), KFServe (Model Serving), Training Operators (Distributed Training), Projects, etc. Possible usage scenarios are aimed to update over time.\n\nKubeflow is powerful tool that runs on Kubernetes (K8s) with containers (process isolation, scaling, distributed and parallel training).\n\n**This repo makes easy to learn and apply projects on your local machine with MiniKF, Virtualbox and Vagrant without any FEE**.\n\n**Tutorial Link:** [**https://github.com/omerbsezer/Fast-Kubeflow**](https://github.com/omerbsezer/Fast-Kubeflow)\n\n**Extra Kubernetes-Tutorial Link:** [**https://github.com/omerbsezer/Fast-Kubernetes**](https://github.com/omerbsezer/Fast-Kubernetes)\n\n**Extra Docker-Tutorial Link:** [**https://github.com/omerbsezer/Fast-Docker**](https://github.com/omerbsezer/Fast-Docker)\n\nQuick Look (HowTo): Scenarios - Hands-on LABs\n\n* [LAB: Creating LAB Environment (WSL2), Installing Kubeflow with MicroK8s, Juju on Ubuntu 20.04](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Installing-Kubeflow.md)\n* [LAB: Creating LAB Environment, Installing MiniKF with Vagrant (Preffered for Easy Usage)](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Using-MiniKF.md)\n* [LAB/Project: Kubeflow Pipeline (From Scratch) with Kubeflow SDK (DSL Compiler) and Custom Docker Images (Decision Tree, Logistic Regression, SVM, Naive Bayes, Xg Boost)](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Kubeflow-Pipeline-Project.md)\n* [LAB/Project: KALE (Kubeflow Automated PipeLines Engine) and KATIB (AutoML: Finding Best Hyperparameter Values)](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Kale-Katib-Project.md)\n* [LAB/Project: KALE (Kubeflow Automated PipeLines Engine) and KServe (Model Serving) for Model Prediction](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/KALE-KServe.md)\n* [LAB/Project: Distributed Training with Tensorflow (MNIST data)](https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Distributed-Training-Tensorflow.md)\n\n**Table of Contents**\n\n* [Motivation](https://github.com/omerbsezer/Fast-Kubeflow#motivation)\n* [What is Kubelow?](https://github.com/omerbsezer/Fast-Kubeflow#whatIsKubeflow)\n* [How Kubeflow Works?](https://github.com/omerbsezer/Fast-Kubeflow#howKubeflowWorks)\n* [What is Container (Docker)?](https://github.com/omerbsezer/Fast-Kubeflow#whatareContainers)\n* [What is Kubernetes?](https://github.com/omerbsezer/Fast-Kubeflow#whatisKubeflow)\n* [Installing Kubeflow](https://github.com/omerbsezer/Fast-Kubeflow#labEnvironment)\n* [Kubeflow Basics](https://github.com/omerbsezer/Fast-Kubeflow#basics)\n* [Kubeflow Jupyter Notebook](https://github.com/omerbsezer/Fast-Kubeflow#notebook)\n* [Kubeflow Pipeline](https://github.com/omerbsezer/Fast-Kubeflow#pipeline)\n* [KALE (Kubeflow Automated PipeLines Engine)](https://github.com/omerbsezer/Fast-Kubeflow#kale)\n* [KATIB (AutoML: Finding Best Hyperparameter Values)](https://github.com/omerbsezer/Fast-Kubeflow#katib)\n* [KServe (Model Serving)](https://github.com/omerbsezer/Fast-Kubeflow#kserve)\n* [Training-Operators (Distributed Training)](https://github.com/omerbsezer/Fast-Kubeflow#operator)\n* [Minio (Object Storage) and ROK (Data Management Platform)](https://github.com/omerbsezer/Fast-Kubeflow#minio_rok)\n* [Project 1: Creating ML Pipeline with Custom Docker Images (Decision Tree, Logistic Regression, SVM, Naive Bayes, Xg Boost)](https://github.com/omerbsezer/Fast-Kubeflow#project1)\n* [Project 2: KALE (Kubeflow Automated PipeLines Engine) and KATIB (AutoML: Finding Best Hyperparameter Values)](https://github.com/omerbsezer/Fast-Kubeflow#project2)\n* [Project 3: KALE (Kubeflow Automated PipeLines Engine) and KServe (Model Serving) for Model Prediction](https://github.com/omerbsezer/Fast-Kubeflow#project3)\n* [Project 4: Distributed Training with Training Operator](https://github.com/omerbsezer/Fast-Kubeflow#project4)\n* [Other Useful Resources Related Kubeflow](https://github.com/omerbsezer/Fast-Kubeflow#resource)\n* [References](https://github.com/omerbsezer/Fast-Kubeflow#references)", "author_fullname": "t2_muiope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast-Kubeflow: Kubeflow Tutorial, Sample Usage Scenarios (Howto: Hands-on LAB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103bk24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672858333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to share the Kubeflow tutorial (Machine Learning Operations on Kubernetes), and usage scenarios that I created as projects for myself. I know that Kubeflow is a detailed topic to learn in a short term, so I gathered useful information and create sample general usage scenarios of Kubeflow.&lt;/p&gt;\n\n&lt;p&gt;This repo covers Kubeflow Environment with LABs: Kubeflow GUI, Jupyter Notebooks running on Kubernetes Pod, Kubeflow Pipeline, KALE (Kubeflow Automated PipeLines Engine), KATIB (AutoML: Finding Best Hyperparameter Values), KFServe (Model Serving), Training Operators (Distributed Training), Projects, etc. Possible usage scenarios are aimed to update over time.&lt;/p&gt;\n\n&lt;p&gt;Kubeflow is powerful tool that runs on Kubernetes (K8s) with containers (process isolation, scaling, distributed and parallel training).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This repo makes easy to learn and apply projects on your local machine with MiniKF, Virtualbox and Vagrant without any FEE&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Kubeflow&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Extra Kubernetes-Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Kubernetes\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Kubernetes&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Extra Docker-Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Docker\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Docker&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick Look (HowTo): Scenarios - Hands-on LABs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Installing-Kubeflow.md\"&gt;LAB: Creating LAB Environment (WSL2), Installing Kubeflow with MicroK8s, Juju on Ubuntu 20.04&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Using-MiniKF.md\"&gt;LAB: Creating LAB Environment, Installing MiniKF with Vagrant (Preffered for Easy Usage)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Kubeflow-Pipeline-Project.md\"&gt;LAB/Project: Kubeflow Pipeline (From Scratch) with Kubeflow SDK (DSL Compiler) and Custom Docker Images (Decision Tree, Logistic Regression, SVM, Naive Bayes, Xg Boost)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Kale-Katib-Project.md\"&gt;LAB/Project: KALE (Kubeflow Automated PipeLines Engine) and KATIB (AutoML: Finding Best Hyperparameter Values)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/KALE-KServe.md\"&gt;LAB/Project: KALE (Kubeflow Automated PipeLines Engine) and KServe (Model Serving) for Model Prediction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow/blob/main/Distributed-Training-Tensorflow.md\"&gt;LAB/Project: Distributed Training with Tensorflow (MNIST data)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#motivation\"&gt;Motivation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#whatIsKubeflow\"&gt;What is Kubelow?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#howKubeflowWorks\"&gt;How Kubeflow Works?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#whatareContainers\"&gt;What is Container (Docker)?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#whatisKubeflow\"&gt;What is Kubernetes?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#labEnvironment\"&gt;Installing Kubeflow&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#basics\"&gt;Kubeflow Basics&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#notebook\"&gt;Kubeflow Jupyter Notebook&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#pipeline\"&gt;Kubeflow Pipeline&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#kale\"&gt;KALE (Kubeflow Automated PipeLines Engine)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#katib\"&gt;KATIB (AutoML: Finding Best Hyperparameter Values)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#kserve\"&gt;KServe (Model Serving)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#operator\"&gt;Training-Operators (Distributed Training)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#minio_rok\"&gt;Minio (Object Storage) and ROK (Data Management Platform)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#project1\"&gt;Project 1: Creating ML Pipeline with Custom Docker Images (Decision Tree, Logistic Regression, SVM, Naive Bayes, Xg Boost)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#project2\"&gt;Project 2: KALE (Kubeflow Automated PipeLines Engine) and KATIB (AutoML: Finding Best Hyperparameter Values)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#project3\"&gt;Project 3: KALE (Kubeflow Automated PipeLines Engine) and KServe (Model Serving) for Model Prediction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#project4\"&gt;Project 4: Distributed Training with Training Operator&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#resource\"&gt;Other Useful Resources Related Kubeflow&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Kubeflow#references\"&gt;References&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?auto=webp&amp;s=8972239301c0c4d5affacbbd29b0f2e306811114", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16a94ca70f737f2370b40aac3f8e91906e0f957b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=538ab272157f7fbbdc34990a022ebc76ef04a95d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=18c191c7a365a3dcd7dd5453aa0d20081e4d1ce4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e6839d5898e4ba4783cddafbc61cf720c03776b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e82f3995a80d28748c000fc40912a475009bc8d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/OgZTEcn6jPv9qhDq0bdea_xIzINxXytEo8_g2-1ZMNE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=153d0307d71e80f4f61f9f274a4b1d4ba3c1ae20", "width": 1080, "height": 540}], "variants": {}, "id": "Up_qqgqv71AbRrRB6fD1yjG5QqUgCZnuuwZu0XqGuwk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "103bk24", "is_robot_indexable": true, "report_reasons": null, "author": "obsezer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103bk24/fastkubeflow_kubeflow_tutorial_sample_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103bk24/fastkubeflow_kubeflow_tutorial_sample_usage/", "subreddit_subscribers": 85188, "created_utc": 1672858333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI have a set of 22 .sql files (generated from pg\\_dump), each containing data for a different chromosome. Each file is around 300-400GB in size, so I'm looking for the most efficient way to load all of this data into a Postgres database.\n\nI would also be interested in hearing about any scripts or techniques for splitting the .sql files into smaller chunks and loading them in parallel using the psql command-line interface.\n\nRight now, it takes around 2-5 Days to load one file. \n\nThank you in advance for your help!", "author_fullname": "t2_cw7qs3v3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting multiple large .sql files into Postgres database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102t84o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672804631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have a set of 22 .sql files (generated from pg_dump), each containing data for a different chromosome. Each file is around 300-400GB in size, so I&amp;#39;m looking for the most efficient way to load all of this data into a Postgres database.&lt;/p&gt;\n\n&lt;p&gt;I would also be interested in hearing about any scripts or techniques for splitting the .sql files into smaller chunks and loading them in parallel using the psql command-line interface.&lt;/p&gt;\n\n&lt;p&gt;Right now, it takes around 2-5 Days to load one file. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "102t84o", "is_robot_indexable": true, "report_reasons": null, "author": "babypinkgoyard", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/102t84o/ingesting_multiple_large_sql_files_into_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/102t84o/ingesting_multiple_large_sql_files_into_postgres/", "subreddit_subscribers": 85188, "created_utc": 1672804631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I downloaded delta, spark and pyspark. Creating and updating delta tables do work fine on python or sql (spark-sql) base so far.\n\nNow I want to access my delta/parquet files via JDBC (here via dbeaver client). Some years ago, when working with good old Spark 2 it was just starting the thrift-server from spark package, configure the spark jdbc driver in beaver and connect.\n\nWith delta, something is weird or I am missing something completely. I can not get it working.\n\nThe online manuals from data bricks are only showing how to connect via jdbc to databricks hosted delta files on port 443 (HTTPS). \n\nTried also to access the delta files via trino but it did also not work. According to their delta connector documentation, you need to additionally install a dedicated hive metastore service (hms) in order to get it working (trino -&gt; hive -&gt; delta ?).  At the same time, in the delta GitHub issues, one of their main developer told that hive integration between spark &lt;-&gt; delta is not compatible.\n\nI am really confused..\n\nDid one of you have any experience / solution on this? Maybe I am overlooking something very obvious.\n\nAlso I wonder, which kind of delta lake tables could be accessed via jdbc driver (hive managed tables or external tables)?", "author_fullname": "t2_f4kq1cjq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect to local Delta Lake (OSS) via JDBC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103i9wv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672873834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded delta, spark and pyspark. Creating and updating delta tables do work fine on python or sql (spark-sql) base so far.&lt;/p&gt;\n\n&lt;p&gt;Now I want to access my delta/parquet files via JDBC (here via dbeaver client). Some years ago, when working with good old Spark 2 it was just starting the thrift-server from spark package, configure the spark jdbc driver in beaver and connect.&lt;/p&gt;\n\n&lt;p&gt;With delta, something is weird or I am missing something completely. I can not get it working.&lt;/p&gt;\n\n&lt;p&gt;The online manuals from data bricks are only showing how to connect via jdbc to databricks hosted delta files on port 443 (HTTPS). &lt;/p&gt;\n\n&lt;p&gt;Tried also to access the delta files via trino but it did also not work. According to their delta connector documentation, you need to additionally install a dedicated hive metastore service (hms) in order to get it working (trino -&amp;gt; hive -&amp;gt; delta ?).  At the same time, in the delta GitHub issues, one of their main developer told that hive integration between spark &amp;lt;-&amp;gt; delta is not compatible.&lt;/p&gt;\n\n&lt;p&gt;I am really confused..&lt;/p&gt;\n\n&lt;p&gt;Did one of you have any experience / solution on this? Maybe I am overlooking something very obvious.&lt;/p&gt;\n\n&lt;p&gt;Also I wonder, which kind of delta lake tables could be accessed via jdbc driver (hive managed tables or external tables)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103i9wv", "is_robot_indexable": true, "report_reasons": null, "author": "consultant82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103i9wv/how_to_connect_to_local_delta_lake_oss_via_jdbc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103i9wv/how_to_connect_to_local_delta_lake_oss_via_jdbc/", "subreddit_subscribers": 85188, "created_utc": 1672873834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm making some experiments on a dataset where I have a float value associated with a DateTime object - Like a dict.\n\nI'm trying to downsample this dataset to optimize the algorithm - I'm currently extracting some elements by the date (removing elements with less than 15 days intervals).\n\nBut now, with that sample that I extract, I don't know how to ensure the quality of the data. How can I make sure that I don't lose any important info in the removed elements?\n\nTL;DR: How can I ensure the quality of info on downsampling compared with the original data?\n\n(I can't use correlation because of the different lengths of the original data and the filtered data.)\n\n(Language is not important, but I'm using Python)", "author_fullname": "t2_9s1yrp6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ensure quality on data sampling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103hnww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672872417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m making some experiments on a dataset where I have a float value associated with a DateTime object - Like a dict.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to downsample this dataset to optimize the algorithm - I&amp;#39;m currently extracting some elements by the date (removing elements with less than 15 days intervals).&lt;/p&gt;\n\n&lt;p&gt;But now, with that sample that I extract, I don&amp;#39;t know how to ensure the quality of the data. How can I make sure that I don&amp;#39;t lose any important info in the removed elements?&lt;/p&gt;\n\n&lt;p&gt;TL;DR: How can I ensure the quality of info on downsampling compared with the original data?&lt;/p&gt;\n\n&lt;p&gt;(I can&amp;#39;t use correlation because of the different lengths of the original data and the filtered data.)&lt;/p&gt;\n\n&lt;p&gt;(Language is not important, but I&amp;#39;m using Python)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103hnww", "is_robot_indexable": true, "report_reasons": null, "author": "ddponwheels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103hnww/ensure_quality_on_data_sampling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103hnww/ensure_quality_on_data_sampling/", "subreddit_subscribers": 85188, "created_utc": 1672872417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm running into some design choices which hinge on us either choosing the datatype for columns on their load into snowflake (for instance, bringing ints in as ints, and taking the time to define what each column should be coming in as in our config), or choosing to bring everything in as a string, and leave all transformations to be done with DBT in the database.\n\nDoes anyone have thoughts on what downsides I may be missing to the second approach? I expect that it would be more costly, though the nature of our work involves frequent new pipeline setups with shifting schemas, so it would be good if we can streamline things in this way.\n\nWe're using Pandas to pull in the data from CSV currently, and pushing to snowflake with the Snowflake \\`write\\_pandas\\` tool.", "author_fullname": "t2_7yr26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Direct loading to Snowflake\u2014to typecast or not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103dp2x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672863610.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672863269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m running into some design choices which hinge on us either choosing the datatype for columns on their load into snowflake (for instance, bringing ints in as ints, and taking the time to define what each column should be coming in as in our config), or choosing to bring everything in as a string, and leave all transformations to be done with DBT in the database.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have thoughts on what downsides I may be missing to the second approach? I expect that it would be more costly, though the nature of our work involves frequent new pipeline setups with shifting schemas, so it would be good if we can streamline things in this way.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Pandas to pull in the data from CSV currently, and pushing to snowflake with the Snowflake `write_pandas` tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103dp2x", "is_robot_indexable": true, "report_reasons": null, "author": "nathanak21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103dp2x/direct_loading_to_snowflaketo_typecast_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103dp2x/direct_loading_to_snowflaketo_typecast_or_not/", "subreddit_subscribers": 85188, "created_utc": 1672863269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5r54hksr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Your ML Data Back: Open-Source Tool to Export Your MLFlow Data to SQLite", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_103a1de", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wXN1kwi7w4hRgvN57lDikPY8juBMJ0huUQAEaBSvho8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672854862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ploomber.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ploomber.io/blog/mlflow2sql/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?auto=webp&amp;s=a01611b4c500985bec4eea7c81b9625f4fc84a8e", "width": 2402, "height": 1262}, "resolutions": [{"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d1d9ae27f0ab4cdf6194eaccce264d2df0ec7eb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=59f9f616fd7113e5fd2b154d26c36fb0c6c92b19", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b6566be246f6de95ceb35ad40145567b4fee505", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98b5bf2fa38b93b98c3d05573b811b24efd21bbb", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49a1defd0a799cb42ab84d35032b27f24a29b5f9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hfTF3Q4_x-cMAq8YTaz4fhcsyvt7F4FdJfqKbGLOekI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f206bfc6ef7a6b1ff19803d79315e77c5f727f05", "width": 1080, "height": 567}], "variants": {}, "id": "Objw1E7bxh1q2DHkIbVVfKXOpJIwmJvOhOKLMKIjEEs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "103a1de", "is_robot_indexable": true, "report_reasons": null, "author": "ploomber-io", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103a1de/get_your_ml_data_back_opensource_tool_to_export/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ploomber.io/blog/mlflow2sql/", "subreddit_subscribers": 85188, "created_utc": 1672854862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI\u2019m not currently in a DE role, but I\u2019ve been asked to centralise &amp; visualise data for my (small) team using Power BI &amp; SharePoint\n\nWe have data on the team members, client projects each of us are working on, skills/tools we\u2019re competent in, codes associated with each project we can put into our timecards, among other things.\n\nRight now this data either exists in our heads or in random excel spreadsheets scattered about.\n\nI\u2019ve considered setting up a MS Access database given that there won\u2019t be much data &amp; that there are many-to-many relationships (e.g, skills matrix), and perhaps linking some of the tables to SharePoint Lists so the team can more easily update the data - then connecting all this to Power BI and linking this within my Team\u2019s SharePoint Site.\n\nJust wondering if this is a bad idea, and if anyone has any suggestions. I\u2019m trying to keep things simple &amp; maintainable, and allow for Team members to update their skills or projects they are working in without much fuss.", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SharePoint &amp; MS Access ok solutions for data centralisation &amp; visualisation in a small team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1034f9r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672840995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not currently in a DE role, but I\u2019ve been asked to centralise &amp;amp; visualise data for my (small) team using Power BI &amp;amp; SharePoint&lt;/p&gt;\n\n&lt;p&gt;We have data on the team members, client projects each of us are working on, skills/tools we\u2019re competent in, codes associated with each project we can put into our timecards, among other things.&lt;/p&gt;\n\n&lt;p&gt;Right now this data either exists in our heads or in random excel spreadsheets scattered about.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve considered setting up a MS Access database given that there won\u2019t be much data &amp;amp; that there are many-to-many relationships (e.g, skills matrix), and perhaps linking some of the tables to SharePoint Lists so the team can more easily update the data - then connecting all this to Power BI and linking this within my Team\u2019s SharePoint Site.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if this is a bad idea, and if anyone has any suggestions. I\u2019m trying to keep things simple &amp;amp; maintainable, and allow for Team members to update their skills or projects they are working in without much fuss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1034f9r", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1034f9r/sharepoint_ms_access_ok_solutions_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1034f9r/sharepoint_ms_access_ok_solutions_for_data/", "subreddit_subscribers": 85188, "created_utc": 1672840995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I'm a college student right now and I'm officially declared as a double major in computer science and data science. I started college wanting to complete both, however I eventually realized the workload was just too much, and only took CS classes this past semester with no intention of completing my data science major requirements. However, I'm still officially declared as both and on my resume, linkedin, school recruitment portal, etc. it still says that I'm both. \n\nI should note that I have a \"relevant coursework\" section on my resume, so I'm being transparent about exactly what classes I've taken, and in all the interviews I've had so far, no employers have really even asked about my major(s), they've seemed to care way more about internship experience and specific coursework. \n\nAny thoughts would be appreciated. Thanks", "author_fullname": "t2_u0b7yebe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unethical to keep a double major on resume even if I intend to drop it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103kudn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672880188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m a college student right now and I&amp;#39;m officially declared as a double major in computer science and data science. I started college wanting to complete both, however I eventually realized the workload was just too much, and only took CS classes this past semester with no intention of completing my data science major requirements. However, I&amp;#39;m still officially declared as both and on my resume, linkedin, school recruitment portal, etc. it still says that I&amp;#39;m both. &lt;/p&gt;\n\n&lt;p&gt;I should note that I have a &amp;quot;relevant coursework&amp;quot; section on my resume, so I&amp;#39;m being transparent about exactly what classes I&amp;#39;ve taken, and in all the interviews I&amp;#39;ve had so far, no employers have really even asked about my major(s), they&amp;#39;ve seemed to care way more about internship experience and specific coursework. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts would be appreciated. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103kudn", "is_robot_indexable": true, "report_reasons": null, "author": "sheepbatman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103kudn/unethical_to_keep_a_double_major_on_resume_even/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103kudn/unethical_to_keep_a_double_major_on_resume_even/", "subreddit_subscribers": 85188, "created_utc": 1672880188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been hearing a lot about OLAP DB's with companies like ClickHouse and DuckDB - can someone who uses them in their org walk me through (in the simplest way) how this sits in your data stack, specific use case examples, and if I'm misunderstanding anything?\n\nI guess specific areas of confusion are what specific workflows OLAP DB's are being used for. At a high level I get that Clickhouse/DuckDB basically allow your team to run SQL queries on data that is not necessarily centralized (i.e., on an analyst's laptop, a random cloud endpoint, etc.) but how often does this come up? Was it difficult to gain adoption within your organization? How has this impacted your spend compared to using just Snowflake or whatever CDW?", "author_fullname": "t2_kve19uny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5 OLAP databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103kq8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672879887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been hearing a lot about OLAP DB&amp;#39;s with companies like ClickHouse and DuckDB - can someone who uses them in their org walk me through (in the simplest way) how this sits in your data stack, specific use case examples, and if I&amp;#39;m misunderstanding anything?&lt;/p&gt;\n\n&lt;p&gt;I guess specific areas of confusion are what specific workflows OLAP DB&amp;#39;s are being used for. At a high level I get that Clickhouse/DuckDB basically allow your team to run SQL queries on data that is not necessarily centralized (i.e., on an analyst&amp;#39;s laptop, a random cloud endpoint, etc.) but how often does this come up? Was it difficult to gain adoption within your organization? How has this impacted your spend compared to using just Snowflake or whatever CDW?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103kq8h", "is_robot_indexable": true, "report_reasons": null, "author": "y0urm0m82", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103kq8h/eli5_olap_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103kq8h/eli5_olap_databases/", "subreddit_subscribers": 85188, "created_utc": 1672879887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://memphis-dev.medium.com/memphis-dev-event-driven-2-0-9be884bab1e2](https://memphis-dev.medium.com/memphis-dev-event-driven-2-0-9be884bab1e2)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event Driven 2.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103bciw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672857846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://memphis-dev.medium.com/memphis-dev-event-driven-2-0-9be884bab1e2\"&gt;https://memphis-dev.medium.com/memphis-dev-event-driven-2-0-9be884bab1e2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?auto=webp&amp;s=b97954d73ffeb765174be750976191506bbf07f3", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=166c1ee55952a69a81770edf907f25176bfec22f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=621c511b51433c0b69a6ee0a643c1f443d2dabff", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8896fecb52c14c2562a678a34fd3c631a2ce86b3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8df222fa31b6f0e98d326dcbb65423706448004e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b59b1a43cf79e3fce46f46efe8fb20776f82f116", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/GVs2LeWhEigk_5F3_8UsDdPTa4DvZ1iR0gf4-qtaIxc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=03fbb61ca9c44d2324e97a724c8ba6d66318e325", "width": 1080, "height": 607}], "variants": {}, "id": "kFIoN7woyuD_BLelZb1ThQDWGropux-yn9HXyH1PbBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "103bciw", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103bciw/event_driven_20/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103bciw/event_driven_20/", "subreddit_subscribers": 85188, "created_utc": 1672857846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a new data source containing thousands of multi GB json files (about 1,500 per calendar year) with [tens of] millions of rows of data each, and a bunch of data scientists and software engineers who are comfortable working in Spark. \n\nMost common analysis of these files will be done on a per year basis (e.g. looking at ~1500 at once) or on a file by file basis.\n\nI'm a relative novice here when it comes to data bigger than my standard relational DB can handle nicely. What are my best options for warehousing this data? If I were forbidden from going with a heavily proprietary set up (e.g. Databricks, Snowflake, etc.), are there alternatives this community would recommend?", "author_fullname": "t2_7b85k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed: Data warehousing and Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103bamo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672857715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a new data source containing thousands of multi GB json files (about 1,500 per calendar year) with [tens of] millions of rows of data each, and a bunch of data scientists and software engineers who are comfortable working in Spark. &lt;/p&gt;\n\n&lt;p&gt;Most common analysis of these files will be done on a per year basis (e.g. looking at ~1500 at once) or on a file by file basis.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a relative novice here when it comes to data bigger than my standard relational DB can handle nicely. What are my best options for warehousing this data? If I were forbidden from going with a heavily proprietary set up (e.g. Databricks, Snowflake, etc.), are there alternatives this community would recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103bamo", "is_robot_indexable": true, "report_reasons": null, "author": "elopeRstatS", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103bamo/advice_needed_data_warehousing_and_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103bamo/advice_needed_data_warehousing_and_spark/", "subreddit_subscribers": 85188, "created_utc": 1672857715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Well, among other tools I want to learn Tableau, but as title points out if I start learning it now I only have 14 days (macOS). What next?", "author_fullname": "t2_124xcawu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep learning Tableau after your 14-day license expires?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103ay19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672856922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Well, among other tools I want to learn Tableau, but as title points out if I start learning it now I only have 14 days (macOS). What next?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "103ay19", "is_robot_indexable": true, "report_reasons": null, "author": "maybenexttime82", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103ay19/how_to_keep_learning_tableau_after_your_14day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103ay19/how_to_keep_learning_tableau_after_your_14day/", "subreddit_subscribers": 85188, "created_utc": 1672856922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since 2006, dotFish has been iterating on this tool and it does so many useful things.  It supports 25 different databases and data systems, with many useful helper features for each type.  I can't think of a more versatile db query tool out there.\n\nhttps://fishcodelib.com/Database.htm", "author_fullname": "t2_22rf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to share with you fantastic tool: Database .NET", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103kxyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672880432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since 2006, dotFish has been iterating on this tool and it does so many useful things.  It supports 25 different databases and data systems, with many useful helper features for each type.  I can&amp;#39;t think of a more versatile db query tool out there.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://fishcodelib.com/Database.htm\"&gt;https://fishcodelib.com/Database.htm&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103kxyw", "is_robot_indexable": true, "report_reasons": null, "author": "mycall", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103kxyw/i_want_to_share_with_you_fantastic_tool_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103kxyw/i_want_to_share_with_you_fantastic_tool_database/", "subreddit_subscribers": 85188, "created_utc": 1672880432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to get a feel for the industry standard at this time: if your company did an internship what was the duration, time commitment, stipend, and industry? If you think location is relevant maybe you could provide that.", "author_fullname": "t2_ossxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "US based Internship Stipends", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103es9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672865790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a feel for the industry standard at this time: if your company did an internship what was the duration, time commitment, stipend, and industry? If you think location is relevant maybe you could provide that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "103es9p", "is_robot_indexable": true, "report_reasons": null, "author": "kaumaron", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/103es9p/us_based_internship_stipends/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103es9p/us_based_internship_stipends/", "subreddit_subscribers": 85188, "created_utc": 1672865790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am Big Data Developer and I have offer an offer as Foundry Support Engineer(much better money - 2times more per hour) in big USA company [Palantir]. I wonder if it good choice or not\n\nReponsibilities o Foundry Support Engineer in Palantir:\n\n- Developing a deep understanding of Foundry applications so they can leverage problem-solving\n\n- Building technical expertise on specific parts of the platform to provide technical support to Data Engineers working in Foundry;\n\n- Collaborating with product engineers to identify, root cause, and ultimately resolve bugs surfaced by users;\n\nTech stack : Python, PySpark", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't know what to do - need advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103clkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672863041.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672860714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am Big Data Developer and I have offer an offer as Foundry Support Engineer(much better money - 2times more per hour) in big USA company [Palantir]. I wonder if it good choice or not&lt;/p&gt;\n\n&lt;p&gt;Reponsibilities o Foundry Support Engineer in Palantir:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Developing a deep understanding of Foundry applications so they can leverage problem-solving&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Building technical expertise on specific parts of the platform to provide technical support to Data Engineers working in Foundry;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Collaborating with product engineers to identify, root cause, and ultimately resolve bugs surfaced by users;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech stack : Python, PySpark&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "103clkv", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/103clkv/i_dont_know_what_to_do_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/103clkv/i_dont_know_what_to_do_need_advice/", "subreddit_subscribers": 85188, "created_utc": 1672860714.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}